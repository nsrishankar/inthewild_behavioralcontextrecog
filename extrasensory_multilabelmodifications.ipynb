{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dataset-parsers-and-cleaning-functions\" data-toc-modified-id=\"Dataset-parsers-and-cleaning-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset parsers and cleaning functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-data\" data-toc-modified-id=\"Test-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Test data</a></span></li></ul></li><li><span><a href=\"#Training-Functions\" data-toc-modified-id=\"Training-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-new-data-structure-for-all-valid-data-and-pickling-it\" data-toc-modified-id=\"Creating-a-new-data-structure-for-all-valid-data-and-pickling-it-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Creating a new data structure for all valid data and pickling it</a></span></li><li><span><a href=\"#Creating-and-pickling-instance-weight-matrix\" data-toc-modified-id=\"Creating-and-pickling-instance-weight-matrix-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating and pickling instance weight matrix</a></span></li><li><span><a href=\"#Loading-data-and-instance-weight-matrix\" data-toc-modified-id=\"Loading-data-and-instance-weight-matrix-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Loading data and instance weight matrix</a></span></li><li><span><a href=\"#Miscellaneous-train/test-functions\" data-toc-modified-id=\"Miscellaneous-train/test-functions-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Miscellaneous train/test functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cuda-enable\" data-toc-modified-id=\"Cuda-enable-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Cuda-enable</a></span></li><li><span><a href=\"#Tackling-missing-labels-using-a-mask\" data-toc-modified-id=\"Tackling-missing-labels-using-a-mask-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Tackling missing labels using a mask</a></span></li><li><span><a href=\"#Linear-Learning-Rate-scheduler\" data-toc-modified-id=\"Linear-Learning-Rate-scheduler-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Linear Learning-Rate scheduler</a></span></li><li><span><a href=\"#Euclidean-Norm-for-weight-matrices\" data-toc-modified-id=\"Euclidean-Norm-for-weight-matrices-3.4.4\"><span class=\"toc-item-num\">3.4.4&nbsp;&nbsp;</span>Euclidean Norm for weight matrices</a></span></li><li><span><a href=\"#Accuracy-(Precision,-Recall,-F1,-Support,-Balanced-Accuracy)-metrics\" data-toc-modified-id=\"Accuracy-(Precision,-Recall,-F1,-Support,-Balanced-Accuracy)-metrics-3.4.5\"><span class=\"toc-item-num\">3.4.5&nbsp;&nbsp;</span>Accuracy (Precision, Recall, F1, Support, Balanced Accuracy) metrics</a></span></li><li><span><a href=\"#K-Fold-cross-validation\" data-toc-modified-id=\"K-Fold-cross-validation-3.4.6\"><span class=\"toc-item-num\">3.4.6&nbsp;&nbsp;</span>K-Fold cross validation</a></span></li><li><span><a href=\"#Train/Fit-function\" data-toc-modified-id=\"Train/Fit-function-3.4.7\"><span class=\"toc-item-num\">3.4.7&nbsp;&nbsp;</span>Train/Fit function</a></span></li></ul></li></ul></li><li><span><a href=\"#Multi-Class-Classifier:-Learning-and-Evaluation\" data-toc-modified-id=\"Multi-Class-Classifier:-Learning-and-Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Multi Class Classifier: Learning and Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Global-Hyperparameter-variables\" data-toc-modified-id=\"Global-Hyperparameter-variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Global Hyperparameter variables</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(0-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(0-Hidden-Layers)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Multi-Layer Perceptron (0 Hidden Layers)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(1-Hidden-Layer)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(1-Hidden-Layer)-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Multi-Layer Perceptron (1 Hidden Layer)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers)-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers, with Dropout)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "from io import StringIO\n",
    "import importlib.machinery\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TT_split\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier as OvR\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,balanced_accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "#from sklearn.metrics import multilabel_confusion_matrix # Only available in dev .21\n",
    "\n",
    "# Need Pytorch for multilabel classifications\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "#import skorch [Scikit-learn wrapper around Pytorch so allowing for K-fold cross-validation]\n",
    "from sklearn.model_selection import KFold\n",
    "random_state=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Data location and sample user\n",
    "prefix='dataset/Extrasensory_uuid_fl_uTAR/'\n",
    "cross_validation_user_loc='dataset/cv_5_folds/'\n",
    "user_sample='3600D531-0C55-44A7-AE95-A7A38519464E.features_labels'\n",
    "done=0 # Pickled files are created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset parsers and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dataset parsers for header/ body for CSVs\n",
    "def parse_header_of_csv(csv_str):\n",
    "    # Isolate the headline columns:\n",
    "    headline = csv_str[:csv_str.index('\\n')];\n",
    "    columns = headline.split(',');\n",
    "\n",
    "    # The first column should be timestamp:\n",
    "    assert columns[0] == 'timestamp';\n",
    "    # The last column should be label_source:\n",
    "    assert columns[-1] == 'label_source';\n",
    "    \n",
    "    # Search for the column of the first label:\n",
    "    for (ci,col) in enumerate(columns):\n",
    "        if col.startswith('label:'):\n",
    "            first_label_ind = ci;\n",
    "            break;\n",
    "        pass;\n",
    "\n",
    "    # Feature columns come after timestamp and before the labels:\n",
    "    feature_names = columns[1:first_label_ind];\n",
    "    # Then come the labels, till the one-before-last column:\n",
    "    label_names = columns[first_label_ind:-1];\n",
    "    for (li,label) in enumerate(label_names):\n",
    "        # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n",
    "        assert label.startswith('label:');\n",
    "        label_names[li] = label.replace('label:','');\n",
    "        pass;\n",
    "    \n",
    "    return (feature_names,label_names);\n",
    "\n",
    "def parse_body_of_csv(csv_str,n_features):\n",
    "    # Read the entire CSV body into a single numeric matrix:\n",
    "    full_table = np.loadtxt(StringIO(csv_str),delimiter=',',skiprows=1);\n",
    "    \n",
    "    # Timestamp is the primary key for the records (examples):\n",
    "    timestamps = full_table[:,0].astype(int);\n",
    "    \n",
    "    # Read the sensor features:\n",
    "    X = full_table[:,1:(n_features+1)];\n",
    "    \n",
    "    # Read the binary label values, and the 'missing label' indicators:\n",
    "    trinary_labels_mat = full_table[:,(n_features+1):-1]; # This should have values of either 0., 1. or NaN\n",
    "    M = np.isnan(trinary_labels_mat); # M is the missing label matrix\n",
    "    \n",
    "    #print(\"M matrix shape:\",M.shape)\n",
    "    #print(\"Matrix: \",np.argwhere(M))\n",
    "    \n",
    "    Y = np.where(M,0,trinary_labels_mat) > 0.; # Y is the label matrix\n",
    "    \n",
    "    return (X,Y,M,timestamps);\n",
    "\n",
    "def read_user_data(directory):\n",
    "    print('Reading {}'.format(directory.split(\"/\")[-1]))\n",
    "\n",
    "    # Read the entire csv file of the user:\n",
    "    with gzip.open(directory,'rb') as fid:\n",
    "        csv_str = fid.read();\n",
    "        csv_str = csv_str.decode(\"utf-8\")\n",
    "        pass;\n",
    "\n",
    "    (feature_names,label_names) = parse_header_of_csv(csv_str);\n",
    "    n_features = len(feature_names);\n",
    "    (X,Y,M,timestamps) = parse_body_of_csv(csv_str,n_features);\n",
    "\n",
    "    return (X,Y,M,timestamps,feature_names,label_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean labels\n",
    "def clean_labels(input_label):\n",
    "    if label.endswith('_'):\n",
    "        label=label[:-1]+')'\n",
    "    label=label.replace('__',' (').replace('_',' ')\n",
    "    label=label[0]+label[1:].lower()\n",
    "    label=label.replace('i m','I\\'m')\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get a summary of the sensor feature\n",
    "'''\n",
    "# Summarize features as we are only using phone_acc,phone_gyro,phone_mag,phone_loc,phone_audio,\n",
    "# phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "# We are ignoring the use of the smartwatch features. There are definitely features that will be used\n",
    "# much more (e.g. than the phone_callstat) but we'll leave that up to the ML algorithm.\n",
    "'''\n",
    "def summarize_features(feature_list):\n",
    "    summary_feature_list=np.empty_like(feature_list)\n",
    "    for (ind,feature) in enumerate(feature_list):\n",
    "        if feature.startswith('raw_acc'):\n",
    "            summary_feature_list[ind]='phone_acc' \n",
    "        if feature.startswith('proc_gyro'):\n",
    "            summary_feature_list[ind]='phone_gyro'\n",
    "        if feature.startswith('raw_magnet'):\n",
    "            summary_feature_list[ind]='phone_mag'\n",
    "        if feature.startswith('watch_acc'):\n",
    "            summary_feature_list[ind]='watch_acc'\n",
    "        if feature.startswith('watch_heading'):\n",
    "            summary_feature_list[ind]='watch_dir'\n",
    "        if feature.startswith('location'):\n",
    "            summary_feature_list[ind]='phone_loc'\n",
    "        if feature.startswith('audio_naive'):\n",
    "            summary_feature_list[ind]='phone_audio'\n",
    "        if feature.startswith('discrete:app_state'):\n",
    "            summary_feature_list[ind]='phone_app'\n",
    "        if feature.startswith('discrete:battery'):\n",
    "            summary_feature_list[ind]='phone_battery'\n",
    "        if feature.startswith('discrete:on'):\n",
    "            summary_feature_list[ind]='phone_use'\n",
    "        if feature.startswith('discrete:ringer'):\n",
    "            summary_feature_list[ind]='phone_callstat'\n",
    "        if feature.startswith('discrete:wifi'):\n",
    "            summary_feature_list[ind]='phone_wifi'\n",
    "        if feature.startswith('lf'):\n",
    "            summary_feature_list[ind]='phone_lf'\n",
    "        if feature.startswith('discrete:time'):\n",
    "            summary_feature_list[ind]='phone_time'\n",
    "\n",
    "    return summary_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Custom dictionary class with help for duplicate keys\n",
    "class Customdictionary(dict):\n",
    "    def __setitem__(self,key,value):\n",
    "        try:\n",
    "            self[key]\n",
    "        except KeyError:\n",
    "            super(Customdictionary,self).__setitem__(key,[])\n",
    "        self[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "Data shape input for user (Len minutes/num examples, num sensors):  (5203, 225)\n",
      "Label shape for user (Len minutes, num labels):  (5203, 51) \n",
      "\n",
      "Sensor feature names:\n",
      "\n",
      "0 :: phone_acc ::--> raw_acc:magnitude_stats:mean\n",
      "\n",
      "1 :: phone_acc ::--> raw_acc:magnitude_stats:std\n",
      "\n",
      "2 :: phone_acc ::--> raw_acc:magnitude_stats:moment3\n",
      "\n",
      "3 :: phone_acc ::--> raw_acc:magnitude_stats:moment4\n",
      "\n",
      "4 :: phone_acc ::--> raw_acc:magnitude_stats:percentile25\n",
      "\n",
      "5 :: phone_acc ::--> raw_acc:magnitude_stats:percentile50\n",
      "\n",
      "6 :: phone_acc ::--> raw_acc:magnitude_stats:percentile75\n",
      "\n",
      "7 :: phone_acc ::--> raw_acc:magnitude_stats:value_entropy\n",
      "\n",
      "8 :: phone_acc ::--> raw_acc:magnitude_stats:time_entropy\n",
      "\n",
      "9 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "10 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "11 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "12 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "13 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "14 :: phone_acc ::--> raw_acc:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "15 :: phone_acc ::--> raw_acc:magnitude_autocorrelation:period\n",
      "\n",
      "16 :: phone_acc ::--> raw_acc:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "17 :: phone_acc ::--> raw_acc:3d:mean_x\n",
      "\n",
      "18 :: phone_acc ::--> raw_acc:3d:mean_y\n",
      "\n",
      "19 :: phone_acc ::--> raw_acc:3d:mean_z\n",
      "\n",
      "20 :: phone_acc ::--> raw_acc:3d:std_x\n",
      "\n",
      "21 :: phone_acc ::--> raw_acc:3d:std_y\n",
      "\n",
      "22 :: phone_acc ::--> raw_acc:3d:std_z\n",
      "\n",
      "23 :: phone_acc ::--> raw_acc:3d:ro_xy\n",
      "\n",
      "24 :: phone_acc ::--> raw_acc:3d:ro_xz\n",
      "\n",
      "25 :: phone_acc ::--> raw_acc:3d:ro_yz\n",
      "\n",
      "26 :: phone_gyro ::--> proc_gyro:magnitude_stats:mean\n",
      "\n",
      "27 :: phone_gyro ::--> proc_gyro:magnitude_stats:std\n",
      "\n",
      "28 :: phone_gyro ::--> proc_gyro:magnitude_stats:moment3\n",
      "\n",
      "29 :: phone_gyro ::--> proc_gyro:magnitude_stats:moment4\n",
      "\n",
      "30 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile25\n",
      "\n",
      "31 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile50\n",
      "\n",
      "32 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile75\n",
      "\n",
      "33 :: phone_gyro ::--> proc_gyro:magnitude_stats:value_entropy\n",
      "\n",
      "34 :: phone_gyro ::--> proc_gyro:magnitude_stats:time_entropy\n",
      "\n",
      "35 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "36 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "37 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "38 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "39 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "40 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "41 :: phone_gyro ::--> proc_gyro:magnitude_autocorrelation:period\n",
      "\n",
      "42 :: phone_gyro ::--> proc_gyro:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "43 :: phone_gyro ::--> proc_gyro:3d:mean_x\n",
      "\n",
      "44 :: phone_gyro ::--> proc_gyro:3d:mean_y\n",
      "\n",
      "45 :: phone_gyro ::--> proc_gyro:3d:mean_z\n",
      "\n",
      "46 :: phone_gyro ::--> proc_gyro:3d:std_x\n",
      "\n",
      "47 :: phone_gyro ::--> proc_gyro:3d:std_y\n",
      "\n",
      "48 :: phone_gyro ::--> proc_gyro:3d:std_z\n",
      "\n",
      "49 :: phone_gyro ::--> proc_gyro:3d:ro_xy\n",
      "\n",
      "50 :: phone_gyro ::--> proc_gyro:3d:ro_xz\n",
      "\n",
      "51 :: phone_gyro ::--> proc_gyro:3d:ro_yz\n",
      "\n",
      "52 :: phone_mag ::--> raw_magnet:magnitude_stats:mean\n",
      "\n",
      "53 :: phone_mag ::--> raw_magnet:magnitude_stats:std\n",
      "\n",
      "54 :: phone_mag ::--> raw_magnet:magnitude_stats:moment3\n",
      "\n",
      "55 :: phone_mag ::--> raw_magnet:magnitude_stats:moment4\n",
      "\n",
      "56 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile25\n",
      "\n",
      "57 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile50\n",
      "\n",
      "58 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile75\n",
      "\n",
      "59 :: phone_mag ::--> raw_magnet:magnitude_stats:value_entropy\n",
      "\n",
      "60 :: phone_mag ::--> raw_magnet:magnitude_stats:time_entropy\n",
      "\n",
      "61 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "62 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "63 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "64 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "65 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "66 :: phone_mag ::--> raw_magnet:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "67 :: phone_mag ::--> raw_magnet:magnitude_autocorrelation:period\n",
      "\n",
      "68 :: phone_mag ::--> raw_magnet:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "69 :: phone_mag ::--> raw_magnet:3d:mean_x\n",
      "\n",
      "70 :: phone_mag ::--> raw_magnet:3d:mean_y\n",
      "\n",
      "71 :: phone_mag ::--> raw_magnet:3d:mean_z\n",
      "\n",
      "72 :: phone_mag ::--> raw_magnet:3d:std_x\n",
      "\n",
      "73 :: phone_mag ::--> raw_magnet:3d:std_y\n",
      "\n",
      "74 :: phone_mag ::--> raw_magnet:3d:std_z\n",
      "\n",
      "75 :: phone_mag ::--> raw_magnet:3d:ro_xy\n",
      "\n",
      "76 :: phone_mag ::--> raw_magnet:3d:ro_xz\n",
      "\n",
      "77 :: phone_mag ::--> raw_magnet:3d:ro_yz\n",
      "\n",
      "78 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range0\n",
      "\n",
      "79 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range1\n",
      "\n",
      "80 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range2\n",
      "\n",
      "81 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range3\n",
      "\n",
      "82 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range4\n",
      "\n",
      "83 :: watch_acc ::--> watch_acceleration:magnitude_stats:mean\n",
      "\n",
      "84 :: watch_acc ::--> watch_acceleration:magnitude_stats:std\n",
      "\n",
      "85 :: watch_acc ::--> watch_acceleration:magnitude_stats:moment3\n",
      "\n",
      "86 :: watch_acc ::--> watch_acceleration:magnitude_stats:moment4\n",
      "\n",
      "87 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile25\n",
      "\n",
      "88 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile50\n",
      "\n",
      "89 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile75\n",
      "\n",
      "90 :: watch_acc ::--> watch_acceleration:magnitude_stats:value_entropy\n",
      "\n",
      "91 :: watch_acc ::--> watch_acceleration:magnitude_stats:time_entropy\n",
      "\n",
      "92 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "93 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "94 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "95 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "96 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "97 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "98 :: watch_acc ::--> watch_acceleration:magnitude_autocorrelation:period\n",
      "\n",
      "99 :: watch_acc ::--> watch_acceleration:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "100 :: watch_acc ::--> watch_acceleration:3d:mean_x\n",
      "\n",
      "101 :: watch_acc ::--> watch_acceleration:3d:mean_y\n",
      "\n",
      "102 :: watch_acc ::--> watch_acceleration:3d:mean_z\n",
      "\n",
      "103 :: watch_acc ::--> watch_acceleration:3d:std_x\n",
      "\n",
      "104 :: watch_acc ::--> watch_acceleration:3d:std_y\n",
      "\n",
      "105 :: watch_acc ::--> watch_acceleration:3d:std_z\n",
      "\n",
      "106 :: watch_acc ::--> watch_acceleration:3d:ro_xy\n",
      "\n",
      "107 :: watch_acc ::--> watch_acceleration:3d:ro_xz\n",
      "\n",
      "108 :: watch_acc ::--> watch_acceleration:3d:ro_yz\n",
      "\n",
      "109 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band0\n",
      "\n",
      "110 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band1\n",
      "\n",
      "111 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band2\n",
      "\n",
      "112 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band3\n",
      "\n",
      "113 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band4\n",
      "\n",
      "114 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band0\n",
      "\n",
      "115 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band1\n",
      "\n",
      "116 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band2\n",
      "\n",
      "117 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band3\n",
      "\n",
      "118 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band4\n",
      "\n",
      "119 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band0\n",
      "\n",
      "120 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band1\n",
      "\n",
      "121 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band2\n",
      "\n",
      "122 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band3\n",
      "\n",
      "123 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band4\n",
      "\n",
      "124 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range0\n",
      "\n",
      "125 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range1\n",
      "\n",
      "126 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range2\n",
      "\n",
      "127 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range3\n",
      "\n",
      "128 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range4\n",
      "\n",
      "129 :: watch_dir ::--> watch_heading:mean_cos\n",
      "\n",
      "130 :: watch_dir ::--> watch_heading:std_cos\n",
      "\n",
      "131 :: watch_dir ::--> watch_heading:mom3_cos\n",
      "\n",
      "132 :: watch_dir ::--> watch_heading:mom4_cos\n",
      "\n",
      "133 :: watch_dir ::--> watch_heading:mean_sin\n",
      "\n",
      "134 :: watch_dir ::--> watch_heading:std_sin\n",
      "\n",
      "135 :: watch_dir ::--> watch_heading:mom3_sin\n",
      "\n",
      "136 :: watch_dir ::--> watch_heading:mom4_sin\n",
      "\n",
      "137 :: watch_dir ::--> watch_heading:entropy_8bins\n",
      "\n",
      "138 :: phone_loc ::--> location:num_valid_updates\n",
      "\n",
      "139 :: phone_loc ::--> location:log_latitude_range\n",
      "\n",
      "140 :: phone_loc ::--> location:log_longitude_range\n",
      "\n",
      "141 :: phone_loc ::--> location:min_altitude\n",
      "\n",
      "142 :: phone_loc ::--> location:max_altitude\n",
      "\n",
      "143 :: phone_loc ::--> location:min_speed\n",
      "\n",
      "144 :: phone_loc ::--> location:max_speed\n",
      "\n",
      "145 :: phone_loc ::--> location:best_horizontal_accuracy\n",
      "\n",
      "146 :: phone_loc ::--> location:best_vertical_accuracy\n",
      "\n",
      "147 :: phone_loc ::--> location:diameter\n",
      "\n",
      "148 :: phone_loc ::--> location:log_diameter\n",
      "\n",
      "149 :: phone_loc ::--> location_quick_features:std_lat\n",
      "\n",
      "150 :: phone_loc ::--> location_quick_features:std_long\n",
      "\n",
      "151 :: phone_loc ::--> location_quick_features:lat_change\n",
      "\n",
      "152 :: phone_loc ::--> location_quick_features:long_change\n",
      "\n",
      "153 :: phone_loc ::--> location_quick_features:mean_abs_lat_deriv\n",
      "\n",
      "154 :: phone_loc ::--> location_quick_features:mean_abs_long_deriv\n",
      "\n",
      "155 :: phone_audio ::--> audio_naive:mfcc0:mean\n",
      "\n",
      "156 :: phone_audio ::--> audio_naive:mfcc1:mean\n",
      "\n",
      "157 :: phone_audio ::--> audio_naive:mfcc2:mean\n",
      "\n",
      "158 :: phone_audio ::--> audio_naive:mfcc3:mean\n",
      "\n",
      "159 :: phone_audio ::--> audio_naive:mfcc4:mean\n",
      "\n",
      "160 :: phone_audio ::--> audio_naive:mfcc5:mean\n",
      "\n",
      "161 :: phone_audio ::--> audio_naive:mfcc6:mean\n",
      "\n",
      "162 :: phone_audio ::--> audio_naive:mfcc7:mean\n",
      "\n",
      "163 :: phone_audio ::--> audio_naive:mfcc8:mean\n",
      "\n",
      "164 :: phone_audio ::--> audio_naive:mfcc9:mean\n",
      "\n",
      "165 :: phone_audio ::--> audio_naive:mfcc10:mean\n",
      "\n",
      "166 :: phone_audio ::--> audio_naive:mfcc11:mean\n",
      "\n",
      "167 :: phone_audio ::--> audio_naive:mfcc12:mean\n",
      "\n",
      "168 :: phone_audio ::--> audio_naive:mfcc0:std\n",
      "\n",
      "169 :: phone_audio ::--> audio_naive:mfcc1:std\n",
      "\n",
      "170 :: phone_audio ::--> audio_naive:mfcc2:std\n",
      "\n",
      "171 :: phone_audio ::--> audio_naive:mfcc3:std\n",
      "\n",
      "172 :: phone_audio ::--> audio_naive:mfcc4:std\n",
      "\n",
      "173 :: phone_audio ::--> audio_naive:mfcc5:std\n",
      "\n",
      "174 :: phone_audio ::--> audio_naive:mfcc6:std\n",
      "\n",
      "175 :: phone_audio ::--> audio_naive:mfcc7:std\n",
      "\n",
      "176 :: phone_audio ::--> audio_naive:mfcc8:std\n",
      "\n",
      "177 :: phone_audio ::--> audio_naive:mfcc9:std\n",
      "\n",
      "178 :: phone_audio ::--> audio_naive:mfcc10:std\n",
      "\n",
      "179 :: phone_audio ::--> audio_naive:mfcc11:std\n",
      "\n",
      "180 :: phone_audio ::--> audio_naive:mfcc12:std\n",
      "\n",
      "181 ::  ::--> audio_properties:max_abs_value\n",
      "\n",
      "182 ::  ::--> audio_properties:normalization_multiplier\n",
      "\n",
      "183 :: phone_app ::--> discrete:app_state:is_active\n",
      "\n",
      "184 :: phone_app ::--> discrete:app_state:is_inactive\n",
      "\n",
      "185 :: phone_app ::--> discrete:app_state:is_background\n",
      "\n",
      "186 :: phone_app ::--> discrete:app_state:missing\n",
      "\n",
      "187 :: phone_battery ::--> discrete:battery_plugged:is_ac\n",
      "\n",
      "188 :: phone_battery ::--> discrete:battery_plugged:is_usb\n",
      "\n",
      "189 :: phone_battery ::--> discrete:battery_plugged:is_wireless\n",
      "\n",
      "190 :: phone_battery ::--> discrete:battery_plugged:missing\n",
      "\n",
      "191 :: phone_battery ::--> discrete:battery_state:is_unknown\n",
      "\n",
      "192 :: phone_battery ::--> discrete:battery_state:is_unplugged\n",
      "\n",
      "193 :: phone_battery ::--> discrete:battery_state:is_not_charging\n",
      "\n",
      "194 :: phone_battery ::--> discrete:battery_state:is_discharging\n",
      "\n",
      "195 :: phone_battery ::--> discrete:battery_state:is_charging\n",
      "\n",
      "196 :: phone_battery ::--> discrete:battery_state:is_full\n",
      "\n",
      "197 :: phone_battery ::--> discrete:battery_state:missing\n",
      "\n",
      "198 :: phone_use ::--> discrete:on_the_phone:is_False\n",
      "\n",
      "199 :: phone_use ::--> discrete:on_the_phone:is_True\n",
      "\n",
      "200 :: phone_use ::--> discrete:on_the_phone:missing\n",
      "\n",
      "201 :: phone_callstat ::--> discrete:ringer_mode:is_normal\n",
      "\n",
      "202 :: phone_callstat ::--> discrete:ringer_mode:is_silent_no_vibrate\n",
      "\n",
      "203 :: phone_callstat ::--> discrete:ringer_mode:is_silent_with_vibrate\n",
      "\n",
      "204 :: phone_callstat ::--> discrete:ringer_mode:missing\n",
      "\n",
      "205 :: phone_wifi ::--> discrete:wifi_status:is_not_reachable\n",
      "\n",
      "206 :: phone_wifi ::--> discrete:wifi_status:is_reachable_via_wifi\n",
      "\n",
      "207 :: phone_wifi ::--> discrete:wifi_status:is_reachable_via_wwan\n",
      "\n",
      "208 :: phone_wifi ::--> discrete:wifi_status:missing\n",
      "\n",
      "209 :: phone_lf ::--> lf_measurements:light\n",
      "\n",
      "210 :: phone_lf ::--> lf_measurements:pressure\n",
      "\n",
      "211 :: phone_lf ::--> lf_measurements:proximity_cm\n",
      "\n",
      "212 :: phone_lf ::--> lf_measurements:proximity\n",
      "\n",
      "213 :: phone_lf ::--> lf_measurements:relative_humidity\n",
      "\n",
      "214 :: phone_lf ::--> lf_measurements:battery_level\n",
      "\n",
      "215 :: phone_lf ::--> lf_measurements:screen_brightness\n",
      "\n",
      "216 :: phone_lf ::--> lf_measurements:temperature_ambient\n",
      "\n",
      "217 :: phone_time ::--> discrete:time_of_day:between0and6\n",
      "\n",
      "218 :: phone_time ::--> discrete:time_of_day:between3and9\n",
      "\n",
      "219 :: phone_time ::--> discrete:time_of_day:between6and12\n",
      "\n",
      "220 :: phone_time ::--> discrete:time_of_day:between9and15\n",
      "\n",
      "221 :: phone_time ::--> discrete:time_of_day:between12and18\n",
      "\n",
      "222 :: phone_time ::--> discrete:time_of_day:between15and21\n",
      "\n",
      "223 :: phone_time ::--> discrete:time_of_day:between18and24\n",
      "\n",
      "224 :: phone_time ::--> discrete:time_of_day:between21and3\n",
      "\n",
      "Activities and counts:\n",
      "[('LOC_home', 3040), ('OR_indoors', 2487), ('PHONE_ON_TABLE', 2179), ('SITTING', 1916), ('WITH_FRIENDS', 1730), ('LYING_DOWN', 1336), ('SLEEPING', 1021), ('WATCHING_TV', 912), ('EATING', 762), ('PHONE_IN_POCKET', 706), ('TALKING', 638), ('DRIVE_-_I_M_A_PASSENGER', 409), ('OR_standing', 384), ('IN_A_CAR', 342), ('OR_exercise', 162), ('AT_THE_GYM', 162), ('SINGING', 136), ('FIX_walking', 132), ('OR_outside', 127), ('SHOPPING', 111), ('AT_SCHOOL', 105), ('BATHING_-_SHOWER', 85), ('DRESSING', 67), ('DRINKING__ALCOHOL_', 66), ('PHONE_IN_HAND', 64), ('FIX_restaurant', 59), ('IN_CLASS', 54), ('PHONE_IN_BAG', 33), ('IN_A_MEETING', 27), ('TOILET', 12), ('COOKING', 5), ('ELEVATOR', 1), ('FIX_running', 0), ('BICYCLING', 0), ('LAB_WORK', 0), ('LOC_main_workplace', 0), ('ON_A_BUS', 0), ('DRIVE_-_I_M_THE_DRIVER', 0), ('STROLLING', 0), ('CLEANING', 0), ('DOING_LAUNDRY', 0), ('WASHING_DISHES', 0), ('SURFING_THE_INTERNET', 0), ('AT_A_PARTY', 0), ('AT_A_BAR', 0), ('LOC_beach', 0), ('COMPUTER_WORK', 0), ('GROOMING', 0), ('STAIRS_-_GOING_UP', 0), ('STAIRS_-_GOING_DOWN', 0), ('WITH_CO-WORKERS', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Reading sample data\n",
    "sample_loc='{}/{}.csv.gz'.format(prefix,user_sample)\n",
    "x_user,y_user,missedlabel_user,tstamp_user,featurename_user,labelname_user=read_user_data(sample_loc)\n",
    "\n",
    "# Dataset summaries for this user\n",
    "print('Data shape input for user (Len minutes/num examples, num sensors): ',x_user.shape) # Timestep examples, number of sensors\n",
    "print('Label shape for user (Len minutes, num labels): ',y_user.shape,'\\n') # Timestep examples, labels\n",
    "\n",
    "countlabels_user=np.sum(y_user,axis=0) # Column summary\n",
    "labelname_countlabel_user=zip(labelname_user,countlabels_user) # Zip together names, counts\n",
    "labelname_countlabel_user=sorted(labelname_countlabel_user,key=lambda row:row[-1],reverse=True)\n",
    "\n",
    "print('Sensor feature names:\\n')\n",
    "feature_names=summarize_features(featurename_user)\n",
    "    \n",
    "for i,sensor_feature in enumerate(featurename_user):\n",
    "    print('{} :: {} ::--> {}\\n'.format(i,feature_names[i],sensor_feature))\n",
    "\n",
    "print('Activities and counts:')\n",
    "print(labelname_countlabel_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    ISSUE: There are some labels (e.g. Phone location:bag etc.) that some users have not filled out for any timestep and shows up as np.nan. The label sum above was a check to see if the same label wasn't filled out for other users (hence would have a count of zero) and would let the label being completely removed. The lowest count was (Elevator:200) which doesn't help.\n",
    "    I cannot do blindly remove rows because a particular label wasn't filled out for any timestep for a user. For single label case, this is fine...but for a multi-label case, this will mean that other valid labels are ignored. The only option that I have so far is to naively convert all nans in the labels to zeros. This could mean a loss of accuracy (the user might have been doing the task in the label but have omitted annotating it, and so we are incorrectly training a feature vector....but there is no choice so far.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Choosing sensor labels\n",
    "'''\n",
    "Summary sensor choices are: phone_acc,phone_gyro,phone_mag,watch_acc,watch_dir,phone_loc,phone_audio,\n",
    "phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "In this project, we aren't using watch_acc,watch_dir (no smartwatch)\n",
    "'''\n",
    "\n",
    "def choose_sensors(X_train,used_sensors,summarized_feature_names):\n",
    "    used_sensor_feature_names=np.zeros(len(summarized_feature_names),dtype=bool)\n",
    "    # Creates a zero boolean vector of all possible feature names\n",
    "    for s in used_sensors:\n",
    "        used_sensor_feature_names=np.logical_or(used_sensor_feature_names,(s==summarized_feature_names))\n",
    "    X_train=X_train[:,used_sensor_feature_names]\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Returns a standardized (0 mean, 1 variance) dataset\n",
    "def standardize(X_train):\n",
    "    mean=np.nanmean(X_train,axis=0).reshape((1,-1))# Ignores NaNs while finding the mean across rows\n",
    "    standard_dev=np.nanstd(X_train,axis=0) # Ignores NaNs while finding the standard deviation across rows\n",
    "    standard_dev_nonzero=np.where(standard_dev>0,standard_dev,1.).reshape((1,-1)) # Div zero\n",
    "    \n",
    "    X=(X_train-mean)/standard_dev_nonzero\n",
    "    return X,mean,standard_dev_nonzero   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Sensor Types, Label Possibilities variables\n",
    "sensor_types=['phone_acc','phone_gyro','phone_mag','phone_loc','phone_audio',\n",
    "'phone_app','phone_battery','phone_use','phone_callstat','phone_wifi','phone_lf','phone_time']\n",
    "label_possibilities=['LOC_home','OR_indoors','PHONE_ON_TABLE','SITTING','WITH_FRIENDS',\n",
    " 'LYING_DOWN','SLEEPING','WATCHING_TV','EATING','PHONE_IN_POCKET',\n",
    " 'TALKING','DRIVE_-_I_M_A_PASSENGER','OR_standing','IN_A_CAR',\n",
    " 'OR_exercise','AT_THE_GYM','SINGING','FIX_walking','OR_outside',\n",
    " 'SHOPPING','AT_SCHOOL','BATHING_-_SHOWER','DRESSING','DRINKING__ALCOHOL_',\n",
    " 'PHONE_IN_HAND','FIX_restaurant','IN_CLASS','PHONE_IN_BAG','IN_A_MEETING',\n",
    " 'TOILET','COOKING','ELEVATOR','FIX_running','BICYCLING','LAB_WORK',\n",
    " 'LOC_main_workplace','ON_A_BUS','DRIVE_-_I_M_THE_DRIVER','STROLLING',\n",
    " 'CLEANING','DOING_LAUNDRY','WASHING_DISHES','SURFING_THE_INTERNET',\n",
    " 'AT_A_PARTY','AT_A_BAR','LOC_beach','COMPUTER_WORK','GROOMING','STAIRS_-_GOING_UP',\n",
    " 'STAIRS_-_GOING_DOWN','WITH_CO-WORKERS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new data structure for all valid data and pickling it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with np.nan labels (missing labels). Zero impute missing feature entries. Standardization done at train time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(5203, 225), after:(5203, 225)\n",
      "Y_shape before removing invalid labels:(5203, 51), after:(5203, 51)\n",
      "\t Per User Training examples:3642, Testing examples:1561\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(9189, 225), after:(9189, 225)\n",
      "Y_shape before removing invalid labels:(9189, 51), after:(9189, 51)\n",
      "\t Per User Training examples:6432, Testing examples:2757\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(10738, 225), after:(10738, 225)\n",
      "Y_shape before removing invalid labels:(10738, 51), after:(10738, 51)\n",
      "\t Per User Training examples:7516, Testing examples:3222\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(6549, 225), after:(6549, 225)\n",
      "Y_shape before removing invalid labels:(6549, 51), after:(6549, 51)\n",
      "\t Per User Training examples:4584, Testing examples:1965\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(8845, 225), after:(8845, 225)\n",
      "Y_shape before removing invalid labels:(8845, 51), after:(8845, 51)\n",
      "\t Per User Training examples:6191, Testing examples:2654\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(7298, 225), after:(7298, 225)\n",
      "Y_shape before removing invalid labels:(7298, 51), after:(7298, 51)\n",
      "\t Per User Training examples:5108, Testing examples:2190\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(4979, 225), after:(4979, 225)\n",
      "Y_shape before removing invalid labels:(4979, 51), after:(4979, 51)\n",
      "\t Per User Training examples:3485, Testing examples:1494\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(7626, 225), after:(7626, 225)\n",
      "Y_shape before removing invalid labels:(7626, 51), after:(7626, 51)\n",
      "\t Per User Training examples:5338, Testing examples:2288\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(7520, 225), after:(7520, 225)\n",
      "Y_shape before removing invalid labels:(7520, 51), after:(7520, 51)\n",
      "\t Per User Training examples:5264, Testing examples:2256\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(5819, 225), after:(5819, 225)\n",
      "Y_shape before removing invalid labels:(5819, 51), after:(5819, 51)\n",
      "\t Per User Training examples:4073, Testing examples:1746\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(9167, 225), after:(9167, 225)\n",
      "Y_shape before removing invalid labels:(9167, 51), after:(9167, 51)\n",
      "\t Per User Training examples:6416, Testing examples:2751\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(8309, 225), after:(8309, 225)\n",
      "Y_shape before removing invalid labels:(8309, 51), after:(8309, 51)\n",
      "\t Per User Training examples:5816, Testing examples:2493\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "X_shape before removing invalid labels:(1667, 225), after:(1667, 225)\n",
      "Y_shape before removing invalid labels:(1667, 51), after:(1667, 51)\n",
      "\t Per User Training examples:1166, Testing examples:501\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# Skipping cell if the data files were already created previously \n",
    "if not done:\n",
    "    # Reading data in the directory (Stacked)\n",
    "    X_combined=np.empty((0,168))\n",
    "    Y_combined=np.empty((0,51))\n",
    "    X_train_t=np.empty((0,168))\n",
    "    Y_train_t=np.empty((0,51))\n",
    "    X_test_t=np.empty((0,168))\n",
    "    Y_test_t=np.empty((0,51))\n",
    "    #M_train_t=np.empty((0,51))\n",
    "    #M_test_t=np.empty((0,51))\n",
    "\n",
    "    for u_file in glob.glob('{}/*.csv.gz'.format(prefix)):\n",
    "            x_user,y_user,missed_label_user,tstamp_user,featurename_user,labelname_user=read_user_data(u_file)\n",
    "            x_sh=x_user.shape\n",
    "            y_sh=y_user.shape\n",
    "            # Removing invalid labels, imputing missing features before splitting\n",
    "            #missed_label_user=missed_label_user.astype(int) # Convert Boolean to int array\n",
    "            #missed_label_user=np.sum(missed_label_user,axis=1)# Sum across columns creating a n_row*1 vector\n",
    "            # If the value for a particular row ==0, no features are missing : Can use that row\n",
    "            #use_labels=np.logical_not(missed_label_user)\n",
    "            #x_user=x_user[use_labels,:]\n",
    "            #y_user=np.nan_to_num(y_user) # Blind way to replace NAN labels in y_train/y_test to 0\n",
    "            y_user[np.isnan(y_user)]=-1 # NEW METHOD: REPLACE NANS WITH -1 INSTEAD OF A FAKE FALSE DATA\n",
    "            # Assuming that if the user hasn't bothered with that label, it means that it wasn't too applicable.\n",
    "            x_user=np.nan_to_num(x_user)\n",
    "            #y_user=y_user[use_labels,:]\n",
    "\n",
    "            copy_x_user=copy.deepcopy(x_user)\n",
    "            # Stacking combined data\n",
    "            temp_x_user=choose_sensors(copy_x_user,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "            X_combined=np.vstack((X_combined,temp_x_user))\n",
    "            Y_combined=np.vstack((Y_combined,y_user))\n",
    "\n",
    "            print('X_shape before removing invalid labels:{}, after:{}'.format(x_sh,x_user.shape))\n",
    "            print('Y_shape before removing invalid labels:{}, after:{}'.format(y_sh,y_user.shape))\n",
    "\n",
    "            # Split each user data into train-test splits .70-.30 as in literature\n",
    "            x_train_u,x_test_u,y_train_u,y_test_u=TT_split(x_user,y_user,test_size=0.30,random_state=random_state)\n",
    "            #m_train,m_test=TT_split(missed_label_user,test_size=0.30,random_state=random_state)\n",
    "\n",
    "            # Removing smart watch features\n",
    "            x_train_u=choose_sensors(x_train_u,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "            x_test_u=choose_sensors(x_test_u,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "\n",
    "            # Stacking data. Will be changed for K-Fold cross-validation\n",
    "            X_train_t=np.vstack((X_train_t,x_train_u))\n",
    "            Y_train_t=np.vstack((Y_train_t,y_train_u))\n",
    "            X_test_t=np.vstack((X_test_t,x_test_u))\n",
    "            Y_test_t=np.vstack((Y_test_t,y_test_u))\n",
    "\n",
    "            print('\\t Per User Training examples:{}, Testing examples:{}'.\n",
    "                  format(y_train_u.shape[0],y_test_u.shape[0]))\n",
    "    assert len(X_train_t)==len(Y_train_t)\n",
    "    assert len(X_test_t)==len(Y_test_t)\n",
    "\n",
    "    print('\\nTraining: X::{} ,Y::{}'.format(X_train_t.shape,Y_train_t.shape))\n",
    "    print('Testing: X::{} ,Y::{}'.format(X_test_t.shape,Y_test_t.shape))\n",
    "\n",
    "    print(\"Pickling data files\")\n",
    "    with open('dataset/pickled/x_combined.pkl','wb') as f:\n",
    "        pickle.dump(X_combined,f)\n",
    "    with open('dataset/pickled/y_combined.pkl','wb') as f:\n",
    "        pickle.dump(Y_combined,f)\n",
    "    # Split datasets\n",
    "    with open('dataset/pickled/x_train.pkl','wb') as f:\n",
    "        pickle.dump(X_train_t,f)\n",
    "    with open('dataset/pickled/y_train.pkl','wb') as f:\n",
    "        pickle.dump(Y_train_t,f)\n",
    "    with open('dataset/pickled/x_test.pkl','wb') as f:\n",
    "        pickle.dump(X_test_t,f)\n",
    "    with open('dataset/pickled/y_test.pkl','wb') as f:\n",
    "        pickle.dump(Y_test_t,f)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Skipping- data files already pickled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and pickling instance weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Skipping cell if the data files were already created previously \n",
    "if not done:\n",
    "    # Creating an instance weight matrix for the training labels\n",
    "    instance_weights=np.zeros_like(Y_combined)\n",
    "    for l in range(len(labelname_user)):\n",
    "        temp_column=Y_train_t[:,l]\n",
    "        count_neg=0\n",
    "        count_0=0\n",
    "        count_1=0\n",
    "        for i in range(len(temp_column)): # n^2 bincount doesn't work with arrays consisting of negative numbers\n",
    "            if (temp_column[i]==-1):\n",
    "                count_neg+=1\n",
    "            elif (temp_column[i]==0):\n",
    "                count_0+=1\n",
    "            elif (temp_column[i]==1):\n",
    "                count_1+=1\n",
    "            else:\n",
    "                raise ValueError(\"Bad Loop\")\n",
    "        for i in range(len(temp_column)):\n",
    "            if (temp_column[i]==-1):\n",
    "                instance_weights[i,l]=0.\n",
    "            elif (temp_column[i]==0):\n",
    "                instance_weights[i,l]=float((count_neg+count_0+count_1)/count_0)\n",
    "            elif (temp_column[i]==1):\n",
    "                instance_weights[i,l]=float((count_neg+count_0+count_1)/count_1)\n",
    "    with open('dataset/pickled/instance_weights.pkl','wb') as f:\n",
    "        pickle.dump(instance_weights,f)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Skipping- instance weight matrix already pickled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and instance weight matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "source": [
    "# Load pickle file datasets and normalize (and normalize the test set using same values)\n",
    "with open('dataset/pickled/x_train.pkl','rb') as f:\n",
    "    X_train=pickle.load(f)\n",
    "    X_train,mean,standard_dev_nonzero=standardize(X_train) # Standardizing X_train\n",
    "    #X_train=C(torch.from_numpy(X_train).double())\n",
    "\n",
    "with open('dataset/pickled/y_train.pkl','rb') as f:\n",
    "    Y_train=pickle.load(f)\n",
    "    #Y_train=C(torch.from_numpy(Y_train).double())\n",
    "\n",
    "with open('dataset/pickled/x_test.pkl','rb') as f:\n",
    "    X_test=pickle.load(f)\n",
    "    X_test=(X_test-mean)/standard_dev_nonzero\n",
    "    #X_test=C(torch.from_numpy(X_test).double())\n",
    "    \n",
    "with open('dataset/pickled/y_test.pkl','rb') as f:\n",
    "    Y_test=pickle.load(f)\n",
    "    #Y_test=C(torch.from_numpy(Y_test).double())\n",
    "\n",
    "# Combined matrices for X,Y for k-fold cross-validation\n",
    "with open('dataset/pickled/x_combined.pkl','rb') as f:\n",
    "    X_combined=pickle.load(f)\n",
    "    X_combined,_,_=standardize(X_combined)\n",
    "    \n",
    "with open('dataset/pickled/y_combined.pkl','rb') as f:\n",
    "    Y_combined=pickle.load(f)\n",
    "\n",
    "# Instance weighting matrices\n",
    "with open('dataset/pickled/instance_weights.pkl') as f:\n",
    "    instance_weights=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous train/test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda-enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Simple function to run using GPU when available\n",
    "def C(structure):\n",
    "    if torch.cuda.is_available():\n",
    "        device=torch.device(\"cuda\")\n",
    "        return structure.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tackling missing labels using a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a mask to hide -1 nans before training and then input to a train criterion\n",
    "def mask(criterion,y_true,y_pred,mask_value):\n",
    "    mask=torch.ne(y_true,mask_value).type(torch.cuda.FloatTensor)\n",
    "    # Cast the ByteTensor from elementwise comparison to a FloatTensor\n",
    "    return criterion(torch.mul(y_pred,mask),torch.mul(y_true,mask).type(torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Learning-Rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Linear decreasing LR scheduler\n",
    "def linear_lr_scheduler(optimizer,epoch):\n",
    "    \"\"\"\n",
    "    LR_init=0.1, LR_final=0.01, n_epochs=40\n",
    "    Sets the learning rate to the initial LR decayed by 1.04 every epoch\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr=param_group['lr']\n",
    "    m=-2.25e-3\n",
    "    c=0.1\n",
    "    lr=(epoch*m)+c # Linear LR decay based on a set number of epochs\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Norm for weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Adds euclidean regularization to weight matrices\n",
    "def frobenius_norm(model,loss):\n",
    "    regularizer_loss=0\n",
    "    \n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.Linear): # Linear layer\n",
    "            frobenius_norm=torch.norm(m.weight,p='fro')\n",
    "            regularizer_loss+=frobenius_norm # Regularization over the weight matrices for linear layers\n",
    "    return loss+0.01*regularizer_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy (Precision, Recall, F1, Support, Balanced Accuracy) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function for the required accuracy metrics per fold\n",
    "def accuracy(fold,target_labels,y_true,y_pred):\n",
    "    balanced_accuracy_dict={}\n",
    "    print('*'*20)\n",
    "    print('For fold {}'.format(fold))\n",
    "    # Precision, Recall, F1, Support\n",
    "    clf_report=classification_report(y_true=y_true,y_pred=y_pred,\n",
    "                                      target_names=target_labels,output_dict=True)\n",
    "    # Balanced accuracy\n",
    "    for i in range(len(target_labels)):\n",
    "        true_perlabel=y_true[:,i]\n",
    "        pred_perlabel=y_pred[:,i]\n",
    "        bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=pred_perlabel)\n",
    "        print('\\t Label {}:::-> Balanced Accuracy {}'.format(target_labels[i],round(bal_acc,5)))\n",
    "        balanced_accuracy_dict[target_labels[i]]=round(bal_acc,5)\n",
    "    return balanced_accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "def kfold_validation(model,X,Y,instance_weights,n_folds,n_epochs,lr_init,momentum):\n",
    "    # X, Y here are the complete datasets\n",
    "    kfolds=KFold(n_folds,shuffle=False,random_state=random_state).split(X) # Make n_folds\n",
    "    \n",
    "    fold_train_dict={} # Initialize dicts for train balanced accuracy- for each fold\n",
    "    fold_valid_dict={} # Initialize dicts for valid balanced accuracy- for each fold\n",
    "    \n",
    "    for fold, (train_index,val_index) in enumerate(kfolds): # Going through the folds\n",
    "        X_train=X[train_index]\n",
    "        y_train=Y[train_index]\n",
    "        X_valid=X[val_index]\n",
    "        y_valid=Y[val_index]\n",
    "\n",
    "         # Separate instance weight matrix based on the train index\n",
    "        instance_weight_matrix=torch.cuda.FloatTensor(instance_weights[train_index])\n",
    "        # Convert the training data to Variables\n",
    "        X_train=V(torch.cuda.FloatTensor(X_train),requires_grad=True)\n",
    "        y_train=V(torch.cuda.FloatTensor(y_train),requires_grad=False)\n",
    "        X_valid=V(torch.cuda.FloatTensor(X_valid),requires_grad=False)\n",
    "        y_valid=V(torch.cuda.FloatTensor(y_valid),requires_grad=False)\n",
    "        \n",
    "        #model_train=copy.deepcopy(model) # Deepcopy of model\n",
    "        \n",
    "        # Cuda compatible\n",
    "        model=C(model)\n",
    "#         X_train=C(X_train)\n",
    "#         y_train=C(y_train)\n",
    "#         X_valid=C(X_valid)\n",
    "#         y_valid=C(y_valid)\n",
    "        \n",
    "        # Train the network\n",
    "        train(model,X_train,y_train,weights=instance_weight_matrix,\n",
    "            n_epoch=n_epochs,batch_size=bs,lr_init=lr_init,momentum=momentum)\n",
    "        \n",
    "        eval_bool=1\n",
    "        if eval_bool: # Basic methodology to ensure gradients aren't updated\n",
    "            model.eval() # Set to evaluation mode\n",
    "            # On training set\n",
    "            y_train_pred=torch.sigmoid(model(X_train))>=0.5\n",
    "            train_dict_out=accuracy(fold,labelname_user,y_train.cpu(),y_train_pred.cpu())\n",
    "            fold_train_dict[str(fold)]=train_dict_out\n",
    "            # On valid set\n",
    "            y_valid_pred=torch.sigmoid(model(X_valid))>=0.5\n",
    "            valid_dict_out=accuracy(fold,labelname_user,y_valid.cpu(),y_valid_pred.cpu())\n",
    "            fold_valid_dict[str(fold)]=valid_dict_out\n",
    "        eval_bool=0\n",
    "        model.train() # Set to train mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train function w/BCE loss, linear LR scheduler, instance weights\n",
    "def train(model,X,Y,weights,n_epoch,batch_size,lr_init,momentum):\n",
    "    optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "    #criterion=C(nn.BCEWithLogitsLoss())\n",
    "    \n",
    "    # Create dataloaders\n",
    "    # Dataloader creation\n",
    "    # Wrap weights for instance weight tensor along with data & label tensors s.t.\n",
    "    # it can be called properly as a dataloader in batches.\n",
    "    train_dataset=utils.TensorDataset(X,Y,weights)\n",
    "    train_loader=utils.DataLoader(dataset=train_dataset,batch_size=bs\n",
    "                                  ,shuffle=False,drop_last=False)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        done=1\n",
    "        for i,data in enumerate(train_loader,0):\n",
    "            \n",
    "            inputs,labels,weights=data\n",
    "            inputs=V(torch.cuda.FloatTensor(inputs),requires_grad=True)\n",
    "            labels=V(torch.cuda.FloatTensor(labels),requires_grad=False)\n",
    "            weights=V(torch.cuda.FloatTensor(weights))\n",
    "            #print(inputs.size(),labels.size(),weights.size())\n",
    "            criterion=C(nn.BCEWithLogitsLoss(weight=weights))\n",
    "            optimizer.zero_grad()   \n",
    "            sum_total=0\n",
    "            \n",
    "            outputs=model(inputs)\n",
    "\n",
    "            # Zero gradients, backward pass, weight update\n",
    "\n",
    "            if done:\n",
    "                linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "                done=0\n",
    "            \n",
    "            loss=criterion(outputs,labels)\n",
    "            #loss=mask(criterion=criterion,y_true=labels,y_pred=output,mask_value=-1)\n",
    "            loss=frobenius_norm(model,loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_total+=loss.item()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                epoch_lr=param_group['lr']\n",
    "                if i%bs==0: # Every minibatch\n",
    "                    print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "                    sum_total=0.\n",
    "        #train_predictions=torch.sigmoid(outputs)>=0.5\n",
    "        #accuracy=torc.eq(Y,train_predictions.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier: Learning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Hyperparameter variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sizes for neural networks and other global hyperparameters\n",
    "input_size=X_train_t.shape[-1]\n",
    "hidden_size=16\n",
    "output_size=Y_train_t.shape[-1]\n",
    "n_fold=5\n",
    "n_epoch=40\n",
    "bs=300\n",
    "lr_init=0.1\n",
    "momentum=0.5\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (0 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMLP,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Train for Linear MLP\n",
    "model=LinearMLP()\n",
    "kfold_validation(model,X=X_combined,Y=Y_combined,\n",
    "                 instance_weights=instance_weights,n_folds=n_fold,n_epochs=n_epoch,\n",
    "                 lr_init=lr_init,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    ISSUE: Doesn't seem to train well.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_0hidden'\n",
    "checkpoint_path=root+'mlp_0hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (1 Hidden Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_1H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "# Train for MLP-1 Hidden\n",
    "model=MLP_1H()\n",
    "kfold_validation(model,X=X_combined,Y=Y_combined,\n",
    "                 instance_weights=instance_weights,n_folds=n_fold,n_epochs=n_epoch,\n",
    "                 lr_init=lr_init,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_1hidden'\n",
    "checkpoint_path=root+'mlp_1hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "# Train for MLP-2 Hidden\n",
    "model=MLP_2H()\n",
    "kfold_validation(model,X=X_combined,Y=Y_combined,\n",
    "                 instance_weights=instance_weights,n_folds=n_fold,n_epochs=n_epoch,\n",
    "                 lr_init=lr_init,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hidden'\n",
    "checkpoint_path=root+'mlp_2hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers, with Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2HDrop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2HDrop,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model=MLP_2HDrop()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "#criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        #sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        #sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        #sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(output.type(torch.cuda.FloatTensor),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hiddendrop'\n",
    "checkpoint_path=root+'mlp_2hiddendrop_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12.2333px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.983px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "930.85px",
    "left": "2.28333px",
    "right": "1417.63px",
    "top": "578px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
