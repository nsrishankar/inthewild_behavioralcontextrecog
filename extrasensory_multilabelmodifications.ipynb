{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dataset-parsers-and-cleaning-functions\" data-toc-modified-id=\"Dataset-parsers-and-cleaning-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset parsers and cleaning functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-data\" data-toc-modified-id=\"Test-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Test data</a></span></li></ul></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-new-data-structure-for-all-valid-data-and-pickling-it\" data-toc-modified-id=\"Creating-a-new-data-structure-for-all-valid-data-and-pickling-it-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Creating a new data structure for all valid data and pickling it</a></span></li></ul></li><li><span><a href=\"#Multi-Class-Classifier:-Train/Test-Functions\" data-toc-modified-id=\"Multi-Class-Classifier:-Train/Test-Functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Multi Class Classifier: Train/Test Functions</a></span></li><li><span><a href=\"#Multi-Class-Classifier:-SOTA-Comparison\" data-toc-modified-id=\"Multi-Class-Classifier:-SOTA-Comparison-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Multi Class Classifier: SOTA Comparison</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multi-Layer-Perceptron-(0-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(0-Hidden-Layers)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Multi-Layer Perceptron (0 Hidden Layers)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(1-Hidden-Layer)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(1-Hidden-Layer)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Multi-Layer Perceptron (1 Hidden Layer)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers)-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers)</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers, with Dropout)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "from io import StringIO\n",
    "import importlib.machinery\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TT_split\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier as OvR\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,balanced_accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "#from sklearn.metrics import multilabel_confusion_matrix # Only available in dev .21\n",
    "\n",
    "# Need Pytorch for multilabel classifications\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "#import skorch [Scikit-learn wrapper around Pytorch so allowing for K-fold cross-validation]\n",
    "from sklearn.model_selection import KFold\n",
    "from skorch import NeuralNetClassifier\n",
    "random_state=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data location and sample user\n",
    "prefix='dataset/Extrasensory_uuid_fl_uTAR/'\n",
    "cross_validation_user_loc='dataset/cv_5_folds/'\n",
    "user_sample='3600D531-0C55-44A7-AE95-A7A38519464E.features_labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset parsers and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dataset parsers for header/ body for CSVs\n",
    "def parse_header_of_csv(csv_str):\n",
    "    # Isolate the headline columns:\n",
    "    headline = csv_str[:csv_str.index('\\n')];\n",
    "    columns = headline.split(',');\n",
    "\n",
    "    # The first column should be timestamp:\n",
    "    assert columns[0] == 'timestamp';\n",
    "    # The last column should be label_source:\n",
    "    assert columns[-1] == 'label_source';\n",
    "    \n",
    "    # Search for the column of the first label:\n",
    "    for (ci,col) in enumerate(columns):\n",
    "        if col.startswith('label:'):\n",
    "            first_label_ind = ci;\n",
    "            break;\n",
    "        pass;\n",
    "\n",
    "    # Feature columns come after timestamp and before the labels:\n",
    "    feature_names = columns[1:first_label_ind];\n",
    "    # Then come the labels, till the one-before-last column:\n",
    "    label_names = columns[first_label_ind:-1];\n",
    "    for (li,label) in enumerate(label_names):\n",
    "        # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n",
    "        assert label.startswith('label:');\n",
    "        label_names[li] = label.replace('label:','');\n",
    "        pass;\n",
    "    \n",
    "    return (feature_names,label_names);\n",
    "\n",
    "def parse_body_of_csv(csv_str,n_features):\n",
    "    # Read the entire CSV body into a single numeric matrix:\n",
    "    full_table = np.loadtxt(StringIO(csv_str),delimiter=',',skiprows=1);\n",
    "    \n",
    "    # Timestamp is the primary key for the records (examples):\n",
    "    timestamps = full_table[:,0].astype(int);\n",
    "    \n",
    "    # Read the sensor features:\n",
    "    X = full_table[:,1:(n_features+1)];\n",
    "    \n",
    "    # Read the binary label values, and the 'missing label' indicators:\n",
    "    trinary_labels_mat = full_table[:,(n_features+1):-1]; # This should have values of either 0., 1. or NaN\n",
    "    M = np.isnan(trinary_labels_mat); # M is the missing label matrix\n",
    "    \n",
    "    #print(\"M matrix shape:\",M.shape)\n",
    "    #print(\"Matrix: \",np.argwhere(M))\n",
    "    \n",
    "    Y = np.where(M,0,trinary_labels_mat) > 0.; # Y is the label matrix\n",
    "    \n",
    "    return (X,Y,M,timestamps);\n",
    "\n",
    "def read_user_data(directory):\n",
    "    print('Reading {}'.format(directory.split(\"/\")[-1]))\n",
    "\n",
    "    # Read the entire csv file of the user:\n",
    "    with gzip.open(directory,'rb') as fid:\n",
    "        csv_str = fid.read();\n",
    "        csv_str = csv_str.decode(\"utf-8\")\n",
    "        pass;\n",
    "\n",
    "    (feature_names,label_names) = parse_header_of_csv(csv_str);\n",
    "    n_features = len(feature_names);\n",
    "    (X,Y,M,timestamps) = parse_body_of_csv(csv_str,n_features);\n",
    "\n",
    "    return (X,Y,M,timestamps,feature_names,label_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean labels\n",
    "def clean_labels(input_label):\n",
    "    if label.endswith('_'):\n",
    "        label=label[:-1]+')'\n",
    "    label=label.replace('__',' (').replace('_',' ')\n",
    "    label=label[0]+label[1:].lower()\n",
    "    label=label.replace('i m','I\\'m')\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get a summary of the sensor feature\n",
    "'''\n",
    "# Summarize features as we are only using phone_acc,phone_gyro,phone_mag,phone_loc,phone_audio,\n",
    "# phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "# We are ignoring the use of the smartwatch features. There are definitely features that will be used\n",
    "# much more (e.g. than the phone_callstat) but we'll leave that up to the ML algorithm.\n",
    "'''\n",
    "def summarize_features(feature_list):\n",
    "    summary_feature_list=np.empty_like(feature_list)\n",
    "    for (ind,feature) in enumerate(feature_list):\n",
    "        if feature.startswith('raw_acc'):\n",
    "            summary_feature_list[ind]='phone_acc' \n",
    "        if feature.startswith('proc_gyro'):\n",
    "            summary_feature_list[ind]='phone_gyro'\n",
    "        if feature.startswith('raw_magnet'):\n",
    "            summary_feature_list[ind]='phone_mag'\n",
    "        if feature.startswith('watch_acc'):\n",
    "            summary_feature_list[ind]='watch_acc'\n",
    "        if feature.startswith('watch_heading'):\n",
    "            summary_feature_list[ind]='watch_dir'\n",
    "        if feature.startswith('location'):\n",
    "            summary_feature_list[ind]='phone_loc'\n",
    "        if feature.startswith('audio_naive'):\n",
    "            summary_feature_list[ind]='phone_audio'\n",
    "        if feature.startswith('discrete:app_state'):\n",
    "            summary_feature_list[ind]='phone_app'\n",
    "        if feature.startswith('discrete:battery'):\n",
    "            summary_feature_list[ind]='phone_battery'\n",
    "        if feature.startswith('discrete:on'):\n",
    "            summary_feature_list[ind]='phone_use'\n",
    "        if feature.startswith('discrete:ringer'):\n",
    "            summary_feature_list[ind]='phone_callstat'\n",
    "        if feature.startswith('discrete:wifi'):\n",
    "            summary_feature_list[ind]='phone_wifi'\n",
    "        if feature.startswith('lf'):\n",
    "            summary_feature_list[ind]='phone_lf'\n",
    "        if feature.startswith('discrete:time'):\n",
    "            summary_feature_list[ind]='phone_time'\n",
    "\n",
    "    return summary_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Custom dictionary class with help for duplicate keys\n",
    "class Customdictionary(dict):\n",
    "    def __setitem__(self,key,value):\n",
    "        try:\n",
    "            self[key]\n",
    "        except KeyError:\n",
    "            super(Customdictionary,self).__setitem__(key,[])\n",
    "        self[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading sample data\n",
    "sample_loc='{}/{}.csv.gz'.format(prefix,user_sample)\n",
    "x_user,y_user,missedlabel_user,tstamp_user,featurename_user,labelname_user=read_user_data(sample_loc)\n",
    "\n",
    "# Dataset summaries for this user\n",
    "print('Data shape input for user (Len minutes/num examples, num sensors): ',x_user.shape) # Timestep examples, number of sensors\n",
    "print('Label shape for user (Len minutes, num labels): ',y_user.shape,'\\n') # Timestep examples, labels\n",
    "\n",
    "countlabels_user=np.sum(y_user,axis=0) # Column summary\n",
    "labelname_countlabel_user=zip(labelname_user,countlabels_user) # Zip together names, counts\n",
    "labelname_countlabel_user=sorted(labelname_countlabel_user,key=lambda row:row[-1],reverse=True)\n",
    "\n",
    "print('Sensor feature names:\\n')\n",
    "feature_names=summarize_features(featurename_user)\n",
    "    \n",
    "for i,sensor_feature in enumerate(featurename_user):\n",
    "    print('{} :: {} ::--> {}\\n'.format(i,feature_names[i],sensor_feature))\n",
    "\n",
    "print('Activities and counts:')\n",
    "print(labelname_countlabel_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    ISSUE: There are some labels (e.g. Phone location:bag etc.) that some users have not filled out for any timestep and shows up as np.nan. The label sum above was a check to see if the same label wasn't filled out for other users (hence would have a count of zero) and would let the label being completely removed. The lowest count was (Elevator:200) which doesn't help.\n",
    "    I cannot do blindly remove rows because a particular label wasn't filled out for any timestep for a user. For single label case, this is fine...but for a multi-label case, this will mean that other valid labels are ignored. The only option that I have so far is to naively convert all nans in the labels to zeros. This could mean a loss of accuracy (the user might have been doing the task in the label but have omitted annotating it, and so we are incorrectly training a feature vector....but there is no choice so far.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Choosing sensor labels\n",
    "'''\n",
    "Summary sensor choices are: phone_acc,phone_gyro,phone_mag,watch_acc,watch_dir,phone_loc,phone_audio,\n",
    "phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "In this project, we aren't using watch_acc,watch_dir (no smartwatch)\n",
    "'''\n",
    "\n",
    "def choose_sensors(X_train,used_sensors,summarized_feature_names):\n",
    "    used_sensor_feature_names=np.zeros(len(summarized_feature_names),dtype=bool)\n",
    "    # Creates a zero boolean vector of all possible feature names\n",
    "    for s in used_sensors:\n",
    "        used_sensor_feature_names=np.logical_or(used_sensor_feature_names,(s==summarized_feature_names))\n",
    "    X_train=X_train[:,used_sensor_feature_names]\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Returns a standardized (0 mean, 1 variance) dataset\n",
    "def standardize(X_train):\n",
    "    mean=np.nanmean(X_train,axis=0).reshape((1,-1))# Ignores NaNs while finding the mean across rows\n",
    "    standard_dev=np.nanstd(X_train,axis=0) # Ignores NaNs while finding the standard deviation across rows\n",
    "    standard_dev_nonzero=np.where(standard_dev>0,standard_dev,1.).reshape((1,-1)) # Div zero\n",
    "    \n",
    "    X=(X_train-mean)/standard_dev_nonzero\n",
    "    return X,mean,standard_dev_nonzero   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Sensor Types, Label Possibilities variables\n",
    "sensor_types=['phone_acc','phone_gyro','phone_mag','phone_loc','phone_audio',\n",
    "'phone_app','phone_battery','phone_use','phone_callstat','phone_wifi','phone_lf','phone_time']\n",
    "label_possibilities=['LOC_home','OR_indoors','PHONE_ON_TABLE','SITTING','WITH_FRIENDS',\n",
    " 'LYING_DOWN','SLEEPING','WATCHING_TV','EATING','PHONE_IN_POCKET',\n",
    " 'TALKING','DRIVE_-_I_M_A_PASSENGER','OR_standing','IN_A_CAR',\n",
    " 'OR_exercise','AT_THE_GYM','SINGING','FIX_walking','OR_outside',\n",
    " 'SHOPPING','AT_SCHOOL','BATHING_-_SHOWER','DRESSING','DRINKING__ALCOHOL_',\n",
    " 'PHONE_IN_HAND','FIX_restaurant','IN_CLASS','PHONE_IN_BAG','IN_A_MEETING',\n",
    " 'TOILET','COOKING','ELEVATOR','FIX_running','BICYCLING','LAB_WORK',\n",
    " 'LOC_main_workplace','ON_A_BUS','DRIVE_-_I_M_THE_DRIVER','STROLLING',\n",
    " 'CLEANING','DOING_LAUNDRY','WASHING_DISHES','SURFING_THE_INTERNET',\n",
    " 'AT_A_PARTY','AT_A_BAR','LOC_beach','COMPUTER_WORK','GROOMING','STAIRS_-_GOING_UP',\n",
    " 'STAIRS_-_GOING_DOWN','WITH_CO-WORKERS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new data structure for all valid data and pickling it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with np.nan labels (missing labels). Zero impute missing feature entries. Standardization done at train time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Reading data in the directory (Stacked)\n",
    "X_train_t=np.empty((0,168))\n",
    "Y_train_t=np.empty((0,51))\n",
    "X_test_t=np.empty((0,168))\n",
    "Y_test_t=np.empty((0,51))\n",
    "#M_train_t=np.empty((0,51))\n",
    "#M_test_t=np.empty((0,51))\n",
    "\n",
    "for u_file in glob.glob('{}/*.csv.gz'.format(prefix)):\n",
    "        x_user,y_user,missed_label_user,tstamp_user,featurename_user,labelname_user=read_user_data(u_file)\n",
    "        x_sh=x_user.shape\n",
    "        y_sh=y_user.shape\n",
    "        # Removing invalid labels, imputing missing features before splitting\n",
    "        #missed_label_user=missed_label_user.astype(int) # Convert Boolean to int array\n",
    "        #missed_label_user=np.sum(missed_label_user,axis=1)# Sum across columns creating a n_row*1 vector\n",
    "        # If the value for a particular row ==0, no features are missing : Can use that row\n",
    "        #use_labels=np.logical_not(missed_label_user)\n",
    "        #x_user=x_user[use_labels,:]\n",
    "        y_user=np.nan_to_num(y_user) # Blind way to replace NAN labels in y_train/y_test to 0\n",
    "        # Assuming that if the user hasn't bothered with that label, it means that it wasn't too applicable.\n",
    "        x_user=np.nan_to_num(x_user)\n",
    "        #y_user=y_user[use_labels,:]\n",
    "        \n",
    "        print('X_shape before removing invalid labels:{}, after:{}'.format(x_sh,x_user.shape))\n",
    "        print('Y_shape before removing invalid labels:{}, after:{}'.format(y_sh,y_user.shape))\n",
    "        \n",
    "        # Split each user data into train-test splits .70-.30 as in literature\n",
    "        x_train_u,x_test_u,y_train_u,y_test_u=TT_split(x_user,y_user,test_size=0.30,random_state=random_state)\n",
    "        #m_train,m_test=TT_split(missed_label_user,test_size=0.30,random_state=random_state)\n",
    "        \n",
    "        # Removing smart watch features\n",
    "        x_train_u=choose_sensors(x_train_u,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "        x_test_u=choose_sensors(x_test_u,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "       \n",
    "        # Stacking data. Will be changed for K-Fold cross-validation\n",
    "        X_train_t=np.vstack((X_train_t,x_train_u))\n",
    "        Y_train_t=np.vstack((Y_train_t,y_train_u))\n",
    "        X_test_t=np.vstack((X_test_t,x_test_u))\n",
    "        Y_test_t=np.vstack((Y_test_t,y_test_u))\n",
    "        \n",
    "        print('\\t Per User Training examples:{}, Testing examples:{}'.\n",
    "              format(y_train_u.shape[0],y_test_u.shape[0]))\n",
    "assert len(X_train_t)==len(Y_train_t)\n",
    "assert len(X_test_t)==len(Y_test_t)\n",
    "\n",
    "print('\\nTraining: X::{} ,Y::{}'.format(X_train_t.shape,Y_train_t.shape))\n",
    "print('Testing: X::{} ,Y::{}'.format(X_test_t.shape,Y_test_t.shape))\n",
    "\n",
    "print(\"Pickling data files\")\n",
    "with open('dataset/pickled/x_train.pkl','wb') as f:\n",
    "    pickle.dump(X_train_t,f)\n",
    "with open('dataset/pickled/y_train.pkl','wb') as f:\n",
    "    pickle.dump(Y_train_t,f)\n",
    "with open('dataset/pickled/x_test.pkl','wb') as f:\n",
    "    pickle.dump(X_test_t,f)\n",
    "with open('dataset/pickled/y_test.pkl','wb') as f:\n",
    "    pickle.dump(Y_test_t,f)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier: Train/Test Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using the saved pickle files for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sizes for neural networks and other hyperparameters\n",
    "input_size=X_train_t.shape[-1]\n",
    "hidden_size=16\n",
    "output_size=Y_train_t.shape[-1]\n",
    "n_epoch=40\n",
    "bs=300\n",
    "lr_init=0.1\n",
    "momentum=0.5\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to run using GPU when available\n",
    "def C(structure):\n",
    "    if torch.cuda.is_available():\n",
    "        device=torch.device(\"cuda\")\n",
    "        return structure.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file datasets and normalize (and normalize the test set using same values)\n",
    "with open('dataset/pickled/x_train.pkl','rb') as f:\n",
    "    X_train=pickle.load(f)\n",
    "    X_train,mean,standard_dev_nonzero=standardize(X_train) # Standardizing X_train\n",
    "    X_train=C(torch.from_numpy(X_train).double())\n",
    "\n",
    "with open('dataset/pickled/y_train.pkl','rb') as f:\n",
    "    Y_train=pickle.load(f)\n",
    "    Y_train=C(torch.from_numpy(Y_train).double())\n",
    "\n",
    "with open('dataset/pickled/x_test.pkl','rb') as f:\n",
    "    X_test=pickle.load(f)\n",
    "    X_test=(X_test-mean)/standard_dev_nonzero\n",
    "    X_test=C(torch.from_numpy(X_test).double())\n",
    "    \n",
    "with open('dataset/pickled/y_test.pkl','rb') as f:\n",
    "    Y_test=pickle.load(f)\n",
    "    Y_test=C(torch.from_numpy(Y_test).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader creation\n",
    "train_dataset=utils.TensorDataset(X_train,Y_train)\n",
    "train_loader=utils.DataLoader(dataset=train_dataset,batch_size=bs,shuffle=False,drop_last=False)\n",
    "\n",
    "test_dataset=utils.TensorDataset(X_test,Y_test)\n",
    "test_loader=utils.DataLoader(dataset=test_dataset,batch_size=bs,shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear decreasing LR scheduler\n",
    "def linear_lr_scheduler(optimizer, epoch):\n",
    "    \"\"\"\n",
    "    LR_init=0.1, LR_final=0.01, n_epochs=40\n",
    "    Sets the learning rate to the initial LR decayed by 1.04 every epoch\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr=param_group['lr']\n",
    "    lr=lr*(0.94**(epoch//1))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds euclidean regularization to weight matrices\n",
    "def frobenius_norm(model,loss):\n",
    "    regularizer_loss=0\n",
    "    \n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.Linear): # Linear layer\n",
    "            reg=torch.sum(((torch.sum(((m.weight)**2),1))**0.5),0) # Only applying regularization to weight matrix\n",
    "            regularizer_loss=regularizer_loss+0.001*reg\n",
    "    return regularizer_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m,nn.Linear):\n",
    "        print(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier: SOTA Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (0 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMLP,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=LinearMLP()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "#criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(sigmoid_output,labels)\n",
    "        regularized_loss=frobenius_norm(model,loss)\n",
    "\n",
    "        regularized_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=regularized_loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    ISSUE: Doesn't seem to train well.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_0hidden'\n",
    "checkpoint_path=root+'mlp_0hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (1 Hidden Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_1H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model=MLP_1H()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "#criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        #sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        #sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        #sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(output.type(torch.cuda.FloatTensor),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_1hidden'\n",
    "checkpoint_path=root+'mlp_1hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model=MLP_2H()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "#criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        #sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        #sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        #sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(output.type(torch.cuda.FloatTensor),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hidden'\n",
    "checkpoint_path=root+'mlp_2hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers, with Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2HDrop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2HDrop,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model=MLP_2HDrop()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "#criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        #sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        #sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        #sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(output.type(torch.cuda.FloatTensor),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hiddendrop'\n",
    "checkpoint_path=root+'mlp_2hiddendrop_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12.2333px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.983px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "930.85px",
    "left": "5.28333px",
    "right": "1716.13px",
    "top": "397px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
