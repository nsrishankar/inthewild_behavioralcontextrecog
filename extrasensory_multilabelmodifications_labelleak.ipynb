{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dataset-parsers-and-cleaning-functions\" data-toc-modified-id=\"Dataset-parsers-and-cleaning-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset parsers and cleaning functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-data\" data-toc-modified-id=\"Test-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Test data</a></span></li></ul></li><li><span><a href=\"#Training-Functions\" data-toc-modified-id=\"Training-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-new-data-structure-for-all-valid-data-and-pickling-it\" data-toc-modified-id=\"Creating-a-new-data-structure-for-all-valid-data-and-pickling-it-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Creating a new data structure for all valid data and pickling it</a></span></li><li><span><a href=\"#Creating-and-pickling-instance-weight-matrix\" data-toc-modified-id=\"Creating-and-pickling-instance-weight-matrix-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating and pickling instance weight matrix</a></span></li><li><span><a href=\"#Loading-data-and-instance-weight-matrix\" data-toc-modified-id=\"Loading-data-and-instance-weight-matrix-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Loading data and instance weight matrix</a></span></li><li><span><a href=\"#Miscellaneous-train/test-functions\" data-toc-modified-id=\"Miscellaneous-train/test-functions-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Miscellaneous train/test functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cuda-enable\" data-toc-modified-id=\"Cuda-enable-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Cuda-enable</a></span></li><li><span><a href=\"#Tackling-missing-labels-using-a-mask\" data-toc-modified-id=\"Tackling-missing-labels-using-a-mask-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Tackling missing labels using a mask</a></span></li><li><span><a href=\"#Linear-Learning-Rate-scheduler\" data-toc-modified-id=\"Linear-Learning-Rate-scheduler-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Linear Learning-Rate scheduler</a></span></li><li><span><a href=\"#Euclidean-Norm-for-weight-matrices\" data-toc-modified-id=\"Euclidean-Norm-for-weight-matrices-3.4.4\"><span class=\"toc-item-num\">3.4.4&nbsp;&nbsp;</span>Euclidean Norm for weight matrices</a></span></li><li><span><a href=\"#Accuracy-(Precision,-Recall,-F1,-Support,-Balanced-Accuracy)-metrics\" data-toc-modified-id=\"Accuracy-(Precision,-Recall,-F1,-Support,-Balanced-Accuracy)-metrics-3.4.5\"><span class=\"toc-item-num\">3.4.5&nbsp;&nbsp;</span>Accuracy (Precision, Recall, F1, Support, Balanced Accuracy) metrics</a></span></li><li><span><a href=\"#K-Fold-cross-validation\" data-toc-modified-id=\"K-Fold-cross-validation-3.4.6\"><span class=\"toc-item-num\">3.4.6&nbsp;&nbsp;</span>K-Fold cross validation</a></span></li><li><span><a href=\"#Train/Fit-function\" data-toc-modified-id=\"Train/Fit-function-3.4.7\"><span class=\"toc-item-num\">3.4.7&nbsp;&nbsp;</span>Train/Fit function</a></span></li></ul></li></ul></li><li><span><a href=\"#Multi-Class-Classifier:-Learning-and-Evaluation\" data-toc-modified-id=\"Multi-Class-Classifier:-Learning-and-Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Multi Class Classifier: Learning and Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Global-Hyperparameter-variables\" data-toc-modified-id=\"Global-Hyperparameter-variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Global Hyperparameter variables</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron-(0-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(0-Hidden-Layers)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Multi-Layer Perceptron (0 Hidden Layers)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Balanced-Accuracy-outputs\" data-toc-modified-id=\"Balanced-Accuracy-outputs-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Balanced Accuracy outputs</a></span></li><li><span><a href=\"#Saving-data\" data-toc-modified-id=\"Saving-data-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Saving data</a></span></li></ul></li><li><span><a href=\"#Multi-Layer-Perceptron-(1-Hidden-Layer)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(1-Hidden-Layer)-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Multi-Layer Perceptron (1 Hidden Layer)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Balanced-Accuracy-outputs\" data-toc-modified-id=\"Balanced-Accuracy-outputs-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Balanced Accuracy outputs</a></span></li><li><span><a href=\"#Saving-data\" data-toc-modified-id=\"Saving-data-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Saving data</a></span></li></ul></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers)-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Balanced-Accuracy-outputs\" data-toc-modified-id=\"Balanced-Accuracy-outputs-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Balanced Accuracy outputs</a></span></li><li><span><a href=\"#Balanced-Accuracy-outputs\" data-toc-modified-id=\"Balanced-Accuracy-outputs-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Balanced Accuracy outputs</a></span></li></ul></li><li><span><a href=\"#Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)\" data-toc-modified-id=\"Multi-Layer-Perceptron-(2-Hidden-Layers,-with-Dropout)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Multi-Layer Perceptron (2 Hidden Layers, with Dropout)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "from io import StringIO\n",
    "# import importlib.machinery\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TT_split\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier as OvR\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,balanced_accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "#from sklearn.metrics import multilabel_confusion_matrix # Only available in dev .21\n",
    "\n",
    "# Need Pytorch for multilabel classifications\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "#import skorch [Scikit-learn wrapper around Pytorch so allowing for K-fold cross-validation]\n",
    "from sklearn.model_selection import KFold\n",
    "random_state=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Data location and sample user\n",
    "prefix='dataset/Extrasensory_uuid_fl_uTAR/'\n",
    "cross_validation_user_loc='dataset/cv_5_folds/'\n",
    "user_sample='3600D531-0C55-44A7-AE95-A7A38519464E.features_labels'\n",
    "done=0 # Pickled files are created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset parsers and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dataset parsers for header/ body for CSVs\n",
    "def parse_header_of_csv(csv_str):\n",
    "    # Isolate the headline columns:\n",
    "    headline = csv_str[:csv_str.index('\\n')];\n",
    "    columns = headline.split(',');\n",
    "\n",
    "    # The first column should be timestamp:\n",
    "    assert columns[0] == 'timestamp';\n",
    "    # The last column should be label_source:\n",
    "    assert columns[-1] == 'label_source';\n",
    "    \n",
    "    # Search for the column of the first label:\n",
    "    for (ci,col) in enumerate(columns):\n",
    "        if col.startswith('label:'):\n",
    "            first_label_ind = ci;\n",
    "            break;\n",
    "        pass;\n",
    "\n",
    "    # Feature columns come after timestamp and before the labels:\n",
    "    feature_names = columns[1:first_label_ind];\n",
    "    # Then come the labels, till the one-before-last column:\n",
    "    label_names = columns[first_label_ind:-1];\n",
    "    for (li,label) in enumerate(label_names):\n",
    "        # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n",
    "        assert label.startswith('label:');\n",
    "        label_names[li] = label.replace('label:','');\n",
    "        pass;\n",
    "    \n",
    "    return (feature_names,label_names);\n",
    "\n",
    "def parse_body_of_csv(csv_str,n_features):\n",
    "    # Read the entire CSV body into a single numeric matrix:\n",
    "    full_table = np.loadtxt(StringIO(csv_str),delimiter=',',skiprows=1);\n",
    "    \n",
    "    # Timestamp is the primary key for the records (examples):\n",
    "    timestamps = full_table[:,0].astype(int);\n",
    "    \n",
    "    # Read the sensor features:\n",
    "    X = full_table[:,1:(n_features+1)];\n",
    "    \n",
    "    # Read the binary label values, and the 'missing label' indicators:\n",
    "    trinary_labels_mat = full_table[:,(n_features+1):-1]; # This should have values of either 0., 1. or NaN\n",
    "    M = np.isnan(trinary_labels_mat); # M is the missing label matrix\n",
    "    \n",
    "    #print(\"M matrix shape:\",M.shape)\n",
    "    #print(\"Matrix: \",np.argwhere(M))\n",
    "    \n",
    "    Y = np.where(M,0,trinary_labels_mat) > 0.; # Y is the label matrix\n",
    "    \n",
    "    return (X,Y,M,timestamps);\n",
    "\n",
    "def read_user_data(directory):\n",
    "    print('Reading {}'.format(directory.split(\"/\")[-1]))\n",
    "\n",
    "    # Read the entire csv file of the user:\n",
    "    with gzip.open(directory,'rb') as fid:\n",
    "        csv_str = fid.read();\n",
    "        csv_str = csv_str.decode(\"utf-8\")\n",
    "        pass;\n",
    "\n",
    "    (feature_names,label_names) = parse_header_of_csv(csv_str);\n",
    "    n_features = len(feature_names);\n",
    "    (X,Y,M,timestamps) = parse_body_of_csv(csv_str,n_features);\n",
    "\n",
    "    return (X,Y,M,timestamps,feature_names,label_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean labels\n",
    "def clean_labels(input_label):\n",
    "    if label.endswith('_'):\n",
    "        label=label[:-1]+')'\n",
    "    label=label.replace('__',' (').replace('_',' ')\n",
    "    label=label[0]+label[1:].lower()\n",
    "    label=label.replace('i m','I\\'m')\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get a summary of the sensor feature\n",
    "'''\n",
    "# Summarize features as we are only using phone_acc,phone_gyro,phone_mag,phone_loc,phone_audio,\n",
    "# phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "# We are ignoring the use of the smartwatch features. There are definitely features that will be used\n",
    "# much more (e.g. than the phone_callstat) but we'll leave that up to the ML algorithm.\n",
    "'''\n",
    "def summarize_features(feature_list):\n",
    "    summary_feature_list=np.empty_like(feature_list)\n",
    "    for (ind,feature) in enumerate(feature_list):\n",
    "        if feature.startswith('raw_acc'):\n",
    "            summary_feature_list[ind]='phone_acc' \n",
    "        if feature.startswith('proc_gyro'):\n",
    "            summary_feature_list[ind]='phone_gyro'\n",
    "        if feature.startswith('raw_magnet'):\n",
    "            summary_feature_list[ind]='phone_mag'\n",
    "        if feature.startswith('watch_acc'):\n",
    "            summary_feature_list[ind]='watch_acc'\n",
    "        if feature.startswith('watch_heading'):\n",
    "            summary_feature_list[ind]='watch_dir'\n",
    "        if feature.startswith('location'):\n",
    "            summary_feature_list[ind]='phone_loc'\n",
    "        if feature.startswith('audio_naive'):\n",
    "            summary_feature_list[ind]='phone_audio'\n",
    "        if feature.startswith('discrete:app_state'):\n",
    "            summary_feature_list[ind]='phone_app'\n",
    "        if feature.startswith('discrete:battery'):\n",
    "            summary_feature_list[ind]='phone_battery'\n",
    "        if feature.startswith('discrete:on'):\n",
    "            summary_feature_list[ind]='phone_use'\n",
    "        if feature.startswith('discrete:ringer'):\n",
    "            summary_feature_list[ind]='phone_callstat'\n",
    "        if feature.startswith('discrete:wifi'):\n",
    "            summary_feature_list[ind]='phone_wifi'\n",
    "        if feature.startswith('lf'):\n",
    "            summary_feature_list[ind]='phone_lf'\n",
    "        if feature.startswith('discrete:time'):\n",
    "            summary_feature_list[ind]='phone_time'\n",
    "\n",
    "    return summary_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Custom dictionary class with help for duplicate keys\n",
    "class Customdictionary(dict):\n",
    "    def __setitem__(self,key,value):\n",
    "        try:\n",
    "            self[key]\n",
    "        except KeyError:\n",
    "            super(Customdictionary,self).__setitem__(key,[])\n",
    "        self[key].append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "('Data shape input for user (Len minutes/num examples, num sensors): ', (5203, 225))\n",
      "('Label shape for user (Len minutes, num labels): ', (5203, 51), '\\n')\n",
      "Sensor feature names:\n",
      "\n",
      "0 :: phone_acc ::--> raw_acc:magnitude_stats:mean\n",
      "\n",
      "1 :: phone_acc ::--> raw_acc:magnitude_stats:std\n",
      "\n",
      "2 :: phone_acc ::--> raw_acc:magnitude_stats:moment3\n",
      "\n",
      "3 :: phone_acc ::--> raw_acc:magnitude_stats:moment4\n",
      "\n",
      "4 :: phone_acc ::--> raw_acc:magnitude_stats:percentile25\n",
      "\n",
      "5 :: phone_acc ::--> raw_acc:magnitude_stats:percentile50\n",
      "\n",
      "6 :: phone_acc ::--> raw_acc:magnitude_stats:percentile75\n",
      "\n",
      "7 :: phone_acc ::--> raw_acc:magnitude_stats:value_entropy\n",
      "\n",
      "8 :: phone_acc ::--> raw_acc:magnitude_stats:time_entropy\n",
      "\n",
      "9 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "10 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "11 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "12 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "13 :: phone_acc ::--> raw_acc:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "14 :: phone_acc ::--> raw_acc:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "15 :: phone_acc ::--> raw_acc:magnitude_autocorrelation:period\n",
      "\n",
      "16 :: phone_acc ::--> raw_acc:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "17 :: phone_acc ::--> raw_acc:3d:mean_x\n",
      "\n",
      "18 :: phone_acc ::--> raw_acc:3d:mean_y\n",
      "\n",
      "19 :: phone_acc ::--> raw_acc:3d:mean_z\n",
      "\n",
      "20 :: phone_acc ::--> raw_acc:3d:std_x\n",
      "\n",
      "21 :: phone_acc ::--> raw_acc:3d:std_y\n",
      "\n",
      "22 :: phone_acc ::--> raw_acc:3d:std_z\n",
      "\n",
      "23 :: phone_acc ::--> raw_acc:3d:ro_xy\n",
      "\n",
      "24 :: phone_acc ::--> raw_acc:3d:ro_xz\n",
      "\n",
      "25 :: phone_acc ::--> raw_acc:3d:ro_yz\n",
      "\n",
      "26 :: phone_gyro ::--> proc_gyro:magnitude_stats:mean\n",
      "\n",
      "27 :: phone_gyro ::--> proc_gyro:magnitude_stats:std\n",
      "\n",
      "28 :: phone_gyro ::--> proc_gyro:magnitude_stats:moment3\n",
      "\n",
      "29 :: phone_gyro ::--> proc_gyro:magnitude_stats:moment4\n",
      "\n",
      "30 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile25\n",
      "\n",
      "31 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile50\n",
      "\n",
      "32 :: phone_gyro ::--> proc_gyro:magnitude_stats:percentile75\n",
      "\n",
      "33 :: phone_gyro ::--> proc_gyro:magnitude_stats:value_entropy\n",
      "\n",
      "34 :: phone_gyro ::--> proc_gyro:magnitude_stats:time_entropy\n",
      "\n",
      "35 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "36 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "37 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "38 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "39 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "40 :: phone_gyro ::--> proc_gyro:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "41 :: phone_gyro ::--> proc_gyro:magnitude_autocorrelation:period\n",
      "\n",
      "42 :: phone_gyro ::--> proc_gyro:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "43 :: phone_gyro ::--> proc_gyro:3d:mean_x\n",
      "\n",
      "44 :: phone_gyro ::--> proc_gyro:3d:mean_y\n",
      "\n",
      "45 :: phone_gyro ::--> proc_gyro:3d:mean_z\n",
      "\n",
      "46 :: phone_gyro ::--> proc_gyro:3d:std_x\n",
      "\n",
      "47 :: phone_gyro ::--> proc_gyro:3d:std_y\n",
      "\n",
      "48 :: phone_gyro ::--> proc_gyro:3d:std_z\n",
      "\n",
      "49 :: phone_gyro ::--> proc_gyro:3d:ro_xy\n",
      "\n",
      "50 :: phone_gyro ::--> proc_gyro:3d:ro_xz\n",
      "\n",
      "51 :: phone_gyro ::--> proc_gyro:3d:ro_yz\n",
      "\n",
      "52 :: phone_mag ::--> raw_magnet:magnitude_stats:mean\n",
      "\n",
      "53 :: phone_mag ::--> raw_magnet:magnitude_stats:std\n",
      "\n",
      "54 :: phone_mag ::--> raw_magnet:magnitude_stats:moment3\n",
      "\n",
      "55 :: phone_mag ::--> raw_magnet:magnitude_stats:moment4\n",
      "\n",
      "56 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile25\n",
      "\n",
      "57 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile50\n",
      "\n",
      "58 :: phone_mag ::--> raw_magnet:magnitude_stats:percentile75\n",
      "\n",
      "59 :: phone_mag ::--> raw_magnet:magnitude_stats:value_entropy\n",
      "\n",
      "60 :: phone_mag ::--> raw_magnet:magnitude_stats:time_entropy\n",
      "\n",
      "61 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "62 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "63 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "64 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "65 :: phone_mag ::--> raw_magnet:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "66 :: phone_mag ::--> raw_magnet:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "67 :: phone_mag ::--> raw_magnet:magnitude_autocorrelation:period\n",
      "\n",
      "68 :: phone_mag ::--> raw_magnet:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "69 :: phone_mag ::--> raw_magnet:3d:mean_x\n",
      "\n",
      "70 :: phone_mag ::--> raw_magnet:3d:mean_y\n",
      "\n",
      "71 :: phone_mag ::--> raw_magnet:3d:mean_z\n",
      "\n",
      "72 :: phone_mag ::--> raw_magnet:3d:std_x\n",
      "\n",
      "73 :: phone_mag ::--> raw_magnet:3d:std_y\n",
      "\n",
      "74 :: phone_mag ::--> raw_magnet:3d:std_z\n",
      "\n",
      "75 :: phone_mag ::--> raw_magnet:3d:ro_xy\n",
      "\n",
      "76 :: phone_mag ::--> raw_magnet:3d:ro_xz\n",
      "\n",
      "77 :: phone_mag ::--> raw_magnet:3d:ro_yz\n",
      "\n",
      "78 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range0\n",
      "\n",
      "79 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range1\n",
      "\n",
      "80 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range2\n",
      "\n",
      "81 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range3\n",
      "\n",
      "82 :: phone_mag ::--> raw_magnet:avr_cosine_similarity_lag_range4\n",
      "\n",
      "83 :: watch_acc ::--> watch_acceleration:magnitude_stats:mean\n",
      "\n",
      "84 :: watch_acc ::--> watch_acceleration:magnitude_stats:std\n",
      "\n",
      "85 :: watch_acc ::--> watch_acceleration:magnitude_stats:moment3\n",
      "\n",
      "86 :: watch_acc ::--> watch_acceleration:magnitude_stats:moment4\n",
      "\n",
      "87 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile25\n",
      "\n",
      "88 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile50\n",
      "\n",
      "89 :: watch_acc ::--> watch_acceleration:magnitude_stats:percentile75\n",
      "\n",
      "90 :: watch_acc ::--> watch_acceleration:magnitude_stats:value_entropy\n",
      "\n",
      "91 :: watch_acc ::--> watch_acceleration:magnitude_stats:time_entropy\n",
      "\n",
      "92 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band0\n",
      "\n",
      "93 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band1\n",
      "\n",
      "94 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band2\n",
      "\n",
      "95 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band3\n",
      "\n",
      "96 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:log_energy_band4\n",
      "\n",
      "97 :: watch_acc ::--> watch_acceleration:magnitude_spectrum:spectral_entropy\n",
      "\n",
      "98 :: watch_acc ::--> watch_acceleration:magnitude_autocorrelation:period\n",
      "\n",
      "99 :: watch_acc ::--> watch_acceleration:magnitude_autocorrelation:normalized_ac\n",
      "\n",
      "100 :: watch_acc ::--> watch_acceleration:3d:mean_x\n",
      "\n",
      "101 :: watch_acc ::--> watch_acceleration:3d:mean_y\n",
      "\n",
      "102 :: watch_acc ::--> watch_acceleration:3d:mean_z\n",
      "\n",
      "103 :: watch_acc ::--> watch_acceleration:3d:std_x\n",
      "\n",
      "104 :: watch_acc ::--> watch_acceleration:3d:std_y\n",
      "\n",
      "105 :: watch_acc ::--> watch_acceleration:3d:std_z\n",
      "\n",
      "106 :: watch_acc ::--> watch_acceleration:3d:ro_xy\n",
      "\n",
      "107 :: watch_acc ::--> watch_acceleration:3d:ro_xz\n",
      "\n",
      "108 :: watch_acc ::--> watch_acceleration:3d:ro_yz\n",
      "\n",
      "109 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band0\n",
      "\n",
      "110 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band1\n",
      "\n",
      "111 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band2\n",
      "\n",
      "112 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band3\n",
      "\n",
      "113 :: watch_acc ::--> watch_acceleration:spectrum:x_log_energy_band4\n",
      "\n",
      "114 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band0\n",
      "\n",
      "115 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band1\n",
      "\n",
      "116 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band2\n",
      "\n",
      "117 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band3\n",
      "\n",
      "118 :: watch_acc ::--> watch_acceleration:spectrum:y_log_energy_band4\n",
      "\n",
      "119 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band0\n",
      "\n",
      "120 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band1\n",
      "\n",
      "121 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band2\n",
      "\n",
      "122 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band3\n",
      "\n",
      "123 :: watch_acc ::--> watch_acceleration:spectrum:z_log_energy_band4\n",
      "\n",
      "124 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range0\n",
      "\n",
      "125 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range1\n",
      "\n",
      "126 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range2\n",
      "\n",
      "127 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range3\n",
      "\n",
      "128 :: watch_acc ::--> watch_acceleration:relative_directions:avr_cosine_similarity_lag_range4\n",
      "\n",
      "129 :: watch_dir ::--> watch_heading:mean_cos\n",
      "\n",
      "130 :: watch_dir ::--> watch_heading:std_cos\n",
      "\n",
      "131 :: watch_dir ::--> watch_heading:mom3_cos\n",
      "\n",
      "132 :: watch_dir ::--> watch_heading:mom4_cos\n",
      "\n",
      "133 :: watch_dir ::--> watch_heading:mean_sin\n",
      "\n",
      "134 :: watch_dir ::--> watch_heading:std_sin\n",
      "\n",
      "135 :: watch_dir ::--> watch_heading:mom3_sin\n",
      "\n",
      "136 :: watch_dir ::--> watch_heading:mom4_sin\n",
      "\n",
      "137 :: watch_dir ::--> watch_heading:entropy_8bins\n",
      "\n",
      "138 :: phone_loc ::--> location:num_valid_updates\n",
      "\n",
      "139 :: phone_loc ::--> location:log_latitude_range\n",
      "\n",
      "140 :: phone_loc ::--> location:log_longitude_range\n",
      "\n",
      "141 :: phone_loc ::--> location:min_altitude\n",
      "\n",
      "142 :: phone_loc ::--> location:max_altitude\n",
      "\n",
      "143 :: phone_loc ::--> location:min_speed\n",
      "\n",
      "144 :: phone_loc ::--> location:max_speed\n",
      "\n",
      "145 :: phone_loc ::--> location:best_horizontal_accuracy\n",
      "\n",
      "146 :: phone_loc ::--> location:best_vertical_accuracy\n",
      "\n",
      "147 :: phone_loc ::--> location:diameter\n",
      "\n",
      "148 :: phone_loc ::--> location:log_diameter\n",
      "\n",
      "149 :: phone_loc ::--> location_quick_features:std_lat\n",
      "\n",
      "150 :: phone_loc ::--> location_quick_features:std_long\n",
      "\n",
      "151 :: phone_loc ::--> location_quick_features:lat_change\n",
      "\n",
      "152 :: phone_loc ::--> location_quick_features:long_change\n",
      "\n",
      "153 :: phone_loc ::--> location_quick_features:mean_abs_lat_deriv\n",
      "\n",
      "154 :: phone_loc ::--> location_quick_features:mean_abs_long_deriv\n",
      "\n",
      "155 :: phone_audio ::--> audio_naive:mfcc0:mean\n",
      "\n",
      "156 :: phone_audio ::--> audio_naive:mfcc1:mean\n",
      "\n",
      "157 :: phone_audio ::--> audio_naive:mfcc2:mean\n",
      "\n",
      "158 :: phone_audio ::--> audio_naive:mfcc3:mean\n",
      "\n",
      "159 :: phone_audio ::--> audio_naive:mfcc4:mean\n",
      "\n",
      "160 :: phone_audio ::--> audio_naive:mfcc5:mean\n",
      "\n",
      "161 :: phone_audio ::--> audio_naive:mfcc6:mean\n",
      "\n",
      "162 :: phone_audio ::--> audio_naive:mfcc7:mean\n",
      "\n",
      "163 :: phone_audio ::--> audio_naive:mfcc8:mean\n",
      "\n",
      "164 :: phone_audio ::--> audio_naive:mfcc9:mean\n",
      "\n",
      "165 :: phone_audio ::--> audio_naive:mfcc10:mean\n",
      "\n",
      "166 :: phone_audio ::--> audio_naive:mfcc11:mean\n",
      "\n",
      "167 :: phone_audio ::--> audio_naive:mfcc12:mean\n",
      "\n",
      "168 :: phone_audio ::--> audio_naive:mfcc0:std\n",
      "\n",
      "169 :: phone_audio ::--> audio_naive:mfcc1:std\n",
      "\n",
      "170 :: phone_audio ::--> audio_naive:mfcc2:std\n",
      "\n",
      "171 :: phone_audio ::--> audio_naive:mfcc3:std\n",
      "\n",
      "172 :: phone_audio ::--> audio_naive:mfcc4:std\n",
      "\n",
      "173 :: phone_audio ::--> audio_naive:mfcc5:std\n",
      "\n",
      "174 :: phone_audio ::--> audio_naive:mfcc6:std\n",
      "\n",
      "175 :: phone_audio ::--> audio_naive:mfcc7:std\n",
      "\n",
      "176 :: phone_audio ::--> audio_naive:mfcc8:std\n",
      "\n",
      "177 :: phone_audio ::--> audio_naive:mfcc9:std\n",
      "\n",
      "178 :: phone_audio ::--> audio_naive:mfcc10:std\n",
      "\n",
      "179 :: phone_audio ::--> audio_naive:mfcc11:std\n",
      "\n",
      "180 :: phone_audio ::--> audio_naive:mfcc12:std\n",
      "\n",
      "181 ::  ::--> audio_properties:max_abs_value\n",
      "\n",
      "182 ::  ::--> audio_properties:normalization_multiplier\n",
      "\n",
      "183 :: phone_app ::--> discrete:app_state:is_active\n",
      "\n",
      "184 :: phone_app ::--> discrete:app_state:is_inactive\n",
      "\n",
      "185 :: phone_app ::--> discrete:app_state:is_background\n",
      "\n",
      "186 :: phone_app ::--> discrete:app_state:missing\n",
      "\n",
      "187 :: phone_battery ::--> discrete:battery_plugged:is_ac\n",
      "\n",
      "188 :: phone_battery ::--> discrete:battery_plugged:is_usb\n",
      "\n",
      "189 :: phone_battery ::--> discrete:battery_plugged:is_wireless\n",
      "\n",
      "190 :: phone_battery ::--> discrete:battery_plugged:missing\n",
      "\n",
      "191 :: phone_battery ::--> discrete:battery_state:is_unknown\n",
      "\n",
      "192 :: phone_battery ::--> discrete:battery_state:is_unplugged\n",
      "\n",
      "193 :: phone_battery ::--> discrete:battery_state:is_not_charging\n",
      "\n",
      "194 :: phone_battery ::--> discrete:battery_state:is_discharging\n",
      "\n",
      "195 :: phone_battery ::--> discrete:battery_state:is_charging\n",
      "\n",
      "196 :: phone_battery ::--> discrete:battery_state:is_full\n",
      "\n",
      "197 :: phone_battery ::--> discrete:battery_state:missing\n",
      "\n",
      "198 :: phone_use ::--> discrete:on_the_phone:is_False\n",
      "\n",
      "199 :: phone_use ::--> discrete:on_the_phone:is_True\n",
      "\n",
      "200 :: phone_use ::--> discrete:on_the_phone:missing\n",
      "\n",
      "201 :: phone_callstat ::--> discrete:ringer_mode:is_normal\n",
      "\n",
      "202 :: phone_callstat ::--> discrete:ringer_mode:is_silent_no_vibrate\n",
      "\n",
      "203 :: phone_callstat ::--> discrete:ringer_mode:is_silent_with_vibrate\n",
      "\n",
      "204 :: phone_callstat ::--> discrete:ringer_mode:missing\n",
      "\n",
      "205 :: phone_wifi ::--> discrete:wifi_status:is_not_reachable\n",
      "\n",
      "206 :: phone_wifi ::--> discrete:wifi_status:is_reachable_via_wifi\n",
      "\n",
      "207 :: phone_wifi ::--> discrete:wifi_status:is_reachable_via_wwan\n",
      "\n",
      "208 :: phone_wifi ::--> discrete:wifi_status:missing\n",
      "\n",
      "209 :: phone_lf ::--> lf_measurements:light\n",
      "\n",
      "210 :: phone_lf ::--> lf_measurements:pressure\n",
      "\n",
      "211 :: phone_lf ::--> lf_measurements:proximity_cm\n",
      "\n",
      "212 :: phone_lf ::--> lf_measurements:proximity\n",
      "\n",
      "213 :: phone_lf ::--> lf_measurements:relative_humidity\n",
      "\n",
      "214 :: phone_lf ::--> lf_measurements:battery_level\n",
      "\n",
      "215 :: phone_lf ::--> lf_measurements:screen_brightness\n",
      "\n",
      "216 :: phone_lf ::--> lf_measurements:temperature_ambient\n",
      "\n",
      "217 :: phone_time ::--> discrete:time_of_day:between0and6\n",
      "\n",
      "218 :: phone_time ::--> discrete:time_of_day:between3and9\n",
      "\n",
      "219 :: phone_time ::--> discrete:time_of_day:between6and12\n",
      "\n",
      "220 :: phone_time ::--> discrete:time_of_day:between9and15\n",
      "\n",
      "221 :: phone_time ::--> discrete:time_of_day:between12and18\n",
      "\n",
      "222 :: phone_time ::--> discrete:time_of_day:between15and21\n",
      "\n",
      "223 :: phone_time ::--> discrete:time_of_day:between18and24\n",
      "\n",
      "224 :: phone_time ::--> discrete:time_of_day:between21and3\n",
      "\n",
      "Activities and counts:\n",
      "[(u'LOC_home', 3040), (u'OR_indoors', 2487), (u'PHONE_ON_TABLE', 2179), (u'SITTING', 1916), (u'WITH_FRIENDS', 1730), (u'LYING_DOWN', 1336), (u'SLEEPING', 1021), (u'WATCHING_TV', 912), (u'EATING', 762), (u'PHONE_IN_POCKET', 706), (u'TALKING', 638), (u'DRIVE_-_I_M_A_PASSENGER', 409), (u'OR_standing', 384), (u'IN_A_CAR', 342), (u'OR_exercise', 162), (u'AT_THE_GYM', 162), (u'SINGING', 136), (u'FIX_walking', 132), (u'OR_outside', 127), (u'SHOPPING', 111), (u'AT_SCHOOL', 105), (u'BATHING_-_SHOWER', 85), (u'DRESSING', 67), (u'DRINKING__ALCOHOL_', 66), (u'PHONE_IN_HAND', 64), (u'FIX_restaurant', 59), (u'IN_CLASS', 54), (u'PHONE_IN_BAG', 33), (u'IN_A_MEETING', 27), (u'TOILET', 12), (u'COOKING', 5), (u'ELEVATOR', 1), (u'FIX_running', 0), (u'BICYCLING', 0), (u'LAB_WORK', 0), (u'LOC_main_workplace', 0), (u'ON_A_BUS', 0), (u'DRIVE_-_I_M_THE_DRIVER', 0), (u'STROLLING', 0), (u'CLEANING', 0), (u'DOING_LAUNDRY', 0), (u'WASHING_DISHES', 0), (u'SURFING_THE_INTERNET', 0), (u'AT_A_PARTY', 0), (u'AT_A_BAR', 0), (u'LOC_beach', 0), (u'COMPUTER_WORK', 0), (u'GROOMING', 0), (u'STAIRS_-_GOING_UP', 0), (u'STAIRS_-_GOING_DOWN', 0), (u'WITH_CO-WORKERS', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Reading sample data\n",
    "sample_loc='{}/{}.csv.gz'.format(prefix,user_sample)\n",
    "x_user,y_user,missedlabel_user,tstamp_user,featurename_user,labelname_user=read_user_data(sample_loc)\n",
    "\n",
    "# Dataset summaries for this user\n",
    "print('Data shape input for user (Len minutes/num examples, num sensors): ',x_user.shape) # Timestep examples, number of sensors\n",
    "print('Label shape for user (Len minutes, num labels): ',y_user.shape,'\\n') # Timestep examples, labels\n",
    "\n",
    "countlabels_user=np.sum(y_user,axis=0) # Column summary\n",
    "labelname_countlabel_user=zip(labelname_user,countlabels_user) # Zip together names, counts\n",
    "labelname_countlabel_user=sorted(labelname_countlabel_user,key=lambda row:row[-1],reverse=True)\n",
    "\n",
    "print('Sensor feature names:\\n')\n",
    "feature_names=summarize_features(featurename_user)\n",
    "    \n",
    "for i,sensor_feature in enumerate(featurename_user):\n",
    "    print('{} :: {} ::--> {}\\n'.format(i,feature_names[i],sensor_feature))\n",
    "\n",
    "print('Activities and counts:')\n",
    "print(labelname_countlabel_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "    ISSUE: There are some labels (e.g. Phone location:bag etc.) that some users have not filled out for any timestep and shows up as np.nan. The label sum above was a check to see if the same label wasn't filled out for other users (hence would have a count of zero) and would let the label being completely removed. The lowest count was (Elevator:200) which doesn't help.\n",
    "    I cannot do blindly remove rows because a particular label wasn't filled out for any timestep for a user. For single label case, this is fine...but for a multi-label case, this will mean that other valid labels are ignored. The only option that I have so far is to naively convert all nans in the labels to zeros. This could mean a loss of accuracy (the user might have been doing the task in the label but have omitted annotating it, and so we are incorrectly training a feature vector....but there is no choice so far.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Choosing sensor labels\n",
    "'''\n",
    "Summary sensor choices are: phone_acc,phone_gyro,phone_mag,watch_acc,watch_dir,phone_loc,phone_audio,\n",
    "phone_app,phone_battery,phone_use,phone_callstat,phone_wifi,phone_lf,phone_time\n",
    "In this project, we aren't using watch_acc,watch_dir (no smartwatch)\n",
    "'''\n",
    "\n",
    "def choose_sensors(X_train,used_sensors,summarized_feature_names):\n",
    "    used_sensor_feature_names=np.zeros(len(summarized_feature_names),dtype=bool)\n",
    "    # Creates a zero boolean vector of all possible feature names\n",
    "    for s in used_sensors:\n",
    "        used_sensor_feature_names=np.logical_or(used_sensor_feature_names,(s==summarized_feature_names))\n",
    "    X_train=X_train[:,used_sensor_feature_names]\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Returns a standardized (0 mean, 1 variance) dataset\n",
    "def standardize(X_train):\n",
    "    mean=np.nanmean(X_train,axis=0).reshape((1,-1))# Ignores NaNs while finding the mean across rows\n",
    "    standard_dev=np.nanstd(X_train,axis=0) # Ignores NaNs while finding the standard deviation across rows\n",
    "    standard_dev_nonzero=np.where(standard_dev>0,standard_dev,1.).reshape((1,-1)) # Div zero\n",
    "    \n",
    "    X=(X_train-mean)/standard_dev_nonzero\n",
    "    return X,mean,standard_dev_nonzero   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Sensor Types, Label Possibilities variables\n",
    "sensor_types=['phone_acc','phone_gyro','phone_loc','phone_audio',\n",
    "'phone_app','phone_battery','phone_use','phone_callstat','watch_acc','phone_wifi','phone_time']\n",
    "\n",
    "label_possibilities=['LOC_home','OR_indoors','PHONE_ON_TABLE','SITTING','WITH_FRIENDS',\n",
    " 'LYING_DOWN','SLEEPING','WATCHING_TV','EATING','PHONE_IN_POCKET',\n",
    " 'TALKING','DRIVE_-_I_M_A_PASSENGER','OR_standing','IN_A_CAR',\n",
    " 'OR_exercise','AT_THE_GYM','SINGING','FIX_walking','OR_outside',\n",
    " 'SHOPPING','AT_SCHOOL','BATHING_-_SHOWER','DRESSING','DRINKING__ALCOHOL_',\n",
    " 'PHONE_IN_HAND','FIX_restaurant','IN_CLASS','PHONE_IN_BAG','IN_A_MEETING',\n",
    " 'TOILET','COOKING','ELEVATOR','FIX_running','BICYCLING','LAB_WORK',\n",
    " 'LOC_main_workplace','ON_A_BUS','DRIVE_-_I_M_THE_DRIVER','STROLLING',\n",
    " 'CLEANING','DOING_LAUNDRY','WASHING_DISHES','SURFING_THE_INTERNET',\n",
    " 'AT_A_PARTY','AT_A_BAR','LOC_beach','COMPUTER_WORK','GROOMING','STAIRS_-_GOING_UP',\n",
    " 'STAIRS_-_GOING_DOWN','WITH_CO-WORKERS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new data structure for all valid data and pickling it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with np.nan labels (missing labels). Zero impute missing feature entries. Standardization done at train time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A\n",
      "Reading 33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A\n",
      "Reading 40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B\n",
      "Reading 481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7\n",
      "Reading 4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5\n",
      "Reading 59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2\n",
      "Reading 59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81\n",
      "Reading 61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C\n",
      "Reading 797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6\n",
      "Reading 806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0\n",
      "Reading 81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "96A358A0-FFF2-4239-B93E-C7425B901B47\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769\n",
      "Reading 99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81\n",
      "Reading A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n",
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C\n",
      "Reading B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1\n",
      "Reading BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F\n",
      "Reading CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9\n",
      "Reading F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E\n",
      "Reading 2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E\n",
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D\n",
      "Reading 5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53\n",
      "Reading 5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C\n",
      "Reading 5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n",
      "61976C24-1C50-4355-9C49-AAE44A7D09F6\n",
      "Reading 61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB\n",
      "Reading 78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2\n",
      "Reading 7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8\n",
      "Reading 7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6\n",
      "Reading 83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C\n",
      "Reading 9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2\n",
      "Reading 9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96\n",
      "Reading A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F\n",
      "Reading B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153\n",
      "Reading C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B\n",
      "Reading CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C\n",
      "Reading CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC\n",
      "Reading CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B\n",
      "Reading D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3\n",
      "Reading E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2\n",
      "Reading ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF\n",
      "Reading FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "\n",
      "Training: Fold::0 X::(312287, 175) ,Y::(312287, 51)\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D\n",
      "Reading 0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Reading 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13\n",
      "Reading 1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842\n",
      "Reading 1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601\n",
      "Reading 00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694\n",
      "Reading 098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B\n",
      "Reading 0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2\n",
      "Reading 136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF\n",
      "Reading 24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "\n",
      "Testing: Fold::0 X::(65059, 175) ,Y::(65059, 51)\n",
      "Pickling data files\n",
      "Done for fold 0\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D\n",
      "Reading 0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Reading 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13\n",
      "Reading 1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842\n",
      "Reading 1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2\n",
      "Reading 59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81\n",
      "Reading 61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C\n",
      "Reading 797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6\n",
      "Reading 806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0\n",
      "Reading 81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "96A358A0-FFF2-4239-B93E-C7425B901B47\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769\n",
      "Reading 99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81\n",
      "Reading A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C\n",
      "Reading B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1\n",
      "Reading BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F\n",
      "Reading CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9\n",
      "Reading F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601\n",
      "Reading 00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694\n",
      "Reading 098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B\n",
      "Reading 0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2\n",
      "Reading 136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF\n",
      "Reading 24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB\n",
      "Reading 78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2\n",
      "Reading 7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8\n",
      "Reading 7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6\n",
      "Reading 83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C\n",
      "Reading 9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2\n",
      "Reading 9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96\n",
      "Reading A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F\n",
      "Reading B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153\n",
      "Reading C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B\n",
      "Reading CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C\n",
      "Reading CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC\n",
      "Reading CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B\n",
      "Reading D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3\n",
      "Reading E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2\n",
      "Reading ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF\n",
      "Reading FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "\n",
      "Training: Fold::1 X::(303064, 175) ,Y::(303064, 51)\n",
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A\n",
      "Reading 33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A\n",
      "Reading 40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B\n",
      "Reading 481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7\n",
      "Reading 4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5\n",
      "Reading 59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E\n",
      "Reading 2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E\n",
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D\n",
      "Reading 5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53\n",
      "Reading 5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C\n",
      "Reading 5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n",
      "61976C24-1C50-4355-9C49-AAE44A7D09F6\n",
      "Reading 61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "\n",
      "Testing: Fold::1 X::(74282, 175) ,Y::(74282, 51)\n",
      "Pickling data files\n",
      "Done for fold 1\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D\n",
      "Reading 0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Reading 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13\n",
      "Reading 1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842\n",
      "Reading 1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A\n",
      "Reading 33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A\n",
      "Reading 40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B\n",
      "Reading 481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7\n",
      "Reading 4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5\n",
      "Reading 59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6\n",
      "Reading 806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0\n",
      "Reading 81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "96A358A0-FFF2-4239-B93E-C7425B901B47\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769\n",
      "Reading 99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81\n",
      "Reading A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n",
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C\n",
      "Reading B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1\n",
      "Reading BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F\n",
      "Reading CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9\n",
      "Reading F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601\n",
      "Reading 00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694\n",
      "Reading 098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B\n",
      "Reading 0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2\n",
      "Reading 136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF\n",
      "Reading 24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E\n",
      "Reading 2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E\n",
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D\n",
      "Reading 5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53\n",
      "Reading 5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C\n",
      "Reading 5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61976C24-1C50-4355-9C49-AAE44A7D09F6\n",
      "Reading 61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96\n",
      "Reading A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F\n",
      "Reading B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153\n",
      "Reading C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B\n",
      "Reading CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C\n",
      "Reading CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC\n",
      "Reading CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B\n",
      "Reading D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3\n",
      "Reading E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2\n",
      "Reading ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF\n",
      "Reading FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "\n",
      "Training: Fold::2 X::(281937, 175) ,Y::(281937, 51)\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2\n",
      "Reading 59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81\n",
      "Reading 61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C\n",
      "Reading 797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB\n",
      "Reading 78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2\n",
      "Reading 7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8\n",
      "Reading 7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6\n",
      "Reading 83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C\n",
      "Reading 9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2\n",
      "Reading 9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "\n",
      "Testing: Fold::2 X::(95409, 175) ,Y::(95409, 51)\n",
      "Pickling data files\n",
      "Done for fold 2\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D\n",
      "Reading 0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Reading 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13\n",
      "Reading 1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842\n",
      "Reading 1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A\n",
      "Reading 33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A\n",
      "Reading 40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B\n",
      "Reading 481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7\n",
      "Reading 4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5\n",
      "Reading 59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2\n",
      "Reading 59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81\n",
      "Reading 61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C\n",
      "Reading 797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81\n",
      "Reading A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n",
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C\n",
      "Reading B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1\n",
      "Reading BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F\n",
      "Reading CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9\n",
      "Reading F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601\n",
      "Reading 00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694\n",
      "Reading 098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B\n",
      "Reading 0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2\n",
      "Reading 136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF\n",
      "Reading 24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E\n",
      "Reading 2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E\n",
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D\n",
      "Reading 5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53\n",
      "Reading 5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C\n",
      "Reading 5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n",
      "61976C24-1C50-4355-9C49-AAE44A7D09F6\n",
      "Reading 61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB\n",
      "Reading 78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2\n",
      "Reading 7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8\n",
      "Reading 7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6\n",
      "Reading 83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C\n",
      "Reading 9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2\n",
      "Reading 9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C\n",
      "Reading CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC\n",
      "Reading CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B\n",
      "Reading D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3\n",
      "Reading E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2\n",
      "Reading ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF\n",
      "Reading FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "\n",
      "Training: Fold::3 X::(288516, 175) ,Y::(288516, 51)\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6\n",
      "Reading 806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0\n",
      "Reading 81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96A358A0-FFF2-4239-B93E-C7425B901B47\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769\n",
      "Reading 99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96\n",
      "Reading A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F\n",
      "Reading B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153\n",
      "Reading C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B\n",
      "Reading CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "\n",
      "Testing: Fold::3 X::(88830, 175) ,Y::(88830, 51)\n",
      "Pickling data files\n",
      "Done for fold 3\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D\n",
      "Reading 0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E\n",
      "Reading 0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13\n",
      "Reading 1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842\n",
      "Reading 1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3\n",
      "Reading 27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A\n",
      "Reading 33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A\n",
      "Reading 40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B\n",
      "Reading 481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7\n",
      "Reading 4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5\n",
      "Reading 59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2\n",
      "Reading 59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81\n",
      "Reading 61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD\n",
      "Reading 665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4\n",
      "Reading 74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C\n",
      "Reading 797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6\n",
      "Reading 806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0\n",
      "Reading 81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF\n",
      "Reading 86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "96A358A0-FFF2-4239-B93E-C7425B901B47\n",
      "Reading 96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769\n",
      "Reading 99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601\n",
      "Reading 00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694\n",
      "Reading 098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B\n",
      "Reading 0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406\n",
      "Reading 11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2\n",
      "Reading 136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20\n",
      "Reading 1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF\n",
      "Reading 24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E\n",
      "Reading 2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E\n",
      "Reading 3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C\n",
      "Reading 4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D\n",
      "Reading 5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53\n",
      "Reading 5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C\n",
      "Reading 5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n",
      "61976C24-1C50-4355-9C49-AAE44A7D09F6\n",
      "Reading 61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB\n",
      "Reading 78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2\n",
      "Reading 7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8\n",
      "Reading 7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F\n",
      "Reading 8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6\n",
      "Reading 83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C\n",
      "Reading 9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2\n",
      "Reading 9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96\n",
      "Reading A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A\n",
      "Reading A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F\n",
      "Reading B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495\n",
      "Reading B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC\n",
      "Reading BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153\n",
      "Reading C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B\n",
      "Reading CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "\n",
      "Training: Fold::4 X::(323580, 175) ,Y::(323580, 51)\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA\n",
      "Reading A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81\n",
      "Reading A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n",
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C\n",
      "Reading B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1\n",
      "Reading BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F\n",
      "Reading CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9\n",
      "Reading F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C\n",
      "Reading CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC\n",
      "Reading CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B\n",
      "Reading D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3\n",
      "Reading E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2\n",
      "Reading ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF\n",
      "Reading FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "\n",
      "Testing: Fold::4 X::(53766, 175) ,Y::(53766, 51)\n",
      "Pickling data files\n",
      "Done for fold 4\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Skipping cell if the data files were already created previously \n",
    "\n",
    "if not done:\n",
    "    # Reading data in the directory (Stacked)\n",
    "    \n",
    "    #M_train_t=np.empty((0,51))\n",
    "    #M_test_t=np.empty((0,51))\n",
    "    for fold_n in [0,1,2,3,4]:\n",
    "        X_train_t=np.empty((0,175))\n",
    "        Y_train_t=np.empty((0,51))\n",
    "        X_test_t=np.empty((0,175))\n",
    "        Y_test_t=np.empty((0,51))\n",
    "        train = glob.glob(cross_validation_user_loc+'fold_%d_train_*_uuids.txt'%fold_n)\n",
    "        test = glob.glob(cross_validation_user_loc+'fold_%d_test_*_uuids.txt'%fold_n)\n",
    "        for tr in train:\n",
    "            with open(tr,'r') as file:\n",
    "                for line in file:\n",
    "                    line = line.replace(\"\\n\",\"\")\n",
    "                    print line\n",
    "                    (x_user_train,y_user_train,missed_label_user,tstamp_user,featurename_user,labelname_user) = read_user_data(prefix+line+'.features_labels.csv.gz')\n",
    "                    x_sh=x_user_train.shape\n",
    "                    y_sh=y_user_train.shape\n",
    "                    y_user_train[np.isnan(y_user_train)]=-1\n",
    "                    x_user_train=np.nan_to_num(x_user_train)\n",
    "                    \n",
    "                    x_user_train=choose_sensors(x_user_train,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "                    X_train_t=np.vstack((X_train_t,x_user_train))\n",
    "                    Y_train_t=np.vstack((Y_train_t,y_user_train))\n",
    "                    X_train_t,_,_=standardize(X_train_t)\n",
    "                    assert len(X_train_t)==len(Y_train_t)\n",
    "        print('\\nTraining: Fold::{} X::{} ,Y::{}'.format(fold_n,X_train_t.shape,Y_train_t.shape))\n",
    "\n",
    "        for te in test:\n",
    "            with open(te,'r') as file:\n",
    "                for line in file:\n",
    "                    line = line.replace(\"\\n\",\"\")\n",
    "                    print line\n",
    "                    (x_user_test,y_user_test,missed_label_user,tstamp_user,featurename_user,labelname_user) = read_user_data(prefix+line+'.features_labels.csv.gz')\n",
    "                    x_sh=x_user_test.shape\n",
    "                    y_sh=y_user_test.shape\n",
    "                    y_user_test[np.isnan(y_user_test)]=-1\n",
    "                    x_user_test=np.nan_to_num(x_user_test)\n",
    "                    \n",
    "                    x_user_test=choose_sensors(x_user_test,used_sensors=sensor_types,summarized_feature_names=feature_names)\n",
    "                    X_test_t=np.vstack((X_test_t,x_user_test))\n",
    "                    Y_test_t=np.vstack((Y_test_t,y_user_test))\n",
    "                    \n",
    "                    assert len(X_test_t)==len(Y_test_t)\n",
    "        print('\\nTesting: Fold::{} X::{} ,Y::{}'.format(fold_n,X_test_t.shape,Y_test_t.shape))\n",
    "        \n",
    "        print(\"Pickling data files\")\n",
    "        # Split datasets\n",
    "        with open('dataset/pickled/x_train_cv{}.pkl'.format(fold_n),'wb') as f:\n",
    "            pickle.dump(X_train_t,f)\n",
    "        with open('dataset/pickled/y_train_cv{}.pkl'.format(fold_n),'wb') as f:\n",
    "            pickle.dump(Y_train_t,f)\n",
    "        with open('dataset/pickled/x_test_cv{}.pkl'.format(fold_n),'wb') as f:\n",
    "            pickle.dump(X_test_t,f)\n",
    "        with open('dataset/pickled/y_test_cv{}.pkl'.format(fold_n),'wb') as f:\n",
    "            pickle.dump(Y_test_t,f)\n",
    "        print(\"Done for fold {}\".format(fold_n))\n",
    "    print (\"DONE\")\n",
    "        \n",
    "                    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and pickling instance weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_instance_matrix(y_train):\n",
    "    instance_weights=np.zeros_like(y_train)\n",
    "    for l in range(len(labelname_user)):\n",
    "        temp_column=y_train[:,l]\n",
    "        count_neg=0\n",
    "        count_0=0\n",
    "        count_1=0\n",
    "        for i in range(len(temp_column)): # n^2 bincount doesn't work with arrays consisting of negative numbers\n",
    "            if (temp_column[i]==-1):\n",
    "                count_neg+=1\n",
    "            elif (temp_column[i]==0):\n",
    "                count_0+=1\n",
    "            elif (temp_column[i]==1):\n",
    "                count_1+=1\n",
    "            else:\n",
    "                raise ValueError(\"Bad Loop\")\n",
    "        for i in range(len(temp_column)):\n",
    "            if (temp_column[i]==-1):\n",
    "                instance_weights[i,l]=0.\n",
    "            elif (temp_column[i]==0):\n",
    "                instance_weights[i,l]=float((count_neg+count_0+count_1)/count_0)\n",
    "            elif (temp_column[i]==1):\n",
    "                instance_weights[i,l]=float((count_neg+count_0+count_1)/count_1)\n",
    "    return instance_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous train/test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda-enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Simple function to run using GPU when available\n",
    "def C(structure):\n",
    "    if torch.cuda.is_available():\n",
    "        device=torch.device(\"cuda\")\n",
    "        return structure.to(device)\n",
    "    else:\n",
    "        return structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tackling missing labels using a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a mask to hide -1 nans before training and then input to a train criterion\n",
    "def mask(criterion,y_true,y_pred,mask_value):\n",
    "    mask=torch.ne(y_true,mask_value).type(torch.cuda.FloatTensor)\n",
    "    # Cast the ByteTensor from elementwise comparison to a FloatTensor\n",
    "    return criterion(torch.mul(y_pred,mask),torch.mul(y_true,mask).type(torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Learning-Rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Linear decreasing LR scheduler\n",
    "def linear_lr_scheduler(optimizer,epoch):\n",
    "    \"\"\"\n",
    "    LR_init=0.1, LR_final=0.01, n_epochs=40\n",
    "    Sets the learning rate to the initial LR decayed by 1.04 every epoch\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr=param_group['lr']\n",
    "    m=-2.25e-3\n",
    "    c=0.1\n",
    "    lr=(epoch*m)+c # Linear LR decay based on a set number of epochs\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_lr_scheduler_2(optimizer, epoch):\n",
    "    gap = (0.1-0.01)/ 39\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        lr -= gap\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Norm for weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Adds euclidean regularization to weight matrices\n",
    "def frobenius_norm(model,loss):\n",
    "    regularizer_loss=0\n",
    "    \n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.Linear): # Linear layer\n",
    "            frobenius_norm=torch.norm(m.weight,p='fro')\n",
    "            regularizer_loss+=frobenius_norm # Regularization over the weight matrices for linear layers\n",
    "    return loss+0.001*regularizer_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy (Precision, Recall, F1, Support, Balanced Accuracy) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function for the required accuracy metrics per fold\n",
    "def accuracy(fold,target_labels,y_true,y_pred):\n",
    "    balanced_accuracy_dict={}\n",
    "    print('*'*20)\n",
    "    print('For fold {}'.format(fold))\n",
    "    # Precision, Recall, F1, Support\n",
    "    clf_report=classification_report(y_true=y_true,y_pred=y_pred,\n",
    "                                      target_names=target_labels,output_dict=True)\n",
    "    # Balanced accuracy\n",
    "    for i in range(len(target_labels)):\n",
    "        true_perlabel=y_true[:,i]\n",
    "        pred_perlabel=y_pred[:,i]\n",
    "        bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=pred_perlabel)\n",
    "        print('\\t Label {}:::-> Balanced Accuracy {}'.format(target_labels[i],round(bal_acc,7)))\n",
    "        balanced_accuracy_dict[target_labels[i]]=round(bal_acc,5)\n",
    "    return balanced_accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "def kfold_validation(model,X,Y,instance_weights,n_folds,n_epochs,lr_init,momentum):\n",
    "    # X, Y here are the complete datasets\n",
    "    kfolds=KFold(n_folds,shuffle=False,random_state=random_state).split(X) # Make n_folds\n",
    "    \n",
    "    fold_train_dict={} # Initialize dicts for train balanced accuracy- for each fold\n",
    "    fold_valid_dict={} # Initialize dicts for valid balanced accuracy- for each fold\n",
    "    \n",
    "    for fold, (train_index,val_index) in enumerate(kfolds): # Going through the folds\n",
    "        X_train=X[train_index]\n",
    "        y_train=Y[train_index]\n",
    "        X_valid=X[val_index]\n",
    "        y_valid=Y[val_index]\n",
    "\n",
    "\n",
    "         # Separate instance weight matrix based on the train index\n",
    "        instance_weights = get_instance_matrix(y_train)\n",
    "        instance_weight_matrix=torch.FloatTensor(instance_weights)\n",
    "        # Convert the training data to Variables\n",
    "        X_train=V(torch.FloatTensor(X_train.float()),requires_grad=True)\n",
    "        y_train=V(torch.FloatTensor(y_train.float()),requires_grad=False)\n",
    "        X_valid=V(torch.FloatTensor(X_valid.float()),requires_grad=False)\n",
    "        y_valid=V(torch.FloatTensor(y_valid.float()),requires_grad=False)\n",
    "        \n",
    "        #model_train=copy.deepcopy(model) # Deepcopy of model\n",
    "        \n",
    "        # Cuda compatible\n",
    "        model=C(model)\n",
    "#         X_train=C(X_train)\n",
    "#         y_train=C(y_train)\n",
    "#         X_valid=C(X_valid)\n",
    "#         y_valid=C(y_valid)\n",
    "        \n",
    "        # Train the network\n",
    "        \n",
    "        train(model,X_train,y_train,X_valid,y_valid,weights=instance_weight_matrix,\n",
    "            n_epoch=n_epochs,batch_size=bs,lr_init=lr_init,momentum=momentum,fold=fold)\n",
    "        \n",
    "        eval_bool=1\n",
    "        if eval_bool: # Basic methodology to ensure gradients aren't updated\n",
    "            model.eval() # Set to evaluation mode\n",
    "            # On training set\n",
    "            y_train_pred=torch.sigmoid(model(X_train))>=0.5\n",
    "            train_dict_out=accuracy(fold,labelname_user,y_train.cpu(),y_train_pred.cpu())\n",
    "            fold_train_dict[str(fold)]=train_dict_out\n",
    "            # On valid set\n",
    "            y_valid_pred=torch.sigmoid(model(X_valid))>=0.5\n",
    "            valid_dict_out=accuracy(fold,labelname_user,y_valid.cpu(),y_valid_pred.cpu())\n",
    "            fold_valid_dict[str(fold)]=valid_dict_out\n",
    "        eval_bool=0\n",
    "        model.train() # Set to train mode\n",
    "        \n",
    "    return fold_train_dict,fold_valid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train function w/BCE loss, linear LR scheduler, instance weights\n",
    "def train(model,X,Y,X_test,Y_test,weights,n_epoch,batch_size,lr_init,momentum,fold):\n",
    "    optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "    \n",
    "\n",
    "\n",
    "#criterion=C(nn.BCEWithLogitsLoss())\n",
    "    X=V(torch.FloatTensor(X),requires_grad=True)\n",
    "    Y=V(torch.FloatTensor(Y),requires_grad=False)\n",
    "    X_test=V(torch.FloatTensor(X_test),requires_grad=False)\n",
    "    Y_test=V(torch.FloatTensor(Y_test),requires_grad=False)\n",
    "    model = C(model)\n",
    "    # Create dataloaders\n",
    "    # Dataloader creation\n",
    "    # Wrap weights for instance weight tensor along with data & label tensors s.t.\n",
    "    # it can be called properly as a dataloader in batches.\n",
    "    train_dataset=utils.TensorDataset(X,Y,torch.from_numpy(weights).float())\n",
    "    train_loader=utils.DataLoader(dataset=train_dataset,batch_size=bs\n",
    "                                  ,shuffle=False,drop_last=False)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        done=1\n",
    "        for i,data in enumerate(train_loader,0):\n",
    "\n",
    "            inputs,labels,weights=data\n",
    "            inputs=V(torch.FloatTensor(inputs),requires_grad=True)\n",
    "            labels=V(torch.FloatTensor(labels),requires_grad=False)\n",
    "            weights=V(torch.FloatTensor(weights))\n",
    "\n",
    "            criterion=C(nn.BCEWithLogitsLoss(weight=weights))\n",
    "            optimizer.zero_grad()   \n",
    "            sum_total=0\n",
    "\n",
    "            outputs=model(inputs)\n",
    "\n",
    "            # Zero gradients, backward pass, weight update\n",
    "\n",
    "\n",
    "            loss=criterion(outputs,labels)\n",
    "            #loss=mask(criterion=criterion,y_true=labels,y_pred=output,mask_value=-1)\n",
    "            loss=frobenius_norm(model,loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_total+=loss.item()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                epoch_lr=param_group['lr']\n",
    "\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "        linear_lr_scheduler_2(optimizer,epoch)\n",
    "    print(\"Training finished, starting predicting\")\n",
    "    model.eval()\n",
    "    y_pred=torch.sigmoid(model(X))>=0.5\n",
    "    train_dict_out=accuracy(fold,labelname_user,Y.cpu(),y_pred.cpu())\n",
    "    fold_train_dict=train_dict_out\n",
    "    Y_test_pred=torch.sigmoid(model(X_test))>=0.5\n",
    "    test_dict_out=accuracy(fold,labelname_user,Y_test.cpu(),Y_test_pred.cpu())\n",
    "    fold_test_dict=test_dict_out\n",
    "    model.train()\n",
    "    return fold_train_dict,fold_test_dict\n",
    "        #train_predictions=torch.sigmoid(outputs)>=0.5\n",
    "        #accuracy=torc.eq(Y,train_predictions.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier: Learning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Hyperparameter variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('dataset/pickled/x_combined.pkl','rb') as f:\n",
    "    X_combined=pickle.load(f)\n",
    "    X_combined=C(torch.from_numpy(X_combined).float())\n",
    "with open('dataset/pickled/y_combined.pkl','rb') as f:\n",
    "    Y_combined=pickle.load(f)\n",
    "    Y_combined=C(torch.from_numpy(Y_combined).float())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 5cv data\n",
    "x_train = dict()\n",
    "y_train = dict()\n",
    "x_test = dict()\n",
    "y_test = dict()\n",
    "\n",
    "for fold_n in [0,1,2,3,4]:\n",
    "    with open('dataset/pickled/x_train_cv{}.pkl'.format(fold_n),'rb') as f:\n",
    "        x_train[fold_n]=pickle.load(f)\n",
    "        x_train[fold_n]=C(torch.from_numpy(x_train[fold_n]).double())\n",
    "    with open('dataset/pickled/y_train_cv{}.pkl'.format(fold_n),'rb') as f:\n",
    "        y_train[fold_n]=pickle.load(f)\n",
    "        y_train[fold_n]=C(torch.from_numpy(y_train[fold_n]).double())\n",
    "    with open('dataset/pickled/x_test_cv{}.pkl'.format(fold_n),'rb') as f:\n",
    "        x_test[fold_n]=pickle.load(f)\n",
    "        x_test[fold_n]=C(torch.from_numpy(x_test[fold_n]).double())\n",
    "    with open('dataset/pickled/y_test_cv{}.pkl'.format(fold_n),'rb') as f:\n",
    "        y_test[fold_n]=pickle.load(f)\n",
    "        y_test[fold_n]=C(torch.from_numpy(y_test[fold_n]).double())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "weights = dict()\n",
    "for fold_n in [0,1,2,3,4]:\n",
    "    print fold_n\n",
    "    weights[fold_n] = get_instance_matrix(y_train[fold_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=175\n",
    "hidden_size=16\n",
    "output_size=51\n",
    "n_fold=5\n",
    "n_epoch=40\n",
    "bs=300\n",
    "lr_init=0.1\n",
    "momentum=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (0 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0235,  0.0246, -0.0287,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0257,  0.0656,  0.0422,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0228,  0.0396, -0.0530,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.0177,  0.1692,  0.1875,  ...,  0.0000,  1.0000,  1.0000],\n",
      "        [ 1.0289,  0.2327,  0.3407,  ...,  0.0000,  1.0000,  1.0000],\n",
      "        [ 1.0049,  0.0444,  0.0559,  ...,  0.0000,  1.0000,  1.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearMLP(\n",
      "  (fc1): Linear(in_features=175, out_features=51, bias=True)\n",
      ")\n",
      "Epoch 1::Minibatch 1::LR 0.1 --> Loss 0.00863846381505\n",
      "Epoch 1::Minibatch 2::LR 0.1 --> Loss 0.00586015899976\n",
      "Epoch 1::Minibatch 3::LR 0.1 --> Loss 0.00594631830851\n",
      "Epoch 1::Minibatch 4::LR 0.1 --> Loss 0.00586006681124\n",
      "Epoch 1::Minibatch 5::LR 0.1 --> Loss 0.00430379112562\n",
      "Epoch 1::Minibatch 6::LR 0.1 --> Loss 0.00356008410454\n",
      "Epoch 1::Minibatch 7::LR 0.1 --> Loss 0.0053485528628\n",
      "Epoch 1::Minibatch 8::LR 0.1 --> Loss 0.0061365087827\n",
      "Epoch 1::Minibatch 9::LR 0.1 --> Loss 0.00486532489459\n",
      "Epoch 1::Minibatch 10::LR 0.1 --> Loss 0.00241277694702\n",
      "Epoch 1::Minibatch 11::LR 0.1 --> Loss 0.00235267241796\n",
      "Epoch 1::Minibatch 12::LR 0.1 --> Loss 0.00479318062464\n",
      "Epoch 1::Minibatch 13::LR 0.1 --> Loss 0.00328678528468\n",
      "Epoch 1::Minibatch 14::LR 0.1 --> Loss 0.00298812667529\n",
      "Epoch 1::Minibatch 15::LR 0.1 --> Loss 0.00417394598325\n",
      "Epoch 1::Minibatch 16::LR 0.1 --> Loss 0.00261644760768\n",
      "Epoch 1::Minibatch 17::LR 0.1 --> Loss 0.00871727069219\n",
      "Epoch 1::Minibatch 18::LR 0.1 --> Loss 0.00363827665647\n",
      "Epoch 1::Minibatch 19::LR 0.1 --> Loss 0.00322547614574\n",
      "Epoch 1::Minibatch 20::LR 0.1 --> Loss 0.00341931422551\n",
      "Epoch 1::Minibatch 21::LR 0.1 --> Loss 0.00432786742846\n",
      "Epoch 1::Minibatch 22::LR 0.1 --> Loss 0.00576774597168\n",
      "Epoch 1::Minibatch 23::LR 0.1 --> Loss 0.00198351641496\n",
      "Epoch 1::Minibatch 24::LR 0.1 --> Loss 0.00183952192465\n",
      "Epoch 1::Minibatch 25::LR 0.1 --> Loss 0.00229872604211\n",
      "Epoch 1::Minibatch 26::LR 0.1 --> Loss 0.0018017633756\n",
      "Epoch 1::Minibatch 27::LR 0.1 --> Loss 0.00173075298468\n",
      "Epoch 1::Minibatch 28::LR 0.1 --> Loss 0.00142623414596\n",
      "Epoch 1::Minibatch 29::LR 0.1 --> Loss 0.00111939807733\n",
      "Epoch 1::Minibatch 30::LR 0.1 --> Loss 0.00134744475285\n",
      "Epoch 1::Minibatch 31::LR 0.1 --> Loss 0.00137904971838\n",
      "Epoch 1::Minibatch 32::LR 0.1 --> Loss 0.00146103074153\n",
      "Epoch 1::Minibatch 33::LR 0.1 --> Loss 0.000840961535772\n",
      "Epoch 1::Minibatch 34::LR 0.1 --> Loss 0.00372640728951\n",
      "Epoch 1::Minibatch 35::LR 0.1 --> Loss 0.00370246092478\n",
      "Epoch 1::Minibatch 36::LR 0.1 --> Loss 0.0023533397913\n",
      "Epoch 1::Minibatch 37::LR 0.1 --> Loss 0.0014458990097\n",
      "Epoch 1::Minibatch 38::LR 0.1 --> Loss 0.00132012655338\n",
      "Epoch 1::Minibatch 39::LR 0.1 --> Loss 0.00223446031411\n",
      "Epoch 1::Minibatch 40::LR 0.1 --> Loss 0.0186833333969\n",
      "Epoch 1::Minibatch 41::LR 0.1 --> Loss 0.00437892397245\n",
      "Epoch 1::Minibatch 42::LR 0.1 --> Loss 0.0066753466924\n",
      "Epoch 1::Minibatch 43::LR 0.1 --> Loss 0.00346997380257\n",
      "Epoch 1::Minibatch 44::LR 0.1 --> Loss 0.00372763673464\n",
      "Epoch 1::Minibatch 45::LR 0.1 --> Loss 0.00388461709023\n",
      "Epoch 1::Minibatch 46::LR 0.1 --> Loss 0.00455597043037\n",
      "Epoch 1::Minibatch 47::LR 0.1 --> Loss 0.014285902977\n",
      "Epoch 1::Minibatch 48::LR 0.1 --> Loss 0.00743271430333\n",
      "Epoch 1::Minibatch 49::LR 0.1 --> Loss 0.00747634569804\n",
      "Epoch 1::Minibatch 50::LR 0.1 --> Loss 0.00868318637212\n",
      "Epoch 1::Minibatch 51::LR 0.1 --> Loss 0.0148628393809\n",
      "Epoch 1::Minibatch 52::LR 0.1 --> Loss 0.00518589178721\n",
      "Epoch 1::Minibatch 53::LR 0.1 --> Loss 0.00649547576904\n",
      "Epoch 1::Minibatch 54::LR 0.1 --> Loss 0.00580472628276\n",
      "Epoch 1::Minibatch 55::LR 0.1 --> Loss 0.00365329265594\n",
      "Epoch 1::Minibatch 56::LR 0.1 --> Loss 0.00517841498057\n",
      "Epoch 1::Minibatch 57::LR 0.1 --> Loss 0.0079643090566\n",
      "Epoch 1::Minibatch 58::LR 0.1 --> Loss 0.00568206707637\n",
      "Epoch 1::Minibatch 59::LR 0.1 --> Loss 0.00584162910779\n",
      "Epoch 1::Minibatch 60::LR 0.1 --> Loss 0.00426271001498\n",
      "Epoch 1::Minibatch 61::LR 0.1 --> Loss 0.00369941870372\n",
      "Epoch 1::Minibatch 62::LR 0.1 --> Loss 0.00603433450063\n",
      "Epoch 1::Minibatch 63::LR 0.1 --> Loss 0.00412587761879\n",
      "Epoch 1::Minibatch 64::LR 0.1 --> Loss 0.00312404930592\n",
      "Epoch 1::Minibatch 65::LR 0.1 --> Loss 0.00373010953267\n",
      "Epoch 1::Minibatch 66::LR 0.1 --> Loss 0.00464589834213\n",
      "Epoch 1::Minibatch 67::LR 0.1 --> Loss 0.00442700306575\n",
      "Epoch 1::Minibatch 68::LR 0.1 --> Loss 0.00351037184397\n",
      "Epoch 1::Minibatch 69::LR 0.1 --> Loss 0.00646267930667\n",
      "Epoch 1::Minibatch 70::LR 0.1 --> Loss 0.00533299009005\n",
      "Epoch 1::Minibatch 71::LR 0.1 --> Loss 0.00354068756104\n",
      "Epoch 1::Minibatch 72::LR 0.1 --> Loss 0.00186374584834\n",
      "Epoch 1::Minibatch 73::LR 0.1 --> Loss 0.00590405066808\n",
      "Epoch 1::Minibatch 74::LR 0.1 --> Loss 0.00568120161692\n",
      "Epoch 1::Minibatch 75::LR 0.1 --> Loss 0.0369407113393\n",
      "Epoch 1::Minibatch 76::LR 0.1 --> Loss 0.0031845364968\n",
      "Epoch 1::Minibatch 77::LR 0.1 --> Loss 0.00536736806234\n",
      "Epoch 1::Minibatch 78::LR 0.1 --> Loss 0.00746623595556\n",
      "Epoch 1::Minibatch 79::LR 0.1 --> Loss 0.00534722526868\n",
      "Epoch 1::Minibatch 80::LR 0.1 --> Loss 0.00743927717209\n",
      "Epoch 1::Minibatch 81::LR 0.1 --> Loss 0.00977976719538\n",
      "Epoch 1::Minibatch 82::LR 0.1 --> Loss 0.00511083841324\n",
      "Epoch 1::Minibatch 83::LR 0.1 --> Loss 0.0092556977272\n",
      "Epoch 1::Minibatch 84::LR 0.1 --> Loss 0.00524459322294\n",
      "Epoch 1::Minibatch 85::LR 0.1 --> Loss 0.00575403292974\n",
      "Epoch 1::Minibatch 86::LR 0.1 --> Loss 0.00520953059196\n",
      "Epoch 1::Minibatch 87::LR 0.1 --> Loss 0.00550229668617\n",
      "Epoch 1::Minibatch 88::LR 0.1 --> Loss 0.00555050810178\n",
      "Epoch 1::Minibatch 89::LR 0.1 --> Loss 0.00547736684481\n",
      "Epoch 1::Minibatch 90::LR 0.1 --> Loss 0.0048199125131\n",
      "Epoch 1::Minibatch 91::LR 0.1 --> Loss 0.00405360380809\n",
      "Epoch 1::Minibatch 92::LR 0.1 --> Loss 0.00698010206223\n",
      "Epoch 1::Minibatch 93::LR 0.1 --> Loss 0.00456112265587\n",
      "Epoch 1::Minibatch 94::LR 0.1 --> Loss 0.00533439358075\n",
      "Epoch 1::Minibatch 95::LR 0.1 --> Loss 0.00434324026108\n",
      "Epoch 1::Minibatch 96::LR 0.1 --> Loss 0.0108312781652\n",
      "Epoch 1::Minibatch 97::LR 0.1 --> Loss 0.00575324455897\n",
      "Epoch 1::Minibatch 98::LR 0.1 --> Loss 0.00296834985415\n",
      "Epoch 1::Minibatch 99::LR 0.1 --> Loss 0.00353150208791\n",
      "Epoch 1::Minibatch 100::LR 0.1 --> Loss 0.0098441529274\n",
      "Epoch 1::Minibatch 101::LR 0.1 --> Loss 0.00408135573069\n",
      "Epoch 1::Minibatch 102::LR 0.1 --> Loss 0.00795519828796\n",
      "Epoch 1::Minibatch 103::LR 0.1 --> Loss 0.00691205581029\n",
      "Epoch 1::Minibatch 104::LR 0.1 --> Loss 0.00639875332514\n",
      "Epoch 1::Minibatch 105::LR 0.1 --> Loss 0.0072253704071\n",
      "Epoch 1::Minibatch 106::LR 0.1 --> Loss 0.0244008382161\n",
      "Epoch 1::Minibatch 107::LR 0.1 --> Loss 0.00837999264399\n",
      "Epoch 1::Minibatch 108::LR 0.1 --> Loss 0.00450749476751\n",
      "Epoch 1::Minibatch 109::LR 0.1 --> Loss 0.00733180522919\n",
      "Epoch 1::Minibatch 110::LR 0.1 --> Loss 0.0052038359642\n",
      "Epoch 1::Minibatch 111::LR 0.1 --> Loss 0.00401640415192\n",
      "Epoch 1::Minibatch 112::LR 0.1 --> Loss 0.0071430238088\n",
      "Epoch 1::Minibatch 113::LR 0.1 --> Loss 0.0053151957194\n",
      "Epoch 1::Minibatch 114::LR 0.1 --> Loss 0.00442766904831\n",
      "Epoch 1::Minibatch 115::LR 0.1 --> Loss 0.00395209709803\n",
      "Epoch 1::Minibatch 116::LR 0.1 --> Loss 0.00529431541761\n",
      "Epoch 1::Minibatch 117::LR 0.1 --> Loss 0.00544899781545\n",
      "Epoch 1::Minibatch 118::LR 0.1 --> Loss 0.00654053370158\n",
      "Epoch 1::Minibatch 119::LR 0.1 --> Loss 0.0029673576355\n",
      "Epoch 1::Minibatch 120::LR 0.1 --> Loss 0.00425462206205\n",
      "Epoch 1::Minibatch 121::LR 0.1 --> Loss 0.00533341765404\n",
      "Epoch 1::Minibatch 122::LR 0.1 --> Loss 0.00542643070221\n",
      "Epoch 1::Minibatch 123::LR 0.1 --> Loss 0.00370186209679\n",
      "Epoch 1::Minibatch 124::LR 0.1 --> Loss 0.00453491568565\n",
      "Epoch 1::Minibatch 125::LR 0.1 --> Loss 0.00883489131927\n",
      "Epoch 1::Minibatch 126::LR 0.1 --> Loss 0.00387904882431\n",
      "Epoch 1::Minibatch 127::LR 0.1 --> Loss 0.00597541689873\n",
      "Epoch 1::Minibatch 128::LR 0.1 --> Loss 0.00457142631213\n",
      "Epoch 1::Minibatch 129::LR 0.1 --> Loss 0.00347952683767\n",
      "Epoch 1::Minibatch 130::LR 0.1 --> Loss 0.00497309009234\n",
      "Epoch 1::Minibatch 131::LR 0.1 --> Loss 0.00321657558282\n",
      "Epoch 1::Minibatch 132::LR 0.1 --> Loss 0.00384597857793\n",
      "Epoch 1::Minibatch 133::LR 0.1 --> Loss 0.00397790749868\n",
      "Epoch 1::Minibatch 134::LR 0.1 --> Loss 0.00387297391891\n",
      "Epoch 1::Minibatch 135::LR 0.1 --> Loss 0.00284854650497\n",
      "Epoch 1::Minibatch 136::LR 0.1 --> Loss 0.00368276198705\n",
      "Epoch 1::Minibatch 137::LR 0.1 --> Loss 0.00423644900322\n",
      "Epoch 1::Minibatch 138::LR 0.1 --> Loss 0.00257365485032\n",
      "Epoch 1::Minibatch 139::LR 0.1 --> Loss 0.00269789775213\n",
      "Epoch 1::Minibatch 140::LR 0.1 --> Loss 0.00295525232951\n",
      "Epoch 1::Minibatch 141::LR 0.1 --> Loss 0.00302252292633\n",
      "Epoch 1::Minibatch 142::LR 0.1 --> Loss 0.00422996719678\n",
      "Epoch 1::Minibatch 143::LR 0.1 --> Loss 0.00150678694248\n",
      "Epoch 1::Minibatch 144::LR 0.1 --> Loss 0.00364939371745\n",
      "Epoch 1::Minibatch 145::LR 0.1 --> Loss 0.00590790748596\n",
      "Epoch 1::Minibatch 146::LR 0.1 --> Loss 0.00393039703369\n",
      "Epoch 1::Minibatch 147::LR 0.1 --> Loss 0.00289965589841\n",
      "Epoch 1::Minibatch 148::LR 0.1 --> Loss 0.00204432646434\n",
      "Epoch 1::Minibatch 149::LR 0.1 --> Loss 0.00459373513858\n",
      "Epoch 1::Minibatch 150::LR 0.1 --> Loss 0.00433918237686\n",
      "Epoch 1::Minibatch 151::LR 0.1 --> Loss 0.00645155191422\n",
      "Epoch 1::Minibatch 152::LR 0.1 --> Loss 0.00193827311198\n",
      "Epoch 1::Minibatch 153::LR 0.1 --> Loss 0.00249155759811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 154::LR 0.1 --> Loss 0.0027583438158\n",
      "Epoch 1::Minibatch 155::LR 0.1 --> Loss 0.0108289011319\n",
      "Epoch 1::Minibatch 156::LR 0.1 --> Loss 0.00465566714605\n",
      "Epoch 1::Minibatch 157::LR 0.1 --> Loss 0.00127026468515\n",
      "Epoch 1::Minibatch 158::LR 0.1 --> Loss 0.00461632728577\n",
      "Epoch 1::Minibatch 159::LR 0.1 --> Loss 0.00395150462786\n",
      "Epoch 1::Minibatch 160::LR 0.1 --> Loss 0.00421960711479\n",
      "Epoch 1::Minibatch 161::LR 0.1 --> Loss 0.00228908220927\n",
      "Epoch 1::Minibatch 162::LR 0.1 --> Loss 0.00355428496997\n",
      "Epoch 1::Minibatch 163::LR 0.1 --> Loss 0.00358997623126\n",
      "Epoch 1::Minibatch 164::LR 0.1 --> Loss 0.00370731194814\n",
      "Epoch 1::Minibatch 165::LR 0.1 --> Loss 0.00170944869518\n",
      "Epoch 1::Minibatch 166::LR 0.1 --> Loss 0.00282417237759\n",
      "Epoch 1::Minibatch 167::LR 0.1 --> Loss 0.00376402139664\n",
      "Epoch 1::Minibatch 168::LR 0.1 --> Loss 0.00322313884894\n",
      "Epoch 1::Minibatch 169::LR 0.1 --> Loss 0.00204031129678\n",
      "Epoch 1::Minibatch 170::LR 0.1 --> Loss 0.00183423876762\n",
      "Epoch 1::Minibatch 171::LR 0.1 --> Loss 0.00347114245097\n",
      "Epoch 1::Minibatch 172::LR 0.1 --> Loss 0.00483655611674\n",
      "Epoch 1::Minibatch 173::LR 0.1 --> Loss 0.00337865908941\n",
      "Epoch 1::Minibatch 174::LR 0.1 --> Loss 0.00168929497401\n",
      "Epoch 1::Minibatch 175::LR 0.1 --> Loss 0.00303882082303\n",
      "Epoch 1::Minibatch 176::LR 0.1 --> Loss 0.00517253081004\n",
      "Epoch 1::Minibatch 177::LR 0.1 --> Loss 0.0146059068044\n",
      "Epoch 1::Minibatch 178::LR 0.1 --> Loss 0.00279949963093\n",
      "Epoch 1::Minibatch 179::LR 0.1 --> Loss 0.00201705972354\n",
      "Epoch 1::Minibatch 180::LR 0.1 --> Loss 0.00812628507614\n",
      "Epoch 1::Minibatch 181::LR 0.1 --> Loss 0.00472603003184\n",
      "Epoch 1::Minibatch 182::LR 0.1 --> Loss 0.00159110873938\n",
      "Epoch 1::Minibatch 183::LR 0.1 --> Loss 0.00292910297712\n",
      "Epoch 1::Minibatch 184::LR 0.1 --> Loss 0.0054751431942\n",
      "Epoch 1::Minibatch 185::LR 0.1 --> Loss 0.0029863512516\n",
      "Epoch 1::Minibatch 186::LR 0.1 --> Loss 0.00177979071935\n",
      "Epoch 1::Minibatch 187::LR 0.1 --> Loss 0.00258275727431\n",
      "Epoch 1::Minibatch 188::LR 0.1 --> Loss 0.00575227181117\n",
      "Epoch 1::Minibatch 189::LR 0.1 --> Loss 0.00460057576497\n",
      "Epoch 1::Minibatch 190::LR 0.1 --> Loss 0.00256242434184\n",
      "Epoch 1::Minibatch 191::LR 0.1 --> Loss 0.00100344508886\n",
      "Epoch 1::Minibatch 192::LR 0.1 --> Loss 0.00403465191523\n",
      "Epoch 1::Minibatch 193::LR 0.1 --> Loss 0.00338370680809\n",
      "Epoch 1::Minibatch 194::LR 0.1 --> Loss 0.00265214979649\n",
      "Epoch 1::Minibatch 195::LR 0.1 --> Loss 0.000902162988981\n",
      "Epoch 1::Minibatch 196::LR 0.1 --> Loss 0.0015770872434\n",
      "Epoch 1::Minibatch 197::LR 0.1 --> Loss 0.00342149337133\n",
      "Epoch 1::Minibatch 198::LR 0.1 --> Loss 0.00229015290737\n",
      "Epoch 1::Minibatch 199::LR 0.1 --> Loss 0.000774924556414\n",
      "Epoch 1::Minibatch 200::LR 0.1 --> Loss 0.00318240821362\n",
      "Epoch 1::Minibatch 201::LR 0.1 --> Loss 0.00266012966633\n",
      "Epoch 1::Minibatch 202::LR 0.1 --> Loss 0.00224446475506\n",
      "Epoch 1::Minibatch 203::LR 0.1 --> Loss 0.00268608808517\n",
      "Epoch 1::Minibatch 204::LR 0.1 --> Loss 0.00247271259626\n",
      "Epoch 1::Minibatch 205::LR 0.1 --> Loss 0.00313060204188\n",
      "Epoch 1::Minibatch 206::LR 0.1 --> Loss 0.0118715492884\n",
      "Epoch 1::Minibatch 207::LR 0.1 --> Loss 0.00183859785398\n",
      "Epoch 1::Minibatch 208::LR 0.1 --> Loss 0.00137537151575\n",
      "Epoch 1::Minibatch 209::LR 0.1 --> Loss 0.00277309894562\n",
      "Epoch 1::Minibatch 210::LR 0.1 --> Loss 0.00251956542333\n",
      "Epoch 1::Minibatch 211::LR 0.1 --> Loss 0.00222460865974\n",
      "Epoch 1::Minibatch 212::LR 0.1 --> Loss 0.00809520721436\n",
      "Epoch 1::Minibatch 213::LR 0.1 --> Loss 0.00944611708323\n",
      "Epoch 1::Minibatch 214::LR 0.1 --> Loss 0.0111705581347\n",
      "Epoch 1::Minibatch 215::LR 0.1 --> Loss 0.00171261986097\n",
      "Epoch 1::Minibatch 216::LR 0.1 --> Loss 0.0066368830204\n",
      "Epoch 1::Minibatch 217::LR 0.1 --> Loss 0.00577343742053\n",
      "Epoch 1::Minibatch 218::LR 0.1 --> Loss 0.00538271943728\n",
      "Epoch 1::Minibatch 219::LR 0.1 --> Loss 0.00308944741885\n",
      "Epoch 1::Minibatch 220::LR 0.1 --> Loss 0.00603168209394\n",
      "Epoch 1::Minibatch 221::LR 0.1 --> Loss 0.0055427646637\n",
      "Epoch 1::Minibatch 222::LR 0.1 --> Loss 0.00437435229619\n",
      "Epoch 1::Minibatch 223::LR 0.1 --> Loss 0.00199749747912\n",
      "Epoch 1::Minibatch 224::LR 0.1 --> Loss 0.00235300401847\n",
      "Epoch 1::Minibatch 225::LR 0.1 --> Loss 0.00615079363187\n",
      "Epoch 1::Minibatch 226::LR 0.1 --> Loss 0.00443672855695\n",
      "Epoch 1::Minibatch 227::LR 0.1 --> Loss 0.00216621776422\n",
      "Epoch 1::Minibatch 228::LR 0.1 --> Loss 0.00145579993725\n",
      "Epoch 1::Minibatch 229::LR 0.1 --> Loss 0.0127013754845\n",
      "Epoch 1::Minibatch 230::LR 0.1 --> Loss 0.00528848052025\n",
      "Epoch 1::Minibatch 231::LR 0.1 --> Loss 0.00321766455968\n",
      "Epoch 1::Minibatch 232::LR 0.1 --> Loss 0.0019973385334\n",
      "Epoch 1::Minibatch 233::LR 0.1 --> Loss 0.00281826833884\n",
      "Epoch 1::Minibatch 234::LR 0.1 --> Loss 0.00644418120384\n",
      "Epoch 1::Minibatch 235::LR 0.1 --> Loss 0.00644431153933\n",
      "Epoch 1::Minibatch 236::LR 0.1 --> Loss 0.00228773554166\n",
      "Epoch 1::Minibatch 237::LR 0.1 --> Loss 0.00143261581659\n",
      "Epoch 1::Minibatch 238::LR 0.1 --> Loss 0.00343505938848\n",
      "Epoch 1::Minibatch 239::LR 0.1 --> Loss 0.00292914231618\n",
      "Epoch 1::Minibatch 240::LR 0.1 --> Loss 0.00322822988033\n",
      "Epoch 1::Minibatch 241::LR 0.1 --> Loss 0.00136361430089\n",
      "Epoch 1::Minibatch 242::LR 0.1 --> Loss 0.0112596217791\n",
      "Epoch 1::Minibatch 243::LR 0.1 --> Loss 0.00468137145042\n",
      "Epoch 1::Minibatch 244::LR 0.1 --> Loss 0.00398352861404\n",
      "Epoch 1::Minibatch 245::LR 0.1 --> Loss 0.00135914345582\n",
      "Epoch 1::Minibatch 246::LR 0.1 --> Loss 0.00311019102732\n",
      "Epoch 1::Minibatch 247::LR 0.1 --> Loss 0.0425814374288\n",
      "Epoch 1::Minibatch 248::LR 0.1 --> Loss 0.00950441360474\n",
      "Epoch 1::Minibatch 249::LR 0.1 --> Loss 0.00953275203705\n",
      "Epoch 1::Minibatch 250::LR 0.1 --> Loss 0.00425317406654\n",
      "Epoch 1::Minibatch 251::LR 0.1 --> Loss 0.00286455730597\n",
      "Epoch 1::Minibatch 252::LR 0.1 --> Loss 0.003443445762\n",
      "Epoch 1::Minibatch 253::LR 0.1 --> Loss 0.00445588906606\n",
      "Epoch 1::Minibatch 254::LR 0.1 --> Loss 0.00816583871841\n",
      "Epoch 1::Minibatch 255::LR 0.1 --> Loss 0.00545938928922\n",
      "Epoch 1::Minibatch 256::LR 0.1 --> Loss 0.00311410844326\n",
      "Epoch 1::Minibatch 257::LR 0.1 --> Loss 0.00292208254337\n",
      "Epoch 1::Minibatch 258::LR 0.1 --> Loss 0.00487759431203\n",
      "Epoch 1::Minibatch 259::LR 0.1 --> Loss 0.00326886137327\n",
      "Epoch 1::Minibatch 260::LR 0.1 --> Loss 0.00332361559073\n",
      "Epoch 1::Minibatch 261::LR 0.1 --> Loss 0.00470746556918\n",
      "Epoch 1::Minibatch 262::LR 0.1 --> Loss 0.00343604326248\n",
      "Epoch 1::Minibatch 263::LR 0.1 --> Loss 0.00381863554319\n",
      "Epoch 1::Minibatch 264::LR 0.1 --> Loss 0.00487442016602\n",
      "Epoch 1::Minibatch 265::LR 0.1 --> Loss 0.0143890666962\n",
      "Epoch 1::Minibatch 266::LR 0.1 --> Loss 0.00226752062639\n",
      "Epoch 1::Minibatch 267::LR 0.1 --> Loss 0.0121340767543\n",
      "Epoch 1::Minibatch 268::LR 0.1 --> Loss 0.00265200614929\n",
      "Epoch 1::Minibatch 269::LR 0.1 --> Loss 0.00582824190458\n",
      "Epoch 1::Minibatch 270::LR 0.1 --> Loss 0.00764585494995\n",
      "Epoch 1::Minibatch 271::LR 0.1 --> Loss 0.00453012824059\n",
      "Epoch 1::Minibatch 272::LR 0.1 --> Loss 0.00524997274081\n",
      "Epoch 1::Minibatch 273::LR 0.1 --> Loss 0.00311703781287\n",
      "Epoch 1::Minibatch 274::LR 0.1 --> Loss 0.00305581867695\n",
      "Epoch 1::Minibatch 275::LR 0.1 --> Loss 0.00404164830844\n",
      "Epoch 1::Minibatch 276::LR 0.1 --> Loss 0.00457692265511\n",
      "Epoch 1::Minibatch 277::LR 0.1 --> Loss 0.00239312052727\n",
      "Epoch 1::Minibatch 278::LR 0.1 --> Loss 0.00355765978495\n",
      "Epoch 1::Minibatch 279::LR 0.1 --> Loss 0.00340917746226\n",
      "Epoch 1::Minibatch 280::LR 0.1 --> Loss 0.00337659041087\n",
      "Epoch 1::Minibatch 281::LR 0.1 --> Loss 0.00243262648582\n",
      "Epoch 1::Minibatch 282::LR 0.1 --> Loss 0.00306681056817\n",
      "Epoch 1::Minibatch 283::LR 0.1 --> Loss 0.00306136568387\n",
      "Epoch 1::Minibatch 284::LR 0.1 --> Loss 0.0027083871762\n",
      "Epoch 1::Minibatch 285::LR 0.1 --> Loss 0.00206022898356\n",
      "Epoch 1::Minibatch 286::LR 0.1 --> Loss 0.00300011436145\n",
      "Epoch 1::Minibatch 287::LR 0.1 --> Loss 0.00289343973001\n",
      "Epoch 1::Minibatch 288::LR 0.1 --> Loss 0.0019145933787\n",
      "Epoch 1::Minibatch 289::LR 0.1 --> Loss 0.00211758752664\n",
      "Epoch 1::Minibatch 290::LR 0.1 --> Loss 0.00275419314702\n",
      "Epoch 1::Minibatch 291::LR 0.1 --> Loss 0.00261253515879\n",
      "Epoch 1::Minibatch 292::LR 0.1 --> Loss 0.00152851462364\n",
      "Epoch 1::Minibatch 293::LR 0.1 --> Loss 0.00210148235162\n",
      "Epoch 1::Minibatch 294::LR 0.1 --> Loss 0.00240028659503\n",
      "Epoch 1::Minibatch 295::LR 0.1 --> Loss 0.00241947789987\n",
      "Epoch 1::Minibatch 296::LR 0.1 --> Loss 0.00211917559306\n",
      "Epoch 1::Minibatch 297::LR 0.1 --> Loss 0.00202919860681\n",
      "Epoch 1::Minibatch 298::LR 0.1 --> Loss 0.00199215233326\n",
      "Epoch 1::Minibatch 299::LR 0.1 --> Loss 0.00153957565626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 300::LR 0.1 --> Loss 0.00458836913109\n",
      "Epoch 1::Minibatch 301::LR 0.1 --> Loss 0.00405575633049\n",
      "Epoch 1::Minibatch 302::LR 0.1 --> Loss 0.0032532342275\n",
      "Epoch 1::Minibatch 303::LR 0.1 --> Loss 0.00150500694911\n",
      "Epoch 1::Minibatch 304::LR 0.1 --> Loss 0.00435640692711\n",
      "Epoch 1::Minibatch 305::LR 0.1 --> Loss 0.0023265906175\n",
      "Epoch 1::Minibatch 306::LR 0.1 --> Loss 0.00158463199933\n",
      "Epoch 1::Minibatch 307::LR 0.1 --> Loss 0.00318704168002\n",
      "Epoch 1::Minibatch 308::LR 0.1 --> Loss 0.00221896886826\n",
      "Epoch 1::Minibatch 309::LR 0.1 --> Loss 0.00140384664138\n",
      "Epoch 1::Minibatch 310::LR 0.1 --> Loss 0.00134390344222\n",
      "Epoch 1::Minibatch 311::LR 0.1 --> Loss 0.0020216157039\n",
      "Epoch 1::Minibatch 312::LR 0.1 --> Loss 0.00487454533577\n",
      "Epoch 1::Minibatch 313::LR 0.1 --> Loss 0.00330500284831\n",
      "Epoch 1::Minibatch 314::LR 0.1 --> Loss 0.00284091055393\n",
      "Epoch 1::Minibatch 315::LR 0.1 --> Loss 0.0012217310071\n",
      "Epoch 1::Minibatch 316::LR 0.1 --> Loss 0.00330433090528\n",
      "Epoch 1::Minibatch 317::LR 0.1 --> Loss 0.00219546159108\n",
      "Epoch 1::Minibatch 318::LR 0.1 --> Loss 0.00148854394754\n",
      "Epoch 1::Minibatch 319::LR 0.1 --> Loss 0.00312008003394\n",
      "Epoch 1::Minibatch 320::LR 0.1 --> Loss 0.00438363432884\n",
      "Epoch 1::Minibatch 321::LR 0.1 --> Loss 0.00142633885145\n",
      "Epoch 1::Minibatch 322::LR 0.1 --> Loss 0.00381596366564\n",
      "Epoch 1::Minibatch 323::LR 0.1 --> Loss 0.00481581290563\n",
      "Epoch 1::Minibatch 324::LR 0.1 --> Loss 0.0031735120217\n",
      "Epoch 1::Minibatch 325::LR 0.1 --> Loss 0.00311794718107\n",
      "Epoch 1::Minibatch 326::LR 0.1 --> Loss 0.0144596322378\n",
      "Epoch 1::Minibatch 327::LR 0.1 --> Loss 0.00332565824191\n",
      "Epoch 1::Minibatch 328::LR 0.1 --> Loss 0.00480018099149\n",
      "Epoch 1::Minibatch 329::LR 0.1 --> Loss 0.00176863571008\n",
      "Epoch 1::Minibatch 330::LR 0.1 --> Loss 0.00237510840098\n",
      "Epoch 1::Minibatch 331::LR 0.1 --> Loss 0.00361597061157\n",
      "Epoch 1::Minibatch 332::LR 0.1 --> Loss 0.00338905255\n",
      "Epoch 1::Minibatch 333::LR 0.1 --> Loss 0.00218511720498\n",
      "Epoch 1::Minibatch 334::LR 0.1 --> Loss 0.00512223402659\n",
      "Epoch 1::Minibatch 335::LR 0.1 --> Loss 0.00246473809083\n",
      "Epoch 1::Minibatch 336::LR 0.1 --> Loss 0.00238065401713\n",
      "Epoch 1::Minibatch 337::LR 0.1 --> Loss 0.00388256231944\n",
      "Epoch 1::Minibatch 338::LR 0.1 --> Loss 0.00096809387207\n",
      "Epoch 1::Minibatch 339::LR 0.1 --> Loss 0.003865117232\n",
      "Epoch 1::Minibatch 340::LR 0.1 --> Loss 0.00728354056676\n",
      "Epoch 1::Minibatch 341::LR 0.1 --> Loss 0.00729924996694\n",
      "Epoch 1::Minibatch 342::LR 0.1 --> Loss 0.011698864301\n",
      "Epoch 1::Minibatch 343::LR 0.1 --> Loss 0.00258668541908\n",
      "Epoch 1::Minibatch 344::LR 0.1 --> Loss 0.00384327252706\n",
      "Epoch 1::Minibatch 345::LR 0.1 --> Loss 0.00513165156047\n",
      "Epoch 1::Minibatch 346::LR 0.1 --> Loss 0.00655247410138\n",
      "Epoch 1::Minibatch 347::LR 0.1 --> Loss 0.00151754925648\n",
      "Epoch 1::Minibatch 348::LR 0.1 --> Loss 0.00644196430842\n",
      "Epoch 1::Minibatch 349::LR 0.1 --> Loss 0.00460336367289\n",
      "Epoch 1::Minibatch 350::LR 0.1 --> Loss 0.00288350522518\n",
      "Epoch 1::Minibatch 351::LR 0.1 --> Loss 0.00448165098826\n",
      "Epoch 1::Minibatch 352::LR 0.1 --> Loss 0.00551782647769\n",
      "Epoch 1::Minibatch 353::LR 0.1 --> Loss 0.0044937924544\n",
      "Epoch 1::Minibatch 354::LR 0.1 --> Loss 0.00379136919975\n",
      "Epoch 1::Minibatch 355::LR 0.1 --> Loss 0.00628368576368\n",
      "Epoch 1::Minibatch 356::LR 0.1 --> Loss 0.00427188634872\n",
      "Epoch 1::Minibatch 357::LR 0.1 --> Loss 0.00189298431079\n",
      "Epoch 1::Minibatch 358::LR 0.1 --> Loss 0.00341676433881\n",
      "Epoch 1::Minibatch 359::LR 0.1 --> Loss 0.00438452760379\n",
      "Epoch 1::Minibatch 360::LR 0.1 --> Loss 0.00355572342873\n",
      "Epoch 1::Minibatch 361::LR 0.1 --> Loss 0.00326284945011\n",
      "Epoch 1::Minibatch 362::LR 0.1 --> Loss 0.00361318786939\n",
      "Epoch 1::Minibatch 363::LR 0.1 --> Loss 0.00126466413339\n",
      "Epoch 1::Minibatch 364::LR 0.1 --> Loss 0.00278632541498\n",
      "Epoch 1::Minibatch 365::LR 0.1 --> Loss 0.00300395449003\n",
      "Epoch 1::Minibatch 366::LR 0.1 --> Loss 0.0031920671463\n",
      "Epoch 1::Minibatch 367::LR 0.1 --> Loss 0.0019071050485\n",
      "Epoch 1::Minibatch 368::LR 0.1 --> Loss 0.00149320443471\n",
      "Epoch 1::Minibatch 369::LR 0.1 --> Loss 0.00360261559486\n",
      "Epoch 1::Minibatch 370::LR 0.1 --> Loss 0.00261849224567\n",
      "Epoch 1::Minibatch 371::LR 0.1 --> Loss 0.00244159281254\n",
      "Epoch 1::Minibatch 372::LR 0.1 --> Loss 0.000962252219518\n",
      "Epoch 1::Minibatch 373::LR 0.1 --> Loss 0.00212970594565\n",
      "Epoch 1::Minibatch 374::LR 0.1 --> Loss 0.00240960319837\n",
      "Epoch 1::Minibatch 375::LR 0.1 --> Loss 0.002155204614\n",
      "Epoch 1::Minibatch 376::LR 0.1 --> Loss 0.00180190960566\n",
      "Epoch 1::Minibatch 377::LR 0.1 --> Loss 0.00278109868368\n",
      "Epoch 1::Minibatch 378::LR 0.1 --> Loss 0.00268154859543\n",
      "Epoch 1::Minibatch 379::LR 0.1 --> Loss 0.00307846069336\n",
      "Epoch 1::Minibatch 380::LR 0.1 --> Loss 0.00199551105499\n",
      "Epoch 1::Minibatch 381::LR 0.1 --> Loss 0.00154446254174\n",
      "Epoch 1::Minibatch 382::LR 0.1 --> Loss 0.0025369211038\n",
      "Epoch 1::Minibatch 383::LR 0.1 --> Loss 0.00240425725778\n",
      "Epoch 1::Minibatch 384::LR 0.1 --> Loss 0.00137995014588\n",
      "Epoch 1::Minibatch 385::LR 0.1 --> Loss 0.00158292869727\n",
      "Epoch 1::Minibatch 386::LR 0.1 --> Loss 0.0030334675312\n",
      "Epoch 1::Minibatch 387::LR 0.1 --> Loss 0.00299365282059\n",
      "Epoch 1::Minibatch 388::LR 0.1 --> Loss 0.00150318076213\n",
      "Epoch 1::Minibatch 389::LR 0.1 --> Loss 0.00293611486753\n",
      "Epoch 1::Minibatch 390::LR 0.1 --> Loss 0.00872472683589\n",
      "Epoch 1::Minibatch 391::LR 0.1 --> Loss 0.00369210124016\n",
      "Epoch 1::Minibatch 392::LR 0.1 --> Loss 0.00414588769277\n",
      "Epoch 1::Minibatch 393::LR 0.1 --> Loss 0.00384679198265\n",
      "Epoch 1::Minibatch 394::LR 0.1 --> Loss 0.00467700441678\n",
      "Epoch 1::Minibatch 395::LR 0.1 --> Loss 0.00306874771913\n",
      "Epoch 1::Minibatch 396::LR 0.1 --> Loss 0.00324958821138\n",
      "Epoch 1::Minibatch 397::LR 0.1 --> Loss 0.00335221131643\n",
      "Epoch 1::Minibatch 398::LR 0.1 --> Loss 0.0032570173343\n",
      "Epoch 1::Minibatch 399::LR 0.1 --> Loss 0.00310404082139\n",
      "Epoch 1::Minibatch 400::LR 0.1 --> Loss 0.003271976312\n",
      "Epoch 1::Minibatch 401::LR 0.1 --> Loss 0.00772317488988\n",
      "Epoch 1::Minibatch 402::LR 0.1 --> Loss 0.00261752009392\n",
      "Epoch 1::Minibatch 403::LR 0.1 --> Loss 0.0021106761694\n",
      "Epoch 1::Minibatch 404::LR 0.1 --> Loss 0.0021766191721\n",
      "Epoch 1::Minibatch 405::LR 0.1 --> Loss 0.00422629117966\n",
      "Epoch 1::Minibatch 406::LR 0.1 --> Loss 0.00329073905945\n",
      "Epoch 1::Minibatch 407::LR 0.1 --> Loss 0.00225750525792\n",
      "Epoch 1::Minibatch 408::LR 0.1 --> Loss 0.00101270159086\n",
      "Epoch 1::Minibatch 409::LR 0.1 --> Loss 0.0045218471686\n",
      "Epoch 1::Minibatch 410::LR 0.1 --> Loss 0.00913371721903\n",
      "Epoch 1::Minibatch 411::LR 0.1 --> Loss 0.00220484515031\n",
      "Epoch 1::Minibatch 412::LR 0.1 --> Loss 0.00147574881713\n",
      "Epoch 1::Minibatch 413::LR 0.1 --> Loss 0.00281905591488\n",
      "Epoch 1::Minibatch 414::LR 0.1 --> Loss 0.00221826891104\n",
      "Epoch 1::Minibatch 415::LR 0.1 --> Loss 0.00162906597058\n",
      "Epoch 1::Minibatch 416::LR 0.1 --> Loss 0.00143173297246\n",
      "Epoch 1::Minibatch 417::LR 0.1 --> Loss 0.00208477079868\n",
      "Epoch 1::Minibatch 418::LR 0.1 --> Loss 0.00849812269211\n",
      "Epoch 1::Minibatch 419::LR 0.1 --> Loss 0.00108167856932\n",
      "Epoch 1::Minibatch 420::LR 0.1 --> Loss 0.00124387095372\n",
      "Epoch 1::Minibatch 421::LR 0.1 --> Loss 0.00253664493561\n",
      "Epoch 1::Minibatch 422::LR 0.1 --> Loss 0.00278613865376\n",
      "Epoch 1::Minibatch 423::LR 0.1 --> Loss 0.00126626471678\n",
      "Epoch 1::Minibatch 424::LR 0.1 --> Loss 0.00223938981692\n",
      "Epoch 1::Minibatch 425::LR 0.1 --> Loss 0.00313148438931\n",
      "Epoch 1::Minibatch 426::LR 0.1 --> Loss 0.00259195566177\n",
      "Epoch 1::Minibatch 427::LR 0.1 --> Loss 0.000996321936448\n",
      "Epoch 1::Minibatch 428::LR 0.1 --> Loss 0.00202216466268\n",
      "Epoch 1::Minibatch 429::LR 0.1 --> Loss 0.00363630175591\n",
      "Epoch 1::Minibatch 430::LR 0.1 --> Loss 0.0126977650325\n",
      "Epoch 1::Minibatch 431::LR 0.1 --> Loss 0.00398255228996\n",
      "Epoch 1::Minibatch 432::LR 0.1 --> Loss 0.0053090985616\n",
      "Epoch 1::Minibatch 433::LR 0.1 --> Loss 0.00304169515769\n",
      "Epoch 1::Minibatch 434::LR 0.1 --> Loss 0.00340813159943\n",
      "Epoch 1::Minibatch 435::LR 0.1 --> Loss 0.00334351738294\n",
      "Epoch 1::Minibatch 436::LR 0.1 --> Loss 0.00220962742964\n",
      "Epoch 1::Minibatch 437::LR 0.1 --> Loss 0.00553948561351\n",
      "Epoch 1::Minibatch 438::LR 0.1 --> Loss 0.00333419919014\n",
      "Epoch 1::Minibatch 439::LR 0.1 --> Loss 0.0027756613493\n",
      "Epoch 1::Minibatch 440::LR 0.1 --> Loss 0.00448511242867\n",
      "Epoch 1::Minibatch 441::LR 0.1 --> Loss 0.004324101607\n",
      "Epoch 1::Minibatch 442::LR 0.1 --> Loss 0.00404239376386\n",
      "Epoch 1::Minibatch 443::LR 0.1 --> Loss 0.00542115410169\n",
      "Epoch 1::Minibatch 444::LR 0.1 --> Loss 0.00374338070552\n",
      "Epoch 1::Minibatch 445::LR 0.1 --> Loss 0.00166651835044\n",
      "Epoch 1::Minibatch 446::LR 0.1 --> Loss 0.00214263359706\n",
      "Epoch 1::Minibatch 447::LR 0.1 --> Loss 0.00358674526215\n",
      "Epoch 1::Minibatch 448::LR 0.1 --> Loss 0.00363802711169\n",
      "Epoch 1::Minibatch 449::LR 0.1 --> Loss 0.00505594849586\n",
      "Epoch 1::Minibatch 450::LR 0.1 --> Loss 0.00367127219836\n",
      "Epoch 1::Minibatch 451::LR 0.1 --> Loss 0.00529442985853\n",
      "Epoch 1::Minibatch 452::LR 0.1 --> Loss 0.00314995825291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 453::LR 0.1 --> Loss 0.00157879412174\n",
      "Epoch 1::Minibatch 454::LR 0.1 --> Loss 0.0117368729909\n",
      "Epoch 1::Minibatch 455::LR 0.1 --> Loss 0.00414233962695\n",
      "Epoch 1::Minibatch 456::LR 0.1 --> Loss 0.00525518099467\n",
      "Epoch 1::Minibatch 457::LR 0.1 --> Loss 0.00294373253981\n",
      "Epoch 1::Minibatch 458::LR 0.1 --> Loss 0.00146152685086\n",
      "Epoch 1::Minibatch 459::LR 0.1 --> Loss 0.00960856199265\n",
      "Epoch 1::Minibatch 460::LR 0.1 --> Loss 0.00412416815758\n",
      "Epoch 1::Minibatch 461::LR 0.1 --> Loss 0.00548822601636\n",
      "Epoch 1::Minibatch 462::LR 0.1 --> Loss 0.00146253774563\n",
      "Epoch 1::Minibatch 463::LR 0.1 --> Loss 0.00604381124179\n",
      "Epoch 1::Minibatch 464::LR 0.1 --> Loss 0.00378623644511\n",
      "Epoch 1::Minibatch 465::LR 0.1 --> Loss 0.00739232142766\n",
      "Epoch 1::Minibatch 466::LR 0.1 --> Loss 0.00643648902575\n",
      "Epoch 1::Minibatch 467::LR 0.1 --> Loss 0.00563307245572\n",
      "Epoch 1::Minibatch 468::LR 0.1 --> Loss 0.00563837488492\n",
      "Epoch 1::Minibatch 469::LR 0.1 --> Loss 0.0119623891513\n",
      "Epoch 1::Minibatch 470::LR 0.1 --> Loss 0.00524410247803\n",
      "Epoch 1::Minibatch 471::LR 0.1 --> Loss 0.00333509087563\n",
      "Epoch 1::Minibatch 472::LR 0.1 --> Loss 0.00433610836665\n",
      "Epoch 1::Minibatch 473::LR 0.1 --> Loss 0.0032797062397\n",
      "Epoch 1::Minibatch 474::LR 0.1 --> Loss 0.0017646441857\n",
      "Epoch 1::Minibatch 475::LR 0.1 --> Loss 0.00577720681826\n",
      "Epoch 1::Minibatch 476::LR 0.1 --> Loss 0.00765095392863\n",
      "Epoch 1::Minibatch 477::LR 0.1 --> Loss 0.00177522321542\n",
      "Epoch 1::Minibatch 478::LR 0.1 --> Loss 0.00364859302839\n",
      "Epoch 1::Minibatch 479::LR 0.1 --> Loss 0.00304096758366\n",
      "Epoch 1::Minibatch 480::LR 0.1 --> Loss 0.00261949439843\n",
      "Epoch 1::Minibatch 481::LR 0.1 --> Loss 0.00158777316411\n",
      "Epoch 1::Minibatch 482::LR 0.1 --> Loss 0.00343044877052\n",
      "Epoch 1::Minibatch 483::LR 0.1 --> Loss 0.00627693653107\n",
      "Epoch 1::Minibatch 484::LR 0.1 --> Loss 0.00526072899501\n",
      "Epoch 1::Minibatch 485::LR 0.1 --> Loss 0.00173473000526\n",
      "Epoch 1::Minibatch 486::LR 0.1 --> Loss 0.00398898800214\n",
      "Epoch 1::Minibatch 487::LR 0.1 --> Loss 0.00533736387889\n",
      "Epoch 1::Minibatch 488::LR 0.1 --> Loss 0.00315115054448\n",
      "Epoch 1::Minibatch 489::LR 0.1 --> Loss 0.00403941750526\n",
      "Epoch 1::Minibatch 490::LR 0.1 --> Loss 0.00133551329374\n",
      "Epoch 1::Minibatch 491::LR 0.1 --> Loss 0.0220333655675\n",
      "Epoch 1::Minibatch 492::LR 0.1 --> Loss 0.00428683876991\n",
      "Epoch 1::Minibatch 493::LR 0.1 --> Loss 0.00461773276329\n",
      "Epoch 1::Minibatch 494::LR 0.1 --> Loss 0.00179932872454\n",
      "Epoch 1::Minibatch 495::LR 0.1 --> Loss 0.00338076710701\n",
      "Epoch 1::Minibatch 496::LR 0.1 --> Loss 0.00564086953799\n",
      "Epoch 1::Minibatch 497::LR 0.1 --> Loss 0.0021583477656\n",
      "Epoch 1::Minibatch 498::LR 0.1 --> Loss 0.00179021100203\n",
      "Epoch 1::Minibatch 499::LR 0.1 --> Loss 0.00574870785077\n",
      "Epoch 1::Minibatch 500::LR 0.1 --> Loss 0.00233935991923\n",
      "Epoch 1::Minibatch 501::LR 0.1 --> Loss 0.00294366737207\n",
      "Epoch 1::Minibatch 502::LR 0.1 --> Loss 0.0048188495636\n",
      "Epoch 1::Minibatch 503::LR 0.1 --> Loss 0.00738731622696\n",
      "Epoch 1::Minibatch 504::LR 0.1 --> Loss 0.00885439475377\n",
      "Epoch 1::Minibatch 505::LR 0.1 --> Loss 0.00587712446849\n",
      "Epoch 1::Minibatch 506::LR 0.1 --> Loss 0.00478925903638\n",
      "Epoch 1::Minibatch 507::LR 0.1 --> Loss 0.00644080042839\n",
      "Epoch 1::Minibatch 508::LR 0.1 --> Loss 0.00418123563131\n",
      "Epoch 1::Minibatch 509::LR 0.1 --> Loss 0.00519554654757\n",
      "Epoch 1::Minibatch 510::LR 0.1 --> Loss 0.00687006314596\n",
      "Epoch 1::Minibatch 511::LR 0.1 --> Loss 0.00449072241783\n",
      "Epoch 1::Minibatch 512::LR 0.1 --> Loss 0.00358902057012\n",
      "Epoch 1::Minibatch 513::LR 0.1 --> Loss 0.00174487948418\n",
      "Epoch 1::Minibatch 514::LR 0.1 --> Loss 0.00356162667274\n",
      "Epoch 1::Minibatch 515::LR 0.1 --> Loss 0.00435841520627\n",
      "Epoch 1::Minibatch 516::LR 0.1 --> Loss 0.0056721830368\n",
      "Epoch 1::Minibatch 517::LR 0.1 --> Loss 0.003931235075\n",
      "Epoch 1::Minibatch 518::LR 0.1 --> Loss 0.00333264569441\n",
      "Epoch 1::Minibatch 519::LR 0.1 --> Loss 0.00427571972211\n",
      "Epoch 1::Minibatch 520::LR 0.1 --> Loss 0.00733216842016\n",
      "Epoch 1::Minibatch 521::LR 0.1 --> Loss 0.00818326632182\n",
      "Epoch 1::Minibatch 522::LR 0.1 --> Loss 0.00667565345764\n",
      "Epoch 1::Minibatch 523::LR 0.1 --> Loss 0.00178269763788\n",
      "Epoch 1::Minibatch 524::LR 0.1 --> Loss 0.00255198319753\n",
      "Epoch 1::Minibatch 525::LR 0.1 --> Loss 0.00417937159538\n",
      "Epoch 1::Minibatch 526::LR 0.1 --> Loss 0.00430897553762\n",
      "Epoch 1::Minibatch 527::LR 0.1 --> Loss 0.00336555480957\n",
      "Epoch 1::Minibatch 528::LR 0.1 --> Loss 0.0021329365174\n",
      "Epoch 1::Minibatch 529::LR 0.1 --> Loss 0.00502894322077\n",
      "Epoch 1::Minibatch 530::LR 0.1 --> Loss 0.0058369187514\n",
      "Epoch 1::Minibatch 531::LR 0.1 --> Loss 0.00527034560839\n",
      "Epoch 1::Minibatch 532::LR 0.1 --> Loss 0.00394967476527\n",
      "Epoch 1::Minibatch 533::LR 0.1 --> Loss 0.00569294691086\n",
      "Epoch 1::Minibatch 534::LR 0.1 --> Loss 0.00426415602366\n",
      "Epoch 1::Minibatch 535::LR 0.1 --> Loss 0.00420746882757\n",
      "Epoch 1::Minibatch 536::LR 0.1 --> Loss 0.00321112155914\n",
      "Epoch 1::Minibatch 537::LR 0.1 --> Loss 0.0017317310969\n",
      "Epoch 1::Minibatch 538::LR 0.1 --> Loss 0.00275477011998\n",
      "Epoch 1::Minibatch 539::LR 0.1 --> Loss 0.00422575076421\n",
      "Epoch 1::Minibatch 540::LR 0.1 --> Loss 0.00430191596349\n",
      "Epoch 1::Minibatch 541::LR 0.1 --> Loss 0.00391966938972\n",
      "Epoch 1::Minibatch 542::LR 0.1 --> Loss 0.00375698129336\n",
      "Epoch 1::Minibatch 543::LR 0.1 --> Loss 0.00406408429146\n",
      "Epoch 1::Minibatch 544::LR 0.1 --> Loss 0.00541764775912\n",
      "Epoch 1::Minibatch 545::LR 0.1 --> Loss 0.0030198019743\n",
      "Epoch 1::Minibatch 546::LR 0.1 --> Loss 0.00176550269127\n",
      "Epoch 1::Minibatch 547::LR 0.1 --> Loss 0.00370301405589\n",
      "Epoch 1::Minibatch 548::LR 0.1 --> Loss 0.00501960833867\n",
      "Epoch 1::Minibatch 549::LR 0.1 --> Loss 0.00705187320709\n",
      "Epoch 1::Minibatch 550::LR 0.1 --> Loss 0.00205472588539\n",
      "Epoch 1::Minibatch 551::LR 0.1 --> Loss 0.00341883659363\n",
      "Epoch 1::Minibatch 552::LR 0.1 --> Loss 0.00476158658663\n",
      "Epoch 1::Minibatch 553::LR 0.1 --> Loss 0.00432175040245\n",
      "Epoch 1::Minibatch 554::LR 0.1 --> Loss 0.00596015254656\n",
      "Epoch 1::Minibatch 555::LR 0.1 --> Loss 0.00181378225485\n",
      "Epoch 1::Minibatch 556::LR 0.1 --> Loss 0.00324512163798\n",
      "Epoch 1::Minibatch 557::LR 0.1 --> Loss 0.00344731370608\n",
      "Epoch 1::Minibatch 558::LR 0.1 --> Loss 0.00472699681918\n",
      "Epoch 1::Minibatch 559::LR 0.1 --> Loss 0.00469566265742\n",
      "Epoch 1::Minibatch 560::LR 0.1 --> Loss 0.00409256736437\n",
      "Epoch 1::Minibatch 561::LR 0.1 --> Loss 0.00401164929072\n",
      "Epoch 1::Minibatch 562::LR 0.1 --> Loss 0.00318890611331\n",
      "Epoch 1::Minibatch 563::LR 0.1 --> Loss 0.00459013938904\n",
      "Epoch 1::Minibatch 564::LR 0.1 --> Loss 0.00389082709948\n",
      "Epoch 1::Minibatch 565::LR 0.1 --> Loss 0.00488692363103\n",
      "Epoch 1::Minibatch 566::LR 0.1 --> Loss 0.00330266316732\n",
      "Epoch 1::Minibatch 567::LR 0.1 --> Loss 0.00383030255636\n",
      "Epoch 1::Minibatch 568::LR 0.1 --> Loss 0.00271205385526\n",
      "Epoch 1::Minibatch 569::LR 0.1 --> Loss 0.00144190212091\n",
      "Epoch 1::Minibatch 570::LR 0.1 --> Loss 0.00279235780239\n",
      "Epoch 1::Minibatch 571::LR 0.1 --> Loss 0.003359263738\n",
      "Epoch 1::Minibatch 572::LR 0.1 --> Loss 0.00329961299896\n",
      "Epoch 1::Minibatch 573::LR 0.1 --> Loss 0.00226064304511\n",
      "Epoch 1::Minibatch 574::LR 0.1 --> Loss 0.00166069895029\n",
      "Epoch 1::Minibatch 575::LR 0.1 --> Loss 0.00261927624544\n",
      "Epoch 1::Minibatch 576::LR 0.1 --> Loss 0.00314521888892\n",
      "Epoch 1::Minibatch 577::LR 0.1 --> Loss 0.00241809666157\n",
      "Epoch 1::Minibatch 578::LR 0.1 --> Loss 0.00181938052177\n",
      "Epoch 1::Minibatch 579::LR 0.1 --> Loss 0.00171718776226\n",
      "Epoch 1::Minibatch 580::LR 0.1 --> Loss 0.00276122411092\n",
      "Epoch 1::Minibatch 581::LR 0.1 --> Loss 0.00244771699111\n",
      "Epoch 1::Minibatch 582::LR 0.1 --> Loss 0.00613294323285\n",
      "Epoch 1::Minibatch 583::LR 0.1 --> Loss 0.00157885700464\n",
      "Epoch 1::Minibatch 584::LR 0.1 --> Loss 0.00197577118874\n",
      "Epoch 1::Minibatch 585::LR 0.1 --> Loss 0.00832453966141\n",
      "Epoch 1::Minibatch 586::LR 0.1 --> Loss 0.00562065402667\n",
      "Epoch 1::Minibatch 587::LR 0.1 --> Loss 0.00173541704814\n",
      "Epoch 1::Minibatch 588::LR 0.1 --> Loss 0.00204253335794\n",
      "Epoch 1::Minibatch 589::LR 0.1 --> Loss 0.00346485535304\n",
      "Epoch 1::Minibatch 590::LR 0.1 --> Loss 0.00314670205116\n",
      "Epoch 1::Minibatch 591::LR 0.1 --> Loss 0.00950036843618\n",
      "Epoch 1::Minibatch 592::LR 0.1 --> Loss 0.00196315010389\n",
      "Epoch 1::Minibatch 593::LR 0.1 --> Loss 0.00400498747826\n",
      "Epoch 1::Minibatch 594::LR 0.1 --> Loss 0.00418580333392\n",
      "Epoch 1::Minibatch 595::LR 0.1 --> Loss 0.00377329985301\n",
      "Epoch 1::Minibatch 596::LR 0.1 --> Loss 0.00324146250884\n",
      "Epoch 1::Minibatch 597::LR 0.1 --> Loss 0.00227895398935\n",
      "Epoch 1::Minibatch 598::LR 0.1 --> Loss 0.00489718953768\n",
      "Epoch 1::Minibatch 599::LR 0.1 --> Loss 0.0028252997001\n",
      "Epoch 1::Minibatch 600::LR 0.1 --> Loss 0.00331091463566\n",
      "Epoch 1::Minibatch 601::LR 0.1 --> Loss 0.00405798872312\n",
      "Epoch 1::Minibatch 602::LR 0.1 --> Loss 0.00256160239379\n",
      "Epoch 1::Minibatch 603::LR 0.1 --> Loss 0.00367152651151\n",
      "Epoch 1::Minibatch 604::LR 0.1 --> Loss 0.00257119357586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 605::LR 0.1 --> Loss 0.0034381433328\n",
      "Epoch 1::Minibatch 606::LR 0.1 --> Loss 0.00284056822459\n",
      "Epoch 1::Minibatch 607::LR 0.1 --> Loss 0.00166408052047\n",
      "Epoch 1::Minibatch 608::LR 0.1 --> Loss 0.00272794683774\n",
      "Epoch 1::Minibatch 609::LR 0.1 --> Loss 0.00303084552288\n",
      "Epoch 1::Minibatch 610::LR 0.1 --> Loss 0.00405449668566\n",
      "Epoch 1::Minibatch 611::LR 0.1 --> Loss 0.00313544631004\n",
      "Epoch 1::Minibatch 612::LR 0.1 --> Loss 0.00137994468212\n",
      "Epoch 1::Minibatch 613::LR 0.1 --> Loss 0.00213009337584\n",
      "Epoch 1::Minibatch 614::LR 0.1 --> Loss 0.00278540511926\n",
      "Epoch 1::Minibatch 615::LR 0.1 --> Loss 0.00249477982521\n",
      "Epoch 1::Minibatch 616::LR 0.1 --> Loss 0.00175677478313\n",
      "Epoch 1::Minibatch 617::LR 0.1 --> Loss 0.00135199119647\n",
      "Epoch 1::Minibatch 618::LR 0.1 --> Loss 0.00305530210336\n",
      "Epoch 1::Minibatch 619::LR 0.1 --> Loss 0.00258580764135\n",
      "Epoch 1::Minibatch 620::LR 0.1 --> Loss 0.00239461123943\n",
      "Epoch 1::Minibatch 621::LR 0.1 --> Loss 0.00155816574891\n",
      "Epoch 1::Minibatch 622::LR 0.1 --> Loss 0.00159609069427\n",
      "Epoch 1::Minibatch 623::LR 0.1 --> Loss 0.00277329981327\n",
      "Epoch 1::Minibatch 624::LR 0.1 --> Loss 0.00211155196031\n",
      "Epoch 1::Minibatch 625::LR 0.1 --> Loss 0.00467031002045\n",
      "Epoch 1::Minibatch 626::LR 0.1 --> Loss 0.00785153230031\n",
      "Epoch 1::Minibatch 627::LR 0.1 --> Loss 0.00221880336603\n",
      "Epoch 1::Minibatch 628::LR 0.1 --> Loss 0.00162190248569\n",
      "Epoch 1::Minibatch 629::LR 0.1 --> Loss 0.00444971283277\n",
      "Epoch 1::Minibatch 630::LR 0.1 --> Loss 0.00448896805445\n",
      "Epoch 1::Minibatch 631::LR 0.1 --> Loss 0.00568616946538\n",
      "Epoch 1::Minibatch 632::LR 0.1 --> Loss 0.00159582267205\n",
      "Epoch 1::Minibatch 633::LR 0.1 --> Loss 0.00250250458717\n",
      "Epoch 1::Minibatch 634::LR 0.1 --> Loss 0.00393594344457\n",
      "Epoch 1::Minibatch 635::LR 0.1 --> Loss 0.00496016422908\n",
      "Epoch 1::Minibatch 636::LR 0.1 --> Loss 0.0304355812073\n",
      "Epoch 1::Minibatch 637::LR 0.1 --> Loss 0.00201139946779\n",
      "Epoch 1::Minibatch 638::LR 0.1 --> Loss 0.00271382153034\n",
      "Epoch 1::Minibatch 639::LR 0.1 --> Loss 0.00436358213425\n",
      "Epoch 1::Minibatch 640::LR 0.1 --> Loss 0.0305626837413\n",
      "Epoch 1::Minibatch 641::LR 0.1 --> Loss 0.00424014806747\n",
      "Epoch 1::Minibatch 642::LR 0.1 --> Loss 0.00147305428982\n",
      "Epoch 1::Minibatch 643::LR 0.1 --> Loss 0.00335938811302\n",
      "Epoch 1::Minibatch 644::LR 0.1 --> Loss 0.00491571585337\n",
      "Epoch 1::Minibatch 645::LR 0.1 --> Loss 0.0114644662539\n",
      "Epoch 1::Minibatch 646::LR 0.1 --> Loss 0.00282438536485\n",
      "Epoch 1::Minibatch 647::LR 0.1 --> Loss 0.0018153878053\n",
      "Epoch 1::Minibatch 648::LR 0.1 --> Loss 0.0045771698157\n",
      "Epoch 1::Minibatch 649::LR 0.1 --> Loss 0.00490284403165\n",
      "Epoch 1::Minibatch 650::LR 0.1 --> Loss 0.00478150089582\n",
      "Epoch 1::Minibatch 651::LR 0.1 --> Loss 0.00265462398529\n",
      "Epoch 1::Minibatch 652::LR 0.1 --> Loss 0.00197956641515\n",
      "Epoch 1::Minibatch 653::LR 0.1 --> Loss 0.00415092309316\n",
      "Epoch 1::Minibatch 654::LR 0.1 --> Loss 0.00397940357526\n",
      "Epoch 1::Minibatch 655::LR 0.1 --> Loss 0.0045162832737\n",
      "Epoch 1::Minibatch 656::LR 0.1 --> Loss 0.00166697065036\n",
      "Epoch 1::Minibatch 657::LR 0.1 --> Loss 0.00281233688196\n",
      "Epoch 1::Minibatch 658::LR 0.1 --> Loss 0.00489385724068\n",
      "Epoch 1::Minibatch 659::LR 0.1 --> Loss 0.00331641495228\n",
      "Epoch 1::Minibatch 660::LR 0.1 --> Loss 0.0031626834472\n",
      "Epoch 1::Minibatch 661::LR 0.1 --> Loss 0.00352609356244\n",
      "Epoch 1::Minibatch 662::LR 0.1 --> Loss 0.0028440507253\n",
      "Epoch 1::Minibatch 663::LR 0.1 --> Loss 0.00490906238556\n",
      "Epoch 1::Minibatch 664::LR 0.1 --> Loss 0.00458202759425\n",
      "Epoch 1::Minibatch 665::LR 0.1 --> Loss 0.0016337198019\n",
      "Epoch 1::Minibatch 666::LR 0.1 --> Loss 0.00433276812236\n",
      "Epoch 1::Minibatch 667::LR 0.1 --> Loss 0.00343960046768\n",
      "Epoch 1::Minibatch 668::LR 0.1 --> Loss 0.0115229392052\n",
      "Epoch 1::Minibatch 669::LR 0.1 --> Loss 0.00200771252314\n",
      "Epoch 1::Minibatch 670::LR 0.1 --> Loss 0.0022169059515\n",
      "Epoch 1::Minibatch 671::LR 0.1 --> Loss 0.00726827144623\n",
      "Epoch 1::Minibatch 672::LR 0.1 --> Loss 0.00552536090215\n",
      "Epoch 1::Minibatch 673::LR 0.1 --> Loss 0.00267817417781\n",
      "Epoch 1::Minibatch 674::LR 0.1 --> Loss 0.00147987057765\n",
      "Epoch 1::Minibatch 675::LR 0.1 --> Loss 0.00313463469346\n",
      "Epoch 1::Minibatch 676::LR 0.1 --> Loss 0.00353383898735\n",
      "Epoch 1::Minibatch 677::LR 0.1 --> Loss 0.0041118768851\n",
      "Epoch 1::Minibatch 678::LR 0.1 --> Loss 0.00286755998929\n",
      "Epoch 1::Minibatch 679::LR 0.1 --> Loss 0.00467222770055\n",
      "Epoch 1::Minibatch 680::LR 0.1 --> Loss 0.0028399882714\n",
      "Epoch 1::Minibatch 681::LR 0.1 --> Loss 0.00326391220093\n",
      "Epoch 1::Minibatch 682::LR 0.1 --> Loss 0.00151442050934\n",
      "Epoch 1::Minibatch 683::LR 0.1 --> Loss 0.00353027145068\n",
      "Epoch 1::Minibatch 684::LR 0.1 --> Loss 0.00314556876818\n",
      "Epoch 1::Minibatch 685::LR 0.1 --> Loss 0.00383291482925\n",
      "Epoch 1::Minibatch 686::LR 0.1 --> Loss 0.00221722960472\n",
      "Epoch 1::Minibatch 687::LR 0.1 --> Loss 0.00151754945517\n",
      "Epoch 1::Minibatch 688::LR 0.1 --> Loss 0.00320667545001\n",
      "Epoch 1::Minibatch 689::LR 0.1 --> Loss 0.00320287923018\n",
      "Epoch 1::Minibatch 690::LR 0.1 --> Loss 0.00267654240131\n",
      "Epoch 1::Minibatch 691::LR 0.1 --> Loss 0.00122321923574\n",
      "Epoch 1::Minibatch 692::LR 0.1 --> Loss 0.00332236468792\n",
      "Epoch 1::Minibatch 693::LR 0.1 --> Loss 0.00319004913171\n",
      "Epoch 1::Minibatch 694::LR 0.1 --> Loss 0.00366423169772\n",
      "Epoch 1::Minibatch 695::LR 0.1 --> Loss 0.00253317197164\n",
      "Epoch 1::Minibatch 696::LR 0.1 --> Loss 0.0026088488102\n",
      "Epoch 1::Minibatch 697::LR 0.1 --> Loss 0.00207361837228\n",
      "Epoch 1::Minibatch 698::LR 0.1 --> Loss 0.00222934623559\n",
      "Epoch 1::Minibatch 699::LR 0.1 --> Loss 0.00452499469121\n",
      "Epoch 1::Minibatch 700::LR 0.1 --> Loss 0.00365545392036\n",
      "Epoch 1::Minibatch 701::LR 0.1 --> Loss 0.00272795935472\n",
      "Epoch 1::Minibatch 702::LR 0.1 --> Loss 0.00234072844187\n",
      "Epoch 1::Minibatch 703::LR 0.1 --> Loss 0.004067902565\n",
      "Epoch 1::Minibatch 704::LR 0.1 --> Loss 0.00248867074649\n",
      "Epoch 1::Minibatch 705::LR 0.1 --> Loss 0.00342275182406\n",
      "Epoch 1::Minibatch 706::LR 0.1 --> Loss 0.00262506802877\n",
      "Epoch 1::Minibatch 707::LR 0.1 --> Loss 0.0019187639157\n",
      "Epoch 1::Minibatch 708::LR 0.1 --> Loss 0.00247612655163\n",
      "Epoch 1::Minibatch 709::LR 0.1 --> Loss 0.00228058516979\n",
      "Epoch 1::Minibatch 710::LR 0.1 --> Loss 0.00300592501958\n",
      "Epoch 1::Minibatch 711::LR 0.1 --> Loss 0.00232529977957\n",
      "Epoch 1::Minibatch 712::LR 0.1 --> Loss 0.00196786324183\n",
      "Epoch 1::Minibatch 713::LR 0.1 --> Loss 0.00219187736511\n",
      "Epoch 1::Minibatch 714::LR 0.1 --> Loss 0.00314197977384\n",
      "Epoch 1::Minibatch 715::LR 0.1 --> Loss 0.00345984896024\n",
      "Epoch 1::Minibatch 716::LR 0.1 --> Loss 0.0020564643542\n",
      "Epoch 1::Minibatch 717::LR 0.1 --> Loss 0.00201756020387\n",
      "Epoch 1::Minibatch 718::LR 0.1 --> Loss 0.0017760938406\n",
      "Epoch 1::Minibatch 719::LR 0.1 --> Loss 0.00230933010578\n",
      "Epoch 1::Minibatch 720::LR 0.1 --> Loss 0.00270461042722\n",
      "Epoch 1::Minibatch 721::LR 0.1 --> Loss 0.00128768960635\n",
      "Epoch 1::Minibatch 722::LR 0.1 --> Loss 0.00741712252299\n",
      "Epoch 1::Minibatch 723::LR 0.1 --> Loss 0.00551392952601\n",
      "Epoch 1::Minibatch 724::LR 0.1 --> Loss 0.00156284689903\n",
      "Epoch 1::Minibatch 725::LR 0.1 --> Loss 0.00391333699226\n",
      "Epoch 1::Minibatch 726::LR 0.1 --> Loss 0.00860877275467\n",
      "Epoch 1::Minibatch 727::LR 0.1 --> Loss 0.00331913212935\n",
      "Epoch 1::Minibatch 728::LR 0.1 --> Loss 0.00139512459437\n",
      "Epoch 1::Minibatch 729::LR 0.1 --> Loss 0.00153646548589\n",
      "Epoch 1::Minibatch 730::LR 0.1 --> Loss 0.00319680929184\n",
      "Epoch 1::Minibatch 731::LR 0.1 --> Loss 0.00299493332704\n",
      "Epoch 1::Minibatch 732::LR 0.1 --> Loss 0.00315170268218\n",
      "Epoch 1::Minibatch 733::LR 0.1 --> Loss 0.0014938506484\n",
      "Epoch 1::Minibatch 734::LR 0.1 --> Loss 0.00255731980006\n",
      "Epoch 1::Minibatch 735::LR 0.1 --> Loss 0.00292604247729\n",
      "Epoch 1::Minibatch 736::LR 0.1 --> Loss 0.00358929753304\n",
      "Epoch 1::Minibatch 737::LR 0.1 --> Loss 0.00349278569221\n",
      "Epoch 1::Minibatch 738::LR 0.1 --> Loss 0.00229016323884\n",
      "Epoch 1::Minibatch 739::LR 0.1 --> Loss 0.00320974787076\n",
      "Epoch 1::Minibatch 740::LR 0.1 --> Loss 0.00450483242671\n",
      "Epoch 1::Minibatch 741::LR 0.1 --> Loss 0.00347189704577\n",
      "Epoch 1::Minibatch 742::LR 0.1 --> Loss 0.00264582951864\n",
      "Epoch 1::Minibatch 743::LR 0.1 --> Loss 0.00155553102493\n",
      "Epoch 1::Minibatch 744::LR 0.1 --> Loss 0.0023868393898\n",
      "Epoch 1::Minibatch 745::LR 0.1 --> Loss 0.00346666495005\n",
      "Epoch 1::Minibatch 746::LR 0.1 --> Loss 0.00378813783328\n",
      "Epoch 1::Minibatch 747::LR 0.1 --> Loss 0.00225115895271\n",
      "Epoch 1::Minibatch 748::LR 0.1 --> Loss 0.00123668223619\n",
      "Epoch 1::Minibatch 749::LR 0.1 --> Loss 0.00221983671188\n",
      "Epoch 1::Minibatch 750::LR 0.1 --> Loss 0.00329486767451\n",
      "Epoch 1::Minibatch 751::LR 0.1 --> Loss 0.00298070629438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 752::LR 0.1 --> Loss 0.00135800302029\n",
      "Epoch 1::Minibatch 753::LR 0.1 --> Loss 0.0025887042284\n",
      "Epoch 1::Minibatch 754::LR 0.1 --> Loss 0.00275073587894\n",
      "Epoch 1::Minibatch 755::LR 0.1 --> Loss 0.00334919611613\n",
      "Epoch 1::Minibatch 756::LR 0.1 --> Loss 0.00187962889671\n",
      "Epoch 1::Minibatch 757::LR 0.1 --> Loss 0.00138959805171\n",
      "Epoch 1::Minibatch 758::LR 0.1 --> Loss 0.00212548394998\n",
      "Epoch 1::Minibatch 759::LR 0.1 --> Loss 0.00452915112178\n",
      "Epoch 1::Minibatch 760::LR 0.1 --> Loss 0.00422606110573\n",
      "Epoch 1::Minibatch 761::LR 0.1 --> Loss 0.00863258759181\n",
      "Epoch 1::Minibatch 762::LR 0.1 --> Loss 0.00481177488963\n",
      "Epoch 1::Minibatch 763::LR 0.1 --> Loss 0.0052247039477\n",
      "Epoch 1::Minibatch 764::LR 0.1 --> Loss 0.00405253767967\n",
      "Epoch 1::Minibatch 765::LR 0.1 --> Loss 0.00195664803187\n",
      "Epoch 1::Minibatch 766::LR 0.1 --> Loss 0.0028740298748\n",
      "Epoch 1::Minibatch 767::LR 0.1 --> Loss 0.00522850513458\n",
      "Epoch 1::Minibatch 768::LR 0.1 --> Loss 0.00409492293994\n",
      "Epoch 1::Minibatch 769::LR 0.1 --> Loss 0.00266960163911\n",
      "Epoch 1::Minibatch 770::LR 0.1 --> Loss 0.00194048126539\n",
      "Epoch 1::Minibatch 771::LR 0.1 --> Loss 0.00521023909251\n",
      "Epoch 1::Minibatch 772::LR 0.1 --> Loss 0.00362362623215\n",
      "Epoch 1::Minibatch 773::LR 0.1 --> Loss 0.00363378683726\n",
      "Epoch 1::Minibatch 774::LR 0.1 --> Loss 0.0022421447436\n",
      "Epoch 1::Minibatch 775::LR 0.1 --> Loss 0.0101781511307\n",
      "Epoch 1::Minibatch 776::LR 0.1 --> Loss 0.0044995756944\n",
      "Epoch 1::Minibatch 777::LR 0.1 --> Loss 0.00709212144216\n",
      "Epoch 1::Minibatch 778::LR 0.1 --> Loss 0.0158842277527\n",
      "Epoch 1::Minibatch 779::LR 0.1 --> Loss 0.00172993540764\n",
      "Epoch 1::Minibatch 780::LR 0.1 --> Loss 0.00229171872139\n",
      "Epoch 1::Minibatch 781::LR 0.1 --> Loss 0.00425431370735\n",
      "Epoch 1::Minibatch 782::LR 0.1 --> Loss 0.00489334662755\n",
      "Epoch 1::Minibatch 783::LR 0.1 --> Loss 0.00339278618495\n",
      "Epoch 1::Minibatch 784::LR 0.1 --> Loss 0.00143348246813\n",
      "Epoch 1::Minibatch 785::LR 0.1 --> Loss 0.00551197926203\n",
      "Epoch 1::Minibatch 786::LR 0.1 --> Loss 0.00451349258423\n",
      "Epoch 1::Minibatch 787::LR 0.1 --> Loss 0.00358123024305\n",
      "Epoch 1::Minibatch 788::LR 0.1 --> Loss 0.00332909921805\n",
      "Epoch 1::Minibatch 789::LR 0.1 --> Loss 0.00126022855441\n",
      "Epoch 1::Minibatch 790::LR 0.1 --> Loss 0.0043067530791\n",
      "Epoch 1::Minibatch 791::LR 0.1 --> Loss 0.00481185913086\n",
      "Epoch 1::Minibatch 792::LR 0.1 --> Loss 0.00485675374667\n",
      "Epoch 1::Minibatch 793::LR 0.1 --> Loss 0.00296920617421\n",
      "Epoch 1::Minibatch 794::LR 0.1 --> Loss 0.00203615446885\n",
      "Epoch 1::Minibatch 795::LR 0.1 --> Loss 0.00508801460266\n",
      "Epoch 1::Minibatch 796::LR 0.1 --> Loss 0.00756055752436\n",
      "Epoch 1::Minibatch 797::LR 0.1 --> Loss 0.0177600495021\n",
      "Epoch 1::Minibatch 798::LR 0.1 --> Loss 0.00385828614235\n",
      "Epoch 1::Minibatch 799::LR 0.1 --> Loss 0.00368917783101\n",
      "Epoch 1::Minibatch 800::LR 0.1 --> Loss 0.00289395272732\n",
      "Epoch 1::Minibatch 801::LR 0.1 --> Loss 0.00486819028854\n",
      "Epoch 1::Minibatch 802::LR 0.1 --> Loss 0.00241014738878\n",
      "Epoch 1::Minibatch 803::LR 0.1 --> Loss 0.00381740689278\n",
      "Epoch 1::Minibatch 804::LR 0.1 --> Loss 0.00333043913047\n",
      "Epoch 1::Minibatch 805::LR 0.1 --> Loss 0.00326680819194\n",
      "Epoch 1::Minibatch 806::LR 0.1 --> Loss 0.00418754140536\n",
      "Epoch 1::Minibatch 807::LR 0.1 --> Loss 0.00406913797061\n",
      "Epoch 1::Minibatch 808::LR 0.1 --> Loss 0.00397175908089\n",
      "Epoch 1::Minibatch 809::LR 0.1 --> Loss 0.00601875623067\n",
      "Epoch 1::Minibatch 810::LR 0.1 --> Loss 0.00853148539861\n",
      "Epoch 1::Minibatch 811::LR 0.1 --> Loss 0.00672351996104\n",
      "Epoch 1::Minibatch 812::LR 0.1 --> Loss 0.00724726756414\n",
      "Epoch 1::Minibatch 813::LR 0.1 --> Loss 0.00590255578359\n",
      "Epoch 1::Minibatch 814::LR 0.1 --> Loss 0.00382847706477\n",
      "Epoch 1::Minibatch 815::LR 0.1 --> Loss 0.00574644009272\n",
      "Epoch 1::Minibatch 816::LR 0.1 --> Loss 0.00534467379252\n",
      "Epoch 1::Minibatch 817::LR 0.1 --> Loss 0.00513959884644\n",
      "Epoch 1::Minibatch 818::LR 0.1 --> Loss 0.00237735549609\n",
      "Epoch 1::Minibatch 819::LR 0.1 --> Loss 0.00148879736662\n",
      "Epoch 1::Minibatch 820::LR 0.1 --> Loss 0.00641789476077\n",
      "Epoch 1::Minibatch 821::LR 0.1 --> Loss 0.00405109723409\n",
      "Epoch 1::Minibatch 822::LR 0.1 --> Loss 0.00487189888954\n",
      "Epoch 1::Minibatch 823::LR 0.1 --> Loss 0.00211867928505\n",
      "Epoch 1::Minibatch 824::LR 0.1 --> Loss 0.00220540344715\n",
      "Epoch 1::Minibatch 825::LR 0.1 --> Loss 0.00450744748116\n",
      "Epoch 1::Minibatch 826::LR 0.1 --> Loss 0.00415808200836\n",
      "Epoch 1::Minibatch 827::LR 0.1 --> Loss 0.00296753247579\n",
      "Epoch 1::Minibatch 828::LR 0.1 --> Loss 0.00133100976547\n",
      "Epoch 1::Minibatch 829::LR 0.1 --> Loss 0.00317244529724\n",
      "Epoch 1::Minibatch 830::LR 0.1 --> Loss 0.00539630373319\n",
      "Epoch 1::Minibatch 831::LR 0.1 --> Loss 0.00331001897653\n",
      "Epoch 1::Minibatch 832::LR 0.1 --> Loss 0.00319799721241\n",
      "Epoch 1::Minibatch 833::LR 0.1 --> Loss 0.00250115235647\n",
      "Epoch 1::Minibatch 834::LR 0.1 --> Loss 0.00132860491673\n",
      "Epoch 1::Minibatch 835::LR 0.1 --> Loss 0.00454178333282\n",
      "Epoch 1::Minibatch 836::LR 0.1 --> Loss 0.0043875904878\n",
      "Epoch 1::Minibatch 837::LR 0.1 --> Loss 0.00327510794004\n",
      "Epoch 1::Minibatch 838::LR 0.1 --> Loss 0.00156531771024\n",
      "Epoch 1::Minibatch 839::LR 0.1 --> Loss 0.00301424145699\n",
      "Epoch 1::Minibatch 840::LR 0.1 --> Loss 0.00385457277298\n",
      "Epoch 1::Minibatch 841::LR 0.1 --> Loss 0.00382011810939\n",
      "Epoch 1::Minibatch 842::LR 0.1 --> Loss 0.00304053564866\n",
      "Epoch 1::Minibatch 843::LR 0.1 --> Loss 0.0014977195859\n",
      "Epoch 1::Minibatch 844::LR 0.1 --> Loss 0.00232881367207\n",
      "Epoch 1::Minibatch 845::LR 0.1 --> Loss 0.0044537738959\n",
      "Epoch 1::Minibatch 846::LR 0.1 --> Loss 0.00230114758015\n",
      "Epoch 1::Minibatch 847::LR 0.1 --> Loss 0.00303688267867\n",
      "Epoch 1::Minibatch 848::LR 0.1 --> Loss 0.00168544173241\n",
      "Epoch 1::Minibatch 849::LR 0.1 --> Loss 0.00253134230773\n",
      "Epoch 1::Minibatch 850::LR 0.1 --> Loss 0.00356366197268\n",
      "Epoch 1::Minibatch 851::LR 0.1 --> Loss 0.0035891854763\n",
      "Epoch 1::Minibatch 852::LR 0.1 --> Loss 0.00157910714547\n",
      "Epoch 1::Minibatch 853::LR 0.1 --> Loss 0.0016248841087\n",
      "Epoch 1::Minibatch 854::LR 0.1 --> Loss 0.00286156992118\n",
      "Epoch 1::Minibatch 855::LR 0.1 --> Loss 0.00267898102601\n",
      "Epoch 1::Minibatch 856::LR 0.1 --> Loss 0.00239199519157\n",
      "Epoch 1::Minibatch 857::LR 0.1 --> Loss 0.00178196867307\n",
      "Epoch 1::Minibatch 858::LR 0.1 --> Loss 0.00107660114765\n",
      "Epoch 1::Minibatch 859::LR 0.1 --> Loss 0.00228558202585\n",
      "Epoch 1::Minibatch 860::LR 0.1 --> Loss 0.00153520127138\n",
      "Epoch 1::Minibatch 861::LR 0.1 --> Loss 0.00121474057436\n",
      "Epoch 1::Minibatch 862::LR 0.1 --> Loss 0.00495182355245\n",
      "Epoch 1::Minibatch 863::LR 0.1 --> Loss 0.00383964061737\n",
      "Epoch 1::Minibatch 864::LR 0.1 --> Loss 0.00331721822421\n",
      "Epoch 1::Minibatch 865::LR 0.1 --> Loss 0.000986813704173\n",
      "Epoch 1::Minibatch 866::LR 0.1 --> Loss 0.00273084084193\n",
      "Epoch 1::Minibatch 867::LR 0.1 --> Loss 0.00319192389647\n",
      "Epoch 1::Minibatch 868::LR 0.1 --> Loss 0.00279319743315\n",
      "Epoch 1::Minibatch 869::LR 0.1 --> Loss 0.00258289674918\n",
      "Epoch 1::Minibatch 870::LR 0.1 --> Loss 0.00430466214816\n",
      "Epoch 1::Minibatch 871::LR 0.1 --> Loss 0.00194804529349\n",
      "Epoch 1::Minibatch 872::LR 0.1 --> Loss 0.00321378926436\n",
      "Epoch 1::Minibatch 873::LR 0.1 --> Loss 0.00274229645729\n",
      "Epoch 1::Minibatch 874::LR 0.1 --> Loss 0.00689790487289\n",
      "Epoch 1::Minibatch 875::LR 0.1 --> Loss 0.000895040730635\n",
      "Epoch 1::Minibatch 876::LR 0.1 --> Loss 0.0072514017423\n",
      "Epoch 1::Minibatch 877::LR 0.1 --> Loss 0.0201075792313\n",
      "Epoch 1::Minibatch 878::LR 0.1 --> Loss 0.00505121350288\n",
      "Epoch 1::Minibatch 879::LR 0.1 --> Loss 0.00534136851629\n",
      "Epoch 1::Minibatch 880::LR 0.1 --> Loss 0.00564133365949\n",
      "Epoch 1::Minibatch 881::LR 0.1 --> Loss 0.00488352139791\n",
      "Epoch 1::Minibatch 882::LR 0.1 --> Loss 0.00292380233606\n",
      "Epoch 1::Minibatch 883::LR 0.1 --> Loss 0.00396805604299\n",
      "Epoch 1::Minibatch 884::LR 0.1 --> Loss 0.00330956836541\n",
      "Epoch 1::Minibatch 885::LR 0.1 --> Loss 0.00388405442238\n",
      "Epoch 1::Minibatch 886::LR 0.1 --> Loss 0.00252635379632\n",
      "Epoch 1::Minibatch 887::LR 0.1 --> Loss 0.00744340976079\n",
      "Epoch 1::Minibatch 888::LR 0.1 --> Loss 0.00334935983022\n",
      "Epoch 1::Minibatch 889::LR 0.1 --> Loss 0.00559395432472\n",
      "Epoch 1::Minibatch 890::LR 0.1 --> Loss 0.00732797861099\n",
      "Epoch 1::Minibatch 891::LR 0.1 --> Loss 0.00371489961942\n",
      "Epoch 1::Minibatch 892::LR 0.1 --> Loss 0.00209428946177\n",
      "Epoch 1::Minibatch 893::LR 0.1 --> Loss 0.003785572052\n",
      "Epoch 1::Minibatch 894::LR 0.1 --> Loss 0.00391183296839\n",
      "Epoch 1::Minibatch 895::LR 0.1 --> Loss 0.00369303743045\n",
      "Epoch 1::Minibatch 896::LR 0.1 --> Loss 0.00298638681571\n",
      "Epoch 1::Minibatch 897::LR 0.1 --> Loss 0.00174849351247\n",
      "Epoch 1::Minibatch 898::LR 0.1 --> Loss 0.00350185672442\n",
      "Epoch 1::Minibatch 899::LR 0.1 --> Loss 0.00345828652382\n",
      "Epoch 1::Minibatch 900::LR 0.1 --> Loss 0.0048569158713\n",
      "Epoch 1::Minibatch 901::LR 0.1 --> Loss 0.00138441960017\n",
      "Epoch 1::Minibatch 902::LR 0.1 --> Loss 0.0021619250377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 903::LR 0.1 --> Loss 0.00394530375799\n",
      "Epoch 1::Minibatch 904::LR 0.1 --> Loss 0.00377851963043\n",
      "Epoch 1::Minibatch 905::LR 0.1 --> Loss 0.00203743914763\n",
      "Epoch 1::Minibatch 906::LR 0.1 --> Loss 0.00150363663832\n",
      "Epoch 1::Minibatch 907::LR 0.1 --> Loss 0.00176962057749\n",
      "Epoch 1::Minibatch 908::LR 0.1 --> Loss 0.00388890067736\n",
      "Epoch 1::Minibatch 909::LR 0.1 --> Loss 0.00418912728628\n",
      "Epoch 1::Minibatch 910::LR 0.1 --> Loss 0.00140459309022\n",
      "Epoch 1::Minibatch 911::LR 0.1 --> Loss 0.00180480698744\n",
      "Epoch 1::Minibatch 912::LR 0.1 --> Loss 0.00353364109993\n",
      "Epoch 1::Minibatch 913::LR 0.1 --> Loss 0.0029579770565\n",
      "Epoch 1::Minibatch 914::LR 0.1 --> Loss 0.00210151394208\n",
      "Epoch 1::Minibatch 915::LR 0.1 --> Loss 0.00094884912173\n",
      "Epoch 1::Minibatch 916::LR 0.1 --> Loss 0.00490268826485\n",
      "Epoch 1::Minibatch 917::LR 0.1 --> Loss 0.00600292166074\n",
      "Epoch 1::Minibatch 918::LR 0.1 --> Loss 0.00990268786748\n",
      "Epoch 1::Minibatch 919::LR 0.1 --> Loss 0.00275502840678\n",
      "Epoch 1::Minibatch 920::LR 0.1 --> Loss 0.0101026813189\n",
      "Epoch 1::Minibatch 921::LR 0.1 --> Loss 0.00518888394038\n",
      "Epoch 1::Minibatch 922::LR 0.1 --> Loss 0.00506120324135\n",
      "Epoch 1::Minibatch 923::LR 0.1 --> Loss 0.00344224214554\n",
      "Epoch 1::Minibatch 924::LR 0.1 --> Loss 0.00543585975965\n",
      "Epoch 1::Minibatch 925::LR 0.1 --> Loss 0.00545812050502\n",
      "Epoch 1::Minibatch 926::LR 0.1 --> Loss 0.00824748675028\n",
      "Epoch 1::Minibatch 927::LR 0.1 --> Loss 0.0244173908234\n",
      "Epoch 1::Minibatch 928::LR 0.1 --> Loss 0.0113585837682\n",
      "Epoch 1::Minibatch 929::LR 0.1 --> Loss 0.0152701155345\n",
      "Epoch 1::Minibatch 930::LR 0.1 --> Loss 0.00887796799342\n",
      "Epoch 1::Minibatch 931::LR 0.1 --> Loss 0.00681400458018\n",
      "Epoch 1::Minibatch 932::LR 0.1 --> Loss 0.0196708218257\n",
      "Epoch 1::Minibatch 933::LR 0.1 --> Loss 0.00867688258489\n",
      "Epoch 1::Minibatch 934::LR 0.1 --> Loss 0.011027516524\n",
      "Epoch 1::Minibatch 935::LR 0.1 --> Loss 0.0142013279597\n",
      "Epoch 1::Minibatch 936::LR 0.1 --> Loss 0.00611245115598\n",
      "Epoch 1::Minibatch 937::LR 0.1 --> Loss 0.00881527423859\n",
      "Epoch 1::Minibatch 938::LR 0.1 --> Loss 0.00889304637909\n",
      "Epoch 1::Minibatch 939::LR 0.1 --> Loss 0.00902610143026\n",
      "Epoch 1::Minibatch 940::LR 0.1 --> Loss 0.00278896351655\n",
      "Epoch 1::Minibatch 941::LR 0.1 --> Loss 0.00254866858323\n",
      "Epoch 1::Minibatch 942::LR 0.1 --> Loss 0.00392671267192\n",
      "Epoch 1::Minibatch 943::LR 0.1 --> Loss 0.00697239637375\n",
      "Epoch 1::Minibatch 944::LR 0.1 --> Loss 0.00624623417854\n",
      "Epoch 1::Minibatch 945::LR 0.1 --> Loss 0.00493500987689\n",
      "Epoch 1::Minibatch 946::LR 0.1 --> Loss 0.0082631889979\n",
      "Epoch 1::Minibatch 947::LR 0.1 --> Loss 0.00736282904943\n",
      "Epoch 1::Minibatch 948::LR 0.1 --> Loss 0.0102918187777\n",
      "Epoch 1::Minibatch 949::LR 0.1 --> Loss 0.00401069879532\n",
      "Epoch 1::Minibatch 950::LR 0.1 --> Loss 0.00157944858074\n",
      "Epoch 1::Minibatch 951::LR 0.1 --> Loss 0.00522560675939\n",
      "Epoch 1::Minibatch 952::LR 0.1 --> Loss 0.00445934335391\n",
      "Epoch 1::Minibatch 953::LR 0.1 --> Loss 0.00229846119881\n",
      "Epoch 1::Minibatch 954::LR 0.1 --> Loss 0.00181859989961\n",
      "Epoch 1::Minibatch 955::LR 0.1 --> Loss 0.00406403899193\n",
      "Epoch 1::Minibatch 956::LR 0.1 --> Loss 0.00865436236064\n",
      "Epoch 1::Minibatch 957::LR 0.1 --> Loss 0.00367335279783\n",
      "Epoch 1::Minibatch 958::LR 0.1 --> Loss 0.00621975779533\n",
      "Epoch 1::Minibatch 959::LR 0.1 --> Loss 0.00717489322027\n",
      "Epoch 1::Minibatch 960::LR 0.1 --> Loss 0.00925245841344\n",
      "Epoch 1::Minibatch 961::LR 0.1 --> Loss 0.00610058665276\n",
      "Epoch 1::Minibatch 962::LR 0.1 --> Loss 0.00539307951927\n",
      "Epoch 1::Minibatch 963::LR 0.1 --> Loss 0.00386313954989\n",
      "Epoch 1::Minibatch 964::LR 0.1 --> Loss 0.00589925249418\n",
      "Epoch 1::Minibatch 965::LR 0.1 --> Loss 0.0127569397291\n",
      "Epoch 1::Minibatch 966::LR 0.1 --> Loss 0.00754678805669\n",
      "Epoch 1::Minibatch 967::LR 0.1 --> Loss 0.00611900091171\n",
      "Epoch 1::Minibatch 968::LR 0.1 --> Loss 0.00585166096687\n",
      "Epoch 1::Minibatch 969::LR 0.1 --> Loss 0.0201027504603\n",
      "Epoch 1::Minibatch 970::LR 0.1 --> Loss 0.00987063487371\n",
      "Epoch 1::Minibatch 971::LR 0.1 --> Loss 0.00664633393288\n",
      "Epoch 1::Minibatch 972::LR 0.1 --> Loss 0.0244343185425\n",
      "Epoch 1::Minibatch 973::LR 0.1 --> Loss 0.0132112240791\n",
      "Epoch 1::Minibatch 974::LR 0.1 --> Loss 0.00844243129094\n",
      "Epoch 1::Minibatch 975::LR 0.1 --> Loss 0.00886536836624\n",
      "Epoch 1::Minibatch 976::LR 0.1 --> Loss 0.00776484171549\n",
      "Epoch 1::Minibatch 977::LR 0.1 --> Loss 0.00782671689987\n",
      "Epoch 1::Minibatch 978::LR 0.1 --> Loss 0.00790394067764\n",
      "Epoch 1::Minibatch 979::LR 0.1 --> Loss 0.00799324353536\n",
      "Epoch 1::Minibatch 980::LR 0.1 --> Loss 0.00696731885274\n",
      "Epoch 1::Minibatch 981::LR 0.1 --> Loss 0.00928599516551\n",
      "Epoch 1::Minibatch 982::LR 0.1 --> Loss 0.0394110075633\n",
      "Epoch 1::Minibatch 983::LR 0.1 --> Loss 0.00795181274414\n",
      "Epoch 1::Minibatch 984::LR 0.1 --> Loss 0.0119841321309\n",
      "Epoch 1::Minibatch 985::LR 0.1 --> Loss 0.0140262444814\n",
      "Epoch 1::Minibatch 986::LR 0.1 --> Loss 0.014674727122\n",
      "Epoch 1::Minibatch 987::LR 0.1 --> Loss 0.0156790939967\n",
      "Epoch 1::Minibatch 988::LR 0.1 --> Loss 0.0137957382202\n",
      "Epoch 1::Minibatch 989::LR 0.1 --> Loss 0.0131178100904\n",
      "Epoch 1::Minibatch 990::LR 0.1 --> Loss 0.0118727620443\n",
      "Epoch 1::Minibatch 991::LR 0.1 --> Loss 0.0110667705536\n",
      "Epoch 1::Minibatch 992::LR 0.1 --> Loss 0.0111584313711\n",
      "Epoch 1::Minibatch 993::LR 0.1 --> Loss 0.01335612456\n",
      "Epoch 1::Minibatch 994::LR 0.1 --> Loss 0.00990448872248\n",
      "Epoch 1::Minibatch 995::LR 0.1 --> Loss 0.00582631309827\n",
      "Epoch 1::Minibatch 996::LR 0.1 --> Loss 0.0194041554133\n",
      "Epoch 1::Minibatch 997::LR 0.1 --> Loss 0.0117972795169\n",
      "Epoch 1::Minibatch 998::LR 0.1 --> Loss 0.0116908748945\n",
      "Epoch 1::Minibatch 999::LR 0.1 --> Loss 0.00967582941055\n",
      "Epoch 1::Minibatch 1000::LR 0.1 --> Loss 0.011539422671\n",
      "Epoch 1::Minibatch 1001::LR 0.1 --> Loss 0.010632285277\n",
      "Epoch 1::Minibatch 1002::LR 0.1 --> Loss 0.0163748407364\n",
      "Epoch 1::Minibatch 1003::LR 0.1 --> Loss 0.0153409767151\n",
      "Epoch 1::Minibatch 1004::LR 0.1 --> Loss 0.00597102920214\n",
      "Epoch 1::Minibatch 1005::LR 0.1 --> Loss 0.0223007774353\n",
      "Epoch 1::Minibatch 1006::LR 0.1 --> Loss 0.0214513667425\n",
      "Epoch 1::Minibatch 1007::LR 0.1 --> Loss 0.0204036649068\n",
      "Epoch 1::Minibatch 1008::LR 0.1 --> Loss 0.00627333243688\n",
      "Epoch 1::Minibatch 1009::LR 0.1 --> Loss 0.022577996254\n",
      "Epoch 1::Minibatch 1010::LR 0.1 --> Loss 0.0209244171778\n",
      "Epoch 1::Minibatch 1011::LR 0.1 --> Loss 0.026753692627\n",
      "Epoch 1::Minibatch 1012::LR 0.1 --> Loss 0.0187190548579\n",
      "Epoch 1::Minibatch 1013::LR 0.1 --> Loss 0.0106887952487\n",
      "Epoch 1::Minibatch 1014::LR 0.1 --> Loss 0.0111887741089\n",
      "Epoch 1::Minibatch 1015::LR 0.1 --> Loss 0.00793586174647\n",
      "Epoch 1::Minibatch 1016::LR 0.1 --> Loss 0.0261773761113\n",
      "Epoch 1::Minibatch 1017::LR 0.1 --> Loss 0.00923759619395\n",
      "Epoch 1::Minibatch 1018::LR 0.1 --> Loss 0.010752398173\n",
      "Epoch 1::Minibatch 1019::LR 0.1 --> Loss 0.00990688006083\n",
      "Epoch 1::Minibatch 1020::LR 0.1 --> Loss 0.00933423598607\n",
      "Epoch 1::Minibatch 1021::LR 0.1 --> Loss 0.00888354539871\n",
      "Epoch 1::Minibatch 1022::LR 0.1 --> Loss 0.00795113325119\n",
      "Epoch 1::Minibatch 1023::LR 0.1 --> Loss 0.00711330413818\n",
      "Epoch 1::Minibatch 1024::LR 0.1 --> Loss 0.00679084142049\n",
      "Epoch 1::Minibatch 1025::LR 0.1 --> Loss 0.011467517217\n",
      "Epoch 1::Minibatch 1026::LR 0.1 --> Loss 0.0111244432131\n",
      "Epoch 1::Minibatch 1027::LR 0.1 --> Loss 0.0107377743721\n",
      "Epoch 1::Minibatch 1028::LR 0.1 --> Loss 0.00960560401281\n",
      "Epoch 1::Minibatch 1029::LR 0.1 --> Loss 0.00829692840576\n",
      "Epoch 1::Minibatch 1030::LR 0.1 --> Loss 0.00820464293162\n",
      "Epoch 1::Minibatch 1031::LR 0.1 --> Loss 0.00772334178289\n",
      "Epoch 1::Minibatch 1032::LR 0.1 --> Loss 0.00689565658569\n",
      "Epoch 1::Minibatch 1033::LR 0.1 --> Loss 0.00651968121529\n",
      "Epoch 1::Minibatch 1034::LR 0.1 --> Loss 0.00686300357183\n",
      "Epoch 1::Minibatch 1035::LR 0.1 --> Loss 0.00603119810422\n",
      "Epoch 1::Minibatch 1036::LR 0.1 --> Loss 0.00481136441231\n",
      "Epoch 1::Minibatch 1037::LR 0.1 --> Loss 0.00551313440005\n",
      "Epoch 1::Minibatch 1038::LR 0.1 --> Loss 0.00543848196665\n",
      "Epoch 1::Minibatch 1039::LR 0.1 --> Loss 0.00699462811152\n",
      "Epoch 1::Minibatch 1040::LR 0.1 --> Loss 0.00396243611972\n",
      "Epoch 1::Minibatch 1041::LR 0.1 --> Loss 0.00419694622358\n",
      "Epoch 2::Minibatch 1::LR 0.0976923076923 --> Loss 0.0298733901978\n",
      "Epoch 2::Minibatch 2::LR 0.0976923076923 --> Loss 0.0241717147827\n",
      "Epoch 2::Minibatch 3::LR 0.0976923076923 --> Loss 0.01554936409\n",
      "Epoch 2::Minibatch 4::LR 0.0976923076923 --> Loss 0.0186198314031\n",
      "Epoch 2::Minibatch 5::LR 0.0976923076923 --> Loss 0.0139488538106\n",
      "Epoch 2::Minibatch 6::LR 0.0976923076923 --> Loss 0.00489442030589\n",
      "Epoch 2::Minibatch 7::LR 0.0976923076923 --> Loss 0.014737127622\n",
      "Epoch 2::Minibatch 8::LR 0.0976923076923 --> Loss 0.0230761798223\n",
      "Epoch 2::Minibatch 9::LR 0.0976923076923 --> Loss 0.0162852191925\n",
      "Epoch 2::Minibatch 10::LR 0.0976923076923 --> Loss 0.00564431150754\n",
      "Epoch 2::Minibatch 11::LR 0.0976923076923 --> Loss 0.00748691320419\n",
      "Epoch 2::Minibatch 12::LR 0.0976923076923 --> Loss 0.0162899684906\n",
      "Epoch 2::Minibatch 13::LR 0.0976923076923 --> Loss 0.0143669382731\n",
      "Epoch 2::Minibatch 14::LR 0.0976923076923 --> Loss 0.0101861818631\n",
      "Epoch 2::Minibatch 15::LR 0.0976923076923 --> Loss 0.00508587797483\n",
      "Epoch 2::Minibatch 16::LR 0.0976923076923 --> Loss 0.00167163689931\n",
      "Epoch 2::Minibatch 17::LR 0.0976923076923 --> Loss 0.00586950977643\n",
      "Epoch 2::Minibatch 18::LR 0.0976923076923 --> Loss 0.0049482134978\n",
      "Epoch 2::Minibatch 19::LR 0.0976923076923 --> Loss 0.00148640404145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 20::LR 0.0976923076923 --> Loss 0.00320471306642\n",
      "Epoch 2::Minibatch 21::LR 0.0976923076923 --> Loss 0.00531861901283\n",
      "Epoch 2::Minibatch 22::LR 0.0976923076923 --> Loss 0.0031936476628\n",
      "Epoch 2::Minibatch 23::LR 0.0976923076923 --> Loss 0.00174649238586\n",
      "Epoch 2::Minibatch 24::LR 0.0976923076923 --> Loss 0.000731611003478\n",
      "Epoch 2::Minibatch 25::LR 0.0976923076923 --> Loss 0.00171223282814\n",
      "Epoch 2::Minibatch 26::LR 0.0976923076923 --> Loss 0.0023339676857\n",
      "Epoch 2::Minibatch 27::LR 0.0976923076923 --> Loss 0.00203061322371\n",
      "Epoch 2::Minibatch 28::LR 0.0976923076923 --> Loss 0.000766113152107\n",
      "Epoch 2::Minibatch 29::LR 0.0976923076923 --> Loss 0.000439020891984\n",
      "Epoch 2::Minibatch 30::LR 0.0976923076923 --> Loss 0.00116420050462\n",
      "Epoch 2::Minibatch 31::LR 0.0976923076923 --> Loss 0.00229368031025\n",
      "Epoch 2::Minibatch 32::LR 0.0976923076923 --> Loss 0.00252847631772\n",
      "Epoch 2::Minibatch 33::LR 0.0976923076923 --> Loss 0.000819924374421\n",
      "Epoch 2::Minibatch 34::LR 0.0976923076923 --> Loss 0.00351193189621\n",
      "Epoch 2::Minibatch 35::LR 0.0976923076923 --> Loss 0.00377535780271\n",
      "Epoch 2::Minibatch 36::LR 0.0976923076923 --> Loss 0.00228598495324\n",
      "Epoch 2::Minibatch 37::LR 0.0976923076923 --> Loss 0.00081123838822\n",
      "Epoch 2::Minibatch 38::LR 0.0976923076923 --> Loss 0.00111441781123\n",
      "Epoch 2::Minibatch 39::LR 0.0976923076923 --> Loss 0.00604765574137\n",
      "Epoch 2::Minibatch 40::LR 0.0976923076923 --> Loss 0.005138844649\n",
      "Epoch 2::Minibatch 41::LR 0.0976923076923 --> Loss 0.00506368557612\n",
      "Epoch 2::Minibatch 42::LR 0.0976923076923 --> Loss 0.00953765630722\n",
      "Epoch 2::Minibatch 43::LR 0.0976923076923 --> Loss 0.00297873735428\n",
      "Epoch 2::Minibatch 44::LR 0.0976923076923 --> Loss 0.00385040442149\n",
      "Epoch 2::Minibatch 45::LR 0.0976923076923 --> Loss 0.00382374763489\n",
      "Epoch 2::Minibatch 46::LR 0.0976923076923 --> Loss 0.0042900844415\n",
      "Epoch 2::Minibatch 47::LR 0.0976923076923 --> Loss 0.00602545301119\n",
      "Epoch 2::Minibatch 48::LR 0.0976923076923 --> Loss 0.0131204040845\n",
      "Epoch 2::Minibatch 49::LR 0.0976923076923 --> Loss 0.00583868463834\n",
      "Epoch 2::Minibatch 50::LR 0.0976923076923 --> Loss 0.00743494590123\n",
      "Epoch 2::Minibatch 51::LR 0.0976923076923 --> Loss 0.00827733596166\n",
      "Epoch 2::Minibatch 52::LR 0.0976923076923 --> Loss 0.00704657713572\n",
      "Epoch 2::Minibatch 53::LR 0.0976923076923 --> Loss 0.00568362593651\n",
      "Epoch 2::Minibatch 54::LR 0.0976923076923 --> Loss 0.00534152905146\n",
      "Epoch 2::Minibatch 55::LR 0.0976923076923 --> Loss 0.00318476657073\n",
      "Epoch 2::Minibatch 56::LR 0.0976923076923 --> Loss 0.00475032965342\n",
      "Epoch 2::Minibatch 57::LR 0.0976923076923 --> Loss 0.00814264456431\n",
      "Epoch 2::Minibatch 58::LR 0.0976923076923 --> Loss 0.00529461185137\n",
      "Epoch 2::Minibatch 59::LR 0.0976923076923 --> Loss 0.00571257869403\n",
      "Epoch 2::Minibatch 60::LR 0.0976923076923 --> Loss 0.0044105831782\n",
      "Epoch 2::Minibatch 61::LR 0.0976923076923 --> Loss 0.00263711690903\n",
      "Epoch 2::Minibatch 62::LR 0.0976923076923 --> Loss 0.0055756020546\n",
      "Epoch 2::Minibatch 63::LR 0.0976923076923 --> Loss 0.00352428078651\n",
      "Epoch 2::Minibatch 64::LR 0.0976923076923 --> Loss 0.00237398604552\n",
      "Epoch 2::Minibatch 65::LR 0.0976923076923 --> Loss 0.00398684223493\n",
      "Epoch 2::Minibatch 66::LR 0.0976923076923 --> Loss 0.00425657113393\n",
      "Epoch 2::Minibatch 67::LR 0.0976923076923 --> Loss 0.00423140327136\n",
      "Epoch 2::Minibatch 68::LR 0.0976923076923 --> Loss 0.00311665554841\n",
      "Epoch 2::Minibatch 69::LR 0.0976923076923 --> Loss 0.00496714512507\n",
      "Epoch 2::Minibatch 70::LR 0.0976923076923 --> Loss 0.00446606079737\n",
      "Epoch 2::Minibatch 71::LR 0.0976923076923 --> Loss 0.0036686917146\n",
      "Epoch 2::Minibatch 72::LR 0.0976923076923 --> Loss 0.00103159328302\n",
      "Epoch 2::Minibatch 73::LR 0.0976923076923 --> Loss 0.00438700993856\n",
      "Epoch 2::Minibatch 74::LR 0.0976923076923 --> Loss 0.00646695971489\n",
      "Epoch 2::Minibatch 75::LR 0.0976923076923 --> Loss 0.00323092718919\n",
      "Epoch 2::Minibatch 76::LR 0.0976923076923 --> Loss 0.00142946104209\n",
      "Epoch 2::Minibatch 77::LR 0.0976923076923 --> Loss 0.0295567353566\n",
      "Epoch 2::Minibatch 78::LR 0.0976923076923 --> Loss 0.00534051974614\n",
      "Epoch 2::Minibatch 79::LR 0.0976923076923 --> Loss 0.00356307864189\n",
      "Epoch 2::Minibatch 80::LR 0.0976923076923 --> Loss 0.00572158336639\n",
      "Epoch 2::Minibatch 81::LR 0.0976923076923 --> Loss 0.00567808349927\n",
      "Epoch 2::Minibatch 82::LR 0.0976923076923 --> Loss 0.00401567459106\n",
      "Epoch 2::Minibatch 83::LR 0.0976923076923 --> Loss 0.0123076049487\n",
      "Epoch 2::Minibatch 84::LR 0.0976923076923 --> Loss 0.00365080078443\n",
      "Epoch 2::Minibatch 85::LR 0.0976923076923 --> Loss 0.00477230350176\n",
      "Epoch 2::Minibatch 86::LR 0.0976923076923 --> Loss 0.00427454710007\n",
      "Epoch 2::Minibatch 87::LR 0.0976923076923 --> Loss 0.00452251195908\n",
      "Epoch 2::Minibatch 88::LR 0.0976923076923 --> Loss 0.00412779768308\n",
      "Epoch 2::Minibatch 89::LR 0.0976923076923 --> Loss 0.00441141009331\n",
      "Epoch 2::Minibatch 90::LR 0.0976923076923 --> Loss 0.00301385124524\n",
      "Epoch 2::Minibatch 91::LR 0.0976923076923 --> Loss 0.00275366286437\n",
      "Epoch 2::Minibatch 92::LR 0.0976923076923 --> Loss 0.00482233047485\n",
      "Epoch 2::Minibatch 93::LR 0.0976923076923 --> Loss 0.00344967047373\n",
      "Epoch 2::Minibatch 94::LR 0.0976923076923 --> Loss 0.00362000743548\n",
      "Epoch 2::Minibatch 95::LR 0.0976923076923 --> Loss 0.00319971124331\n",
      "Epoch 2::Minibatch 96::LR 0.0976923076923 --> Loss 0.00921680212021\n",
      "Epoch 2::Minibatch 97::LR 0.0976923076923 --> Loss 0.00403633952141\n",
      "Epoch 2::Minibatch 98::LR 0.0976923076923 --> Loss 0.0017834242185\n",
      "Epoch 2::Minibatch 99::LR 0.0976923076923 --> Loss 0.00234550595284\n",
      "Epoch 2::Minibatch 100::LR 0.0976923076923 --> Loss 0.0137334442139\n",
      "Epoch 2::Minibatch 101::LR 0.0976923076923 --> Loss 0.00219790617625\n",
      "Epoch 2::Minibatch 102::LR 0.0976923076923 --> Loss 0.00464957078298\n",
      "Epoch 2::Minibatch 103::LR 0.0976923076923 --> Loss 0.00516713817914\n",
      "Epoch 2::Minibatch 104::LR 0.0976923076923 --> Loss 0.00449507196744\n",
      "Epoch 2::Minibatch 105::LR 0.0976923076923 --> Loss 0.00723110993703\n",
      "Epoch 2::Minibatch 106::LR 0.0976923076923 --> Loss 0.0320273844401\n",
      "Epoch 2::Minibatch 107::LR 0.0976923076923 --> Loss 0.00622839252154\n",
      "Epoch 2::Minibatch 108::LR 0.0976923076923 --> Loss 0.00284925897916\n",
      "Epoch 2::Minibatch 109::LR 0.0976923076923 --> Loss 0.00643976569176\n",
      "Epoch 2::Minibatch 110::LR 0.0976923076923 --> Loss 0.00421795169512\n",
      "Epoch 2::Minibatch 111::LR 0.0976923076923 --> Loss 0.0026029998064\n",
      "Epoch 2::Minibatch 112::LR 0.0976923076923 --> Loss 0.00561011592547\n",
      "Epoch 2::Minibatch 113::LR 0.0976923076923 --> Loss 0.00475485364596\n",
      "Epoch 2::Minibatch 114::LR 0.0976923076923 --> Loss 0.00312384068966\n",
      "Epoch 2::Minibatch 115::LR 0.0976923076923 --> Loss 0.00296166280905\n",
      "Epoch 2::Minibatch 116::LR 0.0976923076923 --> Loss 0.00467870314916\n",
      "Epoch 2::Minibatch 117::LR 0.0976923076923 --> Loss 0.00498464226723\n",
      "Epoch 2::Minibatch 118::LR 0.0976923076923 --> Loss 0.00779238144557\n",
      "Epoch 2::Minibatch 119::LR 0.0976923076923 --> Loss 0.002050238053\n",
      "Epoch 2::Minibatch 120::LR 0.0976923076923 --> Loss 0.0036519809564\n",
      "Epoch 2::Minibatch 121::LR 0.0976923076923 --> Loss 0.0049186650912\n",
      "Epoch 2::Minibatch 122::LR 0.0976923076923 --> Loss 0.00540399670601\n",
      "Epoch 2::Minibatch 123::LR 0.0976923076923 --> Loss 0.0031749467055\n",
      "Epoch 2::Minibatch 124::LR 0.0976923076923 --> Loss 0.00431861797969\n",
      "Epoch 2::Minibatch 125::LR 0.0976923076923 --> Loss 0.00620642820994\n",
      "Epoch 2::Minibatch 126::LR 0.0976923076923 --> Loss 0.00422266205152\n",
      "Epoch 2::Minibatch 127::LR 0.0976923076923 --> Loss 0.00616895278295\n",
      "Epoch 2::Minibatch 128::LR 0.0976923076923 --> Loss 0.00465104738871\n",
      "Epoch 2::Minibatch 129::LR 0.0976923076923 --> Loss 0.00415075540543\n",
      "Epoch 2::Minibatch 130::LR 0.0976923076923 --> Loss 0.00505465785662\n",
      "Epoch 2::Minibatch 131::LR 0.0976923076923 --> Loss 0.00293906370799\n",
      "Epoch 2::Minibatch 132::LR 0.0976923076923 --> Loss 0.00429981708527\n",
      "Epoch 2::Minibatch 133::LR 0.0976923076923 --> Loss 0.00439843813578\n",
      "Epoch 2::Minibatch 134::LR 0.0976923076923 --> Loss 0.0038968205452\n",
      "Epoch 2::Minibatch 135::LR 0.0976923076923 --> Loss 0.00305824975173\n",
      "Epoch 2::Minibatch 136::LR 0.0976923076923 --> Loss 0.00388447483381\n",
      "Epoch 2::Minibatch 137::LR 0.0976923076923 --> Loss 0.00463102062543\n",
      "Epoch 2::Minibatch 138::LR 0.0976923076923 --> Loss 0.00239462971687\n",
      "Epoch 2::Minibatch 139::LR 0.0976923076923 --> Loss 0.0027250601848\n",
      "Epoch 2::Minibatch 140::LR 0.0976923076923 --> Loss 0.00330972532431\n",
      "Epoch 2::Minibatch 141::LR 0.0976923076923 --> Loss 0.00388961513837\n",
      "Epoch 2::Minibatch 142::LR 0.0976923076923 --> Loss 0.00506943027178\n",
      "Epoch 2::Minibatch 143::LR 0.0976923076923 --> Loss 0.00136666854223\n",
      "Epoch 2::Minibatch 144::LR 0.0976923076923 --> Loss 0.00355936447779\n",
      "Epoch 2::Minibatch 145::LR 0.0976923076923 --> Loss 0.00514931321144\n",
      "Epoch 2::Minibatch 146::LR 0.0976923076923 --> Loss 0.00376649975777\n",
      "Epoch 2::Minibatch 147::LR 0.0976923076923 --> Loss 0.00249751110872\n",
      "Epoch 2::Minibatch 148::LR 0.0976923076923 --> Loss 0.00173676768939\n",
      "Epoch 2::Minibatch 149::LR 0.0976923076923 --> Loss 0.00365043640137\n",
      "Epoch 2::Minibatch 150::LR 0.0976923076923 --> Loss 0.00397356947263\n",
      "Epoch 2::Minibatch 151::LR 0.0976923076923 --> Loss 0.00538382013639\n",
      "Epoch 2::Minibatch 152::LR 0.0976923076923 --> Loss 0.00150540808837\n",
      "Epoch 2::Minibatch 153::LR 0.0976923076923 --> Loss 0.00239660362403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 154::LR 0.0976923076923 --> Loss 0.00273820976416\n",
      "Epoch 2::Minibatch 155::LR 0.0976923076923 --> Loss 0.00709822654724\n",
      "Epoch 2::Minibatch 156::LR 0.0976923076923 --> Loss 0.00351783831914\n",
      "Epoch 2::Minibatch 157::LR 0.0976923076923 --> Loss 0.00105690528949\n",
      "Epoch 2::Minibatch 158::LR 0.0976923076923 --> Loss 0.00356658697128\n",
      "Epoch 2::Minibatch 159::LR 0.0976923076923 --> Loss 0.003702643315\n",
      "Epoch 2::Minibatch 160::LR 0.0976923076923 --> Loss 0.00366606513659\n",
      "Epoch 2::Minibatch 161::LR 0.0976923076923 --> Loss 0.00160107771556\n",
      "Epoch 2::Minibatch 162::LR 0.0976923076923 --> Loss 0.00359449625015\n",
      "Epoch 2::Minibatch 163::LR 0.0976923076923 --> Loss 0.00323696037134\n",
      "Epoch 2::Minibatch 164::LR 0.0976923076923 --> Loss 0.00311948617299\n",
      "Epoch 2::Minibatch 165::LR 0.0976923076923 --> Loss 0.00108194669088\n",
      "Epoch 2::Minibatch 166::LR 0.0976923076923 --> Loss 0.00244655847549\n",
      "Epoch 2::Minibatch 167::LR 0.0976923076923 --> Loss 0.00331572314103\n",
      "Epoch 2::Minibatch 168::LR 0.0976923076923 --> Loss 0.00297998825709\n",
      "Epoch 2::Minibatch 169::LR 0.0976923076923 --> Loss 0.00160902122657\n",
      "Epoch 2::Minibatch 170::LR 0.0976923076923 --> Loss 0.00149234970411\n",
      "Epoch 2::Minibatch 171::LR 0.0976923076923 --> Loss 0.00302605470022\n",
      "Epoch 2::Minibatch 172::LR 0.0976923076923 --> Loss 0.00969035228093\n",
      "Epoch 2::Minibatch 173::LR 0.0976923076923 --> Loss 0.00279024839401\n",
      "Epoch 2::Minibatch 174::LR 0.0976923076923 --> Loss 0.00138571451108\n",
      "Epoch 2::Minibatch 175::LR 0.0976923076923 --> Loss 0.0027897075812\n",
      "Epoch 2::Minibatch 176::LR 0.0976923076923 --> Loss 0.00427604238192\n",
      "Epoch 2::Minibatch 177::LR 0.0976923076923 --> Loss 0.00742615779241\n",
      "Epoch 2::Minibatch 178::LR 0.0976923076923 --> Loss 0.00239918013414\n",
      "Epoch 2::Minibatch 179::LR 0.0976923076923 --> Loss 0.00177102049192\n",
      "Epoch 2::Minibatch 180::LR 0.0976923076923 --> Loss 0.00487195094426\n",
      "Epoch 2::Minibatch 181::LR 0.0976923076923 --> Loss 0.00450103322665\n",
      "Epoch 2::Minibatch 182::LR 0.0976923076923 --> Loss 0.0013721198837\n",
      "Epoch 2::Minibatch 183::LR 0.0976923076923 --> Loss 0.00206548889478\n",
      "Epoch 2::Minibatch 184::LR 0.0976923076923 --> Loss 0.00500846902529\n",
      "Epoch 2::Minibatch 185::LR 0.0976923076923 --> Loss 0.00326518515746\n",
      "Epoch 2::Minibatch 186::LR 0.0976923076923 --> Loss 0.00146562516689\n",
      "Epoch 2::Minibatch 187::LR 0.0976923076923 --> Loss 0.00198734124502\n",
      "Epoch 2::Minibatch 188::LR 0.0976923076923 --> Loss 0.00519290606181\n",
      "Epoch 2::Minibatch 189::LR 0.0976923076923 --> Loss 0.00525037964185\n",
      "Epoch 2::Minibatch 190::LR 0.0976923076923 --> Loss 0.00277078151703\n",
      "Epoch 2::Minibatch 191::LR 0.0976923076923 --> Loss 0.000916490654151\n",
      "Epoch 2::Minibatch 192::LR 0.0976923076923 --> Loss 0.00351835727692\n",
      "Epoch 2::Minibatch 193::LR 0.0976923076923 --> Loss 0.00313506245613\n",
      "Epoch 2::Minibatch 194::LR 0.0976923076923 --> Loss 0.0022487817208\n",
      "Epoch 2::Minibatch 195::LR 0.0976923076923 --> Loss 0.000627487351497\n",
      "Epoch 2::Minibatch 196::LR 0.0976923076923 --> Loss 0.00142356961966\n",
      "Epoch 2::Minibatch 197::LR 0.0976923076923 --> Loss 0.00300045728683\n",
      "Epoch 2::Minibatch 198::LR 0.0976923076923 --> Loss 0.0023853067557\n",
      "Epoch 2::Minibatch 199::LR 0.0976923076923 --> Loss 0.000501914570729\n",
      "Epoch 2::Minibatch 200::LR 0.0976923076923 --> Loss 0.00287646571795\n",
      "Epoch 2::Minibatch 201::LR 0.0976923076923 --> Loss 0.0025389200449\n",
      "Epoch 2::Minibatch 202::LR 0.0976923076923 --> Loss 0.00228870133559\n",
      "Epoch 2::Minibatch 203::LR 0.0976923076923 --> Loss 0.00238127708435\n",
      "Epoch 2::Minibatch 204::LR 0.0976923076923 --> Loss 0.00208805799484\n",
      "Epoch 2::Minibatch 205::LR 0.0976923076923 --> Loss 0.00292764584223\n",
      "Epoch 2::Minibatch 206::LR 0.0976923076923 --> Loss 0.00894645611445\n",
      "Epoch 2::Minibatch 207::LR 0.0976923076923 --> Loss 0.00171233971914\n",
      "Epoch 2::Minibatch 208::LR 0.0976923076923 --> Loss 0.00142661293348\n",
      "Epoch 2::Minibatch 209::LR 0.0976923076923 --> Loss 0.0025356177489\n",
      "Epoch 2::Minibatch 210::LR 0.0976923076923 --> Loss 0.00219614585241\n",
      "Epoch 2::Minibatch 211::LR 0.0976923076923 --> Loss 0.00227608978748\n",
      "Epoch 2::Minibatch 212::LR 0.0976923076923 --> Loss 0.00539627035459\n",
      "Epoch 2::Minibatch 213::LR 0.0976923076923 --> Loss 0.00708210388819\n",
      "Epoch 2::Minibatch 214::LR 0.0976923076923 --> Loss 0.00952132463455\n",
      "Epoch 2::Minibatch 215::LR 0.0976923076923 --> Loss 0.00166915317376\n",
      "Epoch 2::Minibatch 216::LR 0.0976923076923 --> Loss 0.00546004215876\n",
      "Epoch 2::Minibatch 217::LR 0.0976923076923 --> Loss 0.00547811547915\n",
      "Epoch 2::Minibatch 218::LR 0.0976923076923 --> Loss 0.00495097001394\n",
      "Epoch 2::Minibatch 219::LR 0.0976923076923 --> Loss 0.0033217771848\n",
      "Epoch 2::Minibatch 220::LR 0.0976923076923 --> Loss 0.00487585624059\n",
      "Epoch 2::Minibatch 221::LR 0.0976923076923 --> Loss 0.00477205594381\n",
      "Epoch 2::Minibatch 222::LR 0.0976923076923 --> Loss 0.00382359862328\n",
      "Epoch 2::Minibatch 223::LR 0.0976923076923 --> Loss 0.00166351656119\n",
      "Epoch 2::Minibatch 224::LR 0.0976923076923 --> Loss 0.00227403998375\n",
      "Epoch 2::Minibatch 225::LR 0.0976923076923 --> Loss 0.00704678694407\n",
      "Epoch 2::Minibatch 226::LR 0.0976923076923 --> Loss 0.00420264482498\n",
      "Epoch 2::Minibatch 227::LR 0.0976923076923 --> Loss 0.00191910505295\n",
      "Epoch 2::Minibatch 228::LR 0.0976923076923 --> Loss 0.0011488823096\n",
      "Epoch 2::Minibatch 229::LR 0.0976923076923 --> Loss 0.00528896252314\n",
      "Epoch 2::Minibatch 230::LR 0.0976923076923 --> Loss 0.00462379097939\n",
      "Epoch 2::Minibatch 231::LR 0.0976923076923 --> Loss 0.002986317873\n",
      "Epoch 2::Minibatch 232::LR 0.0976923076923 --> Loss 0.00161975810925\n",
      "Epoch 2::Minibatch 233::LR 0.0976923076923 --> Loss 0.00256652434667\n",
      "Epoch 2::Minibatch 234::LR 0.0976923076923 --> Loss 0.00674887339274\n",
      "Epoch 2::Minibatch 235::LR 0.0976923076923 --> Loss 0.00480867743492\n",
      "Epoch 2::Minibatch 236::LR 0.0976923076923 --> Loss 0.00195533752441\n",
      "Epoch 2::Minibatch 237::LR 0.0976923076923 --> Loss 0.00109944651524\n",
      "Epoch 2::Minibatch 238::LR 0.0976923076923 --> Loss 0.00361005981763\n",
      "Epoch 2::Minibatch 239::LR 0.0976923076923 --> Loss 0.00302370568117\n",
      "Epoch 2::Minibatch 240::LR 0.0976923076923 --> Loss 0.00320834577084\n",
      "Epoch 2::Minibatch 241::LR 0.0976923076923 --> Loss 0.00106643031041\n",
      "Epoch 2::Minibatch 242::LR 0.0976923076923 --> Loss 0.007943054835\n",
      "Epoch 2::Minibatch 243::LR 0.0976923076923 --> Loss 0.0043190463384\n",
      "Epoch 2::Minibatch 244::LR 0.0976923076923 --> Loss 0.00353809912999\n",
      "Epoch 2::Minibatch 245::LR 0.0976923076923 --> Loss 0.00138037214677\n",
      "Epoch 2::Minibatch 246::LR 0.0976923076923 --> Loss 0.00293153822422\n",
      "Epoch 2::Minibatch 247::LR 0.0976923076923 --> Loss 0.0169879690806\n",
      "Epoch 2::Minibatch 248::LR 0.0976923076923 --> Loss 0.0220470794042\n",
      "Epoch 2::Minibatch 249::LR 0.0976923076923 --> Loss 0.00519134759903\n",
      "Epoch 2::Minibatch 250::LR 0.0976923076923 --> Loss 0.00339025338491\n",
      "Epoch 2::Minibatch 251::LR 0.0976923076923 --> Loss 0.00208547870318\n",
      "Epoch 2::Minibatch 252::LR 0.0976923076923 --> Loss 0.00220704038938\n",
      "Epoch 2::Minibatch 253::LR 0.0976923076923 --> Loss 0.00347305258115\n",
      "Epoch 2::Minibatch 254::LR 0.0976923076923 --> Loss 0.00673687378565\n",
      "Epoch 2::Minibatch 255::LR 0.0976923076923 --> Loss 0.00458141803741\n",
      "Epoch 2::Minibatch 256::LR 0.0976923076923 --> Loss 0.00215744415919\n",
      "Epoch 2::Minibatch 257::LR 0.0976923076923 --> Loss 0.00167337914308\n",
      "Epoch 2::Minibatch 258::LR 0.0976923076923 --> Loss 0.00383683363597\n",
      "Epoch 2::Minibatch 259::LR 0.0976923076923 --> Loss 0.00222780883312\n",
      "Epoch 2::Minibatch 260::LR 0.0976923076923 --> Loss 0.00225604375203\n",
      "Epoch 2::Minibatch 261::LR 0.0976923076923 --> Loss 0.0035643307368\n",
      "Epoch 2::Minibatch 262::LR 0.0976923076923 --> Loss 0.00251914103826\n",
      "Epoch 2::Minibatch 263::LR 0.0976923076923 --> Loss 0.00296474476655\n",
      "Epoch 2::Minibatch 264::LR 0.0976923076923 --> Loss 0.00381095091502\n",
      "Epoch 2::Minibatch 265::LR 0.0976923076923 --> Loss 0.0597164217631\n",
      "Epoch 2::Minibatch 266::LR 0.0976923076923 --> Loss 0.00129533926646\n",
      "Epoch 2::Minibatch 267::LR 0.0976923076923 --> Loss 0.0115691550573\n",
      "Epoch 2::Minibatch 268::LR 0.0976923076923 --> Loss 0.00155671268702\n",
      "Epoch 2::Minibatch 269::LR 0.0976923076923 --> Loss 0.00419282396634\n",
      "Epoch 2::Minibatch 270::LR 0.0976923076923 --> Loss 0.00669581095378\n",
      "Epoch 2::Minibatch 271::LR 0.0976923076923 --> Loss 0.00325474639734\n",
      "Epoch 2::Minibatch 272::LR 0.0976923076923 --> Loss 0.00415867964427\n",
      "Epoch 2::Minibatch 273::LR 0.0976923076923 --> Loss 0.00208601931731\n",
      "Epoch 2::Minibatch 274::LR 0.0976923076923 --> Loss 0.00210862874985\n",
      "Epoch 2::Minibatch 275::LR 0.0976923076923 --> Loss 0.00295880556107\n",
      "Epoch 2::Minibatch 276::LR 0.0976923076923 --> Loss 0.00358974854151\n",
      "Epoch 2::Minibatch 277::LR 0.0976923076923 --> Loss 0.00141659289598\n",
      "Epoch 2::Minibatch 278::LR 0.0976923076923 --> Loss 0.00266959150632\n",
      "Epoch 2::Minibatch 279::LR 0.0976923076923 --> Loss 0.00257653057575\n",
      "Epoch 2::Minibatch 280::LR 0.0976923076923 --> Loss 0.00234661281109\n",
      "Epoch 2::Minibatch 281::LR 0.0976923076923 --> Loss 0.00157878319422\n",
      "Epoch 2::Minibatch 282::LR 0.0976923076923 --> Loss 0.00227335512638\n",
      "Epoch 2::Minibatch 283::LR 0.0976923076923 --> Loss 0.00220404068629\n",
      "Epoch 2::Minibatch 284::LR 0.0976923076923 --> Loss 0.00181899110476\n",
      "Epoch 2::Minibatch 285::LR 0.0976923076923 --> Loss 0.00134724567334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 286::LR 0.0976923076923 --> Loss 0.00215450465679\n",
      "Epoch 2::Minibatch 287::LR 0.0976923076923 --> Loss 0.00209585686525\n",
      "Epoch 2::Minibatch 288::LR 0.0976923076923 --> Loss 0.00119556605816\n",
      "Epoch 2::Minibatch 289::LR 0.0976923076923 --> Loss 0.00146148324013\n",
      "Epoch 2::Minibatch 290::LR 0.0976923076923 --> Loss 0.00193625926971\n",
      "Epoch 2::Minibatch 291::LR 0.0976923076923 --> Loss 0.00171267767747\n",
      "Epoch 2::Minibatch 292::LR 0.0976923076923 --> Loss 0.000780600806077\n",
      "Epoch 2::Minibatch 293::LR 0.0976923076923 --> Loss 0.00135903388262\n",
      "Epoch 2::Minibatch 294::LR 0.0976923076923 --> Loss 0.00162831375996\n",
      "Epoch 2::Minibatch 295::LR 0.0976923076923 --> Loss 0.0017084868749\n",
      "Epoch 2::Minibatch 296::LR 0.0976923076923 --> Loss 0.00145097583532\n",
      "Epoch 2::Minibatch 297::LR 0.0976923076923 --> Loss 0.00133716116349\n",
      "Epoch 2::Minibatch 298::LR 0.0976923076923 --> Loss 0.00128767549992\n",
      "Epoch 2::Minibatch 299::LR 0.0976923076923 --> Loss 0.000821884075801\n",
      "Epoch 2::Minibatch 300::LR 0.0976923076923 --> Loss 0.00342525641123\n",
      "Epoch 2::Minibatch 301::LR 0.0976923076923 --> Loss 0.00325426359971\n",
      "Epoch 2::Minibatch 302::LR 0.0976923076923 --> Loss 0.00260887642701\n",
      "Epoch 2::Minibatch 303::LR 0.0976923076923 --> Loss 0.00120402753353\n",
      "Epoch 2::Minibatch 304::LR 0.0976923076923 --> Loss 0.00367805759112\n",
      "Epoch 2::Minibatch 305::LR 0.0976923076923 --> Loss 0.00185270925363\n",
      "Epoch 2::Minibatch 306::LR 0.0976923076923 --> Loss 0.00116536905368\n",
      "Epoch 2::Minibatch 307::LR 0.0976923076923 --> Loss 0.00278864562511\n",
      "Epoch 2::Minibatch 308::LR 0.0976923076923 --> Loss 0.00208189944426\n",
      "Epoch 2::Minibatch 309::LR 0.0976923076923 --> Loss 0.00107856760422\n",
      "Epoch 2::Minibatch 310::LR 0.0976923076923 --> Loss 0.00104389001926\n",
      "Epoch 2::Minibatch 311::LR 0.0976923076923 --> Loss 0.00166999618212\n",
      "Epoch 2::Minibatch 312::LR 0.0976923076923 --> Loss 0.00364159901937\n",
      "Epoch 2::Minibatch 313::LR 0.0976923076923 --> Loss 0.00265097061793\n",
      "Epoch 2::Minibatch 314::LR 0.0976923076923 --> Loss 0.00222557981809\n",
      "Epoch 2::Minibatch 315::LR 0.0976923076923 --> Loss 0.00134158402681\n",
      "Epoch 2::Minibatch 316::LR 0.0976923076923 --> Loss 0.00263457834721\n",
      "Epoch 2::Minibatch 317::LR 0.0976923076923 --> Loss 0.00206586559614\n",
      "Epoch 2::Minibatch 318::LR 0.0976923076923 --> Loss 0.00145773857832\n",
      "Epoch 2::Minibatch 319::LR 0.0976923076923 --> Loss 0.00252200782299\n",
      "Epoch 2::Minibatch 320::LR 0.0976923076923 --> Loss 0.00364142735799\n",
      "Epoch 2::Minibatch 321::LR 0.0976923076923 --> Loss 0.000943243404229\n",
      "Epoch 2::Minibatch 322::LR 0.0976923076923 --> Loss 0.0035776702563\n",
      "Epoch 2::Minibatch 323::LR 0.0976923076923 --> Loss 0.00327913781007\n",
      "Epoch 2::Minibatch 324::LR 0.0976923076923 --> Loss 0.0024936624368\n",
      "Epoch 2::Minibatch 325::LR 0.0976923076923 --> Loss 0.00247586429119\n",
      "Epoch 2::Minibatch 326::LR 0.0976923076923 --> Loss 0.00717233022054\n",
      "Epoch 2::Minibatch 327::LR 0.0976923076923 --> Loss 0.00264962116877\n",
      "Epoch 2::Minibatch 328::LR 0.0976923076923 --> Loss 0.00399065454801\n",
      "Epoch 2::Minibatch 329::LR 0.0976923076923 --> Loss 0.0012746745348\n",
      "Epoch 2::Minibatch 330::LR 0.0976923076923 --> Loss 0.00191324969133\n",
      "Epoch 2::Minibatch 331::LR 0.0976923076923 --> Loss 0.0029576665163\n",
      "Epoch 2::Minibatch 332::LR 0.0976923076923 --> Loss 0.00289880534013\n",
      "Epoch 2::Minibatch 333::LR 0.0976923076923 --> Loss 0.00163324862719\n",
      "Epoch 2::Minibatch 334::LR 0.0976923076923 --> Loss 0.00445263584455\n",
      "Epoch 2::Minibatch 335::LR 0.0976923076923 --> Loss 0.00204211930434\n",
      "Epoch 2::Minibatch 336::LR 0.0976923076923 --> Loss 0.00197415232658\n",
      "Epoch 2::Minibatch 337::LR 0.0976923076923 --> Loss 0.00338625431061\n",
      "Epoch 2::Minibatch 338::LR 0.0976923076923 --> Loss 0.000719166596731\n",
      "Epoch 2::Minibatch 339::LR 0.0976923076923 --> Loss 0.0033384013176\n",
      "Epoch 2::Minibatch 340::LR 0.0976923076923 --> Loss 0.00771795829137\n",
      "Epoch 2::Minibatch 341::LR 0.0976923076923 --> Loss 0.00537728071213\n",
      "Epoch 2::Minibatch 342::LR 0.0976923076923 --> Loss 0.00385031779607\n",
      "Epoch 2::Minibatch 343::LR 0.0976923076923 --> Loss 0.00225409130255\n",
      "Epoch 2::Minibatch 344::LR 0.0976923076923 --> Loss 0.00345050692558\n",
      "Epoch 2::Minibatch 345::LR 0.0976923076923 --> Loss 0.00484213193258\n",
      "Epoch 2::Minibatch 346::LR 0.0976923076923 --> Loss 0.00615350206693\n",
      "Epoch 2::Minibatch 347::LR 0.0976923076923 --> Loss 0.00152878751357\n",
      "Epoch 2::Minibatch 348::LR 0.0976923076923 --> Loss 0.00473369201024\n",
      "Epoch 2::Minibatch 349::LR 0.0976923076923 --> Loss 0.00376087943713\n",
      "Epoch 2::Minibatch 350::LR 0.0976923076923 --> Loss 0.00235129574935\n",
      "Epoch 2::Minibatch 351::LR 0.0976923076923 --> Loss 0.00417741894722\n",
      "Epoch 2::Minibatch 352::LR 0.0976923076923 --> Loss 0.00492687702179\n",
      "Epoch 2::Minibatch 353::LR 0.0976923076923 --> Loss 0.00372572819392\n",
      "Epoch 2::Minibatch 354::LR 0.0976923076923 --> Loss 0.00315350472927\n",
      "Epoch 2::Minibatch 355::LR 0.0976923076923 --> Loss 0.00596064090729\n",
      "Epoch 2::Minibatch 356::LR 0.0976923076923 --> Loss 0.00357815504074\n",
      "Epoch 2::Minibatch 357::LR 0.0976923076923 --> Loss 0.00156035443147\n",
      "Epoch 2::Minibatch 358::LR 0.0976923076923 --> Loss 0.00279853463173\n",
      "Epoch 2::Minibatch 359::LR 0.0976923076923 --> Loss 0.00357159296672\n",
      "Epoch 2::Minibatch 360::LR 0.0976923076923 --> Loss 0.0030175369978\n",
      "Epoch 2::Minibatch 361::LR 0.0976923076923 --> Loss 0.00277262846629\n",
      "Epoch 2::Minibatch 362::LR 0.0976923076923 --> Loss 0.00323108931382\n",
      "Epoch 2::Minibatch 363::LR 0.0976923076923 --> Loss 0.000901537835598\n",
      "Epoch 2::Minibatch 364::LR 0.0976923076923 --> Loss 0.00239920298258\n",
      "Epoch 2::Minibatch 365::LR 0.0976923076923 --> Loss 0.0024435210228\n",
      "Epoch 2::Minibatch 366::LR 0.0976923076923 --> Loss 0.00274848282337\n",
      "Epoch 2::Minibatch 367::LR 0.0976923076923 --> Loss 0.0015218971173\n",
      "Epoch 2::Minibatch 368::LR 0.0976923076923 --> Loss 0.00128644188245\n",
      "Epoch 2::Minibatch 369::LR 0.0976923076923 --> Loss 0.0031942353646\n",
      "Epoch 2::Minibatch 370::LR 0.0976923076923 --> Loss 0.0024249958992\n",
      "Epoch 2::Minibatch 371::LR 0.0976923076923 --> Loss 0.00223428010941\n",
      "Epoch 2::Minibatch 372::LR 0.0976923076923 --> Loss 0.000661794145902\n",
      "Epoch 2::Minibatch 373::LR 0.0976923076923 --> Loss 0.00193185488383\n",
      "Epoch 2::Minibatch 374::LR 0.0976923076923 --> Loss 0.0022368768851\n",
      "Epoch 2::Minibatch 375::LR 0.0976923076923 --> Loss 0.00198779006799\n",
      "Epoch 2::Minibatch 376::LR 0.0976923076923 --> Loss 0.00140412638585\n",
      "Epoch 2::Minibatch 377::LR 0.0976923076923 --> Loss 0.00226052820683\n",
      "Epoch 2::Minibatch 378::LR 0.0976923076923 --> Loss 0.0022968451182\n",
      "Epoch 2::Minibatch 379::LR 0.0976923076923 --> Loss 0.0027471969525\n",
      "Epoch 2::Minibatch 380::LR 0.0976923076923 --> Loss 0.00180556197961\n",
      "Epoch 2::Minibatch 381::LR 0.0976923076923 --> Loss 0.00122992326816\n",
      "Epoch 2::Minibatch 382::LR 0.0976923076923 --> Loss 0.00226208408674\n",
      "Epoch 2::Minibatch 383::LR 0.0976923076923 --> Loss 0.00213346858819\n",
      "Epoch 2::Minibatch 384::LR 0.0976923076923 --> Loss 0.00120443344116\n",
      "Epoch 2::Minibatch 385::LR 0.0976923076923 --> Loss 0.00122936795155\n",
      "Epoch 2::Minibatch 386::LR 0.0976923076923 --> Loss 0.00253260612488\n",
      "Epoch 2::Minibatch 387::LR 0.0976923076923 --> Loss 0.00252507030964\n",
      "Epoch 2::Minibatch 388::LR 0.0976923076923 --> Loss 0.00120870560408\n",
      "Epoch 2::Minibatch 389::LR 0.0976923076923 --> Loss 0.00230758984884\n",
      "Epoch 2::Minibatch 390::LR 0.0976923076923 --> Loss 0.00462198932966\n",
      "Epoch 2::Minibatch 391::LR 0.0976923076923 --> Loss 0.00328527013461\n",
      "Epoch 2::Minibatch 392::LR 0.0976923076923 --> Loss 0.00323584457239\n",
      "Epoch 2::Minibatch 393::LR 0.0976923076923 --> Loss 0.00308958888054\n",
      "Epoch 2::Minibatch 394::LR 0.0976923076923 --> Loss 0.00343692024549\n",
      "Epoch 2::Minibatch 395::LR 0.0976923076923 --> Loss 0.00240043501059\n",
      "Epoch 2::Minibatch 396::LR 0.0976923076923 --> Loss 0.0024545999368\n",
      "Epoch 2::Minibatch 397::LR 0.0976923076923 --> Loss 0.00259573002656\n",
      "Epoch 2::Minibatch 398::LR 0.0976923076923 --> Loss 0.00246855358283\n",
      "Epoch 2::Minibatch 399::LR 0.0976923076923 --> Loss 0.00257592260838\n",
      "Epoch 2::Minibatch 400::LR 0.0976923076923 --> Loss 0.00240617851416\n",
      "Epoch 2::Minibatch 401::LR 0.0976923076923 --> Loss 0.00610139687856\n",
      "Epoch 2::Minibatch 402::LR 0.0976923076923 --> Loss 0.00287916322549\n",
      "Epoch 2::Minibatch 403::LR 0.0976923076923 --> Loss 0.00222673515479\n",
      "Epoch 2::Minibatch 404::LR 0.0976923076923 --> Loss 0.00240456879139\n",
      "Epoch 2::Minibatch 405::LR 0.0976923076923 --> Loss 0.0041602687041\n",
      "Epoch 2::Minibatch 406::LR 0.0976923076923 --> Loss 0.00293464660645\n",
      "Epoch 2::Minibatch 407::LR 0.0976923076923 --> Loss 0.00215217292309\n",
      "Epoch 2::Minibatch 408::LR 0.0976923076923 --> Loss 0.00114795386791\n",
      "Epoch 2::Minibatch 409::LR 0.0976923076923 --> Loss 0.00389502684275\n",
      "Epoch 2::Minibatch 410::LR 0.0976923076923 --> Loss 0.0056903286775\n",
      "Epoch 2::Minibatch 411::LR 0.0976923076923 --> Loss 0.00191172321637\n",
      "Epoch 2::Minibatch 412::LR 0.0976923076923 --> Loss 0.00119068374236\n",
      "Epoch 2::Minibatch 413::LR 0.0976923076923 --> Loss 0.0024952485164\n",
      "Epoch 2::Minibatch 414::LR 0.0976923076923 --> Loss 0.00179763217767\n",
      "Epoch 2::Minibatch 415::LR 0.0976923076923 --> Loss 0.00127531637748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 416::LR 0.0976923076923 --> Loss 0.00102590511243\n",
      "Epoch 2::Minibatch 417::LR 0.0976923076923 --> Loss 0.00183268586795\n",
      "Epoch 2::Minibatch 418::LR 0.0976923076923 --> Loss 0.00488258123398\n",
      "Epoch 2::Minibatch 419::LR 0.0976923076923 --> Loss 0.00123728523652\n",
      "Epoch 2::Minibatch 420::LR 0.0976923076923 --> Loss 0.00143815100193\n",
      "Epoch 2::Minibatch 421::LR 0.0976923076923 --> Loss 0.00263226032257\n",
      "Epoch 2::Minibatch 422::LR 0.0976923076923 --> Loss 0.00300364891688\n",
      "Epoch 2::Minibatch 423::LR 0.0976923076923 --> Loss 0.0016656473279\n",
      "Epoch 2::Minibatch 424::LR 0.0976923076923 --> Loss 0.00222514947255\n",
      "Epoch 2::Minibatch 425::LR 0.0976923076923 --> Loss 0.0027284270525\n",
      "Epoch 2::Minibatch 426::LR 0.0976923076923 --> Loss 0.00243748664856\n",
      "Epoch 2::Minibatch 427::LR 0.0976923076923 --> Loss 0.0013950975736\n",
      "Epoch 2::Minibatch 428::LR 0.0976923076923 --> Loss 0.00216630101204\n",
      "Epoch 2::Minibatch 429::LR 0.0976923076923 --> Loss 0.0032462644577\n",
      "Epoch 2::Minibatch 430::LR 0.0976923076923 --> Loss 0.0112429666519\n",
      "Epoch 2::Minibatch 431::LR 0.0976923076923 --> Loss 0.00440305312475\n",
      "Epoch 2::Minibatch 432::LR 0.0976923076923 --> Loss 0.00468607544899\n",
      "Epoch 2::Minibatch 433::LR 0.0976923076923 --> Loss 0.00284021894137\n",
      "Epoch 2::Minibatch 434::LR 0.0976923076923 --> Loss 0.00296727935473\n",
      "Epoch 2::Minibatch 435::LR 0.0976923076923 --> Loss 0.00282749434312\n",
      "Epoch 2::Minibatch 436::LR 0.0976923076923 --> Loss 0.00230689605077\n",
      "Epoch 2::Minibatch 437::LR 0.0976923076923 --> Loss 0.00516141017278\n",
      "Epoch 2::Minibatch 438::LR 0.0976923076923 --> Loss 0.00362572749456\n",
      "Epoch 2::Minibatch 439::LR 0.0976923076923 --> Loss 0.00278804838657\n",
      "Epoch 2::Minibatch 440::LR 0.0976923076923 --> Loss 0.00440936168035\n",
      "Epoch 2::Minibatch 441::LR 0.0976923076923 --> Loss 0.00436808268229\n",
      "Epoch 2::Minibatch 442::LR 0.0976923076923 --> Loss 0.00414183576902\n",
      "Epoch 2::Minibatch 443::LR 0.0976923076923 --> Loss 0.00493691325188\n",
      "Epoch 2::Minibatch 444::LR 0.0976923076923 --> Loss 0.00381030917168\n",
      "Epoch 2::Minibatch 445::LR 0.0976923076923 --> Loss 0.00121062636375\n",
      "Epoch 2::Minibatch 446::LR 0.0976923076923 --> Loss 0.00238145271937\n",
      "Epoch 2::Minibatch 447::LR 0.0976923076923 --> Loss 0.00339502374331\n",
      "Epoch 2::Minibatch 448::LR 0.0976923076923 --> Loss 0.00346941550573\n",
      "Epoch 2::Minibatch 449::LR 0.0976923076923 --> Loss 0.00487801512082\n",
      "Epoch 2::Minibatch 450::LR 0.0976923076923 --> Loss 0.00350125352542\n",
      "Epoch 2::Minibatch 451::LR 0.0976923076923 --> Loss 0.00523163437843\n",
      "Epoch 2::Minibatch 452::LR 0.0976923076923 --> Loss 0.00299074292183\n",
      "Epoch 2::Minibatch 453::LR 0.0976923076923 --> Loss 0.000919101436933\n",
      "Epoch 2::Minibatch 454::LR 0.0976923076923 --> Loss 0.00364908297857\n",
      "Epoch 2::Minibatch 455::LR 0.0976923076923 --> Loss 0.00352681914965\n",
      "Epoch 2::Minibatch 456::LR 0.0976923076923 --> Loss 0.00394576072693\n",
      "Epoch 2::Minibatch 457::LR 0.0976923076923 --> Loss 0.0024636332194\n",
      "Epoch 2::Minibatch 458::LR 0.0976923076923 --> Loss 0.00107643614213\n",
      "Epoch 2::Minibatch 459::LR 0.0976923076923 --> Loss 0.00606703718503\n",
      "Epoch 2::Minibatch 460::LR 0.0976923076923 --> Loss 0.00358234922091\n",
      "Epoch 2::Minibatch 461::LR 0.0976923076923 --> Loss 0.0044995756944\n",
      "Epoch 2::Minibatch 462::LR 0.0976923076923 --> Loss 0.000728394786517\n",
      "Epoch 2::Minibatch 463::LR 0.0976923076923 --> Loss 0.00663784384727\n",
      "Epoch 2::Minibatch 464::LR 0.0976923076923 --> Loss 0.00291925370693\n",
      "Epoch 2::Minibatch 465::LR 0.0976923076923 --> Loss 0.00680202802022\n",
      "Epoch 2::Minibatch 466::LR 0.0976923076923 --> Loss 0.0058420976003\n",
      "Epoch 2::Minibatch 467::LR 0.0976923076923 --> Loss 0.00602003296216\n",
      "Epoch 2::Minibatch 468::LR 0.0976923076923 --> Loss 0.00627764701843\n",
      "Epoch 2::Minibatch 469::LR 0.0976923076923 --> Loss 0.00757635037104\n",
      "Epoch 2::Minibatch 470::LR 0.0976923076923 --> Loss 0.00470327456792\n",
      "Epoch 2::Minibatch 471::LR 0.0976923076923 --> Loss 0.00276784956455\n",
      "Epoch 2::Minibatch 472::LR 0.0976923076923 --> Loss 0.00403311808904\n",
      "Epoch 2::Minibatch 473::LR 0.0976923076923 --> Loss 0.00263359864553\n",
      "Epoch 2::Minibatch 474::LR 0.0976923076923 --> Loss 0.00111179033915\n",
      "Epoch 2::Minibatch 475::LR 0.0976923076923 --> Loss 0.00499859015147\n",
      "Epoch 2::Minibatch 476::LR 0.0976923076923 --> Loss 0.00617925604184\n",
      "Epoch 2::Minibatch 477::LR 0.0976923076923 --> Loss 0.00134397308032\n",
      "Epoch 2::Minibatch 478::LR 0.0976923076923 --> Loss 0.00295597712199\n",
      "Epoch 2::Minibatch 479::LR 0.0976923076923 --> Loss 0.0024583530426\n",
      "Epoch 2::Minibatch 480::LR 0.0976923076923 --> Loss 0.0020803574721\n",
      "Epoch 2::Minibatch 481::LR 0.0976923076923 --> Loss 0.00135369698207\n",
      "Epoch 2::Minibatch 482::LR 0.0976923076923 --> Loss 0.00267513493697\n",
      "Epoch 2::Minibatch 483::LR 0.0976923076923 --> Loss 0.00421563982964\n",
      "Epoch 2::Minibatch 484::LR 0.0976923076923 --> Loss 0.00424899935722\n",
      "Epoch 2::Minibatch 485::LR 0.0976923076923 --> Loss 0.00115143577258\n",
      "Epoch 2::Minibatch 486::LR 0.0976923076923 --> Loss 0.00387811581294\n",
      "Epoch 2::Minibatch 487::LR 0.0976923076923 --> Loss 0.00417312105497\n",
      "Epoch 2::Minibatch 488::LR 0.0976923076923 --> Loss 0.00258553922176\n",
      "Epoch 2::Minibatch 489::LR 0.0976923076923 --> Loss 0.0039152387778\n",
      "Epoch 2::Minibatch 490::LR 0.0976923076923 --> Loss 0.00076191191872\n",
      "Epoch 2::Minibatch 491::LR 0.0976923076923 --> Loss 0.0042865840594\n",
      "Epoch 2::Minibatch 492::LR 0.0976923076923 --> Loss 0.00350795269012\n",
      "Epoch 2::Minibatch 493::LR 0.0976923076923 --> Loss 0.00406669974327\n",
      "Epoch 2::Minibatch 494::LR 0.0976923076923 --> Loss 0.0011283860604\n",
      "Epoch 2::Minibatch 495::LR 0.0976923076923 --> Loss 0.00250687976678\n",
      "Epoch 2::Minibatch 496::LR 0.0976923076923 --> Loss 0.00402289350828\n",
      "Epoch 2::Minibatch 497::LR 0.0976923076923 --> Loss 0.00130635301272\n",
      "Epoch 2::Minibatch 498::LR 0.0976923076923 --> Loss 0.000941352248192\n",
      "Epoch 2::Minibatch 499::LR 0.0976923076923 --> Loss 0.00519041657448\n",
      "Epoch 2::Minibatch 500::LR 0.0976923076923 --> Loss 0.00191478967667\n",
      "Epoch 2::Minibatch 501::LR 0.0976923076923 --> Loss 0.00258636275927\n",
      "Epoch 2::Minibatch 502::LR 0.0976923076923 --> Loss 0.00438168644905\n",
      "Epoch 2::Minibatch 503::LR 0.0976923076923 --> Loss 0.0120281346639\n",
      "Epoch 2::Minibatch 504::LR 0.0976923076923 --> Loss 0.00936138232549\n",
      "Epoch 2::Minibatch 505::LR 0.0976923076923 --> Loss 0.00497392177582\n",
      "Epoch 2::Minibatch 506::LR 0.0976923076923 --> Loss 0.00414503057798\n",
      "Epoch 2::Minibatch 507::LR 0.0976923076923 --> Loss 0.00612042029699\n",
      "Epoch 2::Minibatch 508::LR 0.0976923076923 --> Loss 0.00383139212926\n",
      "Epoch 2::Minibatch 509::LR 0.0976923076923 --> Loss 0.00531412919362\n",
      "Epoch 2::Minibatch 510::LR 0.0976923076923 --> Loss 0.0056746784846\n",
      "Epoch 2::Minibatch 511::LR 0.0976923076923 --> Loss 0.00402307232221\n",
      "Epoch 2::Minibatch 512::LR 0.0976923076923 --> Loss 0.00335955937703\n",
      "Epoch 2::Minibatch 513::LR 0.0976923076923 --> Loss 0.00161026398341\n",
      "Epoch 2::Minibatch 514::LR 0.0976923076923 --> Loss 0.00353874246279\n",
      "Epoch 2::Minibatch 515::LR 0.0976923076923 --> Loss 0.00373722712199\n",
      "Epoch 2::Minibatch 516::LR 0.0976923076923 --> Loss 0.00514694492022\n",
      "Epoch 2::Minibatch 517::LR 0.0976923076923 --> Loss 0.00339120109876\n",
      "Epoch 2::Minibatch 518::LR 0.0976923076923 --> Loss 0.00288265208403\n",
      "Epoch 2::Minibatch 519::LR 0.0976923076923 --> Loss 0.00383574048678\n",
      "Epoch 2::Minibatch 520::LR 0.0976923076923 --> Loss 0.00517516533534\n",
      "Epoch 2::Minibatch 521::LR 0.0976923076923 --> Loss 0.0057278418541\n",
      "Epoch 2::Minibatch 522::LR 0.0976923076923 --> Loss 0.0104141934713\n",
      "Epoch 2::Minibatch 523::LR 0.0976923076923 --> Loss 0.0012221472462\n",
      "Epoch 2::Minibatch 524::LR 0.0976923076923 --> Loss 0.00183356245359\n",
      "Epoch 2::Minibatch 525::LR 0.0976923076923 --> Loss 0.003849238952\n",
      "Epoch 2::Minibatch 526::LR 0.0976923076923 --> Loss 0.00683468739192\n",
      "Epoch 2::Minibatch 527::LR 0.0976923076923 --> Loss 0.00354516029358\n",
      "Epoch 2::Minibatch 528::LR 0.0976923076923 --> Loss 0.00238755802313\n",
      "Epoch 2::Minibatch 529::LR 0.0976923076923 --> Loss 0.00492092410723\n",
      "Epoch 2::Minibatch 530::LR 0.0976923076923 --> Loss 0.00527924458186\n",
      "Epoch 2::Minibatch 531::LR 0.0976923076923 --> Loss 0.00462199568748\n",
      "Epoch 2::Minibatch 532::LR 0.0976923076923 --> Loss 0.00347010890643\n",
      "Epoch 2::Minibatch 533::LR 0.0976923076923 --> Loss 0.0053827381134\n",
      "Epoch 2::Minibatch 534::LR 0.0976923076923 --> Loss 0.0045095872879\n",
      "Epoch 2::Minibatch 535::LR 0.0976923076923 --> Loss 0.00390133023262\n",
      "Epoch 2::Minibatch 536::LR 0.0976923076923 --> Loss 0.00279262542725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 537::LR 0.0976923076923 --> Loss 0.00142775684595\n",
      "Epoch 2::Minibatch 538::LR 0.0976923076923 --> Loss 0.00221605400244\n",
      "Epoch 2::Minibatch 539::LR 0.0976923076923 --> Loss 0.00404877781868\n",
      "Epoch 2::Minibatch 540::LR 0.0976923076923 --> Loss 0.0040031393369\n",
      "Epoch 2::Minibatch 541::LR 0.0976923076923 --> Loss 0.00349200248718\n",
      "Epoch 2::Minibatch 542::LR 0.0976923076923 --> Loss 0.00335186362267\n",
      "Epoch 2::Minibatch 543::LR 0.0976923076923 --> Loss 0.00357112725576\n",
      "Epoch 2::Minibatch 544::LR 0.0976923076923 --> Loss 0.004722036918\n",
      "Epoch 2::Minibatch 545::LR 0.0976923076923 --> Loss 0.00243399500847\n",
      "Epoch 2::Minibatch 546::LR 0.0976923076923 --> Loss 0.00107084135214\n",
      "Epoch 2::Minibatch 547::LR 0.0976923076923 --> Loss 0.00318145294984\n",
      "Epoch 2::Minibatch 548::LR 0.0976923076923 --> Loss 0.00504689296087\n",
      "Epoch 2::Minibatch 549::LR 0.0976923076923 --> Loss 0.0082790239652\n",
      "Epoch 2::Minibatch 550::LR 0.0976923076923 --> Loss 0.0014688043793\n",
      "Epoch 2::Minibatch 551::LR 0.0976923076923 --> Loss 0.00284600814184\n",
      "Epoch 2::Minibatch 552::LR 0.0976923076923 --> Loss 0.0044554789861\n",
      "Epoch 2::Minibatch 553::LR 0.0976923076923 --> Loss 0.00395156979561\n",
      "Epoch 2::Minibatch 554::LR 0.0976923076923 --> Loss 0.00541250069936\n",
      "Epoch 2::Minibatch 555::LR 0.0976923076923 --> Loss 0.00133442809184\n",
      "Epoch 2::Minibatch 556::LR 0.0976923076923 --> Loss 0.00279742439588\n",
      "Epoch 2::Minibatch 557::LR 0.0976923076923 --> Loss 0.00307112038136\n",
      "Epoch 2::Minibatch 558::LR 0.0976923076923 --> Loss 0.00482474803925\n",
      "Epoch 2::Minibatch 559::LR 0.0976923076923 --> Loss 0.00431653817495\n",
      "Epoch 2::Minibatch 560::LR 0.0976923076923 --> Loss 0.00393439133962\n",
      "Epoch 2::Minibatch 561::LR 0.0976923076923 --> Loss 0.00349251270294\n",
      "Epoch 2::Minibatch 562::LR 0.0976923076923 --> Loss 0.00293342014154\n",
      "Epoch 2::Minibatch 563::LR 0.0976923076923 --> Loss 0.00450985272725\n",
      "Epoch 2::Minibatch 564::LR 0.0976923076923 --> Loss 0.00362825711568\n",
      "Epoch 2::Minibatch 565::LR 0.0976923076923 --> Loss 0.00476084629695\n",
      "Epoch 2::Minibatch 566::LR 0.0976923076923 --> Loss 0.00298819641272\n",
      "Epoch 2::Minibatch 567::LR 0.0976923076923 --> Loss 0.00354250152906\n",
      "Epoch 2::Minibatch 568::LR 0.0976923076923 --> Loss 0.00238312840462\n",
      "Epoch 2::Minibatch 569::LR 0.0976923076923 --> Loss 0.000917434593042\n",
      "Epoch 2::Minibatch 570::LR 0.0976923076923 --> Loss 0.00241070727507\n",
      "Epoch 2::Minibatch 571::LR 0.0976923076923 --> Loss 0.00316917697589\n",
      "Epoch 2::Minibatch 572::LR 0.0976923076923 --> Loss 0.00329867005348\n",
      "Epoch 2::Minibatch 573::LR 0.0976923076923 --> Loss 0.00194444954395\n",
      "Epoch 2::Minibatch 574::LR 0.0976923076923 --> Loss 0.00128226995468\n",
      "Epoch 2::Minibatch 575::LR 0.0976923076923 --> Loss 0.00242426991463\n",
      "Epoch 2::Minibatch 576::LR 0.0976923076923 --> Loss 0.00296785910924\n",
      "Epoch 2::Minibatch 577::LR 0.0976923076923 --> Loss 0.00222684899966\n",
      "Epoch 2::Minibatch 578::LR 0.0976923076923 --> Loss 0.00158767769734\n",
      "Epoch 2::Minibatch 579::LR 0.0976923076923 --> Loss 0.00145270923773\n",
      "Epoch 2::Minibatch 580::LR 0.0976923076923 --> Loss 0.00253989100456\n",
      "Epoch 2::Minibatch 581::LR 0.0976923076923 --> Loss 0.00216002305349\n",
      "Epoch 2::Minibatch 582::LR 0.0976923076923 --> Loss 0.00489814639091\n",
      "Epoch 2::Minibatch 583::LR 0.0976923076923 --> Loss 0.00124368270238\n",
      "Epoch 2::Minibatch 584::LR 0.0976923076923 --> Loss 0.00160483439763\n",
      "Epoch 2::Minibatch 585::LR 0.0976923076923 --> Loss 0.0081649462382\n",
      "Epoch 2::Minibatch 586::LR 0.0976923076923 --> Loss 0.00515450080236\n",
      "Epoch 2::Minibatch 587::LR 0.0976923076923 --> Loss 0.00153359472752\n",
      "Epoch 2::Minibatch 588::LR 0.0976923076923 --> Loss 0.0018623461326\n",
      "Epoch 2::Minibatch 589::LR 0.0976923076923 --> Loss 0.00330361922582\n",
      "Epoch 2::Minibatch 590::LR 0.0976923076923 --> Loss 0.00286462883155\n",
      "Epoch 2::Minibatch 591::LR 0.0976923076923 --> Loss 0.00385505874952\n",
      "Epoch 2::Minibatch 592::LR 0.0976923076923 --> Loss 0.00160191714764\n",
      "Epoch 2::Minibatch 593::LR 0.0976923076923 --> Loss 0.00319371918837\n",
      "Epoch 2::Minibatch 594::LR 0.0976923076923 --> Loss 0.00381277640661\n",
      "Epoch 2::Minibatch 595::LR 0.0976923076923 --> Loss 0.00365293224653\n",
      "Epoch 2::Minibatch 596::LR 0.0976923076923 --> Loss 0.00293932874997\n",
      "Epoch 2::Minibatch 597::LR 0.0976923076923 --> Loss 0.00187417944272\n",
      "Epoch 2::Minibatch 598::LR 0.0976923076923 --> Loss 0.00422387917837\n",
      "Epoch 2::Minibatch 599::LR 0.0976923076923 --> Loss 0.00253621300062\n",
      "Epoch 2::Minibatch 600::LR 0.0976923076923 --> Loss 0.00304377317429\n",
      "Epoch 2::Minibatch 601::LR 0.0976923076923 --> Loss 0.0037239642938\n",
      "Epoch 2::Minibatch 602::LR 0.0976923076923 --> Loss 0.00233604272207\n",
      "Epoch 2::Minibatch 603::LR 0.0976923076923 --> Loss 0.00359527389208\n",
      "Epoch 2::Minibatch 604::LR 0.0976923076923 --> Loss 0.00219729979833\n",
      "Epoch 2::Minibatch 605::LR 0.0976923076923 --> Loss 0.00322696626186\n",
      "Epoch 2::Minibatch 606::LR 0.0976923076923 --> Loss 0.00263394236565\n",
      "Epoch 2::Minibatch 607::LR 0.0976923076923 --> Loss 0.00119345883528\n",
      "Epoch 2::Minibatch 608::LR 0.0976923076923 --> Loss 0.00226266622543\n",
      "Epoch 2::Minibatch 609::LR 0.0976923076923 --> Loss 0.00277833938599\n",
      "Epoch 2::Minibatch 610::LR 0.0976923076923 --> Loss 0.00395440896352\n",
      "Epoch 2::Minibatch 611::LR 0.0976923076923 --> Loss 0.00284866889318\n",
      "Epoch 2::Minibatch 612::LR 0.0976923076923 --> Loss 0.000926256279151\n",
      "Epoch 2::Minibatch 613::LR 0.0976923076923 --> Loss 0.00185984333356\n",
      "Epoch 2::Minibatch 614::LR 0.0976923076923 --> Loss 0.00292262792587\n",
      "Epoch 2::Minibatch 615::LR 0.0976923076923 --> Loss 0.00230439186096\n",
      "Epoch 2::Minibatch 616::LR 0.0976923076923 --> Loss 0.00131861388683\n",
      "Epoch 2::Minibatch 617::LR 0.0976923076923 --> Loss 0.000881489018599\n",
      "Epoch 2::Minibatch 618::LR 0.0976923076923 --> Loss 0.00289273957411\n",
      "Epoch 2::Minibatch 619::LR 0.0976923076923 --> Loss 0.0024303885301\n",
      "Epoch 2::Minibatch 620::LR 0.0976923076923 --> Loss 0.00212993443012\n",
      "Epoch 2::Minibatch 621::LR 0.0976923076923 --> Loss 0.0011440406243\n",
      "Epoch 2::Minibatch 622::LR 0.0976923076923 --> Loss 0.00113841454188\n",
      "Epoch 2::Minibatch 623::LR 0.0976923076923 --> Loss 0.00262961188952\n",
      "Epoch 2::Minibatch 624::LR 0.0976923076923 --> Loss 0.00226131697496\n",
      "Epoch 2::Minibatch 625::LR 0.0976923076923 --> Loss 0.00446374932925\n",
      "Epoch 2::Minibatch 626::LR 0.0976923076923 --> Loss 0.00599573691686\n",
      "Epoch 2::Minibatch 627::LR 0.0976923076923 --> Loss 0.00198909342289\n",
      "Epoch 2::Minibatch 628::LR 0.0976923076923 --> Loss 0.00137160986662\n",
      "Epoch 2::Minibatch 629::LR 0.0976923076923 --> Loss 0.0041504184405\n",
      "Epoch 2::Minibatch 630::LR 0.0976923076923 --> Loss 0.00418738881747\n",
      "Epoch 2::Minibatch 631::LR 0.0976923076923 --> Loss 0.00538939476013\n",
      "Epoch 2::Minibatch 632::LR 0.0976923076923 --> Loss 0.00136086195707\n",
      "Epoch 2::Minibatch 633::LR 0.0976923076923 --> Loss 0.00221345504125\n",
      "Epoch 2::Minibatch 634::LR 0.0976923076923 --> Loss 0.0038102432092\n",
      "Epoch 2::Minibatch 635::LR 0.0976923076923 --> Loss 0.00634935458501\n",
      "Epoch 2::Minibatch 636::LR 0.0976923076923 --> Loss 0.00588829994202\n",
      "Epoch 2::Minibatch 637::LR 0.0976923076923 --> Loss 0.00202694416046\n",
      "Epoch 2::Minibatch 638::LR 0.0976923076923 --> Loss 0.00266727268696\n",
      "Epoch 2::Minibatch 639::LR 0.0976923076923 --> Loss 0.00412394245466\n",
      "Epoch 2::Minibatch 640::LR 0.0976923076923 --> Loss 0.0042019311587\n",
      "Epoch 2::Minibatch 641::LR 0.0976923076923 --> Loss 0.00363796035449\n",
      "Epoch 2::Minibatch 642::LR 0.0976923076923 --> Loss 0.00106820484002\n",
      "Epoch 2::Minibatch 643::LR 0.0976923076923 --> Loss 0.00288433015347\n",
      "Epoch 2::Minibatch 644::LR 0.0976923076923 --> Loss 0.00449314395587\n",
      "Epoch 2::Minibatch 645::LR 0.0976923076923 --> Loss 0.00510112961133\n",
      "Epoch 2::Minibatch 646::LR 0.0976923076923 --> Loss 0.00234672188759\n",
      "Epoch 2::Minibatch 647::LR 0.0976923076923 --> Loss 0.00180443664392\n",
      "Epoch 2::Minibatch 648::LR 0.0976923076923 --> Loss 0.00385350823402\n",
      "Epoch 2::Minibatch 649::LR 0.0976923076923 --> Loss 0.00423711578051\n",
      "Epoch 2::Minibatch 650::LR 0.0976923076923 --> Loss 0.00402820030848\n",
      "Epoch 2::Minibatch 651::LR 0.0976923076923 --> Loss 0.0021516931057\n",
      "Epoch 2::Minibatch 652::LR 0.0976923076923 --> Loss 0.00181155741215\n",
      "Epoch 2::Minibatch 653::LR 0.0976923076923 --> Loss 0.00343627969424\n",
      "Epoch 2::Minibatch 654::LR 0.0976923076923 --> Loss 0.00348797122637\n",
      "Epoch 2::Minibatch 655::LR 0.0976923076923 --> Loss 0.00385236501694\n",
      "Epoch 2::Minibatch 656::LR 0.0976923076923 --> Loss 0.00121525029341\n",
      "Epoch 2::Minibatch 657::LR 0.0976923076923 --> Loss 0.00251496036847\n",
      "Epoch 2::Minibatch 658::LR 0.0976923076923 --> Loss 0.00604643424352\n",
      "Epoch 2::Minibatch 659::LR 0.0976923076923 --> Loss 0.00271270354589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 660::LR 0.0976923076923 --> Loss 0.00278662880262\n",
      "Epoch 2::Minibatch 661::LR 0.0976923076923 --> Loss 0.00298086623351\n",
      "Epoch 2::Minibatch 662::LR 0.0976923076923 --> Loss 0.00221813877424\n",
      "Epoch 2::Minibatch 663::LR 0.0976923076923 --> Loss 0.00417555451393\n",
      "Epoch 2::Minibatch 664::LR 0.0976923076923 --> Loss 0.00425949851672\n",
      "Epoch 2::Minibatch 665::LR 0.0976923076923 --> Loss 0.00128040244182\n",
      "Epoch 2::Minibatch 666::LR 0.0976923076923 --> Loss 0.00417962948481\n",
      "Epoch 2::Minibatch 667::LR 0.0976923076923 --> Loss 0.00320188502471\n",
      "Epoch 2::Minibatch 668::LR 0.0976923076923 --> Loss 0.00835254271825\n",
      "Epoch 2::Minibatch 669::LR 0.0976923076923 --> Loss 0.00166497518619\n",
      "Epoch 2::Minibatch 670::LR 0.0976923076923 --> Loss 0.00186240593592\n",
      "Epoch 2::Minibatch 671::LR 0.0976923076923 --> Loss 0.00598521073659\n",
      "Epoch 2::Minibatch 672::LR 0.0976923076923 --> Loss 0.00474878152212\n",
      "Epoch 2::Minibatch 673::LR 0.0976923076923 --> Loss 0.00217784186204\n",
      "Epoch 2::Minibatch 674::LR 0.0976923076923 --> Loss 0.00105809231599\n",
      "Epoch 2::Minibatch 675::LR 0.0976923076923 --> Loss 0.00280685842037\n",
      "Epoch 2::Minibatch 676::LR 0.0976923076923 --> Loss 0.00266274193923\n",
      "Epoch 2::Minibatch 677::LR 0.0976923076923 --> Loss 0.00363912940025\n",
      "Epoch 2::Minibatch 678::LR 0.0976923076923 --> Loss 0.00251405060291\n",
      "Epoch 2::Minibatch 679::LR 0.0976923076923 --> Loss 0.00394752422969\n",
      "Epoch 2::Minibatch 680::LR 0.0976923076923 --> Loss 0.00268704593182\n",
      "Epoch 2::Minibatch 681::LR 0.0976923076923 --> Loss 0.00296581546466\n",
      "Epoch 2::Minibatch 682::LR 0.0976923076923 --> Loss 0.00120710889498\n",
      "Epoch 2::Minibatch 683::LR 0.0976923076923 --> Loss 0.00304298758507\n",
      "Epoch 2::Minibatch 684::LR 0.0976923076923 --> Loss 0.00289617657661\n",
      "Epoch 2::Minibatch 685::LR 0.0976923076923 --> Loss 0.00352442979813\n",
      "Epoch 2::Minibatch 686::LR 0.0976923076923 --> Loss 0.00192973335584\n",
      "Epoch 2::Minibatch 687::LR 0.0976923076923 --> Loss 0.00118420739969\n",
      "Epoch 2::Minibatch 688::LR 0.0976923076923 --> Loss 0.00310406128565\n",
      "Epoch 2::Minibatch 689::LR 0.0976923076923 --> Loss 0.00297548313936\n",
      "Epoch 2::Minibatch 690::LR 0.0976923076923 --> Loss 0.00235384861628\n",
      "Epoch 2::Minibatch 691::LR 0.0976923076923 --> Loss 0.000998196899891\n",
      "Epoch 2::Minibatch 692::LR 0.0976923076923 --> Loss 0.00296523928642\n",
      "Epoch 2::Minibatch 693::LR 0.0976923076923 --> Loss 0.00305718918641\n",
      "Epoch 2::Minibatch 694::LR 0.0976923076923 --> Loss 0.00358662486076\n",
      "Epoch 2::Minibatch 695::LR 0.0976923076923 --> Loss 0.00236516098181\n",
      "Epoch 2::Minibatch 696::LR 0.0976923076923 --> Loss 0.00237502535184\n",
      "Epoch 2::Minibatch 697::LR 0.0976923076923 --> Loss 0.00169535358747\n",
      "Epoch 2::Minibatch 698::LR 0.0976923076923 --> Loss 0.00189932366212\n",
      "Epoch 2::Minibatch 699::LR 0.0976923076923 --> Loss 0.00462601304054\n",
      "Epoch 2::Minibatch 700::LR 0.0976923076923 --> Loss 0.00307351410389\n",
      "Epoch 2::Minibatch 701::LR 0.0976923076923 --> Loss 0.00253324349721\n",
      "Epoch 2::Minibatch 702::LR 0.0976923076923 --> Loss 0.00213788688183\n",
      "Epoch 2::Minibatch 703::LR 0.0976923076923 --> Loss 0.00452153841654\n",
      "Epoch 2::Minibatch 704::LR 0.0976923076923 --> Loss 0.00225828488668\n",
      "Epoch 2::Minibatch 705::LR 0.0976923076923 --> Loss 0.00326384941737\n",
      "Epoch 2::Minibatch 706::LR 0.0976923076923 --> Loss 0.00249150017897\n",
      "Epoch 2::Minibatch 707::LR 0.0976923076923 --> Loss 0.00162379195293\n",
      "Epoch 2::Minibatch 708::LR 0.0976923076923 --> Loss 0.00210968395074\n",
      "Epoch 2::Minibatch 709::LR 0.0976923076923 --> Loss 0.00210139155388\n",
      "Epoch 2::Minibatch 710::LR 0.0976923076923 --> Loss 0.00269450823466\n",
      "Epoch 2::Minibatch 711::LR 0.0976923076923 --> Loss 0.00219783703486\n",
      "Epoch 2::Minibatch 712::LR 0.0976923076923 --> Loss 0.00176438351472\n",
      "Epoch 2::Minibatch 713::LR 0.0976923076923 --> Loss 0.00210013687611\n",
      "Epoch 2::Minibatch 714::LR 0.0976923076923 --> Loss 0.00302932997545\n",
      "Epoch 2::Minibatch 715::LR 0.0976923076923 --> Loss 0.00324665705363\n",
      "Epoch 2::Minibatch 716::LR 0.0976923076923 --> Loss 0.00186970452468\n",
      "Epoch 2::Minibatch 717::LR 0.0976923076923 --> Loss 0.00190530359745\n",
      "Epoch 2::Minibatch 718::LR 0.0976923076923 --> Loss 0.00169154405594\n",
      "Epoch 2::Minibatch 719::LR 0.0976923076923 --> Loss 0.00216749370098\n",
      "Epoch 2::Minibatch 720::LR 0.0976923076923 --> Loss 0.00278019309044\n",
      "Epoch 2::Minibatch 721::LR 0.0976923076923 --> Loss 0.00108486672242\n",
      "Epoch 2::Minibatch 722::LR 0.0976923076923 --> Loss 0.00565913955371\n",
      "Epoch 2::Minibatch 723::LR 0.0976923076923 --> Loss 0.0053345255057\n",
      "Epoch 2::Minibatch 724::LR 0.0976923076923 --> Loss 0.00143205066522\n",
      "Epoch 2::Minibatch 725::LR 0.0976923076923 --> Loss 0.00301703155041\n",
      "Epoch 2::Minibatch 726::LR 0.0976923076923 --> Loss 0.00623129049937\n",
      "Epoch 2::Minibatch 727::LR 0.0976923076923 --> Loss 0.00355896313985\n",
      "Epoch 2::Minibatch 728::LR 0.0976923076923 --> Loss 0.00122625807921\n",
      "Epoch 2::Minibatch 729::LR 0.0976923076923 --> Loss 0.0013766041398\n",
      "Epoch 2::Minibatch 730::LR 0.0976923076923 --> Loss 0.00308321674665\n",
      "Epoch 2::Minibatch 731::LR 0.0976923076923 --> Loss 0.00312111636003\n",
      "Epoch 2::Minibatch 732::LR 0.0976923076923 --> Loss 0.00321337779363\n",
      "Epoch 2::Minibatch 733::LR 0.0976923076923 --> Loss 0.00149028370778\n",
      "Epoch 2::Minibatch 734::LR 0.0976923076923 --> Loss 0.00254681924979\n",
      "Epoch 2::Minibatch 735::LR 0.0976923076923 --> Loss 0.00303429603577\n",
      "Epoch 2::Minibatch 736::LR 0.0976923076923 --> Loss 0.00388863563538\n",
      "Epoch 2::Minibatch 737::LR 0.0976923076923 --> Loss 0.00364492416382\n",
      "Epoch 2::Minibatch 738::LR 0.0976923076923 --> Loss 0.00205720126629\n",
      "Epoch 2::Minibatch 739::LR 0.0976923076923 --> Loss 0.00290793319543\n",
      "Epoch 2::Minibatch 740::LR 0.0976923076923 --> Loss 0.0041649278005\n",
      "Epoch 2::Minibatch 741::LR 0.0976923076923 --> Loss 0.00342013080915\n",
      "Epoch 2::Minibatch 742::LR 0.0976923076923 --> Loss 0.00263227323691\n",
      "Epoch 2::Minibatch 743::LR 0.0976923076923 --> Loss 0.00150866617759\n",
      "Epoch 2::Minibatch 744::LR 0.0976923076923 --> Loss 0.00217421650887\n",
      "Epoch 2::Minibatch 745::LR 0.0976923076923 --> Loss 0.00323044081529\n",
      "Epoch 2::Minibatch 746::LR 0.0976923076923 --> Loss 0.00343909621239\n",
      "Epoch 2::Minibatch 747::LR 0.0976923076923 --> Loss 0.0020862185955\n",
      "Epoch 2::Minibatch 748::LR 0.0976923076923 --> Loss 0.000960443913937\n",
      "Epoch 2::Minibatch 749::LR 0.0976923076923 --> Loss 0.00193082928658\n",
      "Epoch 2::Minibatch 750::LR 0.0976923076923 --> Loss 0.00288173158964\n",
      "Epoch 2::Minibatch 751::LR 0.0976923076923 --> Loss 0.00314192930857\n",
      "Epoch 2::Minibatch 752::LR 0.0976923076923 --> Loss 0.00129730552435\n",
      "Epoch 2::Minibatch 753::LR 0.0976923076923 --> Loss 0.00250531415145\n",
      "Epoch 2::Minibatch 754::LR 0.0976923076923 --> Loss 0.00279164731503\n",
      "Epoch 2::Minibatch 755::LR 0.0976923076923 --> Loss 0.00294518649578\n",
      "Epoch 2::Minibatch 756::LR 0.0976923076923 --> Loss 0.00209035873413\n",
      "Epoch 2::Minibatch 757::LR 0.0976923076923 --> Loss 0.00160087486108\n",
      "Epoch 2::Minibatch 758::LR 0.0976923076923 --> Loss 0.0021374921004\n",
      "Epoch 2::Minibatch 759::LR 0.0976923076923 --> Loss 0.00466427008311\n",
      "Epoch 2::Minibatch 760::LR 0.0976923076923 --> Loss 0.00411249955495\n",
      "Epoch 2::Minibatch 761::LR 0.0976923076923 --> Loss 0.0069307812055\n",
      "Epoch 2::Minibatch 762::LR 0.0976923076923 --> Loss 0.00459372997284\n",
      "Epoch 2::Minibatch 763::LR 0.0976923076923 --> Loss 0.00472818692525\n",
      "Epoch 2::Minibatch 764::LR 0.0976923076923 --> Loss 0.00416420022647\n",
      "Epoch 2::Minibatch 765::LR 0.0976923076923 --> Loss 0.00179723441601\n",
      "Epoch 2::Minibatch 766::LR 0.0976923076923 --> Loss 0.00263950387637\n",
      "Epoch 2::Minibatch 767::LR 0.0976923076923 --> Loss 0.00540229042371\n",
      "Epoch 2::Minibatch 768::LR 0.0976923076923 --> Loss 0.00419922351837\n",
      "Epoch 2::Minibatch 769::LR 0.0976923076923 --> Loss 0.00262402832508\n",
      "Epoch 2::Minibatch 770::LR 0.0976923076923 --> Loss 0.00197339554628\n",
      "Epoch 2::Minibatch 771::LR 0.0976923076923 --> Loss 0.00510898113251\n",
      "Epoch 2::Minibatch 772::LR 0.0976923076923 --> Loss 0.00390560189883\n",
      "Epoch 2::Minibatch 773::LR 0.0976923076923 --> Loss 0.00402949929237\n",
      "Epoch 2::Minibatch 774::LR 0.0976923076923 --> Loss 0.00231108546257\n",
      "Epoch 2::Minibatch 775::LR 0.0976923076923 --> Loss 0.00612898031871\n",
      "Epoch 2::Minibatch 776::LR 0.0976923076923 --> Loss 0.00420581936836\n",
      "Epoch 2::Minibatch 777::LR 0.0976923076923 --> Loss 0.00795185407003\n",
      "Epoch 2::Minibatch 778::LR 0.0976923076923 --> Loss 0.0152571137746\n",
      "Epoch 2::Minibatch 779::LR 0.0976923076923 --> Loss 0.0019494364659\n",
      "Epoch 2::Minibatch 780::LR 0.0976923076923 --> Loss 0.002087499698\n",
      "Epoch 2::Minibatch 781::LR 0.0976923076923 --> Loss 0.00449319005013\n",
      "Epoch 2::Minibatch 782::LR 0.0976923076923 --> Loss 0.00504111091296\n",
      "Epoch 2::Minibatch 783::LR 0.0976923076923 --> Loss 0.00303894301256\n",
      "Epoch 2::Minibatch 784::LR 0.0976923076923 --> Loss 0.00136474778255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 785::LR 0.0976923076923 --> Loss 0.00547578891118\n",
      "Epoch 2::Minibatch 786::LR 0.0976923076923 --> Loss 0.0047585050265\n",
      "Epoch 2::Minibatch 787::LR 0.0976923076923 --> Loss 0.00387250026067\n",
      "Epoch 2::Minibatch 788::LR 0.0976923076923 --> Loss 0.00337985038757\n",
      "Epoch 2::Minibatch 789::LR 0.0976923076923 --> Loss 0.00105229020119\n",
      "Epoch 2::Minibatch 790::LR 0.0976923076923 --> Loss 0.00397831877073\n",
      "Epoch 2::Minibatch 791::LR 0.0976923076923 --> Loss 0.00511840383212\n",
      "Epoch 2::Minibatch 792::LR 0.0976923076923 --> Loss 0.00530236323675\n",
      "Epoch 2::Minibatch 793::LR 0.0976923076923 --> Loss 0.00340106407801\n",
      "Epoch 2::Minibatch 794::LR 0.0976923076923 --> Loss 0.00224514047305\n",
      "Epoch 2::Minibatch 795::LR 0.0976923076923 --> Loss 0.00502636392911\n",
      "Epoch 2::Minibatch 796::LR 0.0976923076923 --> Loss 0.00752666473389\n",
      "Epoch 2::Minibatch 797::LR 0.0976923076923 --> Loss 0.0129895162582\n",
      "Epoch 2::Minibatch 798::LR 0.0976923076923 --> Loss 0.00448162476222\n",
      "Epoch 2::Minibatch 799::LR 0.0976923076923 --> Loss 0.00414014935493\n",
      "Epoch 2::Minibatch 800::LR 0.0976923076923 --> Loss 0.00282400647799\n",
      "Epoch 2::Minibatch 801::LR 0.0976923076923 --> Loss 0.0043622593085\n",
      "Epoch 2::Minibatch 802::LR 0.0976923076923 --> Loss 0.00197747568289\n",
      "Epoch 2::Minibatch 803::LR 0.0976923076923 --> Loss 0.00291606843472\n",
      "Epoch 2::Minibatch 804::LR 0.0976923076923 --> Loss 0.00298574606578\n",
      "Epoch 2::Minibatch 805::LR 0.0976923076923 --> Loss 0.00287020345529\n",
      "Epoch 2::Minibatch 806::LR 0.0976923076923 --> Loss 0.00368055184682\n",
      "Epoch 2::Minibatch 807::LR 0.0976923076923 --> Loss 0.00365352114042\n",
      "Epoch 2::Minibatch 808::LR 0.0976923076923 --> Loss 0.00391308546066\n",
      "Epoch 2::Minibatch 809::LR 0.0976923076923 --> Loss 0.00634158054988\n",
      "Epoch 2::Minibatch 810::LR 0.0976923076923 --> Loss 0.00763763189316\n",
      "Epoch 2::Minibatch 811::LR 0.0976923076923 --> Loss 0.00660353024801\n",
      "Epoch 2::Minibatch 812::LR 0.0976923076923 --> Loss 0.00943452517192\n",
      "Epoch 2::Minibatch 813::LR 0.0976923076923 --> Loss 0.00647707303365\n",
      "Epoch 2::Minibatch 814::LR 0.0976923076923 --> Loss 0.00435365239779\n",
      "Epoch 2::Minibatch 815::LR 0.0976923076923 --> Loss 0.0061663377285\n",
      "Epoch 2::Minibatch 816::LR 0.0976923076923 --> Loss 0.00569101850192\n",
      "Epoch 2::Minibatch 817::LR 0.0976923076923 --> Loss 0.0058153017362\n",
      "Epoch 2::Minibatch 818::LR 0.0976923076923 --> Loss 0.00265593528748\n",
      "Epoch 2::Minibatch 819::LR 0.0976923076923 --> Loss 0.00171134412289\n",
      "Epoch 2::Minibatch 820::LR 0.0976923076923 --> Loss 0.00690613508224\n",
      "Epoch 2::Minibatch 821::LR 0.0976923076923 --> Loss 0.00457503994306\n",
      "Epoch 2::Minibatch 822::LR 0.0976923076923 --> Loss 0.00555095235507\n",
      "Epoch 2::Minibatch 823::LR 0.0976923076923 --> Loss 0.0018878664573\n",
      "Epoch 2::Minibatch 824::LR 0.0976923076923 --> Loss 0.00208119253318\n",
      "Epoch 2::Minibatch 825::LR 0.0976923076923 --> Loss 0.00479384938876\n",
      "Epoch 2::Minibatch 826::LR 0.0976923076923 --> Loss 0.00477136850357\n",
      "Epoch 2::Minibatch 827::LR 0.0976923076923 --> Loss 0.00356736421585\n",
      "Epoch 2::Minibatch 828::LR 0.0976923076923 --> Loss 0.00179904838403\n",
      "Epoch 2::Minibatch 829::LR 0.0976923076923 --> Loss 0.00328750610352\n",
      "Epoch 2::Minibatch 830::LR 0.0976923076923 --> Loss 0.00542007605235\n",
      "Epoch 2::Minibatch 831::LR 0.0976923076923 --> Loss 0.00311858832836\n",
      "Epoch 2::Minibatch 832::LR 0.0976923076923 --> Loss 0.00285699605942\n",
      "Epoch 2::Minibatch 833::LR 0.0976923076923 --> Loss 0.00233690440655\n",
      "Epoch 2::Minibatch 834::LR 0.0976923076923 --> Loss 0.00113942563534\n",
      "Epoch 2::Minibatch 835::LR 0.0976923076923 --> Loss 0.00446236371994\n",
      "Epoch 2::Minibatch 836::LR 0.0976923076923 --> Loss 0.00506866335869\n",
      "Epoch 2::Minibatch 837::LR 0.0976923076923 --> Loss 0.00405432939529\n",
      "Epoch 2::Minibatch 838::LR 0.0976923076923 --> Loss 0.00199228823185\n",
      "Epoch 2::Minibatch 839::LR 0.0976923076923 --> Loss 0.00362876931826\n",
      "Epoch 2::Minibatch 840::LR 0.0976923076923 --> Loss 0.00427367011706\n",
      "Epoch 2::Minibatch 841::LR 0.0976923076923 --> Loss 0.00464386622111\n",
      "Epoch 2::Minibatch 842::LR 0.0976923076923 --> Loss 0.00355117718379\n",
      "Epoch 2::Minibatch 843::LR 0.0976923076923 --> Loss 0.00141130675872\n",
      "Epoch 2::Minibatch 844::LR 0.0976923076923 --> Loss 0.00215444942315\n",
      "Epoch 2::Minibatch 845::LR 0.0976923076923 --> Loss 0.00478773991267\n",
      "Epoch 2::Minibatch 846::LR 0.0976923076923 --> Loss 0.00231851041317\n",
      "Epoch 2::Minibatch 847::LR 0.0976923076923 --> Loss 0.00391825119654\n",
      "Epoch 2::Minibatch 848::LR 0.0976923076923 --> Loss 0.00234517633915\n",
      "Epoch 2::Minibatch 849::LR 0.0976923076923 --> Loss 0.00304459154606\n",
      "Epoch 2::Minibatch 850::LR 0.0976923076923 --> Loss 0.00407710591952\n",
      "Epoch 2::Minibatch 851::LR 0.0976923076923 --> Loss 0.00415089527766\n",
      "Epoch 2::Minibatch 852::LR 0.0976923076923 --> Loss 0.00214538097382\n",
      "Epoch 2::Minibatch 853::LR 0.0976923076923 --> Loss 0.0021596622467\n",
      "Epoch 2::Minibatch 854::LR 0.0976923076923 --> Loss 0.00286253114541\n",
      "Epoch 2::Minibatch 855::LR 0.0976923076923 --> Loss 0.0025087060531\n",
      "Epoch 2::Minibatch 856::LR 0.0976923076923 --> Loss 0.00215049207211\n",
      "Epoch 2::Minibatch 857::LR 0.0976923076923 --> Loss 0.00149561464787\n",
      "Epoch 2::Minibatch 858::LR 0.0976923076923 --> Loss 0.00094481309255\n",
      "Epoch 2::Minibatch 859::LR 0.0976923076923 --> Loss 0.0021566671133\n",
      "Epoch 2::Minibatch 860::LR 0.0976923076923 --> Loss 0.00147655934095\n",
      "Epoch 2::Minibatch 861::LR 0.0976923076923 --> Loss 0.00118181139231\n",
      "Epoch 2::Minibatch 862::LR 0.0976923076923 --> Loss 0.00398845632871\n",
      "Epoch 2::Minibatch 863::LR 0.0976923076923 --> Loss 0.00395365079244\n",
      "Epoch 2::Minibatch 864::LR 0.0976923076923 --> Loss 0.00438949863116\n",
      "Epoch 2::Minibatch 865::LR 0.0976923076923 --> Loss 0.00183359205723\n",
      "Epoch 2::Minibatch 866::LR 0.0976923076923 --> Loss 0.00282641987006\n",
      "Epoch 2::Minibatch 867::LR 0.0976923076923 --> Loss 0.00422004739443\n",
      "Epoch 2::Minibatch 868::LR 0.0976923076923 --> Loss 0.00410931229591\n",
      "Epoch 2::Minibatch 869::LR 0.0976923076923 --> Loss 0.00306197524071\n",
      "Epoch 2::Minibatch 870::LR 0.0976923076923 --> Loss 0.00420568505923\n",
      "Epoch 2::Minibatch 871::LR 0.0976923076923 --> Loss 0.00240379909674\n",
      "Epoch 2::Minibatch 872::LR 0.0976923076923 --> Loss 0.003570510149\n",
      "Epoch 2::Minibatch 873::LR 0.0976923076923 --> Loss 0.00356013854345\n",
      "Epoch 2::Minibatch 874::LR 0.0976923076923 --> Loss 0.00743284781774\n",
      "Epoch 2::Minibatch 875::LR 0.0976923076923 --> Loss 0.00145109216372\n",
      "Epoch 2::Minibatch 876::LR 0.0976923076923 --> Loss 0.0053870566686\n",
      "Epoch 2::Minibatch 877::LR 0.0976923076923 --> Loss 0.00429362654686\n",
      "Epoch 2::Minibatch 878::LR 0.0976923076923 --> Loss 0.00428107659022\n",
      "Epoch 2::Minibatch 879::LR 0.0976923076923 --> Loss 0.00472373366356\n",
      "Epoch 2::Minibatch 880::LR 0.0976923076923 --> Loss 0.00468773126602\n",
      "Epoch 2::Minibatch 881::LR 0.0976923076923 --> Loss 0.00501304189364\n",
      "Epoch 2::Minibatch 882::LR 0.0976923076923 --> Loss 0.00273966828982\n",
      "Epoch 2::Minibatch 883::LR 0.0976923076923 --> Loss 0.00358838796616\n",
      "Epoch 2::Minibatch 884::LR 0.0976923076923 --> Loss 0.00290479381879\n",
      "Epoch 2::Minibatch 885::LR 0.0976923076923 --> Loss 0.00327616671721\n",
      "Epoch 2::Minibatch 886::LR 0.0976923076923 --> Loss 0.00163059959809\n",
      "Epoch 2::Minibatch 887::LR 0.0976923076923 --> Loss 0.00623960892359\n",
      "Epoch 2::Minibatch 888::LR 0.0976923076923 --> Loss 0.00293764154116\n",
      "Epoch 2::Minibatch 889::LR 0.0976923076923 --> Loss 0.00462618390719\n",
      "Epoch 2::Minibatch 890::LR 0.0976923076923 --> Loss 0.0056100221475\n",
      "Epoch 2::Minibatch 891::LR 0.0976923076923 --> Loss 0.00306935111682\n",
      "Epoch 2::Minibatch 892::LR 0.0976923076923 --> Loss 0.00147193173567\n",
      "Epoch 2::Minibatch 893::LR 0.0976923076923 --> Loss 0.00331675052643\n",
      "Epoch 2::Minibatch 894::LR 0.0976923076923 --> Loss 0.00303078472614\n",
      "Epoch 2::Minibatch 895::LR 0.0976923076923 --> Loss 0.00312087555726\n",
      "Epoch 2::Minibatch 896::LR 0.0976923076923 --> Loss 0.00222069958846\n",
      "Epoch 2::Minibatch 897::LR 0.0976923076923 --> Loss 0.00121736764908\n",
      "Epoch 2::Minibatch 898::LR 0.0976923076923 --> Loss 0.00284557302793\n",
      "Epoch 2::Minibatch 899::LR 0.0976923076923 --> Loss 0.00275448123614\n",
      "Epoch 2::Minibatch 900::LR 0.0976923076923 --> Loss 0.0037406818072\n",
      "Epoch 2::Minibatch 901::LR 0.0976923076923 --> Loss 0.00094610273838\n",
      "Epoch 2::Minibatch 902::LR 0.0976923076923 --> Loss 0.00173733135064\n",
      "Epoch 2::Minibatch 903::LR 0.0976923076923 --> Loss 0.00330582718054\n",
      "Epoch 2::Minibatch 904::LR 0.0976923076923 --> Loss 0.00285369038582\n",
      "Epoch 2::Minibatch 905::LR 0.0976923076923 --> Loss 0.00173507988453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 906::LR 0.0976923076923 --> Loss 0.00129724631707\n",
      "Epoch 2::Minibatch 907::LR 0.0976923076923 --> Loss 0.0016250166297\n",
      "Epoch 2::Minibatch 908::LR 0.0976923076923 --> Loss 0.00348899960518\n",
      "Epoch 2::Minibatch 909::LR 0.0976923076923 --> Loss 0.00310965637366\n",
      "Epoch 2::Minibatch 910::LR 0.0976923076923 --> Loss 0.0010333742698\n",
      "Epoch 2::Minibatch 911::LR 0.0976923076923 --> Loss 0.00146665285031\n",
      "Epoch 2::Minibatch 912::LR 0.0976923076923 --> Loss 0.00291939914227\n",
      "Epoch 2::Minibatch 913::LR 0.0976923076923 --> Loss 0.00239230612914\n",
      "Epoch 2::Minibatch 914::LR 0.0976923076923 --> Loss 0.00159058938424\n",
      "Epoch 2::Minibatch 915::LR 0.0976923076923 --> Loss 0.000692441761494\n",
      "Epoch 2::Minibatch 916::LR 0.0976923076923 --> Loss 0.00329365551472\n",
      "Epoch 2::Minibatch 917::LR 0.0976923076923 --> Loss 0.00530757546425\n",
      "Epoch 2::Minibatch 918::LR 0.0976923076923 --> Loss 0.0117566140493\n",
      "Epoch 2::Minibatch 919::LR 0.0976923076923 --> Loss 0.00222833633423\n",
      "Epoch 2::Minibatch 920::LR 0.0976923076923 --> Loss 0.00883103688558\n",
      "Epoch 2::Minibatch 921::LR 0.0976923076923 --> Loss 0.00451174855232\n",
      "Epoch 2::Minibatch 922::LR 0.0976923076923 --> Loss 0.0046278210481\n",
      "Epoch 2::Minibatch 923::LR 0.0976923076923 --> Loss 0.00303150177002\n",
      "Epoch 2::Minibatch 924::LR 0.0976923076923 --> Loss 0.00467470407486\n",
      "Epoch 2::Minibatch 925::LR 0.0976923076923 --> Loss 0.00445584257444\n",
      "Epoch 2::Minibatch 926::LR 0.0976923076923 --> Loss 0.00716307004293\n",
      "Epoch 2::Minibatch 927::LR 0.0976923076923 --> Loss 0.0127506717046\n",
      "Epoch 2::Minibatch 928::LR 0.0976923076923 --> Loss 0.0083464550972\n",
      "Epoch 2::Minibatch 929::LR 0.0976923076923 --> Loss 0.0133918619156\n",
      "Epoch 2::Minibatch 930::LR 0.0976923076923 --> Loss 0.00807221333186\n",
      "Epoch 2::Minibatch 931::LR 0.0976923076923 --> Loss 0.00582519491514\n",
      "Epoch 2::Minibatch 932::LR 0.0976923076923 --> Loss 0.0126956415176\n",
      "Epoch 2::Minibatch 933::LR 0.0976923076923 --> Loss 0.00701078255971\n",
      "Epoch 2::Minibatch 934::LR 0.0976923076923 --> Loss 0.00917354742686\n",
      "Epoch 2::Minibatch 935::LR 0.0976923076923 --> Loss 0.0109943739573\n",
      "Epoch 2::Minibatch 936::LR 0.0976923076923 --> Loss 0.00490376234055\n",
      "Epoch 2::Minibatch 937::LR 0.0976923076923 --> Loss 0.00691195964813\n",
      "Epoch 2::Minibatch 938::LR 0.0976923076923 --> Loss 0.00674135684967\n",
      "Epoch 2::Minibatch 939::LR 0.0976923076923 --> Loss 0.00712258021037\n",
      "Epoch 2::Minibatch 940::LR 0.0976923076923 --> Loss 0.00200078686078\n",
      "Epoch 2::Minibatch 941::LR 0.0976923076923 --> Loss 0.00179310897986\n",
      "Epoch 2::Minibatch 942::LR 0.0976923076923 --> Loss 0.00324742436409\n",
      "Epoch 2::Minibatch 943::LR 0.0976923076923 --> Loss 0.00553518374761\n",
      "Epoch 2::Minibatch 944::LR 0.0976923076923 --> Loss 0.00498690923055\n",
      "Epoch 2::Minibatch 945::LR 0.0976923076923 --> Loss 0.00363323529561\n",
      "Epoch 2::Minibatch 946::LR 0.0976923076923 --> Loss 0.00595238367716\n",
      "Epoch 2::Minibatch 947::LR 0.0976923076923 --> Loss 0.00524014274279\n",
      "Epoch 2::Minibatch 948::LR 0.0976923076923 --> Loss 0.00787184556325\n",
      "Epoch 2::Minibatch 949::LR 0.0976923076923 --> Loss 0.00290695865949\n",
      "Epoch 2::Minibatch 950::LR 0.0976923076923 --> Loss 0.00115307658911\n",
      "Epoch 2::Minibatch 951::LR 0.0976923076923 --> Loss 0.00419840574265\n",
      "Epoch 2::Minibatch 952::LR 0.0976923076923 --> Loss 0.00324612696966\n",
      "Epoch 2::Minibatch 953::LR 0.0976923076923 --> Loss 0.00171541035175\n",
      "Epoch 2::Minibatch 954::LR 0.0976923076923 --> Loss 0.00136072466771\n",
      "Epoch 2::Minibatch 955::LR 0.0976923076923 --> Loss 0.00308478633563\n",
      "Epoch 2::Minibatch 956::LR 0.0976923076923 --> Loss 0.00623716791471\n",
      "Epoch 2::Minibatch 957::LR 0.0976923076923 --> Loss 0.00272583782673\n",
      "Epoch 2::Minibatch 958::LR 0.0976923076923 --> Loss 0.004211059014\n",
      "Epoch 2::Minibatch 959::LR 0.0976923076923 --> Loss 0.00502939343452\n",
      "Epoch 2::Minibatch 960::LR 0.0976923076923 --> Loss 0.00812776327133\n",
      "Epoch 2::Minibatch 961::LR 0.0976923076923 --> Loss 0.0049161307017\n",
      "Epoch 2::Minibatch 962::LR 0.0976923076923 --> Loss 0.00444459637006\n",
      "Epoch 2::Minibatch 963::LR 0.0976923076923 --> Loss 0.00334558010101\n",
      "Epoch 2::Minibatch 964::LR 0.0976923076923 --> Loss 0.00414737224579\n",
      "Epoch 2::Minibatch 965::LR 0.0976923076923 --> Loss 0.0110931539536\n",
      "Epoch 2::Minibatch 966::LR 0.0976923076923 --> Loss 0.00833433230718\n",
      "Epoch 2::Minibatch 967::LR 0.0976923076923 --> Loss 0.00366985678673\n",
      "Epoch 2::Minibatch 968::LR 0.0976923076923 --> Loss 0.00333148618539\n",
      "Epoch 2::Minibatch 969::LR 0.0976923076923 --> Loss 0.00908670028051\n",
      "Epoch 2::Minibatch 970::LR 0.0976923076923 --> Loss 0.0105502708753\n",
      "Epoch 2::Minibatch 971::LR 0.0976923076923 --> Loss 0.00616587082545\n",
      "Epoch 2::Minibatch 972::LR 0.0976923076923 --> Loss 0.00769003311793\n",
      "Epoch 2::Minibatch 973::LR 0.0976923076923 --> Loss 0.013526023229\n",
      "Epoch 2::Minibatch 974::LR 0.0976923076923 --> Loss 0.00975379705429\n",
      "Epoch 2::Minibatch 975::LR 0.0976923076923 --> Loss 0.00721635739009\n",
      "Epoch 2::Minibatch 976::LR 0.0976923076923 --> Loss 0.00625963687897\n",
      "Epoch 2::Minibatch 977::LR 0.0976923076923 --> Loss 0.00641613483429\n",
      "Epoch 2::Minibatch 978::LR 0.0976923076923 --> Loss 0.00690230449041\n",
      "Epoch 2::Minibatch 979::LR 0.0976923076923 --> Loss 0.00734090566635\n",
      "Epoch 2::Minibatch 980::LR 0.0976923076923 --> Loss 0.00515208443006\n",
      "Epoch 2::Minibatch 981::LR 0.0976923076923 --> Loss 0.00771280527115\n",
      "Epoch 2::Minibatch 982::LR 0.0976923076923 --> Loss 0.00876556714376\n",
      "Epoch 2::Minibatch 983::LR 0.0976923076923 --> Loss 0.00480656981468\n",
      "Epoch 2::Minibatch 984::LR 0.0976923076923 --> Loss 0.00519328077634\n",
      "Epoch 2::Minibatch 985::LR 0.0976923076923 --> Loss 0.006716457208\n",
      "Epoch 2::Minibatch 986::LR 0.0976923076923 --> Loss 0.00627314448357\n",
      "Epoch 2::Minibatch 987::LR 0.0976923076923 --> Loss 0.00654613057772\n",
      "Epoch 2::Minibatch 988::LR 0.0976923076923 --> Loss 0.00530916611354\n",
      "Epoch 2::Minibatch 989::LR 0.0976923076923 --> Loss 0.00492732286453\n",
      "Epoch 2::Minibatch 990::LR 0.0976923076923 --> Loss 0.00476898749669\n",
      "Epoch 2::Minibatch 991::LR 0.0976923076923 --> Loss 0.0032092521588\n",
      "Epoch 2::Minibatch 992::LR 0.0976923076923 --> Loss 0.00328532318274\n",
      "Epoch 2::Minibatch 993::LR 0.0976923076923 --> Loss 0.00444885691007\n",
      "Epoch 2::Minibatch 994::LR 0.0976923076923 --> Loss 0.00299690723419\n",
      "Epoch 2::Minibatch 995::LR 0.0976923076923 --> Loss 0.00151154329379\n",
      "Epoch 2::Minibatch 996::LR 0.0976923076923 --> Loss 0.0051069410642\n",
      "Epoch 2::Minibatch 997::LR 0.0976923076923 --> Loss 0.00275633494059\n",
      "Epoch 2::Minibatch 998::LR 0.0976923076923 --> Loss 0.00300045450528\n",
      "Epoch 2::Minibatch 999::LR 0.0976923076923 --> Loss 0.00259184559186\n",
      "Epoch 2::Minibatch 1000::LR 0.0976923076923 --> Loss 0.00285299758116\n",
      "Epoch 2::Minibatch 1001::LR 0.0976923076923 --> Loss 0.00259104132652\n",
      "Epoch 2::Minibatch 1002::LR 0.0976923076923 --> Loss 0.0127416976293\n",
      "Epoch 2::Minibatch 1003::LR 0.0976923076923 --> Loss 0.00959806283315\n",
      "Epoch 2::Minibatch 1004::LR 0.0976923076923 --> Loss 0.00160912861427\n",
      "Epoch 2::Minibatch 1005::LR 0.0976923076923 --> Loss 0.0126524845759\n",
      "Epoch 2::Minibatch 1006::LR 0.0976923076923 --> Loss 0.0110598985354\n",
      "Epoch 2::Minibatch 1007::LR 0.0976923076923 --> Loss 0.00800571521123\n",
      "Epoch 2::Minibatch 1008::LR 0.0976923076923 --> Loss 0.00149296681086\n",
      "Epoch 2::Minibatch 1009::LR 0.0976923076923 --> Loss 0.00628800233205\n",
      "Epoch 2::Minibatch 1010::LR 0.0976923076923 --> Loss 0.00480374654134\n",
      "Epoch 2::Minibatch 1011::LR 0.0976923076923 --> Loss 0.00726403633753\n",
      "Epoch 2::Minibatch 1012::LR 0.0976923076923 --> Loss 0.0039338350296\n",
      "Epoch 2::Minibatch 1013::LR 0.0976923076923 --> Loss 0.00639085213343\n",
      "Epoch 2::Minibatch 1014::LR 0.0976923076923 --> Loss 0.0060033082962\n",
      "Epoch 2::Minibatch 1015::LR 0.0976923076923 --> Loss 0.00290104210377\n",
      "Epoch 2::Minibatch 1016::LR 0.0976923076923 --> Loss 0.00517535726229\n",
      "Epoch 2::Minibatch 1017::LR 0.0976923076923 --> Loss 0.00358872969945\n",
      "Epoch 2::Minibatch 1018::LR 0.0976923076923 --> Loss 0.0043000626564\n",
      "Epoch 2::Minibatch 1019::LR 0.0976923076923 --> Loss 0.00359803040822\n",
      "Epoch 2::Minibatch 1020::LR 0.0976923076923 --> Loss 0.00336558620135\n",
      "Epoch 2::Minibatch 1021::LR 0.0976923076923 --> Loss 0.00309148470561\n",
      "Epoch 2::Minibatch 1022::LR 0.0976923076923 --> Loss 0.00249176661174\n",
      "Epoch 2::Minibatch 1023::LR 0.0976923076923 --> Loss 0.00215215464433\n",
      "Epoch 2::Minibatch 1024::LR 0.0976923076923 --> Loss 0.00201493740082\n",
      "Epoch 2::Minibatch 1025::LR 0.0976923076923 --> Loss 0.00273270428181\n",
      "Epoch 2::Minibatch 1026::LR 0.0976923076923 --> Loss 0.00243504405022\n",
      "Epoch 2::Minibatch 1027::LR 0.0976923076923 --> Loss 0.00224893152714\n",
      "Epoch 2::Minibatch 1028::LR 0.0976923076923 --> Loss 0.00176631569862\n",
      "Epoch 2::Minibatch 1029::LR 0.0976923076923 --> Loss 0.00154779960712\n",
      "Epoch 2::Minibatch 1030::LR 0.0976923076923 --> Loss 0.00159358183543\n",
      "Epoch 2::Minibatch 1031::LR 0.0976923076923 --> Loss 0.00121312807004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 1032::LR 0.0976923076923 --> Loss 0.00106727540493\n",
      "Epoch 2::Minibatch 1033::LR 0.0976923076923 --> Loss 0.000799097766479\n",
      "Epoch 2::Minibatch 1034::LR 0.0976923076923 --> Loss 0.000833967924118\n",
      "Epoch 2::Minibatch 1035::LR 0.0976923076923 --> Loss 0.000682447055976\n",
      "Epoch 2::Minibatch 1036::LR 0.0976923076923 --> Loss 0.000449011772871\n",
      "Epoch 2::Minibatch 1037::LR 0.0976923076923 --> Loss 0.000615424960852\n",
      "Epoch 2::Minibatch 1038::LR 0.0976923076923 --> Loss 0.00155126372973\n",
      "Epoch 2::Minibatch 1039::LR 0.0976923076923 --> Loss 0.00137006113927\n",
      "Epoch 2::Minibatch 1040::LR 0.0976923076923 --> Loss 0.000686295380195\n",
      "Epoch 2::Minibatch 1041::LR 0.0976923076923 --> Loss 0.00073248843352\n",
      "Epoch 3::Minibatch 1::LR 0.0953846153846 --> Loss 0.0295447603861\n",
      "Epoch 3::Minibatch 2::LR 0.0953846153846 --> Loss 0.0233552249273\n",
      "Epoch 3::Minibatch 3::LR 0.0953846153846 --> Loss 0.0241886456807\n",
      "Epoch 3::Minibatch 4::LR 0.0953846153846 --> Loss 0.019092892011\n",
      "Epoch 3::Minibatch 5::LR 0.0953846153846 --> Loss 0.0145583025614\n",
      "Epoch 3::Minibatch 6::LR 0.0953846153846 --> Loss 0.00752751747767\n",
      "Epoch 3::Minibatch 7::LR 0.0953846153846 --> Loss 0.0138770723343\n",
      "Epoch 3::Minibatch 8::LR 0.0953846153846 --> Loss 0.0171675459544\n",
      "Epoch 3::Minibatch 9::LR 0.0953846153846 --> Loss 0.0134628852208\n",
      "Epoch 3::Minibatch 10::LR 0.0953846153846 --> Loss 0.00872730811437\n",
      "Epoch 3::Minibatch 11::LR 0.0953846153846 --> Loss 0.00678408702215\n",
      "Epoch 3::Minibatch 12::LR 0.0953846153846 --> Loss 0.0101920215289\n",
      "Epoch 3::Minibatch 13::LR 0.0953846153846 --> Loss 0.0112561988831\n",
      "Epoch 3::Minibatch 14::LR 0.0953846153846 --> Loss 0.010198264122\n",
      "Epoch 3::Minibatch 15::LR 0.0953846153846 --> Loss 0.00786516189575\n",
      "Epoch 3::Minibatch 16::LR 0.0953846153846 --> Loss 0.00300583442052\n",
      "Epoch 3::Minibatch 17::LR 0.0953846153846 --> Loss 0.00589212973913\n",
      "Epoch 3::Minibatch 18::LR 0.0953846153846 --> Loss 0.00586501042048\n",
      "Epoch 3::Minibatch 19::LR 0.0953846153846 --> Loss 0.00218335092068\n",
      "Epoch 3::Minibatch 20::LR 0.0953846153846 --> Loss 0.00268471856912\n",
      "Epoch 3::Minibatch 21::LR 0.0953846153846 --> Loss 0.00524761676788\n",
      "Epoch 3::Minibatch 22::LR 0.0953846153846 --> Loss 0.00441831787427\n",
      "Epoch 3::Minibatch 23::LR 0.0953846153846 --> Loss 0.00248483816783\n",
      "Epoch 3::Minibatch 24::LR 0.0953846153846 --> Loss 0.00119600494703\n",
      "Epoch 3::Minibatch 25::LR 0.0953846153846 --> Loss 0.00220036784808\n",
      "Epoch 3::Minibatch 26::LR 0.0953846153846 --> Loss 0.00275572498639\n",
      "Epoch 3::Minibatch 27::LR 0.0953846153846 --> Loss 0.00266617933909\n",
      "Epoch 3::Minibatch 28::LR 0.0953846153846 --> Loss 0.00115871240695\n",
      "Epoch 3::Minibatch 29::LR 0.0953846153846 --> Loss 0.000818223953247\n",
      "Epoch 3::Minibatch 30::LR 0.0953846153846 --> Loss 0.00150348514318\n",
      "Epoch 3::Minibatch 31::LR 0.0953846153846 --> Loss 0.00254304409027\n",
      "Epoch 3::Minibatch 32::LR 0.0953846153846 --> Loss 0.00275073250135\n",
      "Epoch 3::Minibatch 33::LR 0.0953846153846 --> Loss 0.00105109006166\n",
      "Epoch 3::Minibatch 34::LR 0.0953846153846 --> Loss 0.00323503116767\n",
      "Epoch 3::Minibatch 35::LR 0.0953846153846 --> Loss 0.00420015692711\n",
      "Epoch 3::Minibatch 36::LR 0.0953846153846 --> Loss 0.00307712177436\n",
      "Epoch 3::Minibatch 37::LR 0.0953846153846 --> Loss 0.000919378300508\n",
      "Epoch 3::Minibatch 38::LR 0.0953846153846 --> Loss 0.00116791844368\n",
      "Epoch 3::Minibatch 39::LR 0.0953846153846 --> Loss 0.00214069604874\n",
      "Epoch 3::Minibatch 40::LR 0.0953846153846 --> Loss 0.00404830574989\n",
      "Epoch 3::Minibatch 41::LR 0.0953846153846 --> Loss 0.0039544971784\n",
      "Epoch 3::Minibatch 42::LR 0.0953846153846 --> Loss 0.00500595569611\n",
      "Epoch 3::Minibatch 43::LR 0.0953846153846 --> Loss 0.00209220767021\n",
      "Epoch 3::Minibatch 44::LR 0.0953846153846 --> Loss 0.0027915195624\n",
      "Epoch 3::Minibatch 45::LR 0.0953846153846 --> Loss 0.00301520387332\n",
      "Epoch 3::Minibatch 46::LR 0.0953846153846 --> Loss 0.00392446358999\n",
      "Epoch 3::Minibatch 47::LR 0.0953846153846 --> Loss 0.0047785226504\n",
      "Epoch 3::Minibatch 48::LR 0.0953846153846 --> Loss 0.0057774968942\n",
      "Epoch 3::Minibatch 49::LR 0.0953846153846 --> Loss 0.00653316656748\n",
      "Epoch 3::Minibatch 50::LR 0.0953846153846 --> Loss 0.00501680413882\n",
      "Epoch 3::Minibatch 51::LR 0.0953846153846 --> Loss 0.0101769367854\n",
      "Epoch 3::Minibatch 52::LR 0.0953846153846 --> Loss 0.00375517249107\n",
      "Epoch 3::Minibatch 53::LR 0.0953846153846 --> Loss 0.00362670858701\n",
      "Epoch 3::Minibatch 54::LR 0.0953846153846 --> Loss 0.00434538404147\n",
      "Epoch 3::Minibatch 55::LR 0.0953846153846 --> Loss 0.00204011718432\n",
      "Epoch 3::Minibatch 56::LR 0.0953846153846 --> Loss 0.00374805768331\n",
      "Epoch 3::Minibatch 57::LR 0.0953846153846 --> Loss 0.00621638615926\n",
      "Epoch 3::Minibatch 58::LR 0.0953846153846 --> Loss 0.00459533174833\n",
      "Epoch 3::Minibatch 59::LR 0.0953846153846 --> Loss 0.00418738126755\n",
      "Epoch 3::Minibatch 60::LR 0.0953846153846 --> Loss 0.00332548459371\n",
      "Epoch 3::Minibatch 61::LR 0.0953846153846 --> Loss 0.00167257706324\n",
      "Epoch 3::Minibatch 62::LR 0.0953846153846 --> Loss 0.00409280220668\n",
      "Epoch 3::Minibatch 63::LR 0.0953846153846 --> Loss 0.00291363875071\n",
      "Epoch 3::Minibatch 64::LR 0.0953846153846 --> Loss 0.00154634426037\n",
      "Epoch 3::Minibatch 65::LR 0.0953846153846 --> Loss 0.0028129474322\n",
      "Epoch 3::Minibatch 66::LR 0.0953846153846 --> Loss 0.00376299063365\n",
      "Epoch 3::Minibatch 67::LR 0.0953846153846 --> Loss 0.00343605875969\n",
      "Epoch 3::Minibatch 68::LR 0.0953846153846 --> Loss 0.00232168138027\n",
      "Epoch 3::Minibatch 69::LR 0.0953846153846 --> Loss 0.00400299072266\n",
      "Epoch 3::Minibatch 70::LR 0.0953846153846 --> Loss 0.00379266897837\n",
      "Epoch 3::Minibatch 71::LR 0.0953846153846 --> Loss 0.0030837593476\n",
      "Epoch 3::Minibatch 72::LR 0.0953846153846 --> Loss 0.000784735580285\n",
      "Epoch 3::Minibatch 73::LR 0.0953846153846 --> Loss 0.00366046388944\n",
      "Epoch 3::Minibatch 74::LR 0.0953846153846 --> Loss 0.00509867866834\n",
      "Epoch 3::Minibatch 75::LR 0.0953846153846 --> Loss 0.00260629932086\n",
      "Epoch 3::Minibatch 76::LR 0.0953846153846 --> Loss 0.000943745871385\n",
      "Epoch 3::Minibatch 77::LR 0.0953846153846 --> Loss 0.00461093266805\n",
      "Epoch 3::Minibatch 78::LR 0.0953846153846 --> Loss 0.00438000599543\n",
      "Epoch 3::Minibatch 79::LR 0.0953846153846 --> Loss 0.00232127547264\n",
      "Epoch 3::Minibatch 80::LR 0.0953846153846 --> Loss 0.00417632500331\n",
      "Epoch 3::Minibatch 81::LR 0.0953846153846 --> Loss 0.00427700122197\n",
      "Epoch 3::Minibatch 82::LR 0.0953846153846 --> Loss 0.00242091596127\n",
      "Epoch 3::Minibatch 83::LR 0.0953846153846 --> Loss 0.005398042202\n",
      "Epoch 3::Minibatch 84::LR 0.0953846153846 --> Loss 0.00261404176553\n",
      "Epoch 3::Minibatch 85::LR 0.0953846153846 --> Loss 0.00316362818082\n",
      "Epoch 3::Minibatch 86::LR 0.0953846153846 --> Loss 0.00298691391945\n",
      "Epoch 3::Minibatch 87::LR 0.0953846153846 --> Loss 0.00300115784009\n",
      "Epoch 3::Minibatch 88::LR 0.0953846153846 --> Loss 0.00254455109437\n",
      "Epoch 3::Minibatch 89::LR 0.0953846153846 --> Loss 0.00319589118163\n",
      "Epoch 3::Minibatch 90::LR 0.0953846153846 --> Loss 0.0013392701745\n",
      "Epoch 3::Minibatch 91::LR 0.0953846153846 --> Loss 0.0010902829965\n",
      "Epoch 3::Minibatch 92::LR 0.0953846153846 --> Loss 0.00297059973081\n",
      "Epoch 3::Minibatch 93::LR 0.0953846153846 --> Loss 0.00199683288733\n",
      "Epoch 3::Minibatch 94::LR 0.0953846153846 --> Loss 0.00205754876137\n",
      "Epoch 3::Minibatch 95::LR 0.0953846153846 --> Loss 0.00184324463209\n",
      "Epoch 3::Minibatch 96::LR 0.0953846153846 --> Loss 0.00612786014875\n",
      "Epoch 3::Minibatch 97::LR 0.0953846153846 --> Loss 0.00365273276965\n",
      "Epoch 3::Minibatch 98::LR 0.0953846153846 --> Loss 0.00102925101916\n",
      "Epoch 3::Minibatch 99::LR 0.0953846153846 --> Loss 0.00149292866389\n",
      "Epoch 3::Minibatch 100::LR 0.0953846153846 --> Loss 0.00746425072352\n",
      "Epoch 3::Minibatch 101::LR 0.0953846153846 --> Loss 0.0014348312219\n",
      "Epoch 3::Minibatch 102::LR 0.0953846153846 --> Loss 0.00367649952571\n",
      "Epoch 3::Minibatch 103::LR 0.0953846153846 --> Loss 0.00412391146024\n",
      "Epoch 3::Minibatch 104::LR 0.0953846153846 --> Loss 0.00349647045135\n",
      "Epoch 3::Minibatch 105::LR 0.0953846153846 --> Loss 0.00404348770777\n",
      "Epoch 3::Minibatch 106::LR 0.0953846153846 --> Loss 0.0170633824666\n",
      "Epoch 3::Minibatch 107::LR 0.0953846153846 --> Loss 0.00528118292491\n",
      "Epoch 3::Minibatch 108::LR 0.0953846153846 --> Loss 0.00164399464925\n",
      "Epoch 3::Minibatch 109::LR 0.0953846153846 --> Loss 0.00499639749527\n",
      "Epoch 3::Minibatch 110::LR 0.0953846153846 --> Loss 0.0032070394357\n",
      "Epoch 3::Minibatch 111::LR 0.0953846153846 --> Loss 0.00161304622889\n",
      "Epoch 3::Minibatch 112::LR 0.0953846153846 --> Loss 0.00424511949221\n",
      "Epoch 3::Minibatch 113::LR 0.0953846153846 --> Loss 0.00345659732819\n",
      "Epoch 3::Minibatch 114::LR 0.0953846153846 --> Loss 0.00208361228307\n",
      "Epoch 3::Minibatch 115::LR 0.0953846153846 --> Loss 0.00205111940702\n",
      "Epoch 3::Minibatch 116::LR 0.0953846153846 --> Loss 0.0033439441522\n",
      "Epoch 3::Minibatch 117::LR 0.0953846153846 --> Loss 0.00395582795143\n",
      "Epoch 3::Minibatch 118::LR 0.0953846153846 --> Loss 0.00611651420593\n",
      "Epoch 3::Minibatch 119::LR 0.0953846153846 --> Loss 0.00115642368793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 120::LR 0.0953846153846 --> Loss 0.00248318930467\n",
      "Epoch 3::Minibatch 121::LR 0.0953846153846 --> Loss 0.00322427352269\n",
      "Epoch 3::Minibatch 122::LR 0.0953846153846 --> Loss 0.00364877621333\n",
      "Epoch 3::Minibatch 123::LR 0.0953846153846 --> Loss 0.00164734383424\n",
      "Epoch 3::Minibatch 124::LR 0.0953846153846 --> Loss 0.0031417798996\n",
      "Epoch 3::Minibatch 125::LR 0.0953846153846 --> Loss 0.00524857521057\n",
      "Epoch 3::Minibatch 126::LR 0.0953846153846 --> Loss 0.00341735680898\n",
      "Epoch 3::Minibatch 127::LR 0.0953846153846 --> Loss 0.00534946918488\n",
      "Epoch 3::Minibatch 128::LR 0.0953846153846 --> Loss 0.00409264008204\n",
      "Epoch 3::Minibatch 129::LR 0.0953846153846 --> Loss 0.00349302728971\n",
      "Epoch 3::Minibatch 130::LR 0.0953846153846 --> Loss 0.00504016160965\n",
      "Epoch 3::Minibatch 131::LR 0.0953846153846 --> Loss 0.00223697384199\n",
      "Epoch 3::Minibatch 132::LR 0.0953846153846 --> Loss 0.00351165731748\n",
      "Epoch 3::Minibatch 133::LR 0.0953846153846 --> Loss 0.00345539609591\n",
      "Epoch 3::Minibatch 134::LR 0.0953846153846 --> Loss 0.00293001512686\n",
      "Epoch 3::Minibatch 135::LR 0.0953846153846 --> Loss 0.00210233052572\n",
      "Epoch 3::Minibatch 136::LR 0.0953846153846 --> Loss 0.00296622316043\n",
      "Epoch 3::Minibatch 137::LR 0.0953846153846 --> Loss 0.00383997519811\n",
      "Epoch 3::Minibatch 138::LR 0.0953846153846 --> Loss 0.00169901827971\n",
      "Epoch 3::Minibatch 139::LR 0.0953846153846 --> Loss 0.00219197750092\n",
      "Epoch 3::Minibatch 140::LR 0.0953846153846 --> Loss 0.00273648043474\n",
      "Epoch 3::Minibatch 141::LR 0.0953846153846 --> Loss 0.00310367107391\n",
      "Epoch 3::Minibatch 142::LR 0.0953846153846 --> Loss 0.00357003649076\n",
      "Epoch 3::Minibatch 143::LR 0.0953846153846 --> Loss 0.000930940508842\n",
      "Epoch 3::Minibatch 144::LR 0.0953846153846 --> Loss 0.00317672252655\n",
      "Epoch 3::Minibatch 145::LR 0.0953846153846 --> Loss 0.00452170014381\n",
      "Epoch 3::Minibatch 146::LR 0.0953846153846 --> Loss 0.00326804300149\n",
      "Epoch 3::Minibatch 147::LR 0.0953846153846 --> Loss 0.00217312614123\n",
      "Epoch 3::Minibatch 148::LR 0.0953846153846 --> Loss 0.00143200814724\n",
      "Epoch 3::Minibatch 149::LR 0.0953846153846 --> Loss 0.00319215138753\n",
      "Epoch 3::Minibatch 150::LR 0.0953846153846 --> Loss 0.00331050097942\n",
      "Epoch 3::Minibatch 151::LR 0.0953846153846 --> Loss 0.00476207772891\n",
      "Epoch 3::Minibatch 152::LR 0.0953846153846 --> Loss 0.00123467236757\n",
      "Epoch 3::Minibatch 153::LR 0.0953846153846 --> Loss 0.00215587854385\n",
      "Epoch 3::Minibatch 154::LR 0.0953846153846 --> Loss 0.00240401625633\n",
      "Epoch 3::Minibatch 155::LR 0.0953846153846 --> Loss 0.00491975744565\n",
      "Epoch 3::Minibatch 156::LR 0.0953846153846 --> Loss 0.00292433698972\n",
      "Epoch 3::Minibatch 157::LR 0.0953846153846 --> Loss 0.000903215010961\n",
      "Epoch 3::Minibatch 158::LR 0.0953846153846 --> Loss 0.00312837858995\n",
      "Epoch 3::Minibatch 159::LR 0.0953846153846 --> Loss 0.00304416040579\n",
      "Epoch 3::Minibatch 160::LR 0.0953846153846 --> Loss 0.00308509230614\n",
      "Epoch 3::Minibatch 161::LR 0.0953846153846 --> Loss 0.00133480250835\n",
      "Epoch 3::Minibatch 162::LR 0.0953846153846 --> Loss 0.0036243613561\n",
      "Epoch 3::Minibatch 163::LR 0.0953846153846 --> Loss 0.00267365475496\n",
      "Epoch 3::Minibatch 164::LR 0.0953846153846 --> Loss 0.00274837652842\n",
      "Epoch 3::Minibatch 165::LR 0.0953846153846 --> Loss 0.000781101286411\n",
      "Epoch 3::Minibatch 166::LR 0.0953846153846 --> Loss 0.00210111955802\n",
      "Epoch 3::Minibatch 167::LR 0.0953846153846 --> Loss 0.00273659169674\n",
      "Epoch 3::Minibatch 168::LR 0.0953846153846 --> Loss 0.00256300369898\n",
      "Epoch 3::Minibatch 169::LR 0.0953846153846 --> Loss 0.00130470563968\n",
      "Epoch 3::Minibatch 170::LR 0.0953846153846 --> Loss 0.00109814753135\n",
      "Epoch 3::Minibatch 171::LR 0.0953846153846 --> Loss 0.00234434286753\n",
      "Epoch 3::Minibatch 172::LR 0.0953846153846 --> Loss 0.0066293489933\n",
      "Epoch 3::Minibatch 173::LR 0.0953846153846 --> Loss 0.00220945040385\n",
      "Epoch 3::Minibatch 174::LR 0.0953846153846 --> Loss 0.00123714705308\n",
      "Epoch 3::Minibatch 175::LR 0.0953846153846 --> Loss 0.00248291353385\n",
      "Epoch 3::Minibatch 176::LR 0.0953846153846 --> Loss 0.00370707631111\n",
      "Epoch 3::Minibatch 177::LR 0.0953846153846 --> Loss 0.00540913661321\n",
      "Epoch 3::Minibatch 178::LR 0.0953846153846 --> Loss 0.00198351403077\n",
      "Epoch 3::Minibatch 179::LR 0.0953846153846 --> Loss 0.00155202746391\n",
      "Epoch 3::Minibatch 180::LR 0.0953846153846 --> Loss 0.00431993126869\n",
      "Epoch 3::Minibatch 181::LR 0.0953846153846 --> Loss 0.00389120459557\n",
      "Epoch 3::Minibatch 182::LR 0.0953846153846 --> Loss 0.00103102574746\n",
      "Epoch 3::Minibatch 183::LR 0.0953846153846 --> Loss 0.00183761696021\n",
      "Epoch 3::Minibatch 184::LR 0.0953846153846 --> Loss 0.00386839985847\n",
      "Epoch 3::Minibatch 185::LR 0.0953846153846 --> Loss 0.00305791020393\n",
      "Epoch 3::Minibatch 186::LR 0.0953846153846 --> Loss 0.00121841708819\n",
      "Epoch 3::Minibatch 187::LR 0.0953846153846 --> Loss 0.00156730314096\n",
      "Epoch 3::Minibatch 188::LR 0.0953846153846 --> Loss 0.00468658010165\n",
      "Epoch 3::Minibatch 189::LR 0.0953846153846 --> Loss 0.00506742835045\n",
      "Epoch 3::Minibatch 190::LR 0.0953846153846 --> Loss 0.00253676811854\n",
      "Epoch 3::Minibatch 191::LR 0.0953846153846 --> Loss 0.000666010926167\n",
      "Epoch 3::Minibatch 192::LR 0.0953846153846 --> Loss 0.00288230200609\n",
      "Epoch 3::Minibatch 193::LR 0.0953846153846 --> Loss 0.00262613117695\n",
      "Epoch 3::Minibatch 194::LR 0.0953846153846 --> Loss 0.00208695471287\n",
      "Epoch 3::Minibatch 195::LR 0.0953846153846 --> Loss 0.000497843871514\n",
      "Epoch 3::Minibatch 196::LR 0.0953846153846 --> Loss 0.001344328324\n",
      "Epoch 3::Minibatch 197::LR 0.0953846153846 --> Loss 0.00286300798257\n",
      "Epoch 3::Minibatch 198::LR 0.0953846153846 --> Loss 0.0022185754776\n",
      "Epoch 3::Minibatch 199::LR 0.0953846153846 --> Loss 0.000396491810679\n",
      "Epoch 3::Minibatch 200::LR 0.0953846153846 --> Loss 0.00247807145119\n",
      "Epoch 3::Minibatch 201::LR 0.0953846153846 --> Loss 0.00251880228519\n",
      "Epoch 3::Minibatch 202::LR 0.0953846153846 --> Loss 0.0022615524133\n",
      "Epoch 3::Minibatch 203::LR 0.0953846153846 --> Loss 0.00218787292639\n",
      "Epoch 3::Minibatch 204::LR 0.0953846153846 --> Loss 0.00196007827918\n",
      "Epoch 3::Minibatch 205::LR 0.0953846153846 --> Loss 0.00265385468801\n",
      "Epoch 3::Minibatch 206::LR 0.0953846153846 --> Loss 0.00756255785624\n",
      "Epoch 3::Minibatch 207::LR 0.0953846153846 --> Loss 0.00180983046691\n",
      "Epoch 3::Minibatch 208::LR 0.0953846153846 --> Loss 0.00136274367571\n",
      "Epoch 3::Minibatch 209::LR 0.0953846153846 --> Loss 0.00234670420488\n",
      "Epoch 3::Minibatch 210::LR 0.0953846153846 --> Loss 0.00221545080344\n",
      "Epoch 3::Minibatch 211::LR 0.0953846153846 --> Loss 0.00223265369733\n",
      "Epoch 3::Minibatch 212::LR 0.0953846153846 --> Loss 0.00511326869329\n",
      "Epoch 3::Minibatch 213::LR 0.0953846153846 --> Loss 0.0059969274203\n",
      "Epoch 3::Minibatch 214::LR 0.0953846153846 --> Loss 0.0112897014618\n",
      "Epoch 3::Minibatch 215::LR 0.0953846153846 --> Loss 0.00170677045981\n",
      "Epoch 3::Minibatch 216::LR 0.0953846153846 --> Loss 0.00539972742399\n",
      "Epoch 3::Minibatch 217::LR 0.0953846153846 --> Loss 0.00567110498746\n",
      "Epoch 3::Minibatch 218::LR 0.0953846153846 --> Loss 0.00443359851837\n",
      "Epoch 3::Minibatch 219::LR 0.0953846153846 --> Loss 0.00322950343291\n",
      "Epoch 3::Minibatch 220::LR 0.0953846153846 --> Loss 0.00472164471944\n",
      "Epoch 3::Minibatch 221::LR 0.0953846153846 --> Loss 0.00462282856305\n",
      "Epoch 3::Minibatch 222::LR 0.0953846153846 --> Loss 0.00383701324463\n",
      "Epoch 3::Minibatch 223::LR 0.0953846153846 --> Loss 0.0016644513607\n",
      "Epoch 3::Minibatch 224::LR 0.0953846153846 --> Loss 0.00224570870399\n",
      "Epoch 3::Minibatch 225::LR 0.0953846153846 --> Loss 0.00690490722656\n",
      "Epoch 3::Minibatch 226::LR 0.0953846153846 --> Loss 0.00425227046013\n",
      "Epoch 3::Minibatch 227::LR 0.0953846153846 --> Loss 0.00203937351704\n",
      "Epoch 3::Minibatch 228::LR 0.0953846153846 --> Loss 0.00114050239325\n",
      "Epoch 3::Minibatch 229::LR 0.0953846153846 --> Loss 0.00486613313357\n",
      "Epoch 3::Minibatch 230::LR 0.0953846153846 --> Loss 0.00447227398554\n",
      "Epoch 3::Minibatch 231::LR 0.0953846153846 --> Loss 0.00301005840302\n",
      "Epoch 3::Minibatch 232::LR 0.0953846153846 --> Loss 0.00166660100222\n",
      "Epoch 3::Minibatch 233::LR 0.0953846153846 --> Loss 0.0025887298584\n",
      "Epoch 3::Minibatch 234::LR 0.0953846153846 --> Loss 0.00686028401057\n",
      "Epoch 3::Minibatch 235::LR 0.0953846153846 --> Loss 0.00519416451454\n",
      "Epoch 3::Minibatch 236::LR 0.0953846153846 --> Loss 0.00205250700315\n",
      "Epoch 3::Minibatch 237::LR 0.0953846153846 --> Loss 0.00103844702244\n",
      "Epoch 3::Minibatch 238::LR 0.0953846153846 --> Loss 0.00370948712031\n",
      "Epoch 3::Minibatch 239::LR 0.0953846153846 --> Loss 0.00309044241905\n",
      "Epoch 3::Minibatch 240::LR 0.0953846153846 --> Loss 0.00334626197815\n",
      "Epoch 3::Minibatch 241::LR 0.0953846153846 --> Loss 0.00099604109923\n",
      "Epoch 3::Minibatch 242::LR 0.0953846153846 --> Loss 0.00738300164541\n",
      "Epoch 3::Minibatch 243::LR 0.0953846153846 --> Loss 0.0040346300602\n",
      "Epoch 3::Minibatch 244::LR 0.0953846153846 --> Loss 0.00337062120438\n",
      "Epoch 3::Minibatch 245::LR 0.0953846153846 --> Loss 0.00087797164917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 246::LR 0.0953846153846 --> Loss 0.00257392505805\n",
      "Epoch 3::Minibatch 247::LR 0.0953846153846 --> Loss 0.0162665319443\n",
      "Epoch 3::Minibatch 248::LR 0.0953846153846 --> Loss 0.00475856860479\n",
      "Epoch 3::Minibatch 249::LR 0.0953846153846 --> Loss 0.00447373867035\n",
      "Epoch 3::Minibatch 250::LR 0.0953846153846 --> Loss 0.0040056626002\n",
      "Epoch 3::Minibatch 251::LR 0.0953846153846 --> Loss 0.00259715278943\n",
      "Epoch 3::Minibatch 252::LR 0.0953846153846 --> Loss 0.00215944945812\n",
      "Epoch 3::Minibatch 253::LR 0.0953846153846 --> Loss 0.00340045173963\n",
      "Epoch 3::Minibatch 254::LR 0.0953846153846 --> Loss 0.00632362246513\n",
      "Epoch 3::Minibatch 255::LR 0.0953846153846 --> Loss 0.00439121564229\n",
      "Epoch 3::Minibatch 256::LR 0.0953846153846 --> Loss 0.00219384213289\n",
      "Epoch 3::Minibatch 257::LR 0.0953846153846 --> Loss 0.00172162115574\n",
      "Epoch 3::Minibatch 258::LR 0.0953846153846 --> Loss 0.00389603575071\n",
      "Epoch 3::Minibatch 259::LR 0.0953846153846 --> Loss 0.00225686689218\n",
      "Epoch 3::Minibatch 260::LR 0.0953846153846 --> Loss 0.00220674733321\n",
      "Epoch 3::Minibatch 261::LR 0.0953846153846 --> Loss 0.00341406385104\n",
      "Epoch 3::Minibatch 262::LR 0.0953846153846 --> Loss 0.00234629968802\n",
      "Epoch 3::Minibatch 263::LR 0.0953846153846 --> Loss 0.00263540625572\n",
      "Epoch 3::Minibatch 264::LR 0.0953846153846 --> Loss 0.00381886521975\n",
      "Epoch 3::Minibatch 265::LR 0.0953846153846 --> Loss 0.00931081692378\n",
      "Epoch 3::Minibatch 266::LR 0.0953846153846 --> Loss 0.00132952004671\n",
      "Epoch 3::Minibatch 267::LR 0.0953846153846 --> Loss 0.0102805439631\n",
      "Epoch 3::Minibatch 268::LR 0.0953846153846 --> Loss 0.00158553848664\n",
      "Epoch 3::Minibatch 269::LR 0.0953846153846 --> Loss 0.00399059017499\n",
      "Epoch 3::Minibatch 270::LR 0.0953846153846 --> Loss 0.00652014017105\n",
      "Epoch 3::Minibatch 271::LR 0.0953846153846 --> Loss 0.00323537290096\n",
      "Epoch 3::Minibatch 272::LR 0.0953846153846 --> Loss 0.00413355191549\n",
      "Epoch 3::Minibatch 273::LR 0.0953846153846 --> Loss 0.00210896750291\n",
      "Epoch 3::Minibatch 274::LR 0.0953846153846 --> Loss 0.00209965010484\n",
      "Epoch 3::Minibatch 275::LR 0.0953846153846 --> Loss 0.00298392911752\n",
      "Epoch 3::Minibatch 276::LR 0.0953846153846 --> Loss 0.00357944726944\n",
      "Epoch 3::Minibatch 277::LR 0.0953846153846 --> Loss 0.00134483158588\n",
      "Epoch 3::Minibatch 278::LR 0.0953846153846 --> Loss 0.00275531589985\n",
      "Epoch 3::Minibatch 279::LR 0.0953846153846 --> Loss 0.00263237317403\n",
      "Epoch 3::Minibatch 280::LR 0.0953846153846 --> Loss 0.00240722576777\n",
      "Epoch 3::Minibatch 281::LR 0.0953846153846 --> Loss 0.00157309104999\n",
      "Epoch 3::Minibatch 282::LR 0.0953846153846 --> Loss 0.00235818723838\n",
      "Epoch 3::Minibatch 283::LR 0.0953846153846 --> Loss 0.00224547366301\n",
      "Epoch 3::Minibatch 284::LR 0.0953846153846 --> Loss 0.00185196916262\n",
      "Epoch 3::Minibatch 285::LR 0.0953846153846 --> Loss 0.00133602400621\n",
      "Epoch 3::Minibatch 286::LR 0.0953846153846 --> Loss 0.00218430459499\n",
      "Epoch 3::Minibatch 287::LR 0.0953846153846 --> Loss 0.0021429725488\n",
      "Epoch 3::Minibatch 288::LR 0.0953846153846 --> Loss 0.00119189411402\n",
      "Epoch 3::Minibatch 289::LR 0.0953846153846 --> Loss 0.00150438596805\n",
      "Epoch 3::Minibatch 290::LR 0.0953846153846 --> Loss 0.00194882710775\n",
      "Epoch 3::Minibatch 291::LR 0.0953846153846 --> Loss 0.00177857200305\n",
      "Epoch 3::Minibatch 292::LR 0.0953846153846 --> Loss 0.000721862812837\n",
      "Epoch 3::Minibatch 293::LR 0.0953846153846 --> Loss 0.00139701624711\n",
      "Epoch 3::Minibatch 294::LR 0.0953846153846 --> Loss 0.00160932868719\n",
      "Epoch 3::Minibatch 295::LR 0.0953846153846 --> Loss 0.00174569388231\n",
      "Epoch 3::Minibatch 296::LR 0.0953846153846 --> Loss 0.00150262524684\n",
      "Epoch 3::Minibatch 297::LR 0.0953846153846 --> Loss 0.00136919766665\n",
      "Epoch 3::Minibatch 298::LR 0.0953846153846 --> Loss 0.00134984642267\n",
      "Epoch 3::Minibatch 299::LR 0.0953846153846 --> Loss 0.000824537674586\n",
      "Epoch 3::Minibatch 300::LR 0.0953846153846 --> Loss 0.00331993957361\n",
      "Epoch 3::Minibatch 301::LR 0.0953846153846 --> Loss 0.00324754079183\n",
      "Epoch 3::Minibatch 302::LR 0.0953846153846 --> Loss 0.00276525517305\n",
      "Epoch 3::Minibatch 303::LR 0.0953846153846 --> Loss 0.00112594981988\n",
      "Epoch 3::Minibatch 304::LR 0.0953846153846 --> Loss 0.00362680276235\n",
      "Epoch 3::Minibatch 305::LR 0.0953846153846 --> Loss 0.00194628000259\n",
      "Epoch 3::Minibatch 306::LR 0.0953846153846 --> Loss 0.00117181758086\n",
      "Epoch 3::Minibatch 307::LR 0.0953846153846 --> Loss 0.00276617646217\n",
      "Epoch 3::Minibatch 308::LR 0.0953846153846 --> Loss 0.00226778666178\n",
      "Epoch 3::Minibatch 309::LR 0.0953846153846 --> Loss 0.00109944224358\n",
      "Epoch 3::Minibatch 310::LR 0.0953846153846 --> Loss 0.00108033547799\n",
      "Epoch 3::Minibatch 311::LR 0.0953846153846 --> Loss 0.00177869121234\n",
      "Epoch 3::Minibatch 312::LR 0.0953846153846 --> Loss 0.00348737796148\n",
      "Epoch 3::Minibatch 313::LR 0.0953846153846 --> Loss 0.00254552344481\n",
      "Epoch 3::Minibatch 314::LR 0.0953846153846 --> Loss 0.00217536449432\n",
      "Epoch 3::Minibatch 315::LR 0.0953846153846 --> Loss 0.00116785774628\n",
      "Epoch 3::Minibatch 316::LR 0.0953846153846 --> Loss 0.00259556432565\n",
      "Epoch 3::Minibatch 317::LR 0.0953846153846 --> Loss 0.00185329119364\n",
      "Epoch 3::Minibatch 318::LR 0.0953846153846 --> Loss 0.0012730906407\n",
      "Epoch 3::Minibatch 319::LR 0.0953846153846 --> Loss 0.00246608813604\n",
      "Epoch 3::Minibatch 320::LR 0.0953846153846 --> Loss 0.00361277977626\n",
      "Epoch 3::Minibatch 321::LR 0.0953846153846 --> Loss 0.000996956129869\n",
      "Epoch 3::Minibatch 322::LR 0.0953846153846 --> Loss 0.0037010383606\n",
      "Epoch 3::Minibatch 323::LR 0.0953846153846 --> Loss 0.00364443778992\n",
      "Epoch 3::Minibatch 324::LR 0.0953846153846 --> Loss 0.00264981945356\n",
      "Epoch 3::Minibatch 325::LR 0.0953846153846 --> Loss 0.00259158849716\n",
      "Epoch 3::Minibatch 326::LR 0.0953846153846 --> Loss 0.00634799917539\n",
      "Epoch 3::Minibatch 327::LR 0.0953846153846 --> Loss 0.00258740127087\n",
      "Epoch 3::Minibatch 328::LR 0.0953846153846 --> Loss 0.00376128753026\n",
      "Epoch 3::Minibatch 329::LR 0.0953846153846 --> Loss 0.00133114268382\n",
      "Epoch 3::Minibatch 330::LR 0.0953846153846 --> Loss 0.0018666211764\n",
      "Epoch 3::Minibatch 331::LR 0.0953846153846 --> Loss 0.00287377158801\n",
      "Epoch 3::Minibatch 332::LR 0.0953846153846 --> Loss 0.00282558103402\n",
      "Epoch 3::Minibatch 333::LR 0.0953846153846 --> Loss 0.00166254063447\n",
      "Epoch 3::Minibatch 334::LR 0.0953846153846 --> Loss 0.0043280629317\n",
      "Epoch 3::Minibatch 335::LR 0.0953846153846 --> Loss 0.00204465587934\n",
      "Epoch 3::Minibatch 336::LR 0.0953846153846 --> Loss 0.00193584402402\n",
      "Epoch 3::Minibatch 337::LR 0.0953846153846 --> Loss 0.00333577593168\n",
      "Epoch 3::Minibatch 338::LR 0.0953846153846 --> Loss 0.000672512302796\n",
      "Epoch 3::Minibatch 339::LR 0.0953846153846 --> Loss 0.00324441293875\n",
      "Epoch 3::Minibatch 340::LR 0.0953846153846 --> Loss 0.00642819921176\n",
      "Epoch 3::Minibatch 341::LR 0.0953846153846 --> Loss 0.00502177476883\n",
      "Epoch 3::Minibatch 342::LR 0.0953846153846 --> Loss 0.00377188881238\n",
      "Epoch 3::Minibatch 343::LR 0.0953846153846 --> Loss 0.0021451741457\n",
      "Epoch 3::Minibatch 344::LR 0.0953846153846 --> Loss 0.00323663850625\n",
      "Epoch 3::Minibatch 345::LR 0.0953846153846 --> Loss 0.00465593298276\n",
      "Epoch 3::Minibatch 346::LR 0.0953846153846 --> Loss 0.00597508470217\n",
      "Epoch 3::Minibatch 347::LR 0.0953846153846 --> Loss 0.00126569817464\n",
      "Epoch 3::Minibatch 348::LR 0.0953846153846 --> Loss 0.00396364887555\n",
      "Epoch 3::Minibatch 349::LR 0.0953846153846 --> Loss 0.00373982946078\n",
      "Epoch 3::Minibatch 350::LR 0.0953846153846 --> Loss 0.00228552877903\n",
      "Epoch 3::Minibatch 351::LR 0.0953846153846 --> Loss 0.00402845263481\n",
      "Epoch 3::Minibatch 352::LR 0.0953846153846 --> Loss 0.00495199362437\n",
      "Epoch 3::Minibatch 353::LR 0.0953846153846 --> Loss 0.00370741128922\n",
      "Epoch 3::Minibatch 354::LR 0.0953846153846 --> Loss 0.00314713875453\n",
      "Epoch 3::Minibatch 355::LR 0.0953846153846 --> Loss 0.00612226565679\n",
      "Epoch 3::Minibatch 356::LR 0.0953846153846 --> Loss 0.00357637365659\n",
      "Epoch 3::Minibatch 357::LR 0.0953846153846 --> Loss 0.00150432596604\n",
      "Epoch 3::Minibatch 358::LR 0.0953846153846 --> Loss 0.002750548323\n",
      "Epoch 3::Minibatch 359::LR 0.0953846153846 --> Loss 0.00307119270166\n",
      "Epoch 3::Minibatch 360::LR 0.0953846153846 --> Loss 0.00297623852889\n",
      "Epoch 3::Minibatch 361::LR 0.0953846153846 --> Loss 0.00271453599135\n",
      "Epoch 3::Minibatch 362::LR 0.0953846153846 --> Loss 0.00290751258532\n",
      "Epoch 3::Minibatch 363::LR 0.0953846153846 --> Loss 0.000860099097093\n",
      "Epoch 3::Minibatch 364::LR 0.0953846153846 --> Loss 0.00231477975845\n",
      "Epoch 3::Minibatch 365::LR 0.0953846153846 --> Loss 0.00241168121497\n",
      "Epoch 3::Minibatch 366::LR 0.0953846153846 --> Loss 0.0026788409551\n",
      "Epoch 3::Minibatch 367::LR 0.0953846153846 --> Loss 0.0013121894002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 368::LR 0.0953846153846 --> Loss 0.00122828404109\n",
      "Epoch 3::Minibatch 369::LR 0.0953846153846 --> Loss 0.00315927386284\n",
      "Epoch 3::Minibatch 370::LR 0.0953846153846 --> Loss 0.00245158990224\n",
      "Epoch 3::Minibatch 371::LR 0.0953846153846 --> Loss 0.00205264131228\n",
      "Epoch 3::Minibatch 372::LR 0.0953846153846 --> Loss 0.000598583420118\n",
      "Epoch 3::Minibatch 373::LR 0.0953846153846 --> Loss 0.00192172050476\n",
      "Epoch 3::Minibatch 374::LR 0.0953846153846 --> Loss 0.00226169089476\n",
      "Epoch 3::Minibatch 375::LR 0.0953846153846 --> Loss 0.0020240187645\n",
      "Epoch 3::Minibatch 376::LR 0.0953846153846 --> Loss 0.00138353735209\n",
      "Epoch 3::Minibatch 377::LR 0.0953846153846 --> Loss 0.00220280428727\n",
      "Epoch 3::Minibatch 378::LR 0.0953846153846 --> Loss 0.0022565172116\n",
      "Epoch 3::Minibatch 379::LR 0.0953846153846 --> Loss 0.00255172808965\n",
      "Epoch 3::Minibatch 380::LR 0.0953846153846 --> Loss 0.00170484860738\n",
      "Epoch 3::Minibatch 381::LR 0.0953846153846 --> Loss 0.00117060571909\n",
      "Epoch 3::Minibatch 382::LR 0.0953846153846 --> Loss 0.00222797115644\n",
      "Epoch 3::Minibatch 383::LR 0.0953846153846 --> Loss 0.00211449782054\n",
      "Epoch 3::Minibatch 384::LR 0.0953846153846 --> Loss 0.00122424006462\n",
      "Epoch 3::Minibatch 385::LR 0.0953846153846 --> Loss 0.00118653863668\n",
      "Epoch 3::Minibatch 386::LR 0.0953846153846 --> Loss 0.00247334380945\n",
      "Epoch 3::Minibatch 387::LR 0.0953846153846 --> Loss 0.00246500551701\n",
      "Epoch 3::Minibatch 388::LR 0.0953846153846 --> Loss 0.0011887460947\n",
      "Epoch 3::Minibatch 389::LR 0.0953846153846 --> Loss 0.00214978377024\n",
      "Epoch 3::Minibatch 390::LR 0.0953846153846 --> Loss 0.0048116962115\n",
      "Epoch 3::Minibatch 391::LR 0.0953846153846 --> Loss 0.00316910326481\n",
      "Epoch 3::Minibatch 392::LR 0.0953846153846 --> Loss 0.00325559695562\n",
      "Epoch 3::Minibatch 393::LR 0.0953846153846 --> Loss 0.00309810976187\n",
      "Epoch 3::Minibatch 394::LR 0.0953846153846 --> Loss 0.00265270213286\n",
      "Epoch 3::Minibatch 395::LR 0.0953846153846 --> Loss 0.00232175628344\n",
      "Epoch 3::Minibatch 396::LR 0.0953846153846 --> Loss 0.00236398458481\n",
      "Epoch 3::Minibatch 397::LR 0.0953846153846 --> Loss 0.00250223318736\n",
      "Epoch 3::Minibatch 398::LR 0.0953846153846 --> Loss 0.00239895006021\n",
      "Epoch 3::Minibatch 399::LR 0.0953846153846 --> Loss 0.00262431442738\n",
      "Epoch 3::Minibatch 400::LR 0.0953846153846 --> Loss 0.00242465058963\n",
      "Epoch 3::Minibatch 401::LR 0.0953846153846 --> Loss 0.00510384678841\n",
      "Epoch 3::Minibatch 402::LR 0.0953846153846 --> Loss 0.0023975610733\n",
      "Epoch 3::Minibatch 403::LR 0.0953846153846 --> Loss 0.00181317607562\n",
      "Epoch 3::Minibatch 404::LR 0.0953846153846 --> Loss 0.0019027809302\n",
      "Epoch 3::Minibatch 405::LR 0.0953846153846 --> Loss 0.00396278182666\n",
      "Epoch 3::Minibatch 406::LR 0.0953846153846 --> Loss 0.00279307643572\n",
      "Epoch 3::Minibatch 407::LR 0.0953846153846 --> Loss 0.00199342270692\n",
      "Epoch 3::Minibatch 408::LR 0.0953846153846 --> Loss 0.000759946306547\n",
      "Epoch 3::Minibatch 409::LR 0.0953846153846 --> Loss 0.0033370522658\n",
      "Epoch 3::Minibatch 410::LR 0.0953846153846 --> Loss 0.00450609842936\n",
      "Epoch 3::Minibatch 411::LR 0.0953846153846 --> Loss 0.00182295322418\n",
      "Epoch 3::Minibatch 412::LR 0.0953846153846 --> Loss 0.00114049166441\n",
      "Epoch 3::Minibatch 413::LR 0.0953846153846 --> Loss 0.00233372767766\n",
      "Epoch 3::Minibatch 414::LR 0.0953846153846 --> Loss 0.00175965408484\n",
      "Epoch 3::Minibatch 415::LR 0.0953846153846 --> Loss 0.00122954120239\n",
      "Epoch 3::Minibatch 416::LR 0.0953846153846 --> Loss 0.000963704188665\n",
      "Epoch 3::Minibatch 417::LR 0.0953846153846 --> Loss 0.00176033695539\n",
      "Epoch 3::Minibatch 418::LR 0.0953846153846 --> Loss 0.0037927420934\n",
      "Epoch 3::Minibatch 419::LR 0.0953846153846 --> Loss 0.000841791133086\n",
      "Epoch 3::Minibatch 420::LR 0.0953846153846 --> Loss 0.00105208148559\n",
      "Epoch 3::Minibatch 421::LR 0.0953846153846 --> Loss 0.00228497187297\n",
      "Epoch 3::Minibatch 422::LR 0.0953846153846 --> Loss 0.00266198396683\n",
      "Epoch 3::Minibatch 423::LR 0.0953846153846 --> Loss 0.00127681732178\n",
      "Epoch 3::Minibatch 424::LR 0.0953846153846 --> Loss 0.00190188368162\n",
      "Epoch 3::Minibatch 425::LR 0.0953846153846 --> Loss 0.00270085573196\n",
      "Epoch 3::Minibatch 426::LR 0.0953846153846 --> Loss 0.0022405008475\n",
      "Epoch 3::Minibatch 427::LR 0.0953846153846 --> Loss 0.000938061376413\n",
      "Epoch 3::Minibatch 428::LR 0.0953846153846 --> Loss 0.00157226254543\n",
      "Epoch 3::Minibatch 429::LR 0.0953846153846 --> Loss 0.00298764427503\n",
      "Epoch 3::Minibatch 430::LR 0.0953846153846 --> Loss 0.0117513839404\n",
      "Epoch 3::Minibatch 431::LR 0.0953846153846 --> Loss 0.00412564476331\n",
      "Epoch 3::Minibatch 432::LR 0.0953846153846 --> Loss 0.00471860567729\n",
      "Epoch 3::Minibatch 433::LR 0.0953846153846 --> Loss 0.00283989270528\n",
      "Epoch 3::Minibatch 434::LR 0.0953846153846 --> Loss 0.00281051814556\n",
      "Epoch 3::Minibatch 435::LR 0.0953846153846 --> Loss 0.00273555517197\n",
      "Epoch 3::Minibatch 436::LR 0.0953846153846 --> Loss 0.00219233870506\n",
      "Epoch 3::Minibatch 437::LR 0.0953846153846 --> Loss 0.00461690505346\n",
      "Epoch 3::Minibatch 438::LR 0.0953846153846 --> Loss 0.00341205676397\n",
      "Epoch 3::Minibatch 439::LR 0.0953846153846 --> Loss 0.00271472493807\n",
      "Epoch 3::Minibatch 440::LR 0.0953846153846 --> Loss 0.00404802719752\n",
      "Epoch 3::Minibatch 441::LR 0.0953846153846 --> Loss 0.00380198359489\n",
      "Epoch 3::Minibatch 442::LR 0.0953846153846 --> Loss 0.00372784336408\n",
      "Epoch 3::Minibatch 443::LR 0.0953846153846 --> Loss 0.00455000758171\n",
      "Epoch 3::Minibatch 444::LR 0.0953846153846 --> Loss 0.0033791855971\n",
      "Epoch 3::Minibatch 445::LR 0.0953846153846 --> Loss 0.00108375251293\n",
      "Epoch 3::Minibatch 446::LR 0.0953846153846 --> Loss 0.00192653616269\n",
      "Epoch 3::Minibatch 447::LR 0.0953846153846 --> Loss 0.00307135065397\n",
      "Epoch 3::Minibatch 448::LR 0.0953846153846 --> Loss 0.00303175032139\n",
      "Epoch 3::Minibatch 449::LR 0.0953846153846 --> Loss 0.00437524080276\n",
      "Epoch 3::Minibatch 450::LR 0.0953846153846 --> Loss 0.00313357611497\n",
      "Epoch 3::Minibatch 451::LR 0.0953846153846 --> Loss 0.00476837356885\n",
      "Epoch 3::Minibatch 452::LR 0.0953846153846 --> Loss 0.00275951226552\n",
      "Epoch 3::Minibatch 453::LR 0.0953846153846 --> Loss 0.0007167519629\n",
      "Epoch 3::Minibatch 454::LR 0.0953846153846 --> Loss 0.00357262015343\n",
      "Epoch 3::Minibatch 455::LR 0.0953846153846 --> Loss 0.00317633966605\n",
      "Epoch 3::Minibatch 456::LR 0.0953846153846 --> Loss 0.00368603825569\n",
      "Epoch 3::Minibatch 457::LR 0.0953846153846 --> Loss 0.00227642933528\n",
      "Epoch 3::Minibatch 458::LR 0.0953846153846 --> Loss 0.0010245808959\n",
      "Epoch 3::Minibatch 459::LR 0.0953846153846 --> Loss 0.00474838376045\n",
      "Epoch 3::Minibatch 460::LR 0.0953846153846 --> Loss 0.00326596538226\n",
      "Epoch 3::Minibatch 461::LR 0.0953846153846 --> Loss 0.00440079331398\n",
      "Epoch 3::Minibatch 462::LR 0.0953846153846 --> Loss 0.000606775432825\n",
      "Epoch 3::Minibatch 463::LR 0.0953846153846 --> Loss 0.00518200238546\n",
      "Epoch 3::Minibatch 464::LR 0.0953846153846 --> Loss 0.00255918959777\n",
      "Epoch 3::Minibatch 465::LR 0.0953846153846 --> Loss 0.00654882788658\n",
      "Epoch 3::Minibatch 466::LR 0.0953846153846 --> Loss 0.0054743039608\n",
      "Epoch 3::Minibatch 467::LR 0.0953846153846 --> Loss 0.00621334791183\n",
      "Epoch 3::Minibatch 468::LR 0.0953846153846 --> Loss 0.00655355095863\n",
      "Epoch 3::Minibatch 469::LR 0.0953846153846 --> Loss 0.00755483786265\n",
      "Epoch 3::Minibatch 470::LR 0.0953846153846 --> Loss 0.0045554904143\n",
      "Epoch 3::Minibatch 471::LR 0.0953846153846 --> Loss 0.00261709014575\n",
      "Epoch 3::Minibatch 472::LR 0.0953846153846 --> Loss 0.00385393222173\n",
      "Epoch 3::Minibatch 473::LR 0.0953846153846 --> Loss 0.00235863427321\n",
      "Epoch 3::Minibatch 474::LR 0.0953846153846 --> Loss 0.000951701303323\n",
      "Epoch 3::Minibatch 475::LR 0.0953846153846 --> Loss 0.0103552134832\n",
      "Epoch 3::Minibatch 476::LR 0.0953846153846 --> Loss 0.00777398983637\n",
      "Epoch 3::Minibatch 477::LR 0.0953846153846 --> Loss 0.00116306742032\n",
      "Epoch 3::Minibatch 478::LR 0.0953846153846 --> Loss 0.00264956116676\n",
      "Epoch 3::Minibatch 479::LR 0.0953846153846 --> Loss 0.0022343591849\n",
      "Epoch 3::Minibatch 480::LR 0.0953846153846 --> Loss 0.00186522006989\n",
      "Epoch 3::Minibatch 481::LR 0.0953846153846 --> Loss 0.00118517448505\n",
      "Epoch 3::Minibatch 482::LR 0.0953846153846 --> Loss 0.00252980450789\n",
      "Epoch 3::Minibatch 483::LR 0.0953846153846 --> Loss 0.00400586922963\n",
      "Epoch 3::Minibatch 484::LR 0.0953846153846 --> Loss 0.00412855108579\n",
      "Epoch 3::Minibatch 485::LR 0.0953846153846 --> Loss 0.000991131663322\n",
      "Epoch 3::Minibatch 486::LR 0.0953846153846 --> Loss 0.00368135412534\n",
      "Epoch 3::Minibatch 487::LR 0.0953846153846 --> Loss 0.00409233967463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 488::LR 0.0953846153846 --> Loss 0.00236815174421\n",
      "Epoch 3::Minibatch 489::LR 0.0953846153846 --> Loss 0.00326271295547\n",
      "Epoch 3::Minibatch 490::LR 0.0953846153846 --> Loss 0.000614688098431\n",
      "Epoch 3::Minibatch 491::LR 0.0953846153846 --> Loss 0.00641980608304\n",
      "Epoch 3::Minibatch 492::LR 0.0953846153846 --> Loss 0.0033875699838\n",
      "Epoch 3::Minibatch 493::LR 0.0953846153846 --> Loss 0.00382800459862\n",
      "Epoch 3::Minibatch 494::LR 0.0953846153846 --> Loss 0.000980617205302\n",
      "Epoch 3::Minibatch 495::LR 0.0953846153846 --> Loss 0.00224756995837\n",
      "Epoch 3::Minibatch 496::LR 0.0953846153846 --> Loss 0.00392923752467\n",
      "Epoch 3::Minibatch 497::LR 0.0953846153846 --> Loss 0.00117391029994\n",
      "Epoch 3::Minibatch 498::LR 0.0953846153846 --> Loss 0.000852463841438\n",
      "Epoch 3::Minibatch 499::LR 0.0953846153846 --> Loss 0.00469413479169\n",
      "Epoch 3::Minibatch 500::LR 0.0953846153846 --> Loss 0.00170635342598\n",
      "Epoch 3::Minibatch 501::LR 0.0953846153846 --> Loss 0.0022323936224\n",
      "Epoch 3::Minibatch 502::LR 0.0953846153846 --> Loss 0.00426793972651\n",
      "Epoch 3::Minibatch 503::LR 0.0953846153846 --> Loss 0.0113089219729\n",
      "Epoch 3::Minibatch 504::LR 0.0953846153846 --> Loss 0.00839579582214\n",
      "Epoch 3::Minibatch 505::LR 0.0953846153846 --> Loss 0.00487130641937\n",
      "Epoch 3::Minibatch 506::LR 0.0953846153846 --> Loss 0.00416911800702\n",
      "Epoch 3::Minibatch 507::LR 0.0953846153846 --> Loss 0.0061824174722\n",
      "Epoch 3::Minibatch 508::LR 0.0953846153846 --> Loss 0.00364923874537\n",
      "Epoch 3::Minibatch 509::LR 0.0953846153846 --> Loss 0.00452393651009\n",
      "Epoch 3::Minibatch 510::LR 0.0953846153846 --> Loss 0.00547147472699\n",
      "Epoch 3::Minibatch 511::LR 0.0953846153846 --> Loss 0.00393548687299\n",
      "Epoch 3::Minibatch 512::LR 0.0953846153846 --> Loss 0.00302847484748\n",
      "Epoch 3::Minibatch 513::LR 0.0953846153846 --> Loss 0.00106801639001\n",
      "Epoch 3::Minibatch 514::LR 0.0953846153846 --> Loss 0.00284292916457\n",
      "Epoch 3::Minibatch 515::LR 0.0953846153846 --> Loss 0.00362390756607\n",
      "Epoch 3::Minibatch 516::LR 0.0953846153846 --> Loss 0.00488238453865\n",
      "Epoch 3::Minibatch 517::LR 0.0953846153846 --> Loss 0.00335529088974\n",
      "Epoch 3::Minibatch 518::LR 0.0953846153846 --> Loss 0.00272063771884\n",
      "Epoch 3::Minibatch 519::LR 0.0953846153846 --> Loss 0.00371841510137\n",
      "Epoch 3::Minibatch 520::LR 0.0953846153846 --> Loss 0.00563864906629\n",
      "Epoch 3::Minibatch 521::LR 0.0953846153846 --> Loss 0.00635414322217\n",
      "Epoch 3::Minibatch 522::LR 0.0953846153846 --> Loss 0.0084757677714\n",
      "Epoch 3::Minibatch 523::LR 0.0953846153846 --> Loss 0.00106222500404\n",
      "Epoch 3::Minibatch 524::LR 0.0953846153846 --> Loss 0.00172756234805\n",
      "Epoch 3::Minibatch 525::LR 0.0953846153846 --> Loss 0.00367892781893\n",
      "Epoch 3::Minibatch 526::LR 0.0953846153846 --> Loss 0.00450886408488\n",
      "Epoch 3::Minibatch 527::LR 0.0953846153846 --> Loss 0.00297682702541\n",
      "Epoch 3::Minibatch 528::LR 0.0953846153846 --> Loss 0.00177638530731\n",
      "Epoch 3::Minibatch 529::LR 0.0953846153846 --> Loss 0.00451524615288\n",
      "Epoch 3::Minibatch 530::LR 0.0953846153846 --> Loss 0.00494836648305\n",
      "Epoch 3::Minibatch 531::LR 0.0953846153846 --> Loss 0.00437959909439\n",
      "Epoch 3::Minibatch 532::LR 0.0953846153846 --> Loss 0.00318167984486\n",
      "Epoch 3::Minibatch 533::LR 0.0953846153846 --> Loss 0.00526445309321\n",
      "Epoch 3::Minibatch 534::LR 0.0953846153846 --> Loss 0.00445796807607\n",
      "Epoch 3::Minibatch 535::LR 0.0953846153846 --> Loss 0.00361479997635\n",
      "Epoch 3::Minibatch 536::LR 0.0953846153846 --> Loss 0.00262422541777\n",
      "Epoch 3::Minibatch 537::LR 0.0953846153846 --> Loss 0.00104158828656\n",
      "Epoch 3::Minibatch 538::LR 0.0953846153846 --> Loss 0.00205861647924\n",
      "Epoch 3::Minibatch 539::LR 0.0953846153846 --> Loss 0.00381861766179\n",
      "Epoch 3::Minibatch 540::LR 0.0953846153846 --> Loss 0.00380964080493\n",
      "Epoch 3::Minibatch 541::LR 0.0953846153846 --> Loss 0.00330446918805\n",
      "Epoch 3::Minibatch 542::LR 0.0953846153846 --> Loss 0.00309938748678\n",
      "Epoch 3::Minibatch 543::LR 0.0953846153846 --> Loss 0.00341248353322\n",
      "Epoch 3::Minibatch 544::LR 0.0953846153846 --> Loss 0.00429844419161\n",
      "Epoch 3::Minibatch 545::LR 0.0953846153846 --> Loss 0.00231467167536\n",
      "Epoch 3::Minibatch 546::LR 0.0953846153846 --> Loss 0.000968826711178\n",
      "Epoch 3::Minibatch 547::LR 0.0953846153846 --> Loss 0.00300312439601\n",
      "Epoch 3::Minibatch 548::LR 0.0953846153846 --> Loss 0.00459800203641\n",
      "Epoch 3::Minibatch 549::LR 0.0953846153846 --> Loss 0.00729025284449\n",
      "Epoch 3::Minibatch 550::LR 0.0953846153846 --> Loss 0.00138563295205\n",
      "Epoch 3::Minibatch 551::LR 0.0953846153846 --> Loss 0.00264459848404\n",
      "Epoch 3::Minibatch 552::LR 0.0953846153846 --> Loss 0.00419129252434\n",
      "Epoch 3::Minibatch 553::LR 0.0953846153846 --> Loss 0.00375278711319\n",
      "Epoch 3::Minibatch 554::LR 0.0953846153846 --> Loss 0.00424887816111\n",
      "Epoch 3::Minibatch 555::LR 0.0953846153846 --> Loss 0.00126656681299\n",
      "Epoch 3::Minibatch 556::LR 0.0953846153846 --> Loss 0.00250774164995\n",
      "Epoch 3::Minibatch 557::LR 0.0953846153846 --> Loss 0.00292680303256\n",
      "Epoch 3::Minibatch 558::LR 0.0953846153846 --> Loss 0.00407169540723\n",
      "Epoch 3::Minibatch 559::LR 0.0953846153846 --> Loss 0.00414833386739\n",
      "Epoch 3::Minibatch 560::LR 0.0953846153846 --> Loss 0.00329970339934\n",
      "Epoch 3::Minibatch 561::LR 0.0953846153846 --> Loss 0.00329756418864\n",
      "Epoch 3::Minibatch 562::LR 0.0953846153846 --> Loss 0.00274830897649\n",
      "Epoch 3::Minibatch 563::LR 0.0953846153846 --> Loss 0.00400236129761\n",
      "Epoch 3::Minibatch 564::LR 0.0953846153846 --> Loss 0.00338615457217\n",
      "Epoch 3::Minibatch 565::LR 0.0953846153846 --> Loss 0.00417651375135\n",
      "Epoch 3::Minibatch 566::LR 0.0953846153846 --> Loss 0.00278928379218\n",
      "Epoch 3::Minibatch 567::LR 0.0953846153846 --> Loss 0.00326775570711\n",
      "Epoch 3::Minibatch 568::LR 0.0953846153846 --> Loss 0.00225153068701\n",
      "Epoch 3::Minibatch 569::LR 0.0953846153846 --> Loss 0.000841115911802\n",
      "Epoch 3::Minibatch 570::LR 0.0953846153846 --> Loss 0.00223431487878\n",
      "Epoch 3::Minibatch 571::LR 0.0953846153846 --> Loss 0.00294551193714\n",
      "Epoch 3::Minibatch 572::LR 0.0953846153846 --> Loss 0.00303676942984\n",
      "Epoch 3::Minibatch 573::LR 0.0953846153846 --> Loss 0.00184876739979\n",
      "Epoch 3::Minibatch 574::LR 0.0953846153846 --> Loss 0.00125610580047\n",
      "Epoch 3::Minibatch 575::LR 0.0953846153846 --> Loss 0.00226199706395\n",
      "Epoch 3::Minibatch 576::LR 0.0953846153846 --> Loss 0.00268583337466\n",
      "Epoch 3::Minibatch 577::LR 0.0953846153846 --> Loss 0.00211136221886\n",
      "Epoch 3::Minibatch 578::LR 0.0953846153846 --> Loss 0.00155809015036\n",
      "Epoch 3::Minibatch 579::LR 0.0953846153846 --> Loss 0.00145168691874\n",
      "Epoch 3::Minibatch 580::LR 0.0953846153846 --> Loss 0.00242249687513\n",
      "Epoch 3::Minibatch 581::LR 0.0953846153846 --> Loss 0.00206489245097\n",
      "Epoch 3::Minibatch 582::LR 0.0953846153846 --> Loss 0.0045891614755\n",
      "Epoch 3::Minibatch 583::LR 0.0953846153846 --> Loss 0.0011732768019\n",
      "Epoch 3::Minibatch 584::LR 0.0953846153846 --> Loss 0.00156430135171\n",
      "Epoch 3::Minibatch 585::LR 0.0953846153846 --> Loss 0.00738764206568\n",
      "Epoch 3::Minibatch 586::LR 0.0953846153846 --> Loss 0.00494796435038\n",
      "Epoch 3::Minibatch 587::LR 0.0953846153846 --> Loss 0.00141208380461\n",
      "Epoch 3::Minibatch 588::LR 0.0953846153846 --> Loss 0.00175693353017\n",
      "Epoch 3::Minibatch 589::LR 0.0953846153846 --> Loss 0.00322678347429\n",
      "Epoch 3::Minibatch 590::LR 0.0953846153846 --> Loss 0.00263781150182\n",
      "Epoch 3::Minibatch 591::LR 0.0953846153846 --> Loss 0.00397760152817\n",
      "Epoch 3::Minibatch 592::LR 0.0953846153846 --> Loss 0.00149600416422\n",
      "Epoch 3::Minibatch 593::LR 0.0953846153846 --> Loss 0.0029594018062\n",
      "Epoch 3::Minibatch 594::LR 0.0953846153846 --> Loss 0.00350936929385\n",
      "Epoch 3::Minibatch 595::LR 0.0953846153846 --> Loss 0.00341249624888\n",
      "Epoch 3::Minibatch 596::LR 0.0953846153846 --> Loss 0.00262484828631\n",
      "Epoch 3::Minibatch 597::LR 0.0953846153846 --> Loss 0.00163542856773\n",
      "Epoch 3::Minibatch 598::LR 0.0953846153846 --> Loss 0.00390390912692\n",
      "Epoch 3::Minibatch 599::LR 0.0953846153846 --> Loss 0.00234890679518\n",
      "Epoch 3::Minibatch 600::LR 0.0953846153846 --> Loss 0.00284316897392\n",
      "Epoch 3::Minibatch 601::LR 0.0953846153846 --> Loss 0.00381800929705\n",
      "Epoch 3::Minibatch 602::LR 0.0953846153846 --> Loss 0.00231294989586\n",
      "Epoch 3::Minibatch 603::LR 0.0953846153846 --> Loss 0.00333572864532\n",
      "Epoch 3::Minibatch 604::LR 0.0953846153846 --> Loss 0.00204469243685\n",
      "Epoch 3::Minibatch 605::LR 0.0953846153846 --> Loss 0.0030019535621\n",
      "Epoch 3::Minibatch 606::LR 0.0953846153846 --> Loss 0.00243240555127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 607::LR 0.0953846153846 --> Loss 0.00108042786519\n",
      "Epoch 3::Minibatch 608::LR 0.0953846153846 --> Loss 0.00206642925739\n",
      "Epoch 3::Minibatch 609::LR 0.0953846153846 --> Loss 0.00266403496265\n",
      "Epoch 3::Minibatch 610::LR 0.0953846153846 --> Loss 0.00394876996676\n",
      "Epoch 3::Minibatch 611::LR 0.0953846153846 --> Loss 0.00279108087222\n",
      "Epoch 3::Minibatch 612::LR 0.0953846153846 --> Loss 0.000813658634822\n",
      "Epoch 3::Minibatch 613::LR 0.0953846153846 --> Loss 0.00173310359319\n",
      "Epoch 3::Minibatch 614::LR 0.0953846153846 --> Loss 0.00288480460644\n",
      "Epoch 3::Minibatch 615::LR 0.0953846153846 --> Loss 0.00210201402505\n",
      "Epoch 3::Minibatch 616::LR 0.0953846153846 --> Loss 0.00118403017521\n",
      "Epoch 3::Minibatch 617::LR 0.0953846153846 --> Loss 0.000776131053766\n",
      "Epoch 3::Minibatch 618::LR 0.0953846153846 --> Loss 0.00282232423623\n",
      "Epoch 3::Minibatch 619::LR 0.0953846153846 --> Loss 0.00226621905963\n",
      "Epoch 3::Minibatch 620::LR 0.0953846153846 --> Loss 0.00203170398871\n",
      "Epoch 3::Minibatch 621::LR 0.0953846153846 --> Loss 0.00106769601504\n",
      "Epoch 3::Minibatch 622::LR 0.0953846153846 --> Loss 0.00106775750717\n",
      "Epoch 3::Minibatch 623::LR 0.0953846153846 --> Loss 0.00248099644979\n",
      "Epoch 3::Minibatch 624::LR 0.0953846153846 --> Loss 0.00212755401929\n",
      "Epoch 3::Minibatch 625::LR 0.0953846153846 --> Loss 0.00401897867521\n",
      "Epoch 3::Minibatch 626::LR 0.0953846153846 --> Loss 0.00539561867714\n",
      "Epoch 3::Minibatch 627::LR 0.0953846153846 --> Loss 0.00178223371506\n",
      "Epoch 3::Minibatch 628::LR 0.0953846153846 --> Loss 0.00124087144931\n",
      "Epoch 3::Minibatch 629::LR 0.0953846153846 --> Loss 0.00393239855766\n",
      "Epoch 3::Minibatch 630::LR 0.0953846153846 --> Loss 0.00382297754288\n",
      "Epoch 3::Minibatch 631::LR 0.0953846153846 --> Loss 0.0120841439565\n",
      "Epoch 3::Minibatch 632::LR 0.0953846153846 --> Loss 0.00120515614748\n",
      "Epoch 3::Minibatch 633::LR 0.0953846153846 --> Loss 0.00214404503504\n",
      "Epoch 3::Minibatch 634::LR 0.0953846153846 --> Loss 0.00381542205811\n",
      "Epoch 3::Minibatch 635::LR 0.0953846153846 --> Loss 0.00442603826523\n",
      "Epoch 3::Minibatch 636::LR 0.0953846153846 --> Loss 0.00856952031453\n",
      "Epoch 3::Minibatch 637::LR 0.0953846153846 --> Loss 0.00147388150295\n",
      "Epoch 3::Minibatch 638::LR 0.0953846153846 --> Loss 0.00227810164293\n",
      "Epoch 3::Minibatch 639::LR 0.0953846153846 --> Loss 0.00401050170263\n",
      "Epoch 3::Minibatch 640::LR 0.0953846153846 --> Loss 0.00443148851395\n",
      "Epoch 3::Minibatch 641::LR 0.0953846153846 --> Loss 0.00356302857399\n",
      "Epoch 3::Minibatch 642::LR 0.0953846153846 --> Loss 0.000906701584657\n",
      "Epoch 3::Minibatch 643::LR 0.0953846153846 --> Loss 0.00278211593628\n",
      "Epoch 3::Minibatch 644::LR 0.0953846153846 --> Loss 0.00448460380236\n",
      "Epoch 3::Minibatch 645::LR 0.0953846153846 --> Loss 0.00483815511068\n",
      "Epoch 3::Minibatch 646::LR 0.0953846153846 --> Loss 0.00212565004826\n",
      "Epoch 3::Minibatch 647::LR 0.0953846153846 --> Loss 0.00118027240038\n",
      "Epoch 3::Minibatch 648::LR 0.0953846153846 --> Loss 0.00399803121885\n",
      "Epoch 3::Minibatch 649::LR 0.0953846153846 --> Loss 0.00452978253365\n",
      "Epoch 3::Minibatch 650::LR 0.0953846153846 --> Loss 0.0041945095857\n",
      "Epoch 3::Minibatch 651::LR 0.0953846153846 --> Loss 0.00201978782813\n",
      "Epoch 3::Minibatch 652::LR 0.0953846153846 --> Loss 0.00142852991819\n",
      "Epoch 3::Minibatch 653::LR 0.0953846153846 --> Loss 0.00373079021772\n",
      "Epoch 3::Minibatch 654::LR 0.0953846153846 --> Loss 0.00373037894567\n",
      "Epoch 3::Minibatch 655::LR 0.0953846153846 --> Loss 0.00395811994871\n",
      "Epoch 3::Minibatch 656::LR 0.0953846153846 --> Loss 0.00106656710307\n",
      "Epoch 3::Minibatch 657::LR 0.0953846153846 --> Loss 0.00246245245139\n",
      "Epoch 3::Minibatch 658::LR 0.0953846153846 --> Loss 0.00546492576599\n",
      "Epoch 3::Minibatch 659::LR 0.0953846153846 --> Loss 0.00264912565549\n",
      "Epoch 3::Minibatch 660::LR 0.0953846153846 --> Loss 0.0028066188097\n",
      "Epoch 3::Minibatch 661::LR 0.0953846153846 --> Loss 0.00286716302236\n",
      "Epoch 3::Minibatch 662::LR 0.0953846153846 --> Loss 0.00216315130393\n",
      "Epoch 3::Minibatch 663::LR 0.0953846153846 --> Loss 0.00448986728986\n",
      "Epoch 3::Minibatch 664::LR 0.0953846153846 --> Loss 0.00410290718079\n",
      "Epoch 3::Minibatch 665::LR 0.0953846153846 --> Loss 0.00125773121913\n",
      "Epoch 3::Minibatch 666::LR 0.0953846153846 --> Loss 0.00436659614245\n",
      "Epoch 3::Minibatch 667::LR 0.0953846153846 --> Loss 0.00315788825353\n",
      "Epoch 3::Minibatch 668::LR 0.0953846153846 --> Loss 0.00768411159515\n",
      "Epoch 3::Minibatch 669::LR 0.0953846153846 --> Loss 0.00153737286727\n",
      "Epoch 3::Minibatch 670::LR 0.0953846153846 --> Loss 0.00177202741305\n",
      "Epoch 3::Minibatch 671::LR 0.0953846153846 --> Loss 0.00609946409861\n",
      "Epoch 3::Minibatch 672::LR 0.0953846153846 --> Loss 0.00466969966888\n",
      "Epoch 3::Minibatch 673::LR 0.0953846153846 --> Loss 0.00206876595815\n",
      "Epoch 3::Minibatch 674::LR 0.0953846153846 --> Loss 0.000904758373896\n",
      "Epoch 3::Minibatch 675::LR 0.0953846153846 --> Loss 0.00280984024207\n",
      "Epoch 3::Minibatch 676::LR 0.0953846153846 --> Loss 0.00275733530521\n",
      "Epoch 3::Minibatch 677::LR 0.0953846153846 --> Loss 0.00366658608119\n",
      "Epoch 3::Minibatch 678::LR 0.0953846153846 --> Loss 0.00240045408408\n",
      "Epoch 3::Minibatch 679::LR 0.0953846153846 --> Loss 0.00410714030266\n",
      "Epoch 3::Minibatch 680::LR 0.0953846153846 --> Loss 0.00264897267024\n",
      "Epoch 3::Minibatch 681::LR 0.0953846153846 --> Loss 0.002915528814\n",
      "Epoch 3::Minibatch 682::LR 0.0953846153846 --> Loss 0.00106262942155\n",
      "Epoch 3::Minibatch 683::LR 0.0953846153846 --> Loss 0.00288482904434\n",
      "Epoch 3::Minibatch 684::LR 0.0953846153846 --> Loss 0.00287393450737\n",
      "Epoch 3::Minibatch 685::LR 0.0953846153846 --> Loss 0.00352864106496\n",
      "Epoch 3::Minibatch 686::LR 0.0953846153846 --> Loss 0.00187909046809\n",
      "Epoch 3::Minibatch 687::LR 0.0953846153846 --> Loss 0.00109308352073\n",
      "Epoch 3::Minibatch 688::LR 0.0953846153846 --> Loss 0.00306225041548\n",
      "Epoch 3::Minibatch 689::LR 0.0953846153846 --> Loss 0.0031474596262\n",
      "Epoch 3::Minibatch 690::LR 0.0953846153846 --> Loss 0.00228887101014\n",
      "Epoch 3::Minibatch 691::LR 0.0953846153846 --> Loss 0.000878021021684\n",
      "Epoch 3::Minibatch 692::LR 0.0953846153846 --> Loss 0.00295423765977\n",
      "Epoch 3::Minibatch 693::LR 0.0953846153846 --> Loss 0.003172848622\n",
      "Epoch 3::Minibatch 694::LR 0.0953846153846 --> Loss 0.0034873342514\n",
      "Epoch 3::Minibatch 695::LR 0.0953846153846 --> Loss 0.00220661580563\n",
      "Epoch 3::Minibatch 696::LR 0.0953846153846 --> Loss 0.00227593918641\n",
      "Epoch 3::Minibatch 697::LR 0.0953846153846 --> Loss 0.00161588271459\n",
      "Epoch 3::Minibatch 698::LR 0.0953846153846 --> Loss 0.00184134403865\n",
      "Epoch 3::Minibatch 699::LR 0.0953846153846 --> Loss 0.00390768448512\n",
      "Epoch 3::Minibatch 700::LR 0.0953846153846 --> Loss 0.0029377446572\n",
      "Epoch 3::Minibatch 701::LR 0.0953846153846 --> Loss 0.00243717372417\n",
      "Epoch 3::Minibatch 702::LR 0.0953846153846 --> Loss 0.00214485128721\n",
      "Epoch 3::Minibatch 703::LR 0.0953846153846 --> Loss 0.00450611869494\n",
      "Epoch 3::Minibatch 704::LR 0.0953846153846 --> Loss 0.00208996236324\n",
      "Epoch 3::Minibatch 705::LR 0.0953846153846 --> Loss 0.00319087406\n",
      "Epoch 3::Minibatch 706::LR 0.0953846153846 --> Loss 0.00244139214357\n",
      "Epoch 3::Minibatch 707::LR 0.0953846153846 --> Loss 0.00153541813294\n",
      "Epoch 3::Minibatch 708::LR 0.0953846153846 --> Loss 0.00202962080638\n",
      "Epoch 3::Minibatch 709::LR 0.0953846153846 --> Loss 0.00211172540983\n",
      "Epoch 3::Minibatch 710::LR 0.0953846153846 --> Loss 0.00262473960718\n",
      "Epoch 3::Minibatch 711::LR 0.0953846153846 --> Loss 0.00215279916922\n",
      "Epoch 3::Minibatch 712::LR 0.0953846153846 --> Loss 0.00166523118814\n",
      "Epoch 3::Minibatch 713::LR 0.0953846153846 --> Loss 0.00198947469393\n",
      "Epoch 3::Minibatch 714::LR 0.0953846153846 --> Loss 0.00305688718955\n",
      "Epoch 3::Minibatch 715::LR 0.0953846153846 --> Loss 0.00323231319586\n",
      "Epoch 3::Minibatch 716::LR 0.0953846153846 --> Loss 0.00183453718821\n",
      "Epoch 3::Minibatch 717::LR 0.0953846153846 --> Loss 0.00190021455288\n",
      "Epoch 3::Minibatch 718::LR 0.0953846153846 --> Loss 0.00158682465553\n",
      "Epoch 3::Minibatch 719::LR 0.0953846153846 --> Loss 0.00207241753737\n",
      "Epoch 3::Minibatch 720::LR 0.0953846153846 --> Loss 0.00253173728784\n",
      "Epoch 3::Minibatch 721::LR 0.0953846153846 --> Loss 0.000936623811722\n",
      "Epoch 3::Minibatch 722::LR 0.0953846153846 --> Loss 0.00553916017214\n",
      "Epoch 3::Minibatch 723::LR 0.0953846153846 --> Loss 0.00532613833745\n",
      "Epoch 3::Minibatch 724::LR 0.0953846153846 --> Loss 0.00132922917604\n",
      "Epoch 3::Minibatch 725::LR 0.0953846153846 --> Loss 0.00275048275789\n",
      "Epoch 3::Minibatch 726::LR 0.0953846153846 --> Loss 0.00570235610008\n",
      "Epoch 3::Minibatch 727::LR 0.0953846153846 --> Loss 0.00341346780459\n",
      "Epoch 3::Minibatch 728::LR 0.0953846153846 --> Loss 0.00100099245707\n",
      "Epoch 3::Minibatch 729::LR 0.0953846153846 --> Loss 0.00117960135142\n",
      "Epoch 3::Minibatch 730::LR 0.0953846153846 --> Loss 0.00300881922245\n",
      "Epoch 3::Minibatch 731::LR 0.0953846153846 --> Loss 0.00299638609091\n",
      "Epoch 3::Minibatch 732::LR 0.0953846153846 --> Loss 0.00292569975058\n",
      "Epoch 3::Minibatch 733::LR 0.0953846153846 --> Loss 0.00118543018897\n",
      "Epoch 3::Minibatch 734::LR 0.0953846153846 --> Loss 0.0023221685489\n",
      "Epoch 3::Minibatch 735::LR 0.0953846153846 --> Loss 0.00292056043943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 736::LR 0.0953846153846 --> Loss 0.00393829464912\n",
      "Epoch 3::Minibatch 737::LR 0.0953846153846 --> Loss 0.00363333940506\n",
      "Epoch 3::Minibatch 738::LR 0.0953846153846 --> Loss 0.00196240941683\n",
      "Epoch 3::Minibatch 739::LR 0.0953846153846 --> Loss 0.00270614981651\n",
      "Epoch 3::Minibatch 740::LR 0.0953846153846 --> Loss 0.00383940935135\n",
      "Epoch 3::Minibatch 741::LR 0.0953846153846 --> Loss 0.00322267532349\n",
      "Epoch 3::Minibatch 742::LR 0.0953846153846 --> Loss 0.00258598744869\n",
      "Epoch 3::Minibatch 743::LR 0.0953846153846 --> Loss 0.00143236786127\n",
      "Epoch 3::Minibatch 744::LR 0.0953846153846 --> Loss 0.0020699296395\n",
      "Epoch 3::Minibatch 745::LR 0.0953846153846 --> Loss 0.00311343411605\n",
      "Epoch 3::Minibatch 746::LR 0.0953846153846 --> Loss 0.00332927882671\n",
      "Epoch 3::Minibatch 747::LR 0.0953846153846 --> Loss 0.00198257267475\n",
      "Epoch 3::Minibatch 748::LR 0.0953846153846 --> Loss 0.00090360502402\n",
      "Epoch 3::Minibatch 749::LR 0.0953846153846 --> Loss 0.0018685311079\n",
      "Epoch 3::Minibatch 750::LR 0.0953846153846 --> Loss 0.00273503045241\n",
      "Epoch 3::Minibatch 751::LR 0.0953846153846 --> Loss 0.00312997659047\n",
      "Epoch 3::Minibatch 752::LR 0.0953846153846 --> Loss 0.00120720396439\n",
      "Epoch 3::Minibatch 753::LR 0.0953846153846 --> Loss 0.00248689075311\n",
      "Epoch 3::Minibatch 754::LR 0.0953846153846 --> Loss 0.00273587127527\n",
      "Epoch 3::Minibatch 755::LR 0.0953846153846 --> Loss 0.00288596153259\n",
      "Epoch 3::Minibatch 756::LR 0.0953846153846 --> Loss 0.00167731205622\n",
      "Epoch 3::Minibatch 757::LR 0.0953846153846 --> Loss 0.00113557308912\n",
      "Epoch 3::Minibatch 758::LR 0.0953846153846 --> Loss 0.00194988449415\n",
      "Epoch 3::Minibatch 759::LR 0.0953846153846 --> Loss 0.00445870995522\n",
      "Epoch 3::Minibatch 760::LR 0.0953846153846 --> Loss 0.00345641096433\n",
      "Epoch 3::Minibatch 761::LR 0.0953846153846 --> Loss 0.00662024140358\n",
      "Epoch 3::Minibatch 762::LR 0.0953846153846 --> Loss 0.00444988568624\n",
      "Epoch 3::Minibatch 763::LR 0.0953846153846 --> Loss 0.0044836684068\n",
      "Epoch 3::Minibatch 764::LR 0.0953846153846 --> Loss 0.00394888917605\n",
      "Epoch 3::Minibatch 765::LR 0.0953846153846 --> Loss 0.00168423732122\n",
      "Epoch 3::Minibatch 766::LR 0.0953846153846 --> Loss 0.00256513098876\n",
      "Epoch 3::Minibatch 767::LR 0.0953846153846 --> Loss 0.00528123696645\n",
      "Epoch 3::Minibatch 768::LR 0.0953846153846 --> Loss 0.00398030161858\n",
      "Epoch 3::Minibatch 769::LR 0.0953846153846 --> Loss 0.00243559817473\n",
      "Epoch 3::Minibatch 770::LR 0.0953846153846 --> Loss 0.00168311417103\n",
      "Epoch 3::Minibatch 771::LR 0.0953846153846 --> Loss 0.00434997359912\n",
      "Epoch 3::Minibatch 772::LR 0.0953846153846 --> Loss 0.00384081244469\n",
      "Epoch 3::Minibatch 773::LR 0.0953846153846 --> Loss 0.00386298060417\n",
      "Epoch 3::Minibatch 774::LR 0.0953846153846 --> Loss 0.0021504642566\n",
      "Epoch 3::Minibatch 775::LR 0.0953846153846 --> Loss 0.00530399521192\n",
      "Epoch 3::Minibatch 776::LR 0.0953846153846 --> Loss 0.00412084301313\n",
      "Epoch 3::Minibatch 777::LR 0.0953846153846 --> Loss 0.00815304994583\n",
      "Epoch 3::Minibatch 778::LR 0.0953846153846 --> Loss 0.0120668991407\n",
      "Epoch 3::Minibatch 779::LR 0.0953846153846 --> Loss 0.00200205584367\n",
      "Epoch 3::Minibatch 780::LR 0.0953846153846 --> Loss 0.00197197874387\n",
      "Epoch 3::Minibatch 781::LR 0.0953846153846 --> Loss 0.00411884427071\n",
      "Epoch 3::Minibatch 782::LR 0.0953846153846 --> Loss 0.00469388564428\n",
      "Epoch 3::Minibatch 783::LR 0.0953846153846 --> Loss 0.00271791696548\n",
      "Epoch 3::Minibatch 784::LR 0.0953846153846 --> Loss 0.0010532934467\n",
      "Epoch 3::Minibatch 785::LR 0.0953846153846 --> Loss 0.00516532540321\n",
      "Epoch 3::Minibatch 786::LR 0.0953846153846 --> Loss 0.00437403678894\n",
      "Epoch 3::Minibatch 787::LR 0.0953846153846 --> Loss 0.00350482384364\n",
      "Epoch 3::Minibatch 788::LR 0.0953846153846 --> Loss 0.00307377934456\n",
      "Epoch 3::Minibatch 789::LR 0.0953846153846 --> Loss 0.000993764400482\n",
      "Epoch 3::Minibatch 790::LR 0.0953846153846 --> Loss 0.00375541607539\n",
      "Epoch 3::Minibatch 791::LR 0.0953846153846 --> Loss 0.00465695261955\n",
      "Epoch 3::Minibatch 792::LR 0.0953846153846 --> Loss 0.00469665209452\n",
      "Epoch 3::Minibatch 793::LR 0.0953846153846 --> Loss 0.00286136547724\n",
      "Epoch 3::Minibatch 794::LR 0.0953846153846 --> Loss 0.00178801019986\n",
      "Epoch 3::Minibatch 795::LR 0.0953846153846 --> Loss 0.00437656958898\n",
      "Epoch 3::Minibatch 796::LR 0.0953846153846 --> Loss 0.00669930060705\n",
      "Epoch 3::Minibatch 797::LR 0.0953846153846 --> Loss 0.0107519173622\n",
      "Epoch 3::Minibatch 798::LR 0.0953846153846 --> Loss 0.00390726089478\n",
      "Epoch 3::Minibatch 799::LR 0.0953846153846 --> Loss 0.00353009819984\n",
      "Epoch 3::Minibatch 800::LR 0.0953846153846 --> Loss 0.0025897638003\n",
      "Epoch 3::Minibatch 801::LR 0.0953846153846 --> Loss 0.00436990737915\n",
      "Epoch 3::Minibatch 802::LR 0.0953846153846 --> Loss 0.00175032158693\n",
      "Epoch 3::Minibatch 803::LR 0.0953846153846 --> Loss 0.00295347571373\n",
      "Epoch 3::Minibatch 804::LR 0.0953846153846 --> Loss 0.00278498609861\n",
      "Epoch 3::Minibatch 805::LR 0.0953846153846 --> Loss 0.00269807398319\n",
      "Epoch 3::Minibatch 806::LR 0.0953846153846 --> Loss 0.00365424275398\n",
      "Epoch 3::Minibatch 807::LR 0.0953846153846 --> Loss 0.00348993659019\n",
      "Epoch 3::Minibatch 808::LR 0.0953846153846 --> Loss 0.00353738109271\n",
      "Epoch 3::Minibatch 809::LR 0.0953846153846 --> Loss 0.00582436919212\n",
      "Epoch 3::Minibatch 810::LR 0.0953846153846 --> Loss 0.00678756157557\n",
      "Epoch 3::Minibatch 811::LR 0.0953846153846 --> Loss 0.00596955657005\n",
      "Epoch 3::Minibatch 812::LR 0.0953846153846 --> Loss 0.0063783967495\n",
      "Epoch 3::Minibatch 813::LR 0.0953846153846 --> Loss 0.00609923640887\n",
      "Epoch 3::Minibatch 814::LR 0.0953846153846 --> Loss 0.00333533326785\n",
      "Epoch 3::Minibatch 815::LR 0.0953846153846 --> Loss 0.00524436036746\n",
      "Epoch 3::Minibatch 816::LR 0.0953846153846 --> Loss 0.0049606581529\n",
      "Epoch 3::Minibatch 817::LR 0.0953846153846 --> Loss 0.00520624041557\n",
      "Epoch 3::Minibatch 818::LR 0.0953846153846 --> Loss 0.00193050245444\n",
      "Epoch 3::Minibatch 819::LR 0.0953846153846 --> Loss 0.00115265140931\n",
      "Epoch 3::Minibatch 820::LR 0.0953846153846 --> Loss 0.00619582255681\n",
      "Epoch 3::Minibatch 821::LR 0.0953846153846 --> Loss 0.00381302634875\n",
      "Epoch 3::Minibatch 822::LR 0.0953846153846 --> Loss 0.0047699991862\n",
      "Epoch 3::Minibatch 823::LR 0.0953846153846 --> Loss 0.00163547098637\n",
      "Epoch 3::Minibatch 824::LR 0.0953846153846 --> Loss 0.00184075315793\n",
      "Epoch 3::Minibatch 825::LR 0.0953846153846 --> Loss 0.004274614652\n",
      "Epoch 3::Minibatch 826::LR 0.0953846153846 --> Loss 0.00411377668381\n",
      "Epoch 3::Minibatch 827::LR 0.0953846153846 --> Loss 0.00267744938533\n",
      "Epoch 3::Minibatch 828::LR 0.0953846153846 --> Loss 0.0010048909982\n",
      "Epoch 3::Minibatch 829::LR 0.0953846153846 --> Loss 0.00276888151964\n",
      "Epoch 3::Minibatch 830::LR 0.0953846153846 --> Loss 0.00479877034823\n",
      "Epoch 3::Minibatch 831::LR 0.0953846153846 --> Loss 0.00290177822113\n",
      "Epoch 3::Minibatch 832::LR 0.0953846153846 --> Loss 0.00271034955978\n",
      "Epoch 3::Minibatch 833::LR 0.0953846153846 --> Loss 0.00205038845539\n",
      "Epoch 3::Minibatch 834::LR 0.0953846153846 --> Loss 0.00102516452471\n",
      "Epoch 3::Minibatch 835::LR 0.0953846153846 --> Loss 0.00414578040441\n",
      "Epoch 3::Minibatch 836::LR 0.0953846153846 --> Loss 0.00442000428836\n",
      "Epoch 3::Minibatch 837::LR 0.0953846153846 --> Loss 0.00326407412688\n",
      "Epoch 3::Minibatch 838::LR 0.0953846153846 --> Loss 0.00130246142546\n",
      "Epoch 3::Minibatch 839::LR 0.0953846153846 --> Loss 0.00293846507867\n",
      "Epoch 3::Minibatch 840::LR 0.0953846153846 --> Loss 0.00368655641874\n",
      "Epoch 3::Minibatch 841::LR 0.0953846153846 --> Loss 0.00383449077606\n",
      "Epoch 3::Minibatch 842::LR 0.0953846153846 --> Loss 0.00290582160155\n",
      "Epoch 3::Minibatch 843::LR 0.0953846153846 --> Loss 0.00130711476008\n",
      "Epoch 3::Minibatch 844::LR 0.0953846153846 --> Loss 0.00194374541442\n",
      "Epoch 3::Minibatch 845::LR 0.0953846153846 --> Loss 0.00462656656901\n",
      "Epoch 3::Minibatch 846::LR 0.0953846153846 --> Loss 0.00205912947655\n",
      "Epoch 3::Minibatch 847::LR 0.0953846153846 --> Loss 0.00323492944241\n",
      "Epoch 3::Minibatch 848::LR 0.0953846153846 --> Loss 0.00167170961698\n",
      "Epoch 3::Minibatch 849::LR 0.0953846153846 --> Loss 0.00238564888636\n",
      "Epoch 3::Minibatch 850::LR 0.0953846153846 --> Loss 0.00352770209312\n",
      "Epoch 3::Minibatch 851::LR 0.0953846153846 --> Loss 0.00338070948919\n",
      "Epoch 3::Minibatch 852::LR 0.0953846153846 --> Loss 0.00154079496861\n",
      "Epoch 3::Minibatch 853::LR 0.0953846153846 --> Loss 0.00165802121162\n",
      "Epoch 3::Minibatch 854::LR 0.0953846153846 --> Loss 0.00269578735034\n",
      "Epoch 3::Minibatch 855::LR 0.0953846153846 --> Loss 0.00242505073547\n",
      "Epoch 3::Minibatch 856::LR 0.0953846153846 --> Loss 0.00202250460784\n",
      "Epoch 3::Minibatch 857::LR 0.0953846153846 --> Loss 0.00139647434155\n",
      "Epoch 3::Minibatch 858::LR 0.0953846153846 --> Loss 0.000860004723072\n",
      "Epoch 3::Minibatch 859::LR 0.0953846153846 --> Loss 0.0020705117782\n",
      "Epoch 3::Minibatch 860::LR 0.0953846153846 --> Loss 0.00138259987036\n",
      "Epoch 3::Minibatch 861::LR 0.0953846153846 --> Loss 0.00112180560827\n",
      "Epoch 3::Minibatch 862::LR 0.0953846153846 --> Loss 0.0038302954038\n",
      "Epoch 3::Minibatch 863::LR 0.0953846153846 --> Loss 0.00342207193375\n",
      "Epoch 3::Minibatch 864::LR 0.0953846153846 --> Loss 0.00355869611104\n",
      "Epoch 3::Minibatch 865::LR 0.0953846153846 --> Loss 0.000798893918594\n",
      "Epoch 3::Minibatch 866::LR 0.0953846153846 --> Loss 0.00246244211992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 867::LR 0.0953846153846 --> Loss 0.00334971904755\n",
      "Epoch 3::Minibatch 868::LR 0.0953846153846 --> Loss 0.00316147784392\n",
      "Epoch 3::Minibatch 869::LR 0.0953846153846 --> Loss 0.00235424061616\n",
      "Epoch 3::Minibatch 870::LR 0.0953846153846 --> Loss 0.00395757834117\n",
      "Epoch 3::Minibatch 871::LR 0.0953846153846 --> Loss 0.00181199351947\n",
      "Epoch 3::Minibatch 872::LR 0.0953846153846 --> Loss 0.00284017324448\n",
      "Epoch 3::Minibatch 873::LR 0.0953846153846 --> Loss 0.00287955443064\n",
      "Epoch 3::Minibatch 874::LR 0.0953846153846 --> Loss 0.00669022083282\n",
      "Epoch 3::Minibatch 875::LR 0.0953846153846 --> Loss 0.000705396682024\n",
      "Epoch 3::Minibatch 876::LR 0.0953846153846 --> Loss 0.00438151717186\n",
      "Epoch 3::Minibatch 877::LR 0.0953846153846 --> Loss 0.00689980983734\n",
      "Epoch 3::Minibatch 878::LR 0.0953846153846 --> Loss 0.00389388481776\n",
      "Epoch 3::Minibatch 879::LR 0.0953846153846 --> Loss 0.0042307694753\n",
      "Epoch 3::Minibatch 880::LR 0.0953846153846 --> Loss 0.00480513532956\n",
      "Epoch 3::Minibatch 881::LR 0.0953846153846 --> Loss 0.00438293019931\n",
      "Epoch 3::Minibatch 882::LR 0.0953846153846 --> Loss 0.00242972671986\n",
      "Epoch 3::Minibatch 883::LR 0.0953846153846 --> Loss 0.003420971632\n",
      "Epoch 3::Minibatch 884::LR 0.0953846153846 --> Loss 0.0028336751461\n",
      "Epoch 3::Minibatch 885::LR 0.0953846153846 --> Loss 0.00288565556208\n",
      "Epoch 3::Minibatch 886::LR 0.0953846153846 --> Loss 0.00128647665183\n",
      "Epoch 3::Minibatch 887::LR 0.0953846153846 --> Loss 0.00604763031006\n",
      "Epoch 3::Minibatch 888::LR 0.0953846153846 --> Loss 0.00282656113307\n",
      "Epoch 3::Minibatch 889::LR 0.0953846153846 --> Loss 0.00421272595723\n",
      "Epoch 3::Minibatch 890::LR 0.0953846153846 --> Loss 0.00532694021861\n",
      "Epoch 3::Minibatch 891::LR 0.0953846153846 --> Loss 0.00275889575481\n",
      "Epoch 3::Minibatch 892::LR 0.0953846153846 --> Loss 0.00134174853563\n",
      "Epoch 3::Minibatch 893::LR 0.0953846153846 --> Loss 0.0030676929156\n",
      "Epoch 3::Minibatch 894::LR 0.0953846153846 --> Loss 0.00277826488018\n",
      "Epoch 3::Minibatch 895::LR 0.0953846153846 --> Loss 0.002875897487\n",
      "Epoch 3::Minibatch 896::LR 0.0953846153846 --> Loss 0.00194764018059\n",
      "Epoch 3::Minibatch 897::LR 0.0953846153846 --> Loss 0.00111631294092\n",
      "Epoch 3::Minibatch 898::LR 0.0953846153846 --> Loss 0.00266035139561\n",
      "Epoch 3::Minibatch 899::LR 0.0953846153846 --> Loss 0.00268521328767\n",
      "Epoch 3::Minibatch 900::LR 0.0953846153846 --> Loss 0.00359905203183\n",
      "Epoch 3::Minibatch 901::LR 0.0953846153846 --> Loss 0.000861219763756\n",
      "Epoch 3::Minibatch 902::LR 0.0953846153846 --> Loss 0.00163888136546\n",
      "Epoch 3::Minibatch 903::LR 0.0953846153846 --> Loss 0.0030779582262\n",
      "Epoch 3::Minibatch 904::LR 0.0953846153846 --> Loss 0.00262858351072\n",
      "Epoch 3::Minibatch 905::LR 0.0953846153846 --> Loss 0.00162132839362\n",
      "Epoch 3::Minibatch 906::LR 0.0953846153846 --> Loss 0.00124541680018\n",
      "Epoch 3::Minibatch 907::LR 0.0953846153846 --> Loss 0.00163119465113\n",
      "Epoch 3::Minibatch 908::LR 0.0953846153846 --> Loss 0.00308878759543\n",
      "Epoch 3::Minibatch 909::LR 0.0953846153846 --> Loss 0.00272482812405\n",
      "Epoch 3::Minibatch 910::LR 0.0953846153846 --> Loss 0.000987136860689\n",
      "Epoch 3::Minibatch 911::LR 0.0953846153846 --> Loss 0.00138690610727\n",
      "Epoch 3::Minibatch 912::LR 0.0953846153846 --> Loss 0.00250626524289\n",
      "Epoch 3::Minibatch 913::LR 0.0953846153846 --> Loss 0.0023353022337\n",
      "Epoch 3::Minibatch 914::LR 0.0953846153846 --> Loss 0.00144718428453\n",
      "Epoch 3::Minibatch 915::LR 0.0953846153846 --> Loss 0.000635602722565\n",
      "Epoch 3::Minibatch 916::LR 0.0953846153846 --> Loss 0.00315360307693\n",
      "Epoch 3::Minibatch 917::LR 0.0953846153846 --> Loss 0.00453886548678\n",
      "Epoch 3::Minibatch 918::LR 0.0953846153846 --> Loss 0.00683663606644\n",
      "Epoch 3::Minibatch 919::LR 0.0953846153846 --> Loss 0.00146235197783\n",
      "Epoch 3::Minibatch 920::LR 0.0953846153846 --> Loss 0.00840898752213\n",
      "Epoch 3::Minibatch 921::LR 0.0953846153846 --> Loss 0.00357072353363\n",
      "Epoch 3::Minibatch 922::LR 0.0953846153846 --> Loss 0.00362468918165\n",
      "Epoch 3::Minibatch 923::LR 0.0953846153846 --> Loss 0.00214173813661\n",
      "Epoch 3::Minibatch 924::LR 0.0953846153846 --> Loss 0.00384803295135\n",
      "Epoch 3::Minibatch 925::LR 0.0953846153846 --> Loss 0.00358764370282\n",
      "Epoch 3::Minibatch 926::LR 0.0953846153846 --> Loss 0.00605223496755\n",
      "Epoch 3::Minibatch 927::LR 0.0953846153846 --> Loss 0.0103134973844\n",
      "Epoch 3::Minibatch 928::LR 0.0953846153846 --> Loss 0.00725109497706\n",
      "Epoch 3::Minibatch 929::LR 0.0953846153846 --> Loss 0.0116526174545\n",
      "Epoch 3::Minibatch 930::LR 0.0953846153846 --> Loss 0.00874017159144\n",
      "Epoch 3::Minibatch 931::LR 0.0953846153846 --> Loss 0.00475819508235\n",
      "Epoch 3::Minibatch 932::LR 0.0953846153846 --> Loss 0.0103295556704\n",
      "Epoch 3::Minibatch 933::LR 0.0953846153846 --> Loss 0.00599299629529\n",
      "Epoch 3::Minibatch 934::LR 0.0953846153846 --> Loss 0.00786039511363\n",
      "Epoch 3::Minibatch 935::LR 0.0953846153846 --> Loss 0.00960051059723\n",
      "Epoch 3::Minibatch 936::LR 0.0953846153846 --> Loss 0.00367319583893\n",
      "Epoch 3::Minibatch 937::LR 0.0953846153846 --> Loss 0.00574345429738\n",
      "Epoch 3::Minibatch 938::LR 0.0953846153846 --> Loss 0.00562245527903\n",
      "Epoch 3::Minibatch 939::LR 0.0953846153846 --> Loss 0.00582283218702\n",
      "Epoch 3::Minibatch 940::LR 0.0953846153846 --> Loss 0.0016805768013\n",
      "Epoch 3::Minibatch 941::LR 0.0953846153846 --> Loss 0.00147134164969\n",
      "Epoch 3::Minibatch 942::LR 0.0953846153846 --> Loss 0.00277390301228\n",
      "Epoch 3::Minibatch 943::LR 0.0953846153846 --> Loss 0.00459001342456\n",
      "Epoch 3::Minibatch 944::LR 0.0953846153846 --> Loss 0.00391351779302\n",
      "Epoch 3::Minibatch 945::LR 0.0953846153846 --> Loss 0.00259477774302\n",
      "Epoch 3::Minibatch 946::LR 0.0953846153846 --> Loss 0.00489042719205\n",
      "Epoch 3::Minibatch 947::LR 0.0953846153846 --> Loss 0.00424475868543\n",
      "Epoch 3::Minibatch 948::LR 0.0953846153846 --> Loss 0.00671695550283\n",
      "Epoch 3::Minibatch 949::LR 0.0953846153846 --> Loss 0.00245439827442\n",
      "Epoch 3::Minibatch 950::LR 0.0953846153846 --> Loss 0.000983409583569\n",
      "Epoch 3::Minibatch 951::LR 0.0953846153846 --> Loss 0.00379211465518\n",
      "Epoch 3::Minibatch 952::LR 0.0953846153846 --> Loss 0.00289212465286\n",
      "Epoch 3::Minibatch 953::LR 0.0953846153846 --> Loss 0.00153233816226\n",
      "Epoch 3::Minibatch 954::LR 0.0953846153846 --> Loss 0.00119741578897\n",
      "Epoch 3::Minibatch 955::LR 0.0953846153846 --> Loss 0.00279731889566\n",
      "Epoch 3::Minibatch 956::LR 0.0953846153846 --> Loss 0.00529772520065\n",
      "Epoch 3::Minibatch 957::LR 0.0953846153846 --> Loss 0.00232578297456\n",
      "Epoch 3::Minibatch 958::LR 0.0953846153846 --> Loss 0.00334183216095\n",
      "Epoch 3::Minibatch 959::LR 0.0953846153846 --> Loss 0.00414559602737\n",
      "Epoch 3::Minibatch 960::LR 0.0953846153846 --> Loss 0.00751501878103\n",
      "Epoch 3::Minibatch 961::LR 0.0953846153846 --> Loss 0.00410363038381\n",
      "Epoch 3::Minibatch 962::LR 0.0953846153846 --> Loss 0.0037331990401\n",
      "Epoch 3::Minibatch 963::LR 0.0953846153846 --> Loss 0.00213865021865\n",
      "Epoch 3::Minibatch 964::LR 0.0953846153846 --> Loss 0.00322087665399\n",
      "Epoch 3::Minibatch 965::LR 0.0953846153846 --> Loss 0.00938764651616\n",
      "Epoch 3::Minibatch 966::LR 0.0953846153846 --> Loss 0.00585215449333\n",
      "Epoch 3::Minibatch 967::LR 0.0953846153846 --> Loss 0.00261379102866\n",
      "Epoch 3::Minibatch 968::LR 0.0953846153846 --> Loss 0.00231791953246\n",
      "Epoch 3::Minibatch 969::LR 0.0953846153846 --> Loss 0.00829414049784\n",
      "Epoch 3::Minibatch 970::LR 0.0953846153846 --> Loss 0.0066419617335\n",
      "Epoch 3::Minibatch 971::LR 0.0953846153846 --> Loss 0.00379262208939\n",
      "Epoch 3::Minibatch 972::LR 0.0953846153846 --> Loss 0.00868299245834\n",
      "Epoch 3::Minibatch 973::LR 0.0953846153846 --> Loss 0.0120658254623\n",
      "Epoch 3::Minibatch 974::LR 0.0953846153846 --> Loss 0.00604065219561\n",
      "Epoch 3::Minibatch 975::LR 0.0953846153846 --> Loss 0.00547188798587\n",
      "Epoch 3::Minibatch 976::LR 0.0953846153846 --> Loss 0.00493986884753\n",
      "Epoch 3::Minibatch 977::LR 0.0953846153846 --> Loss 0.00502259850502\n",
      "Epoch 3::Minibatch 978::LR 0.0953846153846 --> Loss 0.00489549517632\n",
      "Epoch 3::Minibatch 979::LR 0.0953846153846 --> Loss 0.00489748517672\n",
      "Epoch 3::Minibatch 980::LR 0.0953846153846 --> Loss 0.00452541271845\n",
      "Epoch 3::Minibatch 981::LR 0.0953846153846 --> Loss 0.00590004205704\n",
      "Epoch 3::Minibatch 982::LR 0.0953846153846 --> Loss 0.00677959442139\n",
      "Epoch 3::Minibatch 983::LR 0.0953846153846 --> Loss 0.00402532259623\n",
      "Epoch 3::Minibatch 984::LR 0.0953846153846 --> Loss 0.00306838989258\n",
      "Epoch 3::Minibatch 985::LR 0.0953846153846 --> Loss 0.00470199863116\n",
      "Epoch 3::Minibatch 986::LR 0.0953846153846 --> Loss 0.00407181620598\n",
      "Epoch 3::Minibatch 987::LR 0.0953846153846 --> Loss 0.00438779910405\n",
      "Epoch 3::Minibatch 988::LR 0.0953846153846 --> Loss 0.00334074179331\n",
      "Epoch 3::Minibatch 989::LR 0.0953846153846 --> Loss 0.00324500064055\n",
      "Epoch 3::Minibatch 990::LR 0.0953846153846 --> Loss 0.00375513156255\n",
      "Epoch 3::Minibatch 991::LR 0.0953846153846 --> Loss 0.00162008911371\n",
      "Epoch 3::Minibatch 992::LR 0.0953846153846 --> Loss 0.00195434610049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 993::LR 0.0953846153846 --> Loss 0.00313374956449\n",
      "Epoch 3::Minibatch 994::LR 0.0953846153846 --> Loss 0.00213673770428\n",
      "Epoch 3::Minibatch 995::LR 0.0953846153846 --> Loss 0.0012134590745\n",
      "Epoch 3::Minibatch 996::LR 0.0953846153846 --> Loss 0.00374569694201\n",
      "Epoch 3::Minibatch 997::LR 0.0953846153846 --> Loss 0.00166792094707\n",
      "Epoch 3::Minibatch 998::LR 0.0953846153846 --> Loss 0.00186128516992\n",
      "Epoch 3::Minibatch 999::LR 0.0953846153846 --> Loss 0.00186148027579\n",
      "Epoch 3::Minibatch 1000::LR 0.0953846153846 --> Loss 0.00186046659946\n",
      "Epoch 3::Minibatch 1001::LR 0.0953846153846 --> Loss 0.00162244737148\n",
      "Epoch 3::Minibatch 1002::LR 0.0953846153846 --> Loss 0.00651667515437\n",
      "Epoch 3::Minibatch 1003::LR 0.0953846153846 --> Loss 0.00560820778211\n",
      "Epoch 3::Minibatch 1004::LR 0.0953846153846 --> Loss 0.00137584964434\n",
      "Epoch 3::Minibatch 1005::LR 0.0953846153846 --> Loss 0.00689157009125\n",
      "Epoch 3::Minibatch 1006::LR 0.0953846153846 --> Loss 0.00539920171102\n",
      "Epoch 3::Minibatch 1007::LR 0.0953846153846 --> Loss 0.00422397255898\n",
      "Epoch 3::Minibatch 1008::LR 0.0953846153846 --> Loss 0.00121218830347\n",
      "Epoch 3::Minibatch 1009::LR 0.0953846153846 --> Loss 0.0029835275809\n",
      "Epoch 3::Minibatch 1010::LR 0.0953846153846 --> Loss 0.00213563640912\n",
      "Epoch 3::Minibatch 1011::LR 0.0953846153846 --> Loss 0.00396407604218\n",
      "Epoch 3::Minibatch 1012::LR 0.0953846153846 --> Loss 0.00338612039884\n",
      "Epoch 3::Minibatch 1013::LR 0.0953846153846 --> Loss 0.00470318953196\n",
      "Epoch 3::Minibatch 1014::LR 0.0953846153846 --> Loss 0.00485710700353\n",
      "Epoch 3::Minibatch 1015::LR 0.0953846153846 --> Loss 0.0024106913805\n",
      "Epoch 3::Minibatch 1016::LR 0.0953846153846 --> Loss 0.00478537678719\n",
      "Epoch 3::Minibatch 1017::LR 0.0953846153846 --> Loss 0.00607549707095\n",
      "Epoch 3::Minibatch 1018::LR 0.0953846153846 --> Loss 0.00412814180056\n",
      "Epoch 3::Minibatch 1019::LR 0.0953846153846 --> Loss 0.00358686645826\n",
      "Epoch 3::Minibatch 1020::LR 0.0953846153846 --> Loss 0.00348360935847\n",
      "Epoch 3::Minibatch 1021::LR 0.0953846153846 --> Loss 0.00327046851317\n",
      "Epoch 3::Minibatch 1022::LR 0.0953846153846 --> Loss 0.00277091662089\n",
      "Epoch 3::Minibatch 1023::LR 0.0953846153846 --> Loss 0.00239286879698\n",
      "Epoch 3::Minibatch 1024::LR 0.0953846153846 --> Loss 0.00223348875841\n",
      "Epoch 3::Minibatch 1025::LR 0.0953846153846 --> Loss 0.00278876940409\n",
      "Epoch 3::Minibatch 1026::LR 0.0953846153846 --> Loss 0.0023833022515\n",
      "Epoch 3::Minibatch 1027::LR 0.0953846153846 --> Loss 0.00223468999068\n",
      "Epoch 3::Minibatch 1028::LR 0.0953846153846 --> Loss 0.00185358703136\n",
      "Epoch 3::Minibatch 1029::LR 0.0953846153846 --> Loss 0.00144762396812\n",
      "Epoch 3::Minibatch 1030::LR 0.0953846153846 --> Loss 0.00159121294816\n",
      "Epoch 3::Minibatch 1031::LR 0.0953846153846 --> Loss 0.00131057024002\n",
      "Epoch 3::Minibatch 1032::LR 0.0953846153846 --> Loss 0.00116126159827\n",
      "Epoch 3::Minibatch 1033::LR 0.0953846153846 --> Loss 0.000909611781438\n",
      "Epoch 3::Minibatch 1034::LR 0.0953846153846 --> Loss 0.000933336118857\n",
      "Epoch 3::Minibatch 1035::LR 0.0953846153846 --> Loss 0.000644019196431\n",
      "Epoch 3::Minibatch 1036::LR 0.0953846153846 --> Loss 0.00044740319252\n",
      "Epoch 3::Minibatch 1037::LR 0.0953846153846 --> Loss 0.000675083597501\n",
      "Epoch 3::Minibatch 1038::LR 0.0953846153846 --> Loss 0.00146442780892\n",
      "Epoch 3::Minibatch 1039::LR 0.0953846153846 --> Loss 0.00137959818045\n",
      "Epoch 3::Minibatch 1040::LR 0.0953846153846 --> Loss 0.000663420408964\n",
      "Epoch 3::Minibatch 1041::LR 0.0953846153846 --> Loss 0.000733639597893\n",
      "Epoch 4::Minibatch 1::LR 0.0930769230769 --> Loss 0.0191352891922\n",
      "Epoch 4::Minibatch 2::LR 0.0930769230769 --> Loss 0.013615655899\n",
      "Epoch 4::Minibatch 3::LR 0.0930769230769 --> Loss 0.0123745616277\n",
      "Epoch 4::Minibatch 4::LR 0.0930769230769 --> Loss 0.0102066127459\n",
      "Epoch 4::Minibatch 5::LR 0.0930769230769 --> Loss 0.00751349608103\n",
      "Epoch 4::Minibatch 6::LR 0.0930769230769 --> Loss 0.00321673989296\n",
      "Epoch 4::Minibatch 7::LR 0.0930769230769 --> Loss 0.0101123976707\n",
      "Epoch 4::Minibatch 8::LR 0.0930769230769 --> Loss 0.0115493504206\n",
      "Epoch 4::Minibatch 9::LR 0.0930769230769 --> Loss 0.0090504082044\n",
      "Epoch 4::Minibatch 10::LR 0.0930769230769 --> Loss 0.00483039339383\n",
      "Epoch 4::Minibatch 11::LR 0.0930769230769 --> Loss 0.00389687935511\n",
      "Epoch 4::Minibatch 12::LR 0.0930769230769 --> Loss 0.0059523053964\n",
      "Epoch 4::Minibatch 13::LR 0.0930769230769 --> Loss 0.00740577777227\n",
      "Epoch 4::Minibatch 14::LR 0.0930769230769 --> Loss 0.00647539893786\n",
      "Epoch 4::Minibatch 15::LR 0.0930769230769 --> Loss 0.00466408133507\n",
      "Epoch 4::Minibatch 16::LR 0.0930769230769 --> Loss 0.00158229768276\n",
      "Epoch 4::Minibatch 17::LR 0.0930769230769 --> Loss 0.00384805520376\n",
      "Epoch 4::Minibatch 18::LR 0.0930769230769 --> Loss 0.00349545081457\n",
      "Epoch 4::Minibatch 19::LR 0.0930769230769 --> Loss 0.00121042132378\n",
      "Epoch 4::Minibatch 20::LR 0.0930769230769 --> Loss 0.00176497658094\n",
      "Epoch 4::Minibatch 21::LR 0.0930769230769 --> Loss 0.00368247747421\n",
      "Epoch 4::Minibatch 22::LR 0.0930769230769 --> Loss 0.00320285061995\n",
      "Epoch 4::Minibatch 23::LR 0.0930769230769 --> Loss 0.00152351250251\n",
      "Epoch 4::Minibatch 24::LR 0.0930769230769 --> Loss 0.000684421161811\n",
      "Epoch 4::Minibatch 25::LR 0.0930769230769 --> Loss 0.0016379660368\n",
      "Epoch 4::Minibatch 26::LR 0.0930769230769 --> Loss 0.00195806006591\n",
      "Epoch 4::Minibatch 27::LR 0.0930769230769 --> Loss 0.00175064166387\n",
      "Epoch 4::Minibatch 28::LR 0.0930769230769 --> Loss 0.000614845951398\n",
      "Epoch 4::Minibatch 29::LR 0.0930769230769 --> Loss 0.000530932794015\n",
      "Epoch 4::Minibatch 30::LR 0.0930769230769 --> Loss 0.00118501365185\n",
      "Epoch 4::Minibatch 31::LR 0.0930769230769 --> Loss 0.00181776762009\n",
      "Epoch 4::Minibatch 32::LR 0.0930769230769 --> Loss 0.00187765737375\n",
      "Epoch 4::Minibatch 33::LR 0.0930769230769 --> Loss 0.000878296991189\n",
      "Epoch 4::Minibatch 34::LR 0.0930769230769 --> Loss 0.00304826339086\n",
      "Epoch 4::Minibatch 35::LR 0.0930769230769 --> Loss 0.00393026351929\n",
      "Epoch 4::Minibatch 36::LR 0.0930769230769 --> Loss 0.00234398245811\n",
      "Epoch 4::Minibatch 37::LR 0.0930769230769 --> Loss 0.000644406030575\n",
      "Epoch 4::Minibatch 38::LR 0.0930769230769 --> Loss 0.00102449456851\n",
      "Epoch 4::Minibatch 39::LR 0.0930769230769 --> Loss 0.00317116002242\n",
      "Epoch 4::Minibatch 40::LR 0.0930769230769 --> Loss 0.00370173335075\n",
      "Epoch 4::Minibatch 41::LR 0.0930769230769 --> Loss 0.00402149796486\n",
      "Epoch 4::Minibatch 42::LR 0.0930769230769 --> Loss 0.00540265162786\n",
      "Epoch 4::Minibatch 43::LR 0.0930769230769 --> Loss 0.00217185417811\n",
      "Epoch 4::Minibatch 44::LR 0.0930769230769 --> Loss 0.00326281984647\n",
      "Epoch 4::Minibatch 45::LR 0.0930769230769 --> Loss 0.00302203158538\n",
      "Epoch 4::Minibatch 46::LR 0.0930769230769 --> Loss 0.00402731100718\n",
      "Epoch 4::Minibatch 47::LR 0.0930769230769 --> Loss 0.00559615174929\n",
      "Epoch 4::Minibatch 48::LR 0.0930769230769 --> Loss 0.0058592526118\n",
      "Epoch 4::Minibatch 49::LR 0.0930769230769 --> Loss 0.00602586110433\n",
      "Epoch 4::Minibatch 50::LR 0.0930769230769 --> Loss 0.00507630149523\n",
      "Epoch 4::Minibatch 51::LR 0.0930769230769 --> Loss 0.00870152950287\n",
      "Epoch 4::Minibatch 52::LR 0.0930769230769 --> Loss 0.00333368937174\n",
      "Epoch 4::Minibatch 53::LR 0.0930769230769 --> Loss 0.00358059763908\n",
      "Epoch 4::Minibatch 54::LR 0.0930769230769 --> Loss 0.00416184266408\n",
      "Epoch 4::Minibatch 55::LR 0.0930769230769 --> Loss 0.00182517548402\n",
      "Epoch 4::Minibatch 56::LR 0.0930769230769 --> Loss 0.00340150554975\n",
      "Epoch 4::Minibatch 57::LR 0.0930769230769 --> Loss 0.00605711023013\n",
      "Epoch 4::Minibatch 58::LR 0.0930769230769 --> Loss 0.00460464596748\n",
      "Epoch 4::Minibatch 59::LR 0.0930769230769 --> Loss 0.0039329123497\n",
      "Epoch 4::Minibatch 60::LR 0.0930769230769 --> Loss 0.00296086211999\n",
      "Epoch 4::Minibatch 61::LR 0.0930769230769 --> Loss 0.00151483078798\n",
      "Epoch 4::Minibatch 62::LR 0.0930769230769 --> Loss 0.00402322610219\n",
      "Epoch 4::Minibatch 63::LR 0.0930769230769 --> Loss 0.0026817748944\n",
      "Epoch 4::Minibatch 64::LR 0.0930769230769 --> Loss 0.00139517982801\n",
      "Epoch 4::Minibatch 65::LR 0.0930769230769 --> Loss 0.00272546569506\n",
      "Epoch 4::Minibatch 66::LR 0.0930769230769 --> Loss 0.00337235411008\n",
      "Epoch 4::Minibatch 67::LR 0.0930769230769 --> Loss 0.00322623928388\n",
      "Epoch 4::Minibatch 68::LR 0.0930769230769 --> Loss 0.00220411876837\n",
      "Epoch 4::Minibatch 69::LR 0.0930769230769 --> Loss 0.00389398535093\n",
      "Epoch 4::Minibatch 70::LR 0.0930769230769 --> Loss 0.00365205566088\n",
      "Epoch 4::Minibatch 71::LR 0.0930769230769 --> Loss 0.00280702213446\n",
      "Epoch 4::Minibatch 72::LR 0.0930769230769 --> Loss 0.000714896172285\n",
      "Epoch 4::Minibatch 73::LR 0.0930769230769 --> Loss 0.00373193025589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 74::LR 0.0930769230769 --> Loss 0.00459739406904\n",
      "Epoch 4::Minibatch 75::LR 0.0930769230769 --> Loss 0.00236546357473\n",
      "Epoch 4::Minibatch 76::LR 0.0930769230769 --> Loss 0.000921523968379\n",
      "Epoch 4::Minibatch 77::LR 0.0930769230769 --> Loss 0.00513641834259\n",
      "Epoch 4::Minibatch 78::LR 0.0930769230769 --> Loss 0.00428705215454\n",
      "Epoch 4::Minibatch 79::LR 0.0930769230769 --> Loss 0.00236370265484\n",
      "Epoch 4::Minibatch 80::LR 0.0930769230769 --> Loss 0.00405243555705\n",
      "Epoch 4::Minibatch 81::LR 0.0930769230769 --> Loss 0.00367707014084\n",
      "Epoch 4::Minibatch 82::LR 0.0930769230769 --> Loss 0.00237509568532\n",
      "Epoch 4::Minibatch 83::LR 0.0930769230769 --> Loss 0.00618821620941\n",
      "Epoch 4::Minibatch 84::LR 0.0930769230769 --> Loss 0.00249722679456\n",
      "Epoch 4::Minibatch 85::LR 0.0930769230769 --> Loss 0.00319203416506\n",
      "Epoch 4::Minibatch 86::LR 0.0930769230769 --> Loss 0.00292618811131\n",
      "Epoch 4::Minibatch 87::LR 0.0930769230769 --> Loss 0.00298438966274\n",
      "Epoch 4::Minibatch 88::LR 0.0930769230769 --> Loss 0.00244573116302\n",
      "Epoch 4::Minibatch 89::LR 0.0930769230769 --> Loss 0.00298100729783\n",
      "Epoch 4::Minibatch 90::LR 0.0930769230769 --> Loss 0.00151689648628\n",
      "Epoch 4::Minibatch 91::LR 0.0930769230769 --> Loss 0.00129522422949\n",
      "Epoch 4::Minibatch 92::LR 0.0930769230769 --> Loss 0.00291475673517\n",
      "Epoch 4::Minibatch 93::LR 0.0930769230769 --> Loss 0.00206813514233\n",
      "Epoch 4::Minibatch 94::LR 0.0930769230769 --> Loss 0.00202722847462\n",
      "Epoch 4::Minibatch 95::LR 0.0930769230769 --> Loss 0.00184500396252\n",
      "Epoch 4::Minibatch 96::LR 0.0930769230769 --> Loss 0.00602039694786\n",
      "Epoch 4::Minibatch 97::LR 0.0930769230769 --> Loss 0.00321102579435\n",
      "Epoch 4::Minibatch 98::LR 0.0930769230769 --> Loss 0.00103403230508\n",
      "Epoch 4::Minibatch 99::LR 0.0930769230769 --> Loss 0.00143196264903\n",
      "Epoch 4::Minibatch 100::LR 0.0930769230769 --> Loss 0.00626697301865\n",
      "Epoch 4::Minibatch 101::LR 0.0930769230769 --> Loss 0.00130975743135\n",
      "Epoch 4::Minibatch 102::LR 0.0930769230769 --> Loss 0.00367405692736\n",
      "Epoch 4::Minibatch 103::LR 0.0930769230769 --> Loss 0.00410456856092\n",
      "Epoch 4::Minibatch 104::LR 0.0930769230769 --> Loss 0.00328693091869\n",
      "Epoch 4::Minibatch 105::LR 0.0930769230769 --> Loss 0.00388053337733\n",
      "Epoch 4::Minibatch 106::LR 0.0930769230769 --> Loss 0.0178168757757\n",
      "Epoch 4::Minibatch 107::LR 0.0930769230769 --> Loss 0.00511712114016\n",
      "Epoch 4::Minibatch 108::LR 0.0930769230769 --> Loss 0.00162880520026\n",
      "Epoch 4::Minibatch 109::LR 0.0930769230769 --> Loss 0.00500468413035\n",
      "Epoch 4::Minibatch 110::LR 0.0930769230769 --> Loss 0.00305105745792\n",
      "Epoch 4::Minibatch 111::LR 0.0930769230769 --> Loss 0.00156214753787\n",
      "Epoch 4::Minibatch 112::LR 0.0930769230769 --> Loss 0.00418701211611\n",
      "Epoch 4::Minibatch 113::LR 0.0930769230769 --> Loss 0.0033805290858\n",
      "Epoch 4::Minibatch 114::LR 0.0930769230769 --> Loss 0.00201984306177\n",
      "Epoch 4::Minibatch 115::LR 0.0930769230769 --> Loss 0.00200404663881\n",
      "Epoch 4::Minibatch 116::LR 0.0930769230769 --> Loss 0.00334874510765\n",
      "Epoch 4::Minibatch 117::LR 0.0930769230769 --> Loss 0.00397638161977\n",
      "Epoch 4::Minibatch 118::LR 0.0930769230769 --> Loss 0.00705136458079\n",
      "Epoch 4::Minibatch 119::LR 0.0930769230769 --> Loss 0.00116203894218\n",
      "Epoch 4::Minibatch 120::LR 0.0930769230769 --> Loss 0.00248563309511\n",
      "Epoch 4::Minibatch 121::LR 0.0930769230769 --> Loss 0.00339270512263\n",
      "Epoch 4::Minibatch 122::LR 0.0930769230769 --> Loss 0.00385820706685\n",
      "Epoch 4::Minibatch 123::LR 0.0930769230769 --> Loss 0.00181364297867\n",
      "Epoch 4::Minibatch 124::LR 0.0930769230769 --> Loss 0.00322726786137\n",
      "Epoch 4::Minibatch 125::LR 0.0930769230769 --> Loss 0.00516895413399\n",
      "Epoch 4::Minibatch 126::LR 0.0930769230769 --> Loss 0.00348609089851\n",
      "Epoch 4::Minibatch 127::LR 0.0930769230769 --> Loss 0.00534805258115\n",
      "Epoch 4::Minibatch 128::LR 0.0930769230769 --> Loss 0.00407679637273\n",
      "Epoch 4::Minibatch 129::LR 0.0930769230769 --> Loss 0.00357930620511\n",
      "Epoch 4::Minibatch 130::LR 0.0930769230769 --> Loss 0.00482198834419\n",
      "Epoch 4::Minibatch 131::LR 0.0930769230769 --> Loss 0.00238958597183\n",
      "Epoch 4::Minibatch 132::LR 0.0930769230769 --> Loss 0.00371401071548\n",
      "Epoch 4::Minibatch 133::LR 0.0930769230769 --> Loss 0.00362556775411\n",
      "Epoch 4::Minibatch 134::LR 0.0930769230769 --> Loss 0.00311186710993\n",
      "Epoch 4::Minibatch 135::LR 0.0930769230769 --> Loss 0.00231786747773\n",
      "Epoch 4::Minibatch 136::LR 0.0930769230769 --> Loss 0.00312152028084\n",
      "Epoch 4::Minibatch 137::LR 0.0930769230769 --> Loss 0.00397634784381\n",
      "Epoch 4::Minibatch 138::LR 0.0930769230769 --> Loss 0.00177450656891\n",
      "Epoch 4::Minibatch 139::LR 0.0930769230769 --> Loss 0.00220253427823\n",
      "Epoch 4::Minibatch 140::LR 0.0930769230769 --> Loss 0.00272800664107\n",
      "Epoch 4::Minibatch 141::LR 0.0930769230769 --> Loss 0.00330871582031\n",
      "Epoch 4::Minibatch 142::LR 0.0930769230769 --> Loss 0.00345715562503\n",
      "Epoch 4::Minibatch 143::LR 0.0930769230769 --> Loss 0.000943595071634\n",
      "Epoch 4::Minibatch 144::LR 0.0930769230769 --> Loss 0.00319039225578\n",
      "Epoch 4::Minibatch 145::LR 0.0930769230769 --> Loss 0.00453306992849\n",
      "Epoch 4::Minibatch 146::LR 0.0930769230769 --> Loss 0.00318341592948\n",
      "Epoch 4::Minibatch 147::LR 0.0930769230769 --> Loss 0.00213385164738\n",
      "Epoch 4::Minibatch 148::LR 0.0930769230769 --> Loss 0.00140685250362\n",
      "Epoch 4::Minibatch 149::LR 0.0930769230769 --> Loss 0.00315270105998\n",
      "Epoch 4::Minibatch 150::LR 0.0930769230769 --> Loss 0.00327743212382\n",
      "Epoch 4::Minibatch 151::LR 0.0930769230769 --> Loss 0.00467020988464\n",
      "Epoch 4::Minibatch 152::LR 0.0930769230769 --> Loss 0.00119953165452\n",
      "Epoch 4::Minibatch 153::LR 0.0930769230769 --> Loss 0.00209593454997\n",
      "Epoch 4::Minibatch 154::LR 0.0930769230769 --> Loss 0.00237890342871\n",
      "Epoch 4::Minibatch 155::LR 0.0930769230769 --> Loss 0.00539874037107\n",
      "Epoch 4::Minibatch 156::LR 0.0930769230769 --> Loss 0.00284542779128\n",
      "Epoch 4::Minibatch 157::LR 0.0930769230769 --> Loss 0.000871006449064\n",
      "Epoch 4::Minibatch 158::LR 0.0930769230769 --> Loss 0.00321228901545\n",
      "Epoch 4::Minibatch 159::LR 0.0930769230769 --> Loss 0.0030625073115\n",
      "Epoch 4::Minibatch 160::LR 0.0930769230769 --> Loss 0.00306608041128\n",
      "Epoch 4::Minibatch 161::LR 0.0930769230769 --> Loss 0.00132843176524\n",
      "Epoch 4::Minibatch 162::LR 0.0930769230769 --> Loss 0.00351436972618\n",
      "Epoch 4::Minibatch 163::LR 0.0930769230769 --> Loss 0.00266687730948\n",
      "Epoch 4::Minibatch 164::LR 0.0930769230769 --> Loss 0.00272694071134\n",
      "Epoch 4::Minibatch 165::LR 0.0930769230769 --> Loss 0.000752809792757\n",
      "Epoch 4::Minibatch 166::LR 0.0930769230769 --> Loss 0.00207338293393\n",
      "Epoch 4::Minibatch 167::LR 0.0930769230769 --> Loss 0.00273558636506\n",
      "Epoch 4::Minibatch 168::LR 0.0930769230769 --> Loss 0.00254202922185\n",
      "Epoch 4::Minibatch 169::LR 0.0930769230769 --> Loss 0.00126977056265\n",
      "Epoch 4::Minibatch 170::LR 0.0930769230769 --> Loss 0.00112080166737\n",
      "Epoch 4::Minibatch 171::LR 0.0930769230769 --> Loss 0.00249231636524\n",
      "Epoch 4::Minibatch 172::LR 0.0930769230769 --> Loss 0.00564048528671\n",
      "Epoch 4::Minibatch 173::LR 0.0930769230769 --> Loss 0.0021821620067\n",
      "Epoch 4::Minibatch 174::LR 0.0930769230769 --> Loss 0.00121540675561\n",
      "Epoch 4::Minibatch 175::LR 0.0930769230769 --> Loss 0.00244404256344\n",
      "Epoch 4::Minibatch 176::LR 0.0930769230769 --> Loss 0.00363400777181\n",
      "Epoch 4::Minibatch 177::LR 0.0930769230769 --> Loss 0.00477696617444\n",
      "Epoch 4::Minibatch 178::LR 0.0930769230769 --> Loss 0.00199327111244\n",
      "Epoch 4::Minibatch 179::LR 0.0930769230769 --> Loss 0.00154710998138\n",
      "Epoch 4::Minibatch 180::LR 0.0930769230769 --> Loss 0.00413662274679\n",
      "Epoch 4::Minibatch 181::LR 0.0930769230769 --> Loss 0.00380490700404\n",
      "Epoch 4::Minibatch 182::LR 0.0930769230769 --> Loss 0.00106792787711\n",
      "Epoch 4::Minibatch 183::LR 0.0930769230769 --> Loss 0.00186120291551\n",
      "Epoch 4::Minibatch 184::LR 0.0930769230769 --> Loss 0.00367634137472\n",
      "Epoch 4::Minibatch 185::LR 0.0930769230769 --> Loss 0.00313261548678\n",
      "Epoch 4::Minibatch 186::LR 0.0930769230769 --> Loss 0.0012214371562\n",
      "Epoch 4::Minibatch 187::LR 0.0930769230769 --> Loss 0.00148741265138\n",
      "Epoch 4::Minibatch 188::LR 0.0930769230769 --> Loss 0.00440844575564\n",
      "Epoch 4::Minibatch 189::LR 0.0930769230769 --> Loss 0.00490535457929\n",
      "Epoch 4::Minibatch 190::LR 0.0930769230769 --> Loss 0.00257250527541\n",
      "Epoch 4::Minibatch 191::LR 0.0930769230769 --> Loss 0.000694608440002\n",
      "Epoch 4::Minibatch 192::LR 0.0930769230769 --> Loss 0.00278320352236\n",
      "Epoch 4::Minibatch 193::LR 0.0930769230769 --> Loss 0.00256969551245\n",
      "Epoch 4::Minibatch 194::LR 0.0930769230769 --> Loss 0.00204771538575\n",
      "Epoch 4::Minibatch 195::LR 0.0930769230769 --> Loss 0.000506897568703\n",
      "Epoch 4::Minibatch 196::LR 0.0930769230769 --> Loss 0.00131021678448\n",
      "Epoch 4::Minibatch 197::LR 0.0930769230769 --> Loss 0.00287704666456\n",
      "Epoch 4::Minibatch 198::LR 0.0930769230769 --> Loss 0.00225539366404\n",
      "Epoch 4::Minibatch 199::LR 0.0930769230769 --> Loss 0.000395484566689\n",
      "Epoch 4::Minibatch 200::LR 0.0930769230769 --> Loss 0.0024218783776\n",
      "Epoch 4::Minibatch 201::LR 0.0930769230769 --> Loss 0.00244902551174\n",
      "Epoch 4::Minibatch 202::LR 0.0930769230769 --> Loss 0.00224159677823\n",
      "Epoch 4::Minibatch 203::LR 0.0930769230769 --> Loss 0.00220681051413\n",
      "Epoch 4::Minibatch 204::LR 0.0930769230769 --> Loss 0.00198316792647\n",
      "Epoch 4::Minibatch 205::LR 0.0930769230769 --> Loss 0.0026509787639\n",
      "Epoch 4::Minibatch 206::LR 0.0930769230769 --> Loss 0.00784598032633\n",
      "Epoch 4::Minibatch 207::LR 0.0930769230769 --> Loss 0.00177210887273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 208::LR 0.0930769230769 --> Loss 0.00138972987731\n",
      "Epoch 4::Minibatch 209::LR 0.0930769230769 --> Loss 0.00232954462369\n",
      "Epoch 4::Minibatch 210::LR 0.0930769230769 --> Loss 0.00216766635577\n",
      "Epoch 4::Minibatch 211::LR 0.0930769230769 --> Loss 0.00216737965743\n",
      "Epoch 4::Minibatch 212::LR 0.0930769230769 --> Loss 0.00498115499814\n",
      "Epoch 4::Minibatch 213::LR 0.0930769230769 --> Loss 0.00604576071103\n",
      "Epoch 4::Minibatch 214::LR 0.0930769230769 --> Loss 0.0104271705945\n",
      "Epoch 4::Minibatch 215::LR 0.0930769230769 --> Loss 0.00168871382872\n",
      "Epoch 4::Minibatch 216::LR 0.0930769230769 --> Loss 0.00562147299449\n",
      "Epoch 4::Minibatch 217::LR 0.0930769230769 --> Loss 0.00565306901932\n",
      "Epoch 4::Minibatch 218::LR 0.0930769230769 --> Loss 0.00448338747025\n",
      "Epoch 4::Minibatch 219::LR 0.0930769230769 --> Loss 0.00334779977798\n",
      "Epoch 4::Minibatch 220::LR 0.0930769230769 --> Loss 0.00469100793203\n",
      "Epoch 4::Minibatch 221::LR 0.0930769230769 --> Loss 0.0046150124073\n",
      "Epoch 4::Minibatch 222::LR 0.0930769230769 --> Loss 0.0037370244662\n",
      "Epoch 4::Minibatch 223::LR 0.0930769230769 --> Loss 0.00170269509157\n",
      "Epoch 4::Minibatch 224::LR 0.0930769230769 --> Loss 0.00219769140085\n",
      "Epoch 4::Minibatch 225::LR 0.0930769230769 --> Loss 0.00665704369545\n",
      "Epoch 4::Minibatch 226::LR 0.0930769230769 --> Loss 0.00418576320012\n",
      "Epoch 4::Minibatch 227::LR 0.0930769230769 --> Loss 0.00201254089673\n",
      "Epoch 4::Minibatch 228::LR 0.0930769230769 --> Loss 0.00112193365892\n",
      "Epoch 4::Minibatch 229::LR 0.0930769230769 --> Loss 0.00494727134705\n",
      "Epoch 4::Minibatch 230::LR 0.0930769230769 --> Loss 0.00443966547648\n",
      "Epoch 4::Minibatch 231::LR 0.0930769230769 --> Loss 0.00296752134959\n",
      "Epoch 4::Minibatch 232::LR 0.0930769230769 --> Loss 0.00163209110498\n",
      "Epoch 4::Minibatch 233::LR 0.0930769230769 --> Loss 0.002556108435\n",
      "Epoch 4::Minibatch 234::LR 0.0930769230769 --> Loss 0.00637196699778\n",
      "Epoch 4::Minibatch 235::LR 0.0930769230769 --> Loss 0.00494091908137\n",
      "Epoch 4::Minibatch 236::LR 0.0930769230769 --> Loss 0.0020294636488\n",
      "Epoch 4::Minibatch 237::LR 0.0930769230769 --> Loss 0.00100918849309\n",
      "Epoch 4::Minibatch 238::LR 0.0930769230769 --> Loss 0.00360397577286\n",
      "Epoch 4::Minibatch 239::LR 0.0930769230769 --> Loss 0.00308994392554\n",
      "Epoch 4::Minibatch 240::LR 0.0930769230769 --> Loss 0.00334423343341\n",
      "Epoch 4::Minibatch 241::LR 0.0930769230769 --> Loss 0.000977538228035\n",
      "Epoch 4::Minibatch 242::LR 0.0930769230769 --> Loss 0.00725406805674\n",
      "Epoch 4::Minibatch 243::LR 0.0930769230769 --> Loss 0.00396985332171\n",
      "Epoch 4::Minibatch 244::LR 0.0930769230769 --> Loss 0.00330627242724\n",
      "Epoch 4::Minibatch 245::LR 0.0930769230769 --> Loss 0.000795620779196\n",
      "Epoch 4::Minibatch 246::LR 0.0930769230769 --> Loss 0.00248614112536\n",
      "Epoch 4::Minibatch 247::LR 0.0930769230769 --> Loss 0.0143429629008\n",
      "Epoch 4::Minibatch 248::LR 0.0930769230769 --> Loss 0.00459682067235\n",
      "Epoch 4::Minibatch 249::LR 0.0930769230769 --> Loss 0.00379478534063\n",
      "Epoch 4::Minibatch 250::LR 0.0930769230769 --> Loss 0.00356661399206\n",
      "Epoch 4::Minibatch 251::LR 0.0930769230769 --> Loss 0.00252116322517\n",
      "Epoch 4::Minibatch 252::LR 0.0930769230769 --> Loss 0.0021145961682\n",
      "Epoch 4::Minibatch 253::LR 0.0930769230769 --> Loss 0.00335681637128\n",
      "Epoch 4::Minibatch 254::LR 0.0930769230769 --> Loss 0.00594602425893\n",
      "Epoch 4::Minibatch 255::LR 0.0930769230769 --> Loss 0.00428063193957\n",
      "Epoch 4::Minibatch 256::LR 0.0930769230769 --> Loss 0.00216482738654\n",
      "Epoch 4::Minibatch 257::LR 0.0930769230769 --> Loss 0.00168446203073\n",
      "Epoch 4::Minibatch 258::LR 0.0930769230769 --> Loss 0.00379998246829\n",
      "Epoch 4::Minibatch 259::LR 0.0930769230769 --> Loss 0.00213896870613\n",
      "Epoch 4::Minibatch 260::LR 0.0930769230769 --> Loss 0.00209502081076\n",
      "Epoch 4::Minibatch 261::LR 0.0930769230769 --> Loss 0.00325341741244\n",
      "Epoch 4::Minibatch 262::LR 0.0930769230769 --> Loss 0.00222498416901\n",
      "Epoch 4::Minibatch 263::LR 0.0930769230769 --> Loss 0.00256322741508\n",
      "Epoch 4::Minibatch 264::LR 0.0930769230769 --> Loss 0.00381184339523\n",
      "Epoch 4::Minibatch 265::LR 0.0930769230769 --> Loss 0.00930686553319\n",
      "Epoch 4::Minibatch 266::LR 0.0930769230769 --> Loss 0.00134960403045\n",
      "Epoch 4::Minibatch 267::LR 0.0930769230769 --> Loss 0.0100749238332\n",
      "Epoch 4::Minibatch 268::LR 0.0930769230769 --> Loss 0.00160630106926\n",
      "Epoch 4::Minibatch 269::LR 0.0930769230769 --> Loss 0.00388241648674\n",
      "Epoch 4::Minibatch 270::LR 0.0930769230769 --> Loss 0.00636397918065\n",
      "Epoch 4::Minibatch 271::LR 0.0930769230769 --> Loss 0.00320505201817\n",
      "Epoch 4::Minibatch 272::LR 0.0930769230769 --> Loss 0.00411520799001\n",
      "Epoch 4::Minibatch 273::LR 0.0930769230769 --> Loss 0.00213250180086\n",
      "Epoch 4::Minibatch 274::LR 0.0930769230769 --> Loss 0.00210450967153\n",
      "Epoch 4::Minibatch 275::LR 0.0930769230769 --> Loss 0.00298121651014\n",
      "Epoch 4::Minibatch 276::LR 0.0930769230769 --> Loss 0.00358974734942\n",
      "Epoch 4::Minibatch 277::LR 0.0930769230769 --> Loss 0.0013487303257\n",
      "Epoch 4::Minibatch 278::LR 0.0930769230769 --> Loss 0.00277676065763\n",
      "Epoch 4::Minibatch 279::LR 0.0930769230769 --> Loss 0.00267064551512\n",
      "Epoch 4::Minibatch 280::LR 0.0930769230769 --> Loss 0.00241254150867\n",
      "Epoch 4::Minibatch 281::LR 0.0930769230769 --> Loss 0.00160546183586\n",
      "Epoch 4::Minibatch 282::LR 0.0930769230769 --> Loss 0.00237698773543\n",
      "Epoch 4::Minibatch 283::LR 0.0930769230769 --> Loss 0.0022742976745\n",
      "Epoch 4::Minibatch 284::LR 0.0930769230769 --> Loss 0.00187267184258\n",
      "Epoch 4::Minibatch 285::LR 0.0930769230769 --> Loss 0.00136350323757\n",
      "Epoch 4::Minibatch 286::LR 0.0930769230769 --> Loss 0.00220319966475\n",
      "Epoch 4::Minibatch 287::LR 0.0930769230769 --> Loss 0.0021421978871\n",
      "Epoch 4::Minibatch 288::LR 0.0930769230769 --> Loss 0.00121488392353\n",
      "Epoch 4::Minibatch 289::LR 0.0930769230769 --> Loss 0.00154840350151\n",
      "Epoch 4::Minibatch 290::LR 0.0930769230769 --> Loss 0.00196630934874\n",
      "Epoch 4::Minibatch 291::LR 0.0930769230769 --> Loss 0.00178398211797\n",
      "Epoch 4::Minibatch 292::LR 0.0930769230769 --> Loss 0.000725595404704\n",
      "Epoch 4::Minibatch 293::LR 0.0930769230769 --> Loss 0.00142401576042\n",
      "Epoch 4::Minibatch 294::LR 0.0930769230769 --> Loss 0.00160652548075\n",
      "Epoch 4::Minibatch 295::LR 0.0930769230769 --> Loss 0.0017688113451\n",
      "Epoch 4::Minibatch 296::LR 0.0930769230769 --> Loss 0.00153743525346\n",
      "Epoch 4::Minibatch 297::LR 0.0930769230769 --> Loss 0.0013860587279\n",
      "Epoch 4::Minibatch 298::LR 0.0930769230769 --> Loss 0.00136483927568\n",
      "Epoch 4::Minibatch 299::LR 0.0930769230769 --> Loss 0.000841438074907\n",
      "Epoch 4::Minibatch 300::LR 0.0930769230769 --> Loss 0.00321811119715\n",
      "Epoch 4::Minibatch 301::LR 0.0930769230769 --> Loss 0.00309652964274\n",
      "Epoch 4::Minibatch 302::LR 0.0930769230769 --> Loss 0.00273418009281\n",
      "Epoch 4::Minibatch 303::LR 0.0930769230769 --> Loss 0.00107856025298\n",
      "Epoch 4::Minibatch 304::LR 0.0930769230769 --> Loss 0.00350243290265\n",
      "Epoch 4::Minibatch 305::LR 0.0930769230769 --> Loss 0.00190789540609\n",
      "Epoch 4::Minibatch 306::LR 0.0930769230769 --> Loss 0.00113803813855\n",
      "Epoch 4::Minibatch 307::LR 0.0930769230769 --> Loss 0.0027240884304\n",
      "Epoch 4::Minibatch 308::LR 0.0930769230769 --> Loss 0.00219560186068\n",
      "Epoch 4::Minibatch 309::LR 0.0930769230769 --> Loss 0.00108794301748\n",
      "Epoch 4::Minibatch 310::LR 0.0930769230769 --> Loss 0.00108527292808\n",
      "Epoch 4::Minibatch 311::LR 0.0930769230769 --> Loss 0.00173546830813\n",
      "Epoch 4::Minibatch 312::LR 0.0930769230769 --> Loss 0.00332970162233\n",
      "Epoch 4::Minibatch 313::LR 0.0930769230769 --> Loss 0.00241605321566\n",
      "Epoch 4::Minibatch 314::LR 0.0930769230769 --> Loss 0.00205077409744\n",
      "Epoch 4::Minibatch 315::LR 0.0930769230769 --> Loss 0.00112244526545\n",
      "Epoch 4::Minibatch 316::LR 0.0930769230769 --> Loss 0.00250716189543\n",
      "Epoch 4::Minibatch 317::LR 0.0930769230769 --> Loss 0.00178298652172\n",
      "Epoch 4::Minibatch 318::LR 0.0930769230769 --> Loss 0.00125530670087\n",
      "Epoch 4::Minibatch 319::LR 0.0930769230769 --> Loss 0.00239196856817\n",
      "Epoch 4::Minibatch 320::LR 0.0930769230769 --> Loss 0.0035313141346\n",
      "Epoch 4::Minibatch 321::LR 0.0930769230769 --> Loss 0.00103728224834\n",
      "Epoch 4::Minibatch 322::LR 0.0930769230769 --> Loss 0.00371302167575\n",
      "Epoch 4::Minibatch 323::LR 0.0930769230769 --> Loss 0.00361223936081\n",
      "Epoch 4::Minibatch 324::LR 0.0930769230769 --> Loss 0.00263184527556\n",
      "Epoch 4::Minibatch 325::LR 0.0930769230769 --> Loss 0.00253572483857\n",
      "Epoch 4::Minibatch 326::LR 0.0930769230769 --> Loss 0.00586088617643\n",
      "Epoch 4::Minibatch 327::LR 0.0930769230769 --> Loss 0.00250019093355\n",
      "Epoch 4::Minibatch 328::LR 0.0930769230769 --> Loss 0.00380545457204\n",
      "Epoch 4::Minibatch 329::LR 0.0930769230769 --> Loss 0.00135031620661\n",
      "Epoch 4::Minibatch 330::LR 0.0930769230769 --> Loss 0.00182296852271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 331::LR 0.0930769230769 --> Loss 0.00279196401437\n",
      "Epoch 4::Minibatch 332::LR 0.0930769230769 --> Loss 0.00276526272297\n",
      "Epoch 4::Minibatch 333::LR 0.0930769230769 --> Loss 0.00164905766646\n",
      "Epoch 4::Minibatch 334::LR 0.0930769230769 --> Loss 0.00420508583387\n",
      "Epoch 4::Minibatch 335::LR 0.0930769230769 --> Loss 0.00204569796721\n",
      "Epoch 4::Minibatch 336::LR 0.0930769230769 --> Loss 0.00199804246426\n",
      "Epoch 4::Minibatch 337::LR 0.0930769230769 --> Loss 0.003263707757\n",
      "Epoch 4::Minibatch 338::LR 0.0930769230769 --> Loss 0.000648869425058\n",
      "Epoch 4::Minibatch 339::LR 0.0930769230769 --> Loss 0.00328895231088\n",
      "Epoch 4::Minibatch 340::LR 0.0930769230769 --> Loss 0.00595902959506\n",
      "Epoch 4::Minibatch 341::LR 0.0930769230769 --> Loss 0.00500718315442\n",
      "Epoch 4::Minibatch 342::LR 0.0930769230769 --> Loss 0.0036964070797\n",
      "Epoch 4::Minibatch 343::LR 0.0930769230769 --> Loss 0.00211486657461\n",
      "Epoch 4::Minibatch 344::LR 0.0930769230769 --> Loss 0.00314757446448\n",
      "Epoch 4::Minibatch 345::LR 0.0930769230769 --> Loss 0.00464932918549\n",
      "Epoch 4::Minibatch 346::LR 0.0930769230769 --> Loss 0.0059525068601\n",
      "Epoch 4::Minibatch 347::LR 0.0930769230769 --> Loss 0.00120759805044\n",
      "Epoch 4::Minibatch 348::LR 0.0930769230769 --> Loss 0.00395348389943\n",
      "Epoch 4::Minibatch 349::LR 0.0930769230769 --> Loss 0.00369994441668\n",
      "Epoch 4::Minibatch 350::LR 0.0930769230769 --> Loss 0.0022304803133\n",
      "Epoch 4::Minibatch 351::LR 0.0930769230769 --> Loss 0.00391163110733\n",
      "Epoch 4::Minibatch 352::LR 0.0930769230769 --> Loss 0.0049530728658\n",
      "Epoch 4::Minibatch 353::LR 0.0930769230769 --> Loss 0.00369558254878\n",
      "Epoch 4::Minibatch 354::LR 0.0930769230769 --> Loss 0.00310026784738\n",
      "Epoch 4::Minibatch 355::LR 0.0930769230769 --> Loss 0.0062673274676\n",
      "Epoch 4::Minibatch 356::LR 0.0930769230769 --> Loss 0.00350028077761\n",
      "Epoch 4::Minibatch 357::LR 0.0930769230769 --> Loss 0.00147658735514\n",
      "Epoch 4::Minibatch 358::LR 0.0930769230769 --> Loss 0.00269282778104\n",
      "Epoch 4::Minibatch 359::LR 0.0930769230769 --> Loss 0.00300154109796\n",
      "Epoch 4::Minibatch 360::LR 0.0930769230769 --> Loss 0.00287755767504\n",
      "Epoch 4::Minibatch 361::LR 0.0930769230769 --> Loss 0.00266975561778\n",
      "Epoch 4::Minibatch 362::LR 0.0930769230769 --> Loss 0.00283097426097\n",
      "Epoch 4::Minibatch 363::LR 0.0930769230769 --> Loss 0.000835690498352\n",
      "Epoch 4::Minibatch 364::LR 0.0930769230769 --> Loss 0.00225993951162\n",
      "Epoch 4::Minibatch 365::LR 0.0930769230769 --> Loss 0.00235809385777\n",
      "Epoch 4::Minibatch 366::LR 0.0930769230769 --> Loss 0.00262730757395\n",
      "Epoch 4::Minibatch 367::LR 0.0930769230769 --> Loss 0.0012712469697\n",
      "Epoch 4::Minibatch 368::LR 0.0930769230769 --> Loss 0.00119910508394\n",
      "Epoch 4::Minibatch 369::LR 0.0930769230769 --> Loss 0.00310677448908\n",
      "Epoch 4::Minibatch 370::LR 0.0930769230769 --> Loss 0.00243358910084\n",
      "Epoch 4::Minibatch 371::LR 0.0930769230769 --> Loss 0.00203685998917\n",
      "Epoch 4::Minibatch 372::LR 0.0930769230769 --> Loss 0.000575612932444\n",
      "Epoch 4::Minibatch 373::LR 0.0930769230769 --> Loss 0.0019037570556\n",
      "Epoch 4::Minibatch 374::LR 0.0930769230769 --> Loss 0.00224796513716\n",
      "Epoch 4::Minibatch 375::LR 0.0930769230769 --> Loss 0.00199728747209\n",
      "Epoch 4::Minibatch 376::LR 0.0930769230769 --> Loss 0.00135276407003\n",
      "Epoch 4::Minibatch 377::LR 0.0930769230769 --> Loss 0.0021599894762\n",
      "Epoch 4::Minibatch 378::LR 0.0930769230769 --> Loss 0.00223646700382\n",
      "Epoch 4::Minibatch 379::LR 0.0930769230769 --> Loss 0.00256234288216\n",
      "Epoch 4::Minibatch 380::LR 0.0930769230769 --> Loss 0.00171733856201\n",
      "Epoch 4::Minibatch 381::LR 0.0930769230769 --> Loss 0.00114349146684\n",
      "Epoch 4::Minibatch 382::LR 0.0930769230769 --> Loss 0.00219530502955\n",
      "Epoch 4::Minibatch 383::LR 0.0930769230769 --> Loss 0.0020868062973\n",
      "Epoch 4::Minibatch 384::LR 0.0930769230769 --> Loss 0.00119777490695\n",
      "Epoch 4::Minibatch 385::LR 0.0930769230769 --> Loss 0.00116418431203\n",
      "Epoch 4::Minibatch 386::LR 0.0930769230769 --> Loss 0.00236806889375\n",
      "Epoch 4::Minibatch 387::LR 0.0930769230769 --> Loss 0.00242094218731\n",
      "Epoch 4::Minibatch 388::LR 0.0930769230769 --> Loss 0.00117565562328\n",
      "Epoch 4::Minibatch 389::LR 0.0930769230769 --> Loss 0.00208406805992\n",
      "Epoch 4::Minibatch 390::LR 0.0930769230769 --> Loss 0.00455168485641\n",
      "Epoch 4::Minibatch 391::LR 0.0930769230769 --> Loss 0.00307423512141\n",
      "Epoch 4::Minibatch 392::LR 0.0930769230769 --> Loss 0.00310964504878\n",
      "Epoch 4::Minibatch 393::LR 0.0930769230769 --> Loss 0.0030232022206\n",
      "Epoch 4::Minibatch 394::LR 0.0930769230769 --> Loss 0.00249440749486\n",
      "Epoch 4::Minibatch 395::LR 0.0930769230769 --> Loss 0.00226118783156\n",
      "Epoch 4::Minibatch 396::LR 0.0930769230769 --> Loss 0.00225788474083\n",
      "Epoch 4::Minibatch 397::LR 0.0930769230769 --> Loss 0.00240226566792\n",
      "Epoch 4::Minibatch 398::LR 0.0930769230769 --> Loss 0.002327572306\n",
      "Epoch 4::Minibatch 399::LR 0.0930769230769 --> Loss 0.00257632652918\n",
      "Epoch 4::Minibatch 400::LR 0.0930769230769 --> Loss 0.00230857789516\n",
      "Epoch 4::Minibatch 401::LR 0.0930769230769 --> Loss 0.00468874851863\n",
      "Epoch 4::Minibatch 402::LR 0.0930769230769 --> Loss 0.00230781892935\n",
      "Epoch 4::Minibatch 403::LR 0.0930769230769 --> Loss 0.00174964884917\n",
      "Epoch 4::Minibatch 404::LR 0.0930769230769 --> Loss 0.00185240725676\n",
      "Epoch 4::Minibatch 405::LR 0.0930769230769 --> Loss 0.00387755354246\n",
      "Epoch 4::Minibatch 406::LR 0.0930769230769 --> Loss 0.00274605035782\n",
      "Epoch 4::Minibatch 407::LR 0.0930769230769 --> Loss 0.00195952335993\n",
      "Epoch 4::Minibatch 408::LR 0.0930769230769 --> Loss 0.000707683016857\n",
      "Epoch 4::Minibatch 409::LR 0.0930769230769 --> Loss 0.00304125626882\n",
      "Epoch 4::Minibatch 410::LR 0.0930769230769 --> Loss 0.00399220705032\n",
      "Epoch 4::Minibatch 411::LR 0.0930769230769 --> Loss 0.00180562694867\n",
      "Epoch 4::Minibatch 412::LR 0.0930769230769 --> Loss 0.0011289375027\n",
      "Epoch 4::Minibatch 413::LR 0.0930769230769 --> Loss 0.00225498219331\n",
      "Epoch 4::Minibatch 414::LR 0.0930769230769 --> Loss 0.00177545070648\n",
      "Epoch 4::Minibatch 415::LR 0.0930769230769 --> Loss 0.00122484872739\n",
      "Epoch 4::Minibatch 416::LR 0.0930769230769 --> Loss 0.000950191318989\n",
      "Epoch 4::Minibatch 417::LR 0.0930769230769 --> Loss 0.00175112366676\n",
      "Epoch 4::Minibatch 418::LR 0.0930769230769 --> Loss 0.00336840867996\n",
      "Epoch 4::Minibatch 419::LR 0.0930769230769 --> Loss 0.000785563041766\n",
      "Epoch 4::Minibatch 420::LR 0.0930769230769 --> Loss 0.000988040467103\n",
      "Epoch 4::Minibatch 421::LR 0.0930769230769 --> Loss 0.00221372902393\n",
      "Epoch 4::Minibatch 422::LR 0.0930769230769 --> Loss 0.00259054799875\n",
      "Epoch 4::Minibatch 423::LR 0.0930769230769 --> Loss 0.00126595387856\n",
      "Epoch 4::Minibatch 424::LR 0.0930769230769 --> Loss 0.00186109264692\n",
      "Epoch 4::Minibatch 425::LR 0.0930769230769 --> Loss 0.00275992512703\n",
      "Epoch 4::Minibatch 426::LR 0.0930769230769 --> Loss 0.00220005472501\n",
      "Epoch 4::Minibatch 427::LR 0.0930769230769 --> Loss 0.000901658435663\n",
      "Epoch 4::Minibatch 428::LR 0.0930769230769 --> Loss 0.00148288955291\n",
      "Epoch 4::Minibatch 429::LR 0.0930769230769 --> Loss 0.00290061493715\n",
      "Epoch 4::Minibatch 430::LR 0.0930769230769 --> Loss 0.0107650319735\n",
      "Epoch 4::Minibatch 431::LR 0.0930769230769 --> Loss 0.00390606403351\n",
      "Epoch 4::Minibatch 432::LR 0.0930769230769 --> Loss 0.0047593887647\n",
      "Epoch 4::Minibatch 433::LR 0.0930769230769 --> Loss 0.00280263225238\n",
      "Epoch 4::Minibatch 434::LR 0.0930769230769 --> Loss 0.0027861626943\n",
      "Epoch 4::Minibatch 435::LR 0.0930769230769 --> Loss 0.00269570887089\n",
      "Epoch 4::Minibatch 436::LR 0.0930769230769 --> Loss 0.00210121572018\n",
      "Epoch 4::Minibatch 437::LR 0.0930769230769 --> Loss 0.00404419620832\n",
      "Epoch 4::Minibatch 438::LR 0.0930769230769 --> Loss 0.00302454411983\n",
      "Epoch 4::Minibatch 439::LR 0.0930769230769 --> Loss 0.00242877960205\n",
      "Epoch 4::Minibatch 440::LR 0.0930769230769 --> Loss 0.00359047293663\n",
      "Epoch 4::Minibatch 441::LR 0.0930769230769 --> Loss 0.00340106805166\n",
      "Epoch 4::Minibatch 442::LR 0.0930769230769 --> Loss 0.00329578876495\n",
      "Epoch 4::Minibatch 443::LR 0.0930769230769 --> Loss 0.00421738266945\n",
      "Epoch 4::Minibatch 444::LR 0.0930769230769 --> Loss 0.00300516386827\n",
      "Epoch 4::Minibatch 445::LR 0.0930769230769 --> Loss 0.000962541997433\n",
      "Epoch 4::Minibatch 446::LR 0.0930769230769 --> Loss 0.00169999102751\n",
      "Epoch 4::Minibatch 447::LR 0.0930769230769 --> Loss 0.00274755259355\n",
      "Epoch 4::Minibatch 448::LR 0.0930769230769 --> Loss 0.0027225112915\n",
      "Epoch 4::Minibatch 449::LR 0.0930769230769 --> Loss 0.00410023768743\n",
      "Epoch 4::Minibatch 450::LR 0.0930769230769 --> Loss 0.00279973407586\n",
      "Epoch 4::Minibatch 451::LR 0.0930769230769 --> Loss 0.0044705371062\n",
      "Epoch 4::Minibatch 452::LR 0.0930769230769 --> Loss 0.00258805453777\n",
      "Epoch 4::Minibatch 453::LR 0.0930769230769 --> Loss 0.000609128028154\n",
      "Epoch 4::Minibatch 454::LR 0.0930769230769 --> Loss 0.003916943868\n",
      "Epoch 4::Minibatch 455::LR 0.0930769230769 --> Loss 0.00293335219224\n",
      "Epoch 4::Minibatch 456::LR 0.0930769230769 --> Loss 0.00347823659579\n",
      "Epoch 4::Minibatch 457::LR 0.0930769230769 --> Loss 0.00214225232601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 458::LR 0.0930769230769 --> Loss 0.000958033204079\n",
      "Epoch 4::Minibatch 459::LR 0.0930769230769 --> Loss 0.00481256246567\n",
      "Epoch 4::Minibatch 460::LR 0.0930769230769 --> Loss 0.00317273437977\n",
      "Epoch 4::Minibatch 461::LR 0.0930769230769 --> Loss 0.00424494306246\n",
      "Epoch 4::Minibatch 462::LR 0.0930769230769 --> Loss 0.000526201874018\n",
      "Epoch 4::Minibatch 463::LR 0.0930769230769 --> Loss 0.00563451488813\n",
      "Epoch 4::Minibatch 464::LR 0.0930769230769 --> Loss 0.00236500799656\n",
      "Epoch 4::Minibatch 465::LR 0.0930769230769 --> Loss 0.00628896911939\n",
      "Epoch 4::Minibatch 466::LR 0.0930769230769 --> Loss 0.00543626189232\n",
      "Epoch 4::Minibatch 467::LR 0.0930769230769 --> Loss 0.00696521361669\n",
      "Epoch 4::Minibatch 468::LR 0.0930769230769 --> Loss 0.00667471806208\n",
      "Epoch 4::Minibatch 469::LR 0.0930769230769 --> Loss 0.00867059548696\n",
      "Epoch 4::Minibatch 470::LR 0.0930769230769 --> Loss 0.00439763387044\n",
      "Epoch 4::Minibatch 471::LR 0.0930769230769 --> Loss 0.00238634844621\n",
      "Epoch 4::Minibatch 472::LR 0.0930769230769 --> Loss 0.00373352408409\n",
      "Epoch 4::Minibatch 473::LR 0.0930769230769 --> Loss 0.00225731233756\n",
      "Epoch 4::Minibatch 474::LR 0.0930769230769 --> Loss 0.000851696133614\n",
      "Epoch 4::Minibatch 475::LR 0.0930769230769 --> Loss 0.00498673717181\n",
      "Epoch 4::Minibatch 476::LR 0.0930769230769 --> Loss 0.00780401627223\n",
      "Epoch 4::Minibatch 477::LR 0.0930769230769 --> Loss 0.0010785779357\n",
      "Epoch 4::Minibatch 478::LR 0.0930769230769 --> Loss 0.00258908450603\n",
      "Epoch 4::Minibatch 479::LR 0.0930769230769 --> Loss 0.00207443435987\n",
      "Epoch 4::Minibatch 480::LR 0.0930769230769 --> Loss 0.00166953603427\n",
      "Epoch 4::Minibatch 481::LR 0.0930769230769 --> Loss 0.00109440823396\n",
      "Epoch 4::Minibatch 482::LR 0.0930769230769 --> Loss 0.00230682154497\n",
      "Epoch 4::Minibatch 483::LR 0.0930769230769 --> Loss 0.00379040598869\n",
      "Epoch 4::Minibatch 484::LR 0.0930769230769 --> Loss 0.0039491713047\n",
      "Epoch 4::Minibatch 485::LR 0.0930769230769 --> Loss 0.000891672372818\n",
      "Epoch 4::Minibatch 486::LR 0.0930769230769 --> Loss 0.00368840853373\n",
      "Epoch 4::Minibatch 487::LR 0.0930769230769 --> Loss 0.00388618270556\n",
      "Epoch 4::Minibatch 488::LR 0.0930769230769 --> Loss 0.00218152999878\n",
      "Epoch 4::Minibatch 489::LR 0.0930769230769 --> Loss 0.00326456566652\n",
      "Epoch 4::Minibatch 490::LR 0.0930769230769 --> Loss 0.000541756053766\n",
      "Epoch 4::Minibatch 491::LR 0.0930769230769 --> Loss 0.00571010748545\n",
      "Epoch 4::Minibatch 492::LR 0.0930769230769 --> Loss 0.00317414720853\n",
      "Epoch 4::Minibatch 493::LR 0.0930769230769 --> Loss 0.00344172000885\n",
      "Epoch 4::Minibatch 494::LR 0.0930769230769 --> Loss 0.000881724953651\n",
      "Epoch 4::Minibatch 495::LR 0.0930769230769 --> Loss 0.00209423859914\n",
      "Epoch 4::Minibatch 496::LR 0.0930769230769 --> Loss 0.00341906706492\n",
      "Epoch 4::Minibatch 497::LR 0.0930769230769 --> Loss 0.00109129577875\n",
      "Epoch 4::Minibatch 498::LR 0.0930769230769 --> Loss 0.000759327858686\n",
      "Epoch 4::Minibatch 499::LR 0.0930769230769 --> Loss 0.00449013431867\n",
      "Epoch 4::Minibatch 500::LR 0.0930769230769 --> Loss 0.00162018030882\n",
      "Epoch 4::Minibatch 501::LR 0.0930769230769 --> Loss 0.00241710921129\n",
      "Epoch 4::Minibatch 502::LR 0.0930769230769 --> Loss 0.00431113123894\n",
      "Epoch 4::Minibatch 503::LR 0.0930769230769 --> Loss 0.0116081229846\n",
      "Epoch 4::Minibatch 504::LR 0.0930769230769 --> Loss 0.00830680052439\n",
      "Epoch 4::Minibatch 505::LR 0.0930769230769 --> Loss 0.00484306891759\n",
      "Epoch 4::Minibatch 506::LR 0.0930769230769 --> Loss 0.00393917401632\n",
      "Epoch 4::Minibatch 507::LR 0.0930769230769 --> Loss 0.00625173131625\n",
      "Epoch 4::Minibatch 508::LR 0.0930769230769 --> Loss 0.00349006175995\n",
      "Epoch 4::Minibatch 509::LR 0.0930769230769 --> Loss 0.00473757624626\n",
      "Epoch 4::Minibatch 510::LR 0.0930769230769 --> Loss 0.00514635403951\n",
      "Epoch 4::Minibatch 511::LR 0.0930769230769 --> Loss 0.00384447177251\n",
      "Epoch 4::Minibatch 512::LR 0.0930769230769 --> Loss 0.00288437306881\n",
      "Epoch 4::Minibatch 513::LR 0.0930769230769 --> Loss 0.000937280356884\n",
      "Epoch 4::Minibatch 514::LR 0.0930769230769 --> Loss 0.00283071994781\n",
      "Epoch 4::Minibatch 515::LR 0.0930769230769 --> Loss 0.00340268492699\n",
      "Epoch 4::Minibatch 516::LR 0.0930769230769 --> Loss 0.00465365211169\n",
      "Epoch 4::Minibatch 517::LR 0.0930769230769 --> Loss 0.00335577090581\n",
      "Epoch 4::Minibatch 518::LR 0.0930769230769 --> Loss 0.00263526380062\n",
      "Epoch 4::Minibatch 519::LR 0.0930769230769 --> Loss 0.00355990131696\n",
      "Epoch 4::Minibatch 520::LR 0.0930769230769 --> Loss 0.00560420393944\n",
      "Epoch 4::Minibatch 521::LR 0.0930769230769 --> Loss 0.00615765333176\n",
      "Epoch 4::Minibatch 522::LR 0.0930769230769 --> Loss 0.00716760555903\n",
      "Epoch 4::Minibatch 523::LR 0.0930769230769 --> Loss 0.000953795711199\n",
      "Epoch 4::Minibatch 524::LR 0.0930769230769 --> Loss 0.00161129027605\n",
      "Epoch 4::Minibatch 525::LR 0.0930769230769 --> Loss 0.00350075761477\n",
      "Epoch 4::Minibatch 526::LR 0.0930769230769 --> Loss 0.00452421387037\n",
      "Epoch 4::Minibatch 527::LR 0.0930769230769 --> Loss 0.00280902822812\n",
      "Epoch 4::Minibatch 528::LR 0.0930769230769 --> Loss 0.00165946880976\n",
      "Epoch 4::Minibatch 529::LR 0.0930769230769 --> Loss 0.00440334796906\n",
      "Epoch 4::Minibatch 530::LR 0.0930769230769 --> Loss 0.00472359816233\n",
      "Epoch 4::Minibatch 531::LR 0.0930769230769 --> Loss 0.00400888721148\n",
      "Epoch 4::Minibatch 532::LR 0.0930769230769 --> Loss 0.00295291423798\n",
      "Epoch 4::Minibatch 533::LR 0.0930769230769 --> Loss 0.00496193647385\n",
      "Epoch 4::Minibatch 534::LR 0.0930769230769 --> Loss 0.00410361886024\n",
      "Epoch 4::Minibatch 535::LR 0.0930769230769 --> Loss 0.00338516990344\n",
      "Epoch 4::Minibatch 536::LR 0.0930769230769 --> Loss 0.00239729424318\n",
      "Epoch 4::Minibatch 537::LR 0.0930769230769 --> Loss 0.000934863785903\n",
      "Epoch 4::Minibatch 538::LR 0.0930769230769 --> Loss 0.00191801269849\n",
      "Epoch 4::Minibatch 539::LR 0.0930769230769 --> Loss 0.00364147504171\n",
      "Epoch 4::Minibatch 540::LR 0.0930769230769 --> Loss 0.00352595369021\n",
      "Epoch 4::Minibatch 541::LR 0.0930769230769 --> Loss 0.00304059485594\n",
      "Epoch 4::Minibatch 542::LR 0.0930769230769 --> Loss 0.00281212091446\n",
      "Epoch 4::Minibatch 543::LR 0.0930769230769 --> Loss 0.00315902968248\n",
      "Epoch 4::Minibatch 544::LR 0.0930769230769 --> Loss 0.00426587541898\n",
      "Epoch 4::Minibatch 545::LR 0.0930769230769 --> Loss 0.00221888124943\n",
      "Epoch 4::Minibatch 546::LR 0.0930769230769 --> Loss 0.000855951011181\n",
      "Epoch 4::Minibatch 547::LR 0.0930769230769 --> Loss 0.00287878155708\n",
      "Epoch 4::Minibatch 548::LR 0.0930769230769 --> Loss 0.00445546388626\n",
      "Epoch 4::Minibatch 549::LR 0.0930769230769 --> Loss 0.00760500907898\n",
      "Epoch 4::Minibatch 550::LR 0.0930769230769 --> Loss 0.00129500071208\n",
      "Epoch 4::Minibatch 551::LR 0.0930769230769 --> Loss 0.00261601924896\n",
      "Epoch 4::Minibatch 552::LR 0.0930769230769 --> Loss 0.00404736121496\n",
      "Epoch 4::Minibatch 553::LR 0.0930769230769 --> Loss 0.00360676129659\n",
      "Epoch 4::Minibatch 554::LR 0.0930769230769 --> Loss 0.00453121781349\n",
      "Epoch 4::Minibatch 555::LR 0.0930769230769 --> Loss 0.00117779145638\n",
      "Epoch 4::Minibatch 556::LR 0.0930769230769 --> Loss 0.00237768669923\n",
      "Epoch 4::Minibatch 557::LR 0.0930769230769 --> Loss 0.00277622322241\n",
      "Epoch 4::Minibatch 558::LR 0.0930769230769 --> Loss 0.00391320983569\n",
      "Epoch 4::Minibatch 559::LR 0.0930769230769 --> Loss 0.00395062247912\n",
      "Epoch 4::Minibatch 560::LR 0.0930769230769 --> Loss 0.00330512960752\n",
      "Epoch 4::Minibatch 561::LR 0.0930769230769 --> Loss 0.00310911933581\n",
      "Epoch 4::Minibatch 562::LR 0.0930769230769 --> Loss 0.00261220693588\n",
      "Epoch 4::Minibatch 563::LR 0.0930769230769 --> Loss 0.00423956712087\n",
      "Epoch 4::Minibatch 564::LR 0.0930769230769 --> Loss 0.00331631163756\n",
      "Epoch 4::Minibatch 565::LR 0.0930769230769 --> Loss 0.0040855038166\n",
      "Epoch 4::Minibatch 566::LR 0.0930769230769 --> Loss 0.00258332252502\n",
      "Epoch 4::Minibatch 567::LR 0.0930769230769 --> Loss 0.00303180038929\n",
      "Epoch 4::Minibatch 568::LR 0.0930769230769 --> Loss 0.00207471311092\n",
      "Epoch 4::Minibatch 569::LR 0.0930769230769 --> Loss 0.000747436285019\n",
      "Epoch 4::Minibatch 570::LR 0.0930769230769 --> Loss 0.00206058681011\n",
      "Epoch 4::Minibatch 571::LR 0.0930769230769 --> Loss 0.00267118016879\n",
      "Epoch 4::Minibatch 572::LR 0.0930769230769 --> Loss 0.00277088125547\n",
      "Epoch 4::Minibatch 573::LR 0.0930769230769 --> Loss 0.00170446515083\n",
      "Epoch 4::Minibatch 574::LR 0.0930769230769 --> Loss 0.00118373850981\n",
      "Epoch 4::Minibatch 575::LR 0.0930769230769 --> Loss 0.00209977606932\n",
      "Epoch 4::Minibatch 576::LR 0.0930769230769 --> Loss 0.00247752110163\n",
      "Epoch 4::Minibatch 577::LR 0.0930769230769 --> Loss 0.00194360236327\n",
      "Epoch 4::Minibatch 578::LR 0.0930769230769 --> Loss 0.00146218985319\n",
      "Epoch 4::Minibatch 579::LR 0.0930769230769 --> Loss 0.00137427369754\n",
      "Epoch 4::Minibatch 580::LR 0.0930769230769 --> Loss 0.00225003361702\n",
      "Epoch 4::Minibatch 581::LR 0.0930769230769 --> Loss 0.00191504617532\n",
      "Epoch 4::Minibatch 582::LR 0.0930769230769 --> Loss 0.00440062602361\n",
      "Epoch 4::Minibatch 583::LR 0.0930769230769 --> Loss 0.00109177261591\n",
      "Epoch 4::Minibatch 584::LR 0.0930769230769 --> Loss 0.00145621597767\n",
      "Epoch 4::Minibatch 585::LR 0.0930769230769 --> Loss 0.00681405464808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 586::LR 0.0930769230769 --> Loss 0.00473793705304\n",
      "Epoch 4::Minibatch 587::LR 0.0930769230769 --> Loss 0.00131857454777\n",
      "Epoch 4::Minibatch 588::LR 0.0930769230769 --> Loss 0.00163809676965\n",
      "Epoch 4::Minibatch 589::LR 0.0930769230769 --> Loss 0.00307286043962\n",
      "Epoch 4::Minibatch 590::LR 0.0930769230769 --> Loss 0.00247080226739\n",
      "Epoch 4::Minibatch 591::LR 0.0930769230769 --> Loss 0.00364940126737\n",
      "Epoch 4::Minibatch 592::LR 0.0930769230769 --> Loss 0.0013951103886\n",
      "Epoch 4::Minibatch 593::LR 0.0930769230769 --> Loss 0.00283797442913\n",
      "Epoch 4::Minibatch 594::LR 0.0930769230769 --> Loss 0.00327058891455\n",
      "Epoch 4::Minibatch 595::LR 0.0930769230769 --> Loss 0.00325558682283\n",
      "Epoch 4::Minibatch 596::LR 0.0930769230769 --> Loss 0.00243742148081\n",
      "Epoch 4::Minibatch 597::LR 0.0930769230769 --> Loss 0.00150757114093\n",
      "Epoch 4::Minibatch 598::LR 0.0930769230769 --> Loss 0.00369692405065\n",
      "Epoch 4::Minibatch 599::LR 0.0930769230769 --> Loss 0.0022093586127\n",
      "Epoch 4::Minibatch 600::LR 0.0930769230769 --> Loss 0.00264721969763\n",
      "Epoch 4::Minibatch 601::LR 0.0930769230769 --> Loss 0.00384857137998\n",
      "Epoch 4::Minibatch 602::LR 0.0930769230769 --> Loss 0.00224711875121\n",
      "Epoch 4::Minibatch 603::LR 0.0930769230769 --> Loss 0.00311899383863\n",
      "Epoch 4::Minibatch 604::LR 0.0930769230769 --> Loss 0.00190168758233\n",
      "Epoch 4::Minibatch 605::LR 0.0930769230769 --> Loss 0.0028438782692\n",
      "Epoch 4::Minibatch 606::LR 0.0930769230769 --> Loss 0.00228046000004\n",
      "Epoch 4::Minibatch 607::LR 0.0930769230769 --> Loss 0.000996477206548\n",
      "Epoch 4::Minibatch 608::LR 0.0930769230769 --> Loss 0.00195031265418\n",
      "Epoch 4::Minibatch 609::LR 0.0930769230769 --> Loss 0.00254587988059\n",
      "Epoch 4::Minibatch 610::LR 0.0930769230769 --> Loss 0.00395946621895\n",
      "Epoch 4::Minibatch 611::LR 0.0930769230769 --> Loss 0.00276547431946\n",
      "Epoch 4::Minibatch 612::LR 0.0930769230769 --> Loss 0.000728799253702\n",
      "Epoch 4::Minibatch 613::LR 0.0930769230769 --> Loss 0.00163350651662\n",
      "Epoch 4::Minibatch 614::LR 0.0930769230769 --> Loss 0.00281088153521\n",
      "Epoch 4::Minibatch 615::LR 0.0930769230769 --> Loss 0.00196982721488\n",
      "Epoch 4::Minibatch 616::LR 0.0930769230769 --> Loss 0.00109722703695\n",
      "Epoch 4::Minibatch 617::LR 0.0930769230769 --> Loss 0.000696358879407\n",
      "Epoch 4::Minibatch 618::LR 0.0930769230769 --> Loss 0.00275537629922\n",
      "Epoch 4::Minibatch 619::LR 0.0930769230769 --> Loss 0.00217517077923\n",
      "Epoch 4::Minibatch 620::LR 0.0930769230769 --> Loss 0.00189929068089\n",
      "Epoch 4::Minibatch 621::LR 0.0930769230769 --> Loss 0.000990313490232\n",
      "Epoch 4::Minibatch 622::LR 0.0930769230769 --> Loss 0.000990298986435\n",
      "Epoch 4::Minibatch 623::LR 0.0930769230769 --> Loss 0.00238341490428\n",
      "Epoch 4::Minibatch 624::LR 0.0930769230769 --> Loss 0.00206339319547\n",
      "Epoch 4::Minibatch 625::LR 0.0930769230769 --> Loss 0.0037549217542\n",
      "Epoch 4::Minibatch 626::LR 0.0930769230769 --> Loss 0.00525442083677\n",
      "Epoch 4::Minibatch 627::LR 0.0930769230769 --> Loss 0.00168093899886\n",
      "Epoch 4::Minibatch 628::LR 0.0930769230769 --> Loss 0.0011787985762\n",
      "Epoch 4::Minibatch 629::LR 0.0930769230769 --> Loss 0.0038475505511\n",
      "Epoch 4::Minibatch 630::LR 0.0930769230769 --> Loss 0.00368813514709\n",
      "Epoch 4::Minibatch 631::LR 0.0930769230769 --> Loss 0.00649895270665\n",
      "Epoch 4::Minibatch 632::LR 0.0930769230769 --> Loss 0.00110001931588\n",
      "Epoch 4::Minibatch 633::LR 0.0930769230769 --> Loss 0.00196619590123\n",
      "Epoch 4::Minibatch 634::LR 0.0930769230769 --> Loss 0.00352173129718\n",
      "Epoch 4::Minibatch 635::LR 0.0930769230769 --> Loss 0.00544718265533\n",
      "Epoch 4::Minibatch 636::LR 0.0930769230769 --> Loss 0.00622888724009\n",
      "Epoch 4::Minibatch 637::LR 0.0930769230769 --> Loss 0.00132372776667\n",
      "Epoch 4::Minibatch 638::LR 0.0930769230769 --> Loss 0.00204271475474\n",
      "Epoch 4::Minibatch 639::LR 0.0930769230769 --> Loss 0.00371154665947\n",
      "Epoch 4::Minibatch 640::LR 0.0930769230769 --> Loss 0.00522686203321\n",
      "Epoch 4::Minibatch 641::LR 0.0930769230769 --> Loss 0.00351109862328\n",
      "Epoch 4::Minibatch 642::LR 0.0930769230769 --> Loss 0.000841298699379\n",
      "Epoch 4::Minibatch 643::LR 0.0930769230769 --> Loss 0.00261593123277\n",
      "Epoch 4::Minibatch 644::LR 0.0930769230769 --> Loss 0.00430076003075\n",
      "Epoch 4::Minibatch 645::LR 0.0930769230769 --> Loss 0.00464790940285\n",
      "Epoch 4::Minibatch 646::LR 0.0930769230769 --> Loss 0.00190191268921\n",
      "Epoch 4::Minibatch 647::LR 0.0930769230769 --> Loss 0.0010263072451\n",
      "Epoch 4::Minibatch 648::LR 0.0930769230769 --> Loss 0.00346790035566\n",
      "Epoch 4::Minibatch 649::LR 0.0930769230769 --> Loss 0.00399154146512\n",
      "Epoch 4::Minibatch 650::LR 0.0930769230769 --> Loss 0.00372161904971\n",
      "Epoch 4::Minibatch 651::LR 0.0930769230769 --> Loss 0.00177325884501\n",
      "Epoch 4::Minibatch 652::LR 0.0930769230769 --> Loss 0.0012535661459\n",
      "Epoch 4::Minibatch 653::LR 0.0930769230769 --> Loss 0.00322135865688\n",
      "Epoch 4::Minibatch 654::LR 0.0930769230769 --> Loss 0.00336430827777\n",
      "Epoch 4::Minibatch 655::LR 0.0930769230769 --> Loss 0.00360848784447\n",
      "Epoch 4::Minibatch 656::LR 0.0930769230769 --> Loss 0.0010106275479\n",
      "Epoch 4::Minibatch 657::LR 0.0930769230769 --> Loss 0.00231883982817\n",
      "Epoch 4::Minibatch 658::LR 0.0930769230769 --> Loss 0.0052251068751\n",
      "Epoch 4::Minibatch 659::LR 0.0930769230769 --> Loss 0.00256692389647\n",
      "Epoch 4::Minibatch 660::LR 0.0930769230769 --> Loss 0.002652815183\n",
      "Epoch 4::Minibatch 661::LR 0.0930769230769 --> Loss 0.002790898482\n",
      "Epoch 4::Minibatch 662::LR 0.0930769230769 --> Loss 0.00205740074317\n",
      "Epoch 4::Minibatch 663::LR 0.0930769230769 --> Loss 0.00393494685491\n",
      "Epoch 4::Minibatch 664::LR 0.0930769230769 --> Loss 0.0037975247701\n",
      "Epoch 4::Minibatch 665::LR 0.0930769230769 --> Loss 0.0010894788305\n",
      "Epoch 4::Minibatch 666::LR 0.0930769230769 --> Loss 0.00404981772105\n",
      "Epoch 4::Minibatch 667::LR 0.0930769230769 --> Loss 0.00286757449309\n",
      "Epoch 4::Minibatch 668::LR 0.0930769230769 --> Loss 0.00751105467478\n",
      "Epoch 4::Minibatch 669::LR 0.0930769230769 --> Loss 0.00134970883528\n",
      "Epoch 4::Minibatch 670::LR 0.0930769230769 --> Loss 0.00161839395761\n",
      "Epoch 4::Minibatch 671::LR 0.0930769230769 --> Loss 0.00577782273293\n",
      "Epoch 4::Minibatch 672::LR 0.0930769230769 --> Loss 0.00442683815956\n",
      "Epoch 4::Minibatch 673::LR 0.0930769230769 --> Loss 0.00188133060932\n",
      "Epoch 4::Minibatch 674::LR 0.0930769230769 --> Loss 0.000794792224964\n",
      "Epoch 4::Minibatch 675::LR 0.0930769230769 --> Loss 0.00251383562883\n",
      "Epoch 4::Minibatch 676::LR 0.0930769230769 --> Loss 0.00254303753376\n",
      "Epoch 4::Minibatch 677::LR 0.0930769230769 --> Loss 0.00322853823503\n",
      "Epoch 4::Minibatch 678::LR 0.0930769230769 --> Loss 0.00224022905032\n",
      "Epoch 4::Minibatch 679::LR 0.0930769230769 --> Loss 0.00380809982618\n",
      "Epoch 4::Minibatch 680::LR 0.0930769230769 --> Loss 0.00241095344226\n",
      "Epoch 4::Minibatch 681::LR 0.0930769230769 --> Loss 0.00266710321109\n",
      "Epoch 4::Minibatch 682::LR 0.0930769230769 --> Loss 0.000965339442094\n",
      "Epoch 4::Minibatch 683::LR 0.0930769230769 --> Loss 0.00268312076728\n",
      "Epoch 4::Minibatch 684::LR 0.0930769230769 --> Loss 0.00261922041575\n",
      "Epoch 4::Minibatch 685::LR 0.0930769230769 --> Loss 0.00323454479376\n",
      "Epoch 4::Minibatch 686::LR 0.0930769230769 --> Loss 0.00168306529522\n",
      "Epoch 4::Minibatch 687::LR 0.0930769230769 --> Loss 0.00100694944461\n",
      "Epoch 4::Minibatch 688::LR 0.0930769230769 --> Loss 0.00288623134295\n",
      "Epoch 4::Minibatch 689::LR 0.0930769230769 --> Loss 0.00277106483777\n",
      "Epoch 4::Minibatch 690::LR 0.0930769230769 --> Loss 0.0021081417799\n",
      "Epoch 4::Minibatch 691::LR 0.0930769230769 --> Loss 0.00081452926\n",
      "Epoch 4::Minibatch 692::LR 0.0930769230769 --> Loss 0.0027142316103\n",
      "Epoch 4::Minibatch 693::LR 0.0930769230769 --> Loss 0.00279265403748\n",
      "Epoch 4::Minibatch 694::LR 0.0930769230769 --> Loss 0.00323578476906\n",
      "Epoch 4::Minibatch 695::LR 0.0930769230769 --> Loss 0.00200522025426\n",
      "Epoch 4::Minibatch 696::LR 0.0930769230769 --> Loss 0.00214516361554\n",
      "Epoch 4::Minibatch 697::LR 0.0930769230769 --> Loss 0.00155812690655\n",
      "Epoch 4::Minibatch 698::LR 0.0930769230769 --> Loss 0.00176155050596\n",
      "Epoch 4::Minibatch 699::LR 0.0930769230769 --> Loss 0.00391021450361\n",
      "Epoch 4::Minibatch 700::LR 0.0930769230769 --> Loss 0.00286122957865\n",
      "Epoch 4::Minibatch 701::LR 0.0930769230769 --> Loss 0.00224959830443\n",
      "Epoch 4::Minibatch 702::LR 0.0930769230769 --> Loss 0.00192831178506\n",
      "Epoch 4::Minibatch 703::LR 0.0930769230769 --> Loss 0.00419172883034\n",
      "Epoch 4::Minibatch 704::LR 0.0930769230769 --> Loss 0.00198474645615\n",
      "Epoch 4::Minibatch 705::LR 0.0930769230769 --> Loss 0.00297110776107\n",
      "Epoch 4::Minibatch 706::LR 0.0930769230769 --> Loss 0.00229038655758\n",
      "Epoch 4::Minibatch 707::LR 0.0930769230769 --> Loss 0.00141100674868\n",
      "Epoch 4::Minibatch 708::LR 0.0930769230769 --> Loss 0.00192364752293\n",
      "Epoch 4::Minibatch 709::LR 0.0930769230769 --> Loss 0.00193421185017\n",
      "Epoch 4::Minibatch 710::LR 0.0930769230769 --> Loss 0.00254480183125\n",
      "Epoch 4::Minibatch 711::LR 0.0930769230769 --> Loss 0.00201232075691\n",
      "Epoch 4::Minibatch 712::LR 0.0930769230769 --> Loss 0.00154163002968\n",
      "Epoch 4::Minibatch 713::LR 0.0930769230769 --> Loss 0.00189370413621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 714::LR 0.0930769230769 --> Loss 0.00279885868231\n",
      "Epoch 4::Minibatch 715::LR 0.0930769230769 --> Loss 0.00305922011534\n",
      "Epoch 4::Minibatch 716::LR 0.0930769230769 --> Loss 0.00174005826314\n",
      "Epoch 4::Minibatch 717::LR 0.0930769230769 --> Loss 0.00176535626252\n",
      "Epoch 4::Minibatch 718::LR 0.0930769230769 --> Loss 0.00147287040949\n",
      "Epoch 4::Minibatch 719::LR 0.0930769230769 --> Loss 0.00185875018438\n",
      "Epoch 4::Minibatch 720::LR 0.0930769230769 --> Loss 0.00241516530514\n",
      "Epoch 4::Minibatch 721::LR 0.0930769230769 --> Loss 0.000847195088863\n",
      "Epoch 4::Minibatch 722::LR 0.0930769230769 --> Loss 0.00512768507004\n",
      "Epoch 4::Minibatch 723::LR 0.0930769230769 --> Loss 0.00495974858602\n",
      "Epoch 4::Minibatch 724::LR 0.0930769230769 --> Loss 0.00119047264258\n",
      "Epoch 4::Minibatch 725::LR 0.0930769230769 --> Loss 0.00252165496349\n",
      "Epoch 4::Minibatch 726::LR 0.0930769230769 --> Loss 0.00537333250046\n",
      "Epoch 4::Minibatch 727::LR 0.0930769230769 --> Loss 0.00313067456086\n",
      "Epoch 4::Minibatch 728::LR 0.0930769230769 --> Loss 0.000884820818901\n",
      "Epoch 4::Minibatch 729::LR 0.0930769230769 --> Loss 0.00104182898998\n",
      "Epoch 4::Minibatch 730::LR 0.0930769230769 --> Loss 0.00273866991202\n",
      "Epoch 4::Minibatch 731::LR 0.0930769230769 --> Loss 0.00264234701792\n",
      "Epoch 4::Minibatch 732::LR 0.0930769230769 --> Loss 0.00257598340511\n",
      "Epoch 4::Minibatch 733::LR 0.0930769230769 --> Loss 0.00105700482925\n",
      "Epoch 4::Minibatch 734::LR 0.0930769230769 --> Loss 0.00211084008217\n",
      "Epoch 4::Minibatch 735::LR 0.0930769230769 --> Loss 0.00259178857009\n",
      "Epoch 4::Minibatch 736::LR 0.0930769230769 --> Loss 0.00361444473267\n",
      "Epoch 4::Minibatch 737::LR 0.0930769230769 --> Loss 0.00335803389549\n",
      "Epoch 4::Minibatch 738::LR 0.0930769230769 --> Loss 0.00191389163335\n",
      "Epoch 4::Minibatch 739::LR 0.0930769230769 --> Loss 0.00262019852797\n",
      "Epoch 4::Minibatch 740::LR 0.0930769230769 --> Loss 0.00385653972626\n",
      "Epoch 4::Minibatch 741::LR 0.0930769230769 --> Loss 0.00304952442646\n",
      "Epoch 4::Minibatch 742::LR 0.0930769230769 --> Loss 0.00236688097318\n",
      "Epoch 4::Minibatch 743::LR 0.0930769230769 --> Loss 0.00140798538923\n",
      "Epoch 4::Minibatch 744::LR 0.0930769230769 --> Loss 0.00198604802291\n",
      "Epoch 4::Minibatch 745::LR 0.0930769230769 --> Loss 0.00301499227683\n",
      "Epoch 4::Minibatch 746::LR 0.0930769230769 --> Loss 0.00326225419839\n",
      "Epoch 4::Minibatch 747::LR 0.0930769230769 --> Loss 0.00191203474998\n",
      "Epoch 4::Minibatch 748::LR 0.0930769230769 --> Loss 0.000843879381816\n",
      "Epoch 4::Minibatch 749::LR 0.0930769230769 --> Loss 0.00183314124743\n",
      "Epoch 4::Minibatch 750::LR 0.0930769230769 --> Loss 0.00264167626699\n",
      "Epoch 4::Minibatch 751::LR 0.0930769230769 --> Loss 0.00281595190366\n",
      "Epoch 4::Minibatch 752::LR 0.0930769230769 --> Loss 0.00116698086262\n",
      "Epoch 4::Minibatch 753::LR 0.0930769230769 --> Loss 0.002428779006\n",
      "Epoch 4::Minibatch 754::LR 0.0930769230769 --> Loss 0.00250338733196\n",
      "Epoch 4::Minibatch 755::LR 0.0930769230769 --> Loss 0.00278038005034\n",
      "Epoch 4::Minibatch 756::LR 0.0930769230769 --> Loss 0.00158185650905\n",
      "Epoch 4::Minibatch 757::LR 0.0930769230769 --> Loss 0.00108680178722\n",
      "Epoch 4::Minibatch 758::LR 0.0930769230769 --> Loss 0.00177432119846\n",
      "Epoch 4::Minibatch 759::LR 0.0930769230769 --> Loss 0.00408756613731\n",
      "Epoch 4::Minibatch 760::LR 0.0930769230769 --> Loss 0.00328954478105\n",
      "Epoch 4::Minibatch 761::LR 0.0930769230769 --> Loss 0.00647388219833\n",
      "Epoch 4::Minibatch 762::LR 0.0930769230769 --> Loss 0.0040439860026\n",
      "Epoch 4::Minibatch 763::LR 0.0930769230769 --> Loss 0.00400757074356\n",
      "Epoch 4::Minibatch 764::LR 0.0930769230769 --> Loss 0.00355394005775\n",
      "Epoch 4::Minibatch 765::LR 0.0930769230769 --> Loss 0.0015554801623\n",
      "Epoch 4::Minibatch 766::LR 0.0930769230769 --> Loss 0.00241312364737\n",
      "Epoch 4::Minibatch 767::LR 0.0930769230769 --> Loss 0.00513111313184\n",
      "Epoch 4::Minibatch 768::LR 0.0930769230769 --> Loss 0.00364853819211\n",
      "Epoch 4::Minibatch 769::LR 0.0930769230769 --> Loss 0.00218785027663\n",
      "Epoch 4::Minibatch 770::LR 0.0930769230769 --> Loss 0.0015720329682\n",
      "Epoch 4::Minibatch 771::LR 0.0930769230769 --> Loss 0.00399191856384\n",
      "Epoch 4::Minibatch 772::LR 0.0930769230769 --> Loss 0.00345696250598\n",
      "Epoch 4::Minibatch 773::LR 0.0930769230769 --> Loss 0.00345845778783\n",
      "Epoch 4::Minibatch 774::LR 0.0930769230769 --> Loss 0.00189132312934\n",
      "Epoch 4::Minibatch 775::LR 0.0930769230769 --> Loss 0.00505905350049\n",
      "Epoch 4::Minibatch 776::LR 0.0930769230769 --> Loss 0.00375630776087\n",
      "Epoch 4::Minibatch 777::LR 0.0930769230769 --> Loss 0.00790442228317\n",
      "Epoch 4::Minibatch 778::LR 0.0930769230769 --> Loss 0.0123319085439\n",
      "Epoch 4::Minibatch 779::LR 0.0930769230769 --> Loss 0.00164000521104\n",
      "Epoch 4::Minibatch 780::LR 0.0930769230769 --> Loss 0.00189041217168\n",
      "Epoch 4::Minibatch 781::LR 0.0930769230769 --> Loss 0.00394649187724\n",
      "Epoch 4::Minibatch 782::LR 0.0930769230769 --> Loss 0.00455575942993\n",
      "Epoch 4::Minibatch 783::LR 0.0930769230769 --> Loss 0.00261823276679\n",
      "Epoch 4::Minibatch 784::LR 0.0930769230769 --> Loss 0.000972900191943\n",
      "Epoch 4::Minibatch 785::LR 0.0930769230769 --> Loss 0.00478333115578\n",
      "Epoch 4::Minibatch 786::LR 0.0930769230769 --> Loss 0.00417681535085\n",
      "Epoch 4::Minibatch 787::LR 0.0930769230769 --> Loss 0.00330596208572\n",
      "Epoch 4::Minibatch 788::LR 0.0930769230769 --> Loss 0.00290366093318\n",
      "Epoch 4::Minibatch 789::LR 0.0930769230769 --> Loss 0.000930725534757\n",
      "Epoch 4::Minibatch 790::LR 0.0930769230769 --> Loss 0.00361417333285\n",
      "Epoch 4::Minibatch 791::LR 0.0930769230769 --> Loss 0.00440431276957\n",
      "Epoch 4::Minibatch 792::LR 0.0930769230769 --> Loss 0.00433397650719\n",
      "Epoch 4::Minibatch 793::LR 0.0930769230769 --> Loss 0.00262806773186\n",
      "Epoch 4::Minibatch 794::LR 0.0930769230769 --> Loss 0.0015926772356\n",
      "Epoch 4::Minibatch 795::LR 0.0930769230769 --> Loss 0.00413095672925\n",
      "Epoch 4::Minibatch 796::LR 0.0930769230769 --> Loss 0.00656316320101\n",
      "Epoch 4::Minibatch 797::LR 0.0930769230769 --> Loss 0.00970753272374\n",
      "Epoch 4::Minibatch 798::LR 0.0930769230769 --> Loss 0.00381970524788\n",
      "Epoch 4::Minibatch 799::LR 0.0930769230769 --> Loss 0.00328160544237\n",
      "Epoch 4::Minibatch 800::LR 0.0930769230769 --> Loss 0.00246624350548\n",
      "Epoch 4::Minibatch 801::LR 0.0930769230769 --> Loss 0.00437099575996\n",
      "Epoch 4::Minibatch 802::LR 0.0930769230769 --> Loss 0.00170108874639\n",
      "Epoch 4::Minibatch 803::LR 0.0930769230769 --> Loss 0.00287121872107\n",
      "Epoch 4::Minibatch 804::LR 0.0930769230769 --> Loss 0.00268111387889\n",
      "Epoch 4::Minibatch 805::LR 0.0930769230769 --> Loss 0.00263087610404\n",
      "Epoch 4::Minibatch 806::LR 0.0930769230769 --> Loss 0.00352964242299\n",
      "Epoch 4::Minibatch 807::LR 0.0930769230769 --> Loss 0.00340620319049\n",
      "Epoch 4::Minibatch 808::LR 0.0930769230769 --> Loss 0.00334743658702\n",
      "Epoch 4::Minibatch 809::LR 0.0930769230769 --> Loss 0.00522555907567\n",
      "Epoch 4::Minibatch 810::LR 0.0930769230769 --> Loss 0.00626563707987\n",
      "Epoch 4::Minibatch 811::LR 0.0930769230769 --> Loss 0.00571902950605\n",
      "Epoch 4::Minibatch 812::LR 0.0930769230769 --> Loss 0.00579132517179\n",
      "Epoch 4::Minibatch 813::LR 0.0930769230769 --> Loss 0.00553042451541\n",
      "Epoch 4::Minibatch 814::LR 0.0930769230769 --> Loss 0.00301585396131\n",
      "Epoch 4::Minibatch 815::LR 0.0930769230769 --> Loss 0.00487881024679\n",
      "Epoch 4::Minibatch 816::LR 0.0930769230769 --> Loss 0.00470571637154\n",
      "Epoch 4::Minibatch 817::LR 0.0930769230769 --> Loss 0.00506451010704\n",
      "Epoch 4::Minibatch 818::LR 0.0930769230769 --> Loss 0.001764767766\n",
      "Epoch 4::Minibatch 819::LR 0.0930769230769 --> Loss 0.00105340401332\n",
      "Epoch 4::Minibatch 820::LR 0.0930769230769 --> Loss 0.00590793569883\n",
      "Epoch 4::Minibatch 821::LR 0.0930769230769 --> Loss 0.00363385081291\n",
      "Epoch 4::Minibatch 822::LR 0.0930769230769 --> Loss 0.00440511902173\n",
      "Epoch 4::Minibatch 823::LR 0.0930769230769 --> Loss 0.00155070334673\n",
      "Epoch 4::Minibatch 824::LR 0.0930769230769 --> Loss 0.0017164794604\n",
      "Epoch 4::Minibatch 825::LR 0.0930769230769 --> Loss 0.0040722767512\n",
      "Epoch 4::Minibatch 826::LR 0.0930769230769 --> Loss 0.00398022770882\n",
      "Epoch 4::Minibatch 827::LR 0.0930769230769 --> Loss 0.00257378280163\n",
      "Epoch 4::Minibatch 828::LR 0.0930769230769 --> Loss 0.000943610966206\n",
      "Epoch 4::Minibatch 829::LR 0.0930769230769 --> Loss 0.00272368590037\n",
      "Epoch 4::Minibatch 830::LR 0.0930769230769 --> Loss 0.00469760934512\n",
      "Epoch 4::Minibatch 831::LR 0.0930769230769 --> Loss 0.0028290305535\n",
      "Epoch 4::Minibatch 832::LR 0.0930769230769 --> Loss 0.00255038162072\n",
      "Epoch 4::Minibatch 833::LR 0.0930769230769 --> Loss 0.00202280680339\n",
      "Epoch 4::Minibatch 834::LR 0.0930769230769 --> Loss 0.000965808033943\n",
      "Epoch 4::Minibatch 835::LR 0.0930769230769 --> Loss 0.00400119145711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 836::LR 0.0930769230769 --> Loss 0.00414372563362\n",
      "Epoch 4::Minibatch 837::LR 0.0930769230769 --> Loss 0.00288396954536\n",
      "Epoch 4::Minibatch 838::LR 0.0930769230769 --> Loss 0.00103178123633\n",
      "Epoch 4::Minibatch 839::LR 0.0930769230769 --> Loss 0.00274082442125\n",
      "Epoch 4::Minibatch 840::LR 0.0930769230769 --> Loss 0.00337161858877\n",
      "Epoch 4::Minibatch 841::LR 0.0930769230769 --> Loss 0.00349603295326\n",
      "Epoch 4::Minibatch 842::LR 0.0930769230769 --> Loss 0.00264624277751\n",
      "Epoch 4::Minibatch 843::LR 0.0930769230769 --> Loss 0.00123486002286\n",
      "Epoch 4::Minibatch 844::LR 0.0930769230769 --> Loss 0.00183858255545\n",
      "Epoch 4::Minibatch 845::LR 0.0930769230769 --> Loss 0.00459795276324\n",
      "Epoch 4::Minibatch 846::LR 0.0930769230769 --> Loss 0.00197168707848\n",
      "Epoch 4::Minibatch 847::LR 0.0930769230769 --> Loss 0.00292099157969\n",
      "Epoch 4::Minibatch 848::LR 0.0930769230769 --> Loss 0.00138621081909\n",
      "Epoch 4::Minibatch 849::LR 0.0930769230769 --> Loss 0.00218676249186\n",
      "Epoch 4::Minibatch 850::LR 0.0930769230769 --> Loss 0.00340688427289\n",
      "Epoch 4::Minibatch 851::LR 0.0930769230769 --> Loss 0.00317363123099\n",
      "Epoch 4::Minibatch 852::LR 0.0930769230769 --> Loss 0.00134949535131\n",
      "Epoch 4::Minibatch 853::LR 0.0930769230769 --> Loss 0.00154508898656\n",
      "Epoch 4::Minibatch 854::LR 0.0930769230769 --> Loss 0.00265471855799\n",
      "Epoch 4::Minibatch 855::LR 0.0930769230769 --> Loss 0.00237466375033\n",
      "Epoch 4::Minibatch 856::LR 0.0930769230769 --> Loss 0.00193343480428\n",
      "Epoch 4::Minibatch 857::LR 0.0930769230769 --> Loss 0.00133878668149\n",
      "Epoch 4::Minibatch 858::LR 0.0930769230769 --> Loss 0.000797581473986\n",
      "Epoch 4::Minibatch 859::LR 0.0930769230769 --> Loss 0.00201777954896\n",
      "Epoch 4::Minibatch 860::LR 0.0930769230769 --> Loss 0.00133543183406\n",
      "Epoch 4::Minibatch 861::LR 0.0930769230769 --> Loss 0.00107840289672\n",
      "Epoch 4::Minibatch 862::LR 0.0930769230769 --> Loss 0.00377099355062\n",
      "Epoch 4::Minibatch 863::LR 0.0930769230769 --> Loss 0.00345136682192\n",
      "Epoch 4::Minibatch 864::LR 0.0930769230769 --> Loss 0.00335710922877\n",
      "Epoch 4::Minibatch 865::LR 0.0930769230769 --> Loss 0.00069343701005\n",
      "Epoch 4::Minibatch 866::LR 0.0930769230769 --> Loss 0.00242281814416\n",
      "Epoch 4::Minibatch 867::LR 0.0930769230769 --> Loss 0.00323444922765\n",
      "Epoch 4::Minibatch 868::LR 0.0930769230769 --> Loss 0.00288049459457\n",
      "Epoch 4::Minibatch 869::LR 0.0930769230769 --> Loss 0.00225210666656\n",
      "Epoch 4::Minibatch 870::LR 0.0930769230769 --> Loss 0.003960206906\n",
      "Epoch 4::Minibatch 871::LR 0.0930769230769 --> Loss 0.00171757102013\n",
      "Epoch 4::Minibatch 872::LR 0.0930769230769 --> Loss 0.00264941394329\n",
      "Epoch 4::Minibatch 873::LR 0.0930769230769 --> Loss 0.00274496813615\n",
      "Epoch 4::Minibatch 874::LR 0.0930769230769 --> Loss 0.00652773221334\n",
      "Epoch 4::Minibatch 875::LR 0.0930769230769 --> Loss 0.00064106931289\n",
      "Epoch 4::Minibatch 876::LR 0.0930769230769 --> Loss 0.00415153225263\n",
      "Epoch 4::Minibatch 877::LR 0.0930769230769 --> Loss 0.00776004314423\n",
      "Epoch 4::Minibatch 878::LR 0.0930769230769 --> Loss 0.0037216937542\n",
      "Epoch 4::Minibatch 879::LR 0.0930769230769 --> Loss 0.00429122010867\n",
      "Epoch 4::Minibatch 880::LR 0.0930769230769 --> Loss 0.00490224679311\n",
      "Epoch 4::Minibatch 881::LR 0.0930769230769 --> Loss 0.00437156716983\n",
      "Epoch 4::Minibatch 882::LR 0.0930769230769 --> Loss 0.00228149871031\n",
      "Epoch 4::Minibatch 883::LR 0.0930769230769 --> Loss 0.00347130894661\n",
      "Epoch 4::Minibatch 884::LR 0.0930769230769 --> Loss 0.00283987462521\n",
      "Epoch 4::Minibatch 885::LR 0.0930769230769 --> Loss 0.00279380698999\n",
      "Epoch 4::Minibatch 886::LR 0.0930769230769 --> Loss 0.00119649708271\n",
      "Epoch 4::Minibatch 887::LR 0.0930769230769 --> Loss 0.00593050519625\n",
      "Epoch 4::Minibatch 888::LR 0.0930769230769 --> Loss 0.00287018915017\n",
      "Epoch 4::Minibatch 889::LR 0.0930769230769 --> Loss 0.00407330751419\n",
      "Epoch 4::Minibatch 890::LR 0.0930769230769 --> Loss 0.00515952905019\n",
      "Epoch 4::Minibatch 891::LR 0.0930769230769 --> Loss 0.00260148326556\n",
      "Epoch 4::Minibatch 892::LR 0.0930769230769 --> Loss 0.00124834020933\n",
      "Epoch 4::Minibatch 893::LR 0.0930769230769 --> Loss 0.00298768381278\n",
      "Epoch 4::Minibatch 894::LR 0.0930769230769 --> Loss 0.00274547139804\n",
      "Epoch 4::Minibatch 895::LR 0.0930769230769 --> Loss 0.00284441252549\n",
      "Epoch 4::Minibatch 896::LR 0.0930769230769 --> Loss 0.00184506615003\n",
      "Epoch 4::Minibatch 897::LR 0.0930769230769 --> Loss 0.00103870650132\n",
      "Epoch 4::Minibatch 898::LR 0.0930769230769 --> Loss 0.00258364379406\n",
      "Epoch 4::Minibatch 899::LR 0.0930769230769 --> Loss 0.00268433411916\n",
      "Epoch 4::Minibatch 900::LR 0.0930769230769 --> Loss 0.00359465360641\n",
      "Epoch 4::Minibatch 901::LR 0.0930769230769 --> Loss 0.0008126351734\n",
      "Epoch 4::Minibatch 902::LR 0.0930769230769 --> Loss 0.0015981126825\n",
      "Epoch 4::Minibatch 903::LR 0.0930769230769 --> Loss 0.00301973859469\n",
      "Epoch 4::Minibatch 904::LR 0.0930769230769 --> Loss 0.00257279674212\n",
      "Epoch 4::Minibatch 905::LR 0.0930769230769 --> Loss 0.00162644555171\n",
      "Epoch 4::Minibatch 906::LR 0.0930769230769 --> Loss 0.00126397470633\n",
      "Epoch 4::Minibatch 907::LR 0.0930769230769 --> Loss 0.00165683507919\n",
      "Epoch 4::Minibatch 908::LR 0.0930769230769 --> Loss 0.00292737166087\n",
      "Epoch 4::Minibatch 909::LR 0.0930769230769 --> Loss 0.0025751097997\n",
      "Epoch 4::Minibatch 910::LR 0.0930769230769 --> Loss 0.000958592394988\n",
      "Epoch 4::Minibatch 911::LR 0.0930769230769 --> Loss 0.00135386387507\n",
      "Epoch 4::Minibatch 912::LR 0.0930769230769 --> Loss 0.00245181242625\n",
      "Epoch 4::Minibatch 913::LR 0.0930769230769 --> Loss 0.00231717030207\n",
      "Epoch 4::Minibatch 914::LR 0.0930769230769 --> Loss 0.00141881724199\n",
      "Epoch 4::Minibatch 915::LR 0.0930769230769 --> Loss 0.000606076916059\n",
      "Epoch 4::Minibatch 916::LR 0.0930769230769 --> Loss 0.0030397472779\n",
      "Epoch 4::Minibatch 917::LR 0.0930769230769 --> Loss 0.00447463830312\n",
      "Epoch 4::Minibatch 918::LR 0.0930769230769 --> Loss 0.0062839114666\n",
      "Epoch 4::Minibatch 919::LR 0.0930769230769 --> Loss 0.00131536016862\n",
      "Epoch 4::Minibatch 920::LR 0.0930769230769 --> Loss 0.00918544054031\n",
      "Epoch 4::Minibatch 921::LR 0.0930769230769 --> Loss 0.00346465826035\n",
      "Epoch 4::Minibatch 922::LR 0.0930769230769 --> Loss 0.00355913003286\n",
      "Epoch 4::Minibatch 923::LR 0.0930769230769 --> Loss 0.0020942825079\n",
      "Epoch 4::Minibatch 924::LR 0.0930769230769 --> Loss 0.00387843132019\n",
      "Epoch 4::Minibatch 925::LR 0.0930769230769 --> Loss 0.00361347913742\n",
      "Epoch 4::Minibatch 926::LR 0.0930769230769 --> Loss 0.00591460029284\n",
      "Epoch 4::Minibatch 927::LR 0.0930769230769 --> Loss 0.00955443700155\n",
      "Epoch 4::Minibatch 928::LR 0.0930769230769 --> Loss 0.00707616885503\n",
      "Epoch 4::Minibatch 929::LR 0.0930769230769 --> Loss 0.0111217125257\n",
      "Epoch 4::Minibatch 930::LR 0.0930769230769 --> Loss 0.007394490242\n",
      "Epoch 4::Minibatch 931::LR 0.0930769230769 --> Loss 0.00445103645325\n",
      "Epoch 4::Minibatch 932::LR 0.0930769230769 --> Loss 0.00986401240031\n",
      "Epoch 4::Minibatch 933::LR 0.0930769230769 --> Loss 0.00541689276695\n",
      "Epoch 4::Minibatch 934::LR 0.0930769230769 --> Loss 0.00711463530858\n",
      "Epoch 4::Minibatch 935::LR 0.0930769230769 --> Loss 0.00866532405217\n",
      "Epoch 4::Minibatch 936::LR 0.0930769230769 --> Loss 0.00299364586671\n",
      "Epoch 4::Minibatch 937::LR 0.0930769230769 --> Loss 0.00512012124062\n",
      "Epoch 4::Minibatch 938::LR 0.0930769230769 --> Loss 0.00501929243406\n",
      "Epoch 4::Minibatch 939::LR 0.0930769230769 --> Loss 0.00509318391482\n",
      "Epoch 4::Minibatch 940::LR 0.0930769230769 --> Loss 0.00159114420414\n",
      "Epoch 4::Minibatch 941::LR 0.0930769230769 --> Loss 0.00139726767937\n",
      "Epoch 4::Minibatch 942::LR 0.0930769230769 --> Loss 0.00269602338473\n",
      "Epoch 4::Minibatch 943::LR 0.0930769230769 --> Loss 0.00412789742152\n",
      "Epoch 4::Minibatch 944::LR 0.0930769230769 --> Loss 0.00332812726498\n",
      "Epoch 4::Minibatch 945::LR 0.0930769230769 --> Loss 0.0021430738767\n",
      "Epoch 4::Minibatch 946::LR 0.0930769230769 --> Loss 0.00440602421761\n",
      "Epoch 4::Minibatch 947::LR 0.0930769230769 --> Loss 0.00379500230153\n",
      "Epoch 4::Minibatch 948::LR 0.0930769230769 --> Loss 0.00609902103742\n",
      "Epoch 4::Minibatch 949::LR 0.0930769230769 --> Loss 0.00232160369555\n",
      "Epoch 4::Minibatch 950::LR 0.0930769230769 --> Loss 0.000942836105824\n",
      "Epoch 4::Minibatch 951::LR 0.0930769230769 --> Loss 0.00368189255397\n",
      "Epoch 4::Minibatch 952::LR 0.0930769230769 --> Loss 0.00276754498482\n",
      "Epoch 4::Minibatch 953::LR 0.0930769230769 --> Loss 0.00150574107965\n",
      "Epoch 4::Minibatch 954::LR 0.0930769230769 --> Loss 0.00115629335244\n",
      "Epoch 4::Minibatch 955::LR 0.0930769230769 --> Loss 0.00277299086253\n",
      "Epoch 4::Minibatch 956::LR 0.0930769230769 --> Loss 0.00480235139529\n",
      "Epoch 4::Minibatch 957::LR 0.0930769230769 --> Loss 0.00219260215759\n",
      "Epoch 4::Minibatch 958::LR 0.0930769230769 --> Loss 0.00302498658498\n",
      "Epoch 4::Minibatch 959::LR 0.0930769230769 --> Loss 0.003686277469\n",
      "Epoch 4::Minibatch 960::LR 0.0930769230769 --> Loss 0.00730929692586\n",
      "Epoch 4::Minibatch 961::LR 0.0930769230769 --> Loss 0.00381284594536\n",
      "Epoch 4::Minibatch 962::LR 0.0930769230769 --> Loss 0.00352272311846\n",
      "Epoch 4::Minibatch 963::LR 0.0930769230769 --> Loss 0.00176772991816\n",
      "Epoch 4::Minibatch 964::LR 0.0930769230769 --> Loss 0.00293815096219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4::Minibatch 965::LR 0.0930769230769 --> Loss 0.00928998788198\n",
      "Epoch 4::Minibatch 966::LR 0.0930769230769 --> Loss 0.00658986051877\n",
      "Epoch 4::Minibatch 967::LR 0.0930769230769 --> Loss 0.00252541601658\n",
      "Epoch 4::Minibatch 968::LR 0.0930769230769 --> Loss 0.00231552918752\n",
      "Epoch 4::Minibatch 969::LR 0.0930769230769 --> Loss 0.00831874529521\n",
      "Epoch 4::Minibatch 970::LR 0.0930769230769 --> Loss 0.00641564289729\n",
      "Epoch 4::Minibatch 971::LR 0.0930769230769 --> Loss 0.00383482495944\n",
      "Epoch 4::Minibatch 972::LR 0.0930769230769 --> Loss 0.00841770251592\n",
      "Epoch 4::Minibatch 973::LR 0.0930769230769 --> Loss 0.00997523387273\n",
      "Epoch 4::Minibatch 974::LR 0.0930769230769 --> Loss 0.00600461999575\n",
      "Epoch 4::Minibatch 975::LR 0.0930769230769 --> Loss 0.00509318510691\n",
      "Epoch 4::Minibatch 976::LR 0.0930769230769 --> Loss 0.00456134637197\n",
      "Epoch 4::Minibatch 977::LR 0.0930769230769 --> Loss 0.00461787422498\n",
      "Epoch 4::Minibatch 978::LR 0.0930769230769 --> Loss 0.00448596994082\n",
      "Epoch 4::Minibatch 979::LR 0.0930769230769 --> Loss 0.00446915944417\n",
      "Epoch 4::Minibatch 980::LR 0.0930769230769 --> Loss 0.0040996046861\n",
      "Epoch 4::Minibatch 981::LR 0.0930769230769 --> Loss 0.00544873992602\n",
      "Epoch 4::Minibatch 982::LR 0.0930769230769 --> Loss 0.00729889392853\n",
      "Epoch 4::Minibatch 983::LR 0.0930769230769 --> Loss 0.00353673577309\n",
      "Epoch 4::Minibatch 984::LR 0.0930769230769 --> Loss 0.00332919875781\n",
      "Epoch 4::Minibatch 985::LR 0.0930769230769 --> Loss 0.00465531746546\n",
      "Epoch 4::Minibatch 986::LR 0.0930769230769 --> Loss 0.00414414405823\n",
      "Epoch 4::Minibatch 987::LR 0.0930769230769 --> Loss 0.0046075908343\n",
      "Epoch 4::Minibatch 988::LR 0.0930769230769 --> Loss 0.00344331343969\n",
      "Epoch 4::Minibatch 989::LR 0.0930769230769 --> Loss 0.00330058674018\n",
      "Epoch 4::Minibatch 990::LR 0.0930769230769 --> Loss 0.00361156185468\n",
      "Epoch 4::Minibatch 991::LR 0.0930769230769 --> Loss 0.00173220833143\n",
      "Epoch 4::Minibatch 992::LR 0.0930769230769 --> Loss 0.00204262773196\n",
      "Epoch 4::Minibatch 993::LR 0.0930769230769 --> Loss 0.00325672328472\n",
      "Epoch 4::Minibatch 994::LR 0.0930769230769 --> Loss 0.00210572858651\n",
      "Epoch 4::Minibatch 995::LR 0.0930769230769 --> Loss 0.00103718886773\n",
      "Epoch 4::Minibatch 996::LR 0.0930769230769 --> Loss 0.00352676272392\n",
      "Epoch 4::Minibatch 997::LR 0.0930769230769 --> Loss 0.00191795647144\n",
      "Epoch 4::Minibatch 998::LR 0.0930769230769 --> Loss 0.00203670581182\n",
      "Epoch 4::Minibatch 999::LR 0.0930769230769 --> Loss 0.00178930660089\n",
      "Epoch 4::Minibatch 1000::LR 0.0930769230769 --> Loss 0.00197857936223\n",
      "Epoch 4::Minibatch 1001::LR 0.0930769230769 --> Loss 0.00170272052288\n",
      "Epoch 4::Minibatch 1002::LR 0.0930769230769 --> Loss 0.00499330878258\n",
      "Epoch 4::Minibatch 1003::LR 0.0930769230769 --> Loss 0.00503302296003\n",
      "Epoch 4::Minibatch 1004::LR 0.0930769230769 --> Loss 0.00122370491425\n",
      "Epoch 4::Minibatch 1005::LR 0.0930769230769 --> Loss 0.00562471270561\n",
      "Epoch 4::Minibatch 1006::LR 0.0930769230769 --> Loss 0.00413049181302\n",
      "Epoch 4::Minibatch 1007::LR 0.0930769230769 --> Loss 0.00340137163798\n",
      "Epoch 4::Minibatch 1008::LR 0.0930769230769 --> Loss 0.00110905398925\n",
      "Epoch 4::Minibatch 1009::LR 0.0930769230769 --> Loss 0.00183256228765\n",
      "Epoch 4::Minibatch 1010::LR 0.0930769230769 --> Loss 0.00169778327147\n",
      "Epoch 4::Minibatch 1011::LR 0.0930769230769 --> Loss 0.00521909674009\n",
      "Epoch 4::Minibatch 1012::LR 0.0930769230769 --> Loss 0.00251701831818\n",
      "Epoch 4::Minibatch 1013::LR 0.0930769230769 --> Loss 0.00470483223597\n",
      "Epoch 4::Minibatch 1014::LR 0.0930769230769 --> Loss 0.0047307574749\n",
      "Epoch 4::Minibatch 1015::LR 0.0930769230769 --> Loss 0.00222552676996\n",
      "Epoch 4::Minibatch 1016::LR 0.0930769230769 --> Loss 0.00536864995956\n",
      "Epoch 4::Minibatch 1017::LR 0.0930769230769 --> Loss 0.00346432685852\n",
      "Epoch 4::Minibatch 1018::LR 0.0930769230769 --> Loss 0.00377465565999\n",
      "Epoch 4::Minibatch 1019::LR 0.0930769230769 --> Loss 0.00305617948373\n",
      "Epoch 4::Minibatch 1020::LR 0.0930769230769 --> Loss 0.00284838438034\n",
      "Epoch 4::Minibatch 1021::LR 0.0930769230769 --> Loss 0.002547681729\n",
      "Epoch 4::Minibatch 1022::LR 0.0930769230769 --> Loss 0.00205539067586\n",
      "Epoch 4::Minibatch 1023::LR 0.0930769230769 --> Loss 0.00181212325891\n",
      "Epoch 4::Minibatch 1024::LR 0.0930769230769 --> Loss 0.00169717868169\n",
      "Epoch 4::Minibatch 1025::LR 0.0930769230769 --> Loss 0.00181835234165\n",
      "Epoch 4::Minibatch 1026::LR 0.0930769230769 --> Loss 0.00145178546508\n",
      "Epoch 4::Minibatch 1027::LR 0.0930769230769 --> Loss 0.00140255431334\n",
      "Epoch 4::Minibatch 1028::LR 0.0930769230769 --> Loss 0.00112956811984\n",
      "Epoch 4::Minibatch 1029::LR 0.0930769230769 --> Loss 0.00101306329171\n",
      "Epoch 4::Minibatch 1030::LR 0.0930769230769 --> Loss 0.00120797038078\n",
      "Epoch 4::Minibatch 1031::LR 0.0930769230769 --> Loss 0.000910934408506\n",
      "Epoch 4::Minibatch 1032::LR 0.0930769230769 --> Loss 0.000864886542161\n",
      "Epoch 4::Minibatch 1033::LR 0.0930769230769 --> Loss 0.000718947201967\n",
      "Epoch 4::Minibatch 1034::LR 0.0930769230769 --> Loss 0.000785357306401\n",
      "Epoch 4::Minibatch 1035::LR 0.0930769230769 --> Loss 0.000712680170933\n",
      "Epoch 4::Minibatch 1036::LR 0.0930769230769 --> Loss 0.000541514555613\n",
      "Epoch 4::Minibatch 1037::LR 0.0930769230769 --> Loss 0.000586625536283\n",
      "Epoch 4::Minibatch 1038::LR 0.0930769230769 --> Loss 0.00139809469382\n",
      "Epoch 4::Minibatch 1039::LR 0.0930769230769 --> Loss 0.00122134327888\n",
      "Epoch 4::Minibatch 1040::LR 0.0930769230769 --> Loss 0.000652682681878\n",
      "Epoch 4::Minibatch 1041::LR 0.0930769230769 --> Loss 0.000708241015673\n",
      "Epoch 5::Minibatch 1::LR 0.0907692307692 --> Loss 0.0142012548447\n",
      "Epoch 5::Minibatch 2::LR 0.0907692307692 --> Loss 0.00946165243785\n",
      "Epoch 5::Minibatch 3::LR 0.0907692307692 --> Loss 0.00808814764023\n",
      "Epoch 5::Minibatch 4::LR 0.0907692307692 --> Loss 0.00655803879102\n",
      "Epoch 5::Minibatch 5::LR 0.0907692307692 --> Loss 0.00521768569946\n",
      "Epoch 5::Minibatch 6::LR 0.0907692307692 --> Loss 0.00307478785515\n",
      "Epoch 5::Minibatch 7::LR 0.0907692307692 --> Loss 0.00831142425537\n",
      "Epoch 5::Minibatch 8::LR 0.0907692307692 --> Loss 0.00867412726084\n",
      "Epoch 5::Minibatch 9::LR 0.0907692307692 --> Loss 0.00685265541077\n",
      "Epoch 5::Minibatch 10::LR 0.0907692307692 --> Loss 0.00389098485311\n",
      "Epoch 5::Minibatch 11::LR 0.0907692307692 --> Loss 0.00311002333959\n",
      "Epoch 5::Minibatch 12::LR 0.0907692307692 --> Loss 0.0041210603714\n",
      "Epoch 5::Minibatch 13::LR 0.0907692307692 --> Loss 0.00567331751188\n",
      "Epoch 5::Minibatch 14::LR 0.0907692307692 --> Loss 0.0051768942674\n",
      "Epoch 5::Minibatch 15::LR 0.0907692307692 --> Loss 0.00369043469429\n",
      "Epoch 5::Minibatch 16::LR 0.0907692307692 --> Loss 0.00118754029274\n",
      "Epoch 5::Minibatch 17::LR 0.0907692307692 --> Loss 0.00298957546552\n",
      "Epoch 5::Minibatch 18::LR 0.0907692307692 --> Loss 0.00274824917316\n",
      "Epoch 5::Minibatch 19::LR 0.0907692307692 --> Loss 0.000964443385601\n",
      "Epoch 5::Minibatch 20::LR 0.0907692307692 --> Loss 0.00144691298405\n",
      "Epoch 5::Minibatch 21::LR 0.0907692307692 --> Loss 0.00336544275284\n",
      "Epoch 5::Minibatch 22::LR 0.0907692307692 --> Loss 0.00272710859776\n",
      "Epoch 5::Minibatch 23::LR 0.0907692307692 --> Loss 0.00115044355392\n",
      "Epoch 5::Minibatch 24::LR 0.0907692307692 --> Loss 0.000571839610736\n",
      "Epoch 5::Minibatch 25::LR 0.0907692307692 --> Loss 0.00144786636035\n",
      "Epoch 5::Minibatch 26::LR 0.0907692307692 --> Loss 0.00171915213267\n",
      "Epoch 5::Minibatch 27::LR 0.0907692307692 --> Loss 0.00122511029243\n",
      "Epoch 5::Minibatch 28::LR 0.0907692307692 --> Loss 0.000492445379496\n",
      "Epoch 5::Minibatch 29::LR 0.0907692307692 --> Loss 0.000499892234802\n",
      "Epoch 5::Minibatch 30::LR 0.0907692307692 --> Loss 0.0010822780927\n",
      "Epoch 5::Minibatch 31::LR 0.0907692307692 --> Loss 0.0015290782849\n",
      "Epoch 5::Minibatch 32::LR 0.0907692307692 --> Loss 0.00145405004422\n",
      "Epoch 5::Minibatch 33::LR 0.0907692307692 --> Loss 0.000848113795122\n",
      "Epoch 5::Minibatch 34::LR 0.0907692307692 --> Loss 0.00290262579918\n",
      "Epoch 5::Minibatch 35::LR 0.0907692307692 --> Loss 0.00406127214432\n",
      "Epoch 5::Minibatch 36::LR 0.0907692307692 --> Loss 0.00223697582881\n",
      "Epoch 5::Minibatch 37::LR 0.0907692307692 --> Loss 0.000582408805688\n",
      "Epoch 5::Minibatch 38::LR 0.0907692307692 --> Loss 0.000968095262845\n",
      "Epoch 5::Minibatch 39::LR 0.0907692307692 --> Loss 0.00237145443757\n",
      "Epoch 5::Minibatch 40::LR 0.0907692307692 --> Loss 0.00376306295395\n",
      "Epoch 5::Minibatch 41::LR 0.0907692307692 --> Loss 0.00373137553533\n",
      "Epoch 5::Minibatch 42::LR 0.0907692307692 --> Loss 0.00573585748672\n",
      "Epoch 5::Minibatch 43::LR 0.0907692307692 --> Loss 0.00188672602177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 44::LR 0.0907692307692 --> Loss 0.00301045497259\n",
      "Epoch 5::Minibatch 45::LR 0.0907692307692 --> Loss 0.00270523190498\n",
      "Epoch 5::Minibatch 46::LR 0.0907692307692 --> Loss 0.00387373288472\n",
      "Epoch 5::Minibatch 47::LR 0.0907692307692 --> Loss 0.0056113644441\n",
      "Epoch 5::Minibatch 48::LR 0.0907692307692 --> Loss 0.00573328574498\n",
      "Epoch 5::Minibatch 49::LR 0.0907692307692 --> Loss 0.00573492487272\n",
      "Epoch 5::Minibatch 50::LR 0.0907692307692 --> Loss 0.00481153527896\n",
      "Epoch 5::Minibatch 51::LR 0.0907692307692 --> Loss 0.00897444963455\n",
      "Epoch 5::Minibatch 52::LR 0.0907692307692 --> Loss 0.00364262978236\n",
      "Epoch 5::Minibatch 53::LR 0.0907692307692 --> Loss 0.00386184970538\n",
      "Epoch 5::Minibatch 54::LR 0.0907692307692 --> Loss 0.00406981269519\n",
      "Epoch 5::Minibatch 55::LR 0.0907692307692 --> Loss 0.0015979090333\n",
      "Epoch 5::Minibatch 56::LR 0.0907692307692 --> Loss 0.00328629036744\n",
      "Epoch 5::Minibatch 57::LR 0.0907692307692 --> Loss 0.00606445709864\n",
      "Epoch 5::Minibatch 58::LR 0.0907692307692 --> Loss 0.00408465425173\n",
      "Epoch 5::Minibatch 59::LR 0.0907692307692 --> Loss 0.0036693807443\n",
      "Epoch 5::Minibatch 60::LR 0.0907692307692 --> Loss 0.00274816592534\n",
      "Epoch 5::Minibatch 61::LR 0.0907692307692 --> Loss 0.00142703682184\n",
      "Epoch 5::Minibatch 62::LR 0.0907692307692 --> Loss 0.00392514109612\n",
      "Epoch 5::Minibatch 63::LR 0.0907692307692 --> Loss 0.00258907417456\n",
      "Epoch 5::Minibatch 64::LR 0.0907692307692 --> Loss 0.00134282082319\n",
      "Epoch 5::Minibatch 65::LR 0.0907692307692 --> Loss 0.00260567227999\n",
      "Epoch 5::Minibatch 66::LR 0.0907692307692 --> Loss 0.00352273662885\n",
      "Epoch 5::Minibatch 67::LR 0.0907692307692 --> Loss 0.00315890749296\n",
      "Epoch 5::Minibatch 68::LR 0.0907692307692 --> Loss 0.00218460102876\n",
      "Epoch 5::Minibatch 69::LR 0.0907692307692 --> Loss 0.00386883616447\n",
      "Epoch 5::Minibatch 70::LR 0.0907692307692 --> Loss 0.00362413048744\n",
      "Epoch 5::Minibatch 71::LR 0.0907692307692 --> Loss 0.00266536494096\n",
      "Epoch 5::Minibatch 72::LR 0.0907692307692 --> Loss 0.000697425852219\n",
      "Epoch 5::Minibatch 73::LR 0.0907692307692 --> Loss 0.0038052157561\n",
      "Epoch 5::Minibatch 74::LR 0.0907692307692 --> Loss 0.00441905140877\n",
      "Epoch 5::Minibatch 75::LR 0.0907692307692 --> Loss 0.00233151316643\n",
      "Epoch 5::Minibatch 76::LR 0.0907692307692 --> Loss 0.000899796287219\n",
      "Epoch 5::Minibatch 77::LR 0.0907692307692 --> Loss 0.00483408768972\n",
      "Epoch 5::Minibatch 78::LR 0.0907692307692 --> Loss 0.00418375293414\n",
      "Epoch 5::Minibatch 79::LR 0.0907692307692 --> Loss 0.00236496726672\n",
      "Epoch 5::Minibatch 80::LR 0.0907692307692 --> Loss 0.003923869133\n",
      "Epoch 5::Minibatch 81::LR 0.0907692307692 --> Loss 0.00358777920405\n",
      "Epoch 5::Minibatch 82::LR 0.0907692307692 --> Loss 0.00227067053318\n",
      "Epoch 5::Minibatch 83::LR 0.0907692307692 --> Loss 0.00536769549052\n",
      "Epoch 5::Minibatch 84::LR 0.0907692307692 --> Loss 0.00240020851294\n",
      "Epoch 5::Minibatch 85::LR 0.0907692307692 --> Loss 0.00313245971998\n",
      "Epoch 5::Minibatch 86::LR 0.0907692307692 --> Loss 0.00274693310261\n",
      "Epoch 5::Minibatch 87::LR 0.0907692307692 --> Loss 0.00289317468802\n",
      "Epoch 5::Minibatch 88::LR 0.0907692307692 --> Loss 0.00227074325085\n",
      "Epoch 5::Minibatch 89::LR 0.0907692307692 --> Loss 0.00275168001652\n",
      "Epoch 5::Minibatch 90::LR 0.0907692307692 --> Loss 0.00149502505859\n",
      "Epoch 5::Minibatch 91::LR 0.0907692307692 --> Loss 0.00128679295381\n",
      "Epoch 5::Minibatch 92::LR 0.0907692307692 --> Loss 0.00279186507066\n",
      "Epoch 5::Minibatch 93::LR 0.0907692307692 --> Loss 0.00202771921953\n",
      "Epoch 5::Minibatch 94::LR 0.0907692307692 --> Loss 0.00195671041807\n",
      "Epoch 5::Minibatch 95::LR 0.0907692307692 --> Loss 0.00178189953168\n",
      "Epoch 5::Minibatch 96::LR 0.0907692307692 --> Loss 0.00642473657926\n",
      "Epoch 5::Minibatch 97::LR 0.0907692307692 --> Loss 0.00331915060679\n",
      "Epoch 5::Minibatch 98::LR 0.0907692307692 --> Loss 0.00102270921071\n",
      "Epoch 5::Minibatch 99::LR 0.0907692307692 --> Loss 0.00138949930668\n",
      "Epoch 5::Minibatch 100::LR 0.0907692307692 --> Loss 0.00589759627978\n",
      "Epoch 5::Minibatch 101::LR 0.0907692307692 --> Loss 0.0012294258674\n",
      "Epoch 5::Minibatch 102::LR 0.0907692307692 --> Loss 0.00370264490445\n",
      "Epoch 5::Minibatch 103::LR 0.0907692307692 --> Loss 0.00402143677076\n",
      "Epoch 5::Minibatch 104::LR 0.0907692307692 --> Loss 0.00311390141646\n",
      "Epoch 5::Minibatch 105::LR 0.0907692307692 --> Loss 0.0039463075002\n",
      "Epoch 5::Minibatch 106::LR 0.0907692307692 --> Loss 0.0182616869609\n",
      "Epoch 5::Minibatch 107::LR 0.0907692307692 --> Loss 0.00490486780802\n",
      "Epoch 5::Minibatch 108::LR 0.0907692307692 --> Loss 0.00151140391827\n",
      "Epoch 5::Minibatch 109::LR 0.0907692307692 --> Loss 0.00482086141904\n",
      "Epoch 5::Minibatch 110::LR 0.0907692307692 --> Loss 0.00293577730656\n",
      "Epoch 5::Minibatch 111::LR 0.0907692307692 --> Loss 0.00147997458776\n",
      "Epoch 5::Minibatch 112::LR 0.0907692307692 --> Loss 0.00413025736809\n",
      "Epoch 5::Minibatch 113::LR 0.0907692307692 --> Loss 0.00325752337774\n",
      "Epoch 5::Minibatch 114::LR 0.0907692307692 --> Loss 0.00193744301796\n",
      "Epoch 5::Minibatch 115::LR 0.0907692307692 --> Loss 0.00193439026674\n",
      "Epoch 5::Minibatch 116::LR 0.0907692307692 --> Loss 0.00329420546691\n",
      "Epoch 5::Minibatch 117::LR 0.0907692307692 --> Loss 0.00385560671488\n",
      "Epoch 5::Minibatch 118::LR 0.0907692307692 --> Loss 0.00689235846202\n",
      "Epoch 5::Minibatch 119::LR 0.0907692307692 --> Loss 0.00109472880761\n",
      "Epoch 5::Minibatch 120::LR 0.0907692307692 --> Loss 0.0024060189724\n",
      "Epoch 5::Minibatch 121::LR 0.0907692307692 --> Loss 0.00333654284477\n",
      "Epoch 5::Minibatch 122::LR 0.0907692307692 --> Loss 0.00381707390149\n",
      "Epoch 5::Minibatch 123::LR 0.0907692307692 --> Loss 0.0017692442735\n",
      "Epoch 5::Minibatch 124::LR 0.0907692307692 --> Loss 0.00321472247442\n",
      "Epoch 5::Minibatch 125::LR 0.0907692307692 --> Loss 0.00508605996768\n",
      "Epoch 5::Minibatch 126::LR 0.0907692307692 --> Loss 0.00338864525159\n",
      "Epoch 5::Minibatch 127::LR 0.0907692307692 --> Loss 0.00508673906326\n",
      "Epoch 5::Minibatch 128::LR 0.0907692307692 --> Loss 0.00397865891457\n",
      "Epoch 5::Minibatch 129::LR 0.0907692307692 --> Loss 0.00345000942548\n",
      "Epoch 5::Minibatch 130::LR 0.0907692307692 --> Loss 0.00463558554649\n",
      "Epoch 5::Minibatch 131::LR 0.0907692307692 --> Loss 0.00228103538354\n",
      "Epoch 5::Minibatch 132::LR 0.0907692307692 --> Loss 0.00367226560911\n",
      "Epoch 5::Minibatch 133::LR 0.0907692307692 --> Loss 0.00355755408605\n",
      "Epoch 5::Minibatch 134::LR 0.0907692307692 --> Loss 0.00302373607953\n",
      "Epoch 5::Minibatch 135::LR 0.0907692307692 --> Loss 0.00230247755845\n",
      "Epoch 5::Minibatch 136::LR 0.0907692307692 --> Loss 0.00310991366704\n",
      "Epoch 5::Minibatch 137::LR 0.0907692307692 --> Loss 0.00392612576485\n",
      "Epoch 5::Minibatch 138::LR 0.0907692307692 --> Loss 0.00169649243355\n",
      "Epoch 5::Minibatch 139::LR 0.0907692307692 --> Loss 0.00212662537893\n",
      "Epoch 5::Minibatch 140::LR 0.0907692307692 --> Loss 0.00266346593698\n",
      "Epoch 5::Minibatch 141::LR 0.0907692307692 --> Loss 0.00326570034027\n",
      "Epoch 5::Minibatch 142::LR 0.0907692307692 --> Loss 0.00344939112663\n",
      "Epoch 5::Minibatch 143::LR 0.0907692307692 --> Loss 0.000900154709816\n",
      "Epoch 5::Minibatch 144::LR 0.0907692307692 --> Loss 0.00318284293016\n",
      "Epoch 5::Minibatch 145::LR 0.0907692307692 --> Loss 0.00446136474609\n",
      "Epoch 5::Minibatch 146::LR 0.0907692307692 --> Loss 0.00301752169927\n",
      "Epoch 5::Minibatch 147::LR 0.0907692307692 --> Loss 0.0020362341404\n",
      "Epoch 5::Minibatch 148::LR 0.0907692307692 --> Loss 0.00133096367121\n",
      "Epoch 5::Minibatch 149::LR 0.0907692307692 --> Loss 0.00304884970188\n",
      "Epoch 5::Minibatch 150::LR 0.0907692307692 --> Loss 0.00311743736267\n",
      "Epoch 5::Minibatch 151::LR 0.0907692307692 --> Loss 0.00443936745326\n",
      "Epoch 5::Minibatch 152::LR 0.0907692307692 --> Loss 0.00112918237845\n",
      "Epoch 5::Minibatch 153::LR 0.0907692307692 --> Loss 0.00205993672212\n",
      "Epoch 5::Minibatch 154::LR 0.0907692307692 --> Loss 0.00231161316236\n",
      "Epoch 5::Minibatch 155::LR 0.0907692307692 --> Loss 0.00502454797427\n",
      "Epoch 5::Minibatch 156::LR 0.0907692307692 --> Loss 0.00264575441678\n",
      "Epoch 5::Minibatch 157::LR 0.0907692307692 --> Loss 0.000835797190666\n",
      "Epoch 5::Minibatch 158::LR 0.0907692307692 --> Loss 0.0031945892175\n",
      "Epoch 5::Minibatch 159::LR 0.0907692307692 --> Loss 0.00296702861786\n",
      "Epoch 5::Minibatch 160::LR 0.0907692307692 --> Loss 0.00290572067102\n",
      "Epoch 5::Minibatch 161::LR 0.0907692307692 --> Loss 0.00125479092201\n",
      "Epoch 5::Minibatch 162::LR 0.0907692307692 --> Loss 0.00360303640366\n",
      "Epoch 5::Minibatch 163::LR 0.0907692307692 --> Loss 0.00257744948069\n",
      "Epoch 5::Minibatch 164::LR 0.0907692307692 --> Loss 0.00262975553672\n",
      "Epoch 5::Minibatch 165::LR 0.0907692307692 --> Loss 0.000713010082642\n",
      "Epoch 5::Minibatch 166::LR 0.0907692307692 --> Loss 0.00201857089996\n",
      "Epoch 5::Minibatch 167::LR 0.0907692307692 --> Loss 0.00265175163746\n",
      "Epoch 5::Minibatch 168::LR 0.0907692307692 --> Loss 0.00243366976579\n",
      "Epoch 5::Minibatch 169::LR 0.0907692307692 --> Loss 0.00120735436678\n",
      "Epoch 5::Minibatch 170::LR 0.0907692307692 --> Loss 0.00111581077178\n",
      "Epoch 5::Minibatch 171::LR 0.0907692307692 --> Loss 0.00252057333787\n",
      "Epoch 5::Minibatch 172::LR 0.0907692307692 --> Loss 0.00530671199163\n",
      "Epoch 5::Minibatch 173::LR 0.0907692307692 --> Loss 0.00210489451885\n",
      "Epoch 5::Minibatch 174::LR 0.0907692307692 --> Loss 0.00119440774123\n",
      "Epoch 5::Minibatch 175::LR 0.0907692307692 --> Loss 0.00239664157232\n",
      "Epoch 5::Minibatch 176::LR 0.0907692307692 --> Loss 0.00358277877172\n",
      "Epoch 5::Minibatch 177::LR 0.0907692307692 --> Loss 0.00484480063121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 178::LR 0.0907692307692 --> Loss 0.00190311431885\n",
      "Epoch 5::Minibatch 179::LR 0.0907692307692 --> Loss 0.00152135123809\n",
      "Epoch 5::Minibatch 180::LR 0.0907692307692 --> Loss 0.00400529543559\n",
      "Epoch 5::Minibatch 181::LR 0.0907692307692 --> Loss 0.00373641888301\n",
      "Epoch 5::Minibatch 182::LR 0.0907692307692 --> Loss 0.00103496044874\n",
      "Epoch 5::Minibatch 183::LR 0.0907692307692 --> Loss 0.00184954027335\n",
      "Epoch 5::Minibatch 184::LR 0.0907692307692 --> Loss 0.00357441027959\n",
      "Epoch 5::Minibatch 185::LR 0.0907692307692 --> Loss 0.00306097726027\n",
      "Epoch 5::Minibatch 186::LR 0.0907692307692 --> Loss 0.00117546876272\n",
      "Epoch 5::Minibatch 187::LR 0.0907692307692 --> Loss 0.00141594032447\n",
      "Epoch 5::Minibatch 188::LR 0.0907692307692 --> Loss 0.00427991469701\n",
      "Epoch 5::Minibatch 189::LR 0.0907692307692 --> Loss 0.00474735021591\n",
      "Epoch 5::Minibatch 190::LR 0.0907692307692 --> Loss 0.00249103069305\n",
      "Epoch 5::Minibatch 191::LR 0.0907692307692 --> Loss 0.000694786558549\n",
      "Epoch 5::Minibatch 192::LR 0.0907692307692 --> Loss 0.00273893515269\n",
      "Epoch 5::Minibatch 193::LR 0.0907692307692 --> Loss 0.00253980656465\n",
      "Epoch 5::Minibatch 194::LR 0.0907692307692 --> Loss 0.0019822003444\n",
      "Epoch 5::Minibatch 195::LR 0.0907692307692 --> Loss 0.000495452235142\n",
      "Epoch 5::Minibatch 196::LR 0.0907692307692 --> Loss 0.00128487964471\n",
      "Epoch 5::Minibatch 197::LR 0.0907692307692 --> Loss 0.00284781813622\n",
      "Epoch 5::Minibatch 198::LR 0.0907692307692 --> Loss 0.00222311337789\n",
      "Epoch 5::Minibatch 199::LR 0.0907692307692 --> Loss 0.000381519074241\n",
      "Epoch 5::Minibatch 200::LR 0.0907692307692 --> Loss 0.0023100511233\n",
      "Epoch 5::Minibatch 201::LR 0.0907692307692 --> Loss 0.0023061833779\n",
      "Epoch 5::Minibatch 202::LR 0.0907692307692 --> Loss 0.00216989378134\n",
      "Epoch 5::Minibatch 203::LR 0.0907692307692 --> Loss 0.00211640556653\n",
      "Epoch 5::Minibatch 204::LR 0.0907692307692 --> Loss 0.00190276960532\n",
      "Epoch 5::Minibatch 205::LR 0.0907692307692 --> Loss 0.00254162867864\n",
      "Epoch 5::Minibatch 206::LR 0.0907692307692 --> Loss 0.00771432161331\n",
      "Epoch 5::Minibatch 207::LR 0.0907692307692 --> Loss 0.00166994512081\n",
      "Epoch 5::Minibatch 208::LR 0.0907692307692 --> Loss 0.00136807541053\n",
      "Epoch 5::Minibatch 209::LR 0.0907692307692 --> Loss 0.00225790003935\n",
      "Epoch 5::Minibatch 210::LR 0.0907692307692 --> Loss 0.00207805713018\n",
      "Epoch 5::Minibatch 211::LR 0.0907692307692 --> Loss 0.00213780204455\n",
      "Epoch 5::Minibatch 212::LR 0.0907692307692 --> Loss 0.00467293262482\n",
      "Epoch 5::Minibatch 213::LR 0.0907692307692 --> Loss 0.00621519049009\n",
      "Epoch 5::Minibatch 214::LR 0.0907692307692 --> Loss 0.0103214875857\n",
      "Epoch 5::Minibatch 215::LR 0.0907692307692 --> Loss 0.00163625548283\n",
      "Epoch 5::Minibatch 216::LR 0.0907692307692 --> Loss 0.00560903827349\n",
      "Epoch 5::Minibatch 217::LR 0.0907692307692 --> Loss 0.00573564529419\n",
      "Epoch 5::Minibatch 218::LR 0.0907692307692 --> Loss 0.00439425945282\n",
      "Epoch 5::Minibatch 219::LR 0.0907692307692 --> Loss 0.00343763669332\n",
      "Epoch 5::Minibatch 220::LR 0.0907692307692 --> Loss 0.00468344092369\n",
      "Epoch 5::Minibatch 221::LR 0.0907692307692 --> Loss 0.00449967344602\n",
      "Epoch 5::Minibatch 222::LR 0.0907692307692 --> Loss 0.00360147198041\n",
      "Epoch 5::Minibatch 223::LR 0.0907692307692 --> Loss 0.00163295497497\n",
      "Epoch 5::Minibatch 224::LR 0.0907692307692 --> Loss 0.00214537620544\n",
      "Epoch 5::Minibatch 225::LR 0.0907692307692 --> Loss 0.00659232099851\n",
      "Epoch 5::Minibatch 226::LR 0.0907692307692 --> Loss 0.00407560070356\n",
      "Epoch 5::Minibatch 227::LR 0.0907692307692 --> Loss 0.00193677504857\n",
      "Epoch 5::Minibatch 228::LR 0.0907692307692 --> Loss 0.00108145038287\n",
      "Epoch 5::Minibatch 229::LR 0.0907692307692 --> Loss 0.00502455314\n",
      "Epoch 5::Minibatch 230::LR 0.0907692307692 --> Loss 0.00434240261714\n",
      "Epoch 5::Minibatch 231::LR 0.0907692307692 --> Loss 0.00284271458785\n",
      "Epoch 5::Minibatch 232::LR 0.0907692307692 --> Loss 0.00156529595455\n",
      "Epoch 5::Minibatch 233::LR 0.0907692307692 --> Loss 0.00253669142723\n",
      "Epoch 5::Minibatch 234::LR 0.0907692307692 --> Loss 0.00639962395032\n",
      "Epoch 5::Minibatch 235::LR 0.0907692307692 --> Loss 0.00491736809413\n",
      "Epoch 5::Minibatch 236::LR 0.0907692307692 --> Loss 0.00199016948541\n",
      "Epoch 5::Minibatch 237::LR 0.0907692307692 --> Loss 0.000974162618319\n",
      "Epoch 5::Minibatch 238::LR 0.0907692307692 --> Loss 0.00355476061503\n",
      "Epoch 5::Minibatch 239::LR 0.0907692307692 --> Loss 0.00306431770325\n",
      "Epoch 5::Minibatch 240::LR 0.0907692307692 --> Loss 0.00329418957233\n",
      "Epoch 5::Minibatch 241::LR 0.0907692307692 --> Loss 0.000961368282636\n",
      "Epoch 5::Minibatch 242::LR 0.0907692307692 --> Loss 0.00727082490921\n",
      "Epoch 5::Minibatch 243::LR 0.0907692307692 --> Loss 0.00389489968618\n",
      "Epoch 5::Minibatch 244::LR 0.0907692307692 --> Loss 0.00325124959151\n",
      "Epoch 5::Minibatch 245::LR 0.0907692307692 --> Loss 0.000761640369892\n",
      "Epoch 5::Minibatch 246::LR 0.0907692307692 --> Loss 0.00242217620214\n",
      "Epoch 5::Minibatch 247::LR 0.0907692307692 --> Loss 0.0141170231501\n",
      "Epoch 5::Minibatch 248::LR 0.0907692307692 --> Loss 0.00481371919314\n",
      "Epoch 5::Minibatch 249::LR 0.0907692307692 --> Loss 0.00356008052826\n",
      "Epoch 5::Minibatch 250::LR 0.0907692307692 --> Loss 0.00350990335147\n",
      "Epoch 5::Minibatch 251::LR 0.0907692307692 --> Loss 0.00265316088994\n",
      "Epoch 5::Minibatch 252::LR 0.0907692307692 --> Loss 0.00212341984113\n",
      "Epoch 5::Minibatch 253::LR 0.0907692307692 --> Loss 0.00336527983348\n",
      "Epoch 5::Minibatch 254::LR 0.0907692307692 --> Loss 0.00577347517014\n",
      "Epoch 5::Minibatch 255::LR 0.0907692307692 --> Loss 0.00423171361287\n",
      "Epoch 5::Minibatch 256::LR 0.0907692307692 --> Loss 0.00215849320094\n",
      "Epoch 5::Minibatch 257::LR 0.0907692307692 --> Loss 0.0016800592343\n",
      "Epoch 5::Minibatch 258::LR 0.0907692307692 --> Loss 0.00377156058947\n",
      "Epoch 5::Minibatch 259::LR 0.0907692307692 --> Loss 0.00210431694984\n",
      "Epoch 5::Minibatch 260::LR 0.0907692307692 --> Loss 0.00207228422165\n",
      "Epoch 5::Minibatch 261::LR 0.0907692307692 --> Loss 0.00319882233938\n",
      "Epoch 5::Minibatch 262::LR 0.0907692307692 --> Loss 0.00220079382261\n",
      "Epoch 5::Minibatch 263::LR 0.0907692307692 --> Loss 0.00254805386066\n",
      "Epoch 5::Minibatch 264::LR 0.0907692307692 --> Loss 0.00381342331568\n",
      "Epoch 5::Minibatch 265::LR 0.0907692307692 --> Loss 0.00968379577001\n",
      "Epoch 5::Minibatch 266::LR 0.0907692307692 --> Loss 0.00134184787671\n",
      "Epoch 5::Minibatch 267::LR 0.0907692307692 --> Loss 0.0100864386559\n",
      "Epoch 5::Minibatch 268::LR 0.0907692307692 --> Loss 0.00160001267989\n",
      "Epoch 5::Minibatch 269::LR 0.0907692307692 --> Loss 0.00386010011037\n",
      "Epoch 5::Minibatch 270::LR 0.0907692307692 --> Loss 0.00630190889041\n",
      "Epoch 5::Minibatch 271::LR 0.0907692307692 --> Loss 0.00320006728172\n",
      "Epoch 5::Minibatch 272::LR 0.0907692307692 --> Loss 0.00412824630737\n",
      "Epoch 5::Minibatch 273::LR 0.0907692307692 --> Loss 0.00211110194524\n",
      "Epoch 5::Minibatch 274::LR 0.0907692307692 --> Loss 0.00209051907063\n",
      "Epoch 5::Minibatch 275::LR 0.0907692307692 --> Loss 0.0029912396272\n",
      "Epoch 5::Minibatch 276::LR 0.0907692307692 --> Loss 0.00362026453018\n",
      "Epoch 5::Minibatch 277::LR 0.0907692307692 --> Loss 0.00132984747489\n",
      "Epoch 5::Minibatch 278::LR 0.0907692307692 --> Loss 0.00280199229717\n",
      "Epoch 5::Minibatch 279::LR 0.0907692307692 --> Loss 0.00270297110081\n",
      "Epoch 5::Minibatch 280::LR 0.0907692307692 --> Loss 0.00239057938258\n",
      "Epoch 5::Minibatch 281::LR 0.0907692307692 --> Loss 0.00160798172156\n",
      "Epoch 5::Minibatch 282::LR 0.0907692307692 --> Loss 0.00239776015282\n",
      "Epoch 5::Minibatch 283::LR 0.0907692307692 --> Loss 0.00231549461683\n",
      "Epoch 5::Minibatch 284::LR 0.0907692307692 --> Loss 0.00188394169013\n",
      "Epoch 5::Minibatch 285::LR 0.0907692307692 --> Loss 0.00137444237868\n",
      "Epoch 5::Minibatch 286::LR 0.0907692307692 --> Loss 0.00222772777081\n",
      "Epoch 5::Minibatch 287::LR 0.0907692307692 --> Loss 0.00214420855045\n",
      "Epoch 5::Minibatch 288::LR 0.0907692307692 --> Loss 0.00121932059526\n",
      "Epoch 5::Minibatch 289::LR 0.0907692307692 --> Loss 0.00158396621545\n",
      "Epoch 5::Minibatch 290::LR 0.0907692307692 --> Loss 0.00198281665643\n",
      "Epoch 5::Minibatch 291::LR 0.0907692307692 --> Loss 0.00178708116213\n",
      "Epoch 5::Minibatch 292::LR 0.0907692307692 --> Loss 0.000723711848259\n",
      "Epoch 5::Minibatch 293::LR 0.0907692307692 --> Loss 0.00145441114902\n",
      "Epoch 5::Minibatch 294::LR 0.0907692307692 --> Loss 0.00161332617203\n",
      "Epoch 5::Minibatch 295::LR 0.0907692307692 --> Loss 0.0018069734176\n",
      "Epoch 5::Minibatch 296::LR 0.0907692307692 --> Loss 0.00156151235104\n",
      "Epoch 5::Minibatch 297::LR 0.0907692307692 --> Loss 0.00140555640062\n",
      "Epoch 5::Minibatch 298::LR 0.0907692307692 --> Loss 0.00137273689111\n",
      "Epoch 5::Minibatch 299::LR 0.0907692307692 --> Loss 0.000861490666866\n",
      "Epoch 5::Minibatch 300::LR 0.0907692307692 --> Loss 0.00313396771749\n",
      "Epoch 5::Minibatch 301::LR 0.0907692307692 --> Loss 0.00300116618474\n",
      "Epoch 5::Minibatch 302::LR 0.0907692307692 --> Loss 0.00269836684068\n",
      "Epoch 5::Minibatch 303::LR 0.0907692307692 --> Loss 0.00104525337617\n",
      "Epoch 5::Minibatch 304::LR 0.0907692307692 --> Loss 0.00339978933334\n",
      "Epoch 5::Minibatch 305::LR 0.0907692307692 --> Loss 0.00183488448461\n",
      "Epoch 5::Minibatch 306::LR 0.0907692307692 --> Loss 0.00109481980403\n",
      "Epoch 5::Minibatch 307::LR 0.0907692307692 --> Loss 0.00265526374181\n",
      "Epoch 5::Minibatch 308::LR 0.0907692307692 --> Loss 0.00210836629073\n",
      "Epoch 5::Minibatch 309::LR 0.0907692307692 --> Loss 0.0010671510299\n",
      "Epoch 5::Minibatch 310::LR 0.0907692307692 --> Loss 0.00109157095353\n",
      "Epoch 5::Minibatch 311::LR 0.0907692307692 --> Loss 0.00169858336449\n",
      "Epoch 5::Minibatch 312::LR 0.0907692307692 --> Loss 0.00324096719424\n",
      "Epoch 5::Minibatch 313::LR 0.0907692307692 --> Loss 0.00240828553836\n",
      "Epoch 5::Minibatch 314::LR 0.0907692307692 --> Loss 0.00200432777405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 315::LR 0.0907692307692 --> Loss 0.00109625995159\n",
      "Epoch 5::Minibatch 316::LR 0.0907692307692 --> Loss 0.00244963308175\n",
      "Epoch 5::Minibatch 317::LR 0.0907692307692 --> Loss 0.00173069775105\n",
      "Epoch 5::Minibatch 318::LR 0.0907692307692 --> Loss 0.00125963439544\n",
      "Epoch 5::Minibatch 319::LR 0.0907692307692 --> Loss 0.00236640652021\n",
      "Epoch 5::Minibatch 320::LR 0.0907692307692 --> Loss 0.0035135726134\n",
      "Epoch 5::Minibatch 321::LR 0.0907692307692 --> Loss 0.00103939563036\n",
      "Epoch 5::Minibatch 322::LR 0.0907692307692 --> Loss 0.00370573361715\n",
      "Epoch 5::Minibatch 323::LR 0.0907692307692 --> Loss 0.00363979538282\n",
      "Epoch 5::Minibatch 324::LR 0.0907692307692 --> Loss 0.00266393403212\n",
      "Epoch 5::Minibatch 325::LR 0.0907692307692 --> Loss 0.00255425353845\n",
      "Epoch 5::Minibatch 326::LR 0.0907692307692 --> Loss 0.00561387777328\n",
      "Epoch 5::Minibatch 327::LR 0.0907692307692 --> Loss 0.0024535048008\n",
      "Epoch 5::Minibatch 328::LR 0.0907692307692 --> Loss 0.00369935870171\n",
      "Epoch 5::Minibatch 329::LR 0.0907692307692 --> Loss 0.00135523329178\n",
      "Epoch 5::Minibatch 330::LR 0.0907692307692 --> Loss 0.00179007709026\n",
      "Epoch 5::Minibatch 331::LR 0.0907692307692 --> Loss 0.0027362459898\n",
      "Epoch 5::Minibatch 332::LR 0.0907692307692 --> Loss 0.00269029517968\n",
      "Epoch 5::Minibatch 333::LR 0.0907692307692 --> Loss 0.00162551313639\n",
      "Epoch 5::Minibatch 334::LR 0.0907692307692 --> Loss 0.00415289123853\n",
      "Epoch 5::Minibatch 335::LR 0.0907692307692 --> Loss 0.00203281899293\n",
      "Epoch 5::Minibatch 336::LR 0.0907692307692 --> Loss 0.00201277434826\n",
      "Epoch 5::Minibatch 337::LR 0.0907692307692 --> Loss 0.00325497865677\n",
      "Epoch 5::Minibatch 338::LR 0.0907692307692 --> Loss 0.000620902329683\n",
      "Epoch 5::Minibatch 339::LR 0.0907692307692 --> Loss 0.00329804857572\n",
      "Epoch 5::Minibatch 340::LR 0.0907692307692 --> Loss 0.0056518081824\n",
      "Epoch 5::Minibatch 341::LR 0.0907692307692 --> Loss 0.00506018320719\n",
      "Epoch 5::Minibatch 342::LR 0.0907692307692 --> Loss 0.00378456473351\n",
      "Epoch 5::Minibatch 343::LR 0.0907692307692 --> Loss 0.00205818990866\n",
      "Epoch 5::Minibatch 344::LR 0.0907692307692 --> Loss 0.00309007942677\n",
      "Epoch 5::Minibatch 345::LR 0.0907692307692 --> Loss 0.00456411361694\n",
      "Epoch 5::Minibatch 346::LR 0.0907692307692 --> Loss 0.00584634224574\n",
      "Epoch 5::Minibatch 347::LR 0.0907692307692 --> Loss 0.00115894864003\n",
      "Epoch 5::Minibatch 348::LR 0.0907692307692 --> Loss 0.00395971020063\n",
      "Epoch 5::Minibatch 349::LR 0.0907692307692 --> Loss 0.00366539319356\n",
      "Epoch 5::Minibatch 350::LR 0.0907692307692 --> Loss 0.00215773602327\n",
      "Epoch 5::Minibatch 351::LR 0.0907692307692 --> Loss 0.0038382089138\n",
      "Epoch 5::Minibatch 352::LR 0.0907692307692 --> Loss 0.00488925218582\n",
      "Epoch 5::Minibatch 353::LR 0.0907692307692 --> Loss 0.00367492636045\n",
      "Epoch 5::Minibatch 354::LR 0.0907692307692 --> Loss 0.00308103501797\n",
      "Epoch 5::Minibatch 355::LR 0.0907692307692 --> Loss 0.00628219803174\n",
      "Epoch 5::Minibatch 356::LR 0.0907692307692 --> Loss 0.00342298467954\n",
      "Epoch 5::Minibatch 357::LR 0.0907692307692 --> Loss 0.00142628232638\n",
      "Epoch 5::Minibatch 358::LR 0.0907692307692 --> Loss 0.00261175870895\n",
      "Epoch 5::Minibatch 359::LR 0.0907692307692 --> Loss 0.0029455602169\n",
      "Epoch 5::Minibatch 360::LR 0.0907692307692 --> Loss 0.00277582526207\n",
      "Epoch 5::Minibatch 361::LR 0.0907692307692 --> Loss 0.00262731949488\n",
      "Epoch 5::Minibatch 362::LR 0.0907692307692 --> Loss 0.00276729901632\n",
      "Epoch 5::Minibatch 363::LR 0.0907692307692 --> Loss 0.00081810683012\n",
      "Epoch 5::Minibatch 364::LR 0.0907692307692 --> Loss 0.00222496767839\n",
      "Epoch 5::Minibatch 365::LR 0.0907692307692 --> Loss 0.0023142149051\n",
      "Epoch 5::Minibatch 366::LR 0.0907692307692 --> Loss 0.00256392856439\n",
      "Epoch 5::Minibatch 367::LR 0.0907692307692 --> Loss 0.00125999093056\n",
      "Epoch 5::Minibatch 368::LR 0.0907692307692 --> Loss 0.00116917093595\n",
      "Epoch 5::Minibatch 369::LR 0.0907692307692 --> Loss 0.00306015054385\n",
      "Epoch 5::Minibatch 370::LR 0.0907692307692 --> Loss 0.00240523735682\n",
      "Epoch 5::Minibatch 371::LR 0.0907692307692 --> Loss 0.00201569298903\n",
      "Epoch 5::Minibatch 372::LR 0.0907692307692 --> Loss 0.000559210578601\n",
      "Epoch 5::Minibatch 373::LR 0.0907692307692 --> Loss 0.00187646766504\n",
      "Epoch 5::Minibatch 374::LR 0.0907692307692 --> Loss 0.0022290255626\n",
      "Epoch 5::Minibatch 375::LR 0.0907692307692 --> Loss 0.00195334931215\n",
      "Epoch 5::Minibatch 376::LR 0.0907692307692 --> Loss 0.0013337974747\n",
      "Epoch 5::Minibatch 377::LR 0.0907692307692 --> Loss 0.00212125182152\n",
      "Epoch 5::Minibatch 378::LR 0.0907692307692 --> Loss 0.00220968127251\n",
      "Epoch 5::Minibatch 379::LR 0.0907692307692 --> Loss 0.00250039696693\n",
      "Epoch 5::Minibatch 380::LR 0.0907692307692 --> Loss 0.00166736046473\n",
      "Epoch 5::Minibatch 381::LR 0.0907692307692 --> Loss 0.001116296947\n",
      "Epoch 5::Minibatch 382::LR 0.0907692307692 --> Loss 0.00215597470601\n",
      "Epoch 5::Minibatch 383::LR 0.0907692307692 --> Loss 0.00204314112663\n",
      "Epoch 5::Minibatch 384::LR 0.0907692307692 --> Loss 0.00115735659997\n",
      "Epoch 5::Minibatch 385::LR 0.0907692307692 --> Loss 0.00114317079385\n",
      "Epoch 5::Minibatch 386::LR 0.0907692307692 --> Loss 0.00232967674732\n",
      "Epoch 5::Minibatch 387::LR 0.0907692307692 --> Loss 0.00238794485728\n",
      "Epoch 5::Minibatch 388::LR 0.0907692307692 --> Loss 0.0011718138059\n",
      "Epoch 5::Minibatch 389::LR 0.0907692307692 --> Loss 0.00202938954035\n",
      "Epoch 5::Minibatch 390::LR 0.0907692307692 --> Loss 0.00432403087616\n",
      "Epoch 5::Minibatch 391::LR 0.0907692307692 --> Loss 0.0029890503486\n",
      "Epoch 5::Minibatch 392::LR 0.0907692307692 --> Loss 0.00297675828139\n",
      "Epoch 5::Minibatch 393::LR 0.0907692307692 --> Loss 0.00298196276029\n",
      "Epoch 5::Minibatch 394::LR 0.0907692307692 --> Loss 0.00240682880084\n",
      "Epoch 5::Minibatch 395::LR 0.0907692307692 --> Loss 0.00219617684682\n",
      "Epoch 5::Minibatch 396::LR 0.0907692307692 --> Loss 0.0021834452947\n",
      "Epoch 5::Minibatch 397::LR 0.0907692307692 --> Loss 0.0023199703296\n",
      "Epoch 5::Minibatch 398::LR 0.0907692307692 --> Loss 0.00226074755192\n",
      "Epoch 5::Minibatch 399::LR 0.0907692307692 --> Loss 0.00251812676589\n",
      "Epoch 5::Minibatch 400::LR 0.0907692307692 --> Loss 0.00222180167834\n",
      "Epoch 5::Minibatch 401::LR 0.0907692307692 --> Loss 0.00437382896741\n",
      "Epoch 5::Minibatch 402::LR 0.0907692307692 --> Loss 0.00226494948069\n",
      "Epoch 5::Minibatch 403::LR 0.0907692307692 --> Loss 0.00171634713809\n",
      "Epoch 5::Minibatch 404::LR 0.0907692307692 --> Loss 0.00182347893715\n",
      "Epoch 5::Minibatch 405::LR 0.0907692307692 --> Loss 0.00382341424624\n",
      "Epoch 5::Minibatch 406::LR 0.0907692307692 --> Loss 0.00268798828125\n",
      "Epoch 5::Minibatch 407::LR 0.0907692307692 --> Loss 0.00192296763261\n",
      "Epoch 5::Minibatch 408::LR 0.0907692307692 --> Loss 0.000670385360718\n",
      "Epoch 5::Minibatch 409::LR 0.0907692307692 --> Loss 0.00286830961704\n",
      "Epoch 5::Minibatch 410::LR 0.0907692307692 --> Loss 0.00370773553848\n",
      "Epoch 5::Minibatch 411::LR 0.0907692307692 --> Loss 0.00177227040132\n",
      "Epoch 5::Minibatch 412::LR 0.0907692307692 --> Loss 0.00110452204943\n",
      "Epoch 5::Minibatch 413::LR 0.0907692307692 --> Loss 0.00219975570838\n",
      "Epoch 5::Minibatch 414::LR 0.0907692307692 --> Loss 0.00179450631142\n",
      "Epoch 5::Minibatch 415::LR 0.0907692307692 --> Loss 0.00121334344149\n",
      "Epoch 5::Minibatch 416::LR 0.0907692307692 --> Loss 0.000943229496479\n",
      "Epoch 5::Minibatch 417::LR 0.0907692307692 --> Loss 0.00175734639168\n",
      "Epoch 5::Minibatch 418::LR 0.0907692307692 --> Loss 0.00324273784955\n",
      "Epoch 5::Minibatch 419::LR 0.0907692307692 --> Loss 0.000749478042126\n",
      "Epoch 5::Minibatch 420::LR 0.0907692307692 --> Loss 0.000939395725727\n",
      "Epoch 5::Minibatch 421::LR 0.0907692307692 --> Loss 0.0021691685915\n",
      "Epoch 5::Minibatch 422::LR 0.0907692307692 --> Loss 0.00251587867737\n",
      "Epoch 5::Minibatch 423::LR 0.0907692307692 --> Loss 0.00123311082522\n",
      "Epoch 5::Minibatch 424::LR 0.0907692307692 --> Loss 0.00182748695215\n",
      "Epoch 5::Minibatch 425::LR 0.0907692307692 --> Loss 0.00280712783337\n",
      "Epoch 5::Minibatch 426::LR 0.0907692307692 --> Loss 0.00215415974458\n",
      "Epoch 5::Minibatch 427::LR 0.0907692307692 --> Loss 0.000887463490168\n",
      "Epoch 5::Minibatch 428::LR 0.0907692307692 --> Loss 0.00142264256875\n",
      "Epoch 5::Minibatch 429::LR 0.0907692307692 --> Loss 0.00282566467921\n",
      "Epoch 5::Minibatch 430::LR 0.0907692307692 --> Loss 0.0101773913701\n",
      "Epoch 5::Minibatch 431::LR 0.0907692307692 --> Loss 0.00404338200887\n",
      "Epoch 5::Minibatch 432::LR 0.0907692307692 --> Loss 0.00472355326017\n",
      "Epoch 5::Minibatch 433::LR 0.0907692307692 --> Loss 0.00275477468967\n",
      "Epoch 5::Minibatch 434::LR 0.0907692307692 --> Loss 0.00273023962975\n",
      "Epoch 5::Minibatch 435::LR 0.0907692307692 --> Loss 0.00264751255512\n",
      "Epoch 5::Minibatch 436::LR 0.0907692307692 --> Loss 0.00203980843226\n",
      "Epoch 5::Minibatch 437::LR 0.0907692307692 --> Loss 0.00386478106181\n",
      "Epoch 5::Minibatch 438::LR 0.0907692307692 --> Loss 0.0029469615221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 439::LR 0.0907692307692 --> Loss 0.00239336470763\n",
      "Epoch 5::Minibatch 440::LR 0.0907692307692 --> Loss 0.003473341465\n",
      "Epoch 5::Minibatch 441::LR 0.0907692307692 --> Loss 0.00329339325428\n",
      "Epoch 5::Minibatch 442::LR 0.0907692307692 --> Loss 0.00316604455312\n",
      "Epoch 5::Minibatch 443::LR 0.0907692307692 --> Loss 0.00412840048472\n",
      "Epoch 5::Minibatch 444::LR 0.0907692307692 --> Loss 0.00295014222463\n",
      "Epoch 5::Minibatch 445::LR 0.0907692307692 --> Loss 0.000948725740115\n",
      "Epoch 5::Minibatch 446::LR 0.0907692307692 --> Loss 0.00167564789454\n",
      "Epoch 5::Minibatch 447::LR 0.0907692307692 --> Loss 0.00264825781186\n",
      "Epoch 5::Minibatch 448::LR 0.0907692307692 --> Loss 0.00260150651137\n",
      "Epoch 5::Minibatch 449::LR 0.0907692307692 --> Loss 0.0039700059096\n",
      "Epoch 5::Minibatch 450::LR 0.0907692307692 --> Loss 0.00267230888208\n",
      "Epoch 5::Minibatch 451::LR 0.0907692307692 --> Loss 0.00436757683754\n",
      "Epoch 5::Minibatch 452::LR 0.0907692307692 --> Loss 0.00253471354644\n",
      "Epoch 5::Minibatch 453::LR 0.0907692307692 --> Loss 0.00054970189929\n",
      "Epoch 5::Minibatch 454::LR 0.0907692307692 --> Loss 0.00422229210536\n",
      "Epoch 5::Minibatch 455::LR 0.0907692307692 --> Loss 0.00285719275475\n",
      "Epoch 5::Minibatch 456::LR 0.0907692307692 --> Loss 0.00340532183647\n",
      "Epoch 5::Minibatch 457::LR 0.0907692307692 --> Loss 0.00211902856827\n",
      "Epoch 5::Minibatch 458::LR 0.0907692307692 --> Loss 0.000948672393958\n",
      "Epoch 5::Minibatch 459::LR 0.0907692307692 --> Loss 0.00470375696818\n",
      "Epoch 5::Minibatch 460::LR 0.0907692307692 --> Loss 0.00303807238738\n",
      "Epoch 5::Minibatch 461::LR 0.0907692307692 --> Loss 0.004203962485\n",
      "Epoch 5::Minibatch 462::LR 0.0907692307692 --> Loss 0.000493905792634\n",
      "Epoch 5::Minibatch 463::LR 0.0907692307692 --> Loss 0.00528669238091\n",
      "Epoch 5::Minibatch 464::LR 0.0907692307692 --> Loss 0.00227815945943\n",
      "Epoch 5::Minibatch 465::LR 0.0907692307692 --> Loss 0.00616588155429\n",
      "Epoch 5::Minibatch 466::LR 0.0907692307692 --> Loss 0.0055423438549\n",
      "Epoch 5::Minibatch 467::LR 0.0907692307692 --> Loss 0.00705886522929\n",
      "Epoch 5::Minibatch 468::LR 0.0907692307692 --> Loss 0.00655711531639\n",
      "Epoch 5::Minibatch 469::LR 0.0907692307692 --> Loss 0.00686344941457\n",
      "Epoch 5::Minibatch 470::LR 0.0907692307692 --> Loss 0.00426718393962\n",
      "Epoch 5::Minibatch 471::LR 0.0907692307692 --> Loss 0.00220007856687\n",
      "Epoch 5::Minibatch 472::LR 0.0907692307692 --> Loss 0.00364650328954\n",
      "Epoch 5::Minibatch 473::LR 0.0907692307692 --> Loss 0.00220399240653\n",
      "Epoch 5::Minibatch 474::LR 0.0907692307692 --> Loss 0.000804369499286\n",
      "Epoch 5::Minibatch 475::LR 0.0907692307692 --> Loss 0.00710394144058\n",
      "Epoch 5::Minibatch 476::LR 0.0907692307692 --> Loss 0.00754508415858\n",
      "Epoch 5::Minibatch 477::LR 0.0907692307692 --> Loss 0.00104154497385\n",
      "Epoch 5::Minibatch 478::LR 0.0907692307692 --> Loss 0.00264928837617\n",
      "Epoch 5::Minibatch 479::LR 0.0907692307692 --> Loss 0.0020235401392\n",
      "Epoch 5::Minibatch 480::LR 0.0907692307692 --> Loss 0.00159780810277\n",
      "Epoch 5::Minibatch 481::LR 0.0907692307692 --> Loss 0.00104322920243\n",
      "Epoch 5::Minibatch 482::LR 0.0907692307692 --> Loss 0.00225259880225\n",
      "Epoch 5::Minibatch 483::LR 0.0907692307692 --> Loss 0.00370497663816\n",
      "Epoch 5::Minibatch 484::LR 0.0907692307692 --> Loss 0.00387227654457\n",
      "Epoch 5::Minibatch 485::LR 0.0907692307692 --> Loss 0.000843888223171\n",
      "Epoch 5::Minibatch 486::LR 0.0907692307692 --> Loss 0.00349736611048\n",
      "Epoch 5::Minibatch 487::LR 0.0907692307692 --> Loss 0.00381835063299\n",
      "Epoch 5::Minibatch 488::LR 0.0907692307692 --> Loss 0.00211099565029\n",
      "Epoch 5::Minibatch 489::LR 0.0907692307692 --> Loss 0.00339723706245\n",
      "Epoch 5::Minibatch 490::LR 0.0907692307692 --> Loss 0.000501380066077\n",
      "Epoch 5::Minibatch 491::LR 0.0907692307692 --> Loss 0.00498910983404\n",
      "Epoch 5::Minibatch 492::LR 0.0907692307692 --> Loss 0.00311753292878\n",
      "Epoch 5::Minibatch 493::LR 0.0907692307692 --> Loss 0.00326950748761\n",
      "Epoch 5::Minibatch 494::LR 0.0907692307692 --> Loss 0.000831273148457\n",
      "Epoch 5::Minibatch 495::LR 0.0907692307692 --> Loss 0.00205593168736\n",
      "Epoch 5::Minibatch 496::LR 0.0907692307692 --> Loss 0.00336844364802\n",
      "Epoch 5::Minibatch 497::LR 0.0907692307692 --> Loss 0.0010328428944\n",
      "Epoch 5::Minibatch 498::LR 0.0907692307692 --> Loss 0.000706512282292\n",
      "Epoch 5::Minibatch 499::LR 0.0907692307692 --> Loss 0.00432955304782\n",
      "Epoch 5::Minibatch 500::LR 0.0907692307692 --> Loss 0.00152375012636\n",
      "Epoch 5::Minibatch 501::LR 0.0907692307692 --> Loss 0.00227985878785\n",
      "Epoch 5::Minibatch 502::LR 0.0907692307692 --> Loss 0.00425167520841\n",
      "Epoch 5::Minibatch 503::LR 0.0907692307692 --> Loss 0.0115426969528\n",
      "Epoch 5::Minibatch 504::LR 0.0907692307692 --> Loss 0.0084099149704\n",
      "Epoch 5::Minibatch 505::LR 0.0907692307692 --> Loss 0.00481401165326\n",
      "Epoch 5::Minibatch 506::LR 0.0907692307692 --> Loss 0.00385007143021\n",
      "Epoch 5::Minibatch 507::LR 0.0907692307692 --> Loss 0.00620207905769\n",
      "Epoch 5::Minibatch 508::LR 0.0907692307692 --> Loss 0.00342977921168\n",
      "Epoch 5::Minibatch 509::LR 0.0907692307692 --> Loss 0.00483140269915\n",
      "Epoch 5::Minibatch 510::LR 0.0907692307692 --> Loss 0.00511429588\n",
      "Epoch 5::Minibatch 511::LR 0.0907692307692 --> Loss 0.00383859992027\n",
      "Epoch 5::Minibatch 512::LR 0.0907692307692 --> Loss 0.00282632271449\n",
      "Epoch 5::Minibatch 513::LR 0.0907692307692 --> Loss 0.000881580114365\n",
      "Epoch 5::Minibatch 514::LR 0.0907692307692 --> Loss 0.0028845234712\n",
      "Epoch 5::Minibatch 515::LR 0.0907692307692 --> Loss 0.00330300410589\n",
      "Epoch 5::Minibatch 516::LR 0.0907692307692 --> Loss 0.00454757928848\n",
      "Epoch 5::Minibatch 517::LR 0.0907692307692 --> Loss 0.00336052298546\n",
      "Epoch 5::Minibatch 518::LR 0.0907692307692 --> Loss 0.00263097206752\n",
      "Epoch 5::Minibatch 519::LR 0.0907692307692 --> Loss 0.00347237229347\n",
      "Epoch 5::Minibatch 520::LR 0.0907692307692 --> Loss 0.0056565952301\n",
      "Epoch 5::Minibatch 521::LR 0.0907692307692 --> Loss 0.00628171722094\n",
      "Epoch 5::Minibatch 522::LR 0.0907692307692 --> Loss 0.00815630435944\n",
      "Epoch 5::Minibatch 523::LR 0.0907692307692 --> Loss 0.000874546170235\n",
      "Epoch 5::Minibatch 524::LR 0.0907692307692 --> Loss 0.00155027280251\n",
      "Epoch 5::Minibatch 525::LR 0.0907692307692 --> Loss 0.00345348755519\n",
      "Epoch 5::Minibatch 526::LR 0.0907692307692 --> Loss 0.00452201048533\n",
      "Epoch 5::Minibatch 527::LR 0.0907692307692 --> Loss 0.00271939953168\n",
      "Epoch 5::Minibatch 528::LR 0.0907692307692 --> Loss 0.00156134366989\n",
      "Epoch 5::Minibatch 529::LR 0.0907692307692 --> Loss 0.00441759109497\n",
      "Epoch 5::Minibatch 530::LR 0.0907692307692 --> Loss 0.00466819405556\n",
      "Epoch 5::Minibatch 531::LR 0.0907692307692 --> Loss 0.00400470376015\n",
      "Epoch 5::Minibatch 532::LR 0.0907692307692 --> Loss 0.00290005326271\n",
      "Epoch 5::Minibatch 533::LR 0.0907692307692 --> Loss 0.00501194596291\n",
      "Epoch 5::Minibatch 534::LR 0.0907692307692 --> Loss 0.00409927487373\n",
      "Epoch 5::Minibatch 535::LR 0.0907692307692 --> Loss 0.00337045113246\n",
      "Epoch 5::Minibatch 536::LR 0.0907692307692 --> Loss 0.00228205343088\n",
      "Epoch 5::Minibatch 537::LR 0.0907692307692 --> Loss 0.000870417654514\n",
      "Epoch 5::Minibatch 538::LR 0.0907692307692 --> Loss 0.00186951716741\n",
      "Epoch 5::Minibatch 539::LR 0.0907692307692 --> Loss 0.0036085096995\n",
      "Epoch 5::Minibatch 540::LR 0.0907692307692 --> Loss 0.00351213335991\n",
      "Epoch 5::Minibatch 541::LR 0.0907692307692 --> Loss 0.00302220821381\n",
      "Epoch 5::Minibatch 542::LR 0.0907692307692 --> Loss 0.00278182824453\n",
      "Epoch 5::Minibatch 543::LR 0.0907692307692 --> Loss 0.00312073985736\n",
      "Epoch 5::Minibatch 544::LR 0.0907692307692 --> Loss 0.00420001665751\n",
      "Epoch 5::Minibatch 545::LR 0.0907692307692 --> Loss 0.00217084606489\n",
      "Epoch 5::Minibatch 546::LR 0.0907692307692 --> Loss 0.000797364662091\n",
      "Epoch 5::Minibatch 547::LR 0.0907692307692 --> Loss 0.0028077095747\n",
      "Epoch 5::Minibatch 548::LR 0.0907692307692 --> Loss 0.00439038674037\n",
      "Epoch 5::Minibatch 549::LR 0.0907692307692 --> Loss 0.0076756477356\n",
      "Epoch 5::Minibatch 550::LR 0.0907692307692 --> Loss 0.00125493546327\n",
      "Epoch 5::Minibatch 551::LR 0.0907692307692 --> Loss 0.00253679434458\n",
      "Epoch 5::Minibatch 552::LR 0.0907692307692 --> Loss 0.0039729642868\n",
      "Epoch 5::Minibatch 553::LR 0.0907692307692 --> Loss 0.00353076457977\n",
      "Epoch 5::Minibatch 554::LR 0.0907692307692 --> Loss 0.00409006873767\n",
      "Epoch 5::Minibatch 555::LR 0.0907692307692 --> Loss 0.00112867673238\n",
      "Epoch 5::Minibatch 556::LR 0.0907692307692 --> Loss 0.00226699570815\n",
      "Epoch 5::Minibatch 557::LR 0.0907692307692 --> Loss 0.0027167314291\n",
      "Epoch 5::Minibatch 558::LR 0.0907692307692 --> Loss 0.00409554123878\n",
      "Epoch 5::Minibatch 559::LR 0.0907692307692 --> Loss 0.0039324315389\n",
      "Epoch 5::Minibatch 560::LR 0.0907692307692 --> Loss 0.0034083378315\n",
      "Epoch 5::Minibatch 561::LR 0.0907692307692 --> Loss 0.00305582622687\n",
      "Epoch 5::Minibatch 562::LR 0.0907692307692 --> Loss 0.00256355305513\n",
      "Epoch 5::Minibatch 563::LR 0.0907692307692 --> Loss 0.0043063322703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 564::LR 0.0907692307692 --> Loss 0.00331905623277\n",
      "Epoch 5::Minibatch 565::LR 0.0907692307692 --> Loss 0.00405975143115\n",
      "Epoch 5::Minibatch 566::LR 0.0907692307692 --> Loss 0.00254059652487\n",
      "Epoch 5::Minibatch 567::LR 0.0907692307692 --> Loss 0.00293316543102\n",
      "Epoch 5::Minibatch 568::LR 0.0907692307692 --> Loss 0.0020039220651\n",
      "Epoch 5::Minibatch 569::LR 0.0907692307692 --> Loss 0.000687893877427\n",
      "Epoch 5::Minibatch 570::LR 0.0907692307692 --> Loss 0.00197199702263\n",
      "Epoch 5::Minibatch 571::LR 0.0907692307692 --> Loss 0.00259141425292\n",
      "Epoch 5::Minibatch 572::LR 0.0907692307692 --> Loss 0.00268148163954\n",
      "Epoch 5::Minibatch 573::LR 0.0907692307692 --> Loss 0.00165701935689\n",
      "Epoch 5::Minibatch 574::LR 0.0907692307692 --> Loss 0.00113808015982\n",
      "Epoch 5::Minibatch 575::LR 0.0907692307692 --> Loss 0.0020211883386\n",
      "Epoch 5::Minibatch 576::LR 0.0907692307692 --> Loss 0.00241423388322\n",
      "Epoch 5::Minibatch 577::LR 0.0907692307692 --> Loss 0.00187842567762\n",
      "Epoch 5::Minibatch 578::LR 0.0907692307692 --> Loss 0.00140386790037\n",
      "Epoch 5::Minibatch 579::LR 0.0907692307692 --> Loss 0.00132135490576\n",
      "Epoch 5::Minibatch 580::LR 0.0907692307692 --> Loss 0.00217711965243\n",
      "Epoch 5::Minibatch 581::LR 0.0907692307692 --> Loss 0.00186088959376\n",
      "Epoch 5::Minibatch 582::LR 0.0907692307692 --> Loss 0.00435757915179\n",
      "Epoch 5::Minibatch 583::LR 0.0907692307692 --> Loss 0.00103962918123\n",
      "Epoch 5::Minibatch 584::LR 0.0907692307692 --> Loss 0.00142043729623\n",
      "Epoch 5::Minibatch 585::LR 0.0907692307692 --> Loss 0.00640500426292\n",
      "Epoch 5::Minibatch 586::LR 0.0907692307692 --> Loss 0.00459158937136\n",
      "Epoch 5::Minibatch 587::LR 0.0907692307692 --> Loss 0.00125949203968\n",
      "Epoch 5::Minibatch 588::LR 0.0907692307692 --> Loss 0.00158637563388\n",
      "Epoch 5::Minibatch 589::LR 0.0907692307692 --> Loss 0.00296830236912\n",
      "Epoch 5::Minibatch 590::LR 0.0907692307692 --> Loss 0.00235494772593\n",
      "Epoch 5::Minibatch 591::LR 0.0907692307692 --> Loss 0.00433632254601\n",
      "Epoch 5::Minibatch 592::LR 0.0907692307692 --> Loss 0.00132085015376\n",
      "Epoch 5::Minibatch 593::LR 0.0907692307692 --> Loss 0.00278315107028\n",
      "Epoch 5::Minibatch 594::LR 0.0907692307692 --> Loss 0.00319991568724\n",
      "Epoch 5::Minibatch 595::LR 0.0907692307692 --> Loss 0.00319804032644\n",
      "Epoch 5::Minibatch 596::LR 0.0907692307692 --> Loss 0.00228254020214\n",
      "Epoch 5::Minibatch 597::LR 0.0907692307692 --> Loss 0.00139044175545\n",
      "Epoch 5::Minibatch 598::LR 0.0907692307692 --> Loss 0.00355041861534\n",
      "Epoch 5::Minibatch 599::LR 0.0907692307692 --> Loss 0.00208961149057\n",
      "Epoch 5::Minibatch 600::LR 0.0907692307692 --> Loss 0.00254951337973\n",
      "Epoch 5::Minibatch 601::LR 0.0907692307692 --> Loss 0.00389937480291\n",
      "Epoch 5::Minibatch 602::LR 0.0907692307692 --> Loss 0.00222782512506\n",
      "Epoch 5::Minibatch 603::LR 0.0907692307692 --> Loss 0.00298247595628\n",
      "Epoch 5::Minibatch 604::LR 0.0907692307692 --> Loss 0.00181740780671\n",
      "Epoch 5::Minibatch 605::LR 0.0907692307692 --> Loss 0.00271882931391\n",
      "Epoch 5::Minibatch 606::LR 0.0907692307692 --> Loss 0.00216389099757\n",
      "Epoch 5::Minibatch 607::LR 0.0907692307692 --> Loss 0.00093827098608\n",
      "Epoch 5::Minibatch 608::LR 0.0907692307692 --> Loss 0.00185715079308\n",
      "Epoch 5::Minibatch 609::LR 0.0907692307692 --> Loss 0.00247517685095\n",
      "Epoch 5::Minibatch 610::LR 0.0907692307692 --> Loss 0.00397062381109\n",
      "Epoch 5::Minibatch 611::LR 0.0907692307692 --> Loss 0.00274443546931\n",
      "Epoch 5::Minibatch 612::LR 0.0907692307692 --> Loss 0.00065489222606\n",
      "Epoch 5::Minibatch 613::LR 0.0907692307692 --> Loss 0.00151977767547\n",
      "Epoch 5::Minibatch 614::LR 0.0907692307692 --> Loss 0.00271497865518\n",
      "Epoch 5::Minibatch 615::LR 0.0907692307692 --> Loss 0.00187917729219\n",
      "Epoch 5::Minibatch 616::LR 0.0907692307692 --> Loss 0.00104086200396\n",
      "Epoch 5::Minibatch 617::LR 0.0907692307692 --> Loss 0.000638100902239\n",
      "Epoch 5::Minibatch 618::LR 0.0907692307692 --> Loss 0.0027383718888\n",
      "Epoch 5::Minibatch 619::LR 0.0907692307692 --> Loss 0.00209124624729\n",
      "Epoch 5::Minibatch 620::LR 0.0907692307692 --> Loss 0.00185278495153\n",
      "Epoch 5::Minibatch 621::LR 0.0907692307692 --> Loss 0.000950276752313\n",
      "Epoch 5::Minibatch 622::LR 0.0907692307692 --> Loss 0.000938317974408\n",
      "Epoch 5::Minibatch 623::LR 0.0907692307692 --> Loss 0.00232864816984\n",
      "Epoch 5::Minibatch 624::LR 0.0907692307692 --> Loss 0.00196782390277\n",
      "Epoch 5::Minibatch 625::LR 0.0907692307692 --> Loss 0.00359842975934\n",
      "Epoch 5::Minibatch 626::LR 0.0907692307692 --> Loss 0.00523414452871\n",
      "Epoch 5::Minibatch 627::LR 0.0907692307692 --> Loss 0.0015935832262\n",
      "Epoch 5::Minibatch 628::LR 0.0907692307692 --> Loss 0.00110954642296\n",
      "Epoch 5::Minibatch 629::LR 0.0907692307692 --> Loss 0.00378189007441\n",
      "Epoch 5::Minibatch 630::LR 0.0907692307692 --> Loss 0.00360289216042\n",
      "Epoch 5::Minibatch 631::LR 0.0907692307692 --> Loss 0.00668296337128\n",
      "Epoch 5::Minibatch 632::LR 0.0907692307692 --> Loss 0.00101677417755\n",
      "Epoch 5::Minibatch 633::LR 0.0907692307692 --> Loss 0.00189514557521\n",
      "Epoch 5::Minibatch 634::LR 0.0907692307692 --> Loss 0.00346633474032\n",
      "Epoch 5::Minibatch 635::LR 0.0907692307692 --> Loss 0.00520773212115\n",
      "Epoch 5::Minibatch 636::LR 0.0907692307692 --> Loss 0.00618689020475\n",
      "Epoch 5::Minibatch 637::LR 0.0907692307692 --> Loss 0.00125132600466\n",
      "Epoch 5::Minibatch 638::LR 0.0907692307692 --> Loss 0.00193853894869\n",
      "Epoch 5::Minibatch 639::LR 0.0907692307692 --> Loss 0.00364503423373\n",
      "Epoch 5::Minibatch 640::LR 0.0907692307692 --> Loss 0.00537633697192\n",
      "Epoch 5::Minibatch 641::LR 0.0907692307692 --> Loss 0.00349054217339\n",
      "Epoch 5::Minibatch 642::LR 0.0907692307692 --> Loss 0.000770802746216\n",
      "Epoch 5::Minibatch 643::LR 0.0907692307692 --> Loss 0.00253209650517\n",
      "Epoch 5::Minibatch 644::LR 0.0907692307692 --> Loss 0.00425657113393\n",
      "Epoch 5::Minibatch 645::LR 0.0907692307692 --> Loss 0.00461332519849\n",
      "Epoch 5::Minibatch 646::LR 0.0907692307692 --> Loss 0.00182457288106\n",
      "Epoch 5::Minibatch 647::LR 0.0907692307692 --> Loss 0.000956134299437\n",
      "Epoch 5::Minibatch 648::LR 0.0907692307692 --> Loss 0.00341545701027\n",
      "Epoch 5::Minibatch 649::LR 0.0907692307692 --> Loss 0.00394887367884\n",
      "Epoch 5::Minibatch 650::LR 0.0907692307692 --> Loss 0.00364827553431\n",
      "Epoch 5::Minibatch 651::LR 0.0907692307692 --> Loss 0.00169229626656\n",
      "Epoch 5::Minibatch 652::LR 0.0907692307692 --> Loss 0.0011812188228\n",
      "Epoch 5::Minibatch 653::LR 0.0907692307692 --> Loss 0.00317455351353\n",
      "Epoch 5::Minibatch 654::LR 0.0907692307692 --> Loss 0.003314640522\n",
      "Epoch 5::Minibatch 655::LR 0.0907692307692 --> Loss 0.00359275221825\n",
      "Epoch 5::Minibatch 656::LR 0.0907692307692 --> Loss 0.000956895649433\n",
      "Epoch 5::Minibatch 657::LR 0.0907692307692 --> Loss 0.0022943653663\n",
      "Epoch 5::Minibatch 658::LR 0.0907692307692 --> Loss 0.00515715837479\n",
      "Epoch 5::Minibatch 659::LR 0.0907692307692 --> Loss 0.00252187669277\n",
      "Epoch 5::Minibatch 660::LR 0.0907692307692 --> Loss 0.00264614284039\n",
      "Epoch 5::Minibatch 661::LR 0.0907692307692 --> Loss 0.00276851673921\n",
      "Epoch 5::Minibatch 662::LR 0.0907692307692 --> Loss 0.00199849863847\n",
      "Epoch 5::Minibatch 663::LR 0.0907692307692 --> Loss 0.00387886842092\n",
      "Epoch 5::Minibatch 664::LR 0.0907692307692 --> Loss 0.00375989079475\n",
      "Epoch 5::Minibatch 665::LR 0.0907692307692 --> Loss 0.0010104538997\n",
      "Epoch 5::Minibatch 666::LR 0.0907692307692 --> Loss 0.00404044071833\n",
      "Epoch 5::Minibatch 667::LR 0.0907692307692 --> Loss 0.0027960763375\n",
      "Epoch 5::Minibatch 668::LR 0.0907692307692 --> Loss 0.00760715564092\n",
      "Epoch 5::Minibatch 669::LR 0.0907692307692 --> Loss 0.00126039663951\n",
      "Epoch 5::Minibatch 670::LR 0.0907692307692 --> Loss 0.001548277239\n",
      "Epoch 5::Minibatch 671::LR 0.0907692307692 --> Loss 0.00577847282092\n",
      "Epoch 5::Minibatch 672::LR 0.0907692307692 --> Loss 0.00438497026761\n",
      "Epoch 5::Minibatch 673::LR 0.0907692307692 --> Loss 0.00180092473825\n",
      "Epoch 5::Minibatch 674::LR 0.0907692307692 --> Loss 0.000718173285325\n",
      "Epoch 5::Minibatch 675::LR 0.0907692307692 --> Loss 0.00243188540141\n",
      "Epoch 5::Minibatch 676::LR 0.0907692307692 --> Loss 0.00240371247133\n",
      "Epoch 5::Minibatch 677::LR 0.0907692307692 --> Loss 0.00316570003827\n",
      "Epoch 5::Minibatch 678::LR 0.0907692307692 --> Loss 0.00215500811736\n",
      "Epoch 5::Minibatch 679::LR 0.0907692307692 --> Loss 0.00382068157196\n",
      "Epoch 5::Minibatch 680::LR 0.0907692307692 --> Loss 0.00233135223389\n",
      "Epoch 5::Minibatch 681::LR 0.0907692307692 --> Loss 0.00259170432885\n",
      "Epoch 5::Minibatch 682::LR 0.0907692307692 --> Loss 0.000906289120515\n",
      "Epoch 5::Minibatch 683::LR 0.0907692307692 --> Loss 0.00261071761449\n",
      "Epoch 5::Minibatch 684::LR 0.0907692307692 --> Loss 0.00254249254862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 685::LR 0.0907692307692 --> Loss 0.00316087881724\n",
      "Epoch 5::Minibatch 686::LR 0.0907692307692 --> Loss 0.00162349253893\n",
      "Epoch 5::Minibatch 687::LR 0.0907692307692 --> Loss 0.000952207545439\n",
      "Epoch 5::Minibatch 688::LR 0.0907692307692 --> Loss 0.00285605589549\n",
      "Epoch 5::Minibatch 689::LR 0.0907692307692 --> Loss 0.00272745708625\n",
      "Epoch 5::Minibatch 690::LR 0.0907692307692 --> Loss 0.0020545532306\n",
      "Epoch 5::Minibatch 691::LR 0.0907692307692 --> Loss 0.000770580718915\n",
      "Epoch 5::Minibatch 692::LR 0.0907692307692 --> Loss 0.00265809734662\n",
      "Epoch 5::Minibatch 693::LR 0.0907692307692 --> Loss 0.0027361836036\n",
      "Epoch 5::Minibatch 694::LR 0.0907692307692 --> Loss 0.00316616733869\n",
      "Epoch 5::Minibatch 695::LR 0.0907692307692 --> Loss 0.00189447681109\n",
      "Epoch 5::Minibatch 696::LR 0.0907692307692 --> Loss 0.00209776739279\n",
      "Epoch 5::Minibatch 697::LR 0.0907692307692 --> Loss 0.00150534023841\n",
      "Epoch 5::Minibatch 698::LR 0.0907692307692 --> Loss 0.00169436415037\n",
      "Epoch 5::Minibatch 699::LR 0.0907692307692 --> Loss 0.00402525305748\n",
      "Epoch 5::Minibatch 700::LR 0.0907692307692 --> Loss 0.00281454642614\n",
      "Epoch 5::Minibatch 701::LR 0.0907692307692 --> Loss 0.00218248764674\n",
      "Epoch 5::Minibatch 702::LR 0.0907692307692 --> Loss 0.00183804591497\n",
      "Epoch 5::Minibatch 703::LR 0.0907692307692 --> Loss 0.00419714728991\n",
      "Epoch 5::Minibatch 704::LR 0.0907692307692 --> Loss 0.00192155698935\n",
      "Epoch 5::Minibatch 705::LR 0.0907692307692 --> Loss 0.00290652831395\n",
      "Epoch 5::Minibatch 706::LR 0.0907692307692 --> Loss 0.00224625150363\n",
      "Epoch 5::Minibatch 707::LR 0.0907692307692 --> Loss 0.00133110135794\n",
      "Epoch 5::Minibatch 708::LR 0.0907692307692 --> Loss 0.00185362120469\n",
      "Epoch 5::Minibatch 709::LR 0.0907692307692 --> Loss 0.00187037825584\n",
      "Epoch 5::Minibatch 710::LR 0.0907692307692 --> Loss 0.00252278705438\n",
      "Epoch 5::Minibatch 711::LR 0.0907692307692 --> Loss 0.00195742706458\n",
      "Epoch 5::Minibatch 712::LR 0.0907692307692 --> Loss 0.00145933419466\n",
      "Epoch 5::Minibatch 713::LR 0.0907692307692 --> Loss 0.00183043877284\n",
      "Epoch 5::Minibatch 714::LR 0.0907692307692 --> Loss 0.00275730590026\n",
      "Epoch 5::Minibatch 715::LR 0.0907692307692 --> Loss 0.00301623980204\n",
      "Epoch 5::Minibatch 716::LR 0.0907692307692 --> Loss 0.00168883184592\n",
      "Epoch 5::Minibatch 717::LR 0.0907692307692 --> Loss 0.0017069230477\n",
      "Epoch 5::Minibatch 718::LR 0.0907692307692 --> Loss 0.00139980902274\n",
      "Epoch 5::Minibatch 719::LR 0.0907692307692 --> Loss 0.00179037014643\n",
      "Epoch 5::Minibatch 720::LR 0.0907692307692 --> Loss 0.00249124010404\n",
      "Epoch 5::Minibatch 721::LR 0.0907692307692 --> Loss 0.000783248295387\n",
      "Epoch 5::Minibatch 722::LR 0.0907692307692 --> Loss 0.00510576923688\n",
      "Epoch 5::Minibatch 723::LR 0.0907692307692 --> Loss 0.00492153922717\n",
      "Epoch 5::Minibatch 724::LR 0.0907692307692 --> Loss 0.00112160732349\n",
      "Epoch 5::Minibatch 725::LR 0.0907692307692 --> Loss 0.00250274380048\n",
      "Epoch 5::Minibatch 726::LR 0.0907692307692 --> Loss 0.0053260076046\n",
      "Epoch 5::Minibatch 727::LR 0.0907692307692 --> Loss 0.00306171655655\n",
      "Epoch 5::Minibatch 728::LR 0.0907692307692 --> Loss 0.000804396867752\n",
      "Epoch 5::Minibatch 729::LR 0.0907692307692 --> Loss 0.000962242881457\n",
      "Epoch 5::Minibatch 730::LR 0.0907692307692 --> Loss 0.00268916745981\n",
      "Epoch 5::Minibatch 731::LR 0.0907692307692 --> Loss 0.00256836374601\n",
      "Epoch 5::Minibatch 732::LR 0.0907692307692 --> Loss 0.00253999153773\n",
      "Epoch 5::Minibatch 733::LR 0.0907692307692 --> Loss 0.000972619752089\n",
      "Epoch 5::Minibatch 734::LR 0.0907692307692 --> Loss 0.0020497806867\n",
      "Epoch 5::Minibatch 735::LR 0.0907692307692 --> Loss 0.00251551747322\n",
      "Epoch 5::Minibatch 736::LR 0.0907692307692 --> Loss 0.00354929685593\n",
      "Epoch 5::Minibatch 737::LR 0.0907692307692 --> Loss 0.00328612764676\n",
      "Epoch 5::Minibatch 738::LR 0.0907692307692 --> Loss 0.00187754531701\n",
      "Epoch 5::Minibatch 739::LR 0.0907692307692 --> Loss 0.00262593269348\n",
      "Epoch 5::Minibatch 740::LR 0.0907692307692 --> Loss 0.00389044920603\n",
      "Epoch 5::Minibatch 741::LR 0.0907692307692 --> Loss 0.00296638766925\n",
      "Epoch 5::Minibatch 742::LR 0.0907692307692 --> Loss 0.0022915093104\n",
      "Epoch 5::Minibatch 743::LR 0.0907692307692 --> Loss 0.00138890574376\n",
      "Epoch 5::Minibatch 744::LR 0.0907692307692 --> Loss 0.00193406085173\n",
      "Epoch 5::Minibatch 745::LR 0.0907692307692 --> Loss 0.00297410110633\n",
      "Epoch 5::Minibatch 746::LR 0.0907692307692 --> Loss 0.00320254643758\n",
      "Epoch 5::Minibatch 747::LR 0.0907692307692 --> Loss 0.00187869330247\n",
      "Epoch 5::Minibatch 748::LR 0.0907692307692 --> Loss 0.000788207898537\n",
      "Epoch 5::Minibatch 749::LR 0.0907692307692 --> Loss 0.00178189297517\n",
      "Epoch 5::Minibatch 750::LR 0.0907692307692 --> Loss 0.00260590732098\n",
      "Epoch 5::Minibatch 751::LR 0.0907692307692 --> Loss 0.00275601367156\n",
      "Epoch 5::Minibatch 752::LR 0.0907692307692 --> Loss 0.00113986472289\n",
      "Epoch 5::Minibatch 753::LR 0.0907692307692 --> Loss 0.00238383948803\n",
      "Epoch 5::Minibatch 754::LR 0.0907692307692 --> Loss 0.00246054550012\n",
      "Epoch 5::Minibatch 755::LR 0.0907692307692 --> Loss 0.00275104085604\n",
      "Epoch 5::Minibatch 756::LR 0.0907692307692 --> Loss 0.00156239082416\n",
      "Epoch 5::Minibatch 757::LR 0.0907692307692 --> Loss 0.00106454948584\n",
      "Epoch 5::Minibatch 758::LR 0.0907692307692 --> Loss 0.0017578736941\n",
      "Epoch 5::Minibatch 759::LR 0.0907692307692 --> Loss 0.00399751941363\n",
      "Epoch 5::Minibatch 760::LR 0.0907692307692 --> Loss 0.003276095589\n",
      "Epoch 5::Minibatch 761::LR 0.0907692307692 --> Loss 0.00648680925369\n",
      "Epoch 5::Minibatch 762::LR 0.0907692307692 --> Loss 0.00396876653035\n",
      "Epoch 5::Minibatch 763::LR 0.0907692307692 --> Loss 0.00390347321828\n",
      "Epoch 5::Minibatch 764::LR 0.0907692307692 --> Loss 0.00344973285993\n",
      "Epoch 5::Minibatch 765::LR 0.0907692307692 --> Loss 0.00148638089498\n",
      "Epoch 5::Minibatch 766::LR 0.0907692307692 --> Loss 0.00234711666902\n",
      "Epoch 5::Minibatch 767::LR 0.0907692307692 --> Loss 0.00509737650553\n",
      "Epoch 5::Minibatch 768::LR 0.0907692307692 --> Loss 0.00357839226723\n",
      "Epoch 5::Minibatch 769::LR 0.0907692307692 --> Loss 0.00209635118643\n",
      "Epoch 5::Minibatch 770::LR 0.0907692307692 --> Loss 0.00156773597002\n",
      "Epoch 5::Minibatch 771::LR 0.0907692307692 --> Loss 0.00394565343857\n",
      "Epoch 5::Minibatch 772::LR 0.0907692307692 --> Loss 0.00339781204859\n",
      "Epoch 5::Minibatch 773::LR 0.0907692307692 --> Loss 0.00333496809006\n",
      "Epoch 5::Minibatch 774::LR 0.0907692307692 --> Loss 0.00183889230092\n",
      "Epoch 5::Minibatch 775::LR 0.0907692307692 --> Loss 0.00490085999171\n",
      "Epoch 5::Minibatch 776::LR 0.0907692307692 --> Loss 0.00369556307793\n",
      "Epoch 5::Minibatch 777::LR 0.0907692307692 --> Loss 0.00800100803375\n",
      "Epoch 5::Minibatch 778::LR 0.0907692307692 --> Loss 0.0120198512077\n",
      "Epoch 5::Minibatch 779::LR 0.0907692307692 --> Loss 0.00162914971511\n",
      "Epoch 5::Minibatch 780::LR 0.0907692307692 --> Loss 0.00182974457741\n",
      "Epoch 5::Minibatch 781::LR 0.0907692307692 --> Loss 0.00385482589404\n",
      "Epoch 5::Minibatch 782::LR 0.0907692307692 --> Loss 0.00447445273399\n",
      "Epoch 5::Minibatch 783::LR 0.0907692307692 --> Loss 0.00254954953988\n",
      "Epoch 5::Minibatch 784::LR 0.0907692307692 --> Loss 0.000910865167777\n",
      "Epoch 5::Minibatch 785::LR 0.0907692307692 --> Loss 0.0046146261692\n",
      "Epoch 5::Minibatch 786::LR 0.0907692307692 --> Loss 0.00404652674993\n",
      "Epoch 5::Minibatch 787::LR 0.0907692307692 --> Loss 0.00320091962814\n",
      "Epoch 5::Minibatch 788::LR 0.0907692307692 --> Loss 0.0028167583545\n",
      "Epoch 5::Minibatch 789::LR 0.0907692307692 --> Loss 0.000874399244785\n",
      "Epoch 5::Minibatch 790::LR 0.0907692307692 --> Loss 0.00353687604268\n",
      "Epoch 5::Minibatch 791::LR 0.0907692307692 --> Loss 0.00425229628881\n",
      "Epoch 5::Minibatch 792::LR 0.0907692307692 --> Loss 0.00409495751063\n",
      "Epoch 5::Minibatch 793::LR 0.0907692307692 --> Loss 0.00244790971279\n",
      "Epoch 5::Minibatch 794::LR 0.0907692307692 --> Loss 0.00144411375125\n",
      "Epoch 5::Minibatch 795::LR 0.0907692307692 --> Loss 0.00390624483426\n",
      "Epoch 5::Minibatch 796::LR 0.0907692307692 --> Loss 0.006547224919\n",
      "Epoch 5::Minibatch 797::LR 0.0907692307692 --> Loss 0.009293217659\n",
      "Epoch 5::Minibatch 798::LR 0.0907692307692 --> Loss 0.0037470304966\n",
      "Epoch 5::Minibatch 799::LR 0.0907692307692 --> Loss 0.00307865719\n",
      "Epoch 5::Minibatch 800::LR 0.0907692307692 --> Loss 0.00234284579754\n",
      "Epoch 5::Minibatch 801::LR 0.0907692307692 --> Loss 0.00436037460963\n",
      "Epoch 5::Minibatch 802::LR 0.0907692307692 --> Loss 0.00162987023592\n",
      "Epoch 5::Minibatch 803::LR 0.0907692307692 --> Loss 0.00285142163436\n",
      "Epoch 5::Minibatch 804::LR 0.0907692307692 --> Loss 0.00257375379403\n",
      "Epoch 5::Minibatch 805::LR 0.0907692307692 --> Loss 0.0025595698754\n",
      "Epoch 5::Minibatch 806::LR 0.0907692307692 --> Loss 0.00346247235934\n",
      "Epoch 5::Minibatch 807::LR 0.0907692307692 --> Loss 0.0033149522543\n",
      "Epoch 5::Minibatch 808::LR 0.0907692307692 --> Loss 0.00322305401166\n",
      "Epoch 5::Minibatch 809::LR 0.0907692307692 --> Loss 0.00499958475431\n",
      "Epoch 5::Minibatch 810::LR 0.0907692307692 --> Loss 0.00603682597478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 811::LR 0.0907692307692 --> Loss 0.00559528628985\n",
      "Epoch 5::Minibatch 812::LR 0.0907692307692 --> Loss 0.00564634839694\n",
      "Epoch 5::Minibatch 813::LR 0.0907692307692 --> Loss 0.00539357185364\n",
      "Epoch 5::Minibatch 814::LR 0.0907692307692 --> Loss 0.00278515775998\n",
      "Epoch 5::Minibatch 815::LR 0.0907692307692 --> Loss 0.00471202731133\n",
      "Epoch 5::Minibatch 816::LR 0.0907692307692 --> Loss 0.0046232175827\n",
      "Epoch 5::Minibatch 817::LR 0.0907692307692 --> Loss 0.00515428543091\n",
      "Epoch 5::Minibatch 818::LR 0.0907692307692 --> Loss 0.00167493204276\n",
      "Epoch 5::Minibatch 819::LR 0.0907692307692 --> Loss 0.000988062918186\n",
      "Epoch 5::Minibatch 820::LR 0.0907692307692 --> Loss 0.00580408891042\n",
      "Epoch 5::Minibatch 821::LR 0.0907692307692 --> Loss 0.00355995734533\n",
      "Epoch 5::Minibatch 822::LR 0.0907692307692 --> Loss 0.00427270094554\n",
      "Epoch 5::Minibatch 823::LR 0.0907692307692 --> Loss 0.00150394529104\n",
      "Epoch 5::Minibatch 824::LR 0.0907692307692 --> Loss 0.0016333608826\n",
      "Epoch 5::Minibatch 825::LR 0.0907692307692 --> Loss 0.00403503855069\n",
      "Epoch 5::Minibatch 826::LR 0.0907692307692 --> Loss 0.00397349397341\n",
      "Epoch 5::Minibatch 827::LR 0.0907692307692 --> Loss 0.00256609459718\n",
      "Epoch 5::Minibatch 828::LR 0.0907692307692 --> Loss 0.000951955914497\n",
      "Epoch 5::Minibatch 829::LR 0.0907692307692 --> Loss 0.00268798450629\n",
      "Epoch 5::Minibatch 830::LR 0.0907692307692 --> Loss 0.00473092635473\n",
      "Epoch 5::Minibatch 831::LR 0.0907692307692 --> Loss 0.00277228653431\n",
      "Epoch 5::Minibatch 832::LR 0.0907692307692 --> Loss 0.00250272154808\n",
      "Epoch 5::Minibatch 833::LR 0.0907692307692 --> Loss 0.00198044558366\n",
      "Epoch 5::Minibatch 834::LR 0.0907692307692 --> Loss 0.000911809603373\n",
      "Epoch 5::Minibatch 835::LR 0.0907692307692 --> Loss 0.00397589723269\n",
      "Epoch 5::Minibatch 836::LR 0.0907692307692 --> Loss 0.00405461629232\n",
      "Epoch 5::Minibatch 837::LR 0.0907692307692 --> Loss 0.00266275326411\n",
      "Epoch 5::Minibatch 838::LR 0.0907692307692 --> Loss 0.000872208575408\n",
      "Epoch 5::Minibatch 839::LR 0.0907692307692 --> Loss 0.00263552367687\n",
      "Epoch 5::Minibatch 840::LR 0.0907692307692 --> Loss 0.00322925686836\n",
      "Epoch 5::Minibatch 841::LR 0.0907692307692 --> Loss 0.00331650952498\n",
      "Epoch 5::Minibatch 842::LR 0.0907692307692 --> Loss 0.00248186647892\n",
      "Epoch 5::Minibatch 843::LR 0.0907692307692 --> Loss 0.00116212924321\n",
      "Epoch 5::Minibatch 844::LR 0.0907692307692 --> Loss 0.00173807382584\n",
      "Epoch 5::Minibatch 845::LR 0.0907692307692 --> Loss 0.00456472714742\n",
      "Epoch 5::Minibatch 846::LR 0.0907692307692 --> Loss 0.00188495139281\n",
      "Epoch 5::Minibatch 847::LR 0.0907692307692 --> Loss 0.0027187838157\n",
      "Epoch 5::Minibatch 848::LR 0.0907692307692 --> Loss 0.00121747583151\n",
      "Epoch 5::Minibatch 849::LR 0.0907692307692 --> Loss 0.00208891073863\n",
      "Epoch 5::Minibatch 850::LR 0.0907692307692 --> Loss 0.00336912234624\n",
      "Epoch 5::Minibatch 851::LR 0.0907692307692 --> Loss 0.00307285388311\n",
      "Epoch 5::Minibatch 852::LR 0.0907692307692 --> Loss 0.00124045322339\n",
      "Epoch 5::Minibatch 853::LR 0.0907692307692 --> Loss 0.00148034006357\n",
      "Epoch 5::Minibatch 854::LR 0.0907692307692 --> Loss 0.00264151354631\n",
      "Epoch 5::Minibatch 855::LR 0.0907692307692 --> Loss 0.00233513991038\n",
      "Epoch 5::Minibatch 856::LR 0.0907692307692 --> Loss 0.0019193516175\n",
      "Epoch 5::Minibatch 857::LR 0.0907692307692 --> Loss 0.00132162183523\n",
      "Epoch 5::Minibatch 858::LR 0.0907692307692 --> Loss 0.000733172843854\n",
      "Epoch 5::Minibatch 859::LR 0.0907692307692 --> Loss 0.00196480413278\n",
      "Epoch 5::Minibatch 860::LR 0.0907692307692 --> Loss 0.00129538933436\n",
      "Epoch 5::Minibatch 861::LR 0.0907692307692 --> Loss 0.00103201011817\n",
      "Epoch 5::Minibatch 862::LR 0.0907692307692 --> Loss 0.00374112645785\n",
      "Epoch 5::Minibatch 863::LR 0.0907692307692 --> Loss 0.00346880356471\n",
      "Epoch 5::Minibatch 864::LR 0.0907692307692 --> Loss 0.00328259368738\n",
      "Epoch 5::Minibatch 865::LR 0.0907692307692 --> Loss 0.000659381846587\n",
      "Epoch 5::Minibatch 866::LR 0.0907692307692 --> Loss 0.0023666503032\n",
      "Epoch 5::Minibatch 867::LR 0.0907692307692 --> Loss 0.00320551852385\n",
      "Epoch 5::Minibatch 868::LR 0.0907692307692 --> Loss 0.00278376360734\n",
      "Epoch 5::Minibatch 869::LR 0.0907692307692 --> Loss 0.00220250407855\n",
      "Epoch 5::Minibatch 870::LR 0.0907692307692 --> Loss 0.00389116843541\n",
      "Epoch 5::Minibatch 871::LR 0.0907692307692 --> Loss 0.00165436049302\n",
      "Epoch 5::Minibatch 872::LR 0.0907692307692 --> Loss 0.00253338356813\n",
      "Epoch 5::Minibatch 873::LR 0.0907692307692 --> Loss 0.00266104161739\n",
      "Epoch 5::Minibatch 874::LR 0.0907692307692 --> Loss 0.00649553736051\n",
      "Epoch 5::Minibatch 875::LR 0.0907692307692 --> Loss 0.000618393371503\n",
      "Epoch 5::Minibatch 876::LR 0.0907692307692 --> Loss 0.00407240986824\n",
      "Epoch 5::Minibatch 877::LR 0.0907692307692 --> Loss 0.00582403699557\n",
      "Epoch 5::Minibatch 878::LR 0.0907692307692 --> Loss 0.00360417167346\n",
      "Epoch 5::Minibatch 879::LR 0.0907692307692 --> Loss 0.00403198043505\n",
      "Epoch 5::Minibatch 880::LR 0.0907692307692 --> Loss 0.00469108899434\n",
      "Epoch 5::Minibatch 881::LR 0.0907692307692 --> Loss 0.00421866138776\n",
      "Epoch 5::Minibatch 882::LR 0.0907692307692 --> Loss 0.00216279109319\n",
      "Epoch 5::Minibatch 883::LR 0.0907692307692 --> Loss 0.00337326129278\n",
      "Epoch 5::Minibatch 884::LR 0.0907692307692 --> Loss 0.0027685970068\n",
      "Epoch 5::Minibatch 885::LR 0.0907692307692 --> Loss 0.00259323557218\n",
      "Epoch 5::Minibatch 886::LR 0.0907692307692 --> Loss 0.000864129960537\n",
      "Epoch 5::Minibatch 887::LR 0.0907692307692 --> Loss 0.00558351119359\n",
      "Epoch 5::Minibatch 888::LR 0.0907692307692 --> Loss 0.00280482788881\n",
      "Epoch 5::Minibatch 889::LR 0.0907692307692 --> Loss 0.0035824962457\n",
      "Epoch 5::Minibatch 890::LR 0.0907692307692 --> Loss 0.00472103397051\n",
      "Epoch 5::Minibatch 891::LR 0.0907692307692 --> Loss 0.00232334434986\n",
      "Epoch 5::Minibatch 892::LR 0.0907692307692 --> Loss 0.00115467399359\n",
      "Epoch 5::Minibatch 893::LR 0.0907692307692 --> Loss 0.00280537386735\n",
      "Epoch 5::Minibatch 894::LR 0.0907692307692 --> Loss 0.00257264415423\n",
      "Epoch 5::Minibatch 895::LR 0.0907692307692 --> Loss 0.00267086128394\n",
      "Epoch 5::Minibatch 896::LR 0.0907692307692 --> Loss 0.00161023000876\n",
      "Epoch 5::Minibatch 897::LR 0.0907692307692 --> Loss 0.00094458570083\n",
      "Epoch 5::Minibatch 898::LR 0.0907692307692 --> Loss 0.00242422262828\n",
      "Epoch 5::Minibatch 899::LR 0.0907692307692 --> Loss 0.00261243561904\n",
      "Epoch 5::Minibatch 900::LR 0.0907692307692 --> Loss 0.003478906552\n",
      "Epoch 5::Minibatch 901::LR 0.0907692307692 --> Loss 0.000756483227015\n",
      "Epoch 5::Minibatch 902::LR 0.0907692307692 --> Loss 0.00154873033365\n",
      "Epoch 5::Minibatch 903::LR 0.0907692307692 --> Loss 0.00278776844343\n",
      "Epoch 5::Minibatch 904::LR 0.0907692307692 --> Loss 0.00234310626984\n",
      "Epoch 5::Minibatch 905::LR 0.0907692307692 --> Loss 0.00156232545773\n",
      "Epoch 5::Minibatch 906::LR 0.0907692307692 --> Loss 0.00121885408958\n",
      "Epoch 5::Minibatch 907::LR 0.0907692307692 --> Loss 0.00162430951993\n",
      "Epoch 5::Minibatch 908::LR 0.0907692307692 --> Loss 0.00254605770111\n",
      "Epoch 5::Minibatch 909::LR 0.0907692307692 --> Loss 0.00223905245463\n",
      "Epoch 5::Minibatch 910::LR 0.0907692307692 --> Loss 0.000919824441274\n",
      "Epoch 5::Minibatch 911::LR 0.0907692307692 --> Loss 0.00130959123373\n",
      "Epoch 5::Minibatch 912::LR 0.0907692307692 --> Loss 0.00216176946958\n",
      "Epoch 5::Minibatch 913::LR 0.0907692307692 --> Loss 0.00220015108585\n",
      "Epoch 5::Minibatch 914::LR 0.0907692307692 --> Loss 0.00128318389257\n",
      "Epoch 5::Minibatch 915::LR 0.0907692307692 --> Loss 0.000575680335363\n",
      "Epoch 5::Minibatch 916::LR 0.0907692307692 --> Loss 0.00268240094185\n",
      "Epoch 5::Minibatch 917::LR 0.0907692307692 --> Loss 0.00418045560519\n",
      "Epoch 5::Minibatch 918::LR 0.0907692307692 --> Loss 0.00616131385167\n",
      "Epoch 5::Minibatch 919::LR 0.0907692307692 --> Loss 0.000930629769961\n",
      "Epoch 5::Minibatch 920::LR 0.0907692307692 --> Loss 0.00920546690623\n",
      "Epoch 5::Minibatch 921::LR 0.0907692307692 --> Loss 0.00313269754251\n",
      "Epoch 5::Minibatch 922::LR 0.0907692307692 --> Loss 0.00325934350491\n",
      "Epoch 5::Minibatch 923::LR 0.0907692307692 --> Loss 0.00183341125647\n",
      "Epoch 5::Minibatch 924::LR 0.0907692307692 --> Loss 0.00363723715146\n",
      "Epoch 5::Minibatch 925::LR 0.0907692307692 --> Loss 0.00324408511321\n",
      "Epoch 5::Minibatch 926::LR 0.0907692307692 --> Loss 0.00566503167152\n",
      "Epoch 5::Minibatch 927::LR 0.0907692307692 --> Loss 0.00904066403707\n",
      "Epoch 5::Minibatch 928::LR 0.0907692307692 --> Loss 0.0068800330162\n",
      "Epoch 5::Minibatch 929::LR 0.0907692307692 --> Loss 0.0103742249807\n",
      "Epoch 5::Minibatch 930::LR 0.0907692307692 --> Loss 0.0114124655724\n",
      "Epoch 5::Minibatch 931::LR 0.0907692307692 --> Loss 0.00448762059212\n",
      "Epoch 5::Minibatch 932::LR 0.0907692307692 --> Loss 0.0100719825427\n",
      "Epoch 5::Minibatch 933::LR 0.0907692307692 --> Loss 0.00558693567912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5::Minibatch 934::LR 0.0907692307692 --> Loss 0.0072722419103\n",
      "Epoch 5::Minibatch 935::LR 0.0907692307692 --> Loss 0.00890496810277\n",
      "Epoch 5::Minibatch 936::LR 0.0907692307692 --> Loss 0.00307309309642\n",
      "Epoch 5::Minibatch 937::LR 0.0907692307692 --> Loss 0.0053246541818\n",
      "Epoch 5::Minibatch 938::LR 0.0907692307692 --> Loss 0.00521948536237\n",
      "Epoch 5::Minibatch 939::LR 0.0907692307692 --> Loss 0.00527733961741\n",
      "Epoch 5::Minibatch 940::LR 0.0907692307692 --> Loss 0.00156081457933\n",
      "Epoch 5::Minibatch 941::LR 0.0907692307692 --> Loss 0.0013074996074\n",
      "Epoch 5::Minibatch 942::LR 0.0907692307692 --> Loss 0.00277018129826\n",
      "Epoch 5::Minibatch 943::LR 0.0907692307692 --> Loss 0.0043273683389\n",
      "Epoch 5::Minibatch 944::LR 0.0907692307692 --> Loss 0.0034784690539\n",
      "Epoch 5::Minibatch 945::LR 0.0907692307692 --> Loss 0.00231558322906\n",
      "Epoch 5::Minibatch 946::LR 0.0907692307692 --> Loss 0.0047104259332\n",
      "Epoch 5::Minibatch 947::LR 0.0907692307692 --> Loss 0.00414746324221\n",
      "Epoch 5::Minibatch 948::LR 0.0907692307692 --> Loss 0.00663080255191\n",
      "Epoch 5::Minibatch 949::LR 0.0907692307692 --> Loss 0.0024037583669\n",
      "Epoch 5::Minibatch 950::LR 0.0907692307692 --> Loss 0.000915081004302\n",
      "Epoch 5::Minibatch 951::LR 0.0907692307692 --> Loss 0.00365327914556\n",
      "Epoch 5::Minibatch 952::LR 0.0907692307692 --> Loss 0.00288000424703\n",
      "Epoch 5::Minibatch 953::LR 0.0907692307692 --> Loss 0.00152296334505\n",
      "Epoch 5::Minibatch 954::LR 0.0907692307692 --> Loss 0.00112190425396\n",
      "Epoch 5::Minibatch 955::LR 0.0907692307692 --> Loss 0.00275420804818\n",
      "Epoch 5::Minibatch 956::LR 0.0907692307692 --> Loss 0.0051718711853\n",
      "Epoch 5::Minibatch 957::LR 0.0907692307692 --> Loss 0.00229120274385\n",
      "Epoch 5::Minibatch 958::LR 0.0907692307692 --> Loss 0.00326841096083\n",
      "Epoch 5::Minibatch 959::LR 0.0907692307692 --> Loss 0.00393544395765\n",
      "Epoch 5::Minibatch 960::LR 0.0907692307692 --> Loss 0.00762700557709\n",
      "Epoch 5::Minibatch 961::LR 0.0907692307692 --> Loss 0.00405765453974\n",
      "Epoch 5::Minibatch 962::LR 0.0907692307692 --> Loss 0.00364981174469\n",
      "Epoch 5::Minibatch 963::LR 0.0907692307692 --> Loss 0.00169990619024\n",
      "Epoch 5::Minibatch 964::LR 0.0907692307692 --> Loss 0.00308673560619\n",
      "Epoch 5::Minibatch 965::LR 0.0907692307692 --> Loss 0.00824218273163\n",
      "Epoch 5::Minibatch 966::LR 0.0907692307692 --> Loss 0.0055995508035\n",
      "Epoch 5::Minibatch 967::LR 0.0907692307692 --> Loss 0.00240886072318\n",
      "Epoch 5::Minibatch 968::LR 0.0907692307692 --> Loss 0.00210843861103\n",
      "Epoch 5::Minibatch 969::LR 0.0907692307692 --> Loss 0.00829764048258\n",
      "Epoch 5::Minibatch 970::LR 0.0907692307692 --> Loss 0.00642828861872\n",
      "Epoch 5::Minibatch 971::LR 0.0907692307692 --> Loss 0.00383424719175\n",
      "Epoch 5::Minibatch 972::LR 0.0907692307692 --> Loss 0.00804749409358\n",
      "Epoch 5::Minibatch 973::LR 0.0907692307692 --> Loss 0.00970274448395\n",
      "Epoch 5::Minibatch 974::LR 0.0907692307692 --> Loss 0.00637518127759\n",
      "Epoch 5::Minibatch 975::LR 0.0907692307692 --> Loss 0.00508581002553\n",
      "Epoch 5::Minibatch 976::LR 0.0907692307692 --> Loss 0.00454504330953\n",
      "Epoch 5::Minibatch 977::LR 0.0907692307692 --> Loss 0.00462651968002\n",
      "Epoch 5::Minibatch 978::LR 0.0907692307692 --> Loss 0.00453175266584\n",
      "Epoch 5::Minibatch 979::LR 0.0907692307692 --> Loss 0.00456011652946\n",
      "Epoch 5::Minibatch 980::LR 0.0907692307692 --> Loss 0.00413961450259\n",
      "Epoch 5::Minibatch 981::LR 0.0907692307692 --> Loss 0.00550973852475\n",
      "Epoch 5::Minibatch 982::LR 0.0907692307692 --> Loss 0.00792862733205\n",
      "Epoch 5::Minibatch 983::LR 0.0907692307692 --> Loss 0.00347532073657\n",
      "Epoch 5::Minibatch 984::LR 0.0907692307692 --> Loss 0.00348379850388\n",
      "Epoch 5::Minibatch 985::LR 0.0907692307692 --> Loss 0.00502818862597\n",
      "Epoch 5::Minibatch 986::LR 0.0907692307692 --> Loss 0.0045410879453\n",
      "Epoch 5::Minibatch 987::LR 0.0907692307692 --> Loss 0.00497030377388\n",
      "Epoch 5::Minibatch 988::LR 0.0907692307692 --> Loss 0.00384039402008\n",
      "Epoch 5::Minibatch 989::LR 0.0907692307692 --> Loss 0.00368848164876\n",
      "Epoch 5::Minibatch 990::LR 0.0907692307692 --> Loss 0.00377032717069\n",
      "Epoch 5::Minibatch 991::LR 0.0907692307692 --> Loss 0.00207196911176\n",
      "Epoch 5::Minibatch 992::LR 0.0907692307692 --> Loss 0.00233755668004\n",
      "Epoch 5::Minibatch 993::LR 0.0907692307692 --> Loss 0.00368496656418\n",
      "Epoch 5::Minibatch 994::LR 0.0907692307692 --> Loss 0.00230457246304\n",
      "Epoch 5::Minibatch 995::LR 0.0907692307692 --> Loss 0.00104208439589\n",
      "Epoch 5::Minibatch 996::LR 0.0907692307692 --> Loss 0.00366639415423\n",
      "Epoch 5::Minibatch 997::LR 0.0907692307692 --> Loss 0.00216803948085\n",
      "Epoch 5::Minibatch 998::LR 0.0907692307692 --> Loss 0.00236481348674\n",
      "Epoch 5::Minibatch 999::LR 0.0907692307692 --> Loss 0.00196712692579\n",
      "Epoch 5::Minibatch 1000::LR 0.0907692307692 --> Loss 0.00226796746254\n",
      "Epoch 5::Minibatch 1001::LR 0.0907692307692 --> Loss 0.00194997727871\n",
      "Epoch 5::Minibatch 1002::LR 0.0907692307692 --> Loss 0.0051629670461\n",
      "Epoch 5::Minibatch 1003::LR 0.0907692307692 --> Loss 0.00502035895983\n",
      "Epoch 5::Minibatch 1004::LR 0.0907692307692 --> Loss 0.00118043889602\n",
      "Epoch 5::Minibatch 1005::LR 0.0907692307692 --> Loss 0.00593009630839\n",
      "Epoch 5::Minibatch 1006::LR 0.0907692307692 --> Loss 0.00455395142237\n",
      "Epoch 5::Minibatch 1007::LR 0.0907692307692 --> Loss 0.00388050357501\n",
      "Epoch 5::Minibatch 1008::LR 0.0907692307692 --> Loss 0.00108012984196\n",
      "Epoch 5::Minibatch 1009::LR 0.0907692307692 --> Loss 0.00256075243155\n",
      "Epoch 5::Minibatch 1010::LR 0.0907692307692 --> Loss 0.00231349309285\n",
      "Epoch 5::Minibatch 1011::LR 0.0907692307692 --> Loss 0.00397846738497\n",
      "Epoch 5::Minibatch 1012::LR 0.0907692307692 --> Loss 0.00245711624622\n",
      "Epoch 5::Minibatch 1013::LR 0.0907692307692 --> Loss 0.00486233592033\n",
      "Epoch 5::Minibatch 1014::LR 0.0907692307692 --> Loss 0.00484707474709\n",
      "Epoch 5::Minibatch 1015::LR 0.0907692307692 --> Loss 0.0020981268088\n",
      "Epoch 5::Minibatch 1016::LR 0.0907692307692 --> Loss 0.00568360249201\n",
      "Epoch 5::Minibatch 1017::LR 0.0907692307692 --> Loss 0.00353488524755\n",
      "Epoch 5::Minibatch 1018::LR 0.0907692307692 --> Loss 0.00374336242676\n",
      "Epoch 5::Minibatch 1019::LR 0.0907692307692 --> Loss 0.00301956892014\n",
      "Epoch 5::Minibatch 1020::LR 0.0907692307692 --> Loss 0.00286054054896\n",
      "Epoch 5::Minibatch 1021::LR 0.0907692307692 --> Loss 0.00259873867035\n",
      "Epoch 5::Minibatch 1022::LR 0.0907692307692 --> Loss 0.00210104048252\n",
      "Epoch 5::Minibatch 1023::LR 0.0907692307692 --> Loss 0.00184453924497\n",
      "Epoch 5::Minibatch 1024::LR 0.0907692307692 --> Loss 0.00173598666986\n",
      "Epoch 5::Minibatch 1025::LR 0.0907692307692 --> Loss 0.00178770621618\n",
      "Epoch 5::Minibatch 1026::LR 0.0907692307692 --> Loss 0.00136932343245\n",
      "Epoch 5::Minibatch 1027::LR 0.0907692307692 --> Loss 0.00134791692098\n",
      "Epoch 5::Minibatch 1028::LR 0.0907692307692 --> Loss 0.00109714021285\n",
      "Epoch 5::Minibatch 1029::LR 0.0907692307692 --> Loss 0.000977010726929\n",
      "Epoch 5::Minibatch 1030::LR 0.0907692307692 --> Loss 0.00117997457584\n",
      "Epoch 5::Minibatch 1031::LR 0.0907692307692 --> Loss 0.000896430710951\n",
      "Epoch 5::Minibatch 1032::LR 0.0907692307692 --> Loss 0.000855982204278\n",
      "Epoch 5::Minibatch 1033::LR 0.0907692307692 --> Loss 0.000718882083893\n",
      "Epoch 5::Minibatch 1034::LR 0.0907692307692 --> Loss 0.000791464348634\n",
      "Epoch 5::Minibatch 1035::LR 0.0907692307692 --> Loss 0.000725335478783\n",
      "Epoch 5::Minibatch 1036::LR 0.0907692307692 --> Loss 0.000559758494298\n",
      "Epoch 5::Minibatch 1037::LR 0.0907692307692 --> Loss 0.000600489725669\n",
      "Epoch 5::Minibatch 1038::LR 0.0907692307692 --> Loss 0.00138284951448\n",
      "Epoch 5::Minibatch 1039::LR 0.0907692307692 --> Loss 0.001231110394\n",
      "Epoch 5::Minibatch 1040::LR 0.0907692307692 --> Loss 0.000626635551453\n",
      "Epoch 5::Minibatch 1041::LR 0.0907692307692 --> Loss 0.000705021470785\n",
      "Epoch 6::Minibatch 1::LR 0.0884615384615 --> Loss 0.0121383515994\n",
      "Epoch 6::Minibatch 2::LR 0.0884615384615 --> Loss 0.00790013392766\n",
      "Epoch 6::Minibatch 3::LR 0.0884615384615 --> Loss 0.00634145061175\n",
      "Epoch 6::Minibatch 4::LR 0.0884615384615 --> Loss 0.00542529066404\n",
      "Epoch 6::Minibatch 5::LR 0.0884615384615 --> Loss 0.00479658126831\n",
      "Epoch 6::Minibatch 6::LR 0.0884615384615 --> Loss 0.00267361382643\n",
      "Epoch 6::Minibatch 7::LR 0.0884615384615 --> Loss 0.00818027416865\n",
      "Epoch 6::Minibatch 8::LR 0.0884615384615 --> Loss 0.00812056859334\n",
      "Epoch 6::Minibatch 9::LR 0.0884615384615 --> Loss 0.00627711415291\n",
      "Epoch 6::Minibatch 10::LR 0.0884615384615 --> Loss 0.00356846570969\n",
      "Epoch 6::Minibatch 11::LR 0.0884615384615 --> Loss 0.00296484430631\n",
      "Epoch 6::Minibatch 12::LR 0.0884615384615 --> Loss 0.00376412351926\n",
      "Epoch 6::Minibatch 13::LR 0.0884615384615 --> Loss 0.00538172205289\n",
      "Epoch 6::Minibatch 14::LR 0.0884615384615 --> Loss 0.00485453367233\n",
      "Epoch 6::Minibatch 15::LR 0.0884615384615 --> Loss 0.00360726356506\n",
      "Epoch 6::Minibatch 16::LR 0.0884615384615 --> Loss 0.00110403815905\n",
      "Epoch 6::Minibatch 17::LR 0.0884615384615 --> Loss 0.0030022251606\n",
      "Epoch 6::Minibatch 18::LR 0.0884615384615 --> Loss 0.00252350111802\n",
      "Epoch 6::Minibatch 19::LR 0.0884615384615 --> Loss 0.000932161013285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 20::LR 0.0884615384615 --> Loss 0.00138356635968\n",
      "Epoch 6::Minibatch 21::LR 0.0884615384615 --> Loss 0.00301420191924\n",
      "Epoch 6::Minibatch 22::LR 0.0884615384615 --> Loss 0.00250164031982\n",
      "Epoch 6::Minibatch 23::LR 0.0884615384615 --> Loss 0.000982684393724\n",
      "Epoch 6::Minibatch 24::LR 0.0884615384615 --> Loss 0.000498804450035\n",
      "Epoch 6::Minibatch 25::LR 0.0884615384615 --> Loss 0.00132345030705\n",
      "Epoch 6::Minibatch 26::LR 0.0884615384615 --> Loss 0.00149467200041\n",
      "Epoch 6::Minibatch 27::LR 0.0884615384615 --> Loss 0.00108922680219\n",
      "Epoch 6::Minibatch 28::LR 0.0884615384615 --> Loss 0.000443738996983\n",
      "Epoch 6::Minibatch 29::LR 0.0884615384615 --> Loss 0.000457713603973\n",
      "Epoch 6::Minibatch 30::LR 0.0884615384615 --> Loss 0.000967300534248\n",
      "Epoch 6::Minibatch 31::LR 0.0884615384615 --> Loss 0.00138828943173\n",
      "Epoch 6::Minibatch 32::LR 0.0884615384615 --> Loss 0.00130223145088\n",
      "Epoch 6::Minibatch 33::LR 0.0884615384615 --> Loss 0.000823224931955\n",
      "Epoch 6::Minibatch 34::LR 0.0884615384615 --> Loss 0.00289642294248\n",
      "Epoch 6::Minibatch 35::LR 0.0884615384615 --> Loss 0.00400795976321\n",
      "Epoch 6::Minibatch 36::LR 0.0884615384615 --> Loss 0.00210229098797\n",
      "Epoch 6::Minibatch 37::LR 0.0884615384615 --> Loss 0.000576001157363\n",
      "Epoch 6::Minibatch 38::LR 0.0884615384615 --> Loss 0.000880535940329\n",
      "Epoch 6::Minibatch 39::LR 0.0884615384615 --> Loss 0.00292945802212\n",
      "Epoch 6::Minibatch 40::LR 0.0884615384615 --> Loss 0.00384760737419\n",
      "Epoch 6::Minibatch 41::LR 0.0884615384615 --> Loss 0.00373520453771\n",
      "Epoch 6::Minibatch 42::LR 0.0884615384615 --> Loss 0.00608818610509\n",
      "Epoch 6::Minibatch 43::LR 0.0884615384615 --> Loss 0.00200144549211\n",
      "Epoch 6::Minibatch 44::LR 0.0884615384615 --> Loss 0.00318003038565\n",
      "Epoch 6::Minibatch 45::LR 0.0884615384615 --> Loss 0.0028032485644\n",
      "Epoch 6::Minibatch 46::LR 0.0884615384615 --> Loss 0.00390654484431\n",
      "Epoch 6::Minibatch 47::LR 0.0884615384615 --> Loss 0.00552933295568\n",
      "Epoch 6::Minibatch 48::LR 0.0884615384615 --> Loss 0.00609312494596\n",
      "Epoch 6::Minibatch 49::LR 0.0884615384615 --> Loss 0.00596298098564\n",
      "Epoch 6::Minibatch 50::LR 0.0884615384615 --> Loss 0.00538044134776\n",
      "Epoch 6::Minibatch 51::LR 0.0884615384615 --> Loss 0.00903929551442\n",
      "Epoch 6::Minibatch 52::LR 0.0884615384615 --> Loss 0.00358947237333\n",
      "Epoch 6::Minibatch 53::LR 0.0884615384615 --> Loss 0.00379858374596\n",
      "Epoch 6::Minibatch 54::LR 0.0884615384615 --> Loss 0.00410328984261\n",
      "Epoch 6::Minibatch 55::LR 0.0884615384615 --> Loss 0.00143435696761\n",
      "Epoch 6::Minibatch 56::LR 0.0884615384615 --> Loss 0.00308852175872\n",
      "Epoch 6::Minibatch 57::LR 0.0884615384615 --> Loss 0.00629010081291\n",
      "Epoch 6::Minibatch 58::LR 0.0884615384615 --> Loss 0.0037581884861\n",
      "Epoch 6::Minibatch 59::LR 0.0884615384615 --> Loss 0.00354198257128\n",
      "Epoch 6::Minibatch 60::LR 0.0884615384615 --> Loss 0.00268148541451\n",
      "Epoch 6::Minibatch 61::LR 0.0884615384615 --> Loss 0.00135452439388\n",
      "Epoch 6::Minibatch 62::LR 0.0884615384615 --> Loss 0.00397943019867\n",
      "Epoch 6::Minibatch 63::LR 0.0884615384615 --> Loss 0.00252868612607\n",
      "Epoch 6::Minibatch 64::LR 0.0884615384615 --> Loss 0.00126494050026\n",
      "Epoch 6::Minibatch 65::LR 0.0884615384615 --> Loss 0.00260209818681\n",
      "Epoch 6::Minibatch 66::LR 0.0884615384615 --> Loss 0.00330640236537\n",
      "Epoch 6::Minibatch 67::LR 0.0884615384615 --> Loss 0.00309754033883\n",
      "Epoch 6::Minibatch 68::LR 0.0884615384615 --> Loss 0.00215499242147\n",
      "Epoch 6::Minibatch 69::LR 0.0884615384615 --> Loss 0.00393048604329\n",
      "Epoch 6::Minibatch 70::LR 0.0884615384615 --> Loss 0.00359109044075\n",
      "Epoch 6::Minibatch 71::LR 0.0884615384615 --> Loss 0.00253786881765\n",
      "Epoch 6::Minibatch 72::LR 0.0884615384615 --> Loss 0.000652648061514\n",
      "Epoch 6::Minibatch 73::LR 0.0884615384615 --> Loss 0.0038677418232\n",
      "Epoch 6::Minibatch 74::LR 0.0884615384615 --> Loss 0.00427324692408\n",
      "Epoch 6::Minibatch 75::LR 0.0884615384615 --> Loss 0.00252479612827\n",
      "Epoch 6::Minibatch 76::LR 0.0884615384615 --> Loss 0.000874413351218\n",
      "Epoch 6::Minibatch 77::LR 0.0884615384615 --> Loss 0.00431364774704\n",
      "Epoch 6::Minibatch 78::LR 0.0884615384615 --> Loss 0.00409661610921\n",
      "Epoch 6::Minibatch 79::LR 0.0884615384615 --> Loss 0.00232302149137\n",
      "Epoch 6::Minibatch 80::LR 0.0884615384615 --> Loss 0.00378052473068\n",
      "Epoch 6::Minibatch 81::LR 0.0884615384615 --> Loss 0.00333343068759\n",
      "Epoch 6::Minibatch 82::LR 0.0884615384615 --> Loss 0.00218827346961\n",
      "Epoch 6::Minibatch 83::LR 0.0884615384615 --> Loss 0.00542255361875\n",
      "Epoch 6::Minibatch 84::LR 0.0884615384615 --> Loss 0.00228228966395\n",
      "Epoch 6::Minibatch 85::LR 0.0884615384615 --> Loss 0.00301939169566\n",
      "Epoch 6::Minibatch 86::LR 0.0884615384615 --> Loss 0.00257919152578\n",
      "Epoch 6::Minibatch 87::LR 0.0884615384615 --> Loss 0.00279561559359\n",
      "Epoch 6::Minibatch 88::LR 0.0884615384615 --> Loss 0.00213022371133\n",
      "Epoch 6::Minibatch 89::LR 0.0884615384615 --> Loss 0.00257445573807\n",
      "Epoch 6::Minibatch 90::LR 0.0884615384615 --> Loss 0.0014166978995\n",
      "Epoch 6::Minibatch 91::LR 0.0884615384615 --> Loss 0.00121148079634\n",
      "Epoch 6::Minibatch 92::LR 0.0884615384615 --> Loss 0.00275142172972\n",
      "Epoch 6::Minibatch 93::LR 0.0884615384615 --> Loss 0.00196088433266\n",
      "Epoch 6::Minibatch 94::LR 0.0884615384615 --> Loss 0.00191063225269\n",
      "Epoch 6::Minibatch 95::LR 0.0884615384615 --> Loss 0.00174970964591\n",
      "Epoch 6::Minibatch 96::LR 0.0884615384615 --> Loss 0.00638949473699\n",
      "Epoch 6::Minibatch 97::LR 0.0884615384615 --> Loss 0.00318466941516\n",
      "Epoch 6::Minibatch 98::LR 0.0884615384615 --> Loss 0.000998537143071\n",
      "Epoch 6::Minibatch 99::LR 0.0884615384615 --> Loss 0.00134837071101\n",
      "Epoch 6::Minibatch 100::LR 0.0884615384615 --> Loss 0.00579016208649\n",
      "Epoch 6::Minibatch 101::LR 0.0884615384615 --> Loss 0.00114689608415\n",
      "Epoch 6::Minibatch 102::LR 0.0884615384615 --> Loss 0.00369187275569\n",
      "Epoch 6::Minibatch 103::LR 0.0884615384615 --> Loss 0.00400647203128\n",
      "Epoch 6::Minibatch 104::LR 0.0884615384615 --> Loss 0.0030082521836\n",
      "Epoch 6::Minibatch 105::LR 0.0884615384615 --> Loss 0.00393283843994\n",
      "Epoch 6::Minibatch 106::LR 0.0884615384615 --> Loss 0.0177172533671\n",
      "Epoch 6::Minibatch 107::LR 0.0884615384615 --> Loss 0.00479739824931\n",
      "Epoch 6::Minibatch 108::LR 0.0884615384615 --> Loss 0.00147529284159\n",
      "Epoch 6::Minibatch 109::LR 0.0884615384615 --> Loss 0.00481672565142\n",
      "Epoch 6::Minibatch 110::LR 0.0884615384615 --> Loss 0.00282358149687\n",
      "Epoch 6::Minibatch 111::LR 0.0884615384615 --> Loss 0.00138364781936\n",
      "Epoch 6::Minibatch 112::LR 0.0884615384615 --> Loss 0.00404266873995\n",
      "Epoch 6::Minibatch 113::LR 0.0884615384615 --> Loss 0.0031641570727\n",
      "Epoch 6::Minibatch 114::LR 0.0884615384615 --> Loss 0.00180935740471\n",
      "Epoch 6::Minibatch 115::LR 0.0884615384615 --> Loss 0.00181097129981\n",
      "Epoch 6::Minibatch 116::LR 0.0884615384615 --> Loss 0.00323381384214\n",
      "Epoch 6::Minibatch 117::LR 0.0884615384615 --> Loss 0.0038199822108\n",
      "Epoch 6::Minibatch 118::LR 0.0884615384615 --> Loss 0.00685279289881\n",
      "Epoch 6::Minibatch 119::LR 0.0884615384615 --> Loss 0.00100127130747\n",
      "Epoch 6::Minibatch 120::LR 0.0884615384615 --> Loss 0.00229491730531\n",
      "Epoch 6::Minibatch 121::LR 0.0884615384615 --> Loss 0.00324722528458\n",
      "Epoch 6::Minibatch 122::LR 0.0884615384615 --> Loss 0.0037688378493\n",
      "Epoch 6::Minibatch 123::LR 0.0884615384615 --> Loss 0.00167519986629\n",
      "Epoch 6::Minibatch 124::LR 0.0884615384615 --> Loss 0.00314337154229\n",
      "Epoch 6::Minibatch 125::LR 0.0884615384615 --> Loss 0.00499258677165\n",
      "Epoch 6::Minibatch 126::LR 0.0884615384615 --> Loss 0.00321660816669\n",
      "Epoch 6::Minibatch 127::LR 0.0884615384615 --> Loss 0.00476691047351\n",
      "Epoch 6::Minibatch 128::LR 0.0884615384615 --> Loss 0.00387694279353\n",
      "Epoch 6::Minibatch 129::LR 0.0884615384615 --> Loss 0.00326348245144\n",
      "Epoch 6::Minibatch 130::LR 0.0884615384615 --> Loss 0.00459387222926\n",
      "Epoch 6::Minibatch 131::LR 0.0884615384615 --> Loss 0.0021457785368\n",
      "Epoch 6::Minibatch 132::LR 0.0884615384615 --> Loss 0.00358177860578\n",
      "Epoch 6::Minibatch 133::LR 0.0884615384615 --> Loss 0.00345948815346\n",
      "Epoch 6::Minibatch 134::LR 0.0884615384615 --> Loss 0.00290252168973\n",
      "Epoch 6::Minibatch 135::LR 0.0884615384615 --> Loss 0.00217818101247\n",
      "Epoch 6::Minibatch 136::LR 0.0884615384615 --> Loss 0.00308071196079\n",
      "Epoch 6::Minibatch 137::LR 0.0884615384615 --> Loss 0.00387303034465\n",
      "Epoch 6::Minibatch 138::LR 0.0884615384615 --> Loss 0.00159339348475\n",
      "Epoch 6::Minibatch 139::LR 0.0884615384615 --> Loss 0.00204054872195\n",
      "Epoch 6::Minibatch 140::LR 0.0884615384615 --> Loss 0.00257851382097\n",
      "Epoch 6::Minibatch 141::LR 0.0884615384615 --> Loss 0.00317492246628\n",
      "Epoch 6::Minibatch 142::LR 0.0884615384615 --> Loss 0.00337905406952\n",
      "Epoch 6::Minibatch 143::LR 0.0884615384615 --> Loss 0.00082013040781\n",
      "Epoch 6::Minibatch 144::LR 0.0884615384615 --> Loss 0.00317897498608\n",
      "Epoch 6::Minibatch 145::LR 0.0884615384615 --> Loss 0.00441254059474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 146::LR 0.0884615384615 --> Loss 0.00288879334927\n",
      "Epoch 6::Minibatch 147::LR 0.0884615384615 --> Loss 0.00196644306183\n",
      "Epoch 6::Minibatch 148::LR 0.0884615384615 --> Loss 0.0012449062864\n",
      "Epoch 6::Minibatch 149::LR 0.0884615384615 --> Loss 0.00297962625821\n",
      "Epoch 6::Minibatch 150::LR 0.0884615384615 --> Loss 0.00300483942032\n",
      "Epoch 6::Minibatch 151::LR 0.0884615384615 --> Loss 0.00433577934901\n",
      "Epoch 6::Minibatch 152::LR 0.0884615384615 --> Loss 0.00107118964195\n",
      "Epoch 6::Minibatch 153::LR 0.0884615384615 --> Loss 0.00201198577881\n",
      "Epoch 6::Minibatch 154::LR 0.0884615384615 --> Loss 0.00224879244963\n",
      "Epoch 6::Minibatch 155::LR 0.0884615384615 --> Loss 0.00522450645765\n",
      "Epoch 6::Minibatch 156::LR 0.0884615384615 --> Loss 0.00256335874399\n",
      "Epoch 6::Minibatch 157::LR 0.0884615384615 --> Loss 0.000795192817847\n",
      "Epoch 6::Minibatch 158::LR 0.0884615384615 --> Loss 0.00312334199746\n",
      "Epoch 6::Minibatch 159::LR 0.0884615384615 --> Loss 0.0029187142849\n",
      "Epoch 6::Minibatch 160::LR 0.0884615384615 --> Loss 0.00282943665981\n",
      "Epoch 6::Minibatch 161::LR 0.0884615384615 --> Loss 0.00119820425908\n",
      "Epoch 6::Minibatch 162::LR 0.0884615384615 --> Loss 0.00350487788518\n",
      "Epoch 6::Minibatch 163::LR 0.0884615384615 --> Loss 0.00253608326117\n",
      "Epoch 6::Minibatch 164::LR 0.0884615384615 --> Loss 0.00257966677348\n",
      "Epoch 6::Minibatch 165::LR 0.0884615384615 --> Loss 0.00066321849823\n",
      "Epoch 6::Minibatch 166::LR 0.0884615384615 --> Loss 0.00196385165056\n",
      "Epoch 6::Minibatch 167::LR 0.0884615384615 --> Loss 0.00258778671424\n",
      "Epoch 6::Minibatch 168::LR 0.0884615384615 --> Loss 0.00235665718714\n",
      "Epoch 6::Minibatch 169::LR 0.0884615384615 --> Loss 0.00114760984977\n",
      "Epoch 6::Minibatch 170::LR 0.0884615384615 --> Loss 0.00108993510405\n",
      "Epoch 6::Minibatch 171::LR 0.0884615384615 --> Loss 0.00256058394909\n",
      "Epoch 6::Minibatch 172::LR 0.0884615384615 --> Loss 0.00512356241544\n",
      "Epoch 6::Minibatch 173::LR 0.0884615384615 --> Loss 0.00207643846671\n",
      "Epoch 6::Minibatch 174::LR 0.0884615384615 --> Loss 0.00116100549698\n",
      "Epoch 6::Minibatch 175::LR 0.0884615384615 --> Loss 0.00236225704352\n",
      "Epoch 6::Minibatch 176::LR 0.0884615384615 --> Loss 0.00355468074481\n",
      "Epoch 6::Minibatch 177::LR 0.0884615384615 --> Loss 0.00505592385928\n",
      "Epoch 6::Minibatch 178::LR 0.0884615384615 --> Loss 0.00184836169084\n",
      "Epoch 6::Minibatch 179::LR 0.0884615384615 --> Loss 0.00152527471383\n",
      "Epoch 6::Minibatch 180::LR 0.0884615384615 --> Loss 0.00398499329885\n",
      "Epoch 6::Minibatch 181::LR 0.0884615384615 --> Loss 0.00364497900009\n",
      "Epoch 6::Minibatch 182::LR 0.0884615384615 --> Loss 0.000992795526981\n",
      "Epoch 6::Minibatch 183::LR 0.0884615384615 --> Loss 0.00183607955774\n",
      "Epoch 6::Minibatch 184::LR 0.0884615384615 --> Loss 0.0035059205691\n",
      "Epoch 6::Minibatch 185::LR 0.0884615384615 --> Loss 0.0030133130153\n",
      "Epoch 6::Minibatch 186::LR 0.0884615384615 --> Loss 0.00113705992699\n",
      "Epoch 6::Minibatch 187::LR 0.0884615384615 --> Loss 0.00136894653241\n",
      "Epoch 6::Minibatch 188::LR 0.0884615384615 --> Loss 0.00423485954603\n",
      "Epoch 6::Minibatch 189::LR 0.0884615384615 --> Loss 0.00465560595194\n",
      "Epoch 6::Minibatch 190::LR 0.0884615384615 --> Loss 0.00244039913019\n",
      "Epoch 6::Minibatch 191::LR 0.0884615384615 --> Loss 0.000658207535744\n",
      "Epoch 6::Minibatch 192::LR 0.0884615384615 --> Loss 0.00270279824734\n",
      "Epoch 6::Minibatch 193::LR 0.0884615384615 --> Loss 0.00251897553603\n",
      "Epoch 6::Minibatch 194::LR 0.0884615384615 --> Loss 0.00193082094193\n",
      "Epoch 6::Minibatch 195::LR 0.0884615384615 --> Loss 0.000486992051204\n",
      "Epoch 6::Minibatch 196::LR 0.0884615384615 --> Loss 0.00126819173495\n",
      "Epoch 6::Minibatch 197::LR 0.0884615384615 --> Loss 0.00283528526624\n",
      "Epoch 6::Minibatch 198::LR 0.0884615384615 --> Loss 0.00222115000089\n",
      "Epoch 6::Minibatch 199::LR 0.0884615384615 --> Loss 0.000373236214121\n",
      "Epoch 6::Minibatch 200::LR 0.0884615384615 --> Loss 0.00226059138775\n",
      "Epoch 6::Minibatch 201::LR 0.0884615384615 --> Loss 0.00221103310585\n",
      "Epoch 6::Minibatch 202::LR 0.0884615384615 --> Loss 0.00211928129196\n",
      "Epoch 6::Minibatch 203::LR 0.0884615384615 --> Loss 0.00207657774289\n",
      "Epoch 6::Minibatch 204::LR 0.0884615384615 --> Loss 0.00185398459435\n",
      "Epoch 6::Minibatch 205::LR 0.0884615384615 --> Loss 0.00248059034348\n",
      "Epoch 6::Minibatch 206::LR 0.0884615384615 --> Loss 0.00771103858948\n",
      "Epoch 6::Minibatch 207::LR 0.0884615384615 --> Loss 0.00159382800261\n",
      "Epoch 6::Minibatch 208::LR 0.0884615384615 --> Loss 0.00134768615166\n",
      "Epoch 6::Minibatch 209::LR 0.0884615384615 --> Loss 0.00221843103568\n",
      "Epoch 6::Minibatch 210::LR 0.0884615384615 --> Loss 0.00202716569106\n",
      "Epoch 6::Minibatch 211::LR 0.0884615384615 --> Loss 0.00210641205311\n",
      "Epoch 6::Minibatch 212::LR 0.0884615384615 --> Loss 0.00455796957016\n",
      "Epoch 6::Minibatch 213::LR 0.0884615384615 --> Loss 0.00626407702764\n",
      "Epoch 6::Minibatch 214::LR 0.0884615384615 --> Loss 0.010565683047\n",
      "Epoch 6::Minibatch 215::LR 0.0884615384615 --> Loss 0.00160061875979\n",
      "Epoch 6::Minibatch 216::LR 0.0884615384615 --> Loss 0.00554450591405\n",
      "Epoch 6::Minibatch 217::LR 0.0884615384615 --> Loss 0.00583840409915\n",
      "Epoch 6::Minibatch 218::LR 0.0884615384615 --> Loss 0.00431509653727\n",
      "Epoch 6::Minibatch 219::LR 0.0884615384615 --> Loss 0.00347585638364\n",
      "Epoch 6::Minibatch 220::LR 0.0884615384615 --> Loss 0.0046964553992\n",
      "Epoch 6::Minibatch 221::LR 0.0884615384615 --> Loss 0.00445238629977\n",
      "Epoch 6::Minibatch 222::LR 0.0884615384615 --> Loss 0.00351191163063\n",
      "Epoch 6::Minibatch 223::LR 0.0884615384615 --> Loss 0.00160828004281\n",
      "Epoch 6::Minibatch 224::LR 0.0884615384615 --> Loss 0.00209754844507\n",
      "Epoch 6::Minibatch 225::LR 0.0884615384615 --> Loss 0.00667287508647\n",
      "Epoch 6::Minibatch 226::LR 0.0884615384615 --> Loss 0.00399523814519\n",
      "Epoch 6::Minibatch 227::LR 0.0884615384615 --> Loss 0.0018835546573\n",
      "Epoch 6::Minibatch 228::LR 0.0884615384615 --> Loss 0.0010278703769\n",
      "Epoch 6::Minibatch 229::LR 0.0884615384615 --> Loss 0.00499233206113\n",
      "Epoch 6::Minibatch 230::LR 0.0884615384615 --> Loss 0.00426866849264\n",
      "Epoch 6::Minibatch 231::LR 0.0884615384615 --> Loss 0.00278909862041\n",
      "Epoch 6::Minibatch 232::LR 0.0884615384615 --> Loss 0.00150162557761\n",
      "Epoch 6::Minibatch 233::LR 0.0884615384615 --> Loss 0.00250927309195\n",
      "Epoch 6::Minibatch 234::LR 0.0884615384615 --> Loss 0.00609096805255\n",
      "Epoch 6::Minibatch 235::LR 0.0884615384615 --> Loss 0.00494095563889\n",
      "Epoch 6::Minibatch 236::LR 0.0884615384615 --> Loss 0.00196334242821\n",
      "Epoch 6::Minibatch 237::LR 0.0884615384615 --> Loss 0.000922597448031\n",
      "Epoch 6::Minibatch 238::LR 0.0884615384615 --> Loss 0.00353490074476\n",
      "Epoch 6::Minibatch 239::LR 0.0884615384615 --> Loss 0.00303623855114\n",
      "Epoch 6::Minibatch 240::LR 0.0884615384615 --> Loss 0.00327539960543\n",
      "Epoch 6::Minibatch 241::LR 0.0884615384615 --> Loss 0.000928084850311\n",
      "Epoch 6::Minibatch 242::LR 0.0884615384615 --> Loss 0.00731936136882\n",
      "Epoch 6::Minibatch 243::LR 0.0884615384615 --> Loss 0.00383554816246\n",
      "Epoch 6::Minibatch 244::LR 0.0884615384615 --> Loss 0.00319764316082\n",
      "Epoch 6::Minibatch 245::LR 0.0884615384615 --> Loss 0.000667024254799\n",
      "Epoch 6::Minibatch 246::LR 0.0884615384615 --> Loss 0.00233494480451\n",
      "Epoch 6::Minibatch 247::LR 0.0884615384615 --> Loss 0.0143239847819\n",
      "Epoch 6::Minibatch 248::LR 0.0884615384615 --> Loss 0.00489611705144\n",
      "Epoch 6::Minibatch 249::LR 0.0884615384615 --> Loss 0.00344365437826\n",
      "Epoch 6::Minibatch 250::LR 0.0884615384615 --> Loss 0.00341039776802\n",
      "Epoch 6::Minibatch 251::LR 0.0884615384615 --> Loss 0.00272365132968\n",
      "Epoch 6::Minibatch 252::LR 0.0884615384615 --> Loss 0.0021476962169\n",
      "Epoch 6::Minibatch 253::LR 0.0884615384615 --> Loss 0.0033964463075\n",
      "Epoch 6::Minibatch 254::LR 0.0884615384615 --> Loss 0.00565158565839\n",
      "Epoch 6::Minibatch 255::LR 0.0884615384615 --> Loss 0.00422972400983\n",
      "Epoch 6::Minibatch 256::LR 0.0884615384615 --> Loss 0.0021261715889\n",
      "Epoch 6::Minibatch 257::LR 0.0884615384615 --> Loss 0.00164771179358\n",
      "Epoch 6::Minibatch 258::LR 0.0884615384615 --> Loss 0.00376226743062\n",
      "Epoch 6::Minibatch 259::LR 0.0884615384615 --> Loss 0.00208588838577\n",
      "Epoch 6::Minibatch 260::LR 0.0884615384615 --> Loss 0.00206610182921\n",
      "Epoch 6::Minibatch 261::LR 0.0884615384615 --> Loss 0.00320573270321\n",
      "Epoch 6::Minibatch 262::LR 0.0884615384615 --> Loss 0.00216680387656\n",
      "Epoch 6::Minibatch 263::LR 0.0884615384615 --> Loss 0.00253532191118\n",
      "Epoch 6::Minibatch 264::LR 0.0884615384615 --> Loss 0.00383515278498\n",
      "Epoch 6::Minibatch 265::LR 0.0884615384615 --> Loss 0.00977546771367\n",
      "Epoch 6::Minibatch 266::LR 0.0884615384615 --> Loss 0.00131070892016\n",
      "Epoch 6::Minibatch 267::LR 0.0884615384615 --> Loss 0.0101655141513\n",
      "Epoch 6::Minibatch 268::LR 0.0884615384615 --> Loss 0.00156417061885\n",
      "Epoch 6::Minibatch 269::LR 0.0884615384615 --> Loss 0.00380507270495\n",
      "Epoch 6::Minibatch 270::LR 0.0884615384615 --> Loss 0.0063283542792\n",
      "Epoch 6::Minibatch 271::LR 0.0884615384615 --> Loss 0.00317771871885\n",
      "Epoch 6::Minibatch 272::LR 0.0884615384615 --> Loss 0.00410978476206\n",
      "Epoch 6::Minibatch 273::LR 0.0884615384615 --> Loss 0.00207946320375\n",
      "Epoch 6::Minibatch 274::LR 0.0884615384615 --> Loss 0.00204999427001\n",
      "Epoch 6::Minibatch 275::LR 0.0884615384615 --> Loss 0.0029857258002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 276::LR 0.0884615384615 --> Loss 0.00364408214887\n",
      "Epoch 6::Minibatch 277::LR 0.0884615384615 --> Loss 0.00128676136335\n",
      "Epoch 6::Minibatch 278::LR 0.0884615384615 --> Loss 0.00281002501647\n",
      "Epoch 6::Minibatch 279::LR 0.0884615384615 --> Loss 0.0027069936196\n",
      "Epoch 6::Minibatch 280::LR 0.0884615384615 --> Loss 0.00237667679787\n",
      "Epoch 6::Minibatch 281::LR 0.0884615384615 --> Loss 0.00157667249441\n",
      "Epoch 6::Minibatch 282::LR 0.0884615384615 --> Loss 0.00240747114023\n",
      "Epoch 6::Minibatch 283::LR 0.0884615384615 --> Loss 0.00234023749828\n",
      "Epoch 6::Minibatch 284::LR 0.0884615384615 --> Loss 0.00189360121886\n",
      "Epoch 6::Minibatch 285::LR 0.0884615384615 --> Loss 0.00136184801658\n",
      "Epoch 6::Minibatch 286::LR 0.0884615384615 --> Loss 0.00224907616774\n",
      "Epoch 6::Minibatch 287::LR 0.0884615384615 --> Loss 0.00216000477473\n",
      "Epoch 6::Minibatch 288::LR 0.0884615384615 --> Loss 0.0012134479483\n",
      "Epoch 6::Minibatch 289::LR 0.0884615384615 --> Loss 0.00159559528033\n",
      "Epoch 6::Minibatch 290::LR 0.0884615384615 --> Loss 0.00200325210889\n",
      "Epoch 6::Minibatch 291::LR 0.0884615384615 --> Loss 0.00180137058099\n",
      "Epoch 6::Minibatch 292::LR 0.0884615384615 --> Loss 0.000706641823053\n",
      "Epoch 6::Minibatch 293::LR 0.0884615384615 --> Loss 0.0014795221885\n",
      "Epoch 6::Minibatch 294::LR 0.0884615384615 --> Loss 0.00160981625319\n",
      "Epoch 6::Minibatch 295::LR 0.0884615384615 --> Loss 0.0018342534701\n",
      "Epoch 6::Minibatch 296::LR 0.0884615384615 --> Loss 0.00158588687579\n",
      "Epoch 6::Minibatch 297::LR 0.0884615384615 --> Loss 0.00141551276048\n",
      "Epoch 6::Minibatch 298::LR 0.0884615384615 --> Loss 0.00138529400031\n",
      "Epoch 6::Minibatch 299::LR 0.0884615384615 --> Loss 0.000865618089835\n",
      "Epoch 6::Minibatch 300::LR 0.0884615384615 --> Loss 0.00306615769863\n",
      "Epoch 6::Minibatch 301::LR 0.0884615384615 --> Loss 0.00295100947221\n",
      "Epoch 6::Minibatch 302::LR 0.0884615384615 --> Loss 0.00269763271014\n",
      "Epoch 6::Minibatch 303::LR 0.0884615384615 --> Loss 0.000995237429937\n",
      "Epoch 6::Minibatch 304::LR 0.0884615384615 --> Loss 0.00332632303238\n",
      "Epoch 6::Minibatch 305::LR 0.0884615384615 --> Loss 0.00179387509823\n",
      "Epoch 6::Minibatch 306::LR 0.0884615384615 --> Loss 0.00104648997386\n",
      "Epoch 6::Minibatch 307::LR 0.0884615384615 --> Loss 0.00260661800702\n",
      "Epoch 6::Minibatch 308::LR 0.0884615384615 --> Loss 0.00206075867017\n",
      "Epoch 6::Minibatch 309::LR 0.0884615384615 --> Loss 0.0010477784276\n",
      "Epoch 6::Minibatch 310::LR 0.0884615384615 --> Loss 0.00108900487423\n",
      "Epoch 6::Minibatch 311::LR 0.0884615384615 --> Loss 0.00167890369892\n",
      "Epoch 6::Minibatch 312::LR 0.0884615384615 --> Loss 0.00320070922375\n",
      "Epoch 6::Minibatch 313::LR 0.0884615384615 --> Loss 0.00240076700846\n",
      "Epoch 6::Minibatch 314::LR 0.0884615384615 --> Loss 0.00197050412496\n",
      "Epoch 6::Minibatch 315::LR 0.0884615384615 --> Loss 0.00104537973801\n",
      "Epoch 6::Minibatch 316::LR 0.0884615384615 --> Loss 0.00241802632809\n",
      "Epoch 6::Minibatch 317::LR 0.0884615384615 --> Loss 0.00166167328755\n",
      "Epoch 6::Minibatch 318::LR 0.0884615384615 --> Loss 0.00121859689554\n",
      "Epoch 6::Minibatch 319::LR 0.0884615384615 --> Loss 0.00234452843666\n",
      "Epoch 6::Minibatch 320::LR 0.0884615384615 --> Loss 0.00347874641418\n",
      "Epoch 6::Minibatch 321::LR 0.0884615384615 --> Loss 0.00101966877778\n",
      "Epoch 6::Minibatch 322::LR 0.0884615384615 --> Loss 0.00370441158613\n",
      "Epoch 6::Minibatch 323::LR 0.0884615384615 --> Loss 0.00364167491595\n",
      "Epoch 6::Minibatch 324::LR 0.0884615384615 --> Loss 0.00266151050727\n",
      "Epoch 6::Minibatch 325::LR 0.0884615384615 --> Loss 0.00251275956631\n",
      "Epoch 6::Minibatch 326::LR 0.0884615384615 --> Loss 0.00550596475601\n",
      "Epoch 6::Minibatch 327::LR 0.0884615384615 --> Loss 0.00241417249044\n",
      "Epoch 6::Minibatch 328::LR 0.0884615384615 --> Loss 0.00372309605281\n",
      "Epoch 6::Minibatch 329::LR 0.0884615384615 --> Loss 0.00135308017333\n",
      "Epoch 6::Minibatch 330::LR 0.0884615384615 --> Loss 0.00175267179807\n",
      "Epoch 6::Minibatch 331::LR 0.0884615384615 --> Loss 0.00270043035348\n",
      "Epoch 6::Minibatch 332::LR 0.0884615384615 --> Loss 0.00265853802363\n",
      "Epoch 6::Minibatch 333::LR 0.0884615384615 --> Loss 0.00158870786428\n",
      "Epoch 6::Minibatch 334::LR 0.0884615384615 --> Loss 0.00416399637858\n",
      "Epoch 6::Minibatch 335::LR 0.0884615384615 --> Loss 0.00200832327207\n",
      "Epoch 6::Minibatch 336::LR 0.0884615384615 --> Loss 0.00201917846998\n",
      "Epoch 6::Minibatch 337::LR 0.0884615384615 --> Loss 0.00324475487073\n",
      "Epoch 6::Minibatch 338::LR 0.0884615384615 --> Loss 0.000590600868066\n",
      "Epoch 6::Minibatch 339::LR 0.0884615384615 --> Loss 0.00329830845197\n",
      "Epoch 6::Minibatch 340::LR 0.0884615384615 --> Loss 0.00539698839188\n",
      "Epoch 6::Minibatch 341::LR 0.0884615384615 --> Loss 0.00513026754061\n",
      "Epoch 6::Minibatch 342::LR 0.0884615384615 --> Loss 0.00369070967038\n",
      "Epoch 6::Minibatch 343::LR 0.0884615384615 --> Loss 0.0019772897164\n",
      "Epoch 6::Minibatch 344::LR 0.0884615384615 --> Loss 0.00306341489156\n",
      "Epoch 6::Minibatch 345::LR 0.0884615384615 --> Loss 0.00448547641436\n",
      "Epoch 6::Minibatch 346::LR 0.0884615384615 --> Loss 0.00578960339228\n",
      "Epoch 6::Minibatch 347::LR 0.0884615384615 --> Loss 0.00108345756928\n",
      "Epoch 6::Minibatch 348::LR 0.0884615384615 --> Loss 0.00387520154317\n",
      "Epoch 6::Minibatch 349::LR 0.0884615384615 --> Loss 0.00365625063578\n",
      "Epoch 6::Minibatch 350::LR 0.0884615384615 --> Loss 0.00210466563702\n",
      "Epoch 6::Minibatch 351::LR 0.0884615384615 --> Loss 0.00380292892456\n",
      "Epoch 6::Minibatch 352::LR 0.0884615384615 --> Loss 0.00484530607859\n",
      "Epoch 6::Minibatch 353::LR 0.0884615384615 --> Loss 0.00365795572599\n",
      "Epoch 6::Minibatch 354::LR 0.0884615384615 --> Loss 0.0030501806736\n",
      "Epoch 6::Minibatch 355::LR 0.0884615384615 --> Loss 0.00628342866898\n",
      "Epoch 6::Minibatch 356::LR 0.0884615384615 --> Loss 0.00336509188016\n",
      "Epoch 6::Minibatch 357::LR 0.0884615384615 --> Loss 0.00139061490695\n",
      "Epoch 6::Minibatch 358::LR 0.0884615384615 --> Loss 0.00253050188224\n",
      "Epoch 6::Minibatch 359::LR 0.0884615384615 --> Loss 0.00291617135207\n",
      "Epoch 6::Minibatch 360::LR 0.0884615384615 --> Loss 0.00268710593383\n",
      "Epoch 6::Minibatch 361::LR 0.0884615384615 --> Loss 0.0025903125604\n",
      "Epoch 6::Minibatch 362::LR 0.0884615384615 --> Loss 0.00270561516285\n",
      "Epoch 6::Minibatch 363::LR 0.0884615384615 --> Loss 0.000796598643064\n",
      "Epoch 6::Minibatch 364::LR 0.0884615384615 --> Loss 0.00217737774054\n",
      "Epoch 6::Minibatch 365::LR 0.0884615384615 --> Loss 0.00227427025636\n",
      "Epoch 6::Minibatch 366::LR 0.0884615384615 --> Loss 0.00250708083312\n",
      "Epoch 6::Minibatch 367::LR 0.0884615384615 --> Loss 0.001246988674\n",
      "Epoch 6::Minibatch 368::LR 0.0884615384615 --> Loss 0.00112768272559\n",
      "Epoch 6::Minibatch 369::LR 0.0884615384615 --> Loss 0.00301957329114\n",
      "Epoch 6::Minibatch 370::LR 0.0884615384615 --> Loss 0.002374928991\n",
      "Epoch 6::Minibatch 371::LR 0.0884615384615 --> Loss 0.00198769052823\n",
      "Epoch 6::Minibatch 372::LR 0.0884615384615 --> Loss 0.000538312196732\n",
      "Epoch 6::Minibatch 373::LR 0.0884615384615 --> Loss 0.00184230466684\n",
      "Epoch 6::Minibatch 374::LR 0.0884615384615 --> Loss 0.0022045904398\n",
      "Epoch 6::Minibatch 375::LR 0.0884615384615 --> Loss 0.00192194680373\n",
      "Epoch 6::Minibatch 376::LR 0.0884615384615 --> Loss 0.00132102767626\n",
      "Epoch 6::Minibatch 377::LR 0.0884615384615 --> Loss 0.00208206514517\n",
      "Epoch 6::Minibatch 378::LR 0.0884615384615 --> Loss 0.00218953529994\n",
      "Epoch 6::Minibatch 379::LR 0.0884615384615 --> Loss 0.00250111003717\n",
      "Epoch 6::Minibatch 380::LR 0.0884615384615 --> Loss 0.00167712191741\n",
      "Epoch 6::Minibatch 381::LR 0.0884615384615 --> Loss 0.00108724921942\n",
      "Epoch 6::Minibatch 382::LR 0.0884615384615 --> Loss 0.00211573739847\n",
      "Epoch 6::Minibatch 383::LR 0.0884615384615 --> Loss 0.00202037195365\n",
      "Epoch 6::Minibatch 384::LR 0.0884615384615 --> Loss 0.0011307327946\n",
      "Epoch 6::Minibatch 385::LR 0.0884615384615 --> Loss 0.00111933618784\n",
      "Epoch 6::Minibatch 386::LR 0.0884615384615 --> Loss 0.00229810992877\n",
      "Epoch 6::Minibatch 387::LR 0.0884615384615 --> Loss 0.00237005790075\n",
      "Epoch 6::Minibatch 388::LR 0.0884615384615 --> Loss 0.00116606314977\n",
      "Epoch 6::Minibatch 389::LR 0.0884615384615 --> Loss 0.00197890102863\n",
      "Epoch 6::Minibatch 390::LR 0.0884615384615 --> Loss 0.00414794921875\n",
      "Epoch 6::Minibatch 391::LR 0.0884615384615 --> Loss 0.00292887091637\n",
      "Epoch 6::Minibatch 392::LR 0.0884615384615 --> Loss 0.0029054671526\n",
      "Epoch 6::Minibatch 393::LR 0.0884615384615 --> Loss 0.00291696310043\n",
      "Epoch 6::Minibatch 394::LR 0.0884615384615 --> Loss 0.00229195952415\n",
      "Epoch 6::Minibatch 395::LR 0.0884615384615 --> Loss 0.00216210663319\n",
      "Epoch 6::Minibatch 396::LR 0.0884615384615 --> Loss 0.00213562746843\n",
      "Epoch 6::Minibatch 397::LR 0.0884615384615 --> Loss 0.00225905795892\n",
      "Epoch 6::Minibatch 398::LR 0.0884615384615 --> Loss 0.00221672991912\n",
      "Epoch 6::Minibatch 399::LR 0.0884615384615 --> Loss 0.00248428444068\n",
      "Epoch 6::Minibatch 400::LR 0.0884615384615 --> Loss 0.00217115302881\n",
      "Epoch 6::Minibatch 401::LR 0.0884615384615 --> Loss 0.00415441910426\n",
      "Epoch 6::Minibatch 402::LR 0.0884615384615 --> Loss 0.00212161938349\n",
      "Epoch 6::Minibatch 403::LR 0.0884615384615 --> Loss 0.00162166237831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 404::LR 0.0884615384615 --> Loss 0.00175259629885\n",
      "Epoch 6::Minibatch 405::LR 0.0884615384615 --> Loss 0.0037794927756\n",
      "Epoch 6::Minibatch 406::LR 0.0884615384615 --> Loss 0.00266594866912\n",
      "Epoch 6::Minibatch 407::LR 0.0884615384615 --> Loss 0.00188716709614\n",
      "Epoch 6::Minibatch 408::LR 0.0884615384615 --> Loss 0.000605204552412\n",
      "Epoch 6::Minibatch 409::LR 0.0884615384615 --> Loss 0.00272817353408\n",
      "Epoch 6::Minibatch 410::LR 0.0884615384615 --> Loss 0.00355227351189\n",
      "Epoch 6::Minibatch 411::LR 0.0884615384615 --> Loss 0.00175788680712\n",
      "Epoch 6::Minibatch 412::LR 0.0884615384615 --> Loss 0.00108829220136\n",
      "Epoch 6::Minibatch 413::LR 0.0884615384615 --> Loss 0.00215612391631\n",
      "Epoch 6::Minibatch 414::LR 0.0884615384615 --> Loss 0.00181738615036\n",
      "Epoch 6::Minibatch 415::LR 0.0884615384615 --> Loss 0.00121172169844\n",
      "Epoch 6::Minibatch 416::LR 0.0884615384615 --> Loss 0.000934680302938\n",
      "Epoch 6::Minibatch 417::LR 0.0884615384615 --> Loss 0.00175938487053\n",
      "Epoch 6::Minibatch 418::LR 0.0884615384615 --> Loss 0.00311850567659\n",
      "Epoch 6::Minibatch 419::LR 0.0884615384615 --> Loss 0.000667076756557\n",
      "Epoch 6::Minibatch 420::LR 0.0884615384615 --> Loss 0.00085646400849\n",
      "Epoch 6::Minibatch 421::LR 0.0884615384615 --> Loss 0.00209641138713\n",
      "Epoch 6::Minibatch 422::LR 0.0884615384615 --> Loss 0.00241545975208\n",
      "Epoch 6::Minibatch 423::LR 0.0884615384615 --> Loss 0.00113216588895\n",
      "Epoch 6::Minibatch 424::LR 0.0884615384615 --> Loss 0.00176320970058\n",
      "Epoch 6::Minibatch 425::LR 0.0884615384615 --> Loss 0.00284881909688\n",
      "Epoch 6::Minibatch 426::LR 0.0884615384615 --> Loss 0.00211722453435\n",
      "Epoch 6::Minibatch 427::LR 0.0884615384615 --> Loss 0.000817894538244\n",
      "Epoch 6::Minibatch 428::LR 0.0884615384615 --> Loss 0.00132088840008\n",
      "Epoch 6::Minibatch 429::LR 0.0884615384615 --> Loss 0.00272979219755\n",
      "Epoch 6::Minibatch 430::LR 0.0884615384615 --> Loss 0.00985762198766\n",
      "Epoch 6::Minibatch 431::LR 0.0884615384615 --> Loss 0.00369750181834\n",
      "Epoch 6::Minibatch 432::LR 0.0884615384615 --> Loss 0.00468499104182\n",
      "Epoch 6::Minibatch 433::LR 0.0884615384615 --> Loss 0.00271327912807\n",
      "Epoch 6::Minibatch 434::LR 0.0884615384615 --> Loss 0.00267515480518\n",
      "Epoch 6::Minibatch 435::LR 0.0884615384615 --> Loss 0.0025995473067\n",
      "Epoch 6::Minibatch 436::LR 0.0884615384615 --> Loss 0.00199018478394\n",
      "Epoch 6::Minibatch 437::LR 0.0884615384615 --> Loss 0.00384050488472\n",
      "Epoch 6::Minibatch 438::LR 0.0884615384615 --> Loss 0.00299569567045\n",
      "Epoch 6::Minibatch 439::LR 0.0884615384615 --> Loss 0.00242298563321\n",
      "Epoch 6::Minibatch 440::LR 0.0884615384615 --> Loss 0.00351324001948\n",
      "Epoch 6::Minibatch 441::LR 0.0884615384615 --> Loss 0.00332409759363\n",
      "Epoch 6::Minibatch 442::LR 0.0884615384615 --> Loss 0.00316211005052\n",
      "Epoch 6::Minibatch 443::LR 0.0884615384615 --> Loss 0.00407040079435\n",
      "Epoch 6::Minibatch 444::LR 0.0884615384615 --> Loss 0.00300184408824\n",
      "Epoch 6::Minibatch 445::LR 0.0884615384615 --> Loss 0.000958983103434\n",
      "Epoch 6::Minibatch 446::LR 0.0884615384615 --> Loss 0.00164223978917\n",
      "Epoch 6::Minibatch 447::LR 0.0884615384615 --> Loss 0.00264194150766\n",
      "Epoch 6::Minibatch 448::LR 0.0884615384615 --> Loss 0.00260798076789\n",
      "Epoch 6::Minibatch 449::LR 0.0884615384615 --> Loss 0.00396842638652\n",
      "Epoch 6::Minibatch 450::LR 0.0884615384615 --> Loss 0.00263287305832\n",
      "Epoch 6::Minibatch 451::LR 0.0884615384615 --> Loss 0.00435434937477\n",
      "Epoch 6::Minibatch 452::LR 0.0884615384615 --> Loss 0.00252403696378\n",
      "Epoch 6::Minibatch 453::LR 0.0884615384615 --> Loss 0.000512749254704\n",
      "Epoch 6::Minibatch 454::LR 0.0884615384615 --> Loss 0.00358749111493\n",
      "Epoch 6::Minibatch 455::LR 0.0884615384615 --> Loss 0.00282506763935\n",
      "Epoch 6::Minibatch 456::LR 0.0884615384615 --> Loss 0.00335371692975\n",
      "Epoch 6::Minibatch 457::LR 0.0884615384615 --> Loss 0.00209030707677\n",
      "Epoch 6::Minibatch 458::LR 0.0884615384615 --> Loss 0.000915947258472\n",
      "Epoch 6::Minibatch 459::LR 0.0884615384615 --> Loss 0.00443303306897\n",
      "Epoch 6::Minibatch 460::LR 0.0884615384615 --> Loss 0.00289837956429\n",
      "Epoch 6::Minibatch 461::LR 0.0884615384615 --> Loss 0.00413878599803\n",
      "Epoch 6::Minibatch 462::LR 0.0884615384615 --> Loss 0.000475509812435\n",
      "Epoch 6::Minibatch 463::LR 0.0884615384615 --> Loss 0.00488560676575\n",
      "Epoch 6::Minibatch 464::LR 0.0884615384615 --> Loss 0.00220608750979\n",
      "Epoch 6::Minibatch 465::LR 0.0884615384615 --> Loss 0.0060174993674\n",
      "Epoch 6::Minibatch 466::LR 0.0884615384615 --> Loss 0.00545017997424\n",
      "Epoch 6::Minibatch 467::LR 0.0884615384615 --> Loss 0.00692169745763\n",
      "Epoch 6::Minibatch 468::LR 0.0884615384615 --> Loss 0.00653901457787\n",
      "Epoch 6::Minibatch 469::LR 0.0884615384615 --> Loss 0.00730701287587\n",
      "Epoch 6::Minibatch 470::LR 0.0884615384615 --> Loss 0.00419468164444\n",
      "Epoch 6::Minibatch 471::LR 0.0884615384615 --> Loss 0.00210987687111\n",
      "Epoch 6::Minibatch 472::LR 0.0884615384615 --> Loss 0.00362241903941\n",
      "Epoch 6::Minibatch 473::LR 0.0884615384615 --> Loss 0.0021943316857\n",
      "Epoch 6::Minibatch 474::LR 0.0884615384615 --> Loss 0.000784205098947\n",
      "Epoch 6::Minibatch 475::LR 0.0884615384615 --> Loss 0.00580806533496\n",
      "Epoch 6::Minibatch 476::LR 0.0884615384615 --> Loss 0.00777930736542\n",
      "Epoch 6::Minibatch 477::LR 0.0884615384615 --> Loss 0.00102600206931\n",
      "Epoch 6::Minibatch 478::LR 0.0884615384615 --> Loss 0.0025720568498\n",
      "Epoch 6::Minibatch 479::LR 0.0884615384615 --> Loss 0.00199676394463\n",
      "Epoch 6::Minibatch 480::LR 0.0884615384615 --> Loss 0.00156155794859\n",
      "Epoch 6::Minibatch 481::LR 0.0884615384615 --> Loss 0.00101387560368\n",
      "Epoch 6::Minibatch 482::LR 0.0884615384615 --> Loss 0.00218386173248\n",
      "Epoch 6::Minibatch 483::LR 0.0884615384615 --> Loss 0.00359674771627\n",
      "Epoch 6::Minibatch 484::LR 0.0884615384615 --> Loss 0.00380346099536\n",
      "Epoch 6::Minibatch 485::LR 0.0884615384615 --> Loss 0.000821659614642\n",
      "Epoch 6::Minibatch 486::LR 0.0884615384615 --> Loss 0.00342428088188\n",
      "Epoch 6::Minibatch 487::LR 0.0884615384615 --> Loss 0.00372040271759\n",
      "Epoch 6::Minibatch 488::LR 0.0884615384615 --> Loss 0.00207683106263\n",
      "Epoch 6::Minibatch 489::LR 0.0884615384615 --> Loss 0.00323498030504\n",
      "Epoch 6::Minibatch 490::LR 0.0884615384615 --> Loss 0.000476831595103\n",
      "Epoch 6::Minibatch 491::LR 0.0884615384615 --> Loss 0.00493841290474\n",
      "Epoch 6::Minibatch 492::LR 0.0884615384615 --> Loss 0.00306579808394\n",
      "Epoch 6::Minibatch 493::LR 0.0884615384615 --> Loss 0.00314366499583\n",
      "Epoch 6::Minibatch 494::LR 0.0884615384615 --> Loss 0.000804279744625\n",
      "Epoch 6::Minibatch 495::LR 0.0884615384615 --> Loss 0.00197699189186\n",
      "Epoch 6::Minibatch 496::LR 0.0884615384615 --> Loss 0.00319299896558\n",
      "Epoch 6::Minibatch 497::LR 0.0884615384615 --> Loss 0.0010229464372\n",
      "Epoch 6::Minibatch 498::LR 0.0884615384615 --> Loss 0.000680672278007\n",
      "Epoch 6::Minibatch 499::LR 0.0884615384615 --> Loss 0.00420977950096\n",
      "Epoch 6::Minibatch 500::LR 0.0884615384615 --> Loss 0.001513945659\n",
      "Epoch 6::Minibatch 501::LR 0.0884615384615 --> Loss 0.00238050421079\n",
      "Epoch 6::Minibatch 502::LR 0.0884615384615 --> Loss 0.0042209982872\n",
      "Epoch 6::Minibatch 503::LR 0.0884615384615 --> Loss 0.0111417468389\n",
      "Epoch 6::Minibatch 504::LR 0.0884615384615 --> Loss 0.00864196697871\n",
      "Epoch 6::Minibatch 505::LR 0.0884615384615 --> Loss 0.0047341076533\n",
      "Epoch 6::Minibatch 506::LR 0.0884615384615 --> Loss 0.0037643023332\n",
      "Epoch 6::Minibatch 507::LR 0.0884615384615 --> Loss 0.00623715718587\n",
      "Epoch 6::Minibatch 508::LR 0.0884615384615 --> Loss 0.00340184926987\n",
      "Epoch 6::Minibatch 509::LR 0.0884615384615 --> Loss 0.00490231315295\n",
      "Epoch 6::Minibatch 510::LR 0.0884615384615 --> Loss 0.00501866181691\n",
      "Epoch 6::Minibatch 511::LR 0.0884615384615 --> Loss 0.00385312914848\n",
      "Epoch 6::Minibatch 512::LR 0.0884615384615 --> Loss 0.00277165790399\n",
      "Epoch 6::Minibatch 513::LR 0.0884615384615 --> Loss 0.000800542086363\n",
      "Epoch 6::Minibatch 514::LR 0.0884615384615 --> Loss 0.00276883681615\n",
      "Epoch 6::Minibatch 515::LR 0.0884615384615 --> Loss 0.00321763555209\n",
      "Epoch 6::Minibatch 516::LR 0.0884615384615 --> Loss 0.0044255165259\n",
      "Epoch 6::Minibatch 517::LR 0.0884615384615 --> Loss 0.00337248086929\n",
      "Epoch 6::Minibatch 518::LR 0.0884615384615 --> Loss 0.00259160677592\n",
      "Epoch 6::Minibatch 519::LR 0.0884615384615 --> Loss 0.00341934561729\n",
      "Epoch 6::Minibatch 520::LR 0.0884615384615 --> Loss 0.00558940211932\n",
      "Epoch 6::Minibatch 521::LR 0.0884615384615 --> Loss 0.00569154779116\n",
      "Epoch 6::Minibatch 522::LR 0.0884615384615 --> Loss 0.00836228450139\n",
      "Epoch 6::Minibatch 523::LR 0.0884615384615 --> Loss 0.000826031168302\n",
      "Epoch 6::Minibatch 524::LR 0.0884615384615 --> Loss 0.00152086794376\n",
      "Epoch 6::Minibatch 525::LR 0.0884615384615 --> Loss 0.00339286247889\n",
      "Epoch 6::Minibatch 526::LR 0.0884615384615 --> Loss 0.00440150976181\n",
      "Epoch 6::Minibatch 527::LR 0.0884615384615 --> Loss 0.00257191022237\n",
      "Epoch 6::Minibatch 528::LR 0.0884615384615 --> Loss 0.00141097168128\n",
      "Epoch 6::Minibatch 529::LR 0.0884615384615 --> Loss 0.00430564045906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 530::LR 0.0884615384615 --> Loss 0.00455561041832\n",
      "Epoch 6::Minibatch 531::LR 0.0884615384615 --> Loss 0.00384336471558\n",
      "Epoch 6::Minibatch 532::LR 0.0884615384615 --> Loss 0.0028387482961\n",
      "Epoch 6::Minibatch 533::LR 0.0884615384615 --> Loss 0.0049244360129\n",
      "Epoch 6::Minibatch 534::LR 0.0884615384615 --> Loss 0.00401591499647\n",
      "Epoch 6::Minibatch 535::LR 0.0884615384615 --> Loss 0.00330262839794\n",
      "Epoch 6::Minibatch 536::LR 0.0884615384615 --> Loss 0.00220187604427\n",
      "Epoch 6::Minibatch 537::LR 0.0884615384615 --> Loss 0.000795292854309\n",
      "Epoch 6::Minibatch 538::LR 0.0884615384615 --> Loss 0.0018343414863\n",
      "Epoch 6::Minibatch 539::LR 0.0884615384615 --> Loss 0.00355064471563\n",
      "Epoch 6::Minibatch 540::LR 0.0884615384615 --> Loss 0.00345311164856\n",
      "Epoch 6::Minibatch 541::LR 0.0884615384615 --> Loss 0.00296918710073\n",
      "Epoch 6::Minibatch 542::LR 0.0884615384615 --> Loss 0.00270626485348\n",
      "Epoch 6::Minibatch 543::LR 0.0884615384615 --> Loss 0.00302630821864\n",
      "Epoch 6::Minibatch 544::LR 0.0884615384615 --> Loss 0.0041340303421\n",
      "Epoch 6::Minibatch 545::LR 0.0884615384615 --> Loss 0.00215600371361\n",
      "Epoch 6::Minibatch 546::LR 0.0884615384615 --> Loss 0.000764155685902\n",
      "Epoch 6::Minibatch 547::LR 0.0884615384615 --> Loss 0.00276407460372\n",
      "Epoch 6::Minibatch 548::LR 0.0884615384615 --> Loss 0.00424482742945\n",
      "Epoch 6::Minibatch 549::LR 0.0884615384615 --> Loss 0.00816064755122\n",
      "Epoch 6::Minibatch 550::LR 0.0884615384615 --> Loss 0.00123119950294\n",
      "Epoch 6::Minibatch 551::LR 0.0884615384615 --> Loss 0.00254536012808\n",
      "Epoch 6::Minibatch 552::LR 0.0884615384615 --> Loss 0.00388508756955\n",
      "Epoch 6::Minibatch 553::LR 0.0884615384615 --> Loss 0.00346804420153\n",
      "Epoch 6::Minibatch 554::LR 0.0884615384615 --> Loss 0.00421540339788\n",
      "Epoch 6::Minibatch 555::LR 0.0884615384615 --> Loss 0.0011006145676\n",
      "Epoch 6::Minibatch 556::LR 0.0884615384615 --> Loss 0.00222646216551\n",
      "Epoch 6::Minibatch 557::LR 0.0884615384615 --> Loss 0.00264893591404\n",
      "Epoch 6::Minibatch 558::LR 0.0884615384615 --> Loss 0.00387323498726\n",
      "Epoch 6::Minibatch 559::LR 0.0884615384615 --> Loss 0.00387197891871\n",
      "Epoch 6::Minibatch 560::LR 0.0884615384615 --> Loss 0.00328485588233\n",
      "Epoch 6::Minibatch 561::LR 0.0884615384615 --> Loss 0.00298495809237\n",
      "Epoch 6::Minibatch 562::LR 0.0884615384615 --> Loss 0.00251763840516\n",
      "Epoch 6::Minibatch 563::LR 0.0884615384615 --> Loss 0.00424024581909\n",
      "Epoch 6::Minibatch 564::LR 0.0884615384615 --> Loss 0.00327995081743\n",
      "Epoch 6::Minibatch 565::LR 0.0884615384615 --> Loss 0.00398728529612\n",
      "Epoch 6::Minibatch 566::LR 0.0884615384615 --> Loss 0.00248161117236\n",
      "Epoch 6::Minibatch 567::LR 0.0884615384615 --> Loss 0.00283471147219\n",
      "Epoch 6::Minibatch 568::LR 0.0884615384615 --> Loss 0.00194949169954\n",
      "Epoch 6::Minibatch 569::LR 0.0884615384615 --> Loss 0.000654182732105\n",
      "Epoch 6::Minibatch 570::LR 0.0884615384615 --> Loss 0.00190651138624\n",
      "Epoch 6::Minibatch 571::LR 0.0884615384615 --> Loss 0.00249306837718\n",
      "Epoch 6::Minibatch 572::LR 0.0884615384615 --> Loss 0.00258970518907\n",
      "Epoch 6::Minibatch 573::LR 0.0884615384615 --> Loss 0.00162080963453\n",
      "Epoch 6::Minibatch 574::LR 0.0884615384615 --> Loss 0.00111568977435\n",
      "Epoch 6::Minibatch 575::LR 0.0884615384615 --> Loss 0.00195577204227\n",
      "Epoch 6::Minibatch 576::LR 0.0884615384615 --> Loss 0.00233325362206\n",
      "Epoch 6::Minibatch 577::LR 0.0884615384615 --> Loss 0.00181770245234\n",
      "Epoch 6::Minibatch 578::LR 0.0884615384615 --> Loss 0.00137263258298\n",
      "Epoch 6::Minibatch 579::LR 0.0884615384615 --> Loss 0.00129189322392\n",
      "Epoch 6::Minibatch 580::LR 0.0884615384615 --> Loss 0.00210944096247\n",
      "Epoch 6::Minibatch 581::LR 0.0884615384615 --> Loss 0.00181060552597\n",
      "Epoch 6::Minibatch 582::LR 0.0884615384615 --> Loss 0.00429535468419\n",
      "Epoch 6::Minibatch 583::LR 0.0884615384615 --> Loss 0.00101290961107\n",
      "Epoch 6::Minibatch 584::LR 0.0884615384615 --> Loss 0.00138711492221\n",
      "Epoch 6::Minibatch 585::LR 0.0884615384615 --> Loss 0.00601061105728\n",
      "Epoch 6::Minibatch 586::LR 0.0884615384615 --> Loss 0.00448975125949\n",
      "Epoch 6::Minibatch 587::LR 0.0884615384615 --> Loss 0.00122645248969\n",
      "Epoch 6::Minibatch 588::LR 0.0884615384615 --> Loss 0.00153865178426\n",
      "Epoch 6::Minibatch 589::LR 0.0884615384615 --> Loss 0.00290290415287\n",
      "Epoch 6::Minibatch 590::LR 0.0884615384615 --> Loss 0.00226811210314\n",
      "Epoch 6::Minibatch 591::LR 0.0884615384615 --> Loss 0.00414999723434\n",
      "Epoch 6::Minibatch 592::LR 0.0884615384615 --> Loss 0.00127986172835\n",
      "Epoch 6::Minibatch 593::LR 0.0884615384615 --> Loss 0.00273967583974\n",
      "Epoch 6::Minibatch 594::LR 0.0884615384615 --> Loss 0.00308962921302\n",
      "Epoch 6::Minibatch 595::LR 0.0884615384615 --> Loss 0.00313734471798\n",
      "Epoch 6::Minibatch 596::LR 0.0884615384615 --> Loss 0.0022098582983\n",
      "Epoch 6::Minibatch 597::LR 0.0884615384615 --> Loss 0.00134428749482\n",
      "Epoch 6::Minibatch 598::LR 0.0884615384615 --> Loss 0.00345029950142\n",
      "Epoch 6::Minibatch 599::LR 0.0884615384615 --> Loss 0.00202983776728\n",
      "Epoch 6::Minibatch 600::LR 0.0884615384615 --> Loss 0.00244719644388\n",
      "Epoch 6::Minibatch 601::LR 0.0884615384615 --> Loss 0.00391778031985\n",
      "Epoch 6::Minibatch 602::LR 0.0884615384615 --> Loss 0.00220331430435\n",
      "Epoch 6::Minibatch 603::LR 0.0884615384615 --> Loss 0.00286546647549\n",
      "Epoch 6::Minibatch 604::LR 0.0884615384615 --> Loss 0.00175017992655\n",
      "Epoch 6::Minibatch 605::LR 0.0884615384615 --> Loss 0.00263540387154\n",
      "Epoch 6::Minibatch 606::LR 0.0884615384615 --> Loss 0.0020862787962\n",
      "Epoch 6::Minibatch 607::LR 0.0884615384615 --> Loss 0.000907039841016\n",
      "Epoch 6::Minibatch 608::LR 0.0884615384615 --> Loss 0.00177824159463\n",
      "Epoch 6::Minibatch 609::LR 0.0884615384615 --> Loss 0.0024286510547\n",
      "Epoch 6::Minibatch 610::LR 0.0884615384615 --> Loss 0.00399446805318\n",
      "Epoch 6::Minibatch 611::LR 0.0884615384615 --> Loss 0.00274832129478\n",
      "Epoch 6::Minibatch 612::LR 0.0884615384615 --> Loss 0.000615748067697\n",
      "Epoch 6::Minibatch 613::LR 0.0884615384615 --> Loss 0.00146586298943\n",
      "Epoch 6::Minibatch 614::LR 0.0884615384615 --> Loss 0.00265644967556\n",
      "Epoch 6::Minibatch 615::LR 0.0884615384615 --> Loss 0.00180546442668\n",
      "Epoch 6::Minibatch 616::LR 0.0884615384615 --> Loss 0.000999459524949\n",
      "Epoch 6::Minibatch 617::LR 0.0884615384615 --> Loss 0.000602671603362\n",
      "Epoch 6::Minibatch 618::LR 0.0884615384615 --> Loss 0.00271396656831\n",
      "Epoch 6::Minibatch 619::LR 0.0884615384615 --> Loss 0.00203517576059\n",
      "Epoch 6::Minibatch 620::LR 0.0884615384615 --> Loss 0.00180834035079\n",
      "Epoch 6::Minibatch 621::LR 0.0884615384615 --> Loss 0.000928210814794\n",
      "Epoch 6::Minibatch 622::LR 0.0884615384615 --> Loss 0.000908886094888\n",
      "Epoch 6::Minibatch 623::LR 0.0884615384615 --> Loss 0.00228018840154\n",
      "Epoch 6::Minibatch 624::LR 0.0884615384615 --> Loss 0.0019255165259\n",
      "Epoch 6::Minibatch 625::LR 0.0884615384615 --> Loss 0.00347713152568\n",
      "Epoch 6::Minibatch 626::LR 0.0884615384615 --> Loss 0.00521040519079\n",
      "Epoch 6::Minibatch 627::LR 0.0884615384615 --> Loss 0.00153353095055\n",
      "Epoch 6::Minibatch 628::LR 0.0884615384615 --> Loss 0.00106110483408\n",
      "Epoch 6::Minibatch 629::LR 0.0884615384615 --> Loss 0.00375151316325\n",
      "Epoch 6::Minibatch 630::LR 0.0884615384615 --> Loss 0.00356491963069\n",
      "Epoch 6::Minibatch 631::LR 0.0884615384615 --> Loss 0.00713063081106\n",
      "Epoch 6::Minibatch 632::LR 0.0884615384615 --> Loss 0.000956152478854\n",
      "Epoch 6::Minibatch 633::LR 0.0884615384615 --> Loss 0.00183688561122\n",
      "Epoch 6::Minibatch 634::LR 0.0884615384615 --> Loss 0.00342107097308\n",
      "Epoch 6::Minibatch 635::LR 0.0884615384615 --> Loss 0.00494382699331\n",
      "Epoch 6::Minibatch 636::LR 0.0884615384615 --> Loss 0.00619117498398\n",
      "Epoch 6::Minibatch 637::LR 0.0884615384615 --> Loss 0.0011417243878\n",
      "Epoch 6::Minibatch 638::LR 0.0884615384615 --> Loss 0.00182405173779\n",
      "Epoch 6::Minibatch 639::LR 0.0884615384615 --> Loss 0.00357757767042\n",
      "Epoch 6::Minibatch 640::LR 0.0884615384615 --> Loss 0.00536071062088\n",
      "Epoch 6::Minibatch 641::LR 0.0884615384615 --> Loss 0.00340167482694\n",
      "Epoch 6::Minibatch 642::LR 0.0884615384615 --> Loss 0.000719649940729\n",
      "Epoch 6::Minibatch 643::LR 0.0884615384615 --> Loss 0.00250259935856\n",
      "Epoch 6::Minibatch 644::LR 0.0884615384615 --> Loss 0.00421420812607\n",
      "Epoch 6::Minibatch 645::LR 0.0884615384615 --> Loss 0.00450191179911\n",
      "Epoch 6::Minibatch 646::LR 0.0884615384615 --> Loss 0.00174458146095\n",
      "Epoch 6::Minibatch 647::LR 0.0884615384615 --> Loss 0.000842209955057\n",
      "Epoch 6::Minibatch 648::LR 0.0884615384615 --> Loss 0.00334157625834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 649::LR 0.0884615384615 --> Loss 0.00389510949453\n",
      "Epoch 6::Minibatch 650::LR 0.0884615384615 --> Loss 0.00359233617783\n",
      "Epoch 6::Minibatch 651::LR 0.0884615384615 --> Loss 0.00162329047918\n",
      "Epoch 6::Minibatch 652::LR 0.0884615384615 --> Loss 0.00109300692876\n",
      "Epoch 6::Minibatch 653::LR 0.0884615384615 --> Loss 0.00312060236931\n",
      "Epoch 6::Minibatch 654::LR 0.0884615384615 --> Loss 0.00326304058234\n",
      "Epoch 6::Minibatch 655::LR 0.0884615384615 --> Loss 0.00356049219767\n",
      "Epoch 6::Minibatch 656::LR 0.0884615384615 --> Loss 0.000913557211558\n",
      "Epoch 6::Minibatch 657::LR 0.0884615384615 --> Loss 0.00227093180021\n",
      "Epoch 6::Minibatch 658::LR 0.0884615384615 --> Loss 0.00508673389753\n",
      "Epoch 6::Minibatch 659::LR 0.0884615384615 --> Loss 0.00248071372509\n",
      "Epoch 6::Minibatch 660::LR 0.0884615384615 --> Loss 0.00262869218985\n",
      "Epoch 6::Minibatch 661::LR 0.0884615384615 --> Loss 0.0027276233832\n",
      "Epoch 6::Minibatch 662::LR 0.0884615384615 --> Loss 0.00195011277994\n",
      "Epoch 6::Minibatch 663::LR 0.0884615384615 --> Loss 0.00383569121361\n",
      "Epoch 6::Minibatch 664::LR 0.0884615384615 --> Loss 0.00369775215785\n",
      "Epoch 6::Minibatch 665::LR 0.0884615384615 --> Loss 0.000962665975094\n",
      "Epoch 6::Minibatch 666::LR 0.0884615384615 --> Loss 0.00402182579041\n",
      "Epoch 6::Minibatch 667::LR 0.0884615384615 --> Loss 0.0027221373717\n",
      "Epoch 6::Minibatch 668::LR 0.0884615384615 --> Loss 0.00762265602748\n",
      "Epoch 6::Minibatch 669::LR 0.0884615384615 --> Loss 0.00120734920104\n",
      "Epoch 6::Minibatch 670::LR 0.0884615384615 --> Loss 0.00150019059579\n",
      "Epoch 6::Minibatch 671::LR 0.0884615384615 --> Loss 0.00572933077812\n",
      "Epoch 6::Minibatch 672::LR 0.0884615384615 --> Loss 0.00426596999168\n",
      "Epoch 6::Minibatch 673::LR 0.0884615384615 --> Loss 0.00174453437328\n",
      "Epoch 6::Minibatch 674::LR 0.0884615384615 --> Loss 0.000662773797909\n",
      "Epoch 6::Minibatch 675::LR 0.0884615384615 --> Loss 0.00237238605817\n",
      "Epoch 6::Minibatch 676::LR 0.0884615384615 --> Loss 0.00236308137576\n",
      "Epoch 6::Minibatch 677::LR 0.0884615384615 --> Loss 0.00310366272926\n",
      "Epoch 6::Minibatch 678::LR 0.0884615384615 --> Loss 0.00209315697352\n",
      "Epoch 6::Minibatch 679::LR 0.0884615384615 --> Loss 0.00373943249385\n",
      "Epoch 6::Minibatch 680::LR 0.0884615384615 --> Loss 0.00227921704451\n",
      "Epoch 6::Minibatch 681::LR 0.0884615384615 --> Loss 0.00255706946055\n",
      "Epoch 6::Minibatch 682::LR 0.0884615384615 --> Loss 0.000859523912271\n",
      "Epoch 6::Minibatch 683::LR 0.0884615384615 --> Loss 0.00258577187856\n",
      "Epoch 6::Minibatch 684::LR 0.0884615384615 --> Loss 0.00249779105186\n",
      "Epoch 6::Minibatch 685::LR 0.0884615384615 --> Loss 0.00310467898846\n",
      "Epoch 6::Minibatch 686::LR 0.0884615384615 --> Loss 0.00159048308929\n",
      "Epoch 6::Minibatch 687::LR 0.0884615384615 --> Loss 0.000919162929058\n",
      "Epoch 6::Minibatch 688::LR 0.0884615384615 --> Loss 0.00283399422963\n",
      "Epoch 6::Minibatch 689::LR 0.0884615384615 --> Loss 0.00268706997236\n",
      "Epoch 6::Minibatch 690::LR 0.0884615384615 --> Loss 0.00201324164867\n",
      "Epoch 6::Minibatch 691::LR 0.0884615384615 --> Loss 0.000733898878098\n",
      "Epoch 6::Minibatch 692::LR 0.0884615384615 --> Loss 0.00262586534023\n",
      "Epoch 6::Minibatch 693::LR 0.0884615384615 --> Loss 0.00269246141116\n",
      "Epoch 6::Minibatch 694::LR 0.0884615384615 --> Loss 0.00311807890733\n",
      "Epoch 6::Minibatch 695::LR 0.0884615384615 --> Loss 0.0018153077364\n",
      "Epoch 6::Minibatch 696::LR 0.0884615384615 --> Loss 0.00207122087479\n",
      "Epoch 6::Minibatch 697::LR 0.0884615384615 --> Loss 0.00147475083669\n",
      "Epoch 6::Minibatch 698::LR 0.0884615384615 --> Loss 0.00166545192401\n",
      "Epoch 6::Minibatch 699::LR 0.0884615384615 --> Loss 0.00398265878359\n",
      "Epoch 6::Minibatch 700::LR 0.0884615384615 --> Loss 0.00278108417988\n",
      "Epoch 6::Minibatch 701::LR 0.0884615384615 --> Loss 0.00213451445103\n",
      "Epoch 6::Minibatch 702::LR 0.0884615384615 --> Loss 0.00178776999315\n",
      "Epoch 6::Minibatch 703::LR 0.0884615384615 --> Loss 0.00421234210332\n",
      "Epoch 6::Minibatch 704::LR 0.0884615384615 --> Loss 0.00187255005042\n",
      "Epoch 6::Minibatch 705::LR 0.0884615384615 --> Loss 0.00287718435129\n",
      "Epoch 6::Minibatch 706::LR 0.0884615384615 --> Loss 0.00223031163216\n",
      "Epoch 6::Minibatch 707::LR 0.0884615384615 --> Loss 0.00128736793995\n",
      "Epoch 6::Minibatch 708::LR 0.0884615384615 --> Loss 0.00181125005086\n",
      "Epoch 6::Minibatch 709::LR 0.0884615384615 --> Loss 0.00182803928852\n",
      "Epoch 6::Minibatch 710::LR 0.0884615384615 --> Loss 0.00250152568022\n",
      "Epoch 6::Minibatch 711::LR 0.0884615384615 --> Loss 0.00192912379901\n",
      "Epoch 6::Minibatch 712::LR 0.0884615384615 --> Loss 0.00141006290913\n",
      "Epoch 6::Minibatch 713::LR 0.0884615384615 --> Loss 0.00179021398226\n",
      "Epoch 6::Minibatch 714::LR 0.0884615384615 --> Loss 0.00272886653741\n",
      "Epoch 6::Minibatch 715::LR 0.0884615384615 --> Loss 0.0029961558183\n",
      "Epoch 6::Minibatch 716::LR 0.0884615384615 --> Loss 0.0016565455993\n",
      "Epoch 6::Minibatch 717::LR 0.0884615384615 --> Loss 0.00166756888231\n",
      "Epoch 6::Minibatch 718::LR 0.0884615384615 --> Loss 0.00135143607855\n",
      "Epoch 6::Minibatch 719::LR 0.0884615384615 --> Loss 0.00174200574557\n",
      "Epoch 6::Minibatch 720::LR 0.0884615384615 --> Loss 0.00250613172849\n",
      "Epoch 6::Minibatch 721::LR 0.0884615384615 --> Loss 0.000737096567949\n",
      "Epoch 6::Minibatch 722::LR 0.0884615384615 --> Loss 0.00505823890368\n",
      "Epoch 6::Minibatch 723::LR 0.0884615384615 --> Loss 0.0049111477534\n",
      "Epoch 6::Minibatch 724::LR 0.0884615384615 --> Loss 0.00107263187567\n",
      "Epoch 6::Minibatch 725::LR 0.0884615384615 --> Loss 0.00242035170396\n",
      "Epoch 6::Minibatch 726::LR 0.0884615384615 --> Loss 0.00530074040095\n",
      "Epoch 6::Minibatch 727::LR 0.0884615384615 --> Loss 0.00304224669933\n",
      "Epoch 6::Minibatch 728::LR 0.0884615384615 --> Loss 0.000754996935527\n",
      "Epoch 6::Minibatch 729::LR 0.0884615384615 --> Loss 0.000899345576763\n",
      "Epoch 6::Minibatch 730::LR 0.0884615384615 --> Loss 0.00266838053862\n",
      "Epoch 6::Minibatch 731::LR 0.0884615384615 --> Loss 0.00252668519815\n",
      "Epoch 6::Minibatch 732::LR 0.0884615384615 --> Loss 0.00244194308917\n",
      "Epoch 6::Minibatch 733::LR 0.0884615384615 --> Loss 0.000915380418301\n",
      "Epoch 6::Minibatch 734::LR 0.0884615384615 --> Loss 0.00196099559466\n",
      "Epoch 6::Minibatch 735::LR 0.0884615384615 --> Loss 0.00247182607651\n",
      "Epoch 6::Minibatch 736::LR 0.0884615384615 --> Loss 0.00351517717044\n",
      "Epoch 6::Minibatch 737::LR 0.0884615384615 --> Loss 0.00324215690295\n",
      "Epoch 6::Minibatch 738::LR 0.0884615384615 --> Loss 0.00184721668561\n",
      "Epoch 6::Minibatch 739::LR 0.0884615384615 --> Loss 0.00255279203256\n",
      "Epoch 6::Minibatch 740::LR 0.0884615384615 --> Loss 0.0038637928168\n",
      "Epoch 6::Minibatch 741::LR 0.0884615384615 --> Loss 0.00289849082629\n",
      "Epoch 6::Minibatch 742::LR 0.0884615384615 --> Loss 0.00222204864025\n",
      "Epoch 6::Minibatch 743::LR 0.0884615384615 --> Loss 0.00137253870567\n",
      "Epoch 6::Minibatch 744::LR 0.0884615384615 --> Loss 0.00188702543577\n",
      "Epoch 6::Minibatch 745::LR 0.0884615384615 --> Loss 0.00292094786962\n",
      "Epoch 6::Minibatch 746::LR 0.0884615384615 --> Loss 0.00313459694386\n",
      "Epoch 6::Minibatch 747::LR 0.0884615384615 --> Loss 0.00184403936068\n",
      "Epoch 6::Minibatch 748::LR 0.0884615384615 --> Loss 0.000752697537343\n",
      "Epoch 6::Minibatch 749::LR 0.0884615384615 --> Loss 0.00174478431543\n",
      "Epoch 6::Minibatch 750::LR 0.0884615384615 --> Loss 0.00255420664946\n",
      "Epoch 6::Minibatch 751::LR 0.0884615384615 --> Loss 0.00272749265035\n",
      "Epoch 6::Minibatch 752::LR 0.0884615384615 --> Loss 0.00112620780865\n",
      "Epoch 6::Minibatch 753::LR 0.0884615384615 --> Loss 0.00234121978283\n",
      "Epoch 6::Minibatch 754::LR 0.0884615384615 --> Loss 0.00243304391702\n",
      "Epoch 6::Minibatch 755::LR 0.0884615384615 --> Loss 0.00271536608537\n",
      "Epoch 6::Minibatch 756::LR 0.0884615384615 --> Loss 0.00150085985661\n",
      "Epoch 6::Minibatch 757::LR 0.0884615384615 --> Loss 0.00101659109195\n",
      "Epoch 6::Minibatch 758::LR 0.0884615384615 --> Loss 0.00172226866086\n",
      "Epoch 6::Minibatch 759::LR 0.0884615384615 --> Loss 0.00396999160449\n",
      "Epoch 6::Minibatch 760::LR 0.0884615384615 --> Loss 0.00314964850744\n",
      "Epoch 6::Minibatch 761::LR 0.0884615384615 --> Loss 0.00648918151855\n",
      "Epoch 6::Minibatch 762::LR 0.0884615384615 --> Loss 0.00393801291784\n",
      "Epoch 6::Minibatch 763::LR 0.0884615384615 --> Loss 0.00383286237717\n",
      "Epoch 6::Minibatch 764::LR 0.0884615384615 --> Loss 0.00340883970261\n",
      "Epoch 6::Minibatch 765::LR 0.0884615384615 --> Loss 0.00145243257284\n",
      "Epoch 6::Minibatch 766::LR 0.0884615384615 --> Loss 0.0023457189401\n",
      "Epoch 6::Minibatch 767::LR 0.0884615384615 --> Loss 0.00513064702352\n",
      "Epoch 6::Minibatch 768::LR 0.0884615384615 --> Loss 0.00358356674512\n",
      "Epoch 6::Minibatch 769::LR 0.0884615384615 --> Loss 0.0020469758908\n",
      "Epoch 6::Minibatch 770::LR 0.0884615384615 --> Loss 0.00150461276372\n",
      "Epoch 6::Minibatch 771::LR 0.0884615384615 --> Loss 0.00394014080365\n",
      "Epoch 6::Minibatch 772::LR 0.0884615384615 --> Loss 0.0033851480484\n",
      "Epoch 6::Minibatch 773::LR 0.0884615384615 --> Loss 0.00326931834221\n",
      "Epoch 6::Minibatch 774::LR 0.0884615384615 --> Loss 0.00180248379707\n",
      "Epoch 6::Minibatch 775::LR 0.0884615384615 --> Loss 0.00474717696508\n",
      "Epoch 6::Minibatch 776::LR 0.0884615384615 --> Loss 0.00365855534871\n",
      "Epoch 6::Minibatch 777::LR 0.0884615384615 --> Loss 0.00803709030151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 778::LR 0.0884615384615 --> Loss 0.0116423074404\n",
      "Epoch 6::Minibatch 779::LR 0.0884615384615 --> Loss 0.00169689416885\n",
      "Epoch 6::Minibatch 780::LR 0.0884615384615 --> Loss 0.0017895557483\n",
      "Epoch 6::Minibatch 781::LR 0.0884615384615 --> Loss 0.00378185033798\n",
      "Epoch 6::Minibatch 782::LR 0.0884615384615 --> Loss 0.00440400838852\n",
      "Epoch 6::Minibatch 783::LR 0.0884615384615 --> Loss 0.00247949341933\n",
      "Epoch 6::Minibatch 784::LR 0.0884615384615 --> Loss 0.000857228140036\n",
      "Epoch 6::Minibatch 785::LR 0.0884615384615 --> Loss 0.004439702034\n",
      "Epoch 6::Minibatch 786::LR 0.0884615384615 --> Loss 0.00393972277641\n",
      "Epoch 6::Minibatch 787::LR 0.0884615384615 --> Loss 0.0031093664964\n",
      "Epoch 6::Minibatch 788::LR 0.0884615384615 --> Loss 0.00273649811745\n",
      "Epoch 6::Minibatch 789::LR 0.0884615384615 --> Loss 0.00084282497565\n",
      "Epoch 6::Minibatch 790::LR 0.0884615384615 --> Loss 0.00347550233205\n",
      "Epoch 6::Minibatch 791::LR 0.0884615384615 --> Loss 0.00413303097089\n",
      "Epoch 6::Minibatch 792::LR 0.0884615384615 --> Loss 0.00391753395398\n",
      "Epoch 6::Minibatch 793::LR 0.0884615384615 --> Loss 0.00230958461761\n",
      "Epoch 6::Minibatch 794::LR 0.0884615384615 --> Loss 0.0013381160299\n",
      "Epoch 6::Minibatch 795::LR 0.0884615384615 --> Loss 0.00377350727717\n",
      "Epoch 6::Minibatch 796::LR 0.0884615384615 --> Loss 0.00635219136874\n",
      "Epoch 6::Minibatch 797::LR 0.0884615384615 --> Loss 0.00904908180237\n",
      "Epoch 6::Minibatch 798::LR 0.0884615384615 --> Loss 0.00365748127302\n",
      "Epoch 6::Minibatch 799::LR 0.0884615384615 --> Loss 0.00290716211001\n",
      "Epoch 6::Minibatch 800::LR 0.0884615384615 --> Loss 0.00225375533104\n",
      "Epoch 6::Minibatch 801::LR 0.0884615384615 --> Loss 0.00423815687497\n",
      "Epoch 6::Minibatch 802::LR 0.0884615384615 --> Loss 0.00156852652629\n",
      "Epoch 6::Minibatch 803::LR 0.0884615384615 --> Loss 0.00282779256503\n",
      "Epoch 6::Minibatch 804::LR 0.0884615384615 --> Loss 0.00246779163678\n",
      "Epoch 6::Minibatch 805::LR 0.0884615384615 --> Loss 0.00249795595805\n",
      "Epoch 6::Minibatch 806::LR 0.0884615384615 --> Loss 0.00338628212611\n",
      "Epoch 6::Minibatch 807::LR 0.0884615384615 --> Loss 0.00321045021216\n",
      "Epoch 6::Minibatch 808::LR 0.0884615384615 --> Loss 0.00309687594573\n",
      "Epoch 6::Minibatch 809::LR 0.0884615384615 --> Loss 0.00480412165324\n",
      "Epoch 6::Minibatch 810::LR 0.0884615384615 --> Loss 0.00587428371112\n",
      "Epoch 6::Minibatch 811::LR 0.0884615384615 --> Loss 0.00548017223676\n",
      "Epoch 6::Minibatch 812::LR 0.0884615384615 --> Loss 0.00522395094236\n",
      "Epoch 6::Minibatch 813::LR 0.0884615384615 --> Loss 0.00468352278074\n",
      "Epoch 6::Minibatch 814::LR 0.0884615384615 --> Loss 0.00253840188185\n",
      "Epoch 6::Minibatch 815::LR 0.0884615384615 --> Loss 0.00445843180021\n",
      "Epoch 6::Minibatch 816::LR 0.0884615384615 --> Loss 0.00445083697637\n",
      "Epoch 6::Minibatch 817::LR 0.0884615384615 --> Loss 0.00507703264554\n",
      "Epoch 6::Minibatch 818::LR 0.0884615384615 --> Loss 0.00146311084429\n",
      "Epoch 6::Minibatch 819::LR 0.0884615384615 --> Loss 0.000831679006418\n",
      "Epoch 6::Minibatch 820::LR 0.0884615384615 --> Loss 0.00562128901482\n",
      "Epoch 6::Minibatch 821::LR 0.0884615384615 --> Loss 0.0033935157458\n",
      "Epoch 6::Minibatch 822::LR 0.0884615384615 --> Loss 0.00404963930448\n",
      "Epoch 6::Minibatch 823::LR 0.0884615384615 --> Loss 0.00144426465034\n",
      "Epoch 6::Minibatch 824::LR 0.0884615384615 --> Loss 0.00155695209901\n",
      "Epoch 6::Minibatch 825::LR 0.0884615384615 --> Loss 0.00390054066976\n",
      "Epoch 6::Minibatch 826::LR 0.0884615384615 --> Loss 0.003849508365\n",
      "Epoch 6::Minibatch 827::LR 0.0884615384615 --> Loss 0.00233048597972\n",
      "Epoch 6::Minibatch 828::LR 0.0884615384615 --> Loss 0.000772699862719\n",
      "Epoch 6::Minibatch 829::LR 0.0884615384615 --> Loss 0.00256076733271\n",
      "Epoch 6::Minibatch 830::LR 0.0884615384615 --> Loss 0.00469570557276\n",
      "Epoch 6::Minibatch 831::LR 0.0884615384615 --> Loss 0.00269932746887\n",
      "Epoch 6::Minibatch 832::LR 0.0884615384615 --> Loss 0.0024139414231\n",
      "Epoch 6::Minibatch 833::LR 0.0884615384615 --> Loss 0.00195147196452\n",
      "Epoch 6::Minibatch 834::LR 0.0884615384615 --> Loss 0.000875199039777\n",
      "Epoch 6::Minibatch 835::LR 0.0884615384615 --> Loss 0.00393007357915\n",
      "Epoch 6::Minibatch 836::LR 0.0884615384615 --> Loss 0.00389493346214\n",
      "Epoch 6::Minibatch 837::LR 0.0884615384615 --> Loss 0.0024650345246\n",
      "Epoch 6::Minibatch 838::LR 0.0884615384615 --> Loss 0.000776058485111\n",
      "Epoch 6::Minibatch 839::LR 0.0884615384615 --> Loss 0.00255148231983\n",
      "Epoch 6::Minibatch 840::LR 0.0884615384615 --> Loss 0.00310995101929\n",
      "Epoch 6::Minibatch 841::LR 0.0884615384615 --> Loss 0.00313816050688\n",
      "Epoch 6::Minibatch 842::LR 0.0884615384615 --> Loss 0.00233090321223\n",
      "Epoch 6::Minibatch 843::LR 0.0884615384615 --> Loss 0.00111681371927\n",
      "Epoch 6::Minibatch 844::LR 0.0884615384615 --> Loss 0.00165833095709\n",
      "Epoch 6::Minibatch 845::LR 0.0884615384615 --> Loss 0.00451087196668\n",
      "Epoch 6::Minibatch 846::LR 0.0884615384615 --> Loss 0.00180567880472\n",
      "Epoch 6::Minibatch 847::LR 0.0884615384615 --> Loss 0.00253290255864\n",
      "Epoch 6::Minibatch 848::LR 0.0884615384615 --> Loss 0.0011189109087\n",
      "Epoch 6::Minibatch 849::LR 0.0884615384615 --> Loss 0.00200236777465\n",
      "Epoch 6::Minibatch 850::LR 0.0884615384615 --> Loss 0.0032990171512\n",
      "Epoch 6::Minibatch 851::LR 0.0884615384615 --> Loss 0.00293440282345\n",
      "Epoch 6::Minibatch 852::LR 0.0884615384615 --> Loss 0.00116996635993\n",
      "Epoch 6::Minibatch 853::LR 0.0884615384615 --> Loss 0.00141721993685\n",
      "Epoch 6::Minibatch 854::LR 0.0884615384615 --> Loss 0.00260726650556\n",
      "Epoch 6::Minibatch 855::LR 0.0884615384615 --> Loss 0.0022792895635\n",
      "Epoch 6::Minibatch 856::LR 0.0884615384615 --> Loss 0.00185691873233\n",
      "Epoch 6::Minibatch 857::LR 0.0884615384615 --> Loss 0.00128261893988\n",
      "Epoch 6::Minibatch 858::LR 0.0884615384615 --> Loss 0.000693074117104\n",
      "Epoch 6::Minibatch 859::LR 0.0884615384615 --> Loss 0.00193179229895\n",
      "Epoch 6::Minibatch 860::LR 0.0884615384615 --> Loss 0.00126178095738\n",
      "Epoch 6::Minibatch 861::LR 0.0884615384615 --> Loss 0.00100242137909\n",
      "Epoch 6::Minibatch 862::LR 0.0884615384615 --> Loss 0.00370595971743\n",
      "Epoch 6::Minibatch 863::LR 0.0884615384615 --> Loss 0.00342707157135\n",
      "Epoch 6::Minibatch 864::LR 0.0884615384615 --> Loss 0.00314462502797\n",
      "Epoch 6::Minibatch 865::LR 0.0884615384615 --> Loss 0.00052735850215\n",
      "Epoch 6::Minibatch 866::LR 0.0884615384615 --> Loss 0.00229355692863\n",
      "Epoch 6::Minibatch 867::LR 0.0884615384615 --> Loss 0.00309230466684\n",
      "Epoch 6::Minibatch 868::LR 0.0884615384615 --> Loss 0.00262308359146\n",
      "Epoch 6::Minibatch 869::LR 0.0884615384615 --> Loss 0.00213772992293\n",
      "Epoch 6::Minibatch 870::LR 0.0884615384615 --> Loss 0.00382084488869\n",
      "Epoch 6::Minibatch 871::LR 0.0884615384615 --> Loss 0.00158726920684\n",
      "Epoch 6::Minibatch 872::LR 0.0884615384615 --> Loss 0.00245543082555\n",
      "Epoch 6::Minibatch 873::LR 0.0884615384615 --> Loss 0.00258426467578\n",
      "Epoch 6::Minibatch 874::LR 0.0884615384615 --> Loss 0.00645926833153\n",
      "Epoch 6::Minibatch 875::LR 0.0884615384615 --> Loss 0.000561830451091\n",
      "Epoch 6::Minibatch 876::LR 0.0884615384615 --> Loss 0.00396800676982\n",
      "Epoch 6::Minibatch 877::LR 0.0884615384615 --> Loss 0.00934116681417\n",
      "Epoch 6::Minibatch 878::LR 0.0884615384615 --> Loss 0.00353637456894\n",
      "Epoch 6::Minibatch 879::LR 0.0884615384615 --> Loss 0.00431008577347\n",
      "Epoch 6::Minibatch 880::LR 0.0884615384615 --> Loss 0.00506033658981\n",
      "Epoch 6::Minibatch 881::LR 0.0884615384615 --> Loss 0.00438784003258\n",
      "Epoch 6::Minibatch 882::LR 0.0884615384615 --> Loss 0.00215385993322\n",
      "Epoch 6::Minibatch 883::LR 0.0884615384615 --> Loss 0.003437337478\n",
      "Epoch 6::Minibatch 884::LR 0.0884615384615 --> Loss 0.00277509192626\n",
      "Epoch 6::Minibatch 885::LR 0.0884615384615 --> Loss 0.00269597947598\n",
      "Epoch 6::Minibatch 886::LR 0.0884615384615 --> Loss 0.00109108189742\n",
      "Epoch 6::Minibatch 887::LR 0.0884615384615 --> Loss 0.00583919843038\n",
      "Epoch 6::Minibatch 888::LR 0.0884615384615 --> Loss 0.0028010849158\n",
      "Epoch 6::Minibatch 889::LR 0.0884615384615 --> Loss 0.00387264370918\n",
      "Epoch 6::Minibatch 890::LR 0.0884615384615 --> Loss 0.00512135028839\n",
      "Epoch 6::Minibatch 891::LR 0.0884615384615 --> Loss 0.00244311571121\n",
      "Epoch 6::Minibatch 892::LR 0.0884615384615 --> Loss 0.00113105128209\n",
      "Epoch 6::Minibatch 893::LR 0.0884615384615 --> Loss 0.00282327353954\n",
      "Epoch 6::Minibatch 894::LR 0.0884615384615 --> Loss 0.00256907224655\n",
      "Epoch 6::Minibatch 895::LR 0.0884615384615 --> Loss 0.00275209903717\n",
      "Epoch 6::Minibatch 896::LR 0.0884615384615 --> Loss 0.00175306578477\n",
      "Epoch 6::Minibatch 897::LR 0.0884615384615 --> Loss 0.000931780338287\n",
      "Epoch 6::Minibatch 898::LR 0.0884615384615 --> Loss 0.00250285923481\n",
      "Epoch 6::Minibatch 899::LR 0.0884615384615 --> Loss 0.00261548101902\n",
      "Epoch 6::Minibatch 900::LR 0.0884615384615 --> Loss 0.00354776740074\n",
      "Epoch 6::Minibatch 901::LR 0.0884615384615 --> Loss 0.000737118323644\n",
      "Epoch 6::Minibatch 902::LR 0.0884615384615 --> Loss 0.0015254727006\n",
      "Epoch 6::Minibatch 903::LR 0.0884615384615 --> Loss 0.00298624992371\n",
      "Epoch 6::Minibatch 904::LR 0.0884615384615 --> Loss 0.00249440630277\n",
      "Epoch 6::Minibatch 905::LR 0.0884615384615 --> Loss 0.00155026266972\n",
      "Epoch 6::Minibatch 906::LR 0.0884615384615 --> Loss 0.00120585262775\n",
      "Epoch 6::Minibatch 907::LR 0.0884615384615 --> Loss 0.00163540065289\n",
      "Epoch 6::Minibatch 908::LR 0.0884615384615 --> Loss 0.00280256887277\n",
      "Epoch 6::Minibatch 909::LR 0.0884615384615 --> Loss 0.00253021995227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6::Minibatch 910::LR 0.0884615384615 --> Loss 0.000913651287556\n",
      "Epoch 6::Minibatch 911::LR 0.0884615384615 --> Loss 0.0013051383694\n",
      "Epoch 6::Minibatch 912::LR 0.0884615384615 --> Loss 0.00244651377201\n",
      "Epoch 6::Minibatch 913::LR 0.0884615384615 --> Loss 0.00231410602729\n",
      "Epoch 6::Minibatch 914::LR 0.0884615384615 --> Loss 0.00142194122076\n",
      "Epoch 6::Minibatch 915::LR 0.0884615384615 --> Loss 0.000562342107296\n",
      "Epoch 6::Minibatch 916::LR 0.0884615384615 --> Loss 0.00298444370429\n",
      "Epoch 6::Minibatch 917::LR 0.0884615384615 --> Loss 0.00447312712669\n",
      "Epoch 6::Minibatch 918::LR 0.0884615384615 --> Loss 0.00632693131765\n",
      "Epoch 6::Minibatch 919::LR 0.0884615384615 --> Loss 0.00116273472706\n",
      "Epoch 6::Minibatch 920::LR 0.0884615384615 --> Loss 0.0100354711215\n",
      "Epoch 6::Minibatch 921::LR 0.0884615384615 --> Loss 0.00338593482971\n",
      "Epoch 6::Minibatch 922::LR 0.0884615384615 --> Loss 0.00356321533521\n",
      "Epoch 6::Minibatch 923::LR 0.0884615384615 --> Loss 0.00202973465125\n",
      "Epoch 6::Minibatch 924::LR 0.0884615384615 --> Loss 0.00394954045614\n",
      "Epoch 6::Minibatch 925::LR 0.0884615384615 --> Loss 0.00338618397713\n",
      "Epoch 6::Minibatch 926::LR 0.0884615384615 --> Loss 0.00582770268122\n",
      "Epoch 6::Minibatch 927::LR 0.0884615384615 --> Loss 0.00924990971883\n",
      "Epoch 6::Minibatch 928::LR 0.0884615384615 --> Loss 0.00723291238149\n",
      "Epoch 6::Minibatch 929::LR 0.0884615384615 --> Loss 0.0100506726901\n",
      "Epoch 6::Minibatch 930::LR 0.0884615384615 --> Loss 0.00684712171555\n",
      "Epoch 6::Minibatch 931::LR 0.0884615384615 --> Loss 0.00421373009682\n",
      "Epoch 6::Minibatch 932::LR 0.0884615384615 --> Loss 0.00943360726039\n",
      "Epoch 6::Minibatch 933::LR 0.0884615384615 --> Loss 0.00482863267263\n",
      "Epoch 6::Minibatch 934::LR 0.0884615384615 --> Loss 0.0063199142615\n",
      "Epoch 6::Minibatch 935::LR 0.0884615384615 --> Loss 0.00799820502599\n",
      "Epoch 6::Minibatch 936::LR 0.0884615384615 --> Loss 0.00228608151277\n",
      "Epoch 6::Minibatch 937::LR 0.0884615384615 --> Loss 0.00449366569519\n",
      "Epoch 6::Minibatch 938::LR 0.0884615384615 --> Loss 0.00438228408496\n",
      "Epoch 6::Minibatch 939::LR 0.0884615384615 --> Loss 0.0043886633714\n",
      "Epoch 6::Minibatch 940::LR 0.0884615384615 --> Loss 0.0013294206063\n",
      "Epoch 6::Minibatch 941::LR 0.0884615384615 --> Loss 0.00112076163292\n",
      "Epoch 6::Minibatch 942::LR 0.0884615384615 --> Loss 0.00257998843988\n",
      "Epoch 6::Minibatch 943::LR 0.0884615384615 --> Loss 0.00367776314418\n",
      "Epoch 6::Minibatch 944::LR 0.0884615384615 --> Loss 0.00279025952021\n",
      "Epoch 6::Minibatch 945::LR 0.0884615384615 --> Loss 0.001725405852\n",
      "Epoch 6::Minibatch 946::LR 0.0884615384615 --> Loss 0.00400804400444\n",
      "Epoch 6::Minibatch 947::LR 0.0884615384615 --> Loss 0.00345699469248\n",
      "Epoch 6::Minibatch 948::LR 0.0884615384615 --> Loss 0.00581998268763\n",
      "Epoch 6::Minibatch 949::LR 0.0884615384615 --> Loss 0.00216281414032\n",
      "Epoch 6::Minibatch 950::LR 0.0884615384615 --> Loss 0.000822242399057\n",
      "Epoch 6::Minibatch 951::LR 0.0884615384615 --> Loss 0.0035354355971\n",
      "Epoch 6::Minibatch 952::LR 0.0884615384615 --> Loss 0.00262197852135\n",
      "Epoch 6::Minibatch 953::LR 0.0884615384615 --> Loss 0.00142433861891\n",
      "Epoch 6::Minibatch 954::LR 0.0884615384615 --> Loss 0.00104084471862\n",
      "Epoch 6::Minibatch 955::LR 0.0884615384615 --> Loss 0.00267299016317\n",
      "Epoch 6::Minibatch 956::LR 0.0884615384615 --> Loss 0.00449177225431\n",
      "Epoch 6::Minibatch 957::LR 0.0884615384615 --> Loss 0.0020411280791\n",
      "Epoch 6::Minibatch 958::LR 0.0884615384615 --> Loss 0.00277495761712\n",
      "Epoch 6::Minibatch 959::LR 0.0884615384615 --> Loss 0.0033781627814\n",
      "Epoch 6::Minibatch 960::LR 0.0884615384615 --> Loss 0.0071805413564\n",
      "Epoch 6::Minibatch 961::LR 0.0884615384615 --> Loss 0.00361052513123\n",
      "Epoch 6::Minibatch 962::LR 0.0884615384615 --> Loss 0.00332136809826\n",
      "Epoch 6::Minibatch 963::LR 0.0884615384615 --> Loss 0.00136260171731\n",
      "Epoch 6::Minibatch 964::LR 0.0884615384615 --> Loss 0.00269969006379\n",
      "Epoch 6::Minibatch 965::LR 0.0884615384615 --> Loss 0.00940852403641\n",
      "Epoch 6::Minibatch 966::LR 0.0884615384615 --> Loss 0.00690693298976\n",
      "Epoch 6::Minibatch 967::LR 0.0884615384615 --> Loss 0.0023822871844\n",
      "Epoch 6::Minibatch 968::LR 0.0884615384615 --> Loss 0.00227010786533\n",
      "Epoch 6::Minibatch 969::LR 0.0884615384615 --> Loss 0.00816955645879\n",
      "Epoch 6::Minibatch 970::LR 0.0884615384615 --> Loss 0.0065243935585\n",
      "Epoch 6::Minibatch 971::LR 0.0884615384615 --> Loss 0.00390932122866\n",
      "Epoch 6::Minibatch 972::LR 0.0884615384615 --> Loss 0.00878347396851\n",
      "Epoch 6::Minibatch 973::LR 0.0884615384615 --> Loss 0.00964784065882\n",
      "Epoch 6::Minibatch 974::LR 0.0884615384615 --> Loss 0.00601142724355\n",
      "Epoch 6::Minibatch 975::LR 0.0884615384615 --> Loss 0.00503905455271\n",
      "Epoch 6::Minibatch 976::LR 0.0884615384615 --> Loss 0.0044789592425\n",
      "Epoch 6::Minibatch 977::LR 0.0884615384615 --> Loss 0.00449079950651\n",
      "Epoch 6::Minibatch 978::LR 0.0884615384615 --> Loss 0.00436878204346\n",
      "Epoch 6::Minibatch 979::LR 0.0884615384615 --> Loss 0.00433624943097\n",
      "Epoch 6::Minibatch 980::LR 0.0884615384615 --> Loss 0.00407321572304\n",
      "Epoch 6::Minibatch 981::LR 0.0884615384615 --> Loss 0.00537654519081\n",
      "Epoch 6::Minibatch 982::LR 0.0884615384615 --> Loss 0.00770077546438\n",
      "Epoch 6::Minibatch 983::LR 0.0884615384615 --> Loss 0.00339168548584\n",
      "Epoch 6::Minibatch 984::LR 0.0884615384615 --> Loss 0.0035427069664\n",
      "Epoch 6::Minibatch 985::LR 0.0884615384615 --> Loss 0.00482020656268\n",
      "Epoch 6::Minibatch 986::LR 0.0884615384615 --> Loss 0.00438116550446\n",
      "Epoch 6::Minibatch 987::LR 0.0884615384615 --> Loss 0.00484232584635\n",
      "Epoch 6::Minibatch 988::LR 0.0884615384615 --> Loss 0.00362759510676\n",
      "Epoch 6::Minibatch 989::LR 0.0884615384615 --> Loss 0.0035348657767\n",
      "Epoch 6::Minibatch 990::LR 0.0884615384615 --> Loss 0.00359659353892\n",
      "Epoch 6::Minibatch 991::LR 0.0884615384615 --> Loss 0.00188978294532\n",
      "Epoch 6::Minibatch 992::LR 0.0884615384615 --> Loss 0.00219528456529\n",
      "Epoch 6::Minibatch 993::LR 0.0884615384615 --> Loss 0.00359028577805\n",
      "Epoch 6::Minibatch 994::LR 0.0884615384615 --> Loss 0.00218116343021\n",
      "Epoch 6::Minibatch 995::LR 0.0884615384615 --> Loss 0.000953424870968\n",
      "Epoch 6::Minibatch 996::LR 0.0884615384615 --> Loss 0.00355044126511\n",
      "Epoch 6::Minibatch 997::LR 0.0884615384615 --> Loss 0.00238703807195\n",
      "Epoch 6::Minibatch 998::LR 0.0884615384615 --> Loss 0.0023609606425\n",
      "Epoch 6::Minibatch 999::LR 0.0884615384615 --> Loss 0.00192004064719\n",
      "Epoch 6::Minibatch 1000::LR 0.0884615384615 --> Loss 0.00230195204417\n",
      "Epoch 6::Minibatch 1001::LR 0.0884615384615 --> Loss 0.00193409144878\n",
      "Epoch 6::Minibatch 1002::LR 0.0884615384615 --> Loss 0.00412195722262\n",
      "Epoch 6::Minibatch 1003::LR 0.0884615384615 --> Loss 0.00449692130089\n",
      "Epoch 6::Minibatch 1004::LR 0.0884615384615 --> Loss 0.00110230515401\n",
      "Epoch 6::Minibatch 1005::LR 0.0884615384615 --> Loss 0.0053824810187\n",
      "Epoch 6::Minibatch 1006::LR 0.0884615384615 --> Loss 0.00377656300863\n",
      "Epoch 6::Minibatch 1007::LR 0.0884615384615 --> Loss 0.00361441612244\n",
      "Epoch 6::Minibatch 1008::LR 0.0884615384615 --> Loss 0.00104200253884\n",
      "Epoch 6::Minibatch 1009::LR 0.0884615384615 --> Loss 0.00233410259088\n",
      "Epoch 6::Minibatch 1010::LR 0.0884615384615 --> Loss 0.00218546728293\n",
      "Epoch 6::Minibatch 1011::LR 0.0884615384615 --> Loss 0.00493315935135\n",
      "Epoch 6::Minibatch 1012::LR 0.0884615384615 --> Loss 0.002599645257\n",
      "Epoch 6::Minibatch 1013::LR 0.0884615384615 --> Loss 0.0049253320694\n",
      "Epoch 6::Minibatch 1014::LR 0.0884615384615 --> Loss 0.004762951533\n",
      "Epoch 6::Minibatch 1015::LR 0.0884615384615 --> Loss 0.00197174191475\n",
      "Epoch 6::Minibatch 1016::LR 0.0884615384615 --> Loss 0.00558340469996\n",
      "Epoch 6::Minibatch 1017::LR 0.0884615384615 --> Loss 0.00367986520131\n",
      "Epoch 6::Minibatch 1018::LR 0.0884615384615 --> Loss 0.0036226729552\n",
      "Epoch 6::Minibatch 1019::LR 0.0884615384615 --> Loss 0.00289474546909\n",
      "Epoch 6::Minibatch 1020::LR 0.0884615384615 --> Loss 0.00276856283347\n",
      "Epoch 6::Minibatch 1021::LR 0.0884615384615 --> Loss 0.00255320032438\n",
      "Epoch 6::Minibatch 1022::LR 0.0884615384615 --> Loss 0.00204532583555\n",
      "Epoch 6::Minibatch 1023::LR 0.0884615384615 --> Loss 0.00176243086656\n",
      "Epoch 6::Minibatch 1024::LR 0.0884615384615 --> Loss 0.00167173226674\n",
      "Epoch 6::Minibatch 1025::LR 0.0884615384615 --> Loss 0.00173675835133\n",
      "Epoch 6::Minibatch 1026::LR 0.0884615384615 --> Loss 0.00126758277416\n",
      "Epoch 6::Minibatch 1027::LR 0.0884615384615 --> Loss 0.00129841844241\n",
      "Epoch 6::Minibatch 1028::LR 0.0884615384615 --> Loss 0.00105150967836\n",
      "Epoch 6::Minibatch 1029::LR 0.0884615384615 --> Loss 0.000949279268583\n",
      "Epoch 6::Minibatch 1030::LR 0.0884615384615 --> Loss 0.00115123838186\n",
      "Epoch 6::Minibatch 1031::LR 0.0884615384615 --> Loss 0.000891555051009\n",
      "Epoch 6::Minibatch 1032::LR 0.0884615384615 --> Loss 0.000858583748341\n",
      "Epoch 6::Minibatch 1033::LR 0.0884615384615 --> Loss 0.000718020796776\n",
      "Epoch 6::Minibatch 1034::LR 0.0884615384615 --> Loss 0.000774412353834\n",
      "Epoch 6::Minibatch 1035::LR 0.0884615384615 --> Loss 0.00067037632068\n",
      "Epoch 6::Minibatch 1036::LR 0.0884615384615 --> Loss 0.000531681329012\n",
      "Epoch 6::Minibatch 1037::LR 0.0884615384615 --> Loss 0.000608973403772\n",
      "Epoch 6::Minibatch 1038::LR 0.0884615384615 --> Loss 0.00137917329868\n",
      "Epoch 6::Minibatch 1039::LR 0.0884615384615 --> Loss 0.00122086703777\n",
      "Epoch 6::Minibatch 1040::LR 0.0884615384615 --> Loss 0.000600043237209\n",
      "Epoch 6::Minibatch 1041::LR 0.0884615384615 --> Loss 0.000698054830233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 1::LR 0.0861538461538 --> Loss 0.0110504682859\n",
      "Epoch 7::Minibatch 2::LR 0.0861538461538 --> Loss 0.00670746485392\n",
      "Epoch 7::Minibatch 3::LR 0.0861538461538 --> Loss 0.00492956757545\n",
      "Epoch 7::Minibatch 4::LR 0.0861538461538 --> Loss 0.00444543679555\n",
      "Epoch 7::Minibatch 5::LR 0.0861538461538 --> Loss 0.00453615705172\n",
      "Epoch 7::Minibatch 6::LR 0.0861538461538 --> Loss 0.00261404732863\n",
      "Epoch 7::Minibatch 7::LR 0.0861538461538 --> Loss 0.00734215736389\n",
      "Epoch 7::Minibatch 8::LR 0.0861538461538 --> Loss 0.00735659917196\n",
      "Epoch 7::Minibatch 9::LR 0.0861538461538 --> Loss 0.00542651176453\n",
      "Epoch 7::Minibatch 10::LR 0.0861538461538 --> Loss 0.00319859564304\n",
      "Epoch 7::Minibatch 11::LR 0.0861538461538 --> Loss 0.00258181631565\n",
      "Epoch 7::Minibatch 12::LR 0.0861538461538 --> Loss 0.00333148519198\n",
      "Epoch 7::Minibatch 13::LR 0.0861538461538 --> Loss 0.00482742269834\n",
      "Epoch 7::Minibatch 14::LR 0.0861538461538 --> Loss 0.00453582127889\n",
      "Epoch 7::Minibatch 15::LR 0.0861538461538 --> Loss 0.00336411396662\n",
      "Epoch 7::Minibatch 16::LR 0.0861538461538 --> Loss 0.000923878649871\n",
      "Epoch 7::Minibatch 17::LR 0.0861538461538 --> Loss 0.00275695800781\n",
      "Epoch 7::Minibatch 18::LR 0.0861538461538 --> Loss 0.0023759218057\n",
      "Epoch 7::Minibatch 19::LR 0.0861538461538 --> Loss 0.000910978118579\n",
      "Epoch 7::Minibatch 20::LR 0.0861538461538 --> Loss 0.00139160017172\n",
      "Epoch 7::Minibatch 21::LR 0.0861538461538 --> Loss 0.00308293203513\n",
      "Epoch 7::Minibatch 22::LR 0.0861538461538 --> Loss 0.0024699139595\n",
      "Epoch 7::Minibatch 23::LR 0.0861538461538 --> Loss 0.000881675084432\n",
      "Epoch 7::Minibatch 24::LR 0.0861538461538 --> Loss 0.000428723792235\n",
      "Epoch 7::Minibatch 25::LR 0.0861538461538 --> Loss 0.00119677186012\n",
      "Epoch 7::Minibatch 26::LR 0.0861538461538 --> Loss 0.00141671140989\n",
      "Epoch 7::Minibatch 27::LR 0.0861538461538 --> Loss 0.000981813867887\n",
      "Epoch 7::Minibatch 28::LR 0.0861538461538 --> Loss 0.000400829662879\n",
      "Epoch 7::Minibatch 29::LR 0.0861538461538 --> Loss 0.000397600705425\n",
      "Epoch 7::Minibatch 30::LR 0.0861538461538 --> Loss 0.000897232492765\n",
      "Epoch 7::Minibatch 31::LR 0.0861538461538 --> Loss 0.00133702963591\n",
      "Epoch 7::Minibatch 32::LR 0.0861538461538 --> Loss 0.00126161386569\n",
      "Epoch 7::Minibatch 33::LR 0.0861538461538 --> Loss 0.000804098943869\n",
      "Epoch 7::Minibatch 34::LR 0.0861538461538 --> Loss 0.00266693790754\n",
      "Epoch 7::Minibatch 35::LR 0.0861538461538 --> Loss 0.00426414410273\n",
      "Epoch 7::Minibatch 36::LR 0.0861538461538 --> Loss 0.00215282817682\n",
      "Epoch 7::Minibatch 37::LR 0.0861538461538 --> Loss 0.00059388846159\n",
      "Epoch 7::Minibatch 38::LR 0.0861538461538 --> Loss 0.000883853634199\n",
      "Epoch 7::Minibatch 39::LR 0.0861538461538 --> Loss 0.00238403697809\n",
      "Epoch 7::Minibatch 40::LR 0.0861538461538 --> Loss 0.00436466813087\n",
      "Epoch 7::Minibatch 41::LR 0.0861538461538 --> Loss 0.00356117963791\n",
      "Epoch 7::Minibatch 42::LR 0.0861538461538 --> Loss 0.00609209140142\n",
      "Epoch 7::Minibatch 43::LR 0.0861538461538 --> Loss 0.00186390260855\n",
      "Epoch 7::Minibatch 44::LR 0.0861538461538 --> Loss 0.00304893573125\n",
      "Epoch 7::Minibatch 45::LR 0.0861538461538 --> Loss 0.00267322321733\n",
      "Epoch 7::Minibatch 46::LR 0.0861538461538 --> Loss 0.00381066799164\n",
      "Epoch 7::Minibatch 47::LR 0.0861538461538 --> Loss 0.00539025306702\n",
      "Epoch 7::Minibatch 48::LR 0.0861538461538 --> Loss 0.00616594433784\n",
      "Epoch 7::Minibatch 49::LR 0.0861538461538 --> Loss 0.00592183510462\n",
      "Epoch 7::Minibatch 50::LR 0.0861538461538 --> Loss 0.00544366558393\n",
      "Epoch 7::Minibatch 51::LR 0.0861538461538 --> Loss 0.00929567972819\n",
      "Epoch 7::Minibatch 52::LR 0.0861538461538 --> Loss 0.00373567700386\n",
      "Epoch 7::Minibatch 53::LR 0.0861538461538 --> Loss 0.0036137342453\n",
      "Epoch 7::Minibatch 54::LR 0.0861538461538 --> Loss 0.00406902074814\n",
      "Epoch 7::Minibatch 55::LR 0.0861538461538 --> Loss 0.00129502207041\n",
      "Epoch 7::Minibatch 56::LR 0.0861538461538 --> Loss 0.00309979259968\n",
      "Epoch 7::Minibatch 57::LR 0.0861538461538 --> Loss 0.00642689069112\n",
      "Epoch 7::Minibatch 58::LR 0.0861538461538 --> Loss 0.00361157576243\n",
      "Epoch 7::Minibatch 59::LR 0.0861538461538 --> Loss 0.00333786805471\n",
      "Epoch 7::Minibatch 60::LR 0.0861538461538 --> Loss 0.00260897040367\n",
      "Epoch 7::Minibatch 61::LR 0.0861538461538 --> Loss 0.0012599136432\n",
      "Epoch 7::Minibatch 62::LR 0.0861538461538 --> Loss 0.0038796321551\n",
      "Epoch 7::Minibatch 63::LR 0.0861538461538 --> Loss 0.0024872080485\n",
      "Epoch 7::Minibatch 64::LR 0.0861538461538 --> Loss 0.00120523760716\n",
      "Epoch 7::Minibatch 65::LR 0.0861538461538 --> Loss 0.0025542730093\n",
      "Epoch 7::Minibatch 66::LR 0.0861538461538 --> Loss 0.00335933566093\n",
      "Epoch 7::Minibatch 67::LR 0.0861538461538 --> Loss 0.00305609563986\n",
      "Epoch 7::Minibatch 68::LR 0.0861538461538 --> Loss 0.0021535607179\n",
      "Epoch 7::Minibatch 69::LR 0.0861538461538 --> Loss 0.00397706230481\n",
      "Epoch 7::Minibatch 70::LR 0.0861538461538 --> Loss 0.00358038504918\n",
      "Epoch 7::Minibatch 71::LR 0.0861538461538 --> Loss 0.00250760753949\n",
      "Epoch 7::Minibatch 72::LR 0.0861538461538 --> Loss 0.000634569823742\n",
      "Epoch 7::Minibatch 73::LR 0.0861538461538 --> Loss 0.00393673141797\n",
      "Epoch 7::Minibatch 74::LR 0.0861538461538 --> Loss 0.00425336162249\n",
      "Epoch 7::Minibatch 75::LR 0.0861538461538 --> Loss 0.00272467116515\n",
      "Epoch 7::Minibatch 76::LR 0.0861538461538 --> Loss 0.00081481218338\n",
      "Epoch 7::Minibatch 77::LR 0.0861538461538 --> Loss 0.00402875900269\n",
      "Epoch 7::Minibatch 78::LR 0.0861538461538 --> Loss 0.00404464801153\n",
      "Epoch 7::Minibatch 79::LR 0.0861538461538 --> Loss 0.00228787918886\n",
      "Epoch 7::Minibatch 80::LR 0.0861538461538 --> Loss 0.00368590950966\n",
      "Epoch 7::Minibatch 81::LR 0.0861538461538 --> Loss 0.00324648161729\n",
      "Epoch 7::Minibatch 82::LR 0.0861538461538 --> Loss 0.00214584966501\n",
      "Epoch 7::Minibatch 83::LR 0.0861538461538 --> Loss 0.00536783774694\n",
      "Epoch 7::Minibatch 84::LR 0.0861538461538 --> Loss 0.00224652727445\n",
      "Epoch 7::Minibatch 85::LR 0.0861538461538 --> Loss 0.00300367017587\n",
      "Epoch 7::Minibatch 86::LR 0.0861538461538 --> Loss 0.00249639530977\n",
      "Epoch 7::Minibatch 87::LR 0.0861538461538 --> Loss 0.00275069375833\n",
      "Epoch 7::Minibatch 88::LR 0.0861538461538 --> Loss 0.00206447283427\n",
      "Epoch 7::Minibatch 89::LR 0.0861538461538 --> Loss 0.00251406669617\n",
      "Epoch 7::Minibatch 90::LR 0.0861538461538 --> Loss 0.00136293937763\n",
      "Epoch 7::Minibatch 91::LR 0.0861538461538 --> Loss 0.00115538179874\n",
      "Epoch 7::Minibatch 92::LR 0.0861538461538 --> Loss 0.00273875912031\n",
      "Epoch 7::Minibatch 93::LR 0.0861538461538 --> Loss 0.00193833947182\n",
      "Epoch 7::Minibatch 94::LR 0.0861538461538 --> Loss 0.00187752465407\n",
      "Epoch 7::Minibatch 95::LR 0.0861538461538 --> Loss 0.00173828204473\n",
      "Epoch 7::Minibatch 96::LR 0.0861538461538 --> Loss 0.00632791757584\n",
      "Epoch 7::Minibatch 97::LR 0.0861538461538 --> Loss 0.003206559817\n",
      "Epoch 7::Minibatch 98::LR 0.0861538461538 --> Loss 0.000986747642358\n",
      "Epoch 7::Minibatch 99::LR 0.0861538461538 --> Loss 0.00132758627335\n",
      "Epoch 7::Minibatch 100::LR 0.0861538461538 --> Loss 0.00576089262962\n",
      "Epoch 7::Minibatch 101::LR 0.0861538461538 --> Loss 0.00110437313716\n",
      "Epoch 7::Minibatch 102::LR 0.0861538461538 --> Loss 0.00377663612366\n",
      "Epoch 7::Minibatch 103::LR 0.0861538461538 --> Loss 0.00400635083516\n",
      "Epoch 7::Minibatch 104::LR 0.0861538461538 --> Loss 0.00295887231827\n",
      "Epoch 7::Minibatch 105::LR 0.0861538461538 --> Loss 0.00372025966644\n",
      "Epoch 7::Minibatch 106::LR 0.0861538461538 --> Loss 0.0185112841924\n",
      "Epoch 7::Minibatch 107::LR 0.0861538461538 --> Loss 0.00479341944059\n",
      "Epoch 7::Minibatch 108::LR 0.0861538461538 --> Loss 0.00139598826567\n",
      "Epoch 7::Minibatch 109::LR 0.0861538461538 --> Loss 0.00471886436145\n",
      "Epoch 7::Minibatch 110::LR 0.0861538461538 --> Loss 0.00277444601059\n",
      "Epoch 7::Minibatch 111::LR 0.0861538461538 --> Loss 0.0013186404109\n",
      "Epoch 7::Minibatch 112::LR 0.0861538461538 --> Loss 0.00399221261342\n",
      "Epoch 7::Minibatch 113::LR 0.0861538461538 --> Loss 0.0031036545833\n",
      "Epoch 7::Minibatch 114::LR 0.0861538461538 --> Loss 0.00179033617179\n",
      "Epoch 7::Minibatch 115::LR 0.0861538461538 --> Loss 0.00175132652124\n",
      "Epoch 7::Minibatch 116::LR 0.0861538461538 --> Loss 0.0031841892004\n",
      "Epoch 7::Minibatch 117::LR 0.0861538461538 --> Loss 0.0038161500295\n",
      "Epoch 7::Minibatch 118::LR 0.0861538461538 --> Loss 0.00694840192795\n",
      "Epoch 7::Minibatch 119::LR 0.0861538461538 --> Loss 0.000963611900806\n",
      "Epoch 7::Minibatch 120::LR 0.0861538461538 --> Loss 0.00224017858505\n",
      "Epoch 7::Minibatch 121::LR 0.0861538461538 --> Loss 0.0031815358003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 122::LR 0.0861538461538 --> Loss 0.00375809788704\n",
      "Epoch 7::Minibatch 123::LR 0.0861538461538 --> Loss 0.00161089450121\n",
      "Epoch 7::Minibatch 124::LR 0.0861538461538 --> Loss 0.00313150882721\n",
      "Epoch 7::Minibatch 125::LR 0.0861538461538 --> Loss 0.00494262774785\n",
      "Epoch 7::Minibatch 126::LR 0.0861538461538 --> Loss 0.00316124240557\n",
      "Epoch 7::Minibatch 127::LR 0.0861538461538 --> Loss 0.00477289040883\n",
      "Epoch 7::Minibatch 128::LR 0.0861538461538 --> Loss 0.00383632381757\n",
      "Epoch 7::Minibatch 129::LR 0.0861538461538 --> Loss 0.00317511399587\n",
      "Epoch 7::Minibatch 130::LR 0.0861538461538 --> Loss 0.00454434235891\n",
      "Epoch 7::Minibatch 131::LR 0.0861538461538 --> Loss 0.00207158108552\n",
      "Epoch 7::Minibatch 132::LR 0.0861538461538 --> Loss 0.00351355512937\n",
      "Epoch 7::Minibatch 133::LR 0.0861538461538 --> Loss 0.00337891538938\n",
      "Epoch 7::Minibatch 134::LR 0.0861538461538 --> Loss 0.00281310061614\n",
      "Epoch 7::Minibatch 135::LR 0.0861538461538 --> Loss 0.00210180878639\n",
      "Epoch 7::Minibatch 136::LR 0.0861538461538 --> Loss 0.00305178244909\n",
      "Epoch 7::Minibatch 137::LR 0.0861538461538 --> Loss 0.0038604871432\n",
      "Epoch 7::Minibatch 138::LR 0.0861538461538 --> Loss 0.00154142141342\n",
      "Epoch 7::Minibatch 139::LR 0.0861538461538 --> Loss 0.00200986425082\n",
      "Epoch 7::Minibatch 140::LR 0.0861538461538 --> Loss 0.00256940821807\n",
      "Epoch 7::Minibatch 141::LR 0.0861538461538 --> Loss 0.00314061383406\n",
      "Epoch 7::Minibatch 142::LR 0.0861538461538 --> Loss 0.00332740088304\n",
      "Epoch 7::Minibatch 143::LR 0.0861538461538 --> Loss 0.000780871858199\n",
      "Epoch 7::Minibatch 144::LR 0.0861538461538 --> Loss 0.00317491014798\n",
      "Epoch 7::Minibatch 145::LR 0.0861538461538 --> Loss 0.00442175388336\n",
      "Epoch 7::Minibatch 146::LR 0.0861538461538 --> Loss 0.00283442695936\n",
      "Epoch 7::Minibatch 147::LR 0.0861538461538 --> Loss 0.00192992150784\n",
      "Epoch 7::Minibatch 148::LR 0.0861538461538 --> Loss 0.00119153261185\n",
      "Epoch 7::Minibatch 149::LR 0.0861538461538 --> Loss 0.0029361786445\n",
      "Epoch 7::Minibatch 150::LR 0.0861538461538 --> Loss 0.00294129451116\n",
      "Epoch 7::Minibatch 151::LR 0.0861538461538 --> Loss 0.00430056492488\n",
      "Epoch 7::Minibatch 152::LR 0.0861538461538 --> Loss 0.00104028423627\n",
      "Epoch 7::Minibatch 153::LR 0.0861538461538 --> Loss 0.00200420717398\n",
      "Epoch 7::Minibatch 154::LR 0.0861538461538 --> Loss 0.0022070680062\n",
      "Epoch 7::Minibatch 155::LR 0.0861538461538 --> Loss 0.00499167720477\n",
      "Epoch 7::Minibatch 156::LR 0.0861538461538 --> Loss 0.00251823047797\n",
      "Epoch 7::Minibatch 157::LR 0.0861538461538 --> Loss 0.00077720383803\n",
      "Epoch 7::Minibatch 158::LR 0.0861538461538 --> Loss 0.00315918485324\n",
      "Epoch 7::Minibatch 159::LR 0.0861538461538 --> Loss 0.00287693679333\n",
      "Epoch 7::Minibatch 160::LR 0.0861538461538 --> Loss 0.00278099775314\n",
      "Epoch 7::Minibatch 161::LR 0.0861538461538 --> Loss 0.00115217099587\n",
      "Epoch 7::Minibatch 162::LR 0.0861538461538 --> Loss 0.00358594695727\n",
      "Epoch 7::Minibatch 163::LR 0.0861538461538 --> Loss 0.00250302910805\n",
      "Epoch 7::Minibatch 164::LR 0.0861538461538 --> Loss 0.00255731920401\n",
      "Epoch 7::Minibatch 165::LR 0.0861538461538 --> Loss 0.000639123866955\n",
      "Epoch 7::Minibatch 166::LR 0.0861538461538 --> Loss 0.00193500916163\n",
      "Epoch 7::Minibatch 167::LR 0.0861538461538 --> Loss 0.00255598942439\n",
      "Epoch 7::Minibatch 168::LR 0.0861538461538 --> Loss 0.00232758621375\n",
      "Epoch 7::Minibatch 169::LR 0.0861538461538 --> Loss 0.00112305482229\n",
      "Epoch 7::Minibatch 170::LR 0.0861538461538 --> Loss 0.001078500549\n",
      "Epoch 7::Minibatch 171::LR 0.0861538461538 --> Loss 0.00256223082542\n",
      "Epoch 7::Minibatch 172::LR 0.0861538461538 --> Loss 0.0050012811025\n",
      "Epoch 7::Minibatch 173::LR 0.0861538461538 --> Loss 0.0020465217034\n",
      "Epoch 7::Minibatch 174::LR 0.0861538461538 --> Loss 0.00114763011535\n",
      "Epoch 7::Minibatch 175::LR 0.0861538461538 --> Loss 0.00234009623528\n",
      "Epoch 7::Minibatch 176::LR 0.0861538461538 --> Loss 0.00345335801442\n",
      "Epoch 7::Minibatch 177::LR 0.0861538461538 --> Loss 0.00518072485924\n",
      "Epoch 7::Minibatch 178::LR 0.0861538461538 --> Loss 0.00179497341315\n",
      "Epoch 7::Minibatch 179::LR 0.0861538461538 --> Loss 0.00146732807159\n",
      "Epoch 7::Minibatch 180::LR 0.0861538461538 --> Loss 0.00383456508319\n",
      "Epoch 7::Minibatch 181::LR 0.0861538461538 --> Loss 0.00359454790751\n",
      "Epoch 7::Minibatch 182::LR 0.0861538461538 --> Loss 0.00094591319561\n",
      "Epoch 7::Minibatch 183::LR 0.0861538461538 --> Loss 0.00180675029755\n",
      "Epoch 7::Minibatch 184::LR 0.0861538461538 --> Loss 0.00347559491793\n",
      "Epoch 7::Minibatch 185::LR 0.0861538461538 --> Loss 0.00295438786348\n",
      "Epoch 7::Minibatch 186::LR 0.0861538461538 --> Loss 0.00110337197781\n",
      "Epoch 7::Minibatch 187::LR 0.0861538461538 --> Loss 0.00132155954838\n",
      "Epoch 7::Minibatch 188::LR 0.0861538461538 --> Loss 0.00417307933172\n",
      "Epoch 7::Minibatch 189::LR 0.0861538461538 --> Loss 0.00462314605713\n",
      "Epoch 7::Minibatch 190::LR 0.0861538461538 --> Loss 0.00239465892315\n",
      "Epoch 7::Minibatch 191::LR 0.0861538461538 --> Loss 0.000616038193305\n",
      "Epoch 7::Minibatch 192::LR 0.0861538461538 --> Loss 0.00269559780757\n",
      "Epoch 7::Minibatch 193::LR 0.0861538461538 --> Loss 0.00250389138858\n",
      "Epoch 7::Minibatch 194::LR 0.0861538461538 --> Loss 0.00189856489499\n",
      "Epoch 7::Minibatch 195::LR 0.0861538461538 --> Loss 0.000457189579805\n",
      "Epoch 7::Minibatch 196::LR 0.0861538461538 --> Loss 0.00124504625797\n",
      "Epoch 7::Minibatch 197::LR 0.0861538461538 --> Loss 0.00281133313974\n",
      "Epoch 7::Minibatch 198::LR 0.0861538461538 --> Loss 0.00219347476959\n",
      "Epoch 7::Minibatch 199::LR 0.0861538461538 --> Loss 0.000345678304633\n",
      "Epoch 7::Minibatch 200::LR 0.0861538461538 --> Loss 0.00220249255498\n",
      "Epoch 7::Minibatch 201::LR 0.0861538461538 --> Loss 0.00212420145671\n",
      "Epoch 7::Minibatch 202::LR 0.0861538461538 --> Loss 0.00205255866051\n",
      "Epoch 7::Minibatch 203::LR 0.0861538461538 --> Loss 0.00199230710665\n",
      "Epoch 7::Minibatch 204::LR 0.0861538461538 --> Loss 0.00176041841507\n",
      "Epoch 7::Minibatch 205::LR 0.0861538461538 --> Loss 0.00240331848462\n",
      "Epoch 7::Minibatch 206::LR 0.0861538461538 --> Loss 0.00762984991074\n",
      "Epoch 7::Minibatch 207::LR 0.0861538461538 --> Loss 0.00152749816577\n",
      "Epoch 7::Minibatch 208::LR 0.0861538461538 --> Loss 0.00130221704642\n",
      "Epoch 7::Minibatch 209::LR 0.0861538461538 --> Loss 0.00217572927475\n",
      "Epoch 7::Minibatch 210::LR 0.0861538461538 --> Loss 0.00198951860269\n",
      "Epoch 7::Minibatch 211::LR 0.0861538461538 --> Loss 0.00208893418312\n",
      "Epoch 7::Minibatch 212::LR 0.0861538461538 --> Loss 0.0044617887338\n",
      "Epoch 7::Minibatch 213::LR 0.0861538461538 --> Loss 0.00624078710874\n",
      "Epoch 7::Minibatch 214::LR 0.0861538461538 --> Loss 0.0104334346453\n",
      "Epoch 7::Minibatch 215::LR 0.0861538461538 --> Loss 0.00155339717865\n",
      "Epoch 7::Minibatch 216::LR 0.0861538461538 --> Loss 0.00555274526278\n",
      "Epoch 7::Minibatch 217::LR 0.0861538461538 --> Loss 0.005897402366\n",
      "Epoch 7::Minibatch 218::LR 0.0861538461538 --> Loss 0.00423863331477\n",
      "Epoch 7::Minibatch 219::LR 0.0861538461538 --> Loss 0.00356786251068\n",
      "Epoch 7::Minibatch 220::LR 0.0861538461538 --> Loss 0.0046878361702\n",
      "Epoch 7::Minibatch 221::LR 0.0861538461538 --> Loss 0.00439927180608\n",
      "Epoch 7::Minibatch 222::LR 0.0861538461538 --> Loss 0.00346358895302\n",
      "Epoch 7::Minibatch 223::LR 0.0861538461538 --> Loss 0.00155395229657\n",
      "Epoch 7::Minibatch 224::LR 0.0861538461538 --> Loss 0.00204247375329\n",
      "Epoch 7::Minibatch 225::LR 0.0861538461538 --> Loss 0.00680270671844\n",
      "Epoch 7::Minibatch 226::LR 0.0861538461538 --> Loss 0.00395033041636\n",
      "Epoch 7::Minibatch 227::LR 0.0861538461538 --> Loss 0.00183423002561\n",
      "Epoch 7::Minibatch 228::LR 0.0861538461538 --> Loss 0.000974198977153\n",
      "Epoch 7::Minibatch 229::LR 0.0861538461538 --> Loss 0.00502130230268\n",
      "Epoch 7::Minibatch 230::LR 0.0861538461538 --> Loss 0.00421236197154\n",
      "Epoch 7::Minibatch 231::LR 0.0861538461538 --> Loss 0.0027387513717\n",
      "Epoch 7::Minibatch 232::LR 0.0861538461538 --> Loss 0.00144312262535\n",
      "Epoch 7::Minibatch 233::LR 0.0861538461538 --> Loss 0.0024837376674\n",
      "Epoch 7::Minibatch 234::LR 0.0861538461538 --> Loss 0.00654911438624\n",
      "Epoch 7::Minibatch 235::LR 0.0861538461538 --> Loss 0.00497261762619\n",
      "Epoch 7::Minibatch 236::LR 0.0861538461538 --> Loss 0.0019333978494\n",
      "Epoch 7::Minibatch 237::LR 0.0861538461538 --> Loss 0.000881235003471\n",
      "Epoch 7::Minibatch 238::LR 0.0861538461538 --> Loss 0.00351325352987\n",
      "Epoch 7::Minibatch 239::LR 0.0861538461538 --> Loss 0.00301818648974\n",
      "Epoch 7::Minibatch 240::LR 0.0861538461538 --> Loss 0.00326125741005\n",
      "Epoch 7::Minibatch 241::LR 0.0861538461538 --> Loss 0.000912525256475\n",
      "Epoch 7::Minibatch 242::LR 0.0861538461538 --> Loss 0.00736047665278\n",
      "Epoch 7::Minibatch 243::LR 0.0861538461538 --> Loss 0.00380614240964\n",
      "Epoch 7::Minibatch 244::LR 0.0861538461538 --> Loss 0.00319869975249\n",
      "Epoch 7::Minibatch 245::LR 0.0861538461538 --> Loss 0.000688316325347\n",
      "Epoch 7::Minibatch 246::LR 0.0861538461538 --> Loss 0.00231848259767\n",
      "Epoch 7::Minibatch 247::LR 0.0861538461538 --> Loss 0.0143836228053\n",
      "Epoch 7::Minibatch 248::LR 0.0861538461538 --> Loss 0.00488861997922\n",
      "Epoch 7::Minibatch 249::LR 0.0861538461538 --> Loss 0.0033286211888\n",
      "Epoch 7::Minibatch 250::LR 0.0861538461538 --> Loss 0.00326050718625\n",
      "Epoch 7::Minibatch 251::LR 0.0861538461538 --> Loss 0.00270594139894\n",
      "Epoch 7::Minibatch 252::LR 0.0861538461538 --> Loss 0.00211127022902\n",
      "Epoch 7::Minibatch 253::LR 0.0861538461538 --> Loss 0.00337199131648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 254::LR 0.0861538461538 --> Loss 0.00562646230062\n",
      "Epoch 7::Minibatch 255::LR 0.0861538461538 --> Loss 0.00415441950162\n",
      "Epoch 7::Minibatch 256::LR 0.0861538461538 --> Loss 0.00206249753634\n",
      "Epoch 7::Minibatch 257::LR 0.0861538461538 --> Loss 0.00158469597499\n",
      "Epoch 7::Minibatch 258::LR 0.0861538461538 --> Loss 0.00374752283096\n",
      "Epoch 7::Minibatch 259::LR 0.0861538461538 --> Loss 0.00205084880193\n",
      "Epoch 7::Minibatch 260::LR 0.0861538461538 --> Loss 0.00203519920508\n",
      "Epoch 7::Minibatch 261::LR 0.0861538461538 --> Loss 0.00312889655431\n",
      "Epoch 7::Minibatch 262::LR 0.0861538461538 --> Loss 0.00214278300603\n",
      "Epoch 7::Minibatch 263::LR 0.0861538461538 --> Loss 0.00252510090669\n",
      "Epoch 7::Minibatch 264::LR 0.0861538461538 --> Loss 0.00380085905393\n",
      "Epoch 7::Minibatch 265::LR 0.0861538461538 --> Loss 0.0102971378962\n",
      "Epoch 7::Minibatch 266::LR 0.0861538461538 --> Loss 0.00125157833099\n",
      "Epoch 7::Minibatch 267::LR 0.0861538461538 --> Loss 0.0102177834511\n",
      "Epoch 7::Minibatch 268::LR 0.0861538461538 --> Loss 0.00149548927943\n",
      "Epoch 7::Minibatch 269::LR 0.0861538461538 --> Loss 0.00379406730334\n",
      "Epoch 7::Minibatch 270::LR 0.0861538461538 --> Loss 0.00632036487261\n",
      "Epoch 7::Minibatch 271::LR 0.0861538461538 --> Loss 0.00310832738876\n",
      "Epoch 7::Minibatch 272::LR 0.0861538461538 --> Loss 0.00412969271342\n",
      "Epoch 7::Minibatch 273::LR 0.0861538461538 --> Loss 0.00201255540053\n",
      "Epoch 7::Minibatch 274::LR 0.0861538461538 --> Loss 0.00199234068394\n",
      "Epoch 7::Minibatch 275::LR 0.0861538461538 --> Loss 0.00293987472852\n",
      "Epoch 7::Minibatch 276::LR 0.0861538461538 --> Loss 0.00362674832344\n",
      "Epoch 7::Minibatch 277::LR 0.0861538461538 --> Loss 0.00123250693083\n",
      "Epoch 7::Minibatch 278::LR 0.0861538461538 --> Loss 0.00278167903423\n",
      "Epoch 7::Minibatch 279::LR 0.0861538461538 --> Loss 0.00267503043016\n",
      "Epoch 7::Minibatch 280::LR 0.0861538461538 --> Loss 0.00233706116676\n",
      "Epoch 7::Minibatch 281::LR 0.0861538461538 --> Loss 0.00153101007144\n",
      "Epoch 7::Minibatch 282::LR 0.0861538461538 --> Loss 0.00238120436668\n",
      "Epoch 7::Minibatch 283::LR 0.0861538461538 --> Loss 0.00233618795872\n",
      "Epoch 7::Minibatch 284::LR 0.0861538461538 --> Loss 0.00187776645025\n",
      "Epoch 7::Minibatch 285::LR 0.0861538461538 --> Loss 0.0013378889362\n",
      "Epoch 7::Minibatch 286::LR 0.0861538461538 --> Loss 0.00223866462708\n",
      "Epoch 7::Minibatch 287::LR 0.0861538461538 --> Loss 0.00215175052484\n",
      "Epoch 7::Minibatch 288::LR 0.0861538461538 --> Loss 0.0011943868796\n",
      "Epoch 7::Minibatch 289::LR 0.0861538461538 --> Loss 0.00159477333228\n",
      "Epoch 7::Minibatch 290::LR 0.0861538461538 --> Loss 0.00199903766314\n",
      "Epoch 7::Minibatch 291::LR 0.0861538461538 --> Loss 0.00179802278678\n",
      "Epoch 7::Minibatch 292::LR 0.0861538461538 --> Loss 0.000686854819457\n",
      "Epoch 7::Minibatch 293::LR 0.0861538461538 --> Loss 0.00148808161418\n",
      "Epoch 7::Minibatch 294::LR 0.0861538461538 --> Loss 0.00159931123257\n",
      "Epoch 7::Minibatch 295::LR 0.0861538461538 --> Loss 0.00184161861738\n",
      "Epoch 7::Minibatch 296::LR 0.0861538461538 --> Loss 0.00159288823605\n",
      "Epoch 7::Minibatch 297::LR 0.0861538461538 --> Loss 0.00141359210014\n",
      "Epoch 7::Minibatch 298::LR 0.0861538461538 --> Loss 0.00138400832812\n",
      "Epoch 7::Minibatch 299::LR 0.0861538461538 --> Loss 0.000854549407959\n",
      "Epoch 7::Minibatch 300::LR 0.0861538461538 --> Loss 0.00303005933762\n",
      "Epoch 7::Minibatch 301::LR 0.0861538461538 --> Loss 0.00290153602759\n",
      "Epoch 7::Minibatch 302::LR 0.0861538461538 --> Loss 0.00267224550247\n",
      "Epoch 7::Minibatch 303::LR 0.0861538461538 --> Loss 0.000967201193174\n",
      "Epoch 7::Minibatch 304::LR 0.0861538461538 --> Loss 0.00326457619667\n",
      "Epoch 7::Minibatch 305::LR 0.0861538461538 --> Loss 0.00175503273805\n",
      "Epoch 7::Minibatch 306::LR 0.0861538461538 --> Loss 0.00100823928912\n",
      "Epoch 7::Minibatch 307::LR 0.0861538461538 --> Loss 0.00256489356359\n",
      "Epoch 7::Minibatch 308::LR 0.0861538461538 --> Loss 0.00201981524626\n",
      "Epoch 7::Minibatch 309::LR 0.0861538461538 --> Loss 0.00102978765965\n",
      "Epoch 7::Minibatch 310::LR 0.0861538461538 --> Loss 0.00108581244946\n",
      "Epoch 7::Minibatch 311::LR 0.0861538461538 --> Loss 0.00166340668996\n",
      "Epoch 7::Minibatch 312::LR 0.0861538461538 --> Loss 0.00314380387465\n",
      "Epoch 7::Minibatch 313::LR 0.0861538461538 --> Loss 0.00241364995639\n",
      "Epoch 7::Minibatch 314::LR 0.0861538461538 --> Loss 0.00196951707204\n",
      "Epoch 7::Minibatch 315::LR 0.0861538461538 --> Loss 0.0010433430473\n",
      "Epoch 7::Minibatch 316::LR 0.0861538461538 --> Loss 0.0023874437809\n",
      "Epoch 7::Minibatch 317::LR 0.0861538461538 --> Loss 0.00164744685094\n",
      "Epoch 7::Minibatch 318::LR 0.0861538461538 --> Loss 0.00123998512824\n",
      "Epoch 7::Minibatch 319::LR 0.0861538461538 --> Loss 0.00233949124813\n",
      "Epoch 7::Minibatch 320::LR 0.0861538461538 --> Loss 0.00345742901166\n",
      "Epoch 7::Minibatch 321::LR 0.0861538461538 --> Loss 0.000991082390149\n",
      "Epoch 7::Minibatch 322::LR 0.0861538461538 --> Loss 0.00368868470192\n",
      "Epoch 7::Minibatch 323::LR 0.0861538461538 --> Loss 0.00363260110219\n",
      "Epoch 7::Minibatch 324::LR 0.0861538461538 --> Loss 0.00267588277658\n",
      "Epoch 7::Minibatch 325::LR 0.0861538461538 --> Loss 0.00251420676708\n",
      "Epoch 7::Minibatch 326::LR 0.0861538461538 --> Loss 0.00550122261047\n",
      "Epoch 7::Minibatch 327::LR 0.0861538461538 --> Loss 0.00237304488818\n",
      "Epoch 7::Minibatch 328::LR 0.0861538461538 --> Loss 0.00363225221634\n",
      "Epoch 7::Minibatch 329::LR 0.0861538461538 --> Loss 0.00133373091618\n",
      "Epoch 7::Minibatch 330::LR 0.0861538461538 --> Loss 0.00172515134017\n",
      "Epoch 7::Minibatch 331::LR 0.0861538461538 --> Loss 0.00266034781933\n",
      "Epoch 7::Minibatch 332::LR 0.0861538461538 --> Loss 0.00262012064457\n",
      "Epoch 7::Minibatch 333::LR 0.0861538461538 --> Loss 0.00157056192557\n",
      "Epoch 7::Minibatch 334::LR 0.0861538461538 --> Loss 0.00420082290967\n",
      "Epoch 7::Minibatch 335::LR 0.0861538461538 --> Loss 0.00199282904466\n",
      "Epoch 7::Minibatch 336::LR 0.0861538461538 --> Loss 0.00202976981799\n",
      "Epoch 7::Minibatch 337::LR 0.0861538461538 --> Loss 0.00325439373652\n",
      "Epoch 7::Minibatch 338::LR 0.0861538461538 --> Loss 0.000568862309059\n",
      "Epoch 7::Minibatch 339::LR 0.0861538461538 --> Loss 0.00331918517749\n",
      "Epoch 7::Minibatch 340::LR 0.0861538461538 --> Loss 0.00519659837087\n",
      "Epoch 7::Minibatch 341::LR 0.0861538461538 --> Loss 0.00517959992091\n",
      "Epoch 7::Minibatch 342::LR 0.0861538461538 --> Loss 0.00363139073054\n",
      "Epoch 7::Minibatch 343::LR 0.0861538461538 --> Loss 0.00192450662454\n",
      "Epoch 7::Minibatch 344::LR 0.0861538461538 --> Loss 0.00306307335695\n",
      "Epoch 7::Minibatch 345::LR 0.0861538461538 --> Loss 0.00446665326754\n",
      "Epoch 7::Minibatch 346::LR 0.0861538461538 --> Loss 0.00578063130379\n",
      "Epoch 7::Minibatch 347::LR 0.0861538461538 --> Loss 0.00104244937499\n",
      "Epoch 7::Minibatch 348::LR 0.0861538461538 --> Loss 0.00386458992958\n",
      "Epoch 7::Minibatch 349::LR 0.0861538461538 --> Loss 0.00360561490059\n",
      "Epoch 7::Minibatch 350::LR 0.0861538461538 --> Loss 0.00202969968319\n",
      "Epoch 7::Minibatch 351::LR 0.0861538461538 --> Loss 0.00372056245804\n",
      "Epoch 7::Minibatch 352::LR 0.0861538461538 --> Loss 0.00482991814613\n",
      "Epoch 7::Minibatch 353::LR 0.0861538461538 --> Loss 0.00363543550173\n",
      "Epoch 7::Minibatch 354::LR 0.0861538461538 --> Loss 0.0030396382014\n",
      "Epoch 7::Minibatch 355::LR 0.0861538461538 --> Loss 0.0062537475427\n",
      "Epoch 7::Minibatch 356::LR 0.0861538461538 --> Loss 0.00328715602557\n",
      "Epoch 7::Minibatch 357::LR 0.0861538461538 --> Loss 0.00132351795832\n",
      "Epoch 7::Minibatch 358::LR 0.0861538461538 --> Loss 0.00245934804281\n",
      "Epoch 7::Minibatch 359::LR 0.0861538461538 --> Loss 0.00286914110184\n",
      "Epoch 7::Minibatch 360::LR 0.0861538461538 --> Loss 0.00262155592442\n",
      "Epoch 7::Minibatch 361::LR 0.0861538461538 --> Loss 0.00255993723869\n",
      "Epoch 7::Minibatch 362::LR 0.0861538461538 --> Loss 0.0026553740104\n",
      "Epoch 7::Minibatch 363::LR 0.0861538461538 --> Loss 0.000774146020412\n",
      "Epoch 7::Minibatch 364::LR 0.0861538461538 --> Loss 0.00213942408562\n",
      "Epoch 7::Minibatch 365::LR 0.0861538461538 --> Loss 0.00223537464937\n",
      "Epoch 7::Minibatch 366::LR 0.0861538461538 --> Loss 0.00245177368323\n",
      "Epoch 7::Minibatch 367::LR 0.0861538461538 --> Loss 0.00122152477503\n",
      "Epoch 7::Minibatch 368::LR 0.0861538461538 --> Loss 0.00110237846772\n",
      "Epoch 7::Minibatch 369::LR 0.0861538461538 --> Loss 0.00298731982708\n",
      "Epoch 7::Minibatch 370::LR 0.0861538461538 --> Loss 0.00234765867392\n",
      "Epoch 7::Minibatch 371::LR 0.0861538461538 --> Loss 0.00196450531483\n",
      "Epoch 7::Minibatch 372::LR 0.0861538461538 --> Loss 0.000521321445704\n",
      "Epoch 7::Minibatch 373::LR 0.0861538461538 --> Loss 0.00181404252847\n",
      "Epoch 7::Minibatch 374::LR 0.0861538461538 --> Loss 0.00218419929345\n",
      "Epoch 7::Minibatch 375::LR 0.0861538461538 --> Loss 0.00189358592033\n",
      "Epoch 7::Minibatch 376::LR 0.0861538461538 --> Loss 0.00130099813143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 377::LR 0.0861538461538 --> Loss 0.00204862177372\n",
      "Epoch 7::Minibatch 378::LR 0.0861538461538 --> Loss 0.00217186550299\n",
      "Epoch 7::Minibatch 379::LR 0.0861538461538 --> Loss 0.00245736638705\n",
      "Epoch 7::Minibatch 380::LR 0.0861538461538 --> Loss 0.00164121111234\n",
      "Epoch 7::Minibatch 381::LR 0.0861538461538 --> Loss 0.00106035888195\n",
      "Epoch 7::Minibatch 382::LR 0.0861538461538 --> Loss 0.00207911709944\n",
      "Epoch 7::Minibatch 383::LR 0.0861538461538 --> Loss 0.00198818425337\n",
      "Epoch 7::Minibatch 384::LR 0.0861538461538 --> Loss 0.00110031545162\n",
      "Epoch 7::Minibatch 385::LR 0.0861538461538 --> Loss 0.00109673430522\n",
      "Epoch 7::Minibatch 386::LR 0.0861538461538 --> Loss 0.00225654224555\n",
      "Epoch 7::Minibatch 387::LR 0.0861538461538 --> Loss 0.00235198577245\n",
      "Epoch 7::Minibatch 388::LR 0.0861538461538 --> Loss 0.00116278022528\n",
      "Epoch 7::Minibatch 389::LR 0.0861538461538 --> Loss 0.00194122056166\n",
      "Epoch 7::Minibatch 390::LR 0.0861538461538 --> Loss 0.00400673707326\n",
      "Epoch 7::Minibatch 391::LR 0.0861538461538 --> Loss 0.00287394821644\n",
      "Epoch 7::Minibatch 392::LR 0.0861538461538 --> Loss 0.00283972402414\n",
      "Epoch 7::Minibatch 393::LR 0.0861538461538 --> Loss 0.00289651672045\n",
      "Epoch 7::Minibatch 394::LR 0.0861538461538 --> Loss 0.0022978057464\n",
      "Epoch 7::Minibatch 395::LR 0.0861538461538 --> Loss 0.00211946507295\n",
      "Epoch 7::Minibatch 396::LR 0.0861538461538 --> Loss 0.0020808506012\n",
      "Epoch 7::Minibatch 397::LR 0.0861538461538 --> Loss 0.00220558861891\n",
      "Epoch 7::Minibatch 398::LR 0.0861538461538 --> Loss 0.00216679334641\n",
      "Epoch 7::Minibatch 399::LR 0.0861538461538 --> Loss 0.0024359258016\n",
      "Epoch 7::Minibatch 400::LR 0.0861538461538 --> Loss 0.00212425669034\n",
      "Epoch 7::Minibatch 401::LR 0.0861538461538 --> Loss 0.00399164517721\n",
      "Epoch 7::Minibatch 402::LR 0.0861538461538 --> Loss 0.0021647977829\n",
      "Epoch 7::Minibatch 403::LR 0.0861538461538 --> Loss 0.00164502998193\n",
      "Epoch 7::Minibatch 404::LR 0.0861538461538 --> Loss 0.00174807588259\n",
      "Epoch 7::Minibatch 405::LR 0.0861538461538 --> Loss 0.00375016450882\n",
      "Epoch 7::Minibatch 406::LR 0.0861538461538 --> Loss 0.0026207357645\n",
      "Epoch 7::Minibatch 407::LR 0.0861538461538 --> Loss 0.00186387161414\n",
      "Epoch 7::Minibatch 408::LR 0.0861538461538 --> Loss 0.000581349680821\n",
      "Epoch 7::Minibatch 409::LR 0.0861538461538 --> Loss 0.00266481439273\n",
      "Epoch 7::Minibatch 410::LR 0.0861538461538 --> Loss 0.00344814022382\n",
      "Epoch 7::Minibatch 411::LR 0.0861538461538 --> Loss 0.00173023700714\n",
      "Epoch 7::Minibatch 412::LR 0.0861538461538 --> Loss 0.00106169760227\n",
      "Epoch 7::Minibatch 413::LR 0.0861538461538 --> Loss 0.00211512009303\n",
      "Epoch 7::Minibatch 414::LR 0.0861538461538 --> Loss 0.00182308634122\n",
      "Epoch 7::Minibatch 415::LR 0.0861538461538 --> Loss 0.00119452267885\n",
      "Epoch 7::Minibatch 416::LR 0.0861538461538 --> Loss 0.000918029844761\n",
      "Epoch 7::Minibatch 417::LR 0.0861538461538 --> Loss 0.0017629724741\n",
      "Epoch 7::Minibatch 418::LR 0.0861538461538 --> Loss 0.00308569113413\n",
      "Epoch 7::Minibatch 419::LR 0.0861538461538 --> Loss 0.000669703284899\n",
      "Epoch 7::Minibatch 420::LR 0.0861538461538 --> Loss 0.000847957531611\n",
      "Epoch 7::Minibatch 421::LR 0.0861538461538 --> Loss 0.00211203595002\n",
      "Epoch 7::Minibatch 422::LR 0.0861538461538 --> Loss 0.00241609176\n",
      "Epoch 7::Minibatch 423::LR 0.0861538461538 --> Loss 0.00114458680153\n",
      "Epoch 7::Minibatch 424::LR 0.0861538461538 --> Loss 0.00174165844917\n",
      "Epoch 7::Minibatch 425::LR 0.0861538461538 --> Loss 0.0028707520167\n",
      "Epoch 7::Minibatch 426::LR 0.0861538461538 --> Loss 0.00211235503356\n",
      "Epoch 7::Minibatch 427::LR 0.0861538461538 --> Loss 0.000843467116356\n",
      "Epoch 7::Minibatch 428::LR 0.0861538461538 --> Loss 0.00131739417712\n",
      "Epoch 7::Minibatch 429::LR 0.0861538461538 --> Loss 0.00268781046073\n",
      "Epoch 7::Minibatch 430::LR 0.0861538461538 --> Loss 0.00979696114858\n",
      "Epoch 7::Minibatch 431::LR 0.0861538461538 --> Loss 0.00424143354098\n",
      "Epoch 7::Minibatch 432::LR 0.0861538461538 --> Loss 0.00468336701393\n",
      "Epoch 7::Minibatch 433::LR 0.0861538461538 --> Loss 0.00266972561677\n",
      "Epoch 7::Minibatch 434::LR 0.0861538461538 --> Loss 0.00264464795589\n",
      "Epoch 7::Minibatch 435::LR 0.0861538461538 --> Loss 0.0025556876262\n",
      "Epoch 7::Minibatch 436::LR 0.0861538461538 --> Loss 0.00193822801113\n",
      "Epoch 7::Minibatch 437::LR 0.0861538461538 --> Loss 0.00373711427053\n",
      "Epoch 7::Minibatch 438::LR 0.0861538461538 --> Loss 0.00291376312574\n",
      "Epoch 7::Minibatch 439::LR 0.0861538461538 --> Loss 0.00235080122948\n",
      "Epoch 7::Minibatch 440::LR 0.0861538461538 --> Loss 0.00343764781952\n",
      "Epoch 7::Minibatch 441::LR 0.0861538461538 --> Loss 0.00326679805915\n",
      "Epoch 7::Minibatch 442::LR 0.0861538461538 --> Loss 0.00306835571925\n",
      "Epoch 7::Minibatch 443::LR 0.0861538461538 --> Loss 0.00400759339333\n",
      "Epoch 7::Minibatch 444::LR 0.0861538461538 --> Loss 0.00298177818457\n",
      "Epoch 7::Minibatch 445::LR 0.0861538461538 --> Loss 0.000946664313475\n",
      "Epoch 7::Minibatch 446::LR 0.0861538461538 --> Loss 0.00166077683369\n",
      "Epoch 7::Minibatch 447::LR 0.0861538461538 --> Loss 0.00258236209551\n",
      "Epoch 7::Minibatch 448::LR 0.0861538461538 --> Loss 0.00254948794842\n",
      "Epoch 7::Minibatch 449::LR 0.0861538461538 --> Loss 0.00386423110962\n",
      "Epoch 7::Minibatch 450::LR 0.0861538461538 --> Loss 0.00255788803101\n",
      "Epoch 7::Minibatch 451::LR 0.0861538461538 --> Loss 0.00427136143049\n",
      "Epoch 7::Minibatch 452::LR 0.0861538461538 --> Loss 0.0024871100982\n",
      "Epoch 7::Minibatch 453::LR 0.0861538461538 --> Loss 0.000482245286306\n",
      "Epoch 7::Minibatch 454::LR 0.0861538461538 --> Loss 0.00377375205358\n",
      "Epoch 7::Minibatch 455::LR 0.0861538461538 --> Loss 0.00279831528664\n",
      "Epoch 7::Minibatch 456::LR 0.0861538461538 --> Loss 0.0033161487182\n",
      "Epoch 7::Minibatch 457::LR 0.0861538461538 --> Loss 0.00207272370656\n",
      "Epoch 7::Minibatch 458::LR 0.0861538461538 --> Loss 0.000886424978574\n",
      "Epoch 7::Minibatch 459::LR 0.0861538461538 --> Loss 0.00442587137222\n",
      "Epoch 7::Minibatch 460::LR 0.0861538461538 --> Loss 0.00285019040108\n",
      "Epoch 7::Minibatch 461::LR 0.0861538461538 --> Loss 0.00410698771477\n",
      "Epoch 7::Minibatch 462::LR 0.0861538461538 --> Loss 0.000461907883485\n",
      "Epoch 7::Minibatch 463::LR 0.0861538461538 --> Loss 0.00495620807012\n",
      "Epoch 7::Minibatch 464::LR 0.0861538461538 --> Loss 0.00217923720678\n",
      "Epoch 7::Minibatch 465::LR 0.0861538461538 --> Loss 0.00588382959366\n",
      "Epoch 7::Minibatch 466::LR 0.0861538461538 --> Loss 0.0053548236688\n",
      "Epoch 7::Minibatch 467::LR 0.0861538461538 --> Loss 0.00681016683578\n",
      "Epoch 7::Minibatch 468::LR 0.0861538461538 --> Loss 0.00645952939987\n",
      "Epoch 7::Minibatch 469::LR 0.0861538461538 --> Loss 0.00717379808426\n",
      "Epoch 7::Minibatch 470::LR 0.0861538461538 --> Loss 0.00411164124807\n",
      "Epoch 7::Minibatch 471::LR 0.0861538461538 --> Loss 0.00200820803642\n",
      "Epoch 7::Minibatch 472::LR 0.0861538461538 --> Loss 0.00358745455742\n",
      "Epoch 7::Minibatch 473::LR 0.0861538461538 --> Loss 0.00219287296136\n",
      "Epoch 7::Minibatch 474::LR 0.0861538461538 --> Loss 0.000763537238042\n",
      "Epoch 7::Minibatch 475::LR 0.0861538461538 --> Loss 0.00568929155668\n",
      "Epoch 7::Minibatch 476::LR 0.0861538461538 --> Loss 0.00765958388646\n",
      "Epoch 7::Minibatch 477::LR 0.0861538461538 --> Loss 0.00101026395957\n",
      "Epoch 7::Minibatch 478::LR 0.0861538461538 --> Loss 0.00261952916781\n",
      "Epoch 7::Minibatch 479::LR 0.0861538461538 --> Loss 0.0019824051857\n",
      "Epoch 7::Minibatch 480::LR 0.0861538461538 --> Loss 0.00154675761859\n",
      "Epoch 7::Minibatch 481::LR 0.0861538461538 --> Loss 0.000999102890491\n",
      "Epoch 7::Minibatch 482::LR 0.0861538461538 --> Loss 0.00216286242008\n",
      "Epoch 7::Minibatch 483::LR 0.0861538461538 --> Loss 0.00353140830994\n",
      "Epoch 7::Minibatch 484::LR 0.0861538461538 --> Loss 0.00374883492788\n",
      "Epoch 7::Minibatch 485::LR 0.0861538461538 --> Loss 0.000801730453968\n",
      "Epoch 7::Minibatch 486::LR 0.0861538461538 --> Loss 0.00331755340099\n",
      "Epoch 7::Minibatch 487::LR 0.0861538461538 --> Loss 0.00364783326785\n",
      "Epoch 7::Minibatch 488::LR 0.0861538461538 --> Loss 0.0020669978857\n",
      "Epoch 7::Minibatch 489::LR 0.0861538461538 --> Loss 0.0033076920112\n",
      "Epoch 7::Minibatch 490::LR 0.0861538461538 --> Loss 0.00046072507898\n",
      "Epoch 7::Minibatch 491::LR 0.0861538461538 --> Loss 0.00467949668566\n",
      "Epoch 7::Minibatch 492::LR 0.0861538461538 --> Loss 0.00305094103018\n",
      "Epoch 7::Minibatch 493::LR 0.0861538461538 --> Loss 0.00309001108011\n",
      "Epoch 7::Minibatch 494::LR 0.0861538461538 --> Loss 0.000786138921976\n",
      "Epoch 7::Minibatch 495::LR 0.0861538461538 --> Loss 0.00198060154915\n",
      "Epoch 7::Minibatch 496::LR 0.0861538461538 --> Loss 0.00313841442267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 497::LR 0.0861538461538 --> Loss 0.0009991979599\n",
      "Epoch 7::Minibatch 498::LR 0.0861538461538 --> Loss 0.000656269490719\n",
      "Epoch 7::Minibatch 499::LR 0.0861538461538 --> Loss 0.00410833279292\n",
      "Epoch 7::Minibatch 500::LR 0.0861538461538 --> Loss 0.00147720605135\n",
      "Epoch 7::Minibatch 501::LR 0.0861538461538 --> Loss 0.0023348202308\n",
      "Epoch 7::Minibatch 502::LR 0.0861538461538 --> Loss 0.00416625698407\n",
      "Epoch 7::Minibatch 503::LR 0.0861538461538 --> Loss 0.0106985314687\n",
      "Epoch 7::Minibatch 504::LR 0.0861538461538 --> Loss 0.00857695102692\n",
      "Epoch 7::Minibatch 505::LR 0.0861538461538 --> Loss 0.00466999570529\n",
      "Epoch 7::Minibatch 506::LR 0.0861538461538 --> Loss 0.00369281291962\n",
      "Epoch 7::Minibatch 507::LR 0.0861538461538 --> Loss 0.00618451436361\n",
      "Epoch 7::Minibatch 508::LR 0.0861538461538 --> Loss 0.00339405179024\n",
      "Epoch 7::Minibatch 509::LR 0.0861538461538 --> Loss 0.00487571120262\n",
      "Epoch 7::Minibatch 510::LR 0.0861538461538 --> Loss 0.00496246139208\n",
      "Epoch 7::Minibatch 511::LR 0.0861538461538 --> Loss 0.00385341604551\n",
      "Epoch 7::Minibatch 512::LR 0.0861538461538 --> Loss 0.00278628905614\n",
      "Epoch 7::Minibatch 513::LR 0.0861538461538 --> Loss 0.000841523309549\n",
      "Epoch 7::Minibatch 514::LR 0.0861538461538 --> Loss 0.00285367012024\n",
      "Epoch 7::Minibatch 515::LR 0.0861538461538 --> Loss 0.00314327220122\n",
      "Epoch 7::Minibatch 516::LR 0.0861538461538 --> Loss 0.00432973504066\n",
      "Epoch 7::Minibatch 517::LR 0.0861538461538 --> Loss 0.00337519685427\n",
      "Epoch 7::Minibatch 518::LR 0.0861538461538 --> Loss 0.00259202539921\n",
      "Epoch 7::Minibatch 519::LR 0.0861538461538 --> Loss 0.00339321533839\n",
      "Epoch 7::Minibatch 520::LR 0.0861538461538 --> Loss 0.00549178401629\n",
      "Epoch 7::Minibatch 521::LR 0.0861538461538 --> Loss 0.00607738057772\n",
      "Epoch 7::Minibatch 522::LR 0.0861538461538 --> Loss 0.00827645301819\n",
      "Epoch 7::Minibatch 523::LR 0.0861538461538 --> Loss 0.000786259720723\n",
      "Epoch 7::Minibatch 524::LR 0.0861538461538 --> Loss 0.00149604688088\n",
      "Epoch 7::Minibatch 525::LR 0.0861538461538 --> Loss 0.00338145772616\n",
      "Epoch 7::Minibatch 526::LR 0.0861538461538 --> Loss 0.00441447496414\n",
      "Epoch 7::Minibatch 527::LR 0.0861538461538 --> Loss 0.00264009495576\n",
      "Epoch 7::Minibatch 528::LR 0.0861538461538 --> Loss 0.00144120832284\n",
      "Epoch 7::Minibatch 529::LR 0.0861538461538 --> Loss 0.00442208131154\n",
      "Epoch 7::Minibatch 530::LR 0.0861538461538 --> Loss 0.00455051382383\n",
      "Epoch 7::Minibatch 531::LR 0.0861538461538 --> Loss 0.00391990423203\n",
      "Epoch 7::Minibatch 532::LR 0.0861538461538 --> Loss 0.00283461729685\n",
      "Epoch 7::Minibatch 533::LR 0.0861538461538 --> Loss 0.00501010258993\n",
      "Epoch 7::Minibatch 534::LR 0.0861538461538 --> Loss 0.00396453142166\n",
      "Epoch 7::Minibatch 535::LR 0.0861538461538 --> Loss 0.00332028746605\n",
      "Epoch 7::Minibatch 536::LR 0.0861538461538 --> Loss 0.00216875394185\n",
      "Epoch 7::Minibatch 537::LR 0.0861538461538 --> Loss 0.000800928672155\n",
      "Epoch 7::Minibatch 538::LR 0.0861538461538 --> Loss 0.00180273433526\n",
      "Epoch 7::Minibatch 539::LR 0.0861538461538 --> Loss 0.00353155533473\n",
      "Epoch 7::Minibatch 540::LR 0.0861538461538 --> Loss 0.00343953053157\n",
      "Epoch 7::Minibatch 541::LR 0.0861538461538 --> Loss 0.00295218348503\n",
      "Epoch 7::Minibatch 542::LR 0.0861538461538 --> Loss 0.00268064101537\n",
      "Epoch 7::Minibatch 543::LR 0.0861538461538 --> Loss 0.0029820762078\n",
      "Epoch 7::Minibatch 544::LR 0.0861538461538 --> Loss 0.00408558090528\n",
      "Epoch 7::Minibatch 545::LR 0.0861538461538 --> Loss 0.00213247358799\n",
      "Epoch 7::Minibatch 546::LR 0.0861538461538 --> Loss 0.000734186917543\n",
      "Epoch 7::Minibatch 547::LR 0.0861538461538 --> Loss 0.0027289601167\n",
      "Epoch 7::Minibatch 548::LR 0.0861538461538 --> Loss 0.00425741434097\n",
      "Epoch 7::Minibatch 549::LR 0.0861538461538 --> Loss 0.00798256874084\n",
      "Epoch 7::Minibatch 550::LR 0.0861538461538 --> Loss 0.00121820698182\n",
      "Epoch 7::Minibatch 551::LR 0.0861538461538 --> Loss 0.002509166797\n",
      "Epoch 7::Minibatch 552::LR 0.0861538461538 --> Loss 0.00382582585017\n",
      "Epoch 7::Minibatch 553::LR 0.0861538461538 --> Loss 0.00342251380285\n",
      "Epoch 7::Minibatch 554::LR 0.0861538461538 --> Loss 0.00402662913005\n",
      "Epoch 7::Minibatch 555::LR 0.0861538461538 --> Loss 0.00107426931461\n",
      "Epoch 7::Minibatch 556::LR 0.0861538461538 --> Loss 0.0021710006396\n",
      "Epoch 7::Minibatch 557::LR 0.0861538461538 --> Loss 0.00263076583544\n",
      "Epoch 7::Minibatch 558::LR 0.0861538461538 --> Loss 0.00403367956479\n",
      "Epoch 7::Minibatch 559::LR 0.0861538461538 --> Loss 0.00386298497518\n",
      "Epoch 7::Minibatch 560::LR 0.0861538461538 --> Loss 0.00332319835822\n",
      "Epoch 7::Minibatch 561::LR 0.0861538461538 --> Loss 0.00293605744839\n",
      "Epoch 7::Minibatch 562::LR 0.0861538461538 --> Loss 0.00249437153339\n",
      "Epoch 7::Minibatch 563::LR 0.0861538461538 --> Loss 0.00423937718074\n",
      "Epoch 7::Minibatch 564::LR 0.0861538461538 --> Loss 0.0032733186086\n",
      "Epoch 7::Minibatch 565::LR 0.0861538461538 --> Loss 0.00389802614848\n",
      "Epoch 7::Minibatch 566::LR 0.0861538461538 --> Loss 0.00244214038054\n",
      "Epoch 7::Minibatch 567::LR 0.0861538461538 --> Loss 0.00277711013953\n",
      "Epoch 7::Minibatch 568::LR 0.0861538461538 --> Loss 0.00191767831643\n",
      "Epoch 7::Minibatch 569::LR 0.0861538461538 --> Loss 0.000626508742571\n",
      "Epoch 7::Minibatch 570::LR 0.0861538461538 --> Loss 0.00185029725234\n",
      "Epoch 7::Minibatch 571::LR 0.0861538461538 --> Loss 0.00243002851804\n",
      "Epoch 7::Minibatch 572::LR 0.0861538461538 --> Loss 0.00254350403945\n",
      "Epoch 7::Minibatch 573::LR 0.0861538461538 --> Loss 0.00159399360418\n",
      "Epoch 7::Minibatch 574::LR 0.0861538461538 --> Loss 0.00109384477139\n",
      "Epoch 7::Minibatch 575::LR 0.0861538461538 --> Loss 0.00190691590309\n",
      "Epoch 7::Minibatch 576::LR 0.0861538461538 --> Loss 0.00228965004285\n",
      "Epoch 7::Minibatch 577::LR 0.0861538461538 --> Loss 0.00178254564603\n",
      "Epoch 7::Minibatch 578::LR 0.0861538461538 --> Loss 0.00134479145209\n",
      "Epoch 7::Minibatch 579::LR 0.0861538461538 --> Loss 0.00126499851545\n",
      "Epoch 7::Minibatch 580::LR 0.0861538461538 --> Loss 0.00205858588219\n",
      "Epoch 7::Minibatch 581::LR 0.0861538461538 --> Loss 0.0017843101422\n",
      "Epoch 7::Minibatch 582::LR 0.0861538461538 --> Loss 0.00424166361491\n",
      "Epoch 7::Minibatch 583::LR 0.0861538461538 --> Loss 0.000990107754866\n",
      "Epoch 7::Minibatch 584::LR 0.0861538461538 --> Loss 0.00136351287365\n",
      "Epoch 7::Minibatch 585::LR 0.0861538461538 --> Loss 0.00570449988047\n",
      "Epoch 7::Minibatch 586::LR 0.0861538461538 --> Loss 0.00439485748609\n",
      "Epoch 7::Minibatch 587::LR 0.0861538461538 --> Loss 0.00119738896688\n",
      "Epoch 7::Minibatch 588::LR 0.0861538461538 --> Loss 0.0015049992005\n",
      "Epoch 7::Minibatch 589::LR 0.0861538461538 --> Loss 0.0028453618288\n",
      "Epoch 7::Minibatch 590::LR 0.0861538461538 --> Loss 0.00220624128977\n",
      "Epoch 7::Minibatch 591::LR 0.0861538461538 --> Loss 0.0038118326664\n",
      "Epoch 7::Minibatch 592::LR 0.0861538461538 --> Loss 0.00124614457289\n",
      "Epoch 7::Minibatch 593::LR 0.0861538461538 --> Loss 0.00270497957865\n",
      "Epoch 7::Minibatch 594::LR 0.0861538461538 --> Loss 0.00302331010501\n",
      "Epoch 7::Minibatch 595::LR 0.0861538461538 --> Loss 0.00311452587446\n",
      "Epoch 7::Minibatch 596::LR 0.0861538461538 --> Loss 0.00210217197736\n",
      "Epoch 7::Minibatch 597::LR 0.0861538461538 --> Loss 0.00127744575342\n",
      "Epoch 7::Minibatch 598::LR 0.0861538461538 --> Loss 0.00334237615267\n",
      "Epoch 7::Minibatch 599::LR 0.0861538461538 --> Loss 0.00197219649951\n",
      "Epoch 7::Minibatch 600::LR 0.0861538461538 --> Loss 0.00240948855877\n",
      "Epoch 7::Minibatch 601::LR 0.0861538461538 --> Loss 0.00393086433411\n",
      "Epoch 7::Minibatch 602::LR 0.0861538461538 --> Loss 0.00218683600426\n",
      "Epoch 7::Minibatch 603::LR 0.0861538461538 --> Loss 0.00279489139716\n",
      "Epoch 7::Minibatch 604::LR 0.0861538461538 --> Loss 0.00171425402164\n",
      "Epoch 7::Minibatch 605::LR 0.0861538461538 --> Loss 0.00255771199862\n",
      "Epoch 7::Minibatch 606::LR 0.0861538461538 --> Loss 0.00204048295816\n",
      "Epoch 7::Minibatch 607::LR 0.0861538461538 --> Loss 0.000886959731579\n",
      "Epoch 7::Minibatch 608::LR 0.0861538461538 --> Loss 0.00172512551149\n",
      "Epoch 7::Minibatch 609::LR 0.0861538461538 --> Loss 0.00239737828573\n",
      "Epoch 7::Minibatch 610::LR 0.0861538461538 --> Loss 0.00400186936061\n",
      "Epoch 7::Minibatch 611::LR 0.0861538461538 --> Loss 0.00273223956426\n",
      "Epoch 7::Minibatch 612::LR 0.0861538461538 --> Loss 0.000575295190016\n",
      "Epoch 7::Minibatch 613::LR 0.0861538461538 --> Loss 0.00139698117971\n",
      "Epoch 7::Minibatch 614::LR 0.0861538461538 --> Loss 0.00260989149412\n",
      "Epoch 7::Minibatch 615::LR 0.0861538461538 --> Loss 0.00178023437659\n",
      "Epoch 7::Minibatch 616::LR 0.0861538461538 --> Loss 0.000984721382459\n",
      "Epoch 7::Minibatch 617::LR 0.0861538461538 --> Loss 0.000575608362754\n",
      "Epoch 7::Minibatch 618::LR 0.0861538461538 --> Loss 0.00270553568999\n",
      "Epoch 7::Minibatch 619::LR 0.0861538461538 --> Loss 0.0019978427887\n",
      "Epoch 7::Minibatch 620::LR 0.0861538461538 --> Loss 0.00179026722908\n",
      "Epoch 7::Minibatch 621::LR 0.0861538461538 --> Loss 0.000909118453662\n",
      "Epoch 7::Minibatch 622::LR 0.0861538461538 --> Loss 0.000882406532764\n",
      "Epoch 7::Minibatch 623::LR 0.0861538461538 --> Loss 0.00225440303485\n",
      "Epoch 7::Minibatch 624::LR 0.0861538461538 --> Loss 0.00188772777716\n",
      "Epoch 7::Minibatch 625::LR 0.0861538461538 --> Loss 0.00340467015902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 626::LR 0.0861538461538 --> Loss 0.00518410960833\n",
      "Epoch 7::Minibatch 627::LR 0.0861538461538 --> Loss 0.00148416340351\n",
      "Epoch 7::Minibatch 628::LR 0.0861538461538 --> Loss 0.0010245047013\n",
      "Epoch 7::Minibatch 629::LR 0.0861538461538 --> Loss 0.00369455854098\n",
      "Epoch 7::Minibatch 630::LR 0.0861538461538 --> Loss 0.0035485680898\n",
      "Epoch 7::Minibatch 631::LR 0.0861538461538 --> Loss 0.00756543715795\n",
      "Epoch 7::Minibatch 632::LR 0.0861538461538 --> Loss 0.000911633968353\n",
      "Epoch 7::Minibatch 633::LR 0.0861538461538 --> Loss 0.00179562588533\n",
      "Epoch 7::Minibatch 634::LR 0.0861538461538 --> Loss 0.00339191238085\n",
      "Epoch 7::Minibatch 635::LR 0.0861538461538 --> Loss 0.00477740565936\n",
      "Epoch 7::Minibatch 636::LR 0.0861538461538 --> Loss 0.00598944266637\n",
      "Epoch 7::Minibatch 637::LR 0.0861538461538 --> Loss 0.00109699249268\n",
      "Epoch 7::Minibatch 638::LR 0.0861538461538 --> Loss 0.00179002443949\n",
      "Epoch 7::Minibatch 639::LR 0.0861538461538 --> Loss 0.00352694233259\n",
      "Epoch 7::Minibatch 640::LR 0.0861538461538 --> Loss 0.00536914070447\n",
      "Epoch 7::Minibatch 641::LR 0.0861538461538 --> Loss 0.00336365580559\n",
      "Epoch 7::Minibatch 642::LR 0.0861538461538 --> Loss 0.000680107275645\n",
      "Epoch 7::Minibatch 643::LR 0.0861538461538 --> Loss 0.00245916167895\n",
      "Epoch 7::Minibatch 644::LR 0.0861538461538 --> Loss 0.00418214956919\n",
      "Epoch 7::Minibatch 645::LR 0.0861538461538 --> Loss 0.00443664312363\n",
      "Epoch 7::Minibatch 646::LR 0.0861538461538 --> Loss 0.00172291398048\n",
      "Epoch 7::Minibatch 647::LR 0.0861538461538 --> Loss 0.000835842986902\n",
      "Epoch 7::Minibatch 648::LR 0.0861538461538 --> Loss 0.00329345385234\n",
      "Epoch 7::Minibatch 649::LR 0.0861538461538 --> Loss 0.00384684522947\n",
      "Epoch 7::Minibatch 650::LR 0.0861538461538 --> Loss 0.00354699611664\n",
      "Epoch 7::Minibatch 651::LR 0.0861538461538 --> Loss 0.00157523085674\n",
      "Epoch 7::Minibatch 652::LR 0.0861538461538 --> Loss 0.00105087180932\n",
      "Epoch 7::Minibatch 653::LR 0.0861538461538 --> Loss 0.00306656022867\n",
      "Epoch 7::Minibatch 654::LR 0.0861538461538 --> Loss 0.00322808881601\n",
      "Epoch 7::Minibatch 655::LR 0.0861538461538 --> Loss 0.0035455151399\n",
      "Epoch 7::Minibatch 656::LR 0.0861538461538 --> Loss 0.00087979644537\n",
      "Epoch 7::Minibatch 657::LR 0.0861538461538 --> Loss 0.00225630362829\n",
      "Epoch 7::Minibatch 658::LR 0.0861538461538 --> Loss 0.00508022109667\n",
      "Epoch 7::Minibatch 659::LR 0.0861538461538 --> Loss 0.00246281564236\n",
      "Epoch 7::Minibatch 660::LR 0.0861538461538 --> Loss 0.00262508332729\n",
      "Epoch 7::Minibatch 661::LR 0.0861538461538 --> Loss 0.0027007997036\n",
      "Epoch 7::Minibatch 662::LR 0.0861538461538 --> Loss 0.00192039151986\n",
      "Epoch 7::Minibatch 663::LR 0.0861538461538 --> Loss 0.00379715402921\n",
      "Epoch 7::Minibatch 664::LR 0.0861538461538 --> Loss 0.0037059934934\n",
      "Epoch 7::Minibatch 665::LR 0.0861538461538 --> Loss 0.000900706648827\n",
      "Epoch 7::Minibatch 666::LR 0.0861538461538 --> Loss 0.00400567015012\n",
      "Epoch 7::Minibatch 667::LR 0.0861538461538 --> Loss 0.00269298156102\n",
      "Epoch 7::Minibatch 668::LR 0.0861538461538 --> Loss 0.00759361505508\n",
      "Epoch 7::Minibatch 669::LR 0.0861538461538 --> Loss 0.0011665686965\n",
      "Epoch 7::Minibatch 670::LR 0.0861538461538 --> Loss 0.00146257599195\n",
      "Epoch 7::Minibatch 671::LR 0.0861538461538 --> Loss 0.00569251298904\n",
      "Epoch 7::Minibatch 672::LR 0.0861538461538 --> Loss 0.00419001936913\n",
      "Epoch 7::Minibatch 673::LR 0.0861538461538 --> Loss 0.00170505444209\n",
      "Epoch 7::Minibatch 674::LR 0.0861538461538 --> Loss 0.00062377423048\n",
      "Epoch 7::Minibatch 675::LR 0.0861538461538 --> Loss 0.00231998225053\n",
      "Epoch 7::Minibatch 676::LR 0.0861538461538 --> Loss 0.00222233712673\n",
      "Epoch 7::Minibatch 677::LR 0.0861538461538 --> Loss 0.00303604821364\n",
      "Epoch 7::Minibatch 678::LR 0.0861538461538 --> Loss 0.00204637348652\n",
      "Epoch 7::Minibatch 679::LR 0.0861538461538 --> Loss 0.00373099486033\n",
      "Epoch 7::Minibatch 680::LR 0.0861538461538 --> Loss 0.00223649442196\n",
      "Epoch 7::Minibatch 681::LR 0.0861538461538 --> Loss 0.00251840035121\n",
      "Epoch 7::Minibatch 682::LR 0.0861538461538 --> Loss 0.000836452841759\n",
      "Epoch 7::Minibatch 683::LR 0.0861538461538 --> Loss 0.00254124720891\n",
      "Epoch 7::Minibatch 684::LR 0.0861538461538 --> Loss 0.00244670450687\n",
      "Epoch 7::Minibatch 685::LR 0.0861538461538 --> Loss 0.00307174841563\n",
      "Epoch 7::Minibatch 686::LR 0.0861538461538 --> Loss 0.00156242718299\n",
      "Epoch 7::Minibatch 687::LR 0.0861538461538 --> Loss 0.000890921751658\n",
      "Epoch 7::Minibatch 688::LR 0.0861538461538 --> Loss 0.00282423535983\n",
      "Epoch 7::Minibatch 689::LR 0.0861538461538 --> Loss 0.00265047291915\n",
      "Epoch 7::Minibatch 690::LR 0.0861538461538 --> Loss 0.00199064413706\n",
      "Epoch 7::Minibatch 691::LR 0.0861538461538 --> Loss 0.000720007469257\n",
      "Epoch 7::Minibatch 692::LR 0.0861538461538 --> Loss 0.00258867681026\n",
      "Epoch 7::Minibatch 693::LR 0.0861538461538 --> Loss 0.00264772673448\n",
      "Epoch 7::Minibatch 694::LR 0.0861538461538 --> Loss 0.0030904541413\n",
      "Epoch 7::Minibatch 695::LR 0.0861538461538 --> Loss 0.00178165694078\n",
      "Epoch 7::Minibatch 696::LR 0.0861538461538 --> Loss 0.00205560425917\n",
      "Epoch 7::Minibatch 697::LR 0.0861538461538 --> Loss 0.0014506577452\n",
      "Epoch 7::Minibatch 698::LR 0.0861538461538 --> Loss 0.00163877705733\n",
      "Epoch 7::Minibatch 699::LR 0.0861538461538 --> Loss 0.00393371542295\n",
      "Epoch 7::Minibatch 700::LR 0.0861538461538 --> Loss 0.00276529232661\n",
      "Epoch 7::Minibatch 701::LR 0.0861538461538 --> Loss 0.00210517267386\n",
      "Epoch 7::Minibatch 702::LR 0.0861538461538 --> Loss 0.00174117863178\n",
      "Epoch 7::Minibatch 703::LR 0.0861538461538 --> Loss 0.00421509504318\n",
      "Epoch 7::Minibatch 704::LR 0.0861538461538 --> Loss 0.00185999492804\n",
      "Epoch 7::Minibatch 705::LR 0.0861538461538 --> Loss 0.00286717434724\n",
      "Epoch 7::Minibatch 706::LR 0.0861538461538 --> Loss 0.00222061137358\n",
      "Epoch 7::Minibatch 707::LR 0.0861538461538 --> Loss 0.00124697595835\n",
      "Epoch 7::Minibatch 708::LR 0.0861538461538 --> Loss 0.00178212126096\n",
      "Epoch 7::Minibatch 709::LR 0.0861538461538 --> Loss 0.00178392827511\n",
      "Epoch 7::Minibatch 710::LR 0.0861538461538 --> Loss 0.00250164528688\n",
      "Epoch 7::Minibatch 711::LR 0.0861538461538 --> Loss 0.00190905312697\n",
      "Epoch 7::Minibatch 712::LR 0.0861538461538 --> Loss 0.00137544025977\n",
      "Epoch 7::Minibatch 713::LR 0.0861538461538 --> Loss 0.00177455623945\n",
      "Epoch 7::Minibatch 714::LR 0.0861538461538 --> Loss 0.00271713813146\n",
      "Epoch 7::Minibatch 715::LR 0.0861538461538 --> Loss 0.00298415402571\n",
      "Epoch 7::Minibatch 716::LR 0.0861538461538 --> Loss 0.00163405050834\n",
      "Epoch 7::Minibatch 717::LR 0.0861538461538 --> Loss 0.00163939446211\n",
      "Epoch 7::Minibatch 718::LR 0.0861538461538 --> Loss 0.00132350663344\n",
      "Epoch 7::Minibatch 719::LR 0.0861538461538 --> Loss 0.00171764731407\n",
      "Epoch 7::Minibatch 720::LR 0.0861538461538 --> Loss 0.00249691406886\n",
      "Epoch 7::Minibatch 721::LR 0.0861538461538 --> Loss 0.000711732457081\n",
      "Epoch 7::Minibatch 722::LR 0.0861538461538 --> Loss 0.00503331581752\n",
      "Epoch 7::Minibatch 723::LR 0.0861538461538 --> Loss 0.00491919318835\n",
      "Epoch 7::Minibatch 724::LR 0.0861538461538 --> Loss 0.00104368905226\n",
      "Epoch 7::Minibatch 725::LR 0.0861538461538 --> Loss 0.0024129140377\n",
      "Epoch 7::Minibatch 726::LR 0.0861538461538 --> Loss 0.0052542702357\n",
      "Epoch 7::Minibatch 727::LR 0.0861538461538 --> Loss 0.00306007921696\n",
      "Epoch 7::Minibatch 728::LR 0.0861538461538 --> Loss 0.000719661712646\n",
      "Epoch 7::Minibatch 729::LR 0.0861538461538 --> Loss 0.000867180426915\n",
      "Epoch 7::Minibatch 730::LR 0.0861538461538 --> Loss 0.00265764216582\n",
      "Epoch 7::Minibatch 731::LR 0.0861538461538 --> Loss 0.00249966621399\n",
      "Epoch 7::Minibatch 732::LR 0.0861538461538 --> Loss 0.00248048027356\n",
      "Epoch 7::Minibatch 733::LR 0.0861538461538 --> Loss 0.000877549648285\n",
      "Epoch 7::Minibatch 734::LR 0.0861538461538 --> Loss 0.00193821489811\n",
      "Epoch 7::Minibatch 735::LR 0.0861538461538 --> Loss 0.00242915709813\n",
      "Epoch 7::Minibatch 736::LR 0.0861538461538 --> Loss 0.00348878661791\n",
      "Epoch 7::Minibatch 737::LR 0.0861538461538 --> Loss 0.00321447590987\n",
      "Epoch 7::Minibatch 738::LR 0.0861538461538 --> Loss 0.00181915918986\n",
      "Epoch 7::Minibatch 739::LR 0.0861538461538 --> Loss 0.00257016539574\n",
      "Epoch 7::Minibatch 740::LR 0.0861538461538 --> Loss 0.00389675140381\n",
      "Epoch 7::Minibatch 741::LR 0.0861538461538 --> Loss 0.00286687632402\n",
      "Epoch 7::Minibatch 742::LR 0.0861538461538 --> Loss 0.00218948543072\n",
      "Epoch 7::Minibatch 743::LR 0.0861538461538 --> Loss 0.00136999726295\n",
      "Epoch 7::Minibatch 744::LR 0.0861538461538 --> Loss 0.00185846328735\n",
      "Epoch 7::Minibatch 745::LR 0.0861538461538 --> Loss 0.00290188709895\n",
      "Epoch 7::Minibatch 746::LR 0.0861538461538 --> Loss 0.00309998691082\n",
      "Epoch 7::Minibatch 747::LR 0.0861538461538 --> Loss 0.00183249215285\n",
      "Epoch 7::Minibatch 748::LR 0.0861538461538 --> Loss 0.000720852414767\n",
      "Epoch 7::Minibatch 749::LR 0.0861538461538 --> Loss 0.00171169777711\n",
      "Epoch 7::Minibatch 750::LR 0.0861538461538 --> Loss 0.00253290692965\n",
      "Epoch 7::Minibatch 751::LR 0.0861538461538 --> Loss 0.00271367907524\n",
      "Epoch 7::Minibatch 752::LR 0.0861538461538 --> Loss 0.00111850877603\n",
      "Epoch 7::Minibatch 753::LR 0.0861538461538 --> Loss 0.00231817384561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 754::LR 0.0861538461538 --> Loss 0.00241482496262\n",
      "Epoch 7::Minibatch 755::LR 0.0861538461538 --> Loss 0.00270177543163\n",
      "Epoch 7::Minibatch 756::LR 0.0861538461538 --> Loss 0.00154394010703\n",
      "Epoch 7::Minibatch 757::LR 0.0861538461538 --> Loss 0.00103009402752\n",
      "Epoch 7::Minibatch 758::LR 0.0861538461538 --> Loss 0.00172694563866\n",
      "Epoch 7::Minibatch 759::LR 0.0861538461538 --> Loss 0.00392711321513\n",
      "Epoch 7::Minibatch 760::LR 0.0861538461538 --> Loss 0.00321467240651\n",
      "Epoch 7::Minibatch 761::LR 0.0861538461538 --> Loss 0.00650510191917\n",
      "Epoch 7::Minibatch 762::LR 0.0861538461538 --> Loss 0.00389648199081\n",
      "Epoch 7::Minibatch 763::LR 0.0861538461538 --> Loss 0.00377978126208\n",
      "Epoch 7::Minibatch 764::LR 0.0861538461538 --> Loss 0.00335360685984\n",
      "Epoch 7::Minibatch 765::LR 0.0861538461538 --> Loss 0.00141819685698\n",
      "Epoch 7::Minibatch 766::LR 0.0861538461538 --> Loss 0.00231292724609\n",
      "Epoch 7::Minibatch 767::LR 0.0861538461538 --> Loss 0.00512666503588\n",
      "Epoch 7::Minibatch 768::LR 0.0861538461538 --> Loss 0.00355978091558\n",
      "Epoch 7::Minibatch 769::LR 0.0861538461538 --> Loss 0.00200641274452\n",
      "Epoch 7::Minibatch 770::LR 0.0861538461538 --> Loss 0.00153624286254\n",
      "Epoch 7::Minibatch 771::LR 0.0861538461538 --> Loss 0.00392438729604\n",
      "Epoch 7::Minibatch 772::LR 0.0861538461538 --> Loss 0.00336037397385\n",
      "Epoch 7::Minibatch 773::LR 0.0861538461538 --> Loss 0.00322276433309\n",
      "Epoch 7::Minibatch 774::LR 0.0861538461538 --> Loss 0.00179360310237\n",
      "Epoch 7::Minibatch 775::LR 0.0861538461538 --> Loss 0.00462086757024\n",
      "Epoch 7::Minibatch 776::LR 0.0861538461538 --> Loss 0.00363052129745\n",
      "Epoch 7::Minibatch 777::LR 0.0861538461538 --> Loss 0.00807930787404\n",
      "Epoch 7::Minibatch 778::LR 0.0861538461538 --> Loss 0.0113272182147\n",
      "Epoch 7::Minibatch 779::LR 0.0861538461538 --> Loss 0.0017763197422\n",
      "Epoch 7::Minibatch 780::LR 0.0861538461538 --> Loss 0.00175168593725\n",
      "Epoch 7::Minibatch 781::LR 0.0861538461538 --> Loss 0.00371193726858\n",
      "Epoch 7::Minibatch 782::LR 0.0861538461538 --> Loss 0.00433577736219\n",
      "Epoch 7::Minibatch 783::LR 0.0861538461538 --> Loss 0.00245073497295\n",
      "Epoch 7::Minibatch 784::LR 0.0861538461538 --> Loss 0.000828487078349\n",
      "Epoch 7::Minibatch 785::LR 0.0861538461538 --> Loss 0.00428620219231\n",
      "Epoch 7::Minibatch 786::LR 0.0861538461538 --> Loss 0.00384151498477\n",
      "Epoch 7::Minibatch 787::LR 0.0861538461538 --> Loss 0.0030436082681\n",
      "Epoch 7::Minibatch 788::LR 0.0861538461538 --> Loss 0.00267913659414\n",
      "Epoch 7::Minibatch 789::LR 0.0861538461538 --> Loss 0.000810132175684\n",
      "Epoch 7::Minibatch 790::LR 0.0861538461538 --> Loss 0.00341222127279\n",
      "Epoch 7::Minibatch 791::LR 0.0861538461538 --> Loss 0.00402148564657\n",
      "Epoch 7::Minibatch 792::LR 0.0861538461538 --> Loss 0.00377968708674\n",
      "Epoch 7::Minibatch 793::LR 0.0861538461538 --> Loss 0.00219980498155\n",
      "Epoch 7::Minibatch 794::LR 0.0861538461538 --> Loss 0.00125718931357\n",
      "Epoch 7::Minibatch 795::LR 0.0861538461538 --> Loss 0.00367986957232\n",
      "Epoch 7::Minibatch 796::LR 0.0861538461538 --> Loss 0.00641356865565\n",
      "Epoch 7::Minibatch 797::LR 0.0861538461538 --> Loss 0.00884651899338\n",
      "Epoch 7::Minibatch 798::LR 0.0861538461538 --> Loss 0.00363941947619\n",
      "Epoch 7::Minibatch 799::LR 0.0861538461538 --> Loss 0.00279157181581\n",
      "Epoch 7::Minibatch 800::LR 0.0861538461538 --> Loss 0.00218437234561\n",
      "Epoch 7::Minibatch 801::LR 0.0861538461538 --> Loss 0.00422161022822\n",
      "Epoch 7::Minibatch 802::LR 0.0861538461538 --> Loss 0.00151644587517\n",
      "Epoch 7::Minibatch 803::LR 0.0861538461538 --> Loss 0.00281627118587\n",
      "Epoch 7::Minibatch 804::LR 0.0861538461538 --> Loss 0.00239993929863\n",
      "Epoch 7::Minibatch 805::LR 0.0861538461538 --> Loss 0.00244849741459\n",
      "Epoch 7::Minibatch 806::LR 0.0861538461538 --> Loss 0.00335271755854\n",
      "Epoch 7::Minibatch 807::LR 0.0861538461538 --> Loss 0.00315396904945\n",
      "Epoch 7::Minibatch 808::LR 0.0861538461538 --> Loss 0.00300698717435\n",
      "Epoch 7::Minibatch 809::LR 0.0861538461538 --> Loss 0.00462239980698\n",
      "Epoch 7::Minibatch 810::LR 0.0861538461538 --> Loss 0.00574655969938\n",
      "Epoch 7::Minibatch 811::LR 0.0861538461538 --> Loss 0.00537803212802\n",
      "Epoch 7::Minibatch 812::LR 0.0861538461538 --> Loss 0.00538697242737\n",
      "Epoch 7::Minibatch 813::LR 0.0861538461538 --> Loss 0.00521888693174\n",
      "Epoch 7::Minibatch 814::LR 0.0861538461538 --> Loss 0.00243116378784\n",
      "Epoch 7::Minibatch 815::LR 0.0861538461538 --> Loss 0.00444495956103\n",
      "Epoch 7::Minibatch 816::LR 0.0861538461538 --> Loss 0.0045082906882\n",
      "Epoch 7::Minibatch 817::LR 0.0861538461538 --> Loss 0.00536116123199\n",
      "Epoch 7::Minibatch 818::LR 0.0861538461538 --> Loss 0.00157099654277\n",
      "Epoch 7::Minibatch 819::LR 0.0861538461538 --> Loss 0.000919751723607\n",
      "Epoch 7::Minibatch 820::LR 0.0861538461538 --> Loss 0.00568195939064\n",
      "Epoch 7::Minibatch 821::LR 0.0861538461538 --> Loss 0.00347099820773\n",
      "Epoch 7::Minibatch 822::LR 0.0861538461538 --> Loss 0.00412015279134\n",
      "Epoch 7::Minibatch 823::LR 0.0861538461538 --> Loss 0.00141333858172\n",
      "Epoch 7::Minibatch 824::LR 0.0861538461538 --> Loss 0.00153038372596\n",
      "Epoch 7::Minibatch 825::LR 0.0861538461538 --> Loss 0.00396332899729\n",
      "Epoch 7::Minibatch 826::LR 0.0861538461538 --> Loss 0.00398922244708\n",
      "Epoch 7::Minibatch 827::LR 0.0861538461538 --> Loss 0.00254603803158\n",
      "Epoch 7::Minibatch 828::LR 0.0861538461538 --> Loss 0.00094823906819\n",
      "Epoch 7::Minibatch 829::LR 0.0861538461538 --> Loss 0.00263225038846\n",
      "Epoch 7::Minibatch 830::LR 0.0861538461538 --> Loss 0.00462682962418\n",
      "Epoch 7::Minibatch 831::LR 0.0861538461538 --> Loss 0.00267270803452\n",
      "Epoch 7::Minibatch 832::LR 0.0861538461538 --> Loss 0.0023758773009\n",
      "Epoch 7::Minibatch 833::LR 0.0861538461538 --> Loss 0.00192580739657\n",
      "Epoch 7::Minibatch 834::LR 0.0861538461538 --> Loss 0.000848083396753\n",
      "Epoch 7::Minibatch 835::LR 0.0861538461538 --> Loss 0.00393503546715\n",
      "Epoch 7::Minibatch 836::LR 0.0861538461538 --> Loss 0.00396964391073\n",
      "Epoch 7::Minibatch 837::LR 0.0861538461538 --> Loss 0.0024512954553\n",
      "Epoch 7::Minibatch 838::LR 0.0861538461538 --> Loss 0.00073905830582\n",
      "Epoch 7::Minibatch 839::LR 0.0861538461538 --> Loss 0.00255653619766\n",
      "Epoch 7::Minibatch 840::LR 0.0861538461538 --> Loss 0.00309052467346\n",
      "Epoch 7::Minibatch 841::LR 0.0861538461538 --> Loss 0.00312763770421\n",
      "Epoch 7::Minibatch 842::LR 0.0861538461538 --> Loss 0.00230532824993\n",
      "Epoch 7::Minibatch 843::LR 0.0861538461538 --> Loss 0.00108403871457\n",
      "Epoch 7::Minibatch 844::LR 0.0861538461538 --> Loss 0.00160533736149\n",
      "Epoch 7::Minibatch 845::LR 0.0861538461538 --> Loss 0.00449439446131\n",
      "Epoch 7::Minibatch 846::LR 0.0861538461538 --> Loss 0.00177650908629\n",
      "Epoch 7::Minibatch 847::LR 0.0861538461538 --> Loss 0.00249776721001\n",
      "Epoch 7::Minibatch 848::LR 0.0861538461538 --> Loss 0.00108062744141\n",
      "Epoch 7::Minibatch 849::LR 0.0861538461538 --> Loss 0.00199349105358\n",
      "Epoch 7::Minibatch 850::LR 0.0861538461538 --> Loss 0.00332708875338\n",
      "Epoch 7::Minibatch 851::LR 0.0861538461538 --> Loss 0.00298100610574\n",
      "Epoch 7::Minibatch 852::LR 0.0861538461538 --> Loss 0.00114311953386\n",
      "Epoch 7::Minibatch 853::LR 0.0861538461538 --> Loss 0.00140177597602\n",
      "Epoch 7::Minibatch 854::LR 0.0861538461538 --> Loss 0.00261109431585\n",
      "Epoch 7::Minibatch 855::LR 0.0861538461538 --> Loss 0.00225087821484\n",
      "Epoch 7::Minibatch 856::LR 0.0861538461538 --> Loss 0.00184508681297\n",
      "Epoch 7::Minibatch 857::LR 0.0861538461538 --> Loss 0.00126421133677\n",
      "Epoch 7::Minibatch 858::LR 0.0861538461538 --> Loss 0.000661004831394\n",
      "Epoch 7::Minibatch 859::LR 0.0861538461538 --> Loss 0.00191191474597\n",
      "Epoch 7::Minibatch 860::LR 0.0861538461538 --> Loss 0.00125169793765\n",
      "Epoch 7::Minibatch 861::LR 0.0861538461538 --> Loss 0.000979822178682\n",
      "Epoch 7::Minibatch 862::LR 0.0861538461538 --> Loss 0.00369140625\n",
      "Epoch 7::Minibatch 863::LR 0.0861538461538 --> Loss 0.00348558863004\n",
      "Epoch 7::Minibatch 864::LR 0.0861538461538 --> Loss 0.00320580045382\n",
      "Epoch 7::Minibatch 865::LR 0.0861538461538 --> Loss 0.000644726703564\n",
      "Epoch 7::Minibatch 866::LR 0.0861538461538 --> Loss 0.00229414264361\n",
      "Epoch 7::Minibatch 867::LR 0.0861538461538 --> Loss 0.00318502147992\n",
      "Epoch 7::Minibatch 868::LR 0.0861538461538 --> Loss 0.00269681533178\n",
      "Epoch 7::Minibatch 869::LR 0.0861538461538 --> Loss 0.00217113931974\n",
      "Epoch 7::Minibatch 870::LR 0.0861538461538 --> Loss 0.00377613027891\n",
      "Epoch 7::Minibatch 871::LR 0.0861538461538 --> Loss 0.00159683893124\n",
      "Epoch 7::Minibatch 872::LR 0.0861538461538 --> Loss 0.00240906993548\n",
      "Epoch 7::Minibatch 873::LR 0.0861538461538 --> Loss 0.00257474879424\n",
      "Epoch 7::Minibatch 874::LR 0.0861538461538 --> Loss 0.00650856892268\n",
      "Epoch 7::Minibatch 875::LR 0.0861538461538 --> Loss 0.000607601056496\n",
      "Epoch 7::Minibatch 876::LR 0.0861538461538 --> Loss 0.00388617873192\n",
      "Epoch 7::Minibatch 877::LR 0.0861538461538 --> Loss 0.00429698864619\n",
      "Epoch 7::Minibatch 878::LR 0.0861538461538 --> Loss 0.00349296212196\n",
      "Epoch 7::Minibatch 879::LR 0.0861538461538 --> Loss 0.00394215186437\n",
      "Epoch 7::Minibatch 880::LR 0.0861538461538 --> Loss 0.00456224958102\n",
      "Epoch 7::Minibatch 881::LR 0.0861538461538 --> Loss 0.00418754975001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 882::LR 0.0861538461538 --> Loss 0.00206971168518\n",
      "Epoch 7::Minibatch 883::LR 0.0861538461538 --> Loss 0.00336189349492\n",
      "Epoch 7::Minibatch 884::LR 0.0861538461538 --> Loss 0.00270860354106\n",
      "Epoch 7::Minibatch 885::LR 0.0861538461538 --> Loss 0.00243587732315\n",
      "Epoch 7::Minibatch 886::LR 0.0861538461538 --> Loss 0.000624019255241\n",
      "Epoch 7::Minibatch 887::LR 0.0861538461538 --> Loss 0.00531150857608\n",
      "Epoch 7::Minibatch 888::LR 0.0861538461538 --> Loss 0.00273239076138\n",
      "Epoch 7::Minibatch 889::LR 0.0861538461538 --> Loss 0.00317320923011\n",
      "Epoch 7::Minibatch 890::LR 0.0861538461538 --> Loss 0.00441011706988\n",
      "Epoch 7::Minibatch 891::LR 0.0861538461538 --> Loss 0.0020749437809\n",
      "Epoch 7::Minibatch 892::LR 0.0861538461538 --> Loss 0.00104172279437\n",
      "Epoch 7::Minibatch 893::LR 0.0861538461538 --> Loss 0.00263516525428\n",
      "Epoch 7::Minibatch 894::LR 0.0861538461538 --> Loss 0.00236772278945\n",
      "Epoch 7::Minibatch 895::LR 0.0861538461538 --> Loss 0.00250970602036\n",
      "Epoch 7::Minibatch 896::LR 0.0861538461538 --> Loss 0.00142024368048\n",
      "Epoch 7::Minibatch 897::LR 0.0861538461538 --> Loss 0.000846760372321\n",
      "Epoch 7::Minibatch 898::LR 0.0861538461538 --> Loss 0.00228216906389\n",
      "Epoch 7::Minibatch 899::LR 0.0861538461538 --> Loss 0.00252607603868\n",
      "Epoch 7::Minibatch 900::LR 0.0861538461538 --> Loss 0.00335580786069\n",
      "Epoch 7::Minibatch 901::LR 0.0861538461538 --> Loss 0.000689032922188\n",
      "Epoch 7::Minibatch 902::LR 0.0861538461538 --> Loss 0.00148187021414\n",
      "Epoch 7::Minibatch 903::LR 0.0861538461538 --> Loss 0.0026239524285\n",
      "Epoch 7::Minibatch 904::LR 0.0861538461538 --> Loss 0.00212670564651\n",
      "Epoch 7::Minibatch 905::LR 0.0861538461538 --> Loss 0.0014920882384\n",
      "Epoch 7::Minibatch 906::LR 0.0861538461538 --> Loss 0.00116902252038\n",
      "Epoch 7::Minibatch 907::LR 0.0861538461538 --> Loss 0.00160115559896\n",
      "Epoch 7::Minibatch 908::LR 0.0861538461538 --> Loss 0.00226884345214\n",
      "Epoch 7::Minibatch 909::LR 0.0861538461538 --> Loss 0.00204864601294\n",
      "Epoch 7::Minibatch 910::LR 0.0861538461538 --> Loss 0.000877893368403\n",
      "Epoch 7::Minibatch 911::LR 0.0861538461538 --> Loss 0.00126098314921\n",
      "Epoch 7::Minibatch 912::LR 0.0861538461538 --> Loss 0.00200693329175\n",
      "Epoch 7::Minibatch 913::LR 0.0861538461538 --> Loss 0.0021116433541\n",
      "Epoch 7::Minibatch 914::LR 0.0861538461538 --> Loss 0.00118236233791\n",
      "Epoch 7::Minibatch 915::LR 0.0861538461538 --> Loss 0.000536944270134\n",
      "Epoch 7::Minibatch 916::LR 0.0861538461538 --> Loss 0.00245446185271\n",
      "Epoch 7::Minibatch 917::LR 0.0861538461538 --> Loss 0.00413933038712\n",
      "Epoch 7::Minibatch 918::LR 0.0861538461538 --> Loss 0.00734294255575\n",
      "Epoch 7::Minibatch 919::LR 0.0861538461538 --> Loss 0.000719797114531\n",
      "Epoch 7::Minibatch 920::LR 0.0861538461538 --> Loss 0.00992604017258\n",
      "Epoch 7::Minibatch 921::LR 0.0861538461538 --> Loss 0.00305381317933\n",
      "Epoch 7::Minibatch 922::LR 0.0861538461538 --> Loss 0.0032852379481\n",
      "Epoch 7::Minibatch 923::LR 0.0861538461538 --> Loss 0.00175166189671\n",
      "Epoch 7::Minibatch 924::LR 0.0861538461538 --> Loss 0.00368537664413\n",
      "Epoch 7::Minibatch 925::LR 0.0861538461538 --> Loss 0.0030422137181\n",
      "Epoch 7::Minibatch 926::LR 0.0861538461538 --> Loss 0.00561451633771\n",
      "Epoch 7::Minibatch 927::LR 0.0861538461538 --> Loss 0.00907742818197\n",
      "Epoch 7::Minibatch 928::LR 0.0861538461538 --> Loss 0.00701240619024\n",
      "Epoch 7::Minibatch 929::LR 0.0861538461538 --> Loss 0.0093567387263\n",
      "Epoch 7::Minibatch 930::LR 0.0861538461538 --> Loss 0.0082816529274\n",
      "Epoch 7::Minibatch 931::LR 0.0861538461538 --> Loss 0.00412708083789\n",
      "Epoch 7::Minibatch 932::LR 0.0861538461538 --> Loss 0.00916283289591\n",
      "Epoch 7::Minibatch 933::LR 0.0861538461538 --> Loss 0.00470209757487\n",
      "Epoch 7::Minibatch 934::LR 0.0861538461538 --> Loss 0.00613887151082\n",
      "Epoch 7::Minibatch 935::LR 0.0861538461538 --> Loss 0.00795153697332\n",
      "Epoch 7::Minibatch 936::LR 0.0861538461538 --> Loss 0.00219692607721\n",
      "Epoch 7::Minibatch 937::LR 0.0861538461538 --> Loss 0.00436143875122\n",
      "Epoch 7::Minibatch 938::LR 0.0861538461538 --> Loss 0.00419146140416\n",
      "Epoch 7::Minibatch 939::LR 0.0861538461538 --> Loss 0.00428018927574\n",
      "Epoch 7::Minibatch 940::LR 0.0861538461538 --> Loss 0.0012763890624\n",
      "Epoch 7::Minibatch 941::LR 0.0861538461538 --> Loss 0.00105378568172\n",
      "Epoch 7::Minibatch 942::LR 0.0861538461538 --> Loss 0.00255798776944\n",
      "Epoch 7::Minibatch 943::LR 0.0861538461538 --> Loss 0.00363421400388\n",
      "Epoch 7::Minibatch 944::LR 0.0861538461538 --> Loss 0.0027157253027\n",
      "Epoch 7::Minibatch 945::LR 0.0861538461538 --> Loss 0.00164407690366\n",
      "Epoch 7::Minibatch 946::LR 0.0861538461538 --> Loss 0.00390275200208\n",
      "Epoch 7::Minibatch 947::LR 0.0861538461538 --> Loss 0.00339881340663\n",
      "Epoch 7::Minibatch 948::LR 0.0861538461538 --> Loss 0.00590677460035\n",
      "Epoch 7::Minibatch 949::LR 0.0861538461538 --> Loss 0.00214286108812\n",
      "Epoch 7::Minibatch 950::LR 0.0861538461538 --> Loss 0.000795036703348\n",
      "Epoch 7::Minibatch 951::LR 0.0861538461538 --> Loss 0.00350548783938\n",
      "Epoch 7::Minibatch 952::LR 0.0861538461538 --> Loss 0.00261853734652\n",
      "Epoch 7::Minibatch 953::LR 0.0861538461538 --> Loss 0.00142045835654\n",
      "Epoch 7::Minibatch 954::LR 0.0861538461538 --> Loss 0.00101412345966\n",
      "Epoch 7::Minibatch 955::LR 0.0861538461538 --> Loss 0.00264660656452\n",
      "Epoch 7::Minibatch 956::LR 0.0861538461538 --> Loss 0.0044475154082\n",
      "Epoch 7::Minibatch 957::LR 0.0861538461538 --> Loss 0.00204529563586\n",
      "Epoch 7::Minibatch 958::LR 0.0861538461538 --> Loss 0.00270928621292\n",
      "Epoch 7::Minibatch 959::LR 0.0861538461538 --> Loss 0.00329168160756\n",
      "Epoch 7::Minibatch 960::LR 0.0861538461538 --> Loss 0.00715893745422\n",
      "Epoch 7::Minibatch 961::LR 0.0861538461538 --> Loss 0.00362628618876\n",
      "Epoch 7::Minibatch 962::LR 0.0861538461538 --> Loss 0.00329450945059\n",
      "Epoch 7::Minibatch 963::LR 0.0861538461538 --> Loss 0.00126649816831\n",
      "Epoch 7::Minibatch 964::LR 0.0861538461538 --> Loss 0.00255111376444\n",
      "Epoch 7::Minibatch 965::LR 0.0861538461538 --> Loss 0.00850213527679\n",
      "Epoch 7::Minibatch 966::LR 0.0861538461538 --> Loss 0.0058276673158\n",
      "Epoch 7::Minibatch 967::LR 0.0861538461538 --> Loss 0.00196838378906\n",
      "Epoch 7::Minibatch 968::LR 0.0861538461538 --> Loss 0.00174657205741\n",
      "Epoch 7::Minibatch 969::LR 0.0861538461538 --> Loss 0.00786952098211\n",
      "Epoch 7::Minibatch 970::LR 0.0861538461538 --> Loss 0.00652573625247\n",
      "Epoch 7::Minibatch 971::LR 0.0861538461538 --> Loss 0.00401588757833\n",
      "Epoch 7::Minibatch 972::LR 0.0861538461538 --> Loss 0.00856700579325\n",
      "Epoch 7::Minibatch 973::LR 0.0861538461538 --> Loss 0.00956959803899\n",
      "Epoch 7::Minibatch 974::LR 0.0861538461538 --> Loss 0.00660184621811\n",
      "Epoch 7::Minibatch 975::LR 0.0861538461538 --> Loss 0.00502021193504\n",
      "Epoch 7::Minibatch 976::LR 0.0861538461538 --> Loss 0.00454253077507\n",
      "Epoch 7::Minibatch 977::LR 0.0861538461538 --> Loss 0.00457803726196\n",
      "Epoch 7::Minibatch 978::LR 0.0861538461538 --> Loss 0.00451061884562\n",
      "Epoch 7::Minibatch 979::LR 0.0861538461538 --> Loss 0.00449910402298\n",
      "Epoch 7::Minibatch 980::LR 0.0861538461538 --> Loss 0.00420468211174\n",
      "Epoch 7::Minibatch 981::LR 0.0861538461538 --> Loss 0.00551960547765\n",
      "Epoch 7::Minibatch 982::LR 0.0861538461538 --> Loss 0.00772600809733\n",
      "Epoch 7::Minibatch 983::LR 0.0861538461538 --> Loss 0.00346581419309\n",
      "Epoch 7::Minibatch 984::LR 0.0861538461538 --> Loss 0.00329029262066\n",
      "Epoch 7::Minibatch 985::LR 0.0861538461538 --> Loss 0.00496206363042\n",
      "Epoch 7::Minibatch 986::LR 0.0861538461538 --> Loss 0.00450819214185\n",
      "Epoch 7::Minibatch 987::LR 0.0861538461538 --> Loss 0.0048502834638\n",
      "Epoch 7::Minibatch 988::LR 0.0861538461538 --> Loss 0.00378188649813\n",
      "Epoch 7::Minibatch 989::LR 0.0861538461538 --> Loss 0.00370520949364\n",
      "Epoch 7::Minibatch 990::LR 0.0861538461538 --> Loss 0.00362638870875\n",
      "Epoch 7::Minibatch 991::LR 0.0861538461538 --> Loss 0.00202154397964\n",
      "Epoch 7::Minibatch 992::LR 0.0861538461538 --> Loss 0.0022330113252\n",
      "Epoch 7::Minibatch 993::LR 0.0861538461538 --> Loss 0.00371029456457\n",
      "Epoch 7::Minibatch 994::LR 0.0861538461538 --> Loss 0.00224100808303\n",
      "Epoch 7::Minibatch 995::LR 0.0861538461538 --> Loss 0.000984279115995\n",
      "Epoch 7::Minibatch 996::LR 0.0861538461538 --> Loss 0.00353872855504\n",
      "Epoch 7::Minibatch 997::LR 0.0861538461538 --> Loss 0.00216662247976\n",
      "Epoch 7::Minibatch 998::LR 0.0861538461538 --> Loss 0.00239583611488\n",
      "Epoch 7::Minibatch 999::LR 0.0861538461538 --> Loss 0.00195709705353\n",
      "Epoch 7::Minibatch 1000::LR 0.0861538461538 --> Loss 0.00225378215313\n",
      "Epoch 7::Minibatch 1001::LR 0.0861538461538 --> Loss 0.00192936122417\n",
      "Epoch 7::Minibatch 1002::LR 0.0861538461538 --> Loss 0.00434978048007\n",
      "Epoch 7::Minibatch 1003::LR 0.0861538461538 --> Loss 0.00459593733152\n",
      "Epoch 7::Minibatch 1004::LR 0.0861538461538 --> Loss 0.0010828524828\n",
      "Epoch 7::Minibatch 1005::LR 0.0861538461538 --> Loss 0.00521275599798\n",
      "Epoch 7::Minibatch 1006::LR 0.0861538461538 --> Loss 0.00366650740306\n",
      "Epoch 7::Minibatch 1007::LR 0.0861538461538 --> Loss 0.0033114673694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7::Minibatch 1008::LR 0.0861538461538 --> Loss 0.00100469837586\n",
      "Epoch 7::Minibatch 1009::LR 0.0861538461538 --> Loss 0.00194435497125\n",
      "Epoch 7::Minibatch 1010::LR 0.0861538461538 --> Loss 0.00155217369397\n",
      "Epoch 7::Minibatch 1011::LR 0.0861538461538 --> Loss 0.00340599815051\n",
      "Epoch 7::Minibatch 1012::LR 0.0861538461538 --> Loss 0.00218523263931\n",
      "Epoch 7::Minibatch 1013::LR 0.0861538461538 --> Loss 0.00518409848213\n",
      "Epoch 7::Minibatch 1014::LR 0.0861538461538 --> Loss 0.00509208798409\n",
      "Epoch 7::Minibatch 1015::LR 0.0861538461538 --> Loss 0.00196186939875\n",
      "Epoch 7::Minibatch 1016::LR 0.0861538461538 --> Loss 0.00566888491313\n",
      "Epoch 7::Minibatch 1017::LR 0.0861538461538 --> Loss 0.00321627140045\n",
      "Epoch 7::Minibatch 1018::LR 0.0861538461538 --> Loss 0.00356251637141\n",
      "Epoch 7::Minibatch 1019::LR 0.0861538461538 --> Loss 0.00275470217069\n",
      "Epoch 7::Minibatch 1020::LR 0.0861538461538 --> Loss 0.00265531718731\n",
      "Epoch 7::Minibatch 1021::LR 0.0861538461538 --> Loss 0.00247132837772\n",
      "Epoch 7::Minibatch 1022::LR 0.0861538461538 --> Loss 0.00195095022519\n",
      "Epoch 7::Minibatch 1023::LR 0.0861538461538 --> Loss 0.0016465267539\n",
      "Epoch 7::Minibatch 1024::LR 0.0861538461538 --> Loss 0.00157050381104\n",
      "Epoch 7::Minibatch 1025::LR 0.0861538461538 --> Loss 0.00168242196242\n",
      "Epoch 7::Minibatch 1026::LR 0.0861538461538 --> Loss 0.00118215173483\n",
      "Epoch 7::Minibatch 1027::LR 0.0861538461538 --> Loss 0.00124642411868\n",
      "Epoch 7::Minibatch 1028::LR 0.0861538461538 --> Loss 0.000996154050032\n",
      "Epoch 7::Minibatch 1029::LR 0.0861538461538 --> Loss 0.000917698144913\n",
      "Epoch 7::Minibatch 1030::LR 0.0861538461538 --> Loss 0.00111484577258\n",
      "Epoch 7::Minibatch 1031::LR 0.0861538461538 --> Loss 0.000864386161168\n",
      "Epoch 7::Minibatch 1032::LR 0.0861538461538 --> Loss 0.000841479599476\n",
      "Epoch 7::Minibatch 1033::LR 0.0861538461538 --> Loss 0.00070818160971\n",
      "Epoch 7::Minibatch 1034::LR 0.0861538461538 --> Loss 0.000743481020133\n",
      "Epoch 7::Minibatch 1035::LR 0.0861538461538 --> Loss 0.000624927381674\n",
      "Epoch 7::Minibatch 1036::LR 0.0861538461538 --> Loss 0.000489637951056\n",
      "Epoch 7::Minibatch 1037::LR 0.0861538461538 --> Loss 0.000600175013145\n",
      "Epoch 7::Minibatch 1038::LR 0.0861538461538 --> Loss 0.00137262403965\n",
      "Epoch 7::Minibatch 1039::LR 0.0861538461538 --> Loss 0.0011764327685\n",
      "Epoch 7::Minibatch 1040::LR 0.0861538461538 --> Loss 0.000569139719009\n",
      "Epoch 7::Minibatch 1041::LR 0.0861538461538 --> Loss 0.000683435449998\n",
      "Epoch 8::Minibatch 1::LR 0.0838461538462 --> Loss 0.0108161735535\n",
      "Epoch 8::Minibatch 2::LR 0.0838461538462 --> Loss 0.00715590159098\n",
      "Epoch 8::Minibatch 3::LR 0.0838461538462 --> Loss 0.0048814312617\n",
      "Epoch 8::Minibatch 4::LR 0.0838461538462 --> Loss 0.00472601532936\n",
      "Epoch 8::Minibatch 5::LR 0.0838461538462 --> Loss 0.00480285565058\n",
      "Epoch 8::Minibatch 6::LR 0.0838461538462 --> Loss 0.00257888734341\n",
      "Epoch 8::Minibatch 7::LR 0.0838461538462 --> Loss 0.00793791770935\n",
      "Epoch 8::Minibatch 8::LR 0.0838461538462 --> Loss 0.00784637053808\n",
      "Epoch 8::Minibatch 9::LR 0.0838461538462 --> Loss 0.00578913609187\n",
      "Epoch 8::Minibatch 10::LR 0.0838461538462 --> Loss 0.00325763523579\n",
      "Epoch 8::Minibatch 11::LR 0.0838461538462 --> Loss 0.00266126533349\n",
      "Epoch 8::Minibatch 12::LR 0.0838461538462 --> Loss 0.00359002510707\n",
      "Epoch 8::Minibatch 13::LR 0.0838461538462 --> Loss 0.00534357825915\n",
      "Epoch 8::Minibatch 14::LR 0.0838461538462 --> Loss 0.00485780398051\n",
      "Epoch 8::Minibatch 15::LR 0.0838461538462 --> Loss 0.0036934141318\n",
      "Epoch 8::Minibatch 16::LR 0.0838461538462 --> Loss 0.000942729612192\n",
      "Epoch 8::Minibatch 17::LR 0.0838461538462 --> Loss 0.00310391406218\n",
      "Epoch 8::Minibatch 18::LR 0.0838461538462 --> Loss 0.00243435899417\n",
      "Epoch 8::Minibatch 19::LR 0.0838461538462 --> Loss 0.000974744359652\n",
      "Epoch 8::Minibatch 20::LR 0.0838461538462 --> Loss 0.00140352129936\n",
      "Epoch 8::Minibatch 21::LR 0.0838461538462 --> Loss 0.00311887363593\n",
      "Epoch 8::Minibatch 22::LR 0.0838461538462 --> Loss 0.00243491907914\n",
      "Epoch 8::Minibatch 23::LR 0.0838461538462 --> Loss 0.000860106348991\n",
      "Epoch 8::Minibatch 24::LR 0.0838461538462 --> Loss 0.000402115682761\n",
      "Epoch 8::Minibatch 25::LR 0.0838461538462 --> Loss 0.00117711921533\n",
      "Epoch 8::Minibatch 26::LR 0.0838461538462 --> Loss 0.00134142796199\n",
      "Epoch 8::Minibatch 27::LR 0.0838461538462 --> Loss 0.00101172337929\n",
      "Epoch 8::Minibatch 28::LR 0.0838461538462 --> Loss 0.000395534882943\n",
      "Epoch 8::Minibatch 29::LR 0.0838461538462 --> Loss 0.000381197283665\n",
      "Epoch 8::Minibatch 30::LR 0.0838461538462 --> Loss 0.000868819653988\n",
      "Epoch 8::Minibatch 31::LR 0.0838461538462 --> Loss 0.00131764849027\n",
      "Epoch 8::Minibatch 32::LR 0.0838461538462 --> Loss 0.00127847343683\n",
      "Epoch 8::Minibatch 33::LR 0.0838461538462 --> Loss 0.000793513208628\n",
      "Epoch 8::Minibatch 34::LR 0.0838461538462 --> Loss 0.0028602151076\n",
      "Epoch 8::Minibatch 35::LR 0.0838461538462 --> Loss 0.00412831425667\n",
      "Epoch 8::Minibatch 36::LR 0.0838461538462 --> Loss 0.0021108520031\n",
      "Epoch 8::Minibatch 37::LR 0.0838461538462 --> Loss 0.00059214224418\n",
      "Epoch 8::Minibatch 38::LR 0.0838461538462 --> Loss 0.000809682110945\n",
      "Epoch 8::Minibatch 39::LR 0.0838461538462 --> Loss 0.00268067161242\n",
      "Epoch 8::Minibatch 40::LR 0.0838461538462 --> Loss 0.00372177402178\n",
      "Epoch 8::Minibatch 41::LR 0.0838461538462 --> Loss 0.00352590163549\n",
      "Epoch 8::Minibatch 42::LR 0.0838461538462 --> Loss 0.00627525369326\n",
      "Epoch 8::Minibatch 43::LR 0.0838461538462 --> Loss 0.00191548764706\n",
      "Epoch 8::Minibatch 44::LR 0.0838461538462 --> Loss 0.00311130960782\n",
      "Epoch 8::Minibatch 45::LR 0.0838461538462 --> Loss 0.00268505096436\n",
      "Epoch 8::Minibatch 46::LR 0.0838461538462 --> Loss 0.00379738887151\n",
      "Epoch 8::Minibatch 47::LR 0.0838461538462 --> Loss 0.0054083096981\n",
      "Epoch 8::Minibatch 48::LR 0.0838461538462 --> Loss 0.00626869042714\n",
      "Epoch 8::Minibatch 49::LR 0.0838461538462 --> Loss 0.00608810901642\n",
      "Epoch 8::Minibatch 50::LR 0.0838461538462 --> Loss 0.00571679751078\n",
      "Epoch 8::Minibatch 51::LR 0.0838461538462 --> Loss 0.00947220484416\n",
      "Epoch 8::Minibatch 52::LR 0.0838461538462 --> Loss 0.00361168543498\n",
      "Epoch 8::Minibatch 53::LR 0.0838461538462 --> Loss 0.00360721429189\n",
      "Epoch 8::Minibatch 54::LR 0.0838461538462 --> Loss 0.00404016892115\n",
      "Epoch 8::Minibatch 55::LR 0.0838461538462 --> Loss 0.00119174132744\n",
      "Epoch 8::Minibatch 56::LR 0.0838461538462 --> Loss 0.00295705934366\n",
      "Epoch 8::Minibatch 57::LR 0.0838461538462 --> Loss 0.00648718237877\n",
      "Epoch 8::Minibatch 58::LR 0.0838461538462 --> Loss 0.00357859611511\n",
      "Epoch 8::Minibatch 59::LR 0.0838461538462 --> Loss 0.00319464484851\n",
      "Epoch 8::Minibatch 60::LR 0.0838461538462 --> Loss 0.0025804678599\n",
      "Epoch 8::Minibatch 61::LR 0.0838461538462 --> Loss 0.00118836750587\n",
      "Epoch 8::Minibatch 62::LR 0.0838461538462 --> Loss 0.00383488337199\n",
      "Epoch 8::Minibatch 63::LR 0.0838461538462 --> Loss 0.0024376809597\n",
      "Epoch 8::Minibatch 64::LR 0.0838461538462 --> Loss 0.00113616695007\n",
      "Epoch 8::Minibatch 65::LR 0.0838461538462 --> Loss 0.00252908329169\n",
      "Epoch 8::Minibatch 66::LR 0.0838461538462 --> Loss 0.00320133209229\n",
      "Epoch 8::Minibatch 67::LR 0.0838461538462 --> Loss 0.0030157583952\n",
      "Epoch 8::Minibatch 68::LR 0.0838461538462 --> Loss 0.00211365421613\n",
      "Epoch 8::Minibatch 69::LR 0.0838461538462 --> Loss 0.00406463742256\n",
      "Epoch 8::Minibatch 70::LR 0.0838461538462 --> Loss 0.0035790069898\n",
      "Epoch 8::Minibatch 71::LR 0.0838461538462 --> Loss 0.00243992984295\n",
      "Epoch 8::Minibatch 72::LR 0.0838461538462 --> Loss 0.000595966329177\n",
      "Epoch 8::Minibatch 73::LR 0.0838461538462 --> Loss 0.00397370219231\n",
      "Epoch 8::Minibatch 74::LR 0.0838461538462 --> Loss 0.00421651721001\n",
      "Epoch 8::Minibatch 75::LR 0.0838461538462 --> Loss 0.00287325779597\n",
      "Epoch 8::Minibatch 76::LR 0.0838461538462 --> Loss 0.000797606110573\n",
      "Epoch 8::Minibatch 77::LR 0.0838461538462 --> Loss 0.00411314129829\n",
      "Epoch 8::Minibatch 78::LR 0.0838461538462 --> Loss 0.00401912689209\n",
      "Epoch 8::Minibatch 79::LR 0.0838461538462 --> Loss 0.00230125208696\n",
      "Epoch 8::Minibatch 80::LR 0.0838461538462 --> Loss 0.00366817037265\n",
      "Epoch 8::Minibatch 81::LR 0.0838461538462 --> Loss 0.00321984867255\n",
      "Epoch 8::Minibatch 82::LR 0.0838461538462 --> Loss 0.00212767978509\n",
      "Epoch 8::Minibatch 83::LR 0.0838461538462 --> Loss 0.00534006635348\n",
      "Epoch 8::Minibatch 84::LR 0.0838461538462 --> Loss 0.00220852951209\n",
      "Epoch 8::Minibatch 85::LR 0.0838461538462 --> Loss 0.0029341250658\n",
      "Epoch 8::Minibatch 86::LR 0.0838461538462 --> Loss 0.00246510763963\n",
      "Epoch 8::Minibatch 87::LR 0.0838461538462 --> Loss 0.00272111376127\n",
      "Epoch 8::Minibatch 88::LR 0.0838461538462 --> Loss 0.00203094740709\n",
      "Epoch 8::Minibatch 89::LR 0.0838461538462 --> Loss 0.00248617867629\n",
      "Epoch 8::Minibatch 90::LR 0.0838461538462 --> Loss 0.00137211223443\n",
      "Epoch 8::Minibatch 91::LR 0.0838461538462 --> Loss 0.0011460579435\n",
      "Epoch 8::Minibatch 92::LR 0.0838461538462 --> Loss 0.00274193286896\n",
      "Epoch 8::Minibatch 93::LR 0.0838461538462 --> Loss 0.00191540161769\n",
      "Epoch 8::Minibatch 94::LR 0.0838461538462 --> Loss 0.00190139234066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 95::LR 0.0838461538462 --> Loss 0.00174298961957\n",
      "Epoch 8::Minibatch 96::LR 0.0838461538462 --> Loss 0.00634226957957\n",
      "Epoch 8::Minibatch 97::LR 0.0838461538462 --> Loss 0.00323572039604\n",
      "Epoch 8::Minibatch 98::LR 0.0838461538462 --> Loss 0.000979017515977\n",
      "Epoch 8::Minibatch 99::LR 0.0838461538462 --> Loss 0.00131311913331\n",
      "Epoch 8::Minibatch 100::LR 0.0838461538462 --> Loss 0.00573598663012\n",
      "Epoch 8::Minibatch 101::LR 0.0838461538462 --> Loss 0.00106450170279\n",
      "Epoch 8::Minibatch 102::LR 0.0838461538462 --> Loss 0.00377724250158\n",
      "Epoch 8::Minibatch 103::LR 0.0838461538462 --> Loss 0.00402313510577\n",
      "Epoch 8::Minibatch 104::LR 0.0838461538462 --> Loss 0.00292559166749\n",
      "Epoch 8::Minibatch 105::LR 0.0838461538462 --> Loss 0.00368469436963\n",
      "Epoch 8::Minibatch 106::LR 0.0838461538462 --> Loss 0.0183639955521\n",
      "Epoch 8::Minibatch 107::LR 0.0838461538462 --> Loss 0.00482989231745\n",
      "Epoch 8::Minibatch 108::LR 0.0838461538462 --> Loss 0.00136090020339\n",
      "Epoch 8::Minibatch 109::LR 0.0838461538462 --> Loss 0.00472939888636\n",
      "Epoch 8::Minibatch 110::LR 0.0838461538462 --> Loss 0.0027269812425\n",
      "Epoch 8::Minibatch 111::LR 0.0838461538462 --> Loss 0.00126879731814\n",
      "Epoch 8::Minibatch 112::LR 0.0838461538462 --> Loss 0.00393927534421\n",
      "Epoch 8::Minibatch 113::LR 0.0838461538462 --> Loss 0.00305547058582\n",
      "Epoch 8::Minibatch 114::LR 0.0838461538462 --> Loss 0.00171380360921\n",
      "Epoch 8::Minibatch 115::LR 0.0838461538462 --> Loss 0.00166951636473\n",
      "Epoch 8::Minibatch 116::LR 0.0838461538462 --> Loss 0.00315245469411\n",
      "Epoch 8::Minibatch 117::LR 0.0838461538462 --> Loss 0.00380829056104\n",
      "Epoch 8::Minibatch 118::LR 0.0838461538462 --> Loss 0.00697950363159\n",
      "Epoch 8::Minibatch 119::LR 0.0838461538462 --> Loss 0.0009033147494\n",
      "Epoch 8::Minibatch 120::LR 0.0838461538462 --> Loss 0.00216553092003\n",
      "Epoch 8::Minibatch 121::LR 0.0838461538462 --> Loss 0.00313304523627\n",
      "Epoch 8::Minibatch 122::LR 0.0838461538462 --> Loss 0.00378217418989\n",
      "Epoch 8::Minibatch 123::LR 0.0838461538462 --> Loss 0.00153665184975\n",
      "Epoch 8::Minibatch 124::LR 0.0838461538462 --> Loss 0.00307992021243\n",
      "Epoch 8::Minibatch 125::LR 0.0838461538462 --> Loss 0.00493605812391\n",
      "Epoch 8::Minibatch 126::LR 0.0838461538462 --> Loss 0.00303521653016\n",
      "Epoch 8::Minibatch 127::LR 0.0838461538462 --> Loss 0.00460619529088\n",
      "Epoch 8::Minibatch 128::LR 0.0838461538462 --> Loss 0.00379702846209\n",
      "Epoch 8::Minibatch 129::LR 0.0838461538462 --> Loss 0.00306878785292\n",
      "Epoch 8::Minibatch 130::LR 0.0838461538462 --> Loss 0.00451037247976\n",
      "Epoch 8::Minibatch 131::LR 0.0838461538462 --> Loss 0.00201452970505\n",
      "Epoch 8::Minibatch 132::LR 0.0838461538462 --> Loss 0.0034608968099\n",
      "Epoch 8::Minibatch 133::LR 0.0838461538462 --> Loss 0.00334577004115\n",
      "Epoch 8::Minibatch 134::LR 0.0838461538462 --> Loss 0.00276621023814\n",
      "Epoch 8::Minibatch 135::LR 0.0838461538462 --> Loss 0.00201763629913\n",
      "Epoch 8::Minibatch 136::LR 0.0838461538462 --> Loss 0.00303749163946\n",
      "Epoch 8::Minibatch 137::LR 0.0838461538462 --> Loss 0.0038632730643\n",
      "Epoch 8::Minibatch 138::LR 0.0838461538462 --> Loss 0.0014899362127\n",
      "Epoch 8::Minibatch 139::LR 0.0838461538462 --> Loss 0.00197792291641\n",
      "Epoch 8::Minibatch 140::LR 0.0838461538462 --> Loss 0.00251969754696\n",
      "Epoch 8::Minibatch 141::LR 0.0838461538462 --> Loss 0.00310665845871\n",
      "Epoch 8::Minibatch 142::LR 0.0838461538462 --> Loss 0.00326549430688\n",
      "Epoch 8::Minibatch 143::LR 0.0838461538462 --> Loss 0.000733421047529\n",
      "Epoch 8::Minibatch 144::LR 0.0838461538462 --> Loss 0.00318986872832\n",
      "Epoch 8::Minibatch 145::LR 0.0838461538462 --> Loss 0.00443088769913\n",
      "Epoch 8::Minibatch 146::LR 0.0838461538462 --> Loss 0.00276746988297\n",
      "Epoch 8::Minibatch 147::LR 0.0838461538462 --> Loss 0.0019027976195\n",
      "Epoch 8::Minibatch 148::LR 0.0838461538462 --> Loss 0.00113990535339\n",
      "Epoch 8::Minibatch 149::LR 0.0838461538462 --> Loss 0.00290715197722\n",
      "Epoch 8::Minibatch 150::LR 0.0838461538462 --> Loss 0.0028792544206\n",
      "Epoch 8::Minibatch 151::LR 0.0838461538462 --> Loss 0.00429322520892\n",
      "Epoch 8::Minibatch 152::LR 0.0838461538462 --> Loss 0.00101006150246\n",
      "Epoch 8::Minibatch 153::LR 0.0838461538462 --> Loss 0.00197031676769\n",
      "Epoch 8::Minibatch 154::LR 0.0838461538462 --> Loss 0.00216033538183\n",
      "Epoch 8::Minibatch 155::LR 0.0838461538462 --> Loss 0.00509684205055\n",
      "Epoch 8::Minibatch 156::LR 0.0838461538462 --> Loss 0.00250515242418\n",
      "Epoch 8::Minibatch 157::LR 0.0838461538462 --> Loss 0.000753230303526\n",
      "Epoch 8::Minibatch 158::LR 0.0838461538462 --> Loss 0.00310903807481\n",
      "Epoch 8::Minibatch 159::LR 0.0838461538462 --> Loss 0.00284910559654\n",
      "Epoch 8::Minibatch 160::LR 0.0838461538462 --> Loss 0.00274979134401\n",
      "Epoch 8::Minibatch 161::LR 0.0838461538462 --> Loss 0.00112076302369\n",
      "Epoch 8::Minibatch 162::LR 0.0838461538462 --> Loss 0.00354460954666\n",
      "Epoch 8::Minibatch 163::LR 0.0838461538462 --> Loss 0.00248426278432\n",
      "Epoch 8::Minibatch 164::LR 0.0838461538462 --> Loss 0.00253899435202\n",
      "Epoch 8::Minibatch 165::LR 0.0838461538462 --> Loss 0.000606593986352\n",
      "Epoch 8::Minibatch 166::LR 0.0838461538462 --> Loss 0.00189711829027\n",
      "Epoch 8::Minibatch 167::LR 0.0838461538462 --> Loss 0.00251544694106\n",
      "Epoch 8::Minibatch 168::LR 0.0838461538462 --> Loss 0.00228260815144\n",
      "Epoch 8::Minibatch 169::LR 0.0838461538462 --> Loss 0.00108546753724\n",
      "Epoch 8::Minibatch 170::LR 0.0838461538462 --> Loss 0.00105727771918\n",
      "Epoch 8::Minibatch 171::LR 0.0838461538462 --> Loss 0.00258723596732\n",
      "Epoch 8::Minibatch 172::LR 0.0838461538462 --> Loss 0.00494099140167\n",
      "Epoch 8::Minibatch 173::LR 0.0838461538462 --> Loss 0.00204110205173\n",
      "Epoch 8::Minibatch 174::LR 0.0838461538462 --> Loss 0.00112325022618\n",
      "Epoch 8::Minibatch 175::LR 0.0838461538462 --> Loss 0.00232220689456\n",
      "Epoch 8::Minibatch 176::LR 0.0838461538462 --> Loss 0.0034955684344\n",
      "Epoch 8::Minibatch 177::LR 0.0838461538462 --> Loss 0.0050039156278\n",
      "Epoch 8::Minibatch 178::LR 0.0838461538462 --> Loss 0.00177731156349\n",
      "Epoch 8::Minibatch 179::LR 0.0838461538462 --> Loss 0.00150168140729\n",
      "Epoch 8::Minibatch 180::LR 0.0838461538462 --> Loss 0.00389622012774\n",
      "Epoch 8::Minibatch 181::LR 0.0838461538462 --> Loss 0.00353291630745\n",
      "Epoch 8::Minibatch 182::LR 0.0838461538462 --> Loss 0.000922203958035\n",
      "Epoch 8::Minibatch 183::LR 0.0838461538462 --> Loss 0.00179915825526\n",
      "Epoch 8::Minibatch 184::LR 0.0838461538462 --> Loss 0.00344235142072\n",
      "Epoch 8::Minibatch 185::LR 0.0838461538462 --> Loss 0.00295468529065\n",
      "Epoch 8::Minibatch 186::LR 0.0838461538462 --> Loss 0.0010757090648\n",
      "Epoch 8::Minibatch 187::LR 0.0838461538462 --> Loss 0.00130052626133\n",
      "Epoch 8::Minibatch 188::LR 0.0838461538462 --> Loss 0.00418934265773\n",
      "Epoch 8::Minibatch 189::LR 0.0838461538462 --> Loss 0.00462994217873\n",
      "Epoch 8::Minibatch 190::LR 0.0838461538462 --> Loss 0.00236989736557\n",
      "Epoch 8::Minibatch 191::LR 0.0838461538462 --> Loss 0.000591557621956\n",
      "Epoch 8::Minibatch 192::LR 0.0838461538462 --> Loss 0.00268248180548\n",
      "Epoch 8::Minibatch 193::LR 0.0838461538462 --> Loss 0.00250120123227\n",
      "Epoch 8::Minibatch 194::LR 0.0838461538462 --> Loss 0.00187301834424\n",
      "Epoch 8::Minibatch 195::LR 0.0838461538462 --> Loss 0.000456456243992\n",
      "Epoch 8::Minibatch 196::LR 0.0838461538462 --> Loss 0.00124216357867\n",
      "Epoch 8::Minibatch 197::LR 0.0838461538462 --> Loss 0.00281703372796\n",
      "Epoch 8::Minibatch 198::LR 0.0838461538462 --> Loss 0.0022062732776\n",
      "Epoch 8::Minibatch 199::LR 0.0838461538462 --> Loss 0.000344333822529\n",
      "Epoch 8::Minibatch 200::LR 0.0838461538462 --> Loss 0.00217278659344\n",
      "Epoch 8::Minibatch 201::LR 0.0838461538462 --> Loss 0.00207664529483\n",
      "Epoch 8::Minibatch 202::LR 0.0838461538462 --> Loss 0.00200874229272\n",
      "Epoch 8::Minibatch 203::LR 0.0838461538462 --> Loss 0.00197623034318\n",
      "Epoch 8::Minibatch 204::LR 0.0838461538462 --> Loss 0.00171700437864\n",
      "Epoch 8::Minibatch 205::LR 0.0838461538462 --> Loss 0.00236478428046\n",
      "Epoch 8::Minibatch 206::LR 0.0838461538462 --> Loss 0.00754809141159\n",
      "Epoch 8::Minibatch 207::LR 0.0838461538462 --> Loss 0.00148705730836\n",
      "Epoch 8::Minibatch 208::LR 0.0838461538462 --> Loss 0.00127477586269\n",
      "Epoch 8::Minibatch 209::LR 0.0838461538462 --> Loss 0.00214454809825\n",
      "Epoch 8::Minibatch 210::LR 0.0838461538462 --> Loss 0.00198207040628\n",
      "Epoch 8::Minibatch 211::LR 0.0838461538462 --> Loss 0.00208351870378\n",
      "Epoch 8::Minibatch 212::LR 0.0838461538462 --> Loss 0.00441040873528\n",
      "Epoch 8::Minibatch 213::LR 0.0838461538462 --> Loss 0.00622959136963\n",
      "Epoch 8::Minibatch 214::LR 0.0838461538462 --> Loss 0.0106115810076\n",
      "Epoch 8::Minibatch 215::LR 0.0838461538462 --> Loss 0.00154033998648\n",
      "Epoch 8::Minibatch 216::LR 0.0838461538462 --> Loss 0.00557249625524\n",
      "Epoch 8::Minibatch 217::LR 0.0838461538462 --> Loss 0.00597528616587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 218::LR 0.0838461538462 --> Loss 0.00416963855426\n",
      "Epoch 8::Minibatch 219::LR 0.0838461538462 --> Loss 0.00363213419914\n",
      "Epoch 8::Minibatch 220::LR 0.0838461538462 --> Loss 0.00470024784406\n",
      "Epoch 8::Minibatch 221::LR 0.0838461538462 --> Loss 0.00437394857407\n",
      "Epoch 8::Minibatch 222::LR 0.0838461538462 --> Loss 0.00342183510462\n",
      "Epoch 8::Minibatch 223::LR 0.0838461538462 --> Loss 0.00153094440699\n",
      "Epoch 8::Minibatch 224::LR 0.0838461538462 --> Loss 0.00200968881448\n",
      "Epoch 8::Minibatch 225::LR 0.0838461538462 --> Loss 0.00691025575002\n",
      "Epoch 8::Minibatch 226::LR 0.0838461538462 --> Loss 0.00391453345617\n",
      "Epoch 8::Minibatch 227::LR 0.0838461538462 --> Loss 0.00180573860804\n",
      "Epoch 8::Minibatch 228::LR 0.0838461538462 --> Loss 0.000930563509464\n",
      "Epoch 8::Minibatch 229::LR 0.0838461538462 --> Loss 0.00495725909869\n",
      "Epoch 8::Minibatch 230::LR 0.0838461538462 --> Loss 0.00416338483493\n",
      "Epoch 8::Minibatch 231::LR 0.0838461538462 --> Loss 0.0027029333512\n",
      "Epoch 8::Minibatch 232::LR 0.0838461538462 --> Loss 0.00139972984791\n",
      "Epoch 8::Minibatch 233::LR 0.0838461538462 --> Loss 0.00246867179871\n",
      "Epoch 8::Minibatch 234::LR 0.0838461538462 --> Loss 0.00655522505442\n",
      "Epoch 8::Minibatch 235::LR 0.0838461538462 --> Loss 0.00515285571416\n",
      "Epoch 8::Minibatch 236::LR 0.0838461538462 --> Loss 0.00191601852576\n",
      "Epoch 8::Minibatch 237::LR 0.0838461538462 --> Loss 0.000839518805345\n",
      "Epoch 8::Minibatch 238::LR 0.0838461538462 --> Loss 0.00349526802699\n",
      "Epoch 8::Minibatch 239::LR 0.0838461538462 --> Loss 0.0030096099774\n",
      "Epoch 8::Minibatch 240::LR 0.0838461538462 --> Loss 0.00327880402406\n",
      "Epoch 8::Minibatch 241::LR 0.0838461538462 --> Loss 0.000876356462638\n",
      "Epoch 8::Minibatch 242::LR 0.0838461538462 --> Loss 0.00738165140152\n",
      "Epoch 8::Minibatch 243::LR 0.0838461538462 --> Loss 0.00375433166822\n",
      "Epoch 8::Minibatch 244::LR 0.0838461538462 --> Loss 0.00314240932465\n",
      "Epoch 8::Minibatch 245::LR 0.0838461538462 --> Loss 0.00057990928491\n",
      "Epoch 8::Minibatch 246::LR 0.0838461538462 --> Loss 0.00222718815009\n",
      "Epoch 8::Minibatch 247::LR 0.0838461538462 --> Loss 0.0143860610326\n",
      "Epoch 8::Minibatch 248::LR 0.0838461538462 --> Loss 0.00485066254934\n",
      "Epoch 8::Minibatch 249::LR 0.0838461538462 --> Loss 0.00325081845125\n",
      "Epoch 8::Minibatch 250::LR 0.0838461538462 --> Loss 0.00317274570465\n",
      "Epoch 8::Minibatch 251::LR 0.0838461538462 --> Loss 0.00272019426028\n",
      "Epoch 8::Minibatch 252::LR 0.0838461538462 --> Loss 0.00210035999616\n",
      "Epoch 8::Minibatch 253::LR 0.0838461538462 --> Loss 0.0033761715889\n",
      "Epoch 8::Minibatch 254::LR 0.0838461538462 --> Loss 0.00553241173426\n",
      "Epoch 8::Minibatch 255::LR 0.0838461538462 --> Loss 0.00417584379514\n",
      "Epoch 8::Minibatch 256::LR 0.0838461538462 --> Loss 0.00200868765513\n",
      "Epoch 8::Minibatch 257::LR 0.0838461538462 --> Loss 0.0015320165952\n",
      "Epoch 8::Minibatch 258::LR 0.0838461538462 --> Loss 0.00372714837392\n",
      "Epoch 8::Minibatch 259::LR 0.0838461538462 --> Loss 0.00202592273553\n",
      "Epoch 8::Minibatch 260::LR 0.0838461538462 --> Loss 0.00202133814494\n",
      "Epoch 8::Minibatch 261::LR 0.0838461538462 --> Loss 0.00314930021763\n",
      "Epoch 8::Minibatch 262::LR 0.0838461538462 --> Loss 0.00210495253404\n",
      "Epoch 8::Minibatch 263::LR 0.0838461538462 --> Loss 0.00248857756456\n",
      "Epoch 8::Minibatch 264::LR 0.0838461538462 --> Loss 0.00379889130592\n",
      "Epoch 8::Minibatch 265::LR 0.0838461538462 --> Loss 0.0102743895849\n",
      "Epoch 8::Minibatch 266::LR 0.0838461538462 --> Loss 0.00121603310108\n",
      "Epoch 8::Minibatch 267::LR 0.0838461538462 --> Loss 0.0103021581968\n",
      "Epoch 8::Minibatch 268::LR 0.0838461538462 --> Loss 0.00145014425119\n",
      "Epoch 8::Minibatch 269::LR 0.0838461538462 --> Loss 0.00370292623838\n",
      "Epoch 8::Minibatch 270::LR 0.0838461538462 --> Loss 0.00637591163317\n",
      "Epoch 8::Minibatch 271::LR 0.0838461538462 --> Loss 0.00307013948758\n",
      "Epoch 8::Minibatch 272::LR 0.0838461538462 --> Loss 0.00408686359723\n",
      "Epoch 8::Minibatch 273::LR 0.0838461538462 --> Loss 0.0019790794452\n",
      "Epoch 8::Minibatch 274::LR 0.0838461538462 --> Loss 0.00195350805918\n",
      "Epoch 8::Minibatch 275::LR 0.0838461538462 --> Loss 0.00291348715623\n",
      "Epoch 8::Minibatch 276::LR 0.0838461538462 --> Loss 0.00362832546234\n",
      "Epoch 8::Minibatch 277::LR 0.0838461538462 --> Loss 0.00119097818931\n",
      "Epoch 8::Minibatch 278::LR 0.0838461538462 --> Loss 0.00277169903119\n",
      "Epoch 8::Minibatch 279::LR 0.0838461538462 --> Loss 0.00265200197697\n",
      "Epoch 8::Minibatch 280::LR 0.0838461538462 --> Loss 0.0023201896747\n",
      "Epoch 8::Minibatch 281::LR 0.0838461538462 --> Loss 0.00148998389641\n",
      "Epoch 8::Minibatch 282::LR 0.0838461538462 --> Loss 0.00237403869629\n",
      "Epoch 8::Minibatch 283::LR 0.0838461538462 --> Loss 0.0023343839248\n",
      "Epoch 8::Minibatch 284::LR 0.0838461538462 --> Loss 0.00187720537186\n",
      "Epoch 8::Minibatch 285::LR 0.0838461538462 --> Loss 0.00131558736165\n",
      "Epoch 8::Minibatch 286::LR 0.0838461538462 --> Loss 0.00223908782005\n",
      "Epoch 8::Minibatch 287::LR 0.0838461538462 --> Loss 0.00216513653596\n",
      "Epoch 8::Minibatch 288::LR 0.0838461538462 --> Loss 0.00118214885394\n",
      "Epoch 8::Minibatch 289::LR 0.0838461538462 --> Loss 0.00159134646257\n",
      "Epoch 8::Minibatch 290::LR 0.0838461538462 --> Loss 0.00200319329898\n",
      "Epoch 8::Minibatch 291::LR 0.0838461538462 --> Loss 0.00180649737517\n",
      "Epoch 8::Minibatch 292::LR 0.0838461538462 --> Loss 0.000667547285557\n",
      "Epoch 8::Minibatch 293::LR 0.0838461538462 --> Loss 0.00150033344825\n",
      "Epoch 8::Minibatch 294::LR 0.0838461538462 --> Loss 0.00159063577652\n",
      "Epoch 8::Minibatch 295::LR 0.0838461538462 --> Loss 0.00185177306334\n",
      "Epoch 8::Minibatch 296::LR 0.0838461538462 --> Loss 0.00160798897346\n",
      "Epoch 8::Minibatch 297::LR 0.0838461538462 --> Loss 0.00141525288423\n",
      "Epoch 8::Minibatch 298::LR 0.0838461538462 --> Loss 0.00139326800903\n",
      "Epoch 8::Minibatch 299::LR 0.0838461538462 --> Loss 0.000844175815582\n",
      "Epoch 8::Minibatch 300::LR 0.0838461538462 --> Loss 0.00298527201017\n",
      "Epoch 8::Minibatch 301::LR 0.0838461538462 --> Loss 0.00287127017975\n",
      "Epoch 8::Minibatch 302::LR 0.0838461538462 --> Loss 0.00267563601335\n",
      "Epoch 8::Minibatch 303::LR 0.0838461538462 --> Loss 0.000919027527173\n",
      "Epoch 8::Minibatch 304::LR 0.0838461538462 --> Loss 0.00322605629762\n",
      "Epoch 8::Minibatch 305::LR 0.0838461538462 --> Loss 0.00173684736093\n",
      "Epoch 8::Minibatch 306::LR 0.0838461538462 --> Loss 0.000975739161174\n",
      "Epoch 8::Minibatch 307::LR 0.0838461538462 --> Loss 0.00251808424791\n",
      "Epoch 8::Minibatch 308::LR 0.0838461538462 --> Loss 0.00200651903947\n",
      "Epoch 8::Minibatch 309::LR 0.0838461538462 --> Loss 0.00101723114649\n",
      "Epoch 8::Minibatch 310::LR 0.0838461538462 --> Loss 0.00108196983735\n",
      "Epoch 8::Minibatch 311::LR 0.0838461538462 --> Loss 0.0016598457098\n",
      "Epoch 8::Minibatch 312::LR 0.0838461538462 --> Loss 0.00312401672204\n",
      "Epoch 8::Minibatch 313::LR 0.0838461538462 --> Loss 0.00240587691466\n",
      "Epoch 8::Minibatch 314::LR 0.0838461538462 --> Loss 0.00194757143656\n",
      "Epoch 8::Minibatch 315::LR 0.0838461538462 --> Loss 0.000994613667329\n",
      "Epoch 8::Minibatch 316::LR 0.0838461538462 --> Loss 0.00236714621385\n",
      "Epoch 8::Minibatch 317::LR 0.0838461538462 --> Loss 0.00158577978611\n",
      "Epoch 8::Minibatch 318::LR 0.0838461538462 --> Loss 0.00118543386459\n",
      "Epoch 8::Minibatch 319::LR 0.0838461538462 --> Loss 0.00231938739618\n",
      "Epoch 8::Minibatch 320::LR 0.0838461538462 --> Loss 0.00340958952904\n",
      "Epoch 8::Minibatch 321::LR 0.0838461538462 --> Loss 0.000965799589952\n",
      "Epoch 8::Minibatch 322::LR 0.0838461538462 --> Loss 0.00369297345479\n",
      "Epoch 8::Minibatch 323::LR 0.0838461538462 --> Loss 0.00363436937332\n",
      "Epoch 8::Minibatch 324::LR 0.0838461538462 --> Loss 0.0026711110274\n",
      "Epoch 8::Minibatch 325::LR 0.0838461538462 --> Loss 0.00248609999816\n",
      "Epoch 8::Minibatch 326::LR 0.0838461538462 --> Loss 0.00552952885628\n",
      "Epoch 8::Minibatch 327::LR 0.0838461538462 --> Loss 0.00234375437101\n",
      "Epoch 8::Minibatch 328::LR 0.0838461538462 --> Loss 0.00361657738686\n",
      "Epoch 8::Minibatch 329::LR 0.0838461538462 --> Loss 0.00132555474838\n",
      "Epoch 8::Minibatch 330::LR 0.0838461538462 --> Loss 0.00169252276421\n",
      "Epoch 8::Minibatch 331::LR 0.0838461538462 --> Loss 0.00263512452443\n",
      "Epoch 8::Minibatch 332::LR 0.0838461538462 --> Loss 0.00259157220523\n",
      "Epoch 8::Minibatch 333::LR 0.0838461538462 --> Loss 0.00153686463833\n",
      "Epoch 8::Minibatch 334::LR 0.0838461538462 --> Loss 0.00423129796982\n",
      "Epoch 8::Minibatch 335::LR 0.0838461538462 --> Loss 0.00196566700935\n",
      "Epoch 8::Minibatch 336::LR 0.0838461538462 --> Loss 0.00204008062681\n",
      "Epoch 8::Minibatch 337::LR 0.0838461538462 --> Loss 0.00326993246873\n",
      "Epoch 8::Minibatch 338::LR 0.0838461538462 --> Loss 0.00054881259799\n",
      "Epoch 8::Minibatch 339::LR 0.0838461538462 --> Loss 0.00330531537533\n",
      "Epoch 8::Minibatch 340::LR 0.0838461538462 --> Loss 0.00501002033552\n",
      "Epoch 8::Minibatch 341::LR 0.0838461538462 --> Loss 0.00518802007039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 342::LR 0.0838461538462 --> Loss 0.00350536425908\n",
      "Epoch 8::Minibatch 343::LR 0.0838461538462 --> Loss 0.00186309377352\n",
      "Epoch 8::Minibatch 344::LR 0.0838461538462 --> Loss 0.00304994881153\n",
      "Epoch 8::Minibatch 345::LR 0.0838461538462 --> Loss 0.00441599885623\n",
      "Epoch 8::Minibatch 346::LR 0.0838461538462 --> Loss 0.00575587391853\n",
      "Epoch 8::Minibatch 347::LR 0.0838461538462 --> Loss 0.000996423065662\n",
      "Epoch 8::Minibatch 348::LR 0.0838461538462 --> Loss 0.00379337390264\n",
      "Epoch 8::Minibatch 349::LR 0.0838461538462 --> Loss 0.00361834843953\n",
      "Epoch 8::Minibatch 350::LR 0.0838461538462 --> Loss 0.00200167099635\n",
      "Epoch 8::Minibatch 351::LR 0.0838461538462 --> Loss 0.00371305584908\n",
      "Epoch 8::Minibatch 352::LR 0.0838461538462 --> Loss 0.00481656869253\n",
      "Epoch 8::Minibatch 353::LR 0.0838461538462 --> Loss 0.0036271750927\n",
      "Epoch 8::Minibatch 354::LR 0.0838461538462 --> Loss 0.00300293048223\n",
      "Epoch 8::Minibatch 355::LR 0.0838461538462 --> Loss 0.00624096393585\n",
      "Epoch 8::Minibatch 356::LR 0.0838461538462 --> Loss 0.00324785312017\n",
      "Epoch 8::Minibatch 357::LR 0.0838461538462 --> Loss 0.00130706528823\n",
      "Epoch 8::Minibatch 358::LR 0.0838461538462 --> Loss 0.0023951570193\n",
      "Epoch 8::Minibatch 359::LR 0.0838461538462 --> Loss 0.00284144322077\n",
      "Epoch 8::Minibatch 360::LR 0.0838461538462 --> Loss 0.00257445216179\n",
      "Epoch 8::Minibatch 361::LR 0.0838461538462 --> Loss 0.00252621114254\n",
      "Epoch 8::Minibatch 362::LR 0.0838461538462 --> Loss 0.00260554075241\n",
      "Epoch 8::Minibatch 363::LR 0.0838461538462 --> Loss 0.000752117087444\n",
      "Epoch 8::Minibatch 364::LR 0.0838461538462 --> Loss 0.00210387547811\n",
      "Epoch 8::Minibatch 365::LR 0.0838461538462 --> Loss 0.00220378577709\n",
      "Epoch 8::Minibatch 366::LR 0.0838461538462 --> Loss 0.00240970691045\n",
      "Epoch 8::Minibatch 367::LR 0.0838461538462 --> Loss 0.00120261619488\n",
      "Epoch 8::Minibatch 368::LR 0.0838461538462 --> Loss 0.00106351574262\n",
      "Epoch 8::Minibatch 369::LR 0.0838461538462 --> Loss 0.00296557327112\n",
      "Epoch 8::Minibatch 370::LR 0.0838461538462 --> Loss 0.00232757627964\n",
      "Epoch 8::Minibatch 371::LR 0.0838461538462 --> Loss 0.00193670829137\n",
      "Epoch 8::Minibatch 372::LR 0.0838461538462 --> Loss 0.000500249514977\n",
      "Epoch 8::Minibatch 373::LR 0.0838461538462 --> Loss 0.00179158349832\n",
      "Epoch 8::Minibatch 374::LR 0.0838461538462 --> Loss 0.00217186510563\n",
      "Epoch 8::Minibatch 375::LR 0.0838461538462 --> Loss 0.00187481065591\n",
      "Epoch 8::Minibatch 376::LR 0.0838461538462 --> Loss 0.00128968606393\n",
      "Epoch 8::Minibatch 377::LR 0.0838461538462 --> Loss 0.00202093203863\n",
      "Epoch 8::Minibatch 378::LR 0.0838461538462 --> Loss 0.00215666552385\n",
      "Epoch 8::Minibatch 379::LR 0.0838461538462 --> Loss 0.00244940380255\n",
      "Epoch 8::Minibatch 380::LR 0.0838461538462 --> Loss 0.00164628326893\n",
      "Epoch 8::Minibatch 381::LR 0.0838461538462 --> Loss 0.00103749324878\n",
      "Epoch 8::Minibatch 382::LR 0.0838461538462 --> Loss 0.00205467760563\n",
      "Epoch 8::Minibatch 383::LR 0.0838461538462 --> Loss 0.00197501659393\n",
      "Epoch 8::Minibatch 384::LR 0.0838461538462 --> Loss 0.00108774413665\n",
      "Epoch 8::Minibatch 385::LR 0.0838461538462 --> Loss 0.00107809235652\n",
      "Epoch 8::Minibatch 386::LR 0.0838461538462 --> Loss 0.00223913888137\n",
      "Epoch 8::Minibatch 387::LR 0.0838461538462 --> Loss 0.00233958979448\n",
      "Epoch 8::Minibatch 388::LR 0.0838461538462 --> Loss 0.00115461289883\n",
      "Epoch 8::Minibatch 389::LR 0.0838461538462 --> Loss 0.00189601500829\n",
      "Epoch 8::Minibatch 390::LR 0.0838461538462 --> Loss 0.00390992283821\n",
      "Epoch 8::Minibatch 391::LR 0.0838461538462 --> Loss 0.0028156042099\n",
      "Epoch 8::Minibatch 392::LR 0.0838461538462 --> Loss 0.00280382633209\n",
      "Epoch 8::Minibatch 393::LR 0.0838461538462 --> Loss 0.00285704314709\n",
      "Epoch 8::Minibatch 394::LR 0.0838461538462 --> Loss 0.00216167708238\n",
      "Epoch 8::Minibatch 395::LR 0.0838461538462 --> Loss 0.00209879934788\n",
      "Epoch 8::Minibatch 396::LR 0.0838461538462 --> Loss 0.00204805950324\n",
      "Epoch 8::Minibatch 397::LR 0.0838461538462 --> Loss 0.0021632874012\n",
      "Epoch 8::Minibatch 398::LR 0.0838461538462 --> Loss 0.00213682015737\n",
      "Epoch 8::Minibatch 399::LR 0.0838461538462 --> Loss 0.00241539696852\n",
      "Epoch 8::Minibatch 400::LR 0.0838461538462 --> Loss 0.00209855278333\n",
      "Epoch 8::Minibatch 401::LR 0.0838461538462 --> Loss 0.00386350631714\n",
      "Epoch 8::Minibatch 402::LR 0.0838461538462 --> Loss 0.00196669479211\n",
      "Epoch 8::Minibatch 403::LR 0.0838461538462 --> Loss 0.00153401464224\n",
      "Epoch 8::Minibatch 404::LR 0.0838461538462 --> Loss 0.00167706688245\n",
      "Epoch 8::Minibatch 405::LR 0.0838461538462 --> Loss 0.00371625900269\n",
      "Epoch 8::Minibatch 406::LR 0.0838461538462 --> Loss 0.00260073781013\n",
      "Epoch 8::Minibatch 407::LR 0.0838461538462 --> Loss 0.00182845473289\n",
      "Epoch 8::Minibatch 408::LR 0.0838461538462 --> Loss 0.000525761296352\n",
      "Epoch 8::Minibatch 409::LR 0.0838461538462 --> Loss 0.00256708542506\n",
      "Epoch 8::Minibatch 410::LR 0.0838461538462 --> Loss 0.00339238882065\n",
      "Epoch 8::Minibatch 411::LR 0.0838461538462 --> Loss 0.00171780208747\n",
      "Epoch 8::Minibatch 412::LR 0.0838461538462 --> Loss 0.00104725559553\n",
      "Epoch 8::Minibatch 413::LR 0.0838461538462 --> Loss 0.00208645383517\n",
      "Epoch 8::Minibatch 414::LR 0.0838461538462 --> Loss 0.00183593054612\n",
      "Epoch 8::Minibatch 415::LR 0.0838461538462 --> Loss 0.00119358162085\n",
      "Epoch 8::Minibatch 416::LR 0.0838461538462 --> Loss 0.000904589196046\n",
      "Epoch 8::Minibatch 417::LR 0.0838461538462 --> Loss 0.00175517777602\n",
      "Epoch 8::Minibatch 418::LR 0.0838461538462 --> Loss 0.00300170898437\n",
      "Epoch 8::Minibatch 419::LR 0.0838461538462 --> Loss 0.000575059105953\n",
      "Epoch 8::Minibatch 420::LR 0.0838461538462 --> Loss 0.000762347926696\n",
      "Epoch 8::Minibatch 421::LR 0.0838461538462 --> Loss 0.0020038831234\n",
      "Epoch 8::Minibatch 422::LR 0.0838461538462 --> Loss 0.00228323042393\n",
      "Epoch 8::Minibatch 423::LR 0.0838461538462 --> Loss 0.00102169384559\n",
      "Epoch 8::Minibatch 424::LR 0.0838461538462 --> Loss 0.00166726469994\n",
      "Epoch 8::Minibatch 425::LR 0.0838461538462 --> Loss 0.00288048942884\n",
      "Epoch 8::Minibatch 426::LR 0.0838461538462 --> Loss 0.00206482072671\n",
      "Epoch 8::Minibatch 427::LR 0.0838461538462 --> Loss 0.000750200102727\n",
      "Epoch 8::Minibatch 428::LR 0.0838461538462 --> Loss 0.00121107697487\n",
      "Epoch 8::Minibatch 429::LR 0.0838461538462 --> Loss 0.00260949571927\n",
      "Epoch 8::Minibatch 430::LR 0.0838461538462 --> Loss 0.00972049077352\n",
      "Epoch 8::Minibatch 431::LR 0.0838461538462 --> Loss 0.00387161294619\n",
      "Epoch 8::Minibatch 432::LR 0.0838461538462 --> Loss 0.00462608536084\n",
      "Epoch 8::Minibatch 433::LR 0.0838461538462 --> Loss 0.00264978130658\n",
      "Epoch 8::Minibatch 434::LR 0.0838461538462 --> Loss 0.00261332154274\n",
      "Epoch 8::Minibatch 435::LR 0.0838461538462 --> Loss 0.00252329428991\n",
      "Epoch 8::Minibatch 436::LR 0.0838461538462 --> Loss 0.00189742108186\n",
      "Epoch 8::Minibatch 437::LR 0.0838461538462 --> Loss 0.00370082815488\n",
      "Epoch 8::Minibatch 438::LR 0.0838461538462 --> Loss 0.00291646162669\n",
      "Epoch 8::Minibatch 439::LR 0.0838461538462 --> Loss 0.00234681765238\n",
      "Epoch 8::Minibatch 440::LR 0.0838461538462 --> Loss 0.00345593372981\n",
      "Epoch 8::Minibatch 441::LR 0.0838461538462 --> Loss 0.00326855242252\n",
      "Epoch 8::Minibatch 442::LR 0.0838461538462 --> Loss 0.00305142819881\n",
      "Epoch 8::Minibatch 443::LR 0.0838461538462 --> Loss 0.00395223895709\n",
      "Epoch 8::Minibatch 444::LR 0.0838461538462 --> Loss 0.00301331222057\n",
      "Epoch 8::Minibatch 445::LR 0.0838461538462 --> Loss 0.00094969133536\n",
      "Epoch 8::Minibatch 446::LR 0.0838461538462 --> Loss 0.00157722393672\n",
      "Epoch 8::Minibatch 447::LR 0.0838461538462 --> Loss 0.00257868508498\n",
      "Epoch 8::Minibatch 448::LR 0.0838461538462 --> Loss 0.00254218419393\n",
      "Epoch 8::Minibatch 449::LR 0.0838461538462 --> Loss 0.00387313683828\n",
      "Epoch 8::Minibatch 450::LR 0.0838461538462 --> Loss 0.00253013888995\n",
      "Epoch 8::Minibatch 451::LR 0.0838461538462 --> Loss 0.00425519267718\n",
      "Epoch 8::Minibatch 452::LR 0.0838461538462 --> Loss 0.00247562328974\n",
      "Epoch 8::Minibatch 453::LR 0.0838461538462 --> Loss 0.000461404075225\n",
      "Epoch 8::Minibatch 454::LR 0.0838461538462 --> Loss 0.00366939703623\n",
      "Epoch 8::Minibatch 455::LR 0.0838461538462 --> Loss 0.00278644522031\n",
      "Epoch 8::Minibatch 456::LR 0.0838461538462 --> Loss 0.00328789969285\n",
      "Epoch 8::Minibatch 457::LR 0.0838461538462 --> Loss 0.0020668532451\n",
      "Epoch 8::Minibatch 458::LR 0.0838461538462 --> Loss 0.000868535339832\n",
      "Epoch 8::Minibatch 459::LR 0.0838461538462 --> Loss 0.00432329853376\n",
      "Epoch 8::Minibatch 460::LR 0.0838461538462 --> Loss 0.00279172360897\n",
      "Epoch 8::Minibatch 461::LR 0.0838461538462 --> Loss 0.00408310731252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 462::LR 0.0838461538462 --> Loss 0.000449205289284\n",
      "Epoch 8::Minibatch 463::LR 0.0838461538462 --> Loss 0.00472371339798\n",
      "Epoch 8::Minibatch 464::LR 0.0838461538462 --> Loss 0.00215022067229\n",
      "Epoch 8::Minibatch 465::LR 0.0838461538462 --> Loss 0.00576656063398\n",
      "Epoch 8::Minibatch 466::LR 0.0838461538462 --> Loss 0.00532285928726\n",
      "Epoch 8::Minibatch 467::LR 0.0838461538462 --> Loss 0.00664172768593\n",
      "Epoch 8::Minibatch 468::LR 0.0838461538462 --> Loss 0.00641964435577\n",
      "Epoch 8::Minibatch 469::LR 0.0838461538462 --> Loss 0.00677924394608\n",
      "Epoch 8::Minibatch 470::LR 0.0838461538462 --> Loss 0.00406265099843\n",
      "Epoch 8::Minibatch 471::LR 0.0838461538462 --> Loss 0.00195990542571\n",
      "Epoch 8::Minibatch 472::LR 0.0838461538462 --> Loss 0.00357901493708\n",
      "Epoch 8::Minibatch 473::LR 0.0838461538462 --> Loss 0.00220116913319\n",
      "Epoch 8::Minibatch 474::LR 0.0838461538462 --> Loss 0.000756592204173\n",
      "Epoch 8::Minibatch 475::LR 0.0838461538462 --> Loss 0.0057545375824\n",
      "Epoch 8::Minibatch 476::LR 0.0838461538462 --> Loss 0.00767713228861\n",
      "Epoch 8::Minibatch 477::LR 0.0838461538462 --> Loss 0.00100287278493\n",
      "Epoch 8::Minibatch 478::LR 0.0838461538462 --> Loss 0.00256913503011\n",
      "Epoch 8::Minibatch 479::LR 0.0838461538462 --> Loss 0.00198168555895\n",
      "Epoch 8::Minibatch 480::LR 0.0838461538462 --> Loss 0.00154546280702\n",
      "Epoch 8::Minibatch 481::LR 0.0838461538462 --> Loss 0.00098375360171\n",
      "Epoch 8::Minibatch 482::LR 0.0838461538462 --> Loss 0.00214434166749\n",
      "Epoch 8::Minibatch 483::LR 0.0838461538462 --> Loss 0.00344182451566\n",
      "Epoch 8::Minibatch 484::LR 0.0838461538462 --> Loss 0.00372596184413\n",
      "Epoch 8::Minibatch 485::LR 0.0838461538462 --> Loss 0.000796327739954\n",
      "Epoch 8::Minibatch 486::LR 0.0838461538462 --> Loss 0.00325655440489\n",
      "Epoch 8::Minibatch 487::LR 0.0838461538462 --> Loss 0.00358549833298\n",
      "Epoch 8::Minibatch 488::LR 0.0838461538462 --> Loss 0.00206310311953\n",
      "Epoch 8::Minibatch 489::LR 0.0838461538462 --> Loss 0.00322221497695\n",
      "Epoch 8::Minibatch 490::LR 0.0838461538462 --> Loss 0.000448202292124\n",
      "Epoch 8::Minibatch 491::LR 0.0838461538462 --> Loss 0.00450323859851\n",
      "Epoch 8::Minibatch 492::LR 0.0838461538462 --> Loss 0.00304545402527\n",
      "Epoch 8::Minibatch 493::LR 0.0838461538462 --> Loss 0.00306439260642\n",
      "Epoch 8::Minibatch 494::LR 0.0838461538462 --> Loss 0.000774843494097\n",
      "Epoch 8::Minibatch 495::LR 0.0838461538462 --> Loss 0.00193730632464\n",
      "Epoch 8::Minibatch 496::LR 0.0838461538462 --> Loss 0.0030887144804\n",
      "Epoch 8::Minibatch 497::LR 0.0838461538462 --> Loss 0.000994542042414\n",
      "Epoch 8::Minibatch 498::LR 0.0838461538462 --> Loss 0.000640108982722\n",
      "Epoch 8::Minibatch 499::LR 0.0838461538462 --> Loss 0.00400696555773\n",
      "Epoch 8::Minibatch 500::LR 0.0838461538462 --> Loss 0.00146958053112\n",
      "Epoch 8::Minibatch 501::LR 0.0838461538462 --> Loss 0.00233227729797\n",
      "Epoch 8::Minibatch 502::LR 0.0838461538462 --> Loss 0.00411417484283\n",
      "Epoch 8::Minibatch 503::LR 0.0838461538462 --> Loss 0.0103580331802\n",
      "Epoch 8::Minibatch 504::LR 0.0838461538462 --> Loss 0.00859185536702\n",
      "Epoch 8::Minibatch 505::LR 0.0838461538462 --> Loss 0.00459714531898\n",
      "Epoch 8::Minibatch 506::LR 0.0838461538462 --> Loss 0.00365608890851\n",
      "Epoch 8::Minibatch 507::LR 0.0838461538462 --> Loss 0.00617396116257\n",
      "Epoch 8::Minibatch 508::LR 0.0838461538462 --> Loss 0.00339216073354\n",
      "Epoch 8::Minibatch 509::LR 0.0838461538462 --> Loss 0.00486604452133\n",
      "Epoch 8::Minibatch 510::LR 0.0838461538462 --> Loss 0.00488921364148\n",
      "Epoch 8::Minibatch 511::LR 0.0838461538462 --> Loss 0.00386645833651\n",
      "Epoch 8::Minibatch 512::LR 0.0838461538462 --> Loss 0.00271800835927\n",
      "Epoch 8::Minibatch 513::LR 0.0838461538462 --> Loss 0.000724581728379\n",
      "Epoch 8::Minibatch 514::LR 0.0838461538462 --> Loss 0.00273063679536\n",
      "Epoch 8::Minibatch 515::LR 0.0838461538462 --> Loss 0.00310595730941\n",
      "Epoch 8::Minibatch 516::LR 0.0838461538462 --> Loss 0.00427219430606\n",
      "Epoch 8::Minibatch 517::LR 0.0838461538462 --> Loss 0.00339492758115\n",
      "Epoch 8::Minibatch 518::LR 0.0838461538462 --> Loss 0.00257213195165\n",
      "Epoch 8::Minibatch 519::LR 0.0838461538462 --> Loss 0.00339047551155\n",
      "Epoch 8::Minibatch 520::LR 0.0838461538462 --> Loss 0.0054170191288\n",
      "Epoch 8::Minibatch 521::LR 0.0838461538462 --> Loss 0.0056211455663\n",
      "Epoch 8::Minibatch 522::LR 0.0838461538462 --> Loss 0.00819071531296\n",
      "Epoch 8::Minibatch 523::LR 0.0838461538462 --> Loss 0.000758169690768\n",
      "Epoch 8::Minibatch 524::LR 0.0838461538462 --> Loss 0.00148652305206\n",
      "Epoch 8::Minibatch 525::LR 0.0838461538462 --> Loss 0.00332526346048\n",
      "Epoch 8::Minibatch 526::LR 0.0838461538462 --> Loss 0.00435633063316\n",
      "Epoch 8::Minibatch 527::LR 0.0838461538462 --> Loss 0.00241723001003\n",
      "Epoch 8::Minibatch 528::LR 0.0838461538462 --> Loss 0.00124056915442\n",
      "Epoch 8::Minibatch 529::LR 0.0838461538462 --> Loss 0.0042188902696\n",
      "Epoch 8::Minibatch 530::LR 0.0838461538462 --> Loss 0.0044301923116\n",
      "Epoch 8::Minibatch 531::LR 0.0838461538462 --> Loss 0.00374511877696\n",
      "Epoch 8::Minibatch 532::LR 0.0838461538462 --> Loss 0.00280067582925\n",
      "Epoch 8::Minibatch 533::LR 0.0838461538462 --> Loss 0.00491940935453\n",
      "Epoch 8::Minibatch 534::LR 0.0838461538462 --> Loss 0.00395435810089\n",
      "Epoch 8::Minibatch 535::LR 0.0838461538462 --> Loss 0.00327173610528\n",
      "Epoch 8::Minibatch 536::LR 0.0838461538462 --> Loss 0.00214745501677\n",
      "Epoch 8::Minibatch 537::LR 0.0838461538462 --> Loss 0.000718586742878\n",
      "Epoch 8::Minibatch 538::LR 0.0838461538462 --> Loss 0.0017879507939\n",
      "Epoch 8::Minibatch 539::LR 0.0838461538462 --> Loss 0.0035132475694\n",
      "Epoch 8::Minibatch 540::LR 0.0838461538462 --> Loss 0.00344282150269\n",
      "Epoch 8::Minibatch 541::LR 0.0838461538462 --> Loss 0.00295197208722\n",
      "Epoch 8::Minibatch 542::LR 0.0838461538462 --> Loss 0.00265358587106\n",
      "Epoch 8::Minibatch 543::LR 0.0838461538462 --> Loss 0.00293338954449\n",
      "Epoch 8::Minibatch 544::LR 0.0838461538462 --> Loss 0.00403296311696\n",
      "Epoch 8::Minibatch 545::LR 0.0838461538462 --> Loss 0.00212856074174\n",
      "Epoch 8::Minibatch 546::LR 0.0838461538462 --> Loss 0.00071980809172\n",
      "Epoch 8::Minibatch 547::LR 0.0838461538462 --> Loss 0.00270732680957\n",
      "Epoch 8::Minibatch 548::LR 0.0838461538462 --> Loss 0.00404736995697\n",
      "Epoch 8::Minibatch 549::LR 0.0838461538462 --> Loss 0.00780546108882\n",
      "Epoch 8::Minibatch 550::LR 0.0838461538462 --> Loss 0.00120495329301\n",
      "Epoch 8::Minibatch 551::LR 0.0838461538462 --> Loss 0.002506245176\n",
      "Epoch 8::Minibatch 552::LR 0.0838461538462 --> Loss 0.00376705567042\n",
      "Epoch 8::Minibatch 553::LR 0.0838461538462 --> Loss 0.00338370045026\n",
      "Epoch 8::Minibatch 554::LR 0.0838461538462 --> Loss 0.00399551987648\n",
      "Epoch 8::Minibatch 555::LR 0.0838461538462 --> Loss 0.00105981101592\n",
      "Epoch 8::Minibatch 556::LR 0.0838461538462 --> Loss 0.00214568098386\n",
      "Epoch 8::Minibatch 557::LR 0.0838461538462 --> Loss 0.00257675111294\n",
      "Epoch 8::Minibatch 558::LR 0.0838461538462 --> Loss 0.00388541380564\n",
      "Epoch 8::Minibatch 559::LR 0.0838461538462 --> Loss 0.00384045322736\n",
      "Epoch 8::Minibatch 560::LR 0.0838461538462 --> Loss 0.00323382953803\n",
      "Epoch 8::Minibatch 561::LR 0.0838461538462 --> Loss 0.00289580066999\n",
      "Epoch 8::Minibatch 562::LR 0.0838461538462 --> Loss 0.00247347891331\n",
      "Epoch 8::Minibatch 563::LR 0.0838461538462 --> Loss 0.00412084499995\n",
      "Epoch 8::Minibatch 564::LR 0.0838461538462 --> Loss 0.00323567370574\n",
      "Epoch 8::Minibatch 565::LR 0.0838461538462 --> Loss 0.00387257854144\n",
      "Epoch 8::Minibatch 566::LR 0.0838461538462 --> Loss 0.00242254932721\n",
      "Epoch 8::Minibatch 567::LR 0.0838461538462 --> Loss 0.00273624877135\n",
      "Epoch 8::Minibatch 568::LR 0.0838461538462 --> Loss 0.00190511961778\n",
      "Epoch 8::Minibatch 569::LR 0.0838461538462 --> Loss 0.000611546734969\n",
      "Epoch 8::Minibatch 570::LR 0.0838461538462 --> Loss 0.00182547529538\n",
      "Epoch 8::Minibatch 571::LR 0.0838461538462 --> Loss 0.00239812016487\n",
      "Epoch 8::Minibatch 572::LR 0.0838461538462 --> Loss 0.00251904249191\n",
      "Epoch 8::Minibatch 573::LR 0.0838461538462 --> Loss 0.00158712069194\n",
      "Epoch 8::Minibatch 574::LR 0.0838461538462 --> Loss 0.00108484069506\n",
      "Epoch 8::Minibatch 575::LR 0.0838461538462 --> Loss 0.00188592374325\n",
      "Epoch 8::Minibatch 576::LR 0.0838461538462 --> Loss 0.00225671152274\n",
      "Epoch 8::Minibatch 577::LR 0.0838461538462 --> Loss 0.00176485995452\n",
      "Epoch 8::Minibatch 578::LR 0.0838461538462 --> Loss 0.00133834123611\n",
      "Epoch 8::Minibatch 579::LR 0.0838461538462 --> Loss 0.00125261247158\n",
      "Epoch 8::Minibatch 580::LR 0.0838461538462 --> Loss 0.00203825652599\n",
      "Epoch 8::Minibatch 581::LR 0.0838461538462 --> Loss 0.00177052497864\n",
      "Epoch 8::Minibatch 582::LR 0.0838461538462 --> Loss 0.00420930425326\n",
      "Epoch 8::Minibatch 583::LR 0.0838461538462 --> Loss 0.000979793866475\n",
      "Epoch 8::Minibatch 584::LR 0.0838461538462 --> Loss 0.0013522708416\n",
      "Epoch 8::Minibatch 585::LR 0.0838461538462 --> Loss 0.0054304309686\n",
      "Epoch 8::Minibatch 586::LR 0.0838461538462 --> Loss 0.00434038837751\n",
      "Epoch 8::Minibatch 587::LR 0.0838461538462 --> Loss 0.00118554095427\n",
      "Epoch 8::Minibatch 588::LR 0.0838461538462 --> Loss 0.00148638317982\n",
      "Epoch 8::Minibatch 589::LR 0.0838461538462 --> Loss 0.00282455563545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 590::LR 0.0838461538462 --> Loss 0.00215764343739\n",
      "Epoch 8::Minibatch 591::LR 0.0838461538462 --> Loss 0.00359169244766\n",
      "Epoch 8::Minibatch 592::LR 0.0838461538462 --> Loss 0.00123196681341\n",
      "Epoch 8::Minibatch 593::LR 0.0838461538462 --> Loss 0.00269157846769\n",
      "Epoch 8::Minibatch 594::LR 0.0838461538462 --> Loss 0.0029595887661\n",
      "Epoch 8::Minibatch 595::LR 0.0838461538462 --> Loss 0.00309304773808\n",
      "Epoch 8::Minibatch 596::LR 0.0838461538462 --> Loss 0.00207895139853\n",
      "Epoch 8::Minibatch 597::LR 0.0838461538462 --> Loss 0.00126103788614\n",
      "Epoch 8::Minibatch 598::LR 0.0838461538462 --> Loss 0.00329760034879\n",
      "Epoch 8::Minibatch 599::LR 0.0838461538462 --> Loss 0.00194383919239\n",
      "Epoch 8::Minibatch 600::LR 0.0838461538462 --> Loss 0.00235146721204\n",
      "Epoch 8::Minibatch 601::LR 0.0838461538462 --> Loss 0.00394386967023\n",
      "Epoch 8::Minibatch 602::LR 0.0838461538462 --> Loss 0.00217598557472\n",
      "Epoch 8::Minibatch 603::LR 0.0838461538462 --> Loss 0.00274452666442\n",
      "Epoch 8::Minibatch 604::LR 0.0838461538462 --> Loss 0.00168776869774\n",
      "Epoch 8::Minibatch 605::LR 0.0838461538462 --> Loss 0.00250521520774\n",
      "Epoch 8::Minibatch 606::LR 0.0838461538462 --> Loss 0.00200438042482\n",
      "Epoch 8::Minibatch 607::LR 0.0838461538462 --> Loss 0.000873134434223\n",
      "Epoch 8::Minibatch 608::LR 0.0838461538462 --> Loss 0.00168401122093\n",
      "Epoch 8::Minibatch 609::LR 0.0838461538462 --> Loss 0.00238201498985\n",
      "Epoch 8::Minibatch 610::LR 0.0838461538462 --> Loss 0.0040193649133\n",
      "Epoch 8::Minibatch 611::LR 0.0838461538462 --> Loss 0.00273120462894\n",
      "Epoch 8::Minibatch 612::LR 0.0838461538462 --> Loss 0.000554233143727\n",
      "Epoch 8::Minibatch 613::LR 0.0838461538462 --> Loss 0.00136858989795\n",
      "Epoch 8::Minibatch 614::LR 0.0838461538462 --> Loss 0.0025726856788\n",
      "Epoch 8::Minibatch 615::LR 0.0838461538462 --> Loss 0.0017401488622\n",
      "Epoch 8::Minibatch 616::LR 0.0838461538462 --> Loss 0.000962240894636\n",
      "Epoch 8::Minibatch 617::LR 0.0838461538462 --> Loss 0.000557264933983\n",
      "Epoch 8::Minibatch 618::LR 0.0838461538462 --> Loss 0.00270112216473\n",
      "Epoch 8::Minibatch 619::LR 0.0838461538462 --> Loss 0.00196620722612\n",
      "Epoch 8::Minibatch 620::LR 0.0838461538462 --> Loss 0.00178127328555\n",
      "Epoch 8::Minibatch 621::LR 0.0838461538462 --> Loss 0.000902611215909\n",
      "Epoch 8::Minibatch 622::LR 0.0838461538462 --> Loss 0.000867395897706\n",
      "Epoch 8::Minibatch 623::LR 0.0838461538462 --> Loss 0.00223184585571\n",
      "Epoch 8::Minibatch 624::LR 0.0838461538462 --> Loss 0.00183110872904\n",
      "Epoch 8::Minibatch 625::LR 0.0838461538462 --> Loss 0.00330575704575\n",
      "Epoch 8::Minibatch 626::LR 0.0838461538462 --> Loss 0.00512467424075\n",
      "Epoch 8::Minibatch 627::LR 0.0838461538462 --> Loss 0.00145398000876\n",
      "Epoch 8::Minibatch 628::LR 0.0838461538462 --> Loss 0.000997334122658\n",
      "Epoch 8::Minibatch 629::LR 0.0838461538462 --> Loss 0.00365779876709\n",
      "Epoch 8::Minibatch 630::LR 0.0838461538462 --> Loss 0.00350439310074\n",
      "Epoch 8::Minibatch 631::LR 0.0838461538462 --> Loss 0.00767263730367\n",
      "Epoch 8::Minibatch 632::LR 0.0838461538462 --> Loss 0.00087962081035\n",
      "Epoch 8::Minibatch 633::LR 0.0838461538462 --> Loss 0.0017603957653\n",
      "Epoch 8::Minibatch 634::LR 0.0838461538462 --> Loss 0.00335493882497\n",
      "Epoch 8::Minibatch 635::LR 0.0838461538462 --> Loss 0.00473187327385\n",
      "Epoch 8::Minibatch 636::LR 0.0838461538462 --> Loss 0.00588757077853\n",
      "Epoch 8::Minibatch 637::LR 0.0838461538462 --> Loss 0.000996268987656\n",
      "Epoch 8::Minibatch 638::LR 0.0838461538462 --> Loss 0.00168756445249\n",
      "Epoch 8::Minibatch 639::LR 0.0838461538462 --> Loss 0.00348415335019\n",
      "Epoch 8::Minibatch 640::LR 0.0838461538462 --> Loss 0.00534762978554\n",
      "Epoch 8::Minibatch 641::LR 0.0838461538462 --> Loss 0.00331641515096\n",
      "Epoch 8::Minibatch 642::LR 0.0838461538462 --> Loss 0.000650365352631\n",
      "Epoch 8::Minibatch 643::LR 0.0838461538462 --> Loss 0.00243845939636\n",
      "Epoch 8::Minibatch 644::LR 0.0838461538462 --> Loss 0.00414442221324\n",
      "Epoch 8::Minibatch 645::LR 0.0838461538462 --> Loss 0.00433466792107\n",
      "Epoch 8::Minibatch 646::LR 0.0838461538462 --> Loss 0.00165276934703\n",
      "Epoch 8::Minibatch 647::LR 0.0838461538462 --> Loss 0.000708502431711\n",
      "Epoch 8::Minibatch 648::LR 0.0838461538462 --> Loss 0.00322103798389\n",
      "Epoch 8::Minibatch 649::LR 0.0838461538462 --> Loss 0.00379285772641\n",
      "Epoch 8::Minibatch 650::LR 0.0838461538462 --> Loss 0.0035053384304\n",
      "Epoch 8::Minibatch 651::LR 0.0838461538462 --> Loss 0.00152840216955\n",
      "Epoch 8::Minibatch 652::LR 0.0838461538462 --> Loss 0.000969885488351\n",
      "Epoch 8::Minibatch 653::LR 0.0838461538462 --> Loss 0.00302188356717\n",
      "Epoch 8::Minibatch 654::LR 0.0838461538462 --> Loss 0.00319219768047\n",
      "Epoch 8::Minibatch 655::LR 0.0838461538462 --> Loss 0.00352848291397\n",
      "Epoch 8::Minibatch 656::LR 0.0838461538462 --> Loss 0.000850754678249\n",
      "Epoch 8::Minibatch 657::LR 0.0838461538462 --> Loss 0.00223437766234\n",
      "Epoch 8::Minibatch 658::LR 0.0838461538462 --> Loss 0.00508540391922\n",
      "Epoch 8::Minibatch 659::LR 0.0838461538462 --> Loss 0.00244071662426\n",
      "Epoch 8::Minibatch 660::LR 0.0838461538462 --> Loss 0.00263833920161\n",
      "Epoch 8::Minibatch 661::LR 0.0838461538462 --> Loss 0.00267999867598\n",
      "Epoch 8::Minibatch 662::LR 0.0838461538462 --> Loss 0.00190619548162\n",
      "Epoch 8::Minibatch 663::LR 0.0838461538462 --> Loss 0.0037718017896\n",
      "Epoch 8::Minibatch 664::LR 0.0838461538462 --> Loss 0.00363031983376\n",
      "Epoch 8::Minibatch 665::LR 0.0838461538462 --> Loss 0.000856740276019\n",
      "Epoch 8::Minibatch 666::LR 0.0838461538462 --> Loss 0.00399989366531\n",
      "Epoch 8::Minibatch 667::LR 0.0838461538462 --> Loss 0.00263432979584\n",
      "Epoch 8::Minibatch 668::LR 0.0838461538462 --> Loss 0.00755175272624\n",
      "Epoch 8::Minibatch 669::LR 0.0838461538462 --> Loss 0.00114219844341\n",
      "Epoch 8::Minibatch 670::LR 0.0838461538462 --> Loss 0.00143751809994\n",
      "Epoch 8::Minibatch 671::LR 0.0838461538462 --> Loss 0.00564449906349\n",
      "Epoch 8::Minibatch 672::LR 0.0838461538462 --> Loss 0.00411172668139\n",
      "Epoch 8::Minibatch 673::LR 0.0838461538462 --> Loss 0.00168319106102\n",
      "Epoch 8::Minibatch 674::LR 0.0838461538462 --> Loss 0.000591028829416\n",
      "Epoch 8::Minibatch 675::LR 0.0838461538462 --> Loss 0.00228149294853\n",
      "Epoch 8::Minibatch 676::LR 0.0838461538462 --> Loss 0.00225689192613\n",
      "Epoch 8::Minibatch 677::LR 0.0838461538462 --> Loss 0.00299138148626\n",
      "Epoch 8::Minibatch 678::LR 0.0838461538462 --> Loss 0.00202124516169\n",
      "Epoch 8::Minibatch 679::LR 0.0838461538462 --> Loss 0.00369922995567\n",
      "Epoch 8::Minibatch 680::LR 0.0838461538462 --> Loss 0.00220416506131\n",
      "Epoch 8::Minibatch 681::LR 0.0838461538462 --> Loss 0.00250827411811\n",
      "Epoch 8::Minibatch 682::LR 0.0838461538462 --> Loss 0.000807586461306\n",
      "Epoch 8::Minibatch 683::LR 0.0838461538462 --> Loss 0.00251680374146\n",
      "Epoch 8::Minibatch 684::LR 0.0838461538462 --> Loss 0.00242679774761\n",
      "Epoch 8::Minibatch 685::LR 0.0838461538462 --> Loss 0.00303521414598\n",
      "Epoch 8::Minibatch 686::LR 0.0838461538462 --> Loss 0.00155275175969\n",
      "Epoch 8::Minibatch 687::LR 0.0838461538462 --> Loss 0.000876722534498\n",
      "Epoch 8::Minibatch 688::LR 0.0838461538462 --> Loss 0.0027904911836\n",
      "Epoch 8::Minibatch 689::LR 0.0838461538462 --> Loss 0.00262040058772\n",
      "Epoch 8::Minibatch 690::LR 0.0838461538462 --> Loss 0.00197013815244\n",
      "Epoch 8::Minibatch 691::LR 0.0838461538462 --> Loss 0.000694242268801\n",
      "Epoch 8::Minibatch 692::LR 0.0838461538462 --> Loss 0.00256720423698\n",
      "Epoch 8::Minibatch 693::LR 0.0838461538462 --> Loss 0.0026224921147\n",
      "Epoch 8::Minibatch 694::LR 0.0838461538462 --> Loss 0.00306531627973\n",
      "Epoch 8::Minibatch 695::LR 0.0838461538462 --> Loss 0.00175011018912\n",
      "Epoch 8::Minibatch 696::LR 0.0838461538462 --> Loss 0.00205030918121\n",
      "Epoch 8::Minibatch 697::LR 0.0838461538462 --> Loss 0.00144098967314\n",
      "Epoch 8::Minibatch 698::LR 0.0838461538462 --> Loss 0.00163463522991\n",
      "Epoch 8::Minibatch 699::LR 0.0838461538462 --> Loss 0.00391447464625\n",
      "Epoch 8::Minibatch 700::LR 0.0838461538462 --> Loss 0.00275696714719\n",
      "Epoch 8::Minibatch 701::LR 0.0838461538462 --> Loss 0.00207814653714\n",
      "Epoch 8::Minibatch 702::LR 0.0838461538462 --> Loss 0.00171517392\n",
      "Epoch 8::Minibatch 703::LR 0.0838461538462 --> Loss 0.0042235259215\n",
      "Epoch 8::Minibatch 704::LR 0.0838461538462 --> Loss 0.0018292393287\n",
      "Epoch 8::Minibatch 705::LR 0.0838461538462 --> Loss 0.00286314666271\n",
      "Epoch 8::Minibatch 706::LR 0.0838461538462 --> Loss 0.0022269376119\n",
      "Epoch 8::Minibatch 707::LR 0.0838461538462 --> Loss 0.00123420695464\n",
      "Epoch 8::Minibatch 708::LR 0.0838461538462 --> Loss 0.0017691630125\n",
      "Epoch 8::Minibatch 709::LR 0.0838461538462 --> Loss 0.00176243503888\n",
      "Epoch 8::Minibatch 710::LR 0.0838461538462 --> Loss 0.00249459922314\n",
      "Epoch 8::Minibatch 711::LR 0.0838461538462 --> Loss 0.00190326531728\n",
      "Epoch 8::Minibatch 712::LR 0.0838461538462 --> Loss 0.00135566532612\n",
      "Epoch 8::Minibatch 713::LR 0.0838461538462 --> Loss 0.00175270795822\n",
      "Epoch 8::Minibatch 714::LR 0.0838461538462 --> Loss 0.00271053473155\n",
      "Epoch 8::Minibatch 715::LR 0.0838461538462 --> Loss 0.00297799964746\n",
      "Epoch 8::Minibatch 716::LR 0.0838461538462 --> Loss 0.00161891529957\n",
      "Epoch 8::Minibatch 717::LR 0.0838461538462 --> Loss 0.00162182817856\n",
      "Epoch 8::Minibatch 718::LR 0.0838461538462 --> Loss 0.00129404048125\n",
      "Epoch 8::Minibatch 719::LR 0.0838461538462 --> Loss 0.0016912651062\n",
      "Epoch 8::Minibatch 720::LR 0.0838461538462 --> Loss 0.00250711182753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 721::LR 0.0838461538462 --> Loss 0.00068166633447\n",
      "Epoch 8::Minibatch 722::LR 0.0838461538462 --> Loss 0.00499396443367\n",
      "Epoch 8::Minibatch 723::LR 0.0838461538462 --> Loss 0.00492215037346\n",
      "Epoch 8::Minibatch 724::LR 0.0838461538462 --> Loss 0.00101544380188\n",
      "Epoch 8::Minibatch 725::LR 0.0838461538462 --> Loss 0.00234634180864\n",
      "Epoch 8::Minibatch 726::LR 0.0838461538462 --> Loss 0.00519199967384\n",
      "Epoch 8::Minibatch 727::LR 0.0838461538462 --> Loss 0.00307241141796\n",
      "Epoch 8::Minibatch 728::LR 0.0838461538462 --> Loss 0.000696904212236\n",
      "Epoch 8::Minibatch 729::LR 0.0838461538462 --> Loss 0.000824363380671\n",
      "Epoch 8::Minibatch 730::LR 0.0838461538462 --> Loss 0.00266479969025\n",
      "Epoch 8::Minibatch 731::LR 0.0838461538462 --> Loss 0.00247878730297\n",
      "Epoch 8::Minibatch 732::LR 0.0838461538462 --> Loss 0.00236209313075\n",
      "Epoch 8::Minibatch 733::LR 0.0838461538462 --> Loss 0.000812699049711\n",
      "Epoch 8::Minibatch 734::LR 0.0838461538462 --> Loss 0.00186572194099\n",
      "Epoch 8::Minibatch 735::LR 0.0838461538462 --> Loss 0.00240581015746\n",
      "Epoch 8::Minibatch 736::LR 0.0838461538462 --> Loss 0.00347342014313\n",
      "Epoch 8::Minibatch 737::LR 0.0838461538462 --> Loss 0.00318697889646\n",
      "Epoch 8::Minibatch 738::LR 0.0838461538462 --> Loss 0.00178758064906\n",
      "Epoch 8::Minibatch 739::LR 0.0838461538462 --> Loss 0.00252268234889\n",
      "Epoch 8::Minibatch 740::LR 0.0838461538462 --> Loss 0.00383672992388\n",
      "Epoch 8::Minibatch 741::LR 0.0838461538462 --> Loss 0.0028302381436\n",
      "Epoch 8::Minibatch 742::LR 0.0838461538462 --> Loss 0.0021619250377\n",
      "Epoch 8::Minibatch 743::LR 0.0838461538462 --> Loss 0.00135813961426\n",
      "Epoch 8::Minibatch 744::LR 0.0838461538462 --> Loss 0.0018356047074\n",
      "Epoch 8::Minibatch 745::LR 0.0838461538462 --> Loss 0.00288543025653\n",
      "Epoch 8::Minibatch 746::LR 0.0838461538462 --> Loss 0.00307378510634\n",
      "Epoch 8::Minibatch 747::LR 0.0838461538462 --> Loss 0.00181439399719\n",
      "Epoch 8::Minibatch 748::LR 0.0838461538462 --> Loss 0.000702136605978\n",
      "Epoch 8::Minibatch 749::LR 0.0838461538462 --> Loss 0.00169784963131\n",
      "Epoch 8::Minibatch 750::LR 0.0838461538462 --> Loss 0.00251470903556\n",
      "Epoch 8::Minibatch 751::LR 0.0838461538462 --> Loss 0.00270897726218\n",
      "Epoch 8::Minibatch 752::LR 0.0838461538462 --> Loss 0.00111839880546\n",
      "Epoch 8::Minibatch 753::LR 0.0838461538462 --> Loss 0.00229296902816\n",
      "Epoch 8::Minibatch 754::LR 0.0838461538462 --> Loss 0.00240307748318\n",
      "Epoch 8::Minibatch 755::LR 0.0838461538462 --> Loss 0.00269282658895\n",
      "Epoch 8::Minibatch 756::LR 0.0838461538462 --> Loss 0.00144332875808\n",
      "Epoch 8::Minibatch 757::LR 0.0838461538462 --> Loss 0.000942669014136\n",
      "Epoch 8::Minibatch 758::LR 0.0838461538462 --> Loss 0.00167591154575\n",
      "Epoch 8::Minibatch 759::LR 0.0838461538462 --> Loss 0.00393007715543\n",
      "Epoch 8::Minibatch 760::LR 0.0838461538462 --> Loss 0.00312311549981\n",
      "Epoch 8::Minibatch 761::LR 0.0838461538462 --> Loss 0.00649197419484\n",
      "Epoch 8::Minibatch 762::LR 0.0838461538462 --> Loss 0.00388709068298\n",
      "Epoch 8::Minibatch 763::LR 0.0838461538462 --> Loss 0.00373680233955\n",
      "Epoch 8::Minibatch 764::LR 0.0838461538462 --> Loss 0.0033556731542\n",
      "Epoch 8::Minibatch 765::LR 0.0838461538462 --> Loss 0.00140100419521\n",
      "Epoch 8::Minibatch 766::LR 0.0838461538462 --> Loss 0.00231723109881\n",
      "Epoch 8::Minibatch 767::LR 0.0838461538462 --> Loss 0.0051288151741\n",
      "Epoch 8::Minibatch 768::LR 0.0838461538462 --> Loss 0.00358488758405\n",
      "Epoch 8::Minibatch 769::LR 0.0838461538462 --> Loss 0.00198624491692\n",
      "Epoch 8::Minibatch 770::LR 0.0838461538462 --> Loss 0.00149426897367\n",
      "Epoch 8::Minibatch 771::LR 0.0838461538462 --> Loss 0.00390780568123\n",
      "Epoch 8::Minibatch 772::LR 0.0838461538462 --> Loss 0.0033590277036\n",
      "Epoch 8::Minibatch 773::LR 0.0838461538462 --> Loss 0.00319830874602\n",
      "Epoch 8::Minibatch 774::LR 0.0838461538462 --> Loss 0.00177787125111\n",
      "Epoch 8::Minibatch 775::LR 0.0838461538462 --> Loss 0.00448116938273\n",
      "Epoch 8::Minibatch 776::LR 0.0838461538462 --> Loss 0.00360569039981\n",
      "Epoch 8::Minibatch 777::LR 0.0838461538462 --> Loss 0.0080607064565\n",
      "Epoch 8::Minibatch 778::LR 0.0838461538462 --> Loss 0.0111433712641\n",
      "Epoch 8::Minibatch 779::LR 0.0838461538462 --> Loss 0.00185946464539\n",
      "Epoch 8::Minibatch 780::LR 0.0838461538462 --> Loss 0.00172856171926\n",
      "Epoch 8::Minibatch 781::LR 0.0838461538462 --> Loss 0.00367223302523\n",
      "Epoch 8::Minibatch 782::LR 0.0838461538462 --> Loss 0.00428703308105\n",
      "Epoch 8::Minibatch 783::LR 0.0838461538462 --> Loss 0.00241206586361\n",
      "Epoch 8::Minibatch 784::LR 0.0838461538462 --> Loss 0.000792384048303\n",
      "Epoch 8::Minibatch 785::LR 0.0838461538462 --> Loss 0.0041554137071\n",
      "Epoch 8::Minibatch 786::LR 0.0838461538462 --> Loss 0.00377410809199\n",
      "Epoch 8::Minibatch 787::LR 0.0838461538462 --> Loss 0.00297800262769\n",
      "Epoch 8::Minibatch 788::LR 0.0838461538462 --> Loss 0.00262633144855\n",
      "Epoch 8::Minibatch 789::LR 0.0838461538462 --> Loss 0.000795374562343\n",
      "Epoch 8::Minibatch 790::LR 0.0838461538462 --> Loss 0.00338159759839\n",
      "Epoch 8::Minibatch 791::LR 0.0838461538462 --> Loss 0.00395359079043\n",
      "Epoch 8::Minibatch 792::LR 0.0838461538462 --> Loss 0.00367072343826\n",
      "Epoch 8::Minibatch 793::LR 0.0838461538462 --> Loss 0.00211348116398\n",
      "Epoch 8::Minibatch 794::LR 0.0838461538462 --> Loss 0.0011996525526\n",
      "Epoch 8::Minibatch 795::LR 0.0838461538462 --> Loss 0.00356621543566\n",
      "Epoch 8::Minibatch 796::LR 0.0838461538462 --> Loss 0.00614563862483\n",
      "Epoch 8::Minibatch 797::LR 0.0838461538462 --> Loss 0.00870940446854\n",
      "Epoch 8::Minibatch 798::LR 0.0838461538462 --> Loss 0.00355812072754\n",
      "Epoch 8::Minibatch 799::LR 0.0838461538462 --> Loss 0.00268166840076\n",
      "Epoch 8::Minibatch 800::LR 0.0838461538462 --> Loss 0.00214449286461\n",
      "Epoch 8::Minibatch 801::LR 0.0838461538462 --> Loss 0.00419307549795\n",
      "Epoch 8::Minibatch 802::LR 0.0838461538462 --> Loss 0.00147811134656\n",
      "Epoch 8::Minibatch 803::LR 0.0838461538462 --> Loss 0.00281332989534\n",
      "Epoch 8::Minibatch 804::LR 0.0838461538462 --> Loss 0.00235060969989\n",
      "Epoch 8::Minibatch 805::LR 0.0838461538462 --> Loss 0.00241972903411\n",
      "Epoch 8::Minibatch 806::LR 0.0838461538462 --> Loss 0.00333974758784\n",
      "Epoch 8::Minibatch 807::LR 0.0838461538462 --> Loss 0.00311980942885\n",
      "Epoch 8::Minibatch 808::LR 0.0838461538462 --> Loss 0.00292997697989\n",
      "Epoch 8::Minibatch 809::LR 0.0838461538462 --> Loss 0.00450008392334\n",
      "Epoch 8::Minibatch 810::LR 0.0838461538462 --> Loss 0.00564906915029\n",
      "Epoch 8::Minibatch 811::LR 0.0838461538462 --> Loss 0.00528589765231\n",
      "Epoch 8::Minibatch 812::LR 0.0838461538462 --> Loss 0.00496627926826\n",
      "Epoch 8::Minibatch 813::LR 0.0838461538462 --> Loss 0.00442693869273\n",
      "Epoch 8::Minibatch 814::LR 0.0838461538462 --> Loss 0.00221958955129\n",
      "Epoch 8::Minibatch 815::LR 0.0838461538462 --> Loss 0.00421835343043\n",
      "Epoch 8::Minibatch 816::LR 0.0838461538462 --> Loss 0.00434985280037\n",
      "Epoch 8::Minibatch 817::LR 0.0838461538462 --> Loss 0.00525974114736\n",
      "Epoch 8::Minibatch 818::LR 0.0838461538462 --> Loss 0.00135845383008\n",
      "Epoch 8::Minibatch 819::LR 0.0838461538462 --> Loss 0.000741507510344\n",
      "Epoch 8::Minibatch 820::LR 0.0838461538462 --> Loss 0.00552146156629\n",
      "Epoch 8::Minibatch 821::LR 0.0838461538462 --> Loss 0.00330598254999\n",
      "Epoch 8::Minibatch 822::LR 0.0838461538462 --> Loss 0.00392893791199\n",
      "Epoch 8::Minibatch 823::LR 0.0838461538462 --> Loss 0.00138413250446\n",
      "Epoch 8::Minibatch 824::LR 0.0838461538462 --> Loss 0.00148234238227\n",
      "Epoch 8::Minibatch 825::LR 0.0838461538462 --> Loss 0.00383170604706\n",
      "Epoch 8::Minibatch 826::LR 0.0838461538462 --> Loss 0.00384453177452\n",
      "Epoch 8::Minibatch 827::LR 0.0838461538462 --> Loss 0.0022392988205\n",
      "Epoch 8::Minibatch 828::LR 0.0838461538462 --> Loss 0.000682180076838\n",
      "Epoch 8::Minibatch 829::LR 0.0838461538462 --> Loss 0.0024835807085\n",
      "Epoch 8::Minibatch 830::LR 0.0838461538462 --> Loss 0.00459579984347\n",
      "Epoch 8::Minibatch 831::LR 0.0838461538462 --> Loss 0.00264492988586\n",
      "Epoch 8::Minibatch 832::LR 0.0838461538462 --> Loss 0.00234643260638\n",
      "Epoch 8::Minibatch 833::LR 0.0838461538462 --> Loss 0.00190340479215\n",
      "Epoch 8::Minibatch 834::LR 0.0838461538462 --> Loss 0.00082792793711\n",
      "Epoch 8::Minibatch 835::LR 0.0838461538462 --> Loss 0.00390241146088\n",
      "Epoch 8::Minibatch 836::LR 0.0838461538462 --> Loss 0.00382808407148\n",
      "Epoch 8::Minibatch 837::LR 0.0838461538462 --> Loss 0.00232242484887\n",
      "Epoch 8::Minibatch 838::LR 0.0838461538462 --> Loss 0.000692849854628\n",
      "Epoch 8::Minibatch 839::LR 0.0838461538462 --> Loss 0.00250714838505\n",
      "Epoch 8::Minibatch 840::LR 0.0838461538462 --> Loss 0.00301513969898\n",
      "Epoch 8::Minibatch 841::LR 0.0838461538462 --> Loss 0.0030075498422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 842::LR 0.0838461538462 --> Loss 0.00221752266089\n",
      "Epoch 8::Minibatch 843::LR 0.0838461538462 --> Loss 0.00106349557638\n",
      "Epoch 8::Minibatch 844::LR 0.0838461538462 --> Loss 0.00157548536857\n",
      "Epoch 8::Minibatch 845::LR 0.0838461538462 --> Loss 0.00447884202003\n",
      "Epoch 8::Minibatch 846::LR 0.0838461538462 --> Loss 0.00173997481664\n",
      "Epoch 8::Minibatch 847::LR 0.0838461538462 --> Loss 0.00239608128866\n",
      "Epoch 8::Minibatch 848::LR 0.0838461538462 --> Loss 0.00104227821032\n",
      "Epoch 8::Minibatch 849::LR 0.0838461538462 --> Loss 0.00193269371986\n",
      "Epoch 8::Minibatch 850::LR 0.0838461538462 --> Loss 0.00325505991777\n",
      "Epoch 8::Minibatch 851::LR 0.0838461538462 --> Loss 0.00284474333127\n",
      "Epoch 8::Minibatch 852::LR 0.0838461538462 --> Loss 0.00110742727915\n",
      "Epoch 8::Minibatch 853::LR 0.0838461538462 --> Loss 0.0013608165582\n",
      "Epoch 8::Minibatch 854::LR 0.0838461538462 --> Loss 0.0025941524903\n",
      "Epoch 8::Minibatch 855::LR 0.0838461538462 --> Loss 0.00223223765691\n",
      "Epoch 8::Minibatch 856::LR 0.0838461538462 --> Loss 0.00182915290197\n",
      "Epoch 8::Minibatch 857::LR 0.0838461538462 --> Loss 0.00125466952721\n",
      "Epoch 8::Minibatch 858::LR 0.0838461538462 --> Loss 0.000642854273319\n",
      "Epoch 8::Minibatch 859::LR 0.0838461538462 --> Loss 0.00190846721331\n",
      "Epoch 8::Minibatch 860::LR 0.0838461538462 --> Loss 0.00124171505372\n",
      "Epoch 8::Minibatch 861::LR 0.0838461538462 --> Loss 0.000965942243735\n",
      "Epoch 8::Minibatch 862::LR 0.0838461538462 --> Loss 0.00367963552475\n",
      "Epoch 8::Minibatch 863::LR 0.0838461538462 --> Loss 0.00343756834666\n",
      "Epoch 8::Minibatch 864::LR 0.0838461538462 --> Loss 0.00306830902894\n",
      "Epoch 8::Minibatch 865::LR 0.0838461538462 --> Loss 0.000458114097516\n",
      "Epoch 8::Minibatch 866::LR 0.0838461538462 --> Loss 0.0022331259648\n",
      "Epoch 8::Minibatch 867::LR 0.0838461538462 --> Loss 0.00304545899232\n",
      "Epoch 8::Minibatch 868::LR 0.0838461538462 --> Loss 0.00255003412565\n",
      "Epoch 8::Minibatch 869::LR 0.0838461538462 --> Loss 0.00211572945118\n",
      "Epoch 8::Minibatch 870::LR 0.0838461538462 --> Loss 0.00373553196589\n",
      "Epoch 8::Minibatch 871::LR 0.0838461538462 --> Loss 0.00153986692429\n",
      "Epoch 8::Minibatch 872::LR 0.0838461538462 --> Loss 0.00237040917079\n",
      "Epoch 8::Minibatch 873::LR 0.0838461538462 --> Loss 0.00251980861028\n",
      "Epoch 8::Minibatch 874::LR 0.0838461538462 --> Loss 0.00645919442177\n",
      "Epoch 8::Minibatch 875::LR 0.0838461538462 --> Loss 0.000526667634646\n",
      "Epoch 8::Minibatch 876::LR 0.0838461538462 --> Loss 0.00376313765844\n",
      "Epoch 8::Minibatch 877::LR 0.0838461538462 --> Loss 0.008983827432\n",
      "Epoch 8::Minibatch 878::LR 0.0838461538462 --> Loss 0.00345396995544\n",
      "Epoch 8::Minibatch 879::LR 0.0838461538462 --> Loss 0.00424358963966\n",
      "Epoch 8::Minibatch 880::LR 0.0838461538462 --> Loss 0.00504657387733\n",
      "Epoch 8::Minibatch 881::LR 0.0838461538462 --> Loss 0.00436379353205\n",
      "Epoch 8::Minibatch 882::LR 0.0838461538462 --> Loss 0.00208270986875\n",
      "Epoch 8::Minibatch 883::LR 0.0838461538462 --> Loss 0.00340371608734\n",
      "Epoch 8::Minibatch 884::LR 0.0838461538462 --> Loss 0.00274022718271\n",
      "Epoch 8::Minibatch 885::LR 0.0838461538462 --> Loss 0.0026339673996\n",
      "Epoch 8::Minibatch 886::LR 0.0838461538462 --> Loss 0.00093450576067\n",
      "Epoch 8::Minibatch 887::LR 0.0838461538462 --> Loss 0.00568826198578\n",
      "Epoch 8::Minibatch 888::LR 0.0838461538462 --> Loss 0.00275099674861\n",
      "Epoch 8::Minibatch 889::LR 0.0838461538462 --> Loss 0.00359726230303\n",
      "Epoch 8::Minibatch 890::LR 0.0838461538462 --> Loss 0.00501696785291\n",
      "Epoch 8::Minibatch 891::LR 0.0838461538462 --> Loss 0.00230498373508\n",
      "Epoch 8::Minibatch 892::LR 0.0838461538462 --> Loss 0.00104416062435\n",
      "Epoch 8::Minibatch 893::LR 0.0838461538462 --> Loss 0.00269933879375\n",
      "Epoch 8::Minibatch 894::LR 0.0838461538462 --> Loss 0.00244369745255\n",
      "Epoch 8::Minibatch 895::LR 0.0838461538462 --> Loss 0.00267473737399\n",
      "Epoch 8::Minibatch 896::LR 0.0838461538462 --> Loss 0.00164104094108\n",
      "Epoch 8::Minibatch 897::LR 0.0838461538462 --> Loss 0.000858214894931\n",
      "Epoch 8::Minibatch 898::LR 0.0838461538462 --> Loss 0.00241922477881\n",
      "Epoch 8::Minibatch 899::LR 0.0838461538462 --> Loss 0.00257428089778\n",
      "Epoch 8::Minibatch 900::LR 0.0838461538462 --> Loss 0.00349735935529\n",
      "Epoch 8::Minibatch 901::LR 0.0838461538462 --> Loss 0.000683576862017\n",
      "Epoch 8::Minibatch 902::LR 0.0838461538462 --> Loss 0.00148135652145\n",
      "Epoch 8::Minibatch 903::LR 0.0838461538462 --> Loss 0.00289422869682\n",
      "Epoch 8::Minibatch 904::LR 0.0838461538462 --> Loss 0.00237153112888\n",
      "Epoch 8::Minibatch 905::LR 0.0838461538462 --> Loss 0.00150616586208\n",
      "Epoch 8::Minibatch 906::LR 0.0838461538462 --> Loss 0.00116188794374\n",
      "Epoch 8::Minibatch 907::LR 0.0838461538462 --> Loss 0.0016174997886\n",
      "Epoch 8::Minibatch 908::LR 0.0838461538462 --> Loss 0.00263223191102\n",
      "Epoch 8::Minibatch 909::LR 0.0838461538462 --> Loss 0.00239922245344\n",
      "Epoch 8::Minibatch 910::LR 0.0838461538462 --> Loss 0.000883831481139\n",
      "Epoch 8::Minibatch 911::LR 0.0838461538462 --> Loss 0.00127260833979\n",
      "Epoch 8::Minibatch 912::LR 0.0838461538462 --> Loss 0.00231442431609\n",
      "Epoch 8::Minibatch 913::LR 0.0838461538462 --> Loss 0.00228784739971\n",
      "Epoch 8::Minibatch 914::LR 0.0838461538462 --> Loss 0.00138542711735\n",
      "Epoch 8::Minibatch 915::LR 0.0838461538462 --> Loss 0.000531290819248\n",
      "Epoch 8::Minibatch 916::LR 0.0838461538462 --> Loss 0.00284741560618\n",
      "Epoch 8::Minibatch 917::LR 0.0838461538462 --> Loss 0.00434908986092\n",
      "Epoch 8::Minibatch 918::LR 0.0838461538462 --> Loss 0.00617352048556\n",
      "Epoch 8::Minibatch 919::LR 0.0838461538462 --> Loss 0.000976745684942\n",
      "Epoch 8::Minibatch 920::LR 0.0838461538462 --> Loss 0.0105809775988\n",
      "Epoch 8::Minibatch 921::LR 0.0838461538462 --> Loss 0.00320369899273\n",
      "Epoch 8::Minibatch 922::LR 0.0838461538462 --> Loss 0.00343154509862\n",
      "Epoch 8::Minibatch 923::LR 0.0838461538462 --> Loss 0.00187714874744\n",
      "Epoch 8::Minibatch 924::LR 0.0838461538462 --> Loss 0.00382699131966\n",
      "Epoch 8::Minibatch 925::LR 0.0838461538462 --> Loss 0.00308033307393\n",
      "Epoch 8::Minibatch 926::LR 0.0838461538462 --> Loss 0.00569590012232\n",
      "Epoch 8::Minibatch 927::LR 0.0838461538462 --> Loss 0.00925202687581\n",
      "Epoch 8::Minibatch 928::LR 0.0838461538462 --> Loss 0.00713155110677\n",
      "Epoch 8::Minibatch 929::LR 0.0838461538462 --> Loss 0.00903239568075\n",
      "Epoch 8::Minibatch 930::LR 0.0838461538462 --> Loss 0.00720651944478\n",
      "Epoch 8::Minibatch 931::LR 0.0838461538462 --> Loss 0.00402993122737\n",
      "Epoch 8::Minibatch 932::LR 0.0838461538462 --> Loss 0.00888698021571\n",
      "Epoch 8::Minibatch 933::LR 0.0838461538462 --> Loss 0.00445930997531\n",
      "Epoch 8::Minibatch 934::LR 0.0838461538462 --> Loss 0.0058446208636\n",
      "Epoch 8::Minibatch 935::LR 0.0838461538462 --> Loss 0.00769162654877\n",
      "Epoch 8::Minibatch 936::LR 0.0838461538462 --> Loss 0.00199517945449\n",
      "Epoch 8::Minibatch 937::LR 0.0838461538462 --> Loss 0.00414988875389\n",
      "Epoch 8::Minibatch 938::LR 0.0838461538462 --> Loss 0.00399493217468\n",
      "Epoch 8::Minibatch 939::LR 0.0838461538462 --> Loss 0.00401571591695\n",
      "Epoch 8::Minibatch 940::LR 0.0838461538462 --> Loss 0.00120391130447\n",
      "Epoch 8::Minibatch 941::LR 0.0838461538462 --> Loss 0.000999314586322\n",
      "Epoch 8::Minibatch 942::LR 0.0838461538462 --> Loss 0.00251302282015\n",
      "Epoch 8::Minibatch 943::LR 0.0838461538462 --> Loss 0.00345054666201\n",
      "Epoch 8::Minibatch 944::LR 0.0838461538462 --> Loss 0.00255000730356\n",
      "Epoch 8::Minibatch 945::LR 0.0838461538462 --> Loss 0.00154338945945\n",
      "Epoch 8::Minibatch 946::LR 0.0838461538462 --> Loss 0.00378214637438\n",
      "Epoch 8::Minibatch 947::LR 0.0838461538462 --> Loss 0.00328082084656\n",
      "Epoch 8::Minibatch 948::LR 0.0838461538462 --> Loss 0.00574461142222\n",
      "Epoch 8::Minibatch 949::LR 0.0838461538462 --> Loss 0.00208707849185\n",
      "Epoch 8::Minibatch 950::LR 0.0838461538462 --> Loss 0.000773212959369\n",
      "Epoch 8::Minibatch 951::LR 0.0838461538462 --> Loss 0.00347458044688\n",
      "Epoch 8::Minibatch 952::LR 0.0838461538462 --> Loss 0.00256166617076\n",
      "Epoch 8::Minibatch 953::LR 0.0838461538462 --> Loss 0.00139485448599\n",
      "Epoch 8::Minibatch 954::LR 0.0838461538462 --> Loss 0.00099360148112\n",
      "Epoch 8::Minibatch 955::LR 0.0838461538462 --> Loss 0.00262371242046\n",
      "Epoch 8::Minibatch 956::LR 0.0838461538462 --> Loss 0.00434220949809\n",
      "Epoch 8::Minibatch 957::LR 0.0838461538462 --> Loss 0.0019908674558\n",
      "Epoch 8::Minibatch 958::LR 0.0838461538462 --> Loss 0.00265185594559\n",
      "Epoch 8::Minibatch 959::LR 0.0838461538462 --> Loss 0.0032645380497\n",
      "Epoch 8::Minibatch 960::LR 0.0838461538462 --> Loss 0.0071094640096\n",
      "Epoch 8::Minibatch 961::LR 0.0838461538462 --> Loss 0.00355285088221\n",
      "Epoch 8::Minibatch 962::LR 0.0838461538462 --> Loss 0.0032226528724\n",
      "Epoch 8::Minibatch 963::LR 0.0838461538462 --> Loss 0.00120313078165\n",
      "Epoch 8::Minibatch 964::LR 0.0838461538462 --> Loss 0.00258937180042\n",
      "Epoch 8::Minibatch 965::LR 0.0838461538462 --> Loss 0.00886846144994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8::Minibatch 966::LR 0.0838461538462 --> Loss 0.00611750324567\n",
      "Epoch 8::Minibatch 967::LR 0.0838461538462 --> Loss 0.00211636066437\n",
      "Epoch 8::Minibatch 968::LR 0.0838461538462 --> Loss 0.00197585403919\n",
      "Epoch 8::Minibatch 969::LR 0.0838461538462 --> Loss 0.0078404434522\n",
      "Epoch 8::Minibatch 970::LR 0.0838461538462 --> Loss 0.00636107722918\n",
      "Epoch 8::Minibatch 971::LR 0.0838461538462 --> Loss 0.00376483360926\n",
      "Epoch 8::Minibatch 972::LR 0.0838461538462 --> Loss 0.00913007338842\n",
      "Epoch 8::Minibatch 973::LR 0.0838461538462 --> Loss 0.00944303115209\n",
      "Epoch 8::Minibatch 974::LR 0.0838461538462 --> Loss 0.00625919779142\n",
      "Epoch 8::Minibatch 975::LR 0.0838461538462 --> Loss 0.00491739789645\n",
      "Epoch 8::Minibatch 976::LR 0.0838461538462 --> Loss 0.00440480192502\n",
      "Epoch 8::Minibatch 977::LR 0.0838461538462 --> Loss 0.00443026145299\n",
      "Epoch 8::Minibatch 978::LR 0.0838461538462 --> Loss 0.0043043923378\n",
      "Epoch 8::Minibatch 979::LR 0.0838461538462 --> Loss 0.00427622834841\n",
      "Epoch 8::Minibatch 980::LR 0.0838461538462 --> Loss 0.00411498745282\n",
      "Epoch 8::Minibatch 981::LR 0.0838461538462 --> Loss 0.00537040551503\n",
      "Epoch 8::Minibatch 982::LR 0.0838461538462 --> Loss 0.00729202508926\n",
      "Epoch 8::Minibatch 983::LR 0.0838461538462 --> Loss 0.00329410910606\n",
      "Epoch 8::Minibatch 984::LR 0.0838461538462 --> Loss 0.00323844015598\n",
      "Epoch 8::Minibatch 985::LR 0.0838461538462 --> Loss 0.00465821743011\n",
      "Epoch 8::Minibatch 986::LR 0.0838461538462 --> Loss 0.00420335332553\n",
      "Epoch 8::Minibatch 987::LR 0.0838461538462 --> Loss 0.00460534373919\n",
      "Epoch 8::Minibatch 988::LR 0.0838461538462 --> Loss 0.00345163941383\n",
      "Epoch 8::Minibatch 989::LR 0.0838461538462 --> Loss 0.00342613379161\n",
      "Epoch 8::Minibatch 990::LR 0.0838461538462 --> Loss 0.00338473916054\n",
      "Epoch 8::Minibatch 991::LR 0.0838461538462 --> Loss 0.00173888444901\n",
      "Epoch 8::Minibatch 992::LR 0.0838461538462 --> Loss 0.00200442115466\n",
      "Epoch 8::Minibatch 993::LR 0.0838461538462 --> Loss 0.00345035076141\n",
      "Epoch 8::Minibatch 994::LR 0.0838461538462 --> Loss 0.00205119053523\n",
      "Epoch 8::Minibatch 995::LR 0.0838461538462 --> Loss 0.000899152557055\n",
      "Epoch 8::Minibatch 996::LR 0.0838461538462 --> Loss 0.00334785342216\n",
      "Epoch 8::Minibatch 997::LR 0.0838461538462 --> Loss 0.00219605306784\n",
      "Epoch 8::Minibatch 998::LR 0.0838461538462 --> Loss 0.00222283681234\n",
      "Epoch 8::Minibatch 999::LR 0.0838461538462 --> Loss 0.00181281646093\n",
      "Epoch 8::Minibatch 1000::LR 0.0838461538462 --> Loss 0.0021446488301\n",
      "Epoch 8::Minibatch 1001::LR 0.0838461538462 --> Loss 0.00177073319753\n",
      "Epoch 8::Minibatch 1002::LR 0.0838461538462 --> Loss 0.00344453255335\n",
      "Epoch 8::Minibatch 1003::LR 0.0838461538462 --> Loss 0.00406801939011\n",
      "Epoch 8::Minibatch 1004::LR 0.0838461538462 --> Loss 0.00102239857117\n",
      "Epoch 8::Minibatch 1005::LR 0.0838461538462 --> Loss 0.00460683743159\n",
      "Epoch 8::Minibatch 1006::LR 0.0838461538462 --> Loss 0.00317675709724\n",
      "Epoch 8::Minibatch 1007::LR 0.0838461538462 --> Loss 0.00330994466941\n",
      "Epoch 8::Minibatch 1008::LR 0.0838461538462 --> Loss 0.000980240007242\n",
      "Epoch 8::Minibatch 1009::LR 0.0838461538462 --> Loss 0.00217285811901\n",
      "Epoch 8::Minibatch 1010::LR 0.0838461538462 --> Loss 0.00188086589177\n",
      "Epoch 8::Minibatch 1011::LR 0.0838461538462 --> Loss 0.004945555528\n",
      "Epoch 8::Minibatch 1012::LR 0.0838461538462 --> Loss 0.00237541119258\n",
      "Epoch 8::Minibatch 1013::LR 0.0838461538462 --> Loss 0.00497810761134\n",
      "Epoch 8::Minibatch 1014::LR 0.0838461538462 --> Loss 0.00476919452349\n",
      "Epoch 8::Minibatch 1015::LR 0.0838461538462 --> Loss 0.00184617002805\n",
      "Epoch 8::Minibatch 1016::LR 0.0838461538462 --> Loss 0.00550455649694\n",
      "Epoch 8::Minibatch 1017::LR 0.0838461538462 --> Loss 0.00364047686259\n",
      "Epoch 8::Minibatch 1018::LR 0.0838461538462 --> Loss 0.00344752391179\n",
      "Epoch 8::Minibatch 1019::LR 0.0838461538462 --> Loss 0.00266221046448\n",
      "Epoch 8::Minibatch 1020::LR 0.0838461538462 --> Loss 0.00260023971399\n",
      "Epoch 8::Minibatch 1021::LR 0.0838461538462 --> Loss 0.00246334910393\n",
      "Epoch 8::Minibatch 1022::LR 0.0838461538462 --> Loss 0.00194058557351\n",
      "Epoch 8::Minibatch 1023::LR 0.0838461538462 --> Loss 0.00161407043537\n",
      "Epoch 8::Minibatch 1024::LR 0.0838461538462 --> Loss 0.00154272476832\n",
      "Epoch 8::Minibatch 1025::LR 0.0838461538462 --> Loss 0.00163497050603\n",
      "Epoch 8::Minibatch 1026::LR 0.0838461538462 --> Loss 0.00109730482101\n",
      "Epoch 8::Minibatch 1027::LR 0.0838461538462 --> Loss 0.00120512793461\n",
      "Epoch 8::Minibatch 1028::LR 0.0838461538462 --> Loss 0.000954989691575\n",
      "Epoch 8::Minibatch 1029::LR 0.0838461538462 --> Loss 0.000890814363956\n",
      "Epoch 8::Minibatch 1030::LR 0.0838461538462 --> Loss 0.00109321445227\n",
      "Epoch 8::Minibatch 1031::LR 0.0838461538462 --> Loss 0.000865211486816\n",
      "Epoch 8::Minibatch 1032::LR 0.0838461538462 --> Loss 0.000846698979537\n",
      "Epoch 8::Minibatch 1033::LR 0.0838461538462 --> Loss 0.00070686340332\n",
      "Epoch 8::Minibatch 1034::LR 0.0838461538462 --> Loss 0.000733238309622\n",
      "Epoch 8::Minibatch 1035::LR 0.0838461538462 --> Loss 0.000590200275183\n",
      "Epoch 8::Minibatch 1036::LR 0.0838461538462 --> Loss 0.000471937259038\n",
      "Epoch 8::Minibatch 1037::LR 0.0838461538462 --> Loss 0.000606133540471\n",
      "Epoch 8::Minibatch 1038::LR 0.0838461538462 --> Loss 0.0013688865304\n",
      "Epoch 8::Minibatch 1039::LR 0.0838461538462 --> Loss 0.00117047836383\n",
      "Epoch 8::Minibatch 1040::LR 0.0838461538462 --> Loss 0.000544450879097\n",
      "Epoch 8::Minibatch 1041::LR 0.0838461538462 --> Loss 0.000674152771632\n",
      "Epoch 9::Minibatch 1::LR 0.0815384615385 --> Loss 0.0103766147296\n",
      "Epoch 9::Minibatch 2::LR 0.0815384615385 --> Loss 0.00623467087746\n",
      "Epoch 9::Minibatch 3::LR 0.0815384615385 --> Loss 0.00417008479436\n",
      "Epoch 9::Minibatch 4::LR 0.0815384615385 --> Loss 0.00422590692838\n",
      "Epoch 9::Minibatch 5::LR 0.0815384615385 --> Loss 0.00461281855901\n",
      "Epoch 9::Minibatch 6::LR 0.0815384615385 --> Loss 0.00248280247053\n",
      "Epoch 9::Minibatch 7::LR 0.0815384615385 --> Loss 0.00731346209844\n",
      "Epoch 9::Minibatch 8::LR 0.0815384615385 --> Loss 0.00728591362635\n",
      "Epoch 9::Minibatch 9::LR 0.0815384615385 --> Loss 0.0051847910881\n",
      "Epoch 9::Minibatch 10::LR 0.0815384615385 --> Loss 0.00299742201964\n",
      "Epoch 9::Minibatch 11::LR 0.0815384615385 --> Loss 0.00241728007793\n",
      "Epoch 9::Minibatch 12::LR 0.0815384615385 --> Loss 0.00327409585317\n",
      "Epoch 9::Minibatch 13::LR 0.0815384615385 --> Loss 0.00486752549807\n",
      "Epoch 9::Minibatch 14::LR 0.0815384615385 --> Loss 0.00461419502894\n",
      "Epoch 9::Minibatch 15::LR 0.0815384615385 --> Loss 0.00349107464155\n",
      "Epoch 9::Minibatch 16::LR 0.0815384615385 --> Loss 0.00084496875604\n",
      "Epoch 9::Minibatch 17::LR 0.0815384615385 --> Loss 0.00275941828887\n",
      "Epoch 9::Minibatch 18::LR 0.0815384615385 --> Loss 0.00235078036785\n",
      "Epoch 9::Minibatch 19::LR 0.0815384615385 --> Loss 0.000988358855247\n",
      "Epoch 9::Minibatch 20::LR 0.0815384615385 --> Loss 0.0014649772644\n",
      "Epoch 9::Minibatch 21::LR 0.0815384615385 --> Loss 0.00321318805218\n",
      "Epoch 9::Minibatch 22::LR 0.0815384615385 --> Loss 0.00241995513439\n",
      "Epoch 9::Minibatch 23::LR 0.0815384615385 --> Loss 0.000794316281875\n",
      "Epoch 9::Minibatch 24::LR 0.0815384615385 --> Loss 0.000374351665378\n",
      "Epoch 9::Minibatch 25::LR 0.0815384615385 --> Loss 0.00110063662132\n",
      "Epoch 9::Minibatch 26::LR 0.0815384615385 --> Loss 0.00130195885897\n",
      "Epoch 9::Minibatch 27::LR 0.0815384615385 --> Loss 0.000918675859769\n",
      "Epoch 9::Minibatch 28::LR 0.0815384615385 --> Loss 0.000367080767949\n",
      "Epoch 9::Minibatch 29::LR 0.0815384615385 --> Loss 0.000350337053339\n",
      "Epoch 9::Minibatch 30::LR 0.0815384615385 --> Loss 0.000830135146777\n",
      "Epoch 9::Minibatch 31::LR 0.0815384615385 --> Loss 0.00128598093987\n",
      "Epoch 9::Minibatch 32::LR 0.0815384615385 --> Loss 0.00124630361795\n",
      "Epoch 9::Minibatch 33::LR 0.0815384615385 --> Loss 0.000786966482798\n",
      "Epoch 9::Minibatch 34::LR 0.0815384615385 --> Loss 0.00259683211644\n",
      "Epoch 9::Minibatch 35::LR 0.0815384615385 --> Loss 0.00438694318136\n",
      "Epoch 9::Minibatch 36::LR 0.0815384615385 --> Loss 0.00214553713799\n",
      "Epoch 9::Minibatch 37::LR 0.0815384615385 --> Loss 0.00060820783178\n",
      "Epoch 9::Minibatch 38::LR 0.0815384615385 --> Loss 0.000827010770639\n",
      "Epoch 9::Minibatch 39::LR 0.0815384615385 --> Loss 0.00248845140139\n",
      "Epoch 9::Minibatch 40::LR 0.0815384615385 --> Loss 0.00396373589834\n",
      "Epoch 9::Minibatch 41::LR 0.0815384615385 --> Loss 0.00342326482137\n",
      "Epoch 9::Minibatch 42::LR 0.0815384615385 --> Loss 0.00631993214289\n",
      "Epoch 9::Minibatch 43::LR 0.0815384615385 --> Loss 0.00186558703581\n",
      "Epoch 9::Minibatch 44::LR 0.0815384615385 --> Loss 0.00311471045017\n",
      "Epoch 9::Minibatch 45::LR 0.0815384615385 --> Loss 0.00263838668664\n",
      "Epoch 9::Minibatch 46::LR 0.0815384615385 --> Loss 0.00374941070875\n",
      "Epoch 9::Minibatch 47::LR 0.0815384615385 --> Loss 0.00537927786509\n",
      "Epoch 9::Minibatch 48::LR 0.0815384615385 --> Loss 0.00630100766818\n",
      "Epoch 9::Minibatch 49::LR 0.0815384615385 --> Loss 0.00615288813909\n",
      "Epoch 9::Minibatch 50::LR 0.0815384615385 --> Loss 0.00581184744835\n",
      "Epoch 9::Minibatch 51::LR 0.0815384615385 --> Loss 0.00949096043905\n",
      "Epoch 9::Minibatch 52::LR 0.0815384615385 --> Loss 0.00366974830627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 53::LR 0.0815384615385 --> Loss 0.00358699520429\n",
      "Epoch 9::Minibatch 54::LR 0.0815384615385 --> Loss 0.00404547532399\n",
      "Epoch 9::Minibatch 55::LR 0.0815384615385 --> Loss 0.00112771262725\n",
      "Epoch 9::Minibatch 56::LR 0.0815384615385 --> Loss 0.00293190320333\n",
      "Epoch 9::Minibatch 57::LR 0.0815384615385 --> Loss 0.00648374358813\n",
      "Epoch 9::Minibatch 58::LR 0.0815384615385 --> Loss 0.00355047861735\n",
      "Epoch 9::Minibatch 59::LR 0.0815384615385 --> Loss 0.00304296731949\n",
      "Epoch 9::Minibatch 60::LR 0.0815384615385 --> Loss 0.00253290494283\n",
      "Epoch 9::Minibatch 61::LR 0.0815384615385 --> Loss 0.00112248410781\n",
      "Epoch 9::Minibatch 62::LR 0.0815384615385 --> Loss 0.00375008622805\n",
      "Epoch 9::Minibatch 63::LR 0.0815384615385 --> Loss 0.00239911198616\n",
      "Epoch 9::Minibatch 64::LR 0.0815384615385 --> Loss 0.0010942218701\n",
      "Epoch 9::Minibatch 65::LR 0.0815384615385 --> Loss 0.0025173830986\n",
      "Epoch 9::Minibatch 66::LR 0.0815384615385 --> Loss 0.00317669729392\n",
      "Epoch 9::Minibatch 67::LR 0.0815384615385 --> Loss 0.00297643522422\n",
      "Epoch 9::Minibatch 68::LR 0.0815384615385 --> Loss 0.0021191217502\n",
      "Epoch 9::Minibatch 69::LR 0.0815384615385 --> Loss 0.00409033179283\n",
      "Epoch 9::Minibatch 70::LR 0.0815384615385 --> Loss 0.00354464928309\n",
      "Epoch 9::Minibatch 71::LR 0.0815384615385 --> Loss 0.00243971864382\n",
      "Epoch 9::Minibatch 72::LR 0.0815384615385 --> Loss 0.000592614561319\n",
      "Epoch 9::Minibatch 73::LR 0.0815384615385 --> Loss 0.0040119934082\n",
      "Epoch 9::Minibatch 74::LR 0.0815384615385 --> Loss 0.00424693544706\n",
      "Epoch 9::Minibatch 75::LR 0.0815384615385 --> Loss 0.00286520838737\n",
      "Epoch 9::Minibatch 76::LR 0.0815384615385 --> Loss 0.000748365521431\n",
      "Epoch 9::Minibatch 77::LR 0.0815384615385 --> Loss 0.00425922473272\n",
      "Epoch 9::Minibatch 78::LR 0.0815384615385 --> Loss 0.00399708588918\n",
      "Epoch 9::Minibatch 79::LR 0.0815384615385 --> Loss 0.00226780712605\n",
      "Epoch 9::Minibatch 80::LR 0.0815384615385 --> Loss 0.00362283706665\n",
      "Epoch 9::Minibatch 81::LR 0.0815384615385 --> Loss 0.00317158619563\n",
      "Epoch 9::Minibatch 82::LR 0.0815384615385 --> Loss 0.00213013847669\n",
      "Epoch 9::Minibatch 83::LR 0.0815384615385 --> Loss 0.00532544096311\n",
      "Epoch 9::Minibatch 84::LR 0.0815384615385 --> Loss 0.00220202763875\n",
      "Epoch 9::Minibatch 85::LR 0.0815384615385 --> Loss 0.00298578381538\n",
      "Epoch 9::Minibatch 86::LR 0.0815384615385 --> Loss 0.00245162546635\n",
      "Epoch 9::Minibatch 87::LR 0.0815384615385 --> Loss 0.00272348225117\n",
      "Epoch 9::Minibatch 88::LR 0.0815384615385 --> Loss 0.00201931655407\n",
      "Epoch 9::Minibatch 89::LR 0.0815384615385 --> Loss 0.00249392588933\n",
      "Epoch 9::Minibatch 90::LR 0.0815384615385 --> Loss 0.00136363436778\n",
      "Epoch 9::Minibatch 91::LR 0.0815384615385 --> Loss 0.00113492071629\n",
      "Epoch 9::Minibatch 92::LR 0.0815384615385 --> Loss 0.00276605745157\n",
      "Epoch 9::Minibatch 93::LR 0.0815384615385 --> Loss 0.00192441503207\n",
      "Epoch 9::Minibatch 94::LR 0.0815384615385 --> Loss 0.00188200374444\n",
      "Epoch 9::Minibatch 95::LR 0.0815384615385 --> Loss 0.00176055649916\n",
      "Epoch 9::Minibatch 96::LR 0.0815384615385 --> Loss 0.00635606884956\n",
      "Epoch 9::Minibatch 97::LR 0.0815384615385 --> Loss 0.0032784763972\n",
      "Epoch 9::Minibatch 98::LR 0.0815384615385 --> Loss 0.000977238516013\n",
      "Epoch 9::Minibatch 99::LR 0.0815384615385 --> Loss 0.00130883008242\n",
      "Epoch 9::Minibatch 100::LR 0.0815384615385 --> Loss 0.00572718540827\n",
      "Epoch 9::Minibatch 101::LR 0.0815384615385 --> Loss 0.00104391813278\n",
      "Epoch 9::Minibatch 102::LR 0.0815384615385 --> Loss 0.00382798194885\n",
      "Epoch 9::Minibatch 103::LR 0.0815384615385 --> Loss 0.00404451012611\n",
      "Epoch 9::Minibatch 104::LR 0.0815384615385 --> Loss 0.00291988968849\n",
      "Epoch 9::Minibatch 105::LR 0.0815384615385 --> Loss 0.0034670762221\n",
      "Epoch 9::Minibatch 106::LR 0.0815384615385 --> Loss 0.0191418854396\n",
      "Epoch 9::Minibatch 107::LR 0.0815384615385 --> Loss 0.00487093567848\n",
      "Epoch 9::Minibatch 108::LR 0.0815384615385 --> Loss 0.00131317675114\n",
      "Epoch 9::Minibatch 109::LR 0.0815384615385 --> Loss 0.00466749548912\n",
      "Epoch 9::Minibatch 110::LR 0.0815384615385 --> Loss 0.00269534528255\n",
      "Epoch 9::Minibatch 111::LR 0.0815384615385 --> Loss 0.00121813019117\n",
      "Epoch 9::Minibatch 112::LR 0.0815384615385 --> Loss 0.00390173236529\n",
      "Epoch 9::Minibatch 113::LR 0.0815384615385 --> Loss 0.00301932791869\n",
      "Epoch 9::Minibatch 114::LR 0.0815384615385 --> Loss 0.00171186029911\n",
      "Epoch 9::Minibatch 115::LR 0.0815384615385 --> Loss 0.00162839760383\n",
      "Epoch 9::Minibatch 116::LR 0.0815384615385 --> Loss 0.00310330212116\n",
      "Epoch 9::Minibatch 117::LR 0.0815384615385 --> Loss 0.00381557027499\n",
      "Epoch 9::Minibatch 118::LR 0.0815384615385 --> Loss 0.0070566089948\n",
      "Epoch 9::Minibatch 119::LR 0.0815384615385 --> Loss 0.000879474977652\n",
      "Epoch 9::Minibatch 120::LR 0.0815384615385 --> Loss 0.00212799052397\n",
      "Epoch 9::Minibatch 121::LR 0.0815384615385 --> Loss 0.00309252818425\n",
      "Epoch 9::Minibatch 122::LR 0.0815384615385 --> Loss 0.00378036419551\n",
      "Epoch 9::Minibatch 123::LR 0.0815384615385 --> Loss 0.00147183150053\n",
      "Epoch 9::Minibatch 124::LR 0.0815384615385 --> Loss 0.00306587576866\n",
      "Epoch 9::Minibatch 125::LR 0.0815384615385 --> Loss 0.00490491072337\n",
      "Epoch 9::Minibatch 126::LR 0.0815384615385 --> Loss 0.00302550156911\n",
      "Epoch 9::Minibatch 127::LR 0.0815384615385 --> Loss 0.00464724063873\n",
      "Epoch 9::Minibatch 128::LR 0.0815384615385 --> Loss 0.00377942879995\n",
      "Epoch 9::Minibatch 129::LR 0.0815384615385 --> Loss 0.00303359647592\n",
      "Epoch 9::Minibatch 130::LR 0.0815384615385 --> Loss 0.0044377998511\n",
      "Epoch 9::Minibatch 131::LR 0.0815384615385 --> Loss 0.00198547641436\n",
      "Epoch 9::Minibatch 132::LR 0.0815384615385 --> Loss 0.00340869665146\n",
      "Epoch 9::Minibatch 133::LR 0.0815384615385 --> Loss 0.00328258653482\n",
      "Epoch 9::Minibatch 134::LR 0.0815384615385 --> Loss 0.00270375510057\n",
      "Epoch 9::Minibatch 135::LR 0.0815384615385 --> Loss 0.00195436398188\n",
      "Epoch 9::Minibatch 136::LR 0.0815384615385 --> Loss 0.0029961146911\n",
      "Epoch 9::Minibatch 137::LR 0.0815384615385 --> Loss 0.00385798931122\n",
      "Epoch 9::Minibatch 138::LR 0.0815384615385 --> Loss 0.00146546681722\n",
      "Epoch 9::Minibatch 139::LR 0.0815384615385 --> Loss 0.00197084724903\n",
      "Epoch 9::Minibatch 140::LR 0.0815384615385 --> Loss 0.00253264288108\n",
      "Epoch 9::Minibatch 141::LR 0.0815384615385 --> Loss 0.00309630453587\n",
      "Epoch 9::Minibatch 142::LR 0.0815384615385 --> Loss 0.00323152939479\n",
      "Epoch 9::Minibatch 143::LR 0.0815384615385 --> Loss 0.000714675585429\n",
      "Epoch 9::Minibatch 144::LR 0.0815384615385 --> Loss 0.00319015602271\n",
      "Epoch 9::Minibatch 145::LR 0.0815384615385 --> Loss 0.00443212827047\n",
      "Epoch 9::Minibatch 146::LR 0.0815384615385 --> Loss 0.00275503873825\n",
      "Epoch 9::Minibatch 147::LR 0.0815384615385 --> Loss 0.00189066429933\n",
      "Epoch 9::Minibatch 148::LR 0.0815384615385 --> Loss 0.00111445317666\n",
      "Epoch 9::Minibatch 149::LR 0.0815384615385 --> Loss 0.0028940141201\n",
      "Epoch 9::Minibatch 150::LR 0.0815384615385 --> Loss 0.00286560714245\n",
      "Epoch 9::Minibatch 151::LR 0.0815384615385 --> Loss 0.00430013974508\n",
      "Epoch 9::Minibatch 152::LR 0.0815384615385 --> Loss 0.000995517770449\n",
      "Epoch 9::Minibatch 153::LR 0.0815384615385 --> Loss 0.0019706505537\n",
      "Epoch 9::Minibatch 154::LR 0.0815384615385 --> Loss 0.00214879333973\n",
      "Epoch 9::Minibatch 155::LR 0.0815384615385 --> Loss 0.00498006979624\n",
      "Epoch 9::Minibatch 156::LR 0.0815384615385 --> Loss 0.00249202430248\n",
      "Epoch 9::Minibatch 157::LR 0.0815384615385 --> Loss 0.00074544330438\n",
      "Epoch 9::Minibatch 158::LR 0.0815384615385 --> Loss 0.00313382446766\n",
      "Epoch 9::Minibatch 159::LR 0.0815384615385 --> Loss 0.00284261902173\n",
      "Epoch 9::Minibatch 160::LR 0.0815384615385 --> Loss 0.00274206439654\n",
      "Epoch 9::Minibatch 161::LR 0.0815384615385 --> Loss 0.0010970283548\n",
      "Epoch 9::Minibatch 162::LR 0.0815384615385 --> Loss 0.00360498309135\n",
      "Epoch 9::Minibatch 163::LR 0.0815384615385 --> Loss 0.00247690856457\n",
      "Epoch 9::Minibatch 164::LR 0.0815384615385 --> Loss 0.00253938039144\n",
      "Epoch 9::Minibatch 165::LR 0.0815384615385 --> Loss 0.000595020353794\n",
      "Epoch 9::Minibatch 166::LR 0.0815384615385 --> Loss 0.00188645064831\n",
      "Epoch 9::Minibatch 167::LR 0.0815384615385 --> Loss 0.00251637279987\n",
      "Epoch 9::Minibatch 168::LR 0.0815384615385 --> Loss 0.00228397349517\n",
      "Epoch 9::Minibatch 169::LR 0.0815384615385 --> Loss 0.00107762426138\n",
      "Epoch 9::Minibatch 170::LR 0.0815384615385 --> Loss 0.00104777803024\n",
      "Epoch 9::Minibatch 171::LR 0.0815384615385 --> Loss 0.00257741332054\n",
      "Epoch 9::Minibatch 172::LR 0.0815384615385 --> Loss 0.00489269137383\n",
      "Epoch 9::Minibatch 173::LR 0.0815384615385 --> Loss 0.0020236380895\n",
      "Epoch 9::Minibatch 174::LR 0.0815384615385 --> Loss 0.00111770361662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 175::LR 0.0815384615385 --> Loss 0.00232054054737\n",
      "Epoch 9::Minibatch 176::LR 0.0815384615385 --> Loss 0.00338641564051\n",
      "Epoch 9::Minibatch 177::LR 0.0815384615385 --> Loss 0.00504302660624\n",
      "Epoch 9::Minibatch 178::LR 0.0815384615385 --> Loss 0.00173979838689\n",
      "Epoch 9::Minibatch 179::LR 0.0815384615385 --> Loss 0.00142937978109\n",
      "Epoch 9::Minibatch 180::LR 0.0815384615385 --> Loss 0.00373500585556\n",
      "Epoch 9::Minibatch 181::LR 0.0815384615385 --> Loss 0.00350094278653\n",
      "Epoch 9::Minibatch 182::LR 0.0815384615385 --> Loss 0.000886571407318\n",
      "Epoch 9::Minibatch 183::LR 0.0815384615385 --> Loss 0.00177332301935\n",
      "Epoch 9::Minibatch 184::LR 0.0815384615385 --> Loss 0.00344499389331\n",
      "Epoch 9::Minibatch 185::LR 0.0815384615385 --> Loss 0.00291175683339\n",
      "Epoch 9::Minibatch 186::LR 0.0815384615385 --> Loss 0.00105561643839\n",
      "Epoch 9::Minibatch 187::LR 0.0815384615385 --> Loss 0.00127419213454\n",
      "Epoch 9::Minibatch 188::LR 0.0815384615385 --> Loss 0.00415966550509\n",
      "Epoch 9::Minibatch 189::LR 0.0815384615385 --> Loss 0.00462108294169\n",
      "Epoch 9::Minibatch 190::LR 0.0815384615385 --> Loss 0.00235792497794\n",
      "Epoch 9::Minibatch 191::LR 0.0815384615385 --> Loss 0.000560789207617\n",
      "Epoch 9::Minibatch 192::LR 0.0815384615385 --> Loss 0.00268798410892\n",
      "Epoch 9::Minibatch 193::LR 0.0815384615385 --> Loss 0.00250153938929\n",
      "Epoch 9::Minibatch 194::LR 0.0815384615385 --> Loss 0.00185748140017\n",
      "Epoch 9::Minibatch 195::LR 0.0815384615385 --> Loss 0.000427016963561\n",
      "Epoch 9::Minibatch 196::LR 0.0815384615385 --> Loss 0.00122288197279\n",
      "Epoch 9::Minibatch 197::LR 0.0815384615385 --> Loss 0.00280474384626\n",
      "Epoch 9::Minibatch 198::LR 0.0815384615385 --> Loss 0.00218743006388\n",
      "Epoch 9::Minibatch 199::LR 0.0815384615385 --> Loss 0.000317889799674\n",
      "Epoch 9::Minibatch 200::LR 0.0815384615385 --> Loss 0.00215142846107\n",
      "Epoch 9::Minibatch 201::LR 0.0815384615385 --> Loss 0.00203617930412\n",
      "Epoch 9::Minibatch 202::LR 0.0815384615385 --> Loss 0.00197868863742\n",
      "Epoch 9::Minibatch 203::LR 0.0815384615385 --> Loss 0.00191004713376\n",
      "Epoch 9::Minibatch 204::LR 0.0815384615385 --> Loss 0.00164920230707\n",
      "Epoch 9::Minibatch 205::LR 0.0815384615385 --> Loss 0.00232473174731\n",
      "Epoch 9::Minibatch 206::LR 0.0815384615385 --> Loss 0.00741334756215\n",
      "Epoch 9::Minibatch 207::LR 0.0815384615385 --> Loss 0.00145776351293\n",
      "Epoch 9::Minibatch 208::LR 0.0815384615385 --> Loss 0.00123782942692\n",
      "Epoch 9::Minibatch 209::LR 0.0815384615385 --> Loss 0.00214097877343\n",
      "Epoch 9::Minibatch 210::LR 0.0815384615385 --> Loss 0.00198018590609\n",
      "Epoch 9::Minibatch 211::LR 0.0815384615385 --> Loss 0.00208692908287\n",
      "Epoch 9::Minibatch 212::LR 0.0815384615385 --> Loss 0.0043380800883\n",
      "Epoch 9::Minibatch 213::LR 0.0815384615385 --> Loss 0.00622736016909\n",
      "Epoch 9::Minibatch 214::LR 0.0815384615385 --> Loss 0.0103381268183\n",
      "Epoch 9::Minibatch 215::LR 0.0815384615385 --> Loss 0.0015073766311\n",
      "Epoch 9::Minibatch 216::LR 0.0815384615385 --> Loss 0.00556658903758\n",
      "Epoch 9::Minibatch 217::LR 0.0815384615385 --> Loss 0.0060243054231\n",
      "Epoch 9::Minibatch 218::LR 0.0815384615385 --> Loss 0.00414327422778\n",
      "Epoch 9::Minibatch 219::LR 0.0815384615385 --> Loss 0.00372833808263\n",
      "Epoch 9::Minibatch 220::LR 0.0815384615385 --> Loss 0.00466914812724\n",
      "Epoch 9::Minibatch 221::LR 0.0815384615385 --> Loss 0.00435450792313\n",
      "Epoch 9::Minibatch 222::LR 0.0815384615385 --> Loss 0.00339998165766\n",
      "Epoch 9::Minibatch 223::LR 0.0815384615385 --> Loss 0.00150521377722\n",
      "Epoch 9::Minibatch 224::LR 0.0815384615385 --> Loss 0.00196842432022\n",
      "Epoch 9::Minibatch 225::LR 0.0815384615385 --> Loss 0.00700310627619\n",
      "Epoch 9::Minibatch 226::LR 0.0815384615385 --> Loss 0.00389424681664\n",
      "Epoch 9::Minibatch 227::LR 0.0815384615385 --> Loss 0.00177639941374\n",
      "Epoch 9::Minibatch 228::LR 0.0815384615385 --> Loss 0.000893609623114\n",
      "Epoch 9::Minibatch 229::LR 0.0815384615385 --> Loss 0.00497364521027\n",
      "Epoch 9::Minibatch 230::LR 0.0815384615385 --> Loss 0.00413404862086\n",
      "Epoch 9::Minibatch 231::LR 0.0815384615385 --> Loss 0.0026893423001\n",
      "Epoch 9::Minibatch 232::LR 0.0815384615385 --> Loss 0.00135913461447\n",
      "Epoch 9::Minibatch 233::LR 0.0815384615385 --> Loss 0.0024529149135\n",
      "Epoch 9::Minibatch 234::LR 0.0815384615385 --> Loss 0.00649427930514\n",
      "Epoch 9::Minibatch 235::LR 0.0815384615385 --> Loss 0.00469334483147\n",
      "Epoch 9::Minibatch 236::LR 0.0815384615385 --> Loss 0.00188800772031\n",
      "Epoch 9::Minibatch 237::LR 0.0815384615385 --> Loss 0.00081250200669\n",
      "Epoch 9::Minibatch 238::LR 0.0815384615385 --> Loss 0.00347726345062\n",
      "Epoch 9::Minibatch 239::LR 0.0815384615385 --> Loss 0.00299071133137\n",
      "Epoch 9::Minibatch 240::LR 0.0815384615385 --> Loss 0.0032592856884\n",
      "Epoch 9::Minibatch 241::LR 0.0815384615385 --> Loss 0.0008632649978\n",
      "Epoch 9::Minibatch 242::LR 0.0815384615385 --> Loss 0.00736410458883\n",
      "Epoch 9::Minibatch 243::LR 0.0815384615385 --> Loss 0.00373084227244\n",
      "Epoch 9::Minibatch 244::LR 0.0815384615385 --> Loss 0.0031283356746\n",
      "Epoch 9::Minibatch 245::LR 0.0815384615385 --> Loss 0.000595828592777\n",
      "Epoch 9::Minibatch 246::LR 0.0815384615385 --> Loss 0.00222919185956\n",
      "Epoch 9::Minibatch 247::LR 0.0815384615385 --> Loss 0.014338649114\n",
      "Epoch 9::Minibatch 248::LR 0.0815384615385 --> Loss 0.00475768963496\n",
      "Epoch 9::Minibatch 249::LR 0.0815384615385 --> Loss 0.00315485219161\n",
      "Epoch 9::Minibatch 250::LR 0.0815384615385 --> Loss 0.00305274804433\n",
      "Epoch 9::Minibatch 251::LR 0.0815384615385 --> Loss 0.00269578377406\n",
      "Epoch 9::Minibatch 252::LR 0.0815384615385 --> Loss 0.00204307397207\n",
      "Epoch 9::Minibatch 253::LR 0.0815384615385 --> Loss 0.00332856118679\n",
      "Epoch 9::Minibatch 254::LR 0.0815384615385 --> Loss 0.0055272090435\n",
      "Epoch 9::Minibatch 255::LR 0.0815384615385 --> Loss 0.0040713540713\n",
      "Epoch 9::Minibatch 256::LR 0.0815384615385 --> Loss 0.00194398283958\n",
      "Epoch 9::Minibatch 257::LR 0.0815384615385 --> Loss 0.00147236585617\n",
      "Epoch 9::Minibatch 258::LR 0.0815384615385 --> Loss 0.00370883107185\n",
      "Epoch 9::Minibatch 259::LR 0.0815384615385 --> Loss 0.00198717614015\n",
      "Epoch 9::Minibatch 260::LR 0.0815384615385 --> Loss 0.00199209610621\n",
      "Epoch 9::Minibatch 261::LR 0.0815384615385 --> Loss 0.00306253214677\n",
      "Epoch 9::Minibatch 262::LR 0.0815384615385 --> Loss 0.00207887669404\n",
      "Epoch 9::Minibatch 263::LR 0.0815384615385 --> Loss 0.00247335712115\n",
      "Epoch 9::Minibatch 264::LR 0.0815384615385 --> Loss 0.00375209371249\n",
      "Epoch 9::Minibatch 265::LR 0.0815384615385 --> Loss 0.0104402065277\n",
      "Epoch 9::Minibatch 266::LR 0.0815384615385 --> Loss 0.00116495003303\n",
      "Epoch 9::Minibatch 267::LR 0.0815384615385 --> Loss 0.0103301533063\n",
      "Epoch 9::Minibatch 268::LR 0.0815384615385 --> Loss 0.001385833323\n",
      "Epoch 9::Minibatch 269::LR 0.0815384615385 --> Loss 0.00370967189471\n",
      "Epoch 9::Minibatch 270::LR 0.0815384615385 --> Loss 0.00636893232663\n",
      "Epoch 9::Minibatch 271::LR 0.0815384615385 --> Loss 0.00299336830775\n",
      "Epoch 9::Minibatch 272::LR 0.0815384615385 --> Loss 0.00410246491432\n",
      "Epoch 9::Minibatch 273::LR 0.0815384615385 --> Loss 0.00190726439158\n",
      "Epoch 9::Minibatch 274::LR 0.0815384615385 --> Loss 0.00190763692061\n",
      "Epoch 9::Minibatch 275::LR 0.0815384615385 --> Loss 0.00285745561123\n",
      "Epoch 9::Minibatch 276::LR 0.0815384615385 --> Loss 0.00357913017273\n",
      "Epoch 9::Minibatch 277::LR 0.0815384615385 --> Loss 0.0011479006211\n",
      "Epoch 9::Minibatch 278::LR 0.0815384615385 --> Loss 0.00273410836856\n",
      "Epoch 9::Minibatch 279::LR 0.0815384615385 --> Loss 0.00260250767072\n",
      "Epoch 9::Minibatch 280::LR 0.0815384615385 --> Loss 0.00226219038169\n",
      "Epoch 9::Minibatch 281::LR 0.0815384615385 --> Loss 0.00144956161578\n",
      "Epoch 9::Minibatch 282::LR 0.0815384615385 --> Loss 0.00233688871066\n",
      "Epoch 9::Minibatch 283::LR 0.0815384615385 --> Loss 0.00230572064718\n",
      "Epoch 9::Minibatch 284::LR 0.0815384615385 --> Loss 0.00184131999811\n",
      "Epoch 9::Minibatch 285::LR 0.0815384615385 --> Loss 0.00129311770201\n",
      "Epoch 9::Minibatch 286::LR 0.0815384615385 --> Loss 0.00221588472525\n",
      "Epoch 9::Minibatch 287::LR 0.0815384615385 --> Loss 0.00213270465533\n",
      "Epoch 9::Minibatch 288::LR 0.0815384615385 --> Loss 0.00116292834282\n",
      "Epoch 9::Minibatch 289::LR 0.0815384615385 --> Loss 0.00158575405677\n",
      "Epoch 9::Minibatch 290::LR 0.0815384615385 --> Loss 0.00198476314545\n",
      "Epoch 9::Minibatch 291::LR 0.0815384615385 --> Loss 0.00177985191345\n",
      "Epoch 9::Minibatch 292::LR 0.0815384615385 --> Loss 0.000652312884728\n",
      "Epoch 9::Minibatch 293::LR 0.0815384615385 --> Loss 0.00148994982243\n",
      "Epoch 9::Minibatch 294::LR 0.0815384615385 --> Loss 0.00157960007588\n",
      "Epoch 9::Minibatch 295::LR 0.0815384615385 --> Loss 0.00184685250123\n",
      "Epoch 9::Minibatch 296::LR 0.0815384615385 --> Loss 0.001595056355\n",
      "Epoch 9::Minibatch 297::LR 0.0815384615385 --> Loss 0.0014023972551\n",
      "Epoch 9::Minibatch 298::LR 0.0815384615385 --> Loss 0.00137715091308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 299::LR 0.0815384615385 --> Loss 0.000829970637957\n",
      "Epoch 9::Minibatch 300::LR 0.0815384615385 --> Loss 0.00295143842697\n",
      "Epoch 9::Minibatch 301::LR 0.0815384615385 --> Loss 0.00283484200637\n",
      "Epoch 9::Minibatch 302::LR 0.0815384615385 --> Loss 0.00264056166013\n",
      "Epoch 9::Minibatch 303::LR 0.0815384615385 --> Loss 0.000917223989964\n",
      "Epoch 9::Minibatch 304::LR 0.0815384615385 --> Loss 0.00319599429766\n",
      "Epoch 9::Minibatch 305::LR 0.0815384615385 --> Loss 0.00171477278074\n",
      "Epoch 9::Minibatch 306::LR 0.0815384615385 --> Loss 0.000961795250575\n",
      "Epoch 9::Minibatch 307::LR 0.0815384615385 --> Loss 0.00251250406106\n",
      "Epoch 9::Minibatch 308::LR 0.0815384615385 --> Loss 0.00198316713174\n",
      "Epoch 9::Minibatch 309::LR 0.0815384615385 --> Loss 0.00100689232349\n",
      "Epoch 9::Minibatch 310::LR 0.0815384615385 --> Loss 0.00108185370763\n",
      "Epoch 9::Minibatch 311::LR 0.0815384615385 --> Loss 0.00165860126416\n",
      "Epoch 9::Minibatch 312::LR 0.0815384615385 --> Loss 0.00308082342148\n",
      "Epoch 9::Minibatch 313::LR 0.0815384615385 --> Loss 0.00241321484248\n",
      "Epoch 9::Minibatch 314::LR 0.0815384615385 --> Loss 0.0019430265824\n",
      "Epoch 9::Minibatch 315::LR 0.0815384615385 --> Loss 0.00100796987613\n",
      "Epoch 9::Minibatch 316::LR 0.0815384615385 --> Loss 0.00234865029653\n",
      "Epoch 9::Minibatch 317::LR 0.0815384615385 --> Loss 0.00158785094817\n",
      "Epoch 9::Minibatch 318::LR 0.0815384615385 --> Loss 0.00121127684911\n",
      "Epoch 9::Minibatch 319::LR 0.0815384615385 --> Loss 0.00231718699137\n",
      "Epoch 9::Minibatch 320::LR 0.0815384615385 --> Loss 0.0033830499649\n",
      "Epoch 9::Minibatch 321::LR 0.0815384615385 --> Loss 0.000938868920008\n",
      "Epoch 9::Minibatch 322::LR 0.0815384615385 --> Loss 0.00369413415591\n",
      "Epoch 9::Minibatch 323::LR 0.0815384615385 --> Loss 0.00362089157104\n",
      "Epoch 9::Minibatch 324::LR 0.0815384615385 --> Loss 0.00266025980314\n",
      "Epoch 9::Minibatch 325::LR 0.0815384615385 --> Loss 0.00247037430604\n",
      "Epoch 9::Minibatch 326::LR 0.0815384615385 --> Loss 0.00555591265361\n",
      "Epoch 9::Minibatch 327::LR 0.0815384615385 --> Loss 0.00232583582401\n",
      "Epoch 9::Minibatch 328::LR 0.0815384615385 --> Loss 0.0035524614652\n",
      "Epoch 9::Minibatch 329::LR 0.0815384615385 --> Loss 0.00130052894354\n",
      "Epoch 9::Minibatch 330::LR 0.0815384615385 --> Loss 0.00167756001155\n",
      "Epoch 9::Minibatch 331::LR 0.0815384615385 --> Loss 0.00261257986228\n",
      "Epoch 9::Minibatch 332::LR 0.0815384615385 --> Loss 0.00257346332073\n",
      "Epoch 9::Minibatch 333::LR 0.0815384615385 --> Loss 0.00152310331662\n",
      "Epoch 9::Minibatch 334::LR 0.0815384615385 --> Loss 0.00426453749339\n",
      "Epoch 9::Minibatch 335::LR 0.0815384615385 --> Loss 0.00195013860861\n",
      "Epoch 9::Minibatch 336::LR 0.0815384615385 --> Loss 0.0020669311285\n",
      "Epoch 9::Minibatch 337::LR 0.0815384615385 --> Loss 0.00330357452234\n",
      "Epoch 9::Minibatch 338::LR 0.0815384615385 --> Loss 0.000541031459967\n",
      "Epoch 9::Minibatch 339::LR 0.0815384615385 --> Loss 0.00332583109538\n",
      "Epoch 9::Minibatch 340::LR 0.0815384615385 --> Loss 0.00485499024391\n",
      "Epoch 9::Minibatch 341::LR 0.0815384615385 --> Loss 0.00519239624341\n",
      "Epoch 9::Minibatch 342::LR 0.0815384615385 --> Loss 0.00346004168193\n",
      "Epoch 9::Minibatch 343::LR 0.0815384615385 --> Loss 0.00182803074519\n",
      "Epoch 9::Minibatch 344::LR 0.0815384615385 --> Loss 0.00306289176146\n",
      "Epoch 9::Minibatch 345::LR 0.0815384615385 --> Loss 0.00442149678866\n",
      "Epoch 9::Minibatch 346::LR 0.0815384615385 --> Loss 0.00576903661092\n",
      "Epoch 9::Minibatch 347::LR 0.0815384615385 --> Loss 0.000957465668519\n",
      "Epoch 9::Minibatch 348::LR 0.0815384615385 --> Loss 0.00374749223391\n",
      "Epoch 9::Minibatch 349::LR 0.0815384615385 --> Loss 0.00356945792834\n",
      "Epoch 9::Minibatch 350::LR 0.0815384615385 --> Loss 0.001932969292\n",
      "Epoch 9::Minibatch 351::LR 0.0815384615385 --> Loss 0.00364126205444\n",
      "Epoch 9::Minibatch 352::LR 0.0815384615385 --> Loss 0.00482377886772\n",
      "Epoch 9::Minibatch 353::LR 0.0815384615385 --> Loss 0.00360438386599\n",
      "Epoch 9::Minibatch 354::LR 0.0815384615385 --> Loss 0.00300626059373\n",
      "Epoch 9::Minibatch 355::LR 0.0815384615385 --> Loss 0.00621784885724\n",
      "Epoch 9::Minibatch 356::LR 0.0815384615385 --> Loss 0.00320629854997\n",
      "Epoch 9::Minibatch 357::LR 0.0815384615385 --> Loss 0.00125192085902\n",
      "Epoch 9::Minibatch 358::LR 0.0815384615385 --> Loss 0.00235051234563\n",
      "Epoch 9::Minibatch 359::LR 0.0815384615385 --> Loss 0.00281577428182\n",
      "Epoch 9::Minibatch 360::LR 0.0815384615385 --> Loss 0.00253984014193\n",
      "Epoch 9::Minibatch 361::LR 0.0815384615385 --> Loss 0.00251769582431\n",
      "Epoch 9::Minibatch 362::LR 0.0815384615385 --> Loss 0.00257329265277\n",
      "Epoch 9::Minibatch 363::LR 0.0815384615385 --> Loss 0.000736155708631\n",
      "Epoch 9::Minibatch 364::LR 0.0815384615385 --> Loss 0.00208402633667\n",
      "Epoch 9::Minibatch 365::LR 0.0815384615385 --> Loss 0.00218429724375\n",
      "Epoch 9::Minibatch 366::LR 0.0815384615385 --> Loss 0.0023765963316\n",
      "Epoch 9::Minibatch 367::LR 0.0815384615385 --> Loss 0.0011816261212\n",
      "Epoch 9::Minibatch 368::LR 0.0815384615385 --> Loss 0.0010539568464\n",
      "Epoch 9::Minibatch 369::LR 0.0815384615385 --> Loss 0.00295060853163\n",
      "Epoch 9::Minibatch 370::LR 0.0815384615385 --> Loss 0.00231562475363\n",
      "Epoch 9::Minibatch 371::LR 0.0815384615385 --> Loss 0.00192628264427\n",
      "Epoch 9::Minibatch 372::LR 0.0815384615385 --> Loss 0.00048820634683\n",
      "Epoch 9::Minibatch 373::LR 0.0815384615385 --> Loss 0.00178191880385\n",
      "Epoch 9::Minibatch 374::LR 0.0815384615385 --> Loss 0.00216819226742\n",
      "Epoch 9::Minibatch 375::LR 0.0815384615385 --> Loss 0.00186147689819\n",
      "Epoch 9::Minibatch 376::LR 0.0815384615385 --> Loss 0.00127632151047\n",
      "Epoch 9::Minibatch 377::LR 0.0815384615385 --> Loss 0.00200320045153\n",
      "Epoch 9::Minibatch 378::LR 0.0815384615385 --> Loss 0.00215371330579\n",
      "Epoch 9::Minibatch 379::LR 0.0815384615385 --> Loss 0.00243120670319\n",
      "Epoch 9::Minibatch 380::LR 0.0815384615385 --> Loss 0.00162517338991\n",
      "Epoch 9::Minibatch 381::LR 0.0815384615385 --> Loss 0.00102288802465\n",
      "Epoch 9::Minibatch 382::LR 0.0815384615385 --> Loss 0.0020398068428\n",
      "Epoch 9::Minibatch 383::LR 0.0815384615385 --> Loss 0.00196196536223\n",
      "Epoch 9::Minibatch 384::LR 0.0815384615385 --> Loss 0.00106888035933\n",
      "Epoch 9::Minibatch 385::LR 0.0815384615385 --> Loss 0.00106517285109\n",
      "Epoch 9::Minibatch 386::LR 0.0815384615385 --> Loss 0.00221665720145\n",
      "Epoch 9::Minibatch 387::LR 0.0815384615385 --> Loss 0.00233593205611\n",
      "Epoch 9::Minibatch 388::LR 0.0815384615385 --> Loss 0.0011528296272\n",
      "Epoch 9::Minibatch 389::LR 0.0815384615385 --> Loss 0.0018777012825\n",
      "Epoch 9::Minibatch 390::LR 0.0815384615385 --> Loss 0.00382515748342\n",
      "Epoch 9::Minibatch 391::LR 0.0815384615385 --> Loss 0.00279528558254\n",
      "Epoch 9::Minibatch 392::LR 0.0815384615385 --> Loss 0.00275986611843\n",
      "Epoch 9::Minibatch 393::LR 0.0815384615385 --> Loss 0.00284670988719\n",
      "Epoch 9::Minibatch 394::LR 0.0815384615385 --> Loss 0.00225906570752\n",
      "Epoch 9::Minibatch 395::LR 0.0815384615385 --> Loss 0.00208037793636\n",
      "Epoch 9::Minibatch 396::LR 0.0815384615385 --> Loss 0.00201573967934\n",
      "Epoch 9::Minibatch 397::LR 0.0815384615385 --> Loss 0.00213822682699\n",
      "Epoch 9::Minibatch 398::LR 0.0815384615385 --> Loss 0.00211228132248\n",
      "Epoch 9::Minibatch 399::LR 0.0815384615385 --> Loss 0.00239257693291\n",
      "Epoch 9::Minibatch 400::LR 0.0815384615385 --> Loss 0.00206681549549\n",
      "Epoch 9::Minibatch 401::LR 0.0815384615385 --> Loss 0.0037687154611\n",
      "Epoch 9::Minibatch 402::LR 0.0815384615385 --> Loss 0.00204379061858\n",
      "Epoch 9::Minibatch 403::LR 0.0815384615385 --> Loss 0.00156614551942\n",
      "Epoch 9::Minibatch 404::LR 0.0815384615385 --> Loss 0.00166906793912\n",
      "Epoch 9::Minibatch 405::LR 0.0815384615385 --> Loss 0.00369372407595\n",
      "Epoch 9::Minibatch 406::LR 0.0815384615385 --> Loss 0.00256688296795\n",
      "Epoch 9::Minibatch 407::LR 0.0815384615385 --> Loss 0.00181684513887\n",
      "Epoch 9::Minibatch 408::LR 0.0815384615385 --> Loss 0.000516621470451\n",
      "Epoch 9::Minibatch 409::LR 0.0815384615385 --> Loss 0.00254791041215\n",
      "Epoch 9::Minibatch 410::LR 0.0815384615385 --> Loss 0.00334479093552\n",
      "Epoch 9::Minibatch 411::LR 0.0815384615385 --> Loss 0.00169309337934\n",
      "Epoch 9::Minibatch 412::LR 0.0815384615385 --> Loss 0.00102328677972\n",
      "Epoch 9::Minibatch 413::LR 0.0815384615385 --> Loss 0.00205619513988\n",
      "Epoch 9::Minibatch 414::LR 0.0815384615385 --> Loss 0.00182877381643\n",
      "Epoch 9::Minibatch 415::LR 0.0815384615385 --> Loss 0.00117290188869\n",
      "Epoch 9::Minibatch 416::LR 0.0815384615385 --> Loss 0.000884551505248\n",
      "Epoch 9::Minibatch 417::LR 0.0815384615385 --> Loss 0.00175116717815\n",
      "Epoch 9::Minibatch 418::LR 0.0815384615385 --> Loss 0.00300348202387\n",
      "Epoch 9::Minibatch 419::LR 0.0815384615385 --> Loss 0.000596912751595\n",
      "Epoch 9::Minibatch 420::LR 0.0815384615385 --> Loss 0.00077584952116\n",
      "Epoch 9::Minibatch 421::LR 0.0815384615385 --> Loss 0.00204510887464\n",
      "Epoch 9::Minibatch 422::LR 0.0815384615385 --> Loss 0.00232381979624\n",
      "Epoch 9::Minibatch 423::LR 0.0815384615385 --> Loss 0.00106310884158\n",
      "Epoch 9::Minibatch 424::LR 0.0815384615385 --> Loss 0.00166358331839\n",
      "Epoch 9::Minibatch 425::LR 0.0815384615385 --> Loss 0.00289130250613\n",
      "Epoch 9::Minibatch 426::LR 0.0815384615385 --> Loss 0.00207257767518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 427::LR 0.0815384615385 --> Loss 0.000783896744251\n",
      "Epoch 9::Minibatch 428::LR 0.0815384615385 --> Loss 0.0012095122536\n",
      "Epoch 9::Minibatch 429::LR 0.0815384615385 --> Loss 0.00258513649305\n",
      "Epoch 9::Minibatch 430::LR 0.0815384615385 --> Loss 0.00971703688304\n",
      "Epoch 9::Minibatch 431::LR 0.0815384615385 --> Loss 0.0041699163119\n",
      "Epoch 9::Minibatch 432::LR 0.0815384615385 --> Loss 0.00462614218394\n",
      "Epoch 9::Minibatch 433::LR 0.0815384615385 --> Loss 0.00262745817502\n",
      "Epoch 9::Minibatch 434::LR 0.0815384615385 --> Loss 0.00260377307733\n",
      "Epoch 9::Minibatch 435::LR 0.0815384615385 --> Loss 0.00248680531979\n",
      "Epoch 9::Minibatch 436::LR 0.0815384615385 --> Loss 0.00185993909836\n",
      "Epoch 9::Minibatch 437::LR 0.0815384615385 --> Loss 0.0036269124349\n",
      "Epoch 9::Minibatch 438::LR 0.0815384615385 --> Loss 0.00284553488096\n",
      "Epoch 9::Minibatch 439::LR 0.0815384615385 --> Loss 0.00228434522947\n",
      "Epoch 9::Minibatch 440::LR 0.0815384615385 --> Loss 0.00340051690737\n",
      "Epoch 9::Minibatch 441::LR 0.0815384615385 --> Loss 0.00322259823481\n",
      "Epoch 9::Minibatch 442::LR 0.0815384615385 --> Loss 0.00298784891764\n",
      "Epoch 9::Minibatch 443::LR 0.0815384615385 --> Loss 0.00391424457232\n",
      "Epoch 9::Minibatch 444::LR 0.0815384615385 --> Loss 0.002990847826\n",
      "Epoch 9::Minibatch 445::LR 0.0815384615385 --> Loss 0.000939622620742\n",
      "Epoch 9::Minibatch 446::LR 0.0815384615385 --> Loss 0.00160195797682\n",
      "Epoch 9::Minibatch 447::LR 0.0815384615385 --> Loss 0.00254130681356\n",
      "Epoch 9::Minibatch 448::LR 0.0815384615385 --> Loss 0.00251038968563\n",
      "Epoch 9::Minibatch 449::LR 0.0815384615385 --> Loss 0.00382234613101\n",
      "Epoch 9::Minibatch 450::LR 0.0815384615385 --> Loss 0.00248230616252\n",
      "Epoch 9::Minibatch 451::LR 0.0815384615385 --> Loss 0.00420792341232\n",
      "Epoch 9::Minibatch 452::LR 0.0815384615385 --> Loss 0.00245411992073\n",
      "Epoch 9::Minibatch 453::LR 0.0815384615385 --> Loss 0.000442480196555\n",
      "Epoch 9::Minibatch 454::LR 0.0815384615385 --> Loss 0.0036846657594\n",
      "Epoch 9::Minibatch 455::LR 0.0815384615385 --> Loss 0.00276946942012\n",
      "Epoch 9::Minibatch 456::LR 0.0815384615385 --> Loss 0.00326011399428\n",
      "Epoch 9::Minibatch 457::LR 0.0815384615385 --> Loss 0.00204404513041\n",
      "Epoch 9::Minibatch 458::LR 0.0815384615385 --> Loss 0.000842577417692\n",
      "Epoch 9::Minibatch 459::LR 0.0815384615385 --> Loss 0.00434842626254\n",
      "Epoch 9::Minibatch 460::LR 0.0815384615385 --> Loss 0.00277047495047\n",
      "Epoch 9::Minibatch 461::LR 0.0815384615385 --> Loss 0.00405169804891\n",
      "Epoch 9::Minibatch 462::LR 0.0815384615385 --> Loss 0.000440233945847\n",
      "Epoch 9::Minibatch 463::LR 0.0815384615385 --> Loss 0.00482005119324\n",
      "Epoch 9::Minibatch 464::LR 0.0815384615385 --> Loss 0.00213145911694\n",
      "Epoch 9::Minibatch 465::LR 0.0815384615385 --> Loss 0.00566927830378\n",
      "Epoch 9::Minibatch 466::LR 0.0815384615385 --> Loss 0.00526272813479\n",
      "Epoch 9::Minibatch 467::LR 0.0815384615385 --> Loss 0.0064778137207\n",
      "Epoch 9::Minibatch 468::LR 0.0815384615385 --> Loss 0.00636381109556\n",
      "Epoch 9::Minibatch 469::LR 0.0815384615385 --> Loss 0.00697901248932\n",
      "Epoch 9::Minibatch 470::LR 0.0815384615385 --> Loss 0.0039967306455\n",
      "Epoch 9::Minibatch 471::LR 0.0815384615385 --> Loss 0.0018965558211\n",
      "Epoch 9::Minibatch 472::LR 0.0815384615385 --> Loss 0.00355609258016\n",
      "Epoch 9::Minibatch 473::LR 0.0815384615385 --> Loss 0.0022022664547\n",
      "Epoch 9::Minibatch 474::LR 0.0815384615385 --> Loss 0.000738978485266\n",
      "Epoch 9::Minibatch 475::LR 0.0815384615385 --> Loss 0.00525994221369\n",
      "Epoch 9::Minibatch 476::LR 0.0815384615385 --> Loss 0.00764831145604\n",
      "Epoch 9::Minibatch 477::LR 0.0815384615385 --> Loss 0.000985653499762\n",
      "Epoch 9::Minibatch 478::LR 0.0815384615385 --> Loss 0.00257390975952\n",
      "Epoch 9::Minibatch 479::LR 0.0815384615385 --> Loss 0.00196618278821\n",
      "Epoch 9::Minibatch 480::LR 0.0815384615385 --> Loss 0.00153679619233\n",
      "Epoch 9::Minibatch 481::LR 0.0815384615385 --> Loss 0.000978744626045\n",
      "Epoch 9::Minibatch 482::LR 0.0815384615385 --> Loss 0.00212907930215\n",
      "Epoch 9::Minibatch 483::LR 0.0815384615385 --> Loss 0.00339852690697\n",
      "Epoch 9::Minibatch 484::LR 0.0815384615385 --> Loss 0.00366391420364\n",
      "Epoch 9::Minibatch 485::LR 0.0815384615385 --> Loss 0.00077991604805\n",
      "Epoch 9::Minibatch 486::LR 0.0815384615385 --> Loss 0.0031937712431\n",
      "Epoch 9::Minibatch 487::LR 0.0815384615385 --> Loss 0.00353044350942\n",
      "Epoch 9::Minibatch 488::LR 0.0815384615385 --> Loss 0.0020578010877\n",
      "Epoch 9::Minibatch 489::LR 0.0815384615385 --> Loss 0.00327619830767\n",
      "Epoch 9::Minibatch 490::LR 0.0815384615385 --> Loss 0.000438976337512\n",
      "Epoch 9::Minibatch 491::LR 0.0815384615385 --> Loss 0.00435551603635\n",
      "Epoch 9::Minibatch 492::LR 0.0815384615385 --> Loss 0.00303737958272\n",
      "Epoch 9::Minibatch 493::LR 0.0815384615385 --> Loss 0.00303147852421\n",
      "Epoch 9::Minibatch 494::LR 0.0815384615385 --> Loss 0.000763947168986\n",
      "Epoch 9::Minibatch 495::LR 0.0815384615385 --> Loss 0.00194421927134\n",
      "Epoch 9::Minibatch 496::LR 0.0815384615385 --> Loss 0.00303941249847\n",
      "Epoch 9::Minibatch 497::LR 0.0815384615385 --> Loss 0.00097573330005\n",
      "Epoch 9::Minibatch 498::LR 0.0815384615385 --> Loss 0.000621496637662\n",
      "Epoch 9::Minibatch 499::LR 0.0815384615385 --> Loss 0.00394991517067\n",
      "Epoch 9::Minibatch 500::LR 0.0815384615385 --> Loss 0.00145982563496\n",
      "Epoch 9::Minibatch 501::LR 0.0815384615385 --> Loss 0.00233526448409\n",
      "Epoch 9::Minibatch 502::LR 0.0815384615385 --> Loss 0.00405945936839\n",
      "Epoch 9::Minibatch 503::LR 0.0815384615385 --> Loss 0.0100455466906\n",
      "Epoch 9::Minibatch 504::LR 0.0815384615385 --> Loss 0.00856158177058\n",
      "Epoch 9::Minibatch 505::LR 0.0815384615385 --> Loss 0.00455406228701\n",
      "Epoch 9::Minibatch 506::LR 0.0815384615385 --> Loss 0.00360625942548\n",
      "Epoch 9::Minibatch 507::LR 0.0815384615385 --> Loss 0.00614502191544\n",
      "Epoch 9::Minibatch 508::LR 0.0815384615385 --> Loss 0.00339504003525\n",
      "Epoch 9::Minibatch 509::LR 0.0815384615385 --> Loss 0.00482097625732\n",
      "Epoch 9::Minibatch 510::LR 0.0815384615385 --> Loss 0.00483380158742\n",
      "Epoch 9::Minibatch 511::LR 0.0815384615385 --> Loss 0.00386783043543\n",
      "Epoch 9::Minibatch 512::LR 0.0815384615385 --> Loss 0.00275244255861\n",
      "Epoch 9::Minibatch 513::LR 0.0815384615385 --> Loss 0.000783494810263\n",
      "Epoch 9::Minibatch 514::LR 0.0815384615385 --> Loss 0.00280241847038\n",
      "Epoch 9::Minibatch 515::LR 0.0815384615385 --> Loss 0.00306971549988\n",
      "Epoch 9::Minibatch 516::LR 0.0815384615385 --> Loss 0.00423232118289\n",
      "Epoch 9::Minibatch 517::LR 0.0815384615385 --> Loss 0.00340680082639\n",
      "Epoch 9::Minibatch 518::LR 0.0815384615385 --> Loss 0.00258211771647\n",
      "Epoch 9::Minibatch 519::LR 0.0815384615385 --> Loss 0.00339254935582\n",
      "Epoch 9::Minibatch 520::LR 0.0815384615385 --> Loss 0.00534688711166\n",
      "Epoch 9::Minibatch 521::LR 0.0815384615385 --> Loss 0.00580947240194\n",
      "Epoch 9::Minibatch 522::LR 0.0815384615385 --> Loss 0.00817820628484\n",
      "Epoch 9::Minibatch 523::LR 0.0815384615385 --> Loss 0.000731481363376\n",
      "Epoch 9::Minibatch 524::LR 0.0815384615385 --> Loss 0.00146804908911\n",
      "Epoch 9::Minibatch 525::LR 0.0815384615385 --> Loss 0.00333488663038\n",
      "Epoch 9::Minibatch 526::LR 0.0815384615385 --> Loss 0.00432480017344\n",
      "Epoch 9::Minibatch 527::LR 0.0815384615385 --> Loss 0.0025342096885\n",
      "Epoch 9::Minibatch 528::LR 0.0815384615385 --> Loss 0.001311416924\n",
      "Epoch 9::Minibatch 529::LR 0.0815384615385 --> Loss 0.00435981273651\n",
      "Epoch 9::Minibatch 530::LR 0.0815384615385 --> Loss 0.00447328130404\n",
      "Epoch 9::Minibatch 531::LR 0.0815384615385 --> Loss 0.00386143525441\n",
      "Epoch 9::Minibatch 532::LR 0.0815384615385 --> Loss 0.00280232687791\n",
      "Epoch 9::Minibatch 533::LR 0.0815384615385 --> Loss 0.00503065307935\n",
      "Epoch 9::Minibatch 534::LR 0.0815384615385 --> Loss 0.00393124461174\n",
      "Epoch 9::Minibatch 535::LR 0.0815384615385 --> Loss 0.00329807500045\n",
      "Epoch 9::Minibatch 536::LR 0.0815384615385 --> Loss 0.00213083664576\n",
      "Epoch 9::Minibatch 537::LR 0.0815384615385 --> Loss 0.000736859639486\n",
      "Epoch 9::Minibatch 538::LR 0.0815384615385 --> Loss 0.00176148871581\n",
      "Epoch 9::Minibatch 539::LR 0.0815384615385 --> Loss 0.00349831223488\n",
      "Epoch 9::Minibatch 540::LR 0.0815384615385 --> Loss 0.00342581311862\n",
      "Epoch 9::Minibatch 541::LR 0.0815384615385 --> Loss 0.0029344278574\n",
      "Epoch 9::Minibatch 542::LR 0.0815384615385 --> Loss 0.0026328287522\n",
      "Epoch 9::Minibatch 543::LR 0.0815384615385 --> Loss 0.00289975742499\n",
      "Epoch 9::Minibatch 544::LR 0.0815384615385 --> Loss 0.00400470813115\n",
      "Epoch 9::Minibatch 545::LR 0.0815384615385 --> Loss 0.00210546036561\n",
      "Epoch 9::Minibatch 546::LR 0.0815384615385 --> Loss 0.000697618722916\n",
      "Epoch 9::Minibatch 547::LR 0.0815384615385 --> Loss 0.00269016881784\n",
      "Epoch 9::Minibatch 548::LR 0.0815384615385 --> Loss 0.00408621907234\n",
      "Epoch 9::Minibatch 549::LR 0.0815384615385 --> Loss 0.00798808813095\n",
      "Epoch 9::Minibatch 550::LR 0.0815384615385 --> Loss 0.00119494428237\n",
      "Epoch 9::Minibatch 551::LR 0.0815384615385 --> Loss 0.00249280611674\n",
      "Epoch 9::Minibatch 552::LR 0.0815384615385 --> Loss 0.00373031457265\n",
      "Epoch 9::Minibatch 553::LR 0.0815384615385 --> Loss 0.00335667014122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 554::LR 0.0815384615385 --> Loss 0.00394753336906\n",
      "Epoch 9::Minibatch 555::LR 0.0815384615385 --> Loss 0.00103945116202\n",
      "Epoch 9::Minibatch 556::LR 0.0815384615385 --> Loss 0.00210792978605\n",
      "Epoch 9::Minibatch 557::LR 0.0815384615385 --> Loss 0.00256762405237\n",
      "Epoch 9::Minibatch 558::LR 0.0815384615385 --> Loss 0.00397555232048\n",
      "Epoch 9::Minibatch 559::LR 0.0815384615385 --> Loss 0.00382845600446\n",
      "Epoch 9::Minibatch 560::LR 0.0815384615385 --> Loss 0.00326248129209\n",
      "Epoch 9::Minibatch 561::LR 0.0815384615385 --> Loss 0.00285743077596\n",
      "Epoch 9::Minibatch 562::LR 0.0815384615385 --> Loss 0.00245040953159\n",
      "Epoch 9::Minibatch 563::LR 0.0815384615385 --> Loss 0.00415362556775\n",
      "Epoch 9::Minibatch 564::LR 0.0815384615385 --> Loss 0.00322946151098\n",
      "Epoch 9::Minibatch 565::LR 0.0815384615385 --> Loss 0.00382025877635\n",
      "Epoch 9::Minibatch 566::LR 0.0815384615385 --> Loss 0.00238853832086\n",
      "Epoch 9::Minibatch 567::LR 0.0815384615385 --> Loss 0.00269559403261\n",
      "Epoch 9::Minibatch 568::LR 0.0815384615385 --> Loss 0.0018794165055\n",
      "Epoch 9::Minibatch 569::LR 0.0815384615385 --> Loss 0.000594799170891\n",
      "Epoch 9::Minibatch 570::LR 0.0815384615385 --> Loss 0.00178798774878\n",
      "Epoch 9::Minibatch 571::LR 0.0815384615385 --> Loss 0.00235136846701\n",
      "Epoch 9::Minibatch 572::LR 0.0815384615385 --> Loss 0.00248203853766\n",
      "Epoch 9::Minibatch 573::LR 0.0815384615385 --> Loss 0.00156258036693\n",
      "Epoch 9::Minibatch 574::LR 0.0815384615385 --> Loss 0.00107065012058\n",
      "Epoch 9::Minibatch 575::LR 0.0815384615385 --> Loss 0.00185127874215\n",
      "Epoch 9::Minibatch 576::LR 0.0815384615385 --> Loss 0.00222739815712\n",
      "Epoch 9::Minibatch 577::LR 0.0815384615385 --> Loss 0.00173479715983\n",
      "Epoch 9::Minibatch 578::LR 0.0815384615385 --> Loss 0.00131774624189\n",
      "Epoch 9::Minibatch 579::LR 0.0815384615385 --> Loss 0.00123540729284\n",
      "Epoch 9::Minibatch 580::LR 0.0815384615385 --> Loss 0.00200116097927\n",
      "Epoch 9::Minibatch 581::LR 0.0815384615385 --> Loss 0.0017507982254\n",
      "Epoch 9::Minibatch 582::LR 0.0815384615385 --> Loss 0.0041700108846\n",
      "Epoch 9::Minibatch 583::LR 0.0815384615385 --> Loss 0.000964539349079\n",
      "Epoch 9::Minibatch 584::LR 0.0815384615385 --> Loss 0.00133549143871\n",
      "Epoch 9::Minibatch 585::LR 0.0815384615385 --> Loss 0.00522651116053\n",
      "Epoch 9::Minibatch 586::LR 0.0815384615385 --> Loss 0.00426266312599\n",
      "Epoch 9::Minibatch 587::LR 0.0815384615385 --> Loss 0.00116606305043\n",
      "Epoch 9::Minibatch 588::LR 0.0815384615385 --> Loss 0.00146339118481\n",
      "Epoch 9::Minibatch 589::LR 0.0815384615385 --> Loss 0.0027969978253\n",
      "Epoch 9::Minibatch 590::LR 0.0815384615385 --> Loss 0.00211753547192\n",
      "Epoch 9::Minibatch 591::LR 0.0815384615385 --> Loss 0.00344487905502\n",
      "Epoch 9::Minibatch 592::LR 0.0815384615385 --> Loss 0.00121563285589\n",
      "Epoch 9::Minibatch 593::LR 0.0815384615385 --> Loss 0.00267080465953\n",
      "Epoch 9::Minibatch 594::LR 0.0815384615385 --> Loss 0.00292043069998\n",
      "Epoch 9::Minibatch 595::LR 0.0815384615385 --> Loss 0.00308039526145\n",
      "Epoch 9::Minibatch 596::LR 0.0815384615385 --> Loss 0.00202043533325\n",
      "Epoch 9::Minibatch 597::LR 0.0815384615385 --> Loss 0.00123190999031\n",
      "Epoch 9::Minibatch 598::LR 0.0815384615385 --> Loss 0.00321319878101\n",
      "Epoch 9::Minibatch 599::LR 0.0815384615385 --> Loss 0.0019214173158\n",
      "Epoch 9::Minibatch 600::LR 0.0815384615385 --> Loss 0.00233508725961\n",
      "Epoch 9::Minibatch 601::LR 0.0815384615385 --> Loss 0.00394437630971\n",
      "Epoch 9::Minibatch 602::LR 0.0815384615385 --> Loss 0.00216243286928\n",
      "Epoch 9::Minibatch 603::LR 0.0815384615385 --> Loss 0.00271395385265\n",
      "Epoch 9::Minibatch 604::LR 0.0815384615385 --> Loss 0.00167655805747\n",
      "Epoch 9::Minibatch 605::LR 0.0815384615385 --> Loss 0.00247632424037\n",
      "Epoch 9::Minibatch 606::LR 0.0815384615385 --> Loss 0.00198617259661\n",
      "Epoch 9::Minibatch 607::LR 0.0815384615385 --> Loss 0.000866927305857\n",
      "Epoch 9::Minibatch 608::LR 0.0815384615385 --> Loss 0.00165747513374\n",
      "Epoch 9::Minibatch 609::LR 0.0815384615385 --> Loss 0.0023731225729\n",
      "Epoch 9::Minibatch 610::LR 0.0815384615385 --> Loss 0.00402405341466\n",
      "Epoch 9::Minibatch 611::LR 0.0815384615385 --> Loss 0.00271287937959\n",
      "Epoch 9::Minibatch 612::LR 0.0815384615385 --> Loss 0.000534962415695\n",
      "Epoch 9::Minibatch 613::LR 0.0815384615385 --> Loss 0.00134349554777\n",
      "Epoch 9::Minibatch 614::LR 0.0815384615385 --> Loss 0.00255207796892\n",
      "Epoch 9::Minibatch 615::LR 0.0815384615385 --> Loss 0.00173389196396\n",
      "Epoch 9::Minibatch 616::LR 0.0815384615385 --> Loss 0.000959151784579\n",
      "Epoch 9::Minibatch 617::LR 0.0815384615385 --> Loss 0.000543657441934\n",
      "Epoch 9::Minibatch 618::LR 0.0815384615385 --> Loss 0.00270622611046\n",
      "Epoch 9::Minibatch 619::LR 0.0815384615385 --> Loss 0.00195441206296\n",
      "Epoch 9::Minibatch 620::LR 0.0815384615385 --> Loss 0.00176257809003\n",
      "Epoch 9::Minibatch 621::LR 0.0815384615385 --> Loss 0.000886993010839\n",
      "Epoch 9::Minibatch 622::LR 0.0815384615385 --> Loss 0.000849855144819\n",
      "Epoch 9::Minibatch 623::LR 0.0815384615385 --> Loss 0.00222698311011\n",
      "Epoch 9::Minibatch 624::LR 0.0815384615385 --> Loss 0.00184283991655\n",
      "Epoch 9::Minibatch 625::LR 0.0815384615385 --> Loss 0.00326698303223\n",
      "Epoch 9::Minibatch 626::LR 0.0815384615385 --> Loss 0.0050540248553\n",
      "Epoch 9::Minibatch 627::LR 0.0815384615385 --> Loss 0.00142234563828\n",
      "Epoch 9::Minibatch 628::LR 0.0815384615385 --> Loss 0.000974490046501\n",
      "Epoch 9::Minibatch 629::LR 0.0815384615385 --> Loss 0.0036196231842\n",
      "Epoch 9::Minibatch 630::LR 0.0815384615385 --> Loss 0.00349636077881\n",
      "Epoch 9::Minibatch 631::LR 0.0815384615385 --> Loss 0.0075968837738\n",
      "Epoch 9::Minibatch 632::LR 0.0815384615385 --> Loss 0.000855583151182\n",
      "Epoch 9::Minibatch 633::LR 0.0815384615385 --> Loss 0.00173706094424\n",
      "Epoch 9::Minibatch 634::LR 0.0815384615385 --> Loss 0.00333743135134\n",
      "Epoch 9::Minibatch 635::LR 0.0815384615385 --> Loss 0.00478906393051\n",
      "Epoch 9::Minibatch 636::LR 0.0815384615385 --> Loss 0.00576507210732\n",
      "Epoch 9::Minibatch 637::LR 0.0815384615385 --> Loss 0.000974471370379\n",
      "Epoch 9::Minibatch 638::LR 0.0815384615385 --> Loss 0.00167556961377\n",
      "Epoch 9::Minibatch 639::LR 0.0815384615385 --> Loss 0.00345120509466\n",
      "Epoch 9::Minibatch 640::LR 0.0815384615385 --> Loss 0.0052952281634\n",
      "Epoch 9::Minibatch 641::LR 0.0815384615385 --> Loss 0.00329071978728\n",
      "Epoch 9::Minibatch 642::LR 0.0815384615385 --> Loss 0.000625777790944\n",
      "Epoch 9::Minibatch 643::LR 0.0815384615385 --> Loss 0.00241484781106\n",
      "Epoch 9::Minibatch 644::LR 0.0815384615385 --> Loss 0.00412231167157\n",
      "Epoch 9::Minibatch 645::LR 0.0815384615385 --> Loss 0.00431696573893\n",
      "Epoch 9::Minibatch 646::LR 0.0815384615385 --> Loss 0.00164438138405\n",
      "Epoch 9::Minibatch 647::LR 0.0815384615385 --> Loss 0.00071434294184\n",
      "Epoch 9::Minibatch 648::LR 0.0815384615385 --> Loss 0.00318673849106\n",
      "Epoch 9::Minibatch 649::LR 0.0815384615385 --> Loss 0.0037546813488\n",
      "Epoch 9::Minibatch 650::LR 0.0815384615385 --> Loss 0.00346603433291\n",
      "Epoch 9::Minibatch 651::LR 0.0815384615385 --> Loss 0.00149752110243\n",
      "Epoch 9::Minibatch 652::LR 0.0815384615385 --> Loss 0.000949202378591\n",
      "Epoch 9::Minibatch 653::LR 0.0815384615385 --> Loss 0.00298665324847\n",
      "Epoch 9::Minibatch 654::LR 0.0815384615385 --> Loss 0.00317097842693\n",
      "Epoch 9::Minibatch 655::LR 0.0815384615385 --> Loss 0.00351858258247\n",
      "Epoch 9::Minibatch 656::LR 0.0815384615385 --> Loss 0.000829448054234\n",
      "Epoch 9::Minibatch 657::LR 0.0815384615385 --> Loss 0.00223162253698\n",
      "Epoch 9::Minibatch 658::LR 0.0815384615385 --> Loss 0.00509619951248\n",
      "Epoch 9::Minibatch 659::LR 0.0815384615385 --> Loss 0.00242304801941\n",
      "Epoch 9::Minibatch 660::LR 0.0815384615385 --> Loss 0.00263443648815\n",
      "Epoch 9::Minibatch 661::LR 0.0815384615385 --> Loss 0.00265262246132\n",
      "Epoch 9::Minibatch 662::LR 0.0815384615385 --> Loss 0.00188163518906\n",
      "Epoch 9::Minibatch 663::LR 0.0815384615385 --> Loss 0.00373599012693\n",
      "Epoch 9::Minibatch 664::LR 0.0815384615385 --> Loss 0.00364768902461\n",
      "Epoch 9::Minibatch 665::LR 0.0815384615385 --> Loss 0.000831601321697\n",
      "Epoch 9::Minibatch 666::LR 0.0815384615385 --> Loss 0.00399101734161\n",
      "Epoch 9::Minibatch 667::LR 0.0815384615385 --> Loss 0.002629926006\n",
      "Epoch 9::Minibatch 668::LR 0.0815384615385 --> Loss 0.00748376925786\n",
      "Epoch 9::Minibatch 669::LR 0.0815384615385 --> Loss 0.00112500955661\n",
      "Epoch 9::Minibatch 670::LR 0.0815384615385 --> Loss 0.00141756246487\n",
      "Epoch 9::Minibatch 671::LR 0.0815384615385 --> Loss 0.00560015002886\n",
      "Epoch 9::Minibatch 672::LR 0.0815384615385 --> Loss 0.00404359221458\n",
      "Epoch 9::Minibatch 673::LR 0.0815384615385 --> Loss 0.00166219592094\n",
      "Epoch 9::Minibatch 674::LR 0.0815384615385 --> Loss 0.000573342889547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 675::LR 0.0815384615385 --> Loss 0.00225435038408\n",
      "Epoch 9::Minibatch 676::LR 0.0815384615385 --> Loss 0.00215780377388\n",
      "Epoch 9::Minibatch 677::LR 0.0815384615385 --> Loss 0.0029501136144\n",
      "Epoch 9::Minibatch 678::LR 0.0815384615385 --> Loss 0.00199760595957\n",
      "Epoch 9::Minibatch 679::LR 0.0815384615385 --> Loss 0.00367300311724\n",
      "Epoch 9::Minibatch 680::LR 0.0815384615385 --> Loss 0.00218816181024\n",
      "Epoch 9::Minibatch 681::LR 0.0815384615385 --> Loss 0.00248413642248\n",
      "Epoch 9::Minibatch 682::LR 0.0815384615385 --> Loss 0.000800352146228\n",
      "Epoch 9::Minibatch 683::LR 0.0815384615385 --> Loss 0.0024928043286\n",
      "Epoch 9::Minibatch 684::LR 0.0815384615385 --> Loss 0.002399807175\n",
      "Epoch 9::Minibatch 685::LR 0.0815384615385 --> Loss 0.00301495234172\n",
      "Epoch 9::Minibatch 686::LR 0.0815384615385 --> Loss 0.00154025554657\n",
      "Epoch 9::Minibatch 687::LR 0.0815384615385 --> Loss 0.00086391299963\n",
      "Epoch 9::Minibatch 688::LR 0.0815384615385 --> Loss 0.0027956332763\n",
      "Epoch 9::Minibatch 689::LR 0.0815384615385 --> Loss 0.0026008494695\n",
      "Epoch 9::Minibatch 690::LR 0.0815384615385 --> Loss 0.00195916076501\n",
      "Epoch 9::Minibatch 691::LR 0.0815384615385 --> Loss 0.000693047444026\n",
      "Epoch 9::Minibatch 692::LR 0.0815384615385 --> Loss 0.00254501779874\n",
      "Epoch 9::Minibatch 693::LR 0.0815384615385 --> Loss 0.00259957353274\n",
      "Epoch 9::Minibatch 694::LR 0.0815384615385 --> Loss 0.00305654386679\n",
      "Epoch 9::Minibatch 695::LR 0.0815384615385 --> Loss 0.00174328863621\n",
      "Epoch 9::Minibatch 696::LR 0.0815384615385 --> Loss 0.00204407234987\n",
      "Epoch 9::Minibatch 697::LR 0.0815384615385 --> Loss 0.00142687747876\n",
      "Epoch 9::Minibatch 698::LR 0.0815384615385 --> Loss 0.00162172456582\n",
      "Epoch 9::Minibatch 699::LR 0.0815384615385 --> Loss 0.00389757275581\n",
      "Epoch 9::Minibatch 700::LR 0.0815384615385 --> Loss 0.00274295727412\n",
      "Epoch 9::Minibatch 701::LR 0.0815384615385 --> Loss 0.00206465979417\n",
      "Epoch 9::Minibatch 702::LR 0.0815384615385 --> Loss 0.00169528146585\n",
      "Epoch 9::Minibatch 703::LR 0.0815384615385 --> Loss 0.004232771794\n",
      "Epoch 9::Minibatch 704::LR 0.0815384615385 --> Loss 0.00183223108451\n",
      "Epoch 9::Minibatch 705::LR 0.0815384615385 --> Loss 0.00286293625832\n",
      "Epoch 9::Minibatch 706::LR 0.0815384615385 --> Loss 0.00222704609235\n",
      "Epoch 9::Minibatch 707::LR 0.0815384615385 --> Loss 0.00121109942595\n",
      "Epoch 9::Minibatch 708::LR 0.0815384615385 --> Loss 0.00175490140915\n",
      "Epoch 9::Minibatch 709::LR 0.0815384615385 --> Loss 0.00173745274544\n",
      "Epoch 9::Minibatch 710::LR 0.0815384615385 --> Loss 0.00249886890252\n",
      "Epoch 9::Minibatch 711::LR 0.0815384615385 --> Loss 0.00189924617608\n",
      "Epoch 9::Minibatch 712::LR 0.0815384615385 --> Loss 0.00134211530288\n",
      "Epoch 9::Minibatch 713::LR 0.0815384615385 --> Loss 0.00175485114257\n",
      "Epoch 9::Minibatch 714::LR 0.0815384615385 --> Loss 0.00271145522594\n",
      "Epoch 9::Minibatch 715::LR 0.0815384615385 --> Loss 0.00297186096509\n",
      "Epoch 9::Minibatch 716::LR 0.0815384615385 --> Loss 0.00161254028479\n",
      "Epoch 9::Minibatch 717::LR 0.0815384615385 --> Loss 0.00161383152008\n",
      "Epoch 9::Minibatch 718::LR 0.0815384615385 --> Loss 0.00128711988529\n",
      "Epoch 9::Minibatch 719::LR 0.0815384615385 --> Loss 0.00168304840724\n",
      "Epoch 9::Minibatch 720::LR 0.0815384615385 --> Loss 0.00250857949257\n",
      "Epoch 9::Minibatch 721::LR 0.0815384615385 --> Loss 0.00067202553153\n",
      "Epoch 9::Minibatch 722::LR 0.0815384615385 --> Loss 0.00496437748273\n",
      "Epoch 9::Minibatch 723::LR 0.0815384615385 --> Loss 0.00492974082629\n",
      "Epoch 9::Minibatch 724::LR 0.0815384615385 --> Loss 0.00100480933984\n",
      "Epoch 9::Minibatch 725::LR 0.0815384615385 --> Loss 0.00234441081683\n",
      "Epoch 9::Minibatch 726::LR 0.0815384615385 --> Loss 0.00512491663297\n",
      "Epoch 9::Minibatch 727::LR 0.0815384615385 --> Loss 0.00310674945513\n",
      "Epoch 9::Minibatch 728::LR 0.0815384615385 --> Loss 0.000681662162145\n",
      "Epoch 9::Minibatch 729::LR 0.0815384615385 --> Loss 0.000813936541478\n",
      "Epoch 9::Minibatch 730::LR 0.0815384615385 --> Loss 0.0026692656676\n",
      "Epoch 9::Minibatch 731::LR 0.0815384615385 --> Loss 0.00247089227041\n",
      "Epoch 9::Minibatch 732::LR 0.0815384615385 --> Loss 0.00241182525953\n",
      "Epoch 9::Minibatch 733::LR 0.0815384615385 --> Loss 0.000803987880548\n",
      "Epoch 9::Minibatch 734::LR 0.0815384615385 --> Loss 0.00186870038509\n",
      "Epoch 9::Minibatch 735::LR 0.0815384615385 --> Loss 0.00238097111384\n",
      "Epoch 9::Minibatch 736::LR 0.0815384615385 --> Loss 0.00346460858981\n",
      "Epoch 9::Minibatch 737::LR 0.0815384615385 --> Loss 0.0031698123614\n",
      "Epoch 9::Minibatch 738::LR 0.0815384615385 --> Loss 0.00175961295764\n",
      "Epoch 9::Minibatch 739::LR 0.0815384615385 --> Loss 0.00254796226819\n",
      "Epoch 9::Minibatch 740::LR 0.0815384615385 --> Loss 0.00386761864026\n",
      "Epoch 9::Minibatch 741::LR 0.0815384615385 --> Loss 0.00281249503295\n",
      "Epoch 9::Minibatch 742::LR 0.0815384615385 --> Loss 0.0021484742562\n",
      "Epoch 9::Minibatch 743::LR 0.0815384615385 --> Loss 0.00136311541001\n",
      "Epoch 9::Minibatch 744::LR 0.0815384615385 --> Loss 0.00182317058245\n",
      "Epoch 9::Minibatch 745::LR 0.0815384615385 --> Loss 0.00288086314996\n",
      "Epoch 9::Minibatch 746::LR 0.0815384615385 --> Loss 0.00305761853854\n",
      "Epoch 9::Minibatch 747::LR 0.0815384615385 --> Loss 0.00181382954121\n",
      "Epoch 9::Minibatch 748::LR 0.0815384615385 --> Loss 0.000681181748708\n",
      "Epoch 9::Minibatch 749::LR 0.0815384615385 --> Loss 0.00167684435844\n",
      "Epoch 9::Minibatch 750::LR 0.0815384615385 --> Loss 0.00250618497531\n",
      "Epoch 9::Minibatch 751::LR 0.0815384615385 --> Loss 0.00270290752252\n",
      "Epoch 9::Minibatch 752::LR 0.0815384615385 --> Loss 0.00111977557341\n",
      "Epoch 9::Minibatch 753::LR 0.0815384615385 --> Loss 0.00228215754032\n",
      "Epoch 9::Minibatch 754::LR 0.0815384615385 --> Loss 0.00239791671435\n",
      "Epoch 9::Minibatch 755::LR 0.0815384615385 --> Loss 0.00268375416597\n",
      "Epoch 9::Minibatch 756::LR 0.0815384615385 --> Loss 0.00149806201458\n",
      "Epoch 9::Minibatch 757::LR 0.0815384615385 --> Loss 0.000960740149021\n",
      "Epoch 9::Minibatch 758::LR 0.0815384615385 --> Loss 0.00168734828631\n",
      "Epoch 9::Minibatch 759::LR 0.0815384615385 --> Loss 0.00388248920441\n",
      "Epoch 9::Minibatch 760::LR 0.0815384615385 --> Loss 0.00317284444968\n",
      "Epoch 9::Minibatch 761::LR 0.0815384615385 --> Loss 0.00648160656293\n",
      "Epoch 9::Minibatch 762::LR 0.0815384615385 --> Loss 0.00385167241096\n",
      "Epoch 9::Minibatch 763::LR 0.0815384615385 --> Loss 0.00369696537654\n",
      "Epoch 9::Minibatch 764::LR 0.0815384615385 --> Loss 0.00329566319784\n",
      "Epoch 9::Minibatch 765::LR 0.0815384615385 --> Loss 0.00137863268455\n",
      "Epoch 9::Minibatch 766::LR 0.0815384615385 --> Loss 0.00229511300723\n",
      "Epoch 9::Minibatch 767::LR 0.0815384615385 --> Loss 0.00511893312136\n",
      "Epoch 9::Minibatch 768::LR 0.0815384615385 --> Loss 0.00356631954511\n",
      "Epoch 9::Minibatch 769::LR 0.0815384615385 --> Loss 0.00195729613304\n",
      "Epoch 9::Minibatch 770::LR 0.0815384615385 --> Loss 0.00152454634507\n",
      "Epoch 9::Minibatch 771::LR 0.0815384615385 --> Loss 0.0038853931427\n",
      "Epoch 9::Minibatch 772::LR 0.0815384615385 --> Loss 0.00335379401843\n",
      "Epoch 9::Minibatch 773::LR 0.0815384615385 --> Loss 0.00317155818144\n",
      "Epoch 9::Minibatch 774::LR 0.0815384615385 --> Loss 0.00177844405174\n",
      "Epoch 9::Minibatch 775::LR 0.0815384615385 --> Loss 0.00436525901159\n",
      "Epoch 9::Minibatch 776::LR 0.0815384615385 --> Loss 0.0035915017128\n",
      "Epoch 9::Minibatch 777::LR 0.0815384615385 --> Loss 0.00804243723551\n",
      "Epoch 9::Minibatch 778::LR 0.0815384615385 --> Loss 0.0109981187185\n",
      "Epoch 9::Minibatch 779::LR 0.0815384615385 --> Loss 0.00192695279916\n",
      "Epoch 9::Minibatch 780::LR 0.0815384615385 --> Loss 0.00170245627562\n",
      "Epoch 9::Minibatch 781::LR 0.0815384615385 --> Loss 0.00362359285355\n",
      "Epoch 9::Minibatch 782::LR 0.0815384615385 --> Loss 0.00424166361491\n",
      "Epoch 9::Minibatch 783::LR 0.0815384615385 --> Loss 0.00239862064521\n",
      "Epoch 9::Minibatch 784::LR 0.0815384615385 --> Loss 0.000781625012557\n",
      "Epoch 9::Minibatch 785::LR 0.0815384615385 --> Loss 0.00404734571775\n",
      "Epoch 9::Minibatch 786::LR 0.0815384615385 --> Loss 0.00371602058411\n",
      "Epoch 9::Minibatch 787::LR 0.0815384615385 --> Loss 0.00293815672398\n",
      "Epoch 9::Minibatch 788::LR 0.0815384615385 --> Loss 0.00259251375993\n",
      "Epoch 9::Minibatch 789::LR 0.0815384615385 --> Loss 0.000775928695997\n",
      "Epoch 9::Minibatch 790::LR 0.0815384615385 --> Loss 0.00333649635315\n",
      "Epoch 9::Minibatch 791::LR 0.0815384615385 --> Loss 0.00387581666311\n",
      "Epoch 9::Minibatch 792::LR 0.0815384615385 --> Loss 0.00357988715172\n",
      "Epoch 9::Minibatch 793::LR 0.0815384615385 --> Loss 0.00204364081224\n",
      "Epoch 9::Minibatch 794::LR 0.0815384615385 --> Loss 0.00115496555964\n",
      "Epoch 9::Minibatch 795::LR 0.0815384615385 --> Loss 0.00348169287046\n",
      "Epoch 9::Minibatch 796::LR 0.0815384615385 --> Loss 0.00622579733531\n",
      "Epoch 9::Minibatch 797::LR 0.0815384615385 --> Loss 0.00850724299749\n",
      "Epoch 9::Minibatch 798::LR 0.0815384615385 --> Loss 0.00355943202972\n",
      "Epoch 9::Minibatch 799::LR 0.0815384615385 --> Loss 0.00261842131615\n",
      "Epoch 9::Minibatch 800::LR 0.0815384615385 --> Loss 0.00210646231969\n",
      "Epoch 9::Minibatch 801::LR 0.0815384615385 --> Loss 0.00419442335765\n",
      "Epoch 9::Minibatch 802::LR 0.0815384615385 --> Loss 0.00144114812215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 803::LR 0.0815384615385 --> Loss 0.00281000375748\n",
      "Epoch 9::Minibatch 804::LR 0.0815384615385 --> Loss 0.00230915725231\n",
      "Epoch 9::Minibatch 805::LR 0.0815384615385 --> Loss 0.00238446493944\n",
      "Epoch 9::Minibatch 806::LR 0.0815384615385 --> Loss 0.00332411706448\n",
      "Epoch 9::Minibatch 807::LR 0.0815384615385 --> Loss 0.00309057116508\n",
      "Epoch 9::Minibatch 808::LR 0.0815384615385 --> Loss 0.00287798821926\n",
      "Epoch 9::Minibatch 809::LR 0.0815384615385 --> Loss 0.00436136047045\n",
      "Epoch 9::Minibatch 810::LR 0.0815384615385 --> Loss 0.00555225610733\n",
      "Epoch 9::Minibatch 811::LR 0.0815384615385 --> Loss 0.0052009832859\n",
      "Epoch 9::Minibatch 812::LR 0.0815384615385 --> Loss 0.00508506735166\n",
      "Epoch 9::Minibatch 813::LR 0.0815384615385 --> Loss 0.00488638599714\n",
      "Epoch 9::Minibatch 814::LR 0.0815384615385 --> Loss 0.00217294156551\n",
      "Epoch 9::Minibatch 815::LR 0.0815384615385 --> Loss 0.0042246389389\n",
      "Epoch 9::Minibatch 816::LR 0.0815384615385 --> Loss 0.00439853469531\n",
      "Epoch 9::Minibatch 817::LR 0.0815384615385 --> Loss 0.00549090663592\n",
      "Epoch 9::Minibatch 818::LR 0.0815384615385 --> Loss 0.00146819094817\n",
      "Epoch 9::Minibatch 819::LR 0.0815384615385 --> Loss 0.000835652550062\n",
      "Epoch 9::Minibatch 820::LR 0.0815384615385 --> Loss 0.00558347264926\n",
      "Epoch 9::Minibatch 821::LR 0.0815384615385 --> Loss 0.00337854027748\n",
      "Epoch 9::Minibatch 822::LR 0.0815384615385 --> Loss 0.00399046579997\n",
      "Epoch 9::Minibatch 823::LR 0.0815384615385 --> Loss 0.00136679063241\n",
      "Epoch 9::Minibatch 824::LR 0.0815384615385 --> Loss 0.00147042006254\n",
      "Epoch 9::Minibatch 825::LR 0.0815384615385 --> Loss 0.00387710571289\n",
      "Epoch 9::Minibatch 826::LR 0.0815384615385 --> Loss 0.00396490136782\n",
      "Epoch 9::Minibatch 827::LR 0.0815384615385 --> Loss 0.00243513762951\n",
      "Epoch 9::Minibatch 828::LR 0.0815384615385 --> Loss 0.000831513355176\n",
      "Epoch 9::Minibatch 829::LR 0.0815384615385 --> Loss 0.00255765616894\n",
      "Epoch 9::Minibatch 830::LR 0.0815384615385 --> Loss 0.00456440409025\n",
      "Epoch 9::Minibatch 831::LR 0.0815384615385 --> Loss 0.00263707876205\n",
      "Epoch 9::Minibatch 832::LR 0.0815384615385 --> Loss 0.00232864797115\n",
      "Epoch 9::Minibatch 833::LR 0.0815384615385 --> Loss 0.0018957511584\n",
      "Epoch 9::Minibatch 834::LR 0.0815384615385 --> Loss 0.000812118450801\n",
      "Epoch 9::Minibatch 835::LR 0.0815384615385 --> Loss 0.00390178958575\n",
      "Epoch 9::Minibatch 836::LR 0.0815384615385 --> Loss 0.00389216899872\n",
      "Epoch 9::Minibatch 837::LR 0.0815384615385 --> Loss 0.0023335113128\n",
      "Epoch 9::Minibatch 838::LR 0.0815384615385 --> Loss 0.000680540998777\n",
      "Epoch 9::Minibatch 839::LR 0.0815384615385 --> Loss 0.00252117415269\n",
      "Epoch 9::Minibatch 840::LR 0.0815384615385 --> Loss 0.0030140409867\n",
      "Epoch 9::Minibatch 841::LR 0.0815384615385 --> Loss 0.00301249543826\n",
      "Epoch 9::Minibatch 842::LR 0.0815384615385 --> Loss 0.00220986763636\n",
      "Epoch 9::Minibatch 843::LR 0.0815384615385 --> Loss 0.00104653845231\n",
      "Epoch 9::Minibatch 844::LR 0.0815384615385 --> Loss 0.00154919872681\n",
      "Epoch 9::Minibatch 845::LR 0.0815384615385 --> Loss 0.00446848074595\n",
      "Epoch 9::Minibatch 846::LR 0.0815384615385 --> Loss 0.0017308562994\n",
      "Epoch 9::Minibatch 847::LR 0.0815384615385 --> Loss 0.00239147305489\n",
      "Epoch 9::Minibatch 848::LR 0.0815384615385 --> Loss 0.00103079001109\n",
      "Epoch 9::Minibatch 849::LR 0.0815384615385 --> Loss 0.0019344753027\n",
      "Epoch 9::Minibatch 850::LR 0.0815384615385 --> Loss 0.00327919562658\n",
      "Epoch 9::Minibatch 851::LR 0.0815384615385 --> Loss 0.00288743495941\n",
      "Epoch 9::Minibatch 852::LR 0.0815384615385 --> Loss 0.0010995777448\n",
      "Epoch 9::Minibatch 853::LR 0.0815384615385 --> Loss 0.00135767032703\n",
      "Epoch 9::Minibatch 854::LR 0.0815384615385 --> Loss 0.00259873211384\n",
      "Epoch 9::Minibatch 855::LR 0.0815384615385 --> Loss 0.00221466064453\n",
      "Epoch 9::Minibatch 856::LR 0.0815384615385 --> Loss 0.00182360788186\n",
      "Epoch 9::Minibatch 857::LR 0.0815384615385 --> Loss 0.00124264935652\n",
      "Epoch 9::Minibatch 858::LR 0.0815384615385 --> Loss 0.000625568578641\n",
      "Epoch 9::Minibatch 859::LR 0.0815384615385 --> Loss 0.00190137286981\n",
      "Epoch 9::Minibatch 860::LR 0.0815384615385 --> Loss 0.00123946547508\n",
      "Epoch 9::Minibatch 861::LR 0.0815384615385 --> Loss 0.000954606533051\n",
      "Epoch 9::Minibatch 862::LR 0.0815384615385 --> Loss 0.00366737524668\n",
      "Epoch 9::Minibatch 863::LR 0.0815384615385 --> Loss 0.00347883900007\n",
      "Epoch 9::Minibatch 864::LR 0.0815384615385 --> Loss 0.00312217275302\n",
      "Epoch 9::Minibatch 865::LR 0.0815384615385 --> Loss 0.000569549550613\n",
      "Epoch 9::Minibatch 866::LR 0.0815384615385 --> Loss 0.0022398062547\n",
      "Epoch 9::Minibatch 867::LR 0.0815384615385 --> Loss 0.00312587579091\n",
      "Epoch 9::Minibatch 868::LR 0.0815384615385 --> Loss 0.00261582036813\n",
      "Epoch 9::Minibatch 869::LR 0.0815384615385 --> Loss 0.00214963992437\n",
      "Epoch 9::Minibatch 870::LR 0.0815384615385 --> Loss 0.00370667894681\n",
      "Epoch 9::Minibatch 871::LR 0.0815384615385 --> Loss 0.00155932337046\n",
      "Epoch 9::Minibatch 872::LR 0.0815384615385 --> Loss 0.00235150198142\n",
      "Epoch 9::Minibatch 873::LR 0.0815384615385 --> Loss 0.00252805848916\n",
      "Epoch 9::Minibatch 874::LR 0.0815384615385 --> Loss 0.00648372570674\n",
      "Epoch 9::Minibatch 875::LR 0.0815384615385 --> Loss 0.000572961767515\n",
      "Epoch 9::Minibatch 876::LR 0.0815384615385 --> Loss 0.00368400931358\n",
      "Epoch 9::Minibatch 877::LR 0.0815384615385 --> Loss 0.00444317539533\n",
      "Epoch 9::Minibatch 878::LR 0.0815384615385 --> Loss 0.0034264989694\n",
      "Epoch 9::Minibatch 879::LR 0.0815384615385 --> Loss 0.00395482420921\n",
      "Epoch 9::Minibatch 880::LR 0.0815384615385 --> Loss 0.00461356600126\n",
      "Epoch 9::Minibatch 881::LR 0.0815384615385 --> Loss 0.00422180891037\n",
      "Epoch 9::Minibatch 882::LR 0.0815384615385 --> Loss 0.00202698111534\n",
      "Epoch 9::Minibatch 883::LR 0.0815384615385 --> Loss 0.00336614926656\n",
      "Epoch 9::Minibatch 884::LR 0.0815384615385 --> Loss 0.00269522329171\n",
      "Epoch 9::Minibatch 885::LR 0.0815384615385 --> Loss 0.00243681589762\n",
      "Epoch 9::Minibatch 886::LR 0.0815384615385 --> Loss 0.000562031070391\n",
      "Epoch 9::Minibatch 887::LR 0.0815384615385 --> Loss 0.00526028235753\n",
      "Epoch 9::Minibatch 888::LR 0.0815384615385 --> Loss 0.00270133157571\n",
      "Epoch 9::Minibatch 889::LR 0.0815384615385 --> Loss 0.00303726196289\n",
      "Epoch 9::Minibatch 890::LR 0.0815384615385 --> Loss 0.00439817508062\n",
      "Epoch 9::Minibatch 891::LR 0.0815384615385 --> Loss 0.00199298759302\n",
      "Epoch 9::Minibatch 892::LR 0.0815384615385 --> Loss 0.000974283715089\n",
      "Epoch 9::Minibatch 893::LR 0.0815384615385 --> Loss 0.00256440162659\n",
      "Epoch 9::Minibatch 894::LR 0.0815384615385 --> Loss 0.00228845914205\n",
      "Epoch 9::Minibatch 895::LR 0.0815384615385 --> Loss 0.00246947725614\n",
      "Epoch 9::Minibatch 896::LR 0.0815384615385 --> Loss 0.00135849366585\n",
      "Epoch 9::Minibatch 897::LR 0.0815384615385 --> Loss 0.000794027795394\n",
      "Epoch 9::Minibatch 898::LR 0.0815384615385 --> Loss 0.00223448952039\n",
      "Epoch 9::Minibatch 899::LR 0.0815384615385 --> Loss 0.00249998688698\n",
      "Epoch 9::Minibatch 900::LR 0.0815384615385 --> Loss 0.00332289636135\n",
      "Epoch 9::Minibatch 901::LR 0.0815384615385 --> Loss 0.000649200677872\n",
      "Epoch 9::Minibatch 902::LR 0.0815384615385 --> Loss 0.00145240068436\n",
      "Epoch 9::Minibatch 903::LR 0.0815384615385 --> Loss 0.00259376923243\n",
      "Epoch 9::Minibatch 904::LR 0.0815384615385 --> Loss 0.00205368161201\n",
      "Epoch 9::Minibatch 905::LR 0.0815384615385 --> Loss 0.00146580308676\n",
      "Epoch 9::Minibatch 906::LR 0.0815384615385 --> Loss 0.00113751014074\n",
      "Epoch 9::Minibatch 907::LR 0.0815384615385 --> Loss 0.00159592489401\n",
      "Epoch 9::Minibatch 908::LR 0.0815384615385 --> Loss 0.00220310807228\n",
      "Epoch 9::Minibatch 909::LR 0.0815384615385 --> Loss 0.00201851010323\n",
      "Epoch 9::Minibatch 910::LR 0.0815384615385 --> Loss 0.000857084393501\n",
      "Epoch 9::Minibatch 911::LR 0.0815384615385 --> Loss 0.0012417319417\n",
      "Epoch 9::Minibatch 912::LR 0.0815384615385 --> Loss 0.00197483241558\n",
      "Epoch 9::Minibatch 913::LR 0.0815384615385 --> Loss 0.00211215337118\n",
      "Epoch 9::Minibatch 914::LR 0.0815384615385 --> Loss 0.00117034008106\n",
      "Epoch 9::Minibatch 915::LR 0.0815384615385 --> Loss 0.000514000256856\n",
      "Epoch 9::Minibatch 916::LR 0.0815384615385 --> Loss 0.00239496827126\n",
      "Epoch 9::Minibatch 917::LR 0.0815384615385 --> Loss 0.00405129472415\n",
      "Epoch 9::Minibatch 918::LR 0.0815384615385 --> Loss 0.00720810254415\n",
      "Epoch 9::Minibatch 919::LR 0.0815384615385 --> Loss 0.000648743460576\n",
      "Epoch 9::Minibatch 920::LR 0.0815384615385 --> Loss 0.0104817207654\n",
      "Epoch 9::Minibatch 921::LR 0.0815384615385 --> Loss 0.0029650135835\n",
      "Epoch 9::Minibatch 922::LR 0.0815384615385 --> Loss 0.00321923196316\n",
      "Epoch 9::Minibatch 923::LR 0.0815384615385 --> Loss 0.00167940914631\n",
      "Epoch 9::Minibatch 924::LR 0.0815384615385 --> Loss 0.00364866693815\n",
      "Epoch 9::Minibatch 925::LR 0.0815384615385 --> Loss 0.00284252385298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9::Minibatch 926::LR 0.0815384615385 --> Loss 0.00554783423742\n",
      "Epoch 9::Minibatch 927::LR 0.0815384615385 --> Loss 0.00906812588374\n",
      "Epoch 9::Minibatch 928::LR 0.0815384615385 --> Loss 0.00691399971644\n",
      "Epoch 9::Minibatch 929::LR 0.0815384615385 --> Loss 0.00851091066996\n",
      "Epoch 9::Minibatch 930::LR 0.0815384615385 --> Loss 0.00867685715357\n",
      "Epoch 9::Minibatch 931::LR 0.0815384615385 --> Loss 0.00399004340172\n",
      "Epoch 9::Minibatch 932::LR 0.0815384615385 --> Loss 0.0087348818779\n",
      "Epoch 9::Minibatch 933::LR 0.0815384615385 --> Loss 0.00440187772115\n",
      "Epoch 9::Minibatch 934::LR 0.0815384615385 --> Loss 0.0057575126489\n",
      "Epoch 9::Minibatch 935::LR 0.0815384615385 --> Loss 0.00769128481547\n",
      "Epoch 9::Minibatch 936::LR 0.0815384615385 --> Loss 0.00199782729149\n",
      "Epoch 9::Minibatch 937::LR 0.0815384615385 --> Loss 0.00409959673882\n",
      "Epoch 9::Minibatch 938::LR 0.0815384615385 --> Loss 0.00389655987422\n",
      "Epoch 9::Minibatch 939::LR 0.0815384615385 --> Loss 0.00398271004359\n",
      "Epoch 9::Minibatch 940::LR 0.0815384615385 --> Loss 0.00118275413911\n",
      "Epoch 9::Minibatch 941::LR 0.0815384615385 --> Loss 0.000966991980871\n",
      "Epoch 9::Minibatch 942::LR 0.0815384615385 --> Loss 0.00251342554887\n",
      "Epoch 9::Minibatch 943::LR 0.0815384615385 --> Loss 0.00345661918322\n",
      "Epoch 9::Minibatch 944::LR 0.0815384615385 --> Loss 0.00254246075948\n",
      "Epoch 9::Minibatch 945::LR 0.0815384615385 --> Loss 0.00151595562696\n",
      "Epoch 9::Minibatch 946::LR 0.0815384615385 --> Loss 0.00372846444448\n",
      "Epoch 9::Minibatch 947::LR 0.0815384615385 --> Loss 0.00327136377494\n",
      "Epoch 9::Minibatch 948::LR 0.0815384615385 --> Loss 0.00584234038989\n",
      "Epoch 9::Minibatch 949::LR 0.0815384615385 --> Loss 0.0020834894975\n",
      "Epoch 9::Minibatch 950::LR 0.0815384615385 --> Loss 0.000762510250012\n",
      "Epoch 9::Minibatch 951::LR 0.0815384615385 --> Loss 0.00345980842908\n",
      "Epoch 9::Minibatch 952::LR 0.0815384615385 --> Loss 0.002574685812\n",
      "Epoch 9::Minibatch 953::LR 0.0815384615385 --> Loss 0.00140211174885\n",
      "Epoch 9::Minibatch 954::LR 0.0815384615385 --> Loss 0.000983645021915\n",
      "Epoch 9::Minibatch 955::LR 0.0815384615385 --> Loss 0.00261084616184\n",
      "Epoch 9::Minibatch 956::LR 0.0815384615385 --> Loss 0.00433847030004\n",
      "Epoch 9::Minibatch 957::LR 0.0815384615385 --> Loss 0.00201377809048\n",
      "Epoch 9::Minibatch 958::LR 0.0815384615385 --> Loss 0.00261873404185\n",
      "Epoch 9::Minibatch 959::LR 0.0815384615385 --> Loss 0.00321573535601\n",
      "Epoch 9::Minibatch 960::LR 0.0815384615385 --> Loss 0.00707919756571\n",
      "Epoch 9::Minibatch 961::LR 0.0815384615385 --> Loss 0.00359303633372\n",
      "Epoch 9::Minibatch 962::LR 0.0815384615385 --> Loss 0.00321111718814\n",
      "Epoch 9::Minibatch 963::LR 0.0815384615385 --> Loss 0.00115235030651\n",
      "Epoch 9::Minibatch 964::LR 0.0815384615385 --> Loss 0.00249263723691\n",
      "Epoch 9::Minibatch 965::LR 0.0815384615385 --> Loss 0.00805198987325\n",
      "Epoch 9::Minibatch 966::LR 0.0815384615385 --> Loss 0.00556608597438\n",
      "Epoch 9::Minibatch 967::LR 0.0815384615385 --> Loss 0.00181791583697\n",
      "Epoch 9::Minibatch 968::LR 0.0815384615385 --> Loss 0.00159872462352\n",
      "Epoch 9::Minibatch 969::LR 0.0815384615385 --> Loss 0.00761045614878\n",
      "Epoch 9::Minibatch 970::LR 0.0815384615385 --> Loss 0.0063650461038\n",
      "Epoch 9::Minibatch 971::LR 0.0815384615385 --> Loss 0.00387801567713\n",
      "Epoch 9::Minibatch 972::LR 0.0815384615385 --> Loss 0.00909812927246\n",
      "Epoch 9::Minibatch 973::LR 0.0815384615385 --> Loss 0.00936873912811\n",
      "Epoch 9::Minibatch 974::LR 0.0815384615385 --> Loss 0.00682567755381\n",
      "Epoch 9::Minibatch 975::LR 0.0815384615385 --> Loss 0.00493849158287\n",
      "Epoch 9::Minibatch 976::LR 0.0815384615385 --> Loss 0.00448300361633\n",
      "Epoch 9::Minibatch 977::LR 0.0815384615385 --> Loss 0.00452445626259\n",
      "Epoch 9::Minibatch 978::LR 0.0815384615385 --> Loss 0.00445785363515\n",
      "Epoch 9::Minibatch 979::LR 0.0815384615385 --> Loss 0.00444841861725\n",
      "Epoch 9::Minibatch 980::LR 0.0815384615385 --> Loss 0.00422394951185\n",
      "Epoch 9::Minibatch 981::LR 0.0815384615385 --> Loss 0.00552261988322\n",
      "Epoch 9::Minibatch 982::LR 0.0815384615385 --> Loss 0.00743245919545\n",
      "Epoch 9::Minibatch 983::LR 0.0815384615385 --> Loss 0.00337862531344\n",
      "Epoch 9::Minibatch 984::LR 0.0815384615385 --> Loss 0.00312473833561\n",
      "Epoch 9::Minibatch 985::LR 0.0815384615385 --> Loss 0.00484294374784\n",
      "Epoch 9::Minibatch 986::LR 0.0815384615385 --> Loss 0.00439371943474\n",
      "Epoch 9::Minibatch 987::LR 0.0815384615385 --> Loss 0.00471207737923\n",
      "Epoch 9::Minibatch 988::LR 0.0815384615385 --> Loss 0.00365830143293\n",
      "Epoch 9::Minibatch 989::LR 0.0815384615385 --> Loss 0.00363967021306\n",
      "Epoch 9::Minibatch 990::LR 0.0815384615385 --> Loss 0.00346906304359\n",
      "Epoch 9::Minibatch 991::LR 0.0815384615385 --> Loss 0.0019186659654\n",
      "Epoch 9::Minibatch 992::LR 0.0815384615385 --> Loss 0.00211631596088\n",
      "Epoch 9::Minibatch 993::LR 0.0815384615385 --> Loss 0.0036316315333\n",
      "Epoch 9::Minibatch 994::LR 0.0815384615385 --> Loss 0.00217815498511\n",
      "Epoch 9::Minibatch 995::LR 0.0815384615385 --> Loss 0.000958186487357\n",
      "Epoch 9::Minibatch 996::LR 0.0815384615385 --> Loss 0.00341946641604\n",
      "Epoch 9::Minibatch 997::LR 0.0815384615385 --> Loss 0.0021340717872\n",
      "Epoch 9::Minibatch 998::LR 0.0815384615385 --> Loss 0.0023595503966\n",
      "Epoch 9::Minibatch 999::LR 0.0815384615385 --> Loss 0.0019214651982\n",
      "Epoch 9::Minibatch 1000::LR 0.0815384615385 --> Loss 0.00221673389276\n",
      "Epoch 9::Minibatch 1001::LR 0.0815384615385 --> Loss 0.00186550001303\n",
      "Epoch 9::Minibatch 1002::LR 0.0815384615385 --> Loss 0.00390904068947\n",
      "Epoch 9::Minibatch 1003::LR 0.0815384615385 --> Loss 0.0043657942613\n",
      "Epoch 9::Minibatch 1004::LR 0.0815384615385 --> Loss 0.00105647375186\n",
      "Epoch 9::Minibatch 1005::LR 0.0815384615385 --> Loss 0.00484924713771\n",
      "Epoch 9::Minibatch 1006::LR 0.0815384615385 --> Loss 0.00337661822637\n",
      "Epoch 9::Minibatch 1007::LR 0.0815384615385 --> Loss 0.00324670255184\n",
      "Epoch 9::Minibatch 1008::LR 0.0815384615385 --> Loss 0.00098634749651\n",
      "Epoch 9::Minibatch 1009::LR 0.0815384615385 --> Loss 0.00197875956694\n",
      "Epoch 9::Minibatch 1010::LR 0.0815384615385 --> Loss 0.00155521730582\n",
      "Epoch 9::Minibatch 1011::LR 0.0815384615385 --> Loss 0.00297261675199\n",
      "Epoch 9::Minibatch 1012::LR 0.0815384615385 --> Loss 0.00194862822692\n",
      "Epoch 9::Minibatch 1013::LR 0.0815384615385 --> Loss 0.00511140147845\n",
      "Epoch 9::Minibatch 1014::LR 0.0815384615385 --> Loss 0.00494794448217\n",
      "Epoch 9::Minibatch 1015::LR 0.0815384615385 --> Loss 0.00187366843224\n",
      "Epoch 9::Minibatch 1016::LR 0.0815384615385 --> Loss 0.00550874193509\n",
      "Epoch 9::Minibatch 1017::LR 0.0815384615385 --> Loss 0.00308696111043\n",
      "Epoch 9::Minibatch 1018::LR 0.0815384615385 --> Loss 0.00338855862617\n",
      "Epoch 9::Minibatch 1019::LR 0.0815384615385 --> Loss 0.00252330978711\n",
      "Epoch 9::Minibatch 1020::LR 0.0815384615385 --> Loss 0.00246660629908\n",
      "Epoch 9::Minibatch 1021::LR 0.0815384615385 --> Loss 0.00234622915586\n",
      "Epoch 9::Minibatch 1022::LR 0.0815384615385 --> Loss 0.0018195805947\n",
      "Epoch 9::Minibatch 1023::LR 0.0815384615385 --> Loss 0.00148768951495\n",
      "Epoch 9::Minibatch 1024::LR 0.0815384615385 --> Loss 0.00142811338107\n",
      "Epoch 9::Minibatch 1025::LR 0.0815384615385 --> Loss 0.00156508604685\n",
      "Epoch 9::Minibatch 1026::LR 0.0815384615385 --> Loss 0.00102017174164\n",
      "Epoch 9::Minibatch 1027::LR 0.0815384615385 --> Loss 0.00115670055151\n",
      "Epoch 9::Minibatch 1028::LR 0.0815384615385 --> Loss 0.000907949010531\n",
      "Epoch 9::Minibatch 1029::LR 0.0815384615385 --> Loss 0.000865049461524\n",
      "Epoch 9::Minibatch 1030::LR 0.0815384615385 --> Loss 0.00106211880843\n",
      "Epoch 9::Minibatch 1031::LR 0.0815384615385 --> Loss 0.000833561122417\n",
      "Epoch 9::Minibatch 1032::LR 0.0815384615385 --> Loss 0.000824926644564\n",
      "Epoch 9::Minibatch 1033::LR 0.0815384615385 --> Loss 0.00069600045681\n",
      "Epoch 9::Minibatch 1034::LR 0.0815384615385 --> Loss 0.000706842988729\n",
      "Epoch 9::Minibatch 1035::LR 0.0815384615385 --> Loss 0.00055560896794\n",
      "Epoch 9::Minibatch 1036::LR 0.0815384615385 --> Loss 0.000433924595515\n",
      "Epoch 9::Minibatch 1037::LR 0.0815384615385 --> Loss 0.000596234897772\n",
      "Epoch 9::Minibatch 1038::LR 0.0815384615385 --> Loss 0.00135943949223\n",
      "Epoch 9::Minibatch 1039::LR 0.0815384615385 --> Loss 0.00112922370434\n",
      "Epoch 9::Minibatch 1040::LR 0.0815384615385 --> Loss 0.00051923195521\n",
      "Epoch 9::Minibatch 1041::LR 0.0815384615385 --> Loss 0.00065913716952\n",
      "Epoch 10::Minibatch 1::LR 0.0792307692308 --> Loss 0.0103960951169\n",
      "Epoch 10::Minibatch 2::LR 0.0792307692308 --> Loss 0.00650827805201\n",
      "Epoch 10::Minibatch 3::LR 0.0792307692308 --> Loss 0.0044577729702\n",
      "Epoch 10::Minibatch 4::LR 0.0792307692308 --> Loss 0.00446424086889\n",
      "Epoch 10::Minibatch 5::LR 0.0792307692308 --> Loss 0.00476359128952\n",
      "Epoch 10::Minibatch 6::LR 0.0792307692308 --> Loss 0.00251859823863\n",
      "Epoch 10::Minibatch 7::LR 0.0792307692308 --> Loss 0.00778158505758\n",
      "Epoch 10::Minibatch 8::LR 0.0792307692308 --> Loss 0.00758989651998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 9::LR 0.0792307692308 --> Loss 0.00550006985664\n",
      "Epoch 10::Minibatch 10::LR 0.0792307692308 --> Loss 0.00302488088608\n",
      "Epoch 10::Minibatch 11::LR 0.0792307692308 --> Loss 0.00252672433853\n",
      "Epoch 10::Minibatch 12::LR 0.0792307692308 --> Loss 0.00345253189405\n",
      "Epoch 10::Minibatch 13::LR 0.0792307692308 --> Loss 0.00516700148582\n",
      "Epoch 10::Minibatch 14::LR 0.0792307692308 --> Loss 0.00488127112389\n",
      "Epoch 10::Minibatch 15::LR 0.0792307692308 --> Loss 0.00383753021558\n",
      "Epoch 10::Minibatch 16::LR 0.0792307692308 --> Loss 0.000908660193284\n",
      "Epoch 10::Minibatch 17::LR 0.0792307692308 --> Loss 0.00298699557781\n",
      "Epoch 10::Minibatch 18::LR 0.0792307692308 --> Loss 0.00241588870684\n",
      "Epoch 10::Minibatch 19::LR 0.0792307692308 --> Loss 0.00106275955836\n",
      "Epoch 10::Minibatch 20::LR 0.0792307692308 --> Loss 0.00148872683446\n",
      "Epoch 10::Minibatch 21::LR 0.0792307692308 --> Loss 0.00313005765279\n",
      "Epoch 10::Minibatch 22::LR 0.0792307692308 --> Loss 0.00239651461442\n",
      "Epoch 10::Minibatch 23::LR 0.0792307692308 --> Loss 0.00079317505161\n",
      "Epoch 10::Minibatch 24::LR 0.0792307692308 --> Loss 0.000370628386736\n",
      "Epoch 10::Minibatch 25::LR 0.0792307692308 --> Loss 0.00111719310284\n",
      "Epoch 10::Minibatch 26::LR 0.0792307692308 --> Loss 0.00128958334525\n",
      "Epoch 10::Minibatch 27::LR 0.0792307692308 --> Loss 0.000937972664833\n",
      "Epoch 10::Minibatch 28::LR 0.0792307692308 --> Loss 0.000366896664103\n",
      "Epoch 10::Minibatch 29::LR 0.0792307692308 --> Loss 0.000352240204811\n",
      "Epoch 10::Minibatch 30::LR 0.0792307692308 --> Loss 0.000832491020362\n",
      "Epoch 10::Minibatch 31::LR 0.0792307692308 --> Loss 0.00129204332829\n",
      "Epoch 10::Minibatch 32::LR 0.0792307692308 --> Loss 0.00126188079516\n",
      "Epoch 10::Minibatch 33::LR 0.0792307692308 --> Loss 0.000783432225386\n",
      "Epoch 10::Minibatch 34::LR 0.0792307692308 --> Loss 0.00262135028839\n",
      "Epoch 10::Minibatch 35::LR 0.0792307692308 --> Loss 0.00422933022181\n",
      "Epoch 10::Minibatch 36::LR 0.0792307692308 --> Loss 0.00213880578677\n",
      "Epoch 10::Minibatch 37::LR 0.0792307692308 --> Loss 0.000607698659102\n",
      "Epoch 10::Minibatch 38::LR 0.0792307692308 --> Loss 0.000797588477532\n",
      "Epoch 10::Minibatch 39::LR 0.0792307692308 --> Loss 0.00256772001584\n",
      "Epoch 10::Minibatch 40::LR 0.0792307692308 --> Loss 0.00363347371419\n",
      "Epoch 10::Minibatch 41::LR 0.0792307692308 --> Loss 0.00335396965345\n",
      "Epoch 10::Minibatch 42::LR 0.0792307692308 --> Loss 0.00634666045507\n",
      "Epoch 10::Minibatch 43::LR 0.0792307692308 --> Loss 0.00187211791674\n",
      "Epoch 10::Minibatch 44::LR 0.0792307692308 --> Loss 0.00312709331512\n",
      "Epoch 10::Minibatch 45::LR 0.0792307692308 --> Loss 0.00261717895667\n",
      "Epoch 10::Minibatch 46::LR 0.0792307692308 --> Loss 0.00371331254641\n",
      "Epoch 10::Minibatch 47::LR 0.0792307692308 --> Loss 0.00529399037361\n",
      "Epoch 10::Minibatch 48::LR 0.0792307692308 --> Loss 0.00630574742953\n",
      "Epoch 10::Minibatch 49::LR 0.0792307692308 --> Loss 0.00625608801842\n",
      "Epoch 10::Minibatch 50::LR 0.0792307692308 --> Loss 0.005922823747\n",
      "Epoch 10::Minibatch 51::LR 0.0792307692308 --> Loss 0.00943941990534\n",
      "Epoch 10::Minibatch 52::LR 0.0792307692308 --> Loss 0.00363287528356\n",
      "Epoch 10::Minibatch 53::LR 0.0792307692308 --> Loss 0.00356838027636\n",
      "Epoch 10::Minibatch 54::LR 0.0792307692308 --> Loss 0.00402835766474\n",
      "Epoch 10::Minibatch 55::LR 0.0792307692308 --> Loss 0.00107676883539\n",
      "Epoch 10::Minibatch 56::LR 0.0792307692308 --> Loss 0.00287557661533\n",
      "Epoch 10::Minibatch 57::LR 0.0792307692308 --> Loss 0.00640394965808\n",
      "Epoch 10::Minibatch 58::LR 0.0792307692308 --> Loss 0.00352589249611\n",
      "Epoch 10::Minibatch 59::LR 0.0792307692308 --> Loss 0.00293358425299\n",
      "Epoch 10::Minibatch 60::LR 0.0792307692308 --> Loss 0.00250577112039\n",
      "Epoch 10::Minibatch 61::LR 0.0792307692308 --> Loss 0.00107327113549\n",
      "Epoch 10::Minibatch 62::LR 0.0792307692308 --> Loss 0.00368123928706\n",
      "Epoch 10::Minibatch 63::LR 0.0792307692308 --> Loss 0.00235143323739\n",
      "Epoch 10::Minibatch 64::LR 0.0792307692308 --> Loss 0.00105178723733\n",
      "Epoch 10::Minibatch 65::LR 0.0792307692308 --> Loss 0.00250281572342\n",
      "Epoch 10::Minibatch 66::LR 0.0792307692308 --> Loss 0.00310508608818\n",
      "Epoch 10::Minibatch 67::LR 0.0792307692308 --> Loss 0.00295558929443\n",
      "Epoch 10::Minibatch 68::LR 0.0792307692308 --> Loss 0.00209178407987\n",
      "Epoch 10::Minibatch 69::LR 0.0792307692308 --> Loss 0.00412410736084\n",
      "Epoch 10::Minibatch 70::LR 0.0792307692308 --> Loss 0.00352877298991\n",
      "Epoch 10::Minibatch 71::LR 0.0792307692308 --> Loss 0.00241351207097\n",
      "Epoch 10::Minibatch 72::LR 0.0792307692308 --> Loss 0.000575379083554\n",
      "Epoch 10::Minibatch 73::LR 0.0792307692308 --> Loss 0.0039735809962\n",
      "Epoch 10::Minibatch 74::LR 0.0792307692308 --> Loss 0.00424417614937\n",
      "Epoch 10::Minibatch 75::LR 0.0792307692308 --> Loss 0.0028270761172\n",
      "Epoch 10::Minibatch 76::LR 0.0792307692308 --> Loss 0.000728616168102\n",
      "Epoch 10::Minibatch 77::LR 0.0792307692308 --> Loss 0.00439060489337\n",
      "Epoch 10::Minibatch 78::LR 0.0792307692308 --> Loss 0.00398395578067\n",
      "Epoch 10::Minibatch 79::LR 0.0792307692308 --> Loss 0.00225155413151\n",
      "Epoch 10::Minibatch 80::LR 0.0792307692308 --> Loss 0.00361134449641\n",
      "Epoch 10::Minibatch 81::LR 0.0792307692308 --> Loss 0.00313765962919\n",
      "Epoch 10::Minibatch 82::LR 0.0792307692308 --> Loss 0.00212050278982\n",
      "Epoch 10::Minibatch 83::LR 0.0792307692308 --> Loss 0.00526445150375\n",
      "Epoch 10::Minibatch 84::LR 0.0792307692308 --> Loss 0.0021767282486\n",
      "Epoch 10::Minibatch 85::LR 0.0792307692308 --> Loss 0.00290490070979\n",
      "Epoch 10::Minibatch 86::LR 0.0792307692308 --> Loss 0.00242626786232\n",
      "Epoch 10::Minibatch 87::LR 0.0792307692308 --> Loss 0.00270029127598\n",
      "Epoch 10::Minibatch 88::LR 0.0792307692308 --> Loss 0.00199631869793\n",
      "Epoch 10::Minibatch 89::LR 0.0792307692308 --> Loss 0.00247994144758\n",
      "Epoch 10::Minibatch 90::LR 0.0792307692308 --> Loss 0.00135209600131\n",
      "Epoch 10::Minibatch 91::LR 0.0792307692308 --> Loss 0.00111644168695\n",
      "Epoch 10::Minibatch 92::LR 0.0792307692308 --> Loss 0.00277316868305\n",
      "Epoch 10::Minibatch 93::LR 0.0792307692308 --> Loss 0.00190418879191\n",
      "Epoch 10::Minibatch 94::LR 0.0792307692308 --> Loss 0.00188667595387\n",
      "Epoch 10::Minibatch 95::LR 0.0792307692308 --> Loss 0.00177121023337\n",
      "Epoch 10::Minibatch 96::LR 0.0792307692308 --> Loss 0.0063340485096\n",
      "Epoch 10::Minibatch 97::LR 0.0792307692308 --> Loss 0.00329516331355\n",
      "Epoch 10::Minibatch 98::LR 0.0792307692308 --> Loss 0.000972200830777\n",
      "Epoch 10::Minibatch 99::LR 0.0792307692308 --> Loss 0.00130684773127\n",
      "Epoch 10::Minibatch 100::LR 0.0792307692308 --> Loss 0.00568909565608\n",
      "Epoch 10::Minibatch 101::LR 0.0792307692308 --> Loss 0.00102038383484\n",
      "Epoch 10::Minibatch 102::LR 0.0792307692308 --> Loss 0.00379674593608\n",
      "Epoch 10::Minibatch 103::LR 0.0792307692308 --> Loss 0.00405482212702\n",
      "Epoch 10::Minibatch 104::LR 0.0792307692308 --> Loss 0.00289763649305\n",
      "Epoch 10::Minibatch 105::LR 0.0792307692308 --> Loss 0.00338789621989\n",
      "Epoch 10::Minibatch 106::LR 0.0792307692308 --> Loss 0.0185981877645\n",
      "Epoch 10::Minibatch 107::LR 0.0792307692308 --> Loss 0.00489637414614\n",
      "Epoch 10::Minibatch 108::LR 0.0792307692308 --> Loss 0.00126940319935\n",
      "Epoch 10::Minibatch 109::LR 0.0792307692308 --> Loss 0.00465244293213\n",
      "Epoch 10::Minibatch 110::LR 0.0792307692308 --> Loss 0.00265429099401\n",
      "Epoch 10::Minibatch 111::LR 0.0792307692308 --> Loss 0.00117731710275\n",
      "Epoch 10::Minibatch 112::LR 0.0792307692308 --> Loss 0.0038508673509\n",
      "Epoch 10::Minibatch 113::LR 0.0792307692308 --> Loss 0.00297094742457\n",
      "Epoch 10::Minibatch 114::LR 0.0792307692308 --> Loss 0.00165358761946\n",
      "Epoch 10::Minibatch 115::LR 0.0792307692308 --> Loss 0.0015686460336\n",
      "Epoch 10::Minibatch 116::LR 0.0792307692308 --> Loss 0.00305160442988\n",
      "Epoch 10::Minibatch 117::LR 0.0792307692308 --> Loss 0.00380541125933\n",
      "Epoch 10::Minibatch 118::LR 0.0792307692308 --> Loss 0.00706298748652\n",
      "Epoch 10::Minibatch 119::LR 0.0792307692308 --> Loss 0.000828881065051\n",
      "Epoch 10::Minibatch 120::LR 0.0792307692308 --> Loss 0.00206201692422\n",
      "Epoch 10::Minibatch 121::LR 0.0792307692308 --> Loss 0.00303921798865\n",
      "Epoch 10::Minibatch 122::LR 0.0792307692308 --> Loss 0.00378175298373\n",
      "Epoch 10::Minibatch 123::LR 0.0792307692308 --> Loss 0.00139637798071\n",
      "Epoch 10::Minibatch 124::LR 0.0792307692308 --> Loss 0.00301456570625\n",
      "Epoch 10::Minibatch 125::LR 0.0792307692308 --> Loss 0.00489436348279\n",
      "Epoch 10::Minibatch 126::LR 0.0792307692308 --> Loss 0.00295083979766\n",
      "Epoch 10::Minibatch 127::LR 0.0792307692308 --> Loss 0.00446694215139\n",
      "Epoch 10::Minibatch 128::LR 0.0792307692308 --> Loss 0.00375379363696\n",
      "Epoch 10::Minibatch 129::LR 0.0792307692308 --> Loss 0.00296853621801\n",
      "Epoch 10::Minibatch 130::LR 0.0792307692308 --> Loss 0.00442604700724\n",
      "Epoch 10::Minibatch 131::LR 0.0792307692308 --> Loss 0.00194723765055\n",
      "Epoch 10::Minibatch 132::LR 0.0792307692308 --> Loss 0.00336325844129\n",
      "Epoch 10::Minibatch 133::LR 0.0792307692308 --> Loss 0.00324025332928\n",
      "Epoch 10::Minibatch 134::LR 0.0792307692308 --> Loss 0.00265792191029\n",
      "Epoch 10::Minibatch 135::LR 0.0792307692308 --> Loss 0.00188315212727\n",
      "Epoch 10::Minibatch 136::LR 0.0792307692308 --> Loss 0.00296778738499\n",
      "Epoch 10::Minibatch 137::LR 0.0792307692308 --> Loss 0.0038465321064\n",
      "Epoch 10::Minibatch 138::LR 0.0792307692308 --> Loss 0.00142895768086\n",
      "Epoch 10::Minibatch 139::LR 0.0792307692308 --> Loss 0.00195259571075\n",
      "Epoch 10::Minibatch 140::LR 0.0792307692308 --> Loss 0.00250550866127\n",
      "Epoch 10::Minibatch 141::LR 0.0792307692308 --> Loss 0.00307136972745\n",
      "Epoch 10::Minibatch 142::LR 0.0792307692308 --> Loss 0.00317513465881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 143::LR 0.0792307692308 --> Loss 0.000684021462997\n",
      "Epoch 10::Minibatch 144::LR 0.0792307692308 --> Loss 0.00320611159007\n",
      "Epoch 10::Minibatch 145::LR 0.0792307692308 --> Loss 0.00443442702293\n",
      "Epoch 10::Minibatch 146::LR 0.0792307692308 --> Loss 0.00271465599537\n",
      "Epoch 10::Minibatch 147::LR 0.0792307692308 --> Loss 0.00187668542067\n",
      "Epoch 10::Minibatch 148::LR 0.0792307692308 --> Loss 0.00108509590228\n",
      "Epoch 10::Minibatch 149::LR 0.0792307692308 --> Loss 0.0028832924366\n",
      "Epoch 10::Minibatch 150::LR 0.0792307692308 --> Loss 0.0028302025795\n",
      "Epoch 10::Minibatch 151::LR 0.0792307692308 --> Loss 0.00429750045141\n",
      "Epoch 10::Minibatch 152::LR 0.0792307692308 --> Loss 0.000975681344668\n",
      "Epoch 10::Minibatch 153::LR 0.0792307692308 --> Loss 0.0019407504797\n",
      "Epoch 10::Minibatch 154::LR 0.0792307692308 --> Loss 0.00212313671907\n",
      "Epoch 10::Minibatch 155::LR 0.0792307692308 --> Loss 0.00491624077161\n",
      "Epoch 10::Minibatch 156::LR 0.0792307692308 --> Loss 0.00248529473941\n",
      "Epoch 10::Minibatch 157::LR 0.0792307692308 --> Loss 0.00072889238596\n",
      "Epoch 10::Minibatch 158::LR 0.0792307692308 --> Loss 0.00307093203068\n",
      "Epoch 10::Minibatch 159::LR 0.0792307692308 --> Loss 0.00282297809919\n",
      "Epoch 10::Minibatch 160::LR 0.0792307692308 --> Loss 0.00271816293399\n",
      "Epoch 10::Minibatch 161::LR 0.0792307692308 --> Loss 0.00107868452867\n",
      "Epoch 10::Minibatch 162::LR 0.0792307692308 --> Loss 0.00361109256744\n",
      "Epoch 10::Minibatch 163::LR 0.0792307692308 --> Loss 0.00246330976486\n",
      "Epoch 10::Minibatch 164::LR 0.0792307692308 --> Loss 0.00252836326758\n",
      "Epoch 10::Minibatch 165::LR 0.0792307692308 --> Loss 0.000576664209366\n",
      "Epoch 10::Minibatch 166::LR 0.0792307692308 --> Loss 0.00186257600784\n",
      "Epoch 10::Minibatch 167::LR 0.0792307692308 --> Loss 0.00249295294285\n",
      "Epoch 10::Minibatch 168::LR 0.0792307692308 --> Loss 0.00225464125474\n",
      "Epoch 10::Minibatch 169::LR 0.0792307692308 --> Loss 0.00105773081382\n",
      "Epoch 10::Minibatch 170::LR 0.0792307692308 --> Loss 0.00103274752696\n",
      "Epoch 10::Minibatch 171::LR 0.0792307692308 --> Loss 0.0025787627697\n",
      "Epoch 10::Minibatch 172::LR 0.0792307692308 --> Loss 0.00485109090805\n",
      "Epoch 10::Minibatch 173::LR 0.0792307692308 --> Loss 0.00201568325361\n",
      "Epoch 10::Minibatch 174::LR 0.0792307692308 --> Loss 0.00110175291697\n",
      "Epoch 10::Minibatch 175::LR 0.0792307692308 --> Loss 0.00231169342995\n",
      "Epoch 10::Minibatch 176::LR 0.0792307692308 --> Loss 0.00340763807297\n",
      "Epoch 10::Minibatch 177::LR 0.0792307692308 --> Loss 0.00485081235568\n",
      "Epoch 10::Minibatch 178::LR 0.0792307692308 --> Loss 0.00173207104206\n",
      "Epoch 10::Minibatch 179::LR 0.0792307692308 --> Loss 0.0014396383365\n",
      "Epoch 10::Minibatch 180::LR 0.0792307692308 --> Loss 0.00375527222951\n",
      "Epoch 10::Minibatch 181::LR 0.0792307692308 --> Loss 0.00343930323919\n",
      "Epoch 10::Minibatch 182::LR 0.0792307692308 --> Loss 0.000864834189415\n",
      "Epoch 10::Minibatch 183::LR 0.0792307692308 --> Loss 0.00176705956459\n",
      "Epoch 10::Minibatch 184::LR 0.0792307692308 --> Loss 0.00342374165853\n",
      "Epoch 10::Minibatch 185::LR 0.0792307692308 --> Loss 0.00291386206945\n",
      "Epoch 10::Minibatch 186::LR 0.0792307692308 --> Loss 0.00103614618381\n",
      "Epoch 10::Minibatch 187::LR 0.0792307692308 --> Loss 0.00126790424188\n",
      "Epoch 10::Minibatch 188::LR 0.0792307692308 --> Loss 0.00417715032895\n",
      "Epoch 10::Minibatch 189::LR 0.0792307692308 --> Loss 0.00461299975713\n",
      "Epoch 10::Minibatch 190::LR 0.0792307692308 --> Loss 0.00234651605288\n",
      "Epoch 10::Minibatch 191::LR 0.0792307692308 --> Loss 0.000542708039284\n",
      "Epoch 10::Minibatch 192::LR 0.0792307692308 --> Loss 0.00268630007903\n",
      "Epoch 10::Minibatch 193::LR 0.0792307692308 --> Loss 0.00250613669554\n",
      "Epoch 10::Minibatch 194::LR 0.0792307692308 --> Loss 0.00184227108955\n",
      "Epoch 10::Minibatch 195::LR 0.0792307692308 --> Loss 0.000420661767324\n",
      "Epoch 10::Minibatch 196::LR 0.0792307692308 --> Loss 0.00122180908918\n",
      "Epoch 10::Minibatch 197::LR 0.0792307692308 --> Loss 0.00281467119853\n",
      "Epoch 10::Minibatch 198::LR 0.0792307692308 --> Loss 0.00219715376695\n",
      "Epoch 10::Minibatch 199::LR 0.0792307692308 --> Loss 0.000313188433647\n",
      "Epoch 10::Minibatch 200::LR 0.0792307692308 --> Loss 0.00213318010171\n",
      "Epoch 10::Minibatch 201::LR 0.0792307692308 --> Loss 0.00201855818431\n",
      "Epoch 10::Minibatch 202::LR 0.0792307692308 --> Loss 0.00195666531722\n",
      "Epoch 10::Minibatch 203::LR 0.0792307692308 --> Loss 0.00189373274644\n",
      "Epoch 10::Minibatch 204::LR 0.0792307692308 --> Loss 0.00161749362946\n",
      "Epoch 10::Minibatch 205::LR 0.0792307692308 --> Loss 0.00230292359988\n",
      "Epoch 10::Minibatch 206::LR 0.0792307692308 --> Loss 0.00728864431381\n",
      "Epoch 10::Minibatch 207::LR 0.0792307692308 --> Loss 0.00143946657578\n",
      "Epoch 10::Minibatch 208::LR 0.0792307692308 --> Loss 0.00121727198362\n",
      "Epoch 10::Minibatch 209::LR 0.0792307692308 --> Loss 0.00212951819102\n",
      "Epoch 10::Minibatch 210::LR 0.0792307692308 --> Loss 0.00199194590251\n",
      "Epoch 10::Minibatch 211::LR 0.0792307692308 --> Loss 0.00210259695848\n",
      "Epoch 10::Minibatch 212::LR 0.0792307692308 --> Loss 0.00429427226384\n",
      "Epoch 10::Minibatch 213::LR 0.0792307692308 --> Loss 0.00620101849238\n",
      "Epoch 10::Minibatch 214::LR 0.0792307692308 --> Loss 0.0104209796588\n",
      "Epoch 10::Minibatch 215::LR 0.0792307692308 --> Loss 0.00148497809966\n",
      "Epoch 10::Minibatch 216::LR 0.0792307692308 --> Loss 0.00557478149732\n",
      "Epoch 10::Minibatch 217::LR 0.0792307692308 --> Loss 0.00607864777247\n",
      "Epoch 10::Minibatch 218::LR 0.0792307692308 --> Loss 0.00410242358843\n",
      "Epoch 10::Minibatch 219::LR 0.0792307692308 --> Loss 0.00375996430715\n",
      "Epoch 10::Minibatch 220::LR 0.0792307692308 --> Loss 0.0046629969279\n",
      "Epoch 10::Minibatch 221::LR 0.0792307692308 --> Loss 0.00433854262034\n",
      "Epoch 10::Minibatch 222::LR 0.0792307692308 --> Loss 0.00337473988533\n",
      "Epoch 10::Minibatch 223::LR 0.0792307692308 --> Loss 0.00149401644866\n",
      "Epoch 10::Minibatch 224::LR 0.0792307692308 --> Loss 0.00194455961386\n",
      "Epoch 10::Minibatch 225::LR 0.0792307692308 --> Loss 0.00705422321955\n",
      "Epoch 10::Minibatch 226::LR 0.0792307692308 --> Loss 0.00387467225393\n",
      "Epoch 10::Minibatch 227::LR 0.0792307692308 --> Loss 0.00176258385181\n",
      "Epoch 10::Minibatch 228::LR 0.0792307692308 --> Loss 0.000869030753771\n",
      "Epoch 10::Minibatch 229::LR 0.0792307692308 --> Loss 0.00488723715146\n",
      "Epoch 10::Minibatch 230::LR 0.0792307692308 --> Loss 0.00410100420316\n",
      "Epoch 10::Minibatch 231::LR 0.0792307692308 --> Loss 0.00267410635948\n",
      "Epoch 10::Minibatch 232::LR 0.0792307692308 --> Loss 0.00133400907119\n",
      "Epoch 10::Minibatch 233::LR 0.0792307692308 --> Loss 0.00244641224543\n",
      "Epoch 10::Minibatch 234::LR 0.0792307692308 --> Loss 0.0065690211455\n",
      "Epoch 10::Minibatch 235::LR 0.0792307692308 --> Loss 0.00498546163241\n",
      "Epoch 10::Minibatch 236::LR 0.0792307692308 --> Loss 0.00187589983145\n",
      "Epoch 10::Minibatch 237::LR 0.0792307692308 --> Loss 0.000788534084956\n",
      "Epoch 10::Minibatch 238::LR 0.0792307692308 --> Loss 0.00346837600072\n",
      "Epoch 10::Minibatch 239::LR 0.0792307692308 --> Loss 0.00299189905326\n",
      "Epoch 10::Minibatch 240::LR 0.0792307692308 --> Loss 0.00327676514784\n",
      "Epoch 10::Minibatch 241::LR 0.0792307692308 --> Loss 0.00084050655365\n",
      "Epoch 10::Minibatch 242::LR 0.0792307692308 --> Loss 0.00734443346659\n",
      "Epoch 10::Minibatch 243::LR 0.0792307692308 --> Loss 0.00368757724762\n",
      "Epoch 10::Minibatch 244::LR 0.0792307692308 --> Loss 0.00308424373468\n",
      "Epoch 10::Minibatch 245::LR 0.0792307692308 --> Loss 0.000539976507425\n",
      "Epoch 10::Minibatch 246::LR 0.0792307692308 --> Loss 0.00217465559642\n",
      "Epoch 10::Minibatch 247::LR 0.0792307692308 --> Loss 0.0142700974147\n",
      "Epoch 10::Minibatch 248::LR 0.0792307692308 --> Loss 0.00473092317581\n",
      "Epoch 10::Minibatch 249::LR 0.0792307692308 --> Loss 0.00309321701527\n",
      "Epoch 10::Minibatch 250::LR 0.0792307692308 --> Loss 0.00298743108908\n",
      "Epoch 10::Minibatch 251::LR 0.0792307692308 --> Loss 0.00269726157188\n",
      "Epoch 10::Minibatch 252::LR 0.0792307692308 --> Loss 0.00201728582382\n",
      "Epoch 10::Minibatch 253::LR 0.0792307692308 --> Loss 0.00331596533457\n",
      "Epoch 10::Minibatch 254::LR 0.0792307692308 --> Loss 0.00545031428337\n",
      "Epoch 10::Minibatch 255::LR 0.0792307692308 --> Loss 0.00406057357788\n",
      "Epoch 10::Minibatch 256::LR 0.0792307692308 --> Loss 0.00189683973789\n",
      "Epoch 10::Minibatch 257::LR 0.0792307692308 --> Loss 0.00142928679784\n",
      "Epoch 10::Minibatch 258::LR 0.0792307692308 --> Loss 0.00369235356649\n",
      "Epoch 10::Minibatch 259::LR 0.0792307692308 --> Loss 0.00196464300156\n",
      "Epoch 10::Minibatch 260::LR 0.0792307692308 --> Loss 0.00198255439599\n",
      "Epoch 10::Minibatch 261::LR 0.0792307692308 --> Loss 0.00307323376338\n",
      "Epoch 10::Minibatch 262::LR 0.0792307692308 --> Loss 0.00205540537834\n",
      "Epoch 10::Minibatch 263::LR 0.0792307692308 --> Loss 0.00245725035667\n",
      "Epoch 10::Minibatch 264::LR 0.0792307692308 --> Loss 0.00375060717265\n",
      "Epoch 10::Minibatch 265::LR 0.0792307692308 --> Loss 0.0102586380641\n",
      "Epoch 10::Minibatch 266::LR 0.0792307692308 --> Loss 0.00113843888044\n",
      "Epoch 10::Minibatch 267::LR 0.0792307692308 --> Loss 0.0103472105662\n",
      "Epoch 10::Minibatch 268::LR 0.0792307692308 --> Loss 0.00135001977285\n",
      "Epoch 10::Minibatch 269::LR 0.0792307692308 --> Loss 0.00365651488304\n",
      "Epoch 10::Minibatch 270::LR 0.0792307692308 --> Loss 0.00642481644948\n",
      "Epoch 10::Minibatch 271::LR 0.0792307692308 --> Loss 0.00295192042987\n",
      "Epoch 10::Minibatch 272::LR 0.0792307692308 --> Loss 0.00407992362976\n",
      "Epoch 10::Minibatch 273::LR 0.0792307692308 --> Loss 0.00187381664912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 274::LR 0.0792307692308 --> Loss 0.00188248018424\n",
      "Epoch 10::Minibatch 275::LR 0.0792307692308 --> Loss 0.00282787839572\n",
      "Epoch 10::Minibatch 276::LR 0.0792307692308 --> Loss 0.00357026020686\n",
      "Epoch 10::Minibatch 277::LR 0.0792307692308 --> Loss 0.00111802279949\n",
      "Epoch 10::Minibatch 278::LR 0.0792307692308 --> Loss 0.00271944761276\n",
      "Epoch 10::Minibatch 279::LR 0.0792307692308 --> Loss 0.00257323503494\n",
      "Epoch 10::Minibatch 280::LR 0.0792307692308 --> Loss 0.00223883966605\n",
      "Epoch 10::Minibatch 281::LR 0.0792307692308 --> Loss 0.00141878763835\n",
      "Epoch 10::Minibatch 282::LR 0.0792307692308 --> Loss 0.00232360839844\n",
      "Epoch 10::Minibatch 283::LR 0.0792307692308 --> Loss 0.00229280809561\n",
      "Epoch 10::Minibatch 284::LR 0.0792307692308 --> Loss 0.00183173437913\n",
      "Epoch 10::Minibatch 285::LR 0.0792307692308 --> Loss 0.00127598851919\n",
      "Epoch 10::Minibatch 286::LR 0.0792307692308 --> Loss 0.00221034367879\n",
      "Epoch 10::Minibatch 287::LR 0.0792307692308 --> Loss 0.00213435530663\n",
      "Epoch 10::Minibatch 288::LR 0.0792307692308 --> Loss 0.00115279972553\n",
      "Epoch 10::Minibatch 289::LR 0.0792307692308 --> Loss 0.00158261299133\n",
      "Epoch 10::Minibatch 290::LR 0.0792307692308 --> Loss 0.00198357264201\n",
      "Epoch 10::Minibatch 291::LR 0.0792307692308 --> Loss 0.00177863955498\n",
      "Epoch 10::Minibatch 292::LR 0.0792307692308 --> Loss 0.000638842185338\n",
      "Epoch 10::Minibatch 293::LR 0.0792307692308 --> Loss 0.0014918483297\n",
      "Epoch 10::Minibatch 294::LR 0.0792307692308 --> Loss 0.00157357364893\n",
      "Epoch 10::Minibatch 295::LR 0.0792307692308 --> Loss 0.00184845765432\n",
      "Epoch 10::Minibatch 296::LR 0.0792307692308 --> Loss 0.00160172015429\n",
      "Epoch 10::Minibatch 297::LR 0.0792307692308 --> Loss 0.00140164613724\n",
      "Epoch 10::Minibatch 298::LR 0.0792307692308 --> Loss 0.00138012250264\n",
      "Epoch 10::Minibatch 299::LR 0.0792307692308 --> Loss 0.000821288029353\n",
      "Epoch 10::Minibatch 300::LR 0.0792307692308 --> Loss 0.00292449692885\n",
      "Epoch 10::Minibatch 301::LR 0.0792307692308 --> Loss 0.00282283862432\n",
      "Epoch 10::Minibatch 302::LR 0.0792307692308 --> Loss 0.00263694365819\n",
      "Epoch 10::Minibatch 303::LR 0.0792307692308 --> Loss 0.000895322859287\n",
      "Epoch 10::Minibatch 304::LR 0.0792307692308 --> Loss 0.00318653662999\n",
      "Epoch 10::Minibatch 305::LR 0.0792307692308 --> Loss 0.00171052118142\n",
      "Epoch 10::Minibatch 306::LR 0.0792307692308 --> Loss 0.000949979424477\n",
      "Epoch 10::Minibatch 307::LR 0.0792307692308 --> Loss 0.00249367733796\n",
      "Epoch 10::Minibatch 308::LR 0.0792307692308 --> Loss 0.00198733905951\n",
      "Epoch 10::Minibatch 309::LR 0.0792307692308 --> Loss 0.00100294133027\n",
      "Epoch 10::Minibatch 310::LR 0.0792307692308 --> Loss 0.00108413517475\n",
      "Epoch 10::Minibatch 311::LR 0.0792307692308 --> Loss 0.00166942318281\n",
      "Epoch 10::Minibatch 312::LR 0.0792307692308 --> Loss 0.00306660234928\n",
      "Epoch 10::Minibatch 313::LR 0.0792307692308 --> Loss 0.0024112123251\n",
      "Epoch 10::Minibatch 314::LR 0.0792307692308 --> Loss 0.00193187614282\n",
      "Epoch 10::Minibatch 315::LR 0.0792307692308 --> Loss 0.000985859135787\n",
      "Epoch 10::Minibatch 316::LR 0.0792307692308 --> Loss 0.0023452325662\n",
      "Epoch 10::Minibatch 317::LR 0.0792307692308 --> Loss 0.00156095027924\n",
      "Epoch 10::Minibatch 318::LR 0.0792307692308 --> Loss 0.00118607133627\n",
      "Epoch 10::Minibatch 319::LR 0.0792307692308 --> Loss 0.00230441848437\n",
      "Epoch 10::Minibatch 320::LR 0.0792307692308 --> Loss 0.00334204236666\n",
      "Epoch 10::Minibatch 321::LR 0.0792307692308 --> Loss 0.000919876396656\n",
      "Epoch 10::Minibatch 322::LR 0.0792307692308 --> Loss 0.00370312770208\n",
      "Epoch 10::Minibatch 323::LR 0.0792307692308 --> Loss 0.00361881931623\n",
      "Epoch 10::Minibatch 324::LR 0.0792307692308 --> Loss 0.00265944898129\n",
      "Epoch 10::Minibatch 325::LR 0.0792307692308 --> Loss 0.00245825588703\n",
      "Epoch 10::Minibatch 326::LR 0.0792307692308 --> Loss 0.00556829929352\n",
      "Epoch 10::Minibatch 327::LR 0.0792307692308 --> Loss 0.0023102893432\n",
      "Epoch 10::Minibatch 328::LR 0.0792307692308 --> Loss 0.00351923465729\n",
      "Epoch 10::Minibatch 329::LR 0.0792307692308 --> Loss 0.00129011611144\n",
      "Epoch 10::Minibatch 330::LR 0.0792307692308 --> Loss 0.0016599303484\n",
      "Epoch 10::Minibatch 331::LR 0.0792307692308 --> Loss 0.00260144770145\n",
      "Epoch 10::Minibatch 332::LR 0.0792307692308 --> Loss 0.002559491992\n",
      "Epoch 10::Minibatch 333::LR 0.0792307692308 --> Loss 0.00149754951398\n",
      "Epoch 10::Minibatch 334::LR 0.0792307692308 --> Loss 0.00429127256076\n",
      "Epoch 10::Minibatch 335::LR 0.0792307692308 --> Loss 0.00193181395531\n",
      "Epoch 10::Minibatch 336::LR 0.0792307692308 --> Loss 0.00207666655382\n",
      "Epoch 10::Minibatch 337::LR 0.0792307692308 --> Loss 0.0033096464475\n",
      "Epoch 10::Minibatch 338::LR 0.0792307692308 --> Loss 0.000530703713497\n",
      "Epoch 10::Minibatch 339::LR 0.0792307692308 --> Loss 0.00331673502922\n",
      "Epoch 10::Minibatch 340::LR 0.0792307692308 --> Loss 0.00471428394318\n",
      "Epoch 10::Minibatch 341::LR 0.0792307692308 --> Loss 0.00516438802083\n",
      "Epoch 10::Minibatch 342::LR 0.0792307692308 --> Loss 0.0033859928449\n",
      "Epoch 10::Minibatch 343::LR 0.0792307692308 --> Loss 0.00179265081882\n",
      "Epoch 10::Minibatch 344::LR 0.0792307692308 --> Loss 0.00306334873041\n",
      "Epoch 10::Minibatch 345::LR 0.0792307692308 --> Loss 0.00438718716304\n",
      "Epoch 10::Minibatch 346::LR 0.0792307692308 --> Loss 0.00575313886007\n",
      "Epoch 10::Minibatch 347::LR 0.0792307692308 --> Loss 0.000940826634566\n",
      "Epoch 10::Minibatch 348::LR 0.0792307692308 --> Loss 0.00367680986722\n",
      "Epoch 10::Minibatch 349::LR 0.0792307692308 --> Loss 0.0035742243131\n",
      "Epoch 10::Minibatch 350::LR 0.0792307692308 --> Loss 0.00192156096299\n",
      "Epoch 10::Minibatch 351::LR 0.0792307692308 --> Loss 0.00363518476486\n",
      "Epoch 10::Minibatch 352::LR 0.0792307692308 --> Loss 0.00483021497726\n",
      "Epoch 10::Minibatch 353::LR 0.0792307692308 --> Loss 0.00359579443932\n",
      "Epoch 10::Minibatch 354::LR 0.0792307692308 --> Loss 0.00298653662205\n",
      "Epoch 10::Minibatch 355::LR 0.0792307692308 --> Loss 0.00621205012004\n",
      "Epoch 10::Minibatch 356::LR 0.0792307692308 --> Loss 0.00319115360578\n",
      "Epoch 10::Minibatch 357::LR 0.0792307692308 --> Loss 0.00123901903629\n",
      "Epoch 10::Minibatch 358::LR 0.0792307692308 --> Loss 0.00231137633324\n",
      "Epoch 10::Minibatch 359::LR 0.0792307692308 --> Loss 0.00279887755712\n",
      "Epoch 10::Minibatch 360::LR 0.0792307692308 --> Loss 0.0025158260266\n",
      "Epoch 10::Minibatch 361::LR 0.0792307692308 --> Loss 0.00249925573667\n",
      "Epoch 10::Minibatch 362::LR 0.0792307692308 --> Loss 0.00253538270791\n",
      "Epoch 10::Minibatch 363::LR 0.0792307692308 --> Loss 0.000721091131369\n",
      "Epoch 10::Minibatch 364::LR 0.0792307692308 --> Loss 0.00206459581852\n",
      "Epoch 10::Minibatch 365::LR 0.0792307692308 --> Loss 0.00216751893361\n",
      "Epoch 10::Minibatch 366::LR 0.0792307692308 --> Loss 0.00234978795052\n",
      "Epoch 10::Minibatch 367::LR 0.0792307692308 --> Loss 0.00116547226906\n",
      "Epoch 10::Minibatch 368::LR 0.0792307692308 --> Loss 0.00103091766437\n",
      "Epoch 10::Minibatch 369::LR 0.0792307692308 --> Loss 0.00293865561485\n",
      "Epoch 10::Minibatch 370::LR 0.0792307692308 --> Loss 0.00230564753215\n",
      "Epoch 10::Minibatch 371::LR 0.0792307692308 --> Loss 0.00190598368645\n",
      "Epoch 10::Minibatch 372::LR 0.0792307692308 --> Loss 0.00047468200326\n",
      "Epoch 10::Minibatch 373::LR 0.0792307692308 --> Loss 0.00177347898483\n",
      "Epoch 10::Minibatch 374::LR 0.0792307692308 --> Loss 0.00216674764951\n",
      "Epoch 10::Minibatch 375::LR 0.0792307692308 --> Loss 0.00185231645902\n",
      "Epoch 10::Minibatch 376::LR 0.0792307692308 --> Loss 0.00126890768607\n",
      "Epoch 10::Minibatch 377::LR 0.0792307692308 --> Loss 0.00198881526788\n",
      "Epoch 10::Minibatch 378::LR 0.0792307692308 --> Loss 0.00214726706346\n",
      "Epoch 10::Minibatch 379::LR 0.0792307692308 --> Loss 0.00242104411125\n",
      "Epoch 10::Minibatch 380::LR 0.0792307692308 --> Loss 0.00162200580041\n",
      "Epoch 10::Minibatch 381::LR 0.0792307692308 --> Loss 0.00101072609425\n",
      "Epoch 10::Minibatch 382::LR 0.0792307692308 --> Loss 0.0020291463534\n",
      "Epoch 10::Minibatch 383::LR 0.0792307692308 --> Loss 0.00195894360542\n",
      "Epoch 10::Minibatch 384::LR 0.0792307692308 --> Loss 0.00106274038553\n",
      "Epoch 10::Minibatch 385::LR 0.0792307692308 --> Loss 0.00105576346318\n",
      "Epoch 10::Minibatch 386::LR 0.0792307692308 --> Loss 0.00220648169518\n",
      "Epoch 10::Minibatch 387::LR 0.0792307692308 --> Loss 0.00233362933\n",
      "Epoch 10::Minibatch 388::LR 0.0792307692308 --> Loss 0.00114743888378\n",
      "Epoch 10::Minibatch 389::LR 0.0792307692308 --> Loss 0.00185354272525\n",
      "Epoch 10::Minibatch 390::LR 0.0792307692308 --> Loss 0.0037747379144\n",
      "Epoch 10::Minibatch 391::LR 0.0792307692308 --> Loss 0.00275954465071\n",
      "Epoch 10::Minibatch 392::LR 0.0792307692308 --> Loss 0.00274021307627\n",
      "Epoch 10::Minibatch 393::LR 0.0792307692308 --> Loss 0.00282231549422\n",
      "Epoch 10::Minibatch 394::LR 0.0792307692308 --> Loss 0.00212372283141\n",
      "Epoch 10::Minibatch 395::LR 0.0792307692308 --> Loss 0.0020737238725\n",
      "Epoch 10::Minibatch 396::LR 0.0792307692308 --> Loss 0.00200022776922\n",
      "Epoch 10::Minibatch 397::LR 0.0792307692308 --> Loss 0.00211698313554\n",
      "Epoch 10::Minibatch 398::LR 0.0792307692308 --> Loss 0.00209839026133\n",
      "Epoch 10::Minibatch 399::LR 0.0792307692308 --> Loss 0.00238695720832\n",
      "Epoch 10::Minibatch 400::LR 0.0792307692308 --> Loss 0.00205621143182\n",
      "Epoch 10::Minibatch 401::LR 0.0792307692308 --> Loss 0.00368727564812\n",
      "Epoch 10::Minibatch 402::LR 0.0792307692308 --> Loss 0.00189275105794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 403::LR 0.0792307692308 --> Loss 0.001507110099\n",
      "Epoch 10::Minibatch 404::LR 0.0792307692308 --> Loss 0.00161660979191\n",
      "Epoch 10::Minibatch 405::LR 0.0792307692308 --> Loss 0.00366549452146\n",
      "Epoch 10::Minibatch 406::LR 0.0792307692308 --> Loss 0.00254198849201\n",
      "Epoch 10::Minibatch 407::LR 0.0792307692308 --> Loss 0.00178894420465\n",
      "Epoch 10::Minibatch 408::LR 0.0792307692308 --> Loss 0.00048624108235\n",
      "Epoch 10::Minibatch 409::LR 0.0792307692308 --> Loss 0.00248659114043\n",
      "Epoch 10::Minibatch 410::LR 0.0792307692308 --> Loss 0.00332083702087\n",
      "Epoch 10::Minibatch 411::LR 0.0792307692308 --> Loss 0.00168312688669\n",
      "Epoch 10::Minibatch 412::LR 0.0792307692308 --> Loss 0.00101174006859\n",
      "Epoch 10::Minibatch 413::LR 0.0792307692308 --> Loss 0.00203755696615\n",
      "Epoch 10::Minibatch 414::LR 0.0792307692308 --> Loss 0.00183288753033\n",
      "Epoch 10::Minibatch 415::LR 0.0792307692308 --> Loss 0.00116843163967\n",
      "Epoch 10::Minibatch 416::LR 0.0792307692308 --> Loss 0.00087100058794\n",
      "Epoch 10::Minibatch 417::LR 0.0792307692308 --> Loss 0.0017391093572\n",
      "Epoch 10::Minibatch 418::LR 0.0792307692308 --> Loss 0.00293805976709\n",
      "Epoch 10::Minibatch 419::LR 0.0792307692308 --> Loss 0.000536236365636\n",
      "Epoch 10::Minibatch 420::LR 0.0792307692308 --> Loss 0.00072639927268\n",
      "Epoch 10::Minibatch 421::LR 0.0792307692308 --> Loss 0.00196664492289\n",
      "Epoch 10::Minibatch 422::LR 0.0792307692308 --> Loss 0.00222109993299\n",
      "Epoch 10::Minibatch 423::LR 0.0792307692308 --> Loss 0.000980825324853\n",
      "Epoch 10::Minibatch 424::LR 0.0792307692308 --> Loss 0.00161719421546\n",
      "Epoch 10::Minibatch 425::LR 0.0792307692308 --> Loss 0.00289289534092\n",
      "Epoch 10::Minibatch 426::LR 0.0792307692308 --> Loss 0.00203500171502\n",
      "Epoch 10::Minibatch 427::LR 0.0792307692308 --> Loss 0.000722658733527\n",
      "Epoch 10::Minibatch 428::LR 0.0792307692308 --> Loss 0.00114078015089\n",
      "Epoch 10::Minibatch 429::LR 0.0792307692308 --> Loss 0.00252764165401\n",
      "Epoch 10::Minibatch 430::LR 0.0792307692308 --> Loss 0.00967912753423\n",
      "Epoch 10::Minibatch 431::LR 0.0792307692308 --> Loss 0.00383940339088\n",
      "Epoch 10::Minibatch 432::LR 0.0792307692308 --> Loss 0.0045839814345\n",
      "Epoch 10::Minibatch 433::LR 0.0792307692308 --> Loss 0.00261703650157\n",
      "Epoch 10::Minibatch 434::LR 0.0792307692308 --> Loss 0.00258701701959\n",
      "Epoch 10::Minibatch 435::LR 0.0792307692308 --> Loss 0.00246091345946\n",
      "Epoch 10::Minibatch 436::LR 0.0792307692308 --> Loss 0.00183137933413\n",
      "Epoch 10::Minibatch 437::LR 0.0792307692308 --> Loss 0.00358596404394\n",
      "Epoch 10::Minibatch 438::LR 0.0792307692308 --> Loss 0.00284360984961\n",
      "Epoch 10::Minibatch 439::LR 0.0792307692308 --> Loss 0.00228137135506\n",
      "Epoch 10::Minibatch 440::LR 0.0792307692308 --> Loss 0.0034142824014\n",
      "Epoch 10::Minibatch 441::LR 0.0792307692308 --> Loss 0.00321680148443\n",
      "Epoch 10::Minibatch 442::LR 0.0792307692308 --> Loss 0.00297808746497\n",
      "Epoch 10::Minibatch 443::LR 0.0792307692308 --> Loss 0.00387133161227\n",
      "Epoch 10::Minibatch 444::LR 0.0792307692308 --> Loss 0.00300890723864\n",
      "Epoch 10::Minibatch 445::LR 0.0792307692308 --> Loss 0.000940385560195\n",
      "Epoch 10::Minibatch 446::LR 0.0792307692308 --> Loss 0.00154485940933\n",
      "Epoch 10::Minibatch 447::LR 0.0792307692308 --> Loss 0.00254484057426\n",
      "Epoch 10::Minibatch 448::LR 0.0792307692308 --> Loss 0.00250825981299\n",
      "Epoch 10::Minibatch 449::LR 0.0792307692308 --> Loss 0.00383327325185\n",
      "Epoch 10::Minibatch 450::LR 0.0792307692308 --> Loss 0.00246685266495\n",
      "Epoch 10::Minibatch 451::LR 0.0792307692308 --> Loss 0.00419926921527\n",
      "Epoch 10::Minibatch 452::LR 0.0792307692308 --> Loss 0.0024489680926\n",
      "Epoch 10::Minibatch 453::LR 0.0792307692308 --> Loss 0.000429316461086\n",
      "Epoch 10::Minibatch 454::LR 0.0792307692308 --> Loss 0.00364766081174\n",
      "Epoch 10::Minibatch 455::LR 0.0792307692308 --> Loss 0.00276646296183\n",
      "Epoch 10::Minibatch 456::LR 0.0792307692308 --> Loss 0.00324036180973\n",
      "Epoch 10::Minibatch 457::LR 0.0792307692308 --> Loss 0.00204300204913\n",
      "Epoch 10::Minibatch 458::LR 0.0792307692308 --> Loss 0.000831926514705\n",
      "Epoch 10::Minibatch 459::LR 0.0792307692308 --> Loss 0.00424921115239\n",
      "Epoch 10::Minibatch 460::LR 0.0792307692308 --> Loss 0.00272902667522\n",
      "Epoch 10::Minibatch 461::LR 0.0792307692308 --> Loss 0.00403798063596\n",
      "Epoch 10::Minibatch 462::LR 0.0792307692308 --> Loss 0.000431017378966\n",
      "Epoch 10::Minibatch 463::LR 0.0792307692308 --> Loss 0.00465248346329\n",
      "Epoch 10::Minibatch 464::LR 0.0792307692308 --> Loss 0.00211733043194\n",
      "Epoch 10::Minibatch 465::LR 0.0792307692308 --> Loss 0.0055833252271\n",
      "Epoch 10::Minibatch 466::LR 0.0792307692308 --> Loss 0.00524043679237\n",
      "Epoch 10::Minibatch 467::LR 0.0792307692308 --> Loss 0.00632850925128\n",
      "Epoch 10::Minibatch 468::LR 0.0792307692308 --> Loss 0.00632680733999\n",
      "Epoch 10::Minibatch 469::LR 0.0792307692308 --> Loss 0.0064757835865\n",
      "Epoch 10::Minibatch 470::LR 0.0792307692308 --> Loss 0.00396128972371\n",
      "Epoch 10::Minibatch 471::LR 0.0792307692308 --> Loss 0.00186984042327\n",
      "Epoch 10::Minibatch 472::LR 0.0792307692308 --> Loss 0.0035532772541\n",
      "Epoch 10::Minibatch 473::LR 0.0792307692308 --> Loss 0.00221146086852\n",
      "Epoch 10::Minibatch 474::LR 0.0792307692308 --> Loss 0.000737005472183\n",
      "Epoch 10::Minibatch 475::LR 0.0792307692308 --> Loss 0.00542672475179\n",
      "Epoch 10::Minibatch 476::LR 0.0792307692308 --> Loss 0.00769169092178\n",
      "Epoch 10::Minibatch 477::LR 0.0792307692308 --> Loss 0.000979813237985\n",
      "Epoch 10::Minibatch 478::LR 0.0792307692308 --> Loss 0.00251547197501\n",
      "Epoch 10::Minibatch 479::LR 0.0792307692308 --> Loss 0.00196846981843\n",
      "Epoch 10::Minibatch 480::LR 0.0792307692308 --> Loss 0.00153994043668\n",
      "Epoch 10::Minibatch 481::LR 0.0792307692308 --> Loss 0.000971370836099\n",
      "Epoch 10::Minibatch 482::LR 0.0792307692308 --> Loss 0.0021234190464\n",
      "Epoch 10::Minibatch 483::LR 0.0792307692308 --> Loss 0.00333999435107\n",
      "Epoch 10::Minibatch 484::LR 0.0792307692308 --> Loss 0.00367163777351\n",
      "Epoch 10::Minibatch 485::LR 0.0792307692308 --> Loss 0.000777859638135\n",
      "Epoch 10::Minibatch 486::LR 0.0792307692308 --> Loss 0.00314866264661\n",
      "Epoch 10::Minibatch 487::LR 0.0792307692308 --> Loss 0.00349582314491\n",
      "Epoch 10::Minibatch 488::LR 0.0792307692308 --> Loss 0.00205820242564\n",
      "Epoch 10::Minibatch 489::LR 0.0792307692308 --> Loss 0.00317259351412\n",
      "Epoch 10::Minibatch 490::LR 0.0792307692308 --> Loss 0.000432109286388\n",
      "Epoch 10::Minibatch 491::LR 0.0792307692308 --> Loss 0.00423600117366\n",
      "Epoch 10::Minibatch 492::LR 0.0792307692308 --> Loss 0.00304290811221\n",
      "Epoch 10::Minibatch 493::LR 0.0792307692308 --> Loss 0.0030303243796\n",
      "Epoch 10::Minibatch 494::LR 0.0792307692308 --> Loss 0.000760077734788\n",
      "Epoch 10::Minibatch 495::LR 0.0792307692308 --> Loss 0.00191158950329\n",
      "Epoch 10::Minibatch 496::LR 0.0792307692308 --> Loss 0.00301566163699\n",
      "Epoch 10::Minibatch 497::LR 0.0792307692308 --> Loss 0.000971731344859\n",
      "Epoch 10::Minibatch 498::LR 0.0792307692308 --> Loss 0.000611566305161\n",
      "Epoch 10::Minibatch 499::LR 0.0792307692308 --> Loss 0.00388089378675\n",
      "Epoch 10::Minibatch 500::LR 0.0792307692308 --> Loss 0.00145699858665\n",
      "Epoch 10::Minibatch 501::LR 0.0792307692308 --> Loss 0.00231675505638\n",
      "Epoch 10::Minibatch 502::LR 0.0792307692308 --> Loss 0.00401466329892\n",
      "Epoch 10::Minibatch 503::LR 0.0792307692308 --> Loss 0.00977838118871\n",
      "Epoch 10::Minibatch 504::LR 0.0792307692308 --> Loss 0.00847245693207\n",
      "Epoch 10::Minibatch 505::LR 0.0792307692308 --> Loss 0.00448679010073\n",
      "Epoch 10::Minibatch 506::LR 0.0792307692308 --> Loss 0.0035862437884\n",
      "Epoch 10::Minibatch 507::LR 0.0792307692308 --> Loss 0.00613108038902\n",
      "Epoch 10::Minibatch 508::LR 0.0792307692308 --> Loss 0.00339873115222\n",
      "Epoch 10::Minibatch 509::LR 0.0792307692308 --> Loss 0.00478642265002\n",
      "Epoch 10::Minibatch 510::LR 0.0792307692308 --> Loss 0.00477007071177\n",
      "Epoch 10::Minibatch 511::LR 0.0792307692308 --> Loss 0.00388109445572\n",
      "Epoch 10::Minibatch 512::LR 0.0792307692308 --> Loss 0.00269673188527\n",
      "Epoch 10::Minibatch 513::LR 0.0792307692308 --> Loss 0.000690403381983\n",
      "Epoch 10::Minibatch 514::LR 0.0792307692308 --> Loss 0.00264193554719\n",
      "Epoch 10::Minibatch 515::LR 0.0792307692308 --> Loss 0.00305546760559\n",
      "Epoch 10::Minibatch 516::LR 0.0792307692308 --> Loss 0.00421087702115\n",
      "Epoch 10::Minibatch 517::LR 0.0792307692308 --> Loss 0.00342676122983\n",
      "Epoch 10::Minibatch 518::LR 0.0792307692308 --> Loss 0.00256285727024\n",
      "Epoch 10::Minibatch 519::LR 0.0792307692308 --> Loss 0.00339938203494\n",
      "Epoch 10::Minibatch 520::LR 0.0792307692308 --> Loss 0.00540491422017\n",
      "Epoch 10::Minibatch 521::LR 0.0792307692308 --> Loss 0.00558531800906\n",
      "Epoch 10::Minibatch 522::LR 0.0792307692308 --> Loss 0.00814102093379\n",
      "Epoch 10::Minibatch 523::LR 0.0792307692308 --> Loss 0.000715207705895\n",
      "Epoch 10::Minibatch 524::LR 0.0792307692308 --> Loss 0.0014666907986\n",
      "Epoch 10::Minibatch 525::LR 0.0792307692308 --> Loss 0.00329563617706\n",
      "Epoch 10::Minibatch 526::LR 0.0792307692308 --> Loss 0.00426291664441\n",
      "Epoch 10::Minibatch 527::LR 0.0792307692308 --> Loss 0.0023529813687\n",
      "Epoch 10::Minibatch 528::LR 0.0792307692308 --> Loss 0.00116434524457\n",
      "Epoch 10::Minibatch 529::LR 0.0792307692308 --> Loss 0.00422533432643\n",
      "Epoch 10::Minibatch 530::LR 0.0792307692308 --> Loss 0.00437803824743\n",
      "Epoch 10::Minibatch 531::LR 0.0792307692308 --> Loss 0.00377177874247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 532::LR 0.0792307692308 --> Loss 0.00278295417627\n",
      "Epoch 10::Minibatch 533::LR 0.0792307692308 --> Loss 0.00499421477318\n",
      "Epoch 10::Minibatch 534::LR 0.0792307692308 --> Loss 0.00391678730647\n",
      "Epoch 10::Minibatch 535::LR 0.0792307692308 --> Loss 0.00326242884\n",
      "Epoch 10::Minibatch 536::LR 0.0792307692308 --> Loss 0.00212397436301\n",
      "Epoch 10::Minibatch 537::LR 0.0792307692308 --> Loss 0.000680818359057\n",
      "Epoch 10::Minibatch 538::LR 0.0792307692308 --> Loss 0.00175620933374\n",
      "Epoch 10::Minibatch 539::LR 0.0792307692308 --> Loss 0.00349133968353\n",
      "Epoch 10::Minibatch 540::LR 0.0792307692308 --> Loss 0.00343375205994\n",
      "Epoch 10::Minibatch 541::LR 0.0792307692308 --> Loss 0.00294027884801\n",
      "Epoch 10::Minibatch 542::LR 0.0792307692308 --> Loss 0.00261604249477\n",
      "Epoch 10::Minibatch 543::LR 0.0792307692308 --> Loss 0.00286919931571\n",
      "Epoch 10::Minibatch 544::LR 0.0792307692308 --> Loss 0.00397042473157\n",
      "Epoch 10::Minibatch 545::LR 0.0792307692308 --> Loss 0.00210196991762\n",
      "Epoch 10::Minibatch 546::LR 0.0792307692308 --> Loss 0.000691569447517\n",
      "Epoch 10::Minibatch 547::LR 0.0792307692308 --> Loss 0.00267912467321\n",
      "Epoch 10::Minibatch 548::LR 0.0792307692308 --> Loss 0.00391860405604\n",
      "Epoch 10::Minibatch 549::LR 0.0792307692308 --> Loss 0.00792310158412\n",
      "Epoch 10::Minibatch 550::LR 0.0792307692308 --> Loss 0.00118747750918\n",
      "Epoch 10::Minibatch 551::LR 0.0792307692308 --> Loss 0.00248999635379\n",
      "Epoch 10::Minibatch 552::LR 0.0792307692308 --> Loss 0.00369039138158\n",
      "Epoch 10::Minibatch 553::LR 0.0792307692308 --> Loss 0.00333251814047\n",
      "Epoch 10::Minibatch 554::LR 0.0792307692308 --> Loss 0.00389839331309\n",
      "Epoch 10::Minibatch 555::LR 0.0792307692308 --> Loss 0.00103148003419\n",
      "Epoch 10::Minibatch 556::LR 0.0792307692308 --> Loss 0.00209204892317\n",
      "Epoch 10::Minibatch 557::LR 0.0792307692308 --> Loss 0.00253409663836\n",
      "Epoch 10::Minibatch 558::LR 0.0792307692308 --> Loss 0.0037884024779\n",
      "Epoch 10::Minibatch 559::LR 0.0792307692308 --> Loss 0.00381344119708\n",
      "Epoch 10::Minibatch 560::LR 0.0792307692308 --> Loss 0.00315557360649\n",
      "Epoch 10::Minibatch 561::LR 0.0792307692308 --> Loss 0.00283236205578\n",
      "Epoch 10::Minibatch 562::LR 0.0792307692308 --> Loss 0.00243769566218\n",
      "Epoch 10::Minibatch 563::LR 0.0792307692308 --> Loss 0.0040689154466\n",
      "Epoch 10::Minibatch 564::LR 0.0792307692308 --> Loss 0.00319810211658\n",
      "Epoch 10::Minibatch 565::LR 0.0792307692308 --> Loss 0.00379914283752\n",
      "Epoch 10::Minibatch 566::LR 0.0792307692308 --> Loss 0.00237926801046\n",
      "Epoch 10::Minibatch 567::LR 0.0792307692308 --> Loss 0.00267313957214\n",
      "Epoch 10::Minibatch 568::LR 0.0792307692308 --> Loss 0.00187462747097\n",
      "Epoch 10::Minibatch 569::LR 0.0792307692308 --> Loss 0.000589169959227\n",
      "Epoch 10::Minibatch 570::LR 0.0792307692308 --> Loss 0.00177871763706\n",
      "Epoch 10::Minibatch 571::LR 0.0792307692308 --> Loss 0.00233732541402\n",
      "Epoch 10::Minibatch 572::LR 0.0792307692308 --> Loss 0.00246869822343\n",
      "Epoch 10::Minibatch 573::LR 0.0792307692308 --> Loss 0.00156049162149\n",
      "Epoch 10::Minibatch 574::LR 0.0792307692308 --> Loss 0.00106937279304\n",
      "Epoch 10::Minibatch 575::LR 0.0792307692308 --> Loss 0.00184547146161\n",
      "Epoch 10::Minibatch 576::LR 0.0792307692308 --> Loss 0.00220975041389\n",
      "Epoch 10::Minibatch 577::LR 0.0792307692308 --> Loss 0.00172644476096\n",
      "Epoch 10::Minibatch 578::LR 0.0792307692308 --> Loss 0.00131768127282\n",
      "Epoch 10::Minibatch 579::LR 0.0792307692308 --> Loss 0.00123237113158\n",
      "Epoch 10::Minibatch 580::LR 0.0792307692308 --> Loss 0.00199665009975\n",
      "Epoch 10::Minibatch 581::LR 0.0792307692308 --> Loss 0.00174687465032\n",
      "Epoch 10::Minibatch 582::LR 0.0792307692308 --> Loss 0.00415803313255\n",
      "Epoch 10::Minibatch 583::LR 0.0792307692308 --> Loss 0.000961838861307\n",
      "Epoch 10::Minibatch 584::LR 0.0792307692308 --> Loss 0.00133304248254\n",
      "Epoch 10::Minibatch 585::LR 0.0792307692308 --> Loss 0.0050431406498\n",
      "Epoch 10::Minibatch 586::LR 0.0792307692308 --> Loss 0.00423163930575\n",
      "Epoch 10::Minibatch 587::LR 0.0792307692308 --> Loss 0.00116185307503\n",
      "Epoch 10::Minibatch 588::LR 0.0792307692308 --> Loss 0.0014564015468\n",
      "Epoch 10::Minibatch 589::LR 0.0792307692308 --> Loss 0.00279608011246\n",
      "Epoch 10::Minibatch 590::LR 0.0792307692308 --> Loss 0.00208725074927\n",
      "Epoch 10::Minibatch 591::LR 0.0792307692308 --> Loss 0.00333822290103\n",
      "Epoch 10::Minibatch 592::LR 0.0792307692308 --> Loss 0.00121151506901\n",
      "Epoch 10::Minibatch 593::LR 0.0792307692308 --> Loss 0.00266914327939\n",
      "Epoch 10::Minibatch 594::LR 0.0792307692308 --> Loss 0.00288429876169\n",
      "Epoch 10::Minibatch 595::LR 0.0792307692308 --> Loss 0.00307552933693\n",
      "Epoch 10::Minibatch 596::LR 0.0792307692308 --> Loss 0.00202241162459\n",
      "Epoch 10::Minibatch 597::LR 0.0792307692308 --> Loss 0.0012282410264\n",
      "Epoch 10::Minibatch 598::LR 0.0792307692308 --> Loss 0.00320290486018\n",
      "Epoch 10::Minibatch 599::LR 0.0792307692308 --> Loss 0.00191130956014\n",
      "Epoch 10::Minibatch 600::LR 0.0792307692308 --> Loss 0.00230119268099\n",
      "Epoch 10::Minibatch 601::LR 0.0792307692308 --> Loss 0.00395247181257\n",
      "Epoch 10::Minibatch 602::LR 0.0792307692308 --> Loss 0.00215824147065\n",
      "Epoch 10::Minibatch 603::LR 0.0792307692308 --> Loss 0.00269413252672\n",
      "Epoch 10::Minibatch 604::LR 0.0792307692308 --> Loss 0.00166906317075\n",
      "Epoch 10::Minibatch 605::LR 0.0792307692308 --> Loss 0.00245070695877\n",
      "Epoch 10::Minibatch 606::LR 0.0792307692308 --> Loss 0.00197172999382\n",
      "Epoch 10::Minibatch 607::LR 0.0792307692308 --> Loss 0.000861629148324\n",
      "Epoch 10::Minibatch 608::LR 0.0792307692308 --> Loss 0.00163870602846\n",
      "Epoch 10::Minibatch 609::LR 0.0792307692308 --> Loss 0.00237419784069\n",
      "Epoch 10::Minibatch 610::LR 0.0792307692308 --> Loss 0.00403665145238\n",
      "Epoch 10::Minibatch 611::LR 0.0792307692308 --> Loss 0.00270953873793\n",
      "Epoch 10::Minibatch 612::LR 0.0792307692308 --> Loss 0.00052515561382\n",
      "Epoch 10::Minibatch 613::LR 0.0792307692308 --> Loss 0.00133556514978\n",
      "Epoch 10::Minibatch 614::LR 0.0792307692308 --> Loss 0.00253041843573\n",
      "Epoch 10::Minibatch 615::LR 0.0792307692308 --> Loss 0.00171344280243\n",
      "Epoch 10::Minibatch 616::LR 0.0792307692308 --> Loss 0.000946497321129\n",
      "Epoch 10::Minibatch 617::LR 0.0792307692308 --> Loss 0.000534974684318\n",
      "Epoch 10::Minibatch 618::LR 0.0792307692308 --> Loss 0.00271318932374\n",
      "Epoch 10::Minibatch 619::LR 0.0792307692308 --> Loss 0.00194132884343\n",
      "Epoch 10::Minibatch 620::LR 0.0792307692308 --> Loss 0.00176035543283\n",
      "Epoch 10::Minibatch 621::LR 0.0792307692308 --> Loss 0.000884872277578\n",
      "Epoch 10::Minibatch 622::LR 0.0792307692308 --> Loss 0.000843142271042\n",
      "Epoch 10::Minibatch 623::LR 0.0792307692308 --> Loss 0.00222036441167\n",
      "Epoch 10::Minibatch 624::LR 0.0792307692308 --> Loss 0.00181008696556\n",
      "Epoch 10::Minibatch 625::LR 0.0792307692308 --> Loss 0.00319277882576\n",
      "Epoch 10::Minibatch 626::LR 0.0792307692308 --> Loss 0.00496776262919\n",
      "Epoch 10::Minibatch 627::LR 0.0792307692308 --> Loss 0.00140509068966\n",
      "Epoch 10::Minibatch 628::LR 0.0792307692308 --> Loss 0.000959633092086\n",
      "Epoch 10::Minibatch 629::LR 0.0792307692308 --> Loss 0.00358832796415\n",
      "Epoch 10::Minibatch 630::LR 0.0792307692308 --> Loss 0.00345098416011\n",
      "Epoch 10::Minibatch 631::LR 0.0792307692308 --> Loss 0.0074262770017\n",
      "Epoch 10::Minibatch 632::LR 0.0792307692308 --> Loss 0.000839169422785\n",
      "Epoch 10::Minibatch 633::LR 0.0792307692308 --> Loss 0.00171727518241\n",
      "Epoch 10::Minibatch 634::LR 0.0792307692308 --> Loss 0.00331222216288\n",
      "Epoch 10::Minibatch 635::LR 0.0792307692308 --> Loss 0.00484769423803\n",
      "Epoch 10::Minibatch 636::LR 0.0792307692308 --> Loss 0.00565546075503\n",
      "Epoch 10::Minibatch 637::LR 0.0792307692308 --> Loss 0.000912323196729\n",
      "Epoch 10::Minibatch 638::LR 0.0792307692308 --> Loss 0.00161501636108\n",
      "Epoch 10::Minibatch 639::LR 0.0792307692308 --> Loss 0.00342458089193\n",
      "Epoch 10::Minibatch 640::LR 0.0792307692308 --> Loss 0.00522672891617\n",
      "Epoch 10::Minibatch 641::LR 0.0792307692308 --> Loss 0.0032443712155\n",
      "Epoch 10::Minibatch 642::LR 0.0792307692308 --> Loss 0.000608706573645\n",
      "Epoch 10::Minibatch 643::LR 0.0792307692308 --> Loss 0.00240374445915\n",
      "Epoch 10::Minibatch 644::LR 0.0792307692308 --> Loss 0.00409108400345\n",
      "Epoch 10::Minibatch 645::LR 0.0792307692308 --> Loss 0.00425500512123\n",
      "Epoch 10::Minibatch 646::LR 0.0792307692308 --> Loss 0.00159565915664\n",
      "Epoch 10::Minibatch 647::LR 0.0792307692308 --> Loss 0.000633653948704\n",
      "Epoch 10::Minibatch 648::LR 0.0792307692308 --> Loss 0.00313193102678\n",
      "Epoch 10::Minibatch 649::LR 0.0792307692308 --> Loss 0.00370948553085\n",
      "Epoch 10::Minibatch 650::LR 0.0792307692308 --> Loss 0.00343355218569\n",
      "Epoch 10::Minibatch 651::LR 0.0792307692308 --> Loss 0.00146933545669\n",
      "Epoch 10::Minibatch 652::LR 0.0792307692308 --> Loss 0.000900719066461\n",
      "Epoch 10::Minibatch 653::LR 0.0792307692308 --> Loss 0.00295461277167\n",
      "Epoch 10::Minibatch 654::LR 0.0792307692308 --> Loss 0.00314782003562\n",
      "Epoch 10::Minibatch 655::LR 0.0792307692308 --> Loss 0.003506184419\n",
      "Epoch 10::Minibatch 656::LR 0.0792307692308 --> Loss 0.00081224595507\n",
      "Epoch 10::Minibatch 657::LR 0.0792307692308 --> Loss 0.0022231400013\n",
      "Epoch 10::Minibatch 658::LR 0.0792307692308 --> Loss 0.00509604414304\n",
      "Epoch 10::Minibatch 659::LR 0.0792307692308 --> Loss 0.00240741312504\n",
      "Epoch 10::Minibatch 660::LR 0.0792307692308 --> Loss 0.00264591832956\n",
      "Epoch 10::Minibatch 661::LR 0.0792307692308 --> Loss 0.00263300379117\n",
      "Epoch 10::Minibatch 662::LR 0.0792307692308 --> Loss 0.00187425851822\n",
      "Epoch 10::Minibatch 663::LR 0.0792307692308 --> Loss 0.00371922214826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 664::LR 0.0792307692308 --> Loss 0.00357577403386\n",
      "Epoch 10::Minibatch 665::LR 0.0792307692308 --> Loss 0.000805517484744\n",
      "Epoch 10::Minibatch 666::LR 0.0792307692308 --> Loss 0.00398382147153\n",
      "Epoch 10::Minibatch 667::LR 0.0792307692308 --> Loss 0.00259232064088\n",
      "Epoch 10::Minibatch 668::LR 0.0792307692308 --> Loss 0.00741578181585\n",
      "Epoch 10::Minibatch 669::LR 0.0792307692308 --> Loss 0.00111529221137\n",
      "Epoch 10::Minibatch 670::LR 0.0792307692308 --> Loss 0.00140424102545\n",
      "Epoch 10::Minibatch 671::LR 0.0792307692308 --> Loss 0.00556380589803\n",
      "Epoch 10::Minibatch 672::LR 0.0792307692308 --> Loss 0.00399108131727\n",
      "Epoch 10::Minibatch 673::LR 0.0792307692308 --> Loss 0.00165366739035\n",
      "Epoch 10::Minibatch 674::LR 0.0792307692308 --> Loss 0.000555477291346\n",
      "Epoch 10::Minibatch 675::LR 0.0792307692308 --> Loss 0.00223410089811\n",
      "Epoch 10::Minibatch 676::LR 0.0792307692308 --> Loss 0.00220528225104\n",
      "Epoch 10::Minibatch 677::LR 0.0792307692308 --> Loss 0.00292086640994\n",
      "Epoch 10::Minibatch 678::LR 0.0792307692308 --> Loss 0.00198762933413\n",
      "Epoch 10::Minibatch 679::LR 0.0792307692308 --> Loss 0.00364951133728\n",
      "Epoch 10::Minibatch 680::LR 0.0792307692308 --> Loss 0.00217288037141\n",
      "Epoch 10::Minibatch 681::LR 0.0792307692308 --> Loss 0.00248136421045\n",
      "Epoch 10::Minibatch 682::LR 0.0792307692308 --> Loss 0.000784276624521\n",
      "Epoch 10::Minibatch 683::LR 0.0792307692308 --> Loss 0.00246982534726\n",
      "Epoch 10::Minibatch 684::LR 0.0792307692308 --> Loss 0.00239385426044\n",
      "Epoch 10::Minibatch 685::LR 0.0792307692308 --> Loss 0.00298977096876\n",
      "Epoch 10::Minibatch 686::LR 0.0792307692308 --> Loss 0.00154008785884\n",
      "Epoch 10::Minibatch 687::LR 0.0792307692308 --> Loss 0.000859386324883\n",
      "Epoch 10::Minibatch 688::LR 0.0792307692308 --> Loss 0.00277149001757\n",
      "Epoch 10::Minibatch 689::LR 0.0792307692308 --> Loss 0.00258188247681\n",
      "Epoch 10::Minibatch 690::LR 0.0792307692308 --> Loss 0.00194773594538\n",
      "Epoch 10::Minibatch 691::LR 0.0792307692308 --> Loss 0.000676902830601\n",
      "Epoch 10::Minibatch 692::LR 0.0792307692308 --> Loss 0.00252809643745\n",
      "Epoch 10::Minibatch 693::LR 0.0792307692308 --> Loss 0.00258942763011\n",
      "Epoch 10::Minibatch 694::LR 0.0792307692308 --> Loss 0.00304439445337\n",
      "Epoch 10::Minibatch 695::LR 0.0792307692308 --> Loss 0.00173153261344\n",
      "Epoch 10::Minibatch 696::LR 0.0792307692308 --> Loss 0.00204538583755\n",
      "Epoch 10::Minibatch 697::LR 0.0792307692308 --> Loss 0.00142712722222\n",
      "Epoch 10::Minibatch 698::LR 0.0792307692308 --> Loss 0.0016284313798\n",
      "Epoch 10::Minibatch 699::LR 0.0792307692308 --> Loss 0.00389135797819\n",
      "Epoch 10::Minibatch 700::LR 0.0792307692308 --> Loss 0.00273677786191\n",
      "Epoch 10::Minibatch 701::LR 0.0792307692308 --> Loss 0.00204783221086\n",
      "Epoch 10::Minibatch 702::LR 0.0792307692308 --> Loss 0.00168422400951\n",
      "Epoch 10::Minibatch 703::LR 0.0792307692308 --> Loss 0.00424467325211\n",
      "Epoch 10::Minibatch 704::LR 0.0792307692308 --> Loss 0.00181322276592\n",
      "Epoch 10::Minibatch 705::LR 0.0792307692308 --> Loss 0.0028613136212\n",
      "Epoch 10::Minibatch 706::LR 0.0792307692308 --> Loss 0.00223445812861\n",
      "Epoch 10::Minibatch 707::LR 0.0792307692308 --> Loss 0.00120818138123\n",
      "Epoch 10::Minibatch 708::LR 0.0792307692308 --> Loss 0.00175342301528\n",
      "Epoch 10::Minibatch 709::LR 0.0792307692308 --> Loss 0.00172778507074\n",
      "Epoch 10::Minibatch 710::LR 0.0792307692308 --> Loss 0.00249650041262\n",
      "Epoch 10::Minibatch 711::LR 0.0792307692308 --> Loss 0.00190360387166\n",
      "Epoch 10::Minibatch 712::LR 0.0792307692308 --> Loss 0.00133642375469\n",
      "Epoch 10::Minibatch 713::LR 0.0792307692308 --> Loss 0.00174432535966\n",
      "Epoch 10::Minibatch 714::LR 0.0792307692308 --> Loss 0.00271100878716\n",
      "Epoch 10::Minibatch 715::LR 0.0792307692308 --> Loss 0.00296726942062\n",
      "Epoch 10::Minibatch 716::LR 0.0792307692308 --> Loss 0.00160751293103\n",
      "Epoch 10::Minibatch 717::LR 0.0792307692308 --> Loss 0.00160827110211\n",
      "Epoch 10::Minibatch 718::LR 0.0792307692308 --> Loss 0.00127150893211\n",
      "Epoch 10::Minibatch 719::LR 0.0792307692308 --> Loss 0.00166864812374\n",
      "Epoch 10::Minibatch 720::LR 0.0792307692308 --> Loss 0.00251724561056\n",
      "Epoch 10::Minibatch 721::LR 0.0792307692308 --> Loss 0.000654753694932\n",
      "Epoch 10::Minibatch 722::LR 0.0792307692308 --> Loss 0.00493260939916\n",
      "Epoch 10::Minibatch 723::LR 0.0792307692308 --> Loss 0.0049288614591\n",
      "Epoch 10::Minibatch 724::LR 0.0792307692308 --> Loss 0.000989936490854\n",
      "Epoch 10::Minibatch 725::LR 0.0792307692308 --> Loss 0.00227829217911\n",
      "Epoch 10::Minibatch 726::LR 0.0792307692308 --> Loss 0.0050505510966\n",
      "Epoch 10::Minibatch 727::LR 0.0792307692308 --> Loss 0.0031234250466\n",
      "Epoch 10::Minibatch 728::LR 0.0792307692308 --> Loss 0.000671032915513\n",
      "Epoch 10::Minibatch 729::LR 0.0792307692308 --> Loss 0.000787598540386\n",
      "Epoch 10::Minibatch 730::LR 0.0792307692308 --> Loss 0.00268418113391\n",
      "Epoch 10::Minibatch 731::LR 0.0792307692308 --> Loss 0.0024637389183\n",
      "Epoch 10::Minibatch 732::LR 0.0792307692308 --> Loss 0.00230850160122\n",
      "Epoch 10::Minibatch 733::LR 0.0792307692308 --> Loss 0.000758036871751\n",
      "Epoch 10::Minibatch 734::LR 0.0792307692308 --> Loss 0.00180390715599\n",
      "Epoch 10::Minibatch 735::LR 0.0792307692308 --> Loss 0.00237107833227\n",
      "Epoch 10::Minibatch 736::LR 0.0792307692308 --> Loss 0.00345981915792\n",
      "Epoch 10::Minibatch 737::LR 0.0792307692308 --> Loss 0.00314779361089\n",
      "Epoch 10::Minibatch 738::LR 0.0792307692308 --> Loss 0.00172945817312\n",
      "Epoch 10::Minibatch 739::LR 0.0792307692308 --> Loss 0.00249303936958\n",
      "Epoch 10::Minibatch 740::LR 0.0792307692308 --> Loss 0.00382769664129\n",
      "Epoch 10::Minibatch 741::LR 0.0792307692308 --> Loss 0.00278526703517\n",
      "Epoch 10::Minibatch 742::LR 0.0792307692308 --> Loss 0.00213298678398\n",
      "Epoch 10::Minibatch 743::LR 0.0792307692308 --> Loss 0.00135755976041\n",
      "Epoch 10::Minibatch 744::LR 0.0792307692308 --> Loss 0.00181307892005\n",
      "Epoch 10::Minibatch 745::LR 0.0792307692308 --> Loss 0.00287380973498\n",
      "Epoch 10::Minibatch 746::LR 0.0792307692308 --> Loss 0.00304381072521\n",
      "Epoch 10::Minibatch 747::LR 0.0792307692308 --> Loss 0.00180318395297\n",
      "Epoch 10::Minibatch 748::LR 0.0792307692308 --> Loss 0.000672524968783\n",
      "Epoch 10::Minibatch 749::LR 0.0792307692308 --> Loss 0.00167481978734\n",
      "Epoch 10::Minibatch 750::LR 0.0792307692308 --> Loss 0.002499071757\n",
      "Epoch 10::Minibatch 751::LR 0.0792307692308 --> Loss 0.00270347575347\n",
      "Epoch 10::Minibatch 752::LR 0.0792307692308 --> Loss 0.0011261789004\n",
      "Epoch 10::Minibatch 753::LR 0.0792307692308 --> Loss 0.00226742426554\n",
      "Epoch 10::Minibatch 754::LR 0.0792307692308 --> Loss 0.00239366074403\n",
      "Epoch 10::Minibatch 755::LR 0.0792307692308 --> Loss 0.00268163283666\n",
      "Epoch 10::Minibatch 756::LR 0.0792307692308 --> Loss 0.00141290555398\n",
      "Epoch 10::Minibatch 757::LR 0.0792307692308 --> Loss 0.00089040795962\n",
      "Epoch 10::Minibatch 758::LR 0.0792307692308 --> Loss 0.00164642900229\n",
      "Epoch 10::Minibatch 759::LR 0.0792307692308 --> Loss 0.00387692928314\n",
      "Epoch 10::Minibatch 760::LR 0.0792307692308 --> Loss 0.00306417524815\n",
      "Epoch 10::Minibatch 761::LR 0.0792307692308 --> Loss 0.00644506335258\n",
      "Epoch 10::Minibatch 762::LR 0.0792307692308 --> Loss 0.00383923053741\n",
      "Epoch 10::Minibatch 763::LR 0.0792307692308 --> Loss 0.00366244077682\n",
      "Epoch 10::Minibatch 764::LR 0.0792307692308 --> Loss 0.00328144987424\n",
      "Epoch 10::Minibatch 765::LR 0.0792307692308 --> Loss 0.00136901160081\n",
      "Epoch 10::Minibatch 766::LR 0.0792307692308 --> Loss 0.00229400098324\n",
      "Epoch 10::Minibatch 767::LR 0.0792307692308 --> Loss 0.00510600646337\n",
      "Epoch 10::Minibatch 768::LR 0.0792307692308 --> Loss 0.00358589132627\n",
      "Epoch 10::Minibatch 769::LR 0.0792307692308 --> Loss 0.00194516003132\n",
      "Epoch 10::Minibatch 770::LR 0.0792307692308 --> Loss 0.00146579007308\n",
      "Epoch 10::Minibatch 771::LR 0.0792307692308 --> Loss 0.00385966738065\n",
      "Epoch 10::Minibatch 772::LR 0.0792307692308 --> Loss 0.0033666173617\n",
      "Epoch 10::Minibatch 773::LR 0.0792307692308 --> Loss 0.00315829058488\n",
      "Epoch 10::Minibatch 774::LR 0.0792307692308 --> Loss 0.00176530003548\n",
      "Epoch 10::Minibatch 775::LR 0.0792307692308 --> Loss 0.00424933195114\n",
      "Epoch 10::Minibatch 776::LR 0.0792307692308 --> Loss 0.00357544461886\n",
      "Epoch 10::Minibatch 777::LR 0.0792307692308 --> Loss 0.00797330617905\n",
      "Epoch 10::Minibatch 778::LR 0.0792307692308 --> Loss 0.0108214767774\n",
      "Epoch 10::Minibatch 779::LR 0.0792307692308 --> Loss 0.00201941390832\n",
      "Epoch 10::Minibatch 780::LR 0.0792307692308 --> Loss 0.00168928941091\n",
      "Epoch 10::Minibatch 781::LR 0.0792307692308 --> Loss 0.00359186053276\n",
      "Epoch 10::Minibatch 782::LR 0.0792307692308 --> Loss 0.00420279463132\n",
      "Epoch 10::Minibatch 783::LR 0.0792307692308 --> Loss 0.00237011194229\n",
      "Epoch 10::Minibatch 784::LR 0.0792307692308 --> Loss 0.000756998906533\n",
      "Epoch 10::Minibatch 785::LR 0.0792307692308 --> Loss 0.00394038756688\n",
      "Epoch 10::Minibatch 786::LR 0.0792307692308 --> Loss 0.00366935809453\n",
      "Epoch 10::Minibatch 787::LR 0.0792307692308 --> Loss 0.00288818697135\n",
      "Epoch 10::Minibatch 788::LR 0.0792307692308 --> Loss 0.00254956503709\n",
      "Epoch 10::Minibatch 789::LR 0.0792307692308 --> Loss 0.000771825760603\n",
      "Epoch 10::Minibatch 790::LR 0.0792307692308 --> Loss 0.00330641369025\n",
      "Epoch 10::Minibatch 791::LR 0.0792307692308 --> Loss 0.00382357915243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 792::LR 0.0792307692308 --> Loss 0.0034950709343\n",
      "Epoch 10::Minibatch 793::LR 0.0792307692308 --> Loss 0.00198589662711\n",
      "Epoch 10::Minibatch 794::LR 0.0792307692308 --> Loss 0.00112375050783\n",
      "Epoch 10::Minibatch 795::LR 0.0792307692308 --> Loss 0.00337690711021\n",
      "Epoch 10::Minibatch 796::LR 0.0792307692308 --> Loss 0.00598486423492\n",
      "Epoch 10::Minibatch 797::LR 0.0792307692308 --> Loss 0.00835299571355\n",
      "Epoch 10::Minibatch 798::LR 0.0792307692308 --> Loss 0.00349078774452\n",
      "Epoch 10::Minibatch 799::LR 0.0792307692308 --> Loss 0.00254464129607\n",
      "Epoch 10::Minibatch 800::LR 0.0792307692308 --> Loss 0.0020884881417\n",
      "Epoch 10::Minibatch 801::LR 0.0792307692308 --> Loss 0.00418615102768\n",
      "Epoch 10::Minibatch 802::LR 0.0792307692308 --> Loss 0.00141599963109\n",
      "Epoch 10::Minibatch 803::LR 0.0792307692308 --> Loss 0.00281661331654\n",
      "Epoch 10::Minibatch 804::LR 0.0792307692308 --> Loss 0.00228217919668\n",
      "Epoch 10::Minibatch 805::LR 0.0792307692308 --> Loss 0.00236661116282\n",
      "Epoch 10::Minibatch 806::LR 0.0792307692308 --> Loss 0.00332519412041\n",
      "Epoch 10::Minibatch 807::LR 0.0792307692308 --> Loss 0.00307633578777\n",
      "Epoch 10::Minibatch 808::LR 0.0792307692308 --> Loss 0.00282765825589\n",
      "Epoch 10::Minibatch 809::LR 0.0792307692308 --> Loss 0.00425833503405\n",
      "Epoch 10::Minibatch 810::LR 0.0792307692308 --> Loss 0.00546355764071\n",
      "Epoch 10::Minibatch 811::LR 0.0792307692308 --> Loss 0.00512296001116\n",
      "Epoch 10::Minibatch 812::LR 0.0792307692308 --> Loss 0.00475541989009\n",
      "Epoch 10::Minibatch 813::LR 0.0792307692308 --> Loss 0.00414336284002\n",
      "Epoch 10::Minibatch 814::LR 0.0792307692308 --> Loss 0.00202377299468\n",
      "Epoch 10::Minibatch 815::LR 0.0792307692308 --> Loss 0.00405460357666\n",
      "Epoch 10::Minibatch 816::LR 0.0792307692308 --> Loss 0.00427195111911\n",
      "Epoch 10::Minibatch 817::LR 0.0792307692308 --> Loss 0.00538843512535\n",
      "Epoch 10::Minibatch 818::LR 0.0792307692308 --> Loss 0.00129750460386\n",
      "Epoch 10::Minibatch 819::LR 0.0792307692308 --> Loss 0.0007010024786\n",
      "Epoch 10::Minibatch 820::LR 0.0792307692308 --> Loss 0.00546180884043\n",
      "Epoch 10::Minibatch 821::LR 0.0792307692308 --> Loss 0.00324889441331\n",
      "Epoch 10::Minibatch 822::LR 0.0792307692308 --> Loss 0.00384138027827\n",
      "Epoch 10::Minibatch 823::LR 0.0792307692308 --> Loss 0.00134782085816\n",
      "Epoch 10::Minibatch 824::LR 0.0792307692308 --> Loss 0.00144236713648\n",
      "Epoch 10::Minibatch 825::LR 0.0792307692308 --> Loss 0.00377900242805\n",
      "Epoch 10::Minibatch 826::LR 0.0792307692308 --> Loss 0.00385195175807\n",
      "Epoch 10::Minibatch 827::LR 0.0792307692308 --> Loss 0.00217511852582\n",
      "Epoch 10::Minibatch 828::LR 0.0792307692308 --> Loss 0.000622653414806\n",
      "Epoch 10::Minibatch 829::LR 0.0792307692308 --> Loss 0.00244685630004\n",
      "Epoch 10::Minibatch 830::LR 0.0792307692308 --> Loss 0.00453947464625\n",
      "Epoch 10::Minibatch 831::LR 0.0792307692308 --> Loss 0.00262203613917\n",
      "Epoch 10::Minibatch 832::LR 0.0792307692308 --> Loss 0.00231239557266\n",
      "Epoch 10::Minibatch 833::LR 0.0792307692308 --> Loss 0.00188196659088\n",
      "Epoch 10::Minibatch 834::LR 0.0792307692308 --> Loss 0.000802406867345\n",
      "Epoch 10::Minibatch 835::LR 0.0792307692308 --> Loss 0.00387630065282\n",
      "Epoch 10::Minibatch 836::LR 0.0792307692308 --> Loss 0.00378604610761\n",
      "Epoch 10::Minibatch 837::LR 0.0792307692308 --> Loss 0.00224842985471\n",
      "Epoch 10::Minibatch 838::LR 0.0792307692308 --> Loss 0.00065629824996\n",
      "Epoch 10::Minibatch 839::LR 0.0792307692308 --> Loss 0.00249082843463\n",
      "Epoch 10::Minibatch 840::LR 0.0792307692308 --> Loss 0.00296680688858\n",
      "Epoch 10::Minibatch 841::LR 0.0792307692308 --> Loss 0.00293651382128\n",
      "Epoch 10::Minibatch 842::LR 0.0792307692308 --> Loss 0.00215196887652\n",
      "Epoch 10::Minibatch 843::LR 0.0792307692308 --> Loss 0.00103783855836\n",
      "Epoch 10::Minibatch 844::LR 0.0792307692308 --> Loss 0.00153869777918\n",
      "Epoch 10::Minibatch 845::LR 0.0792307692308 --> Loss 0.00445308725039\n",
      "Epoch 10::Minibatch 846::LR 0.0792307692308 --> Loss 0.00171174983184\n",
      "Epoch 10::Minibatch 847::LR 0.0792307692308 --> Loss 0.00232829272747\n",
      "Epoch 10::Minibatch 848::LR 0.0792307692308 --> Loss 0.00101219991843\n",
      "Epoch 10::Minibatch 849::LR 0.0792307692308 --> Loss 0.00189563175042\n",
      "Epoch 10::Minibatch 850::LR 0.0792307692308 --> Loss 0.00322701970736\n",
      "Epoch 10::Minibatch 851::LR 0.0792307692308 --> Loss 0.002777475516\n",
      "Epoch 10::Minibatch 852::LR 0.0792307692308 --> Loss 0.00108122368654\n",
      "Epoch 10::Minibatch 853::LR 0.0792307692308 --> Loss 0.0013337769111\n",
      "Epoch 10::Minibatch 854::LR 0.0792307692308 --> Loss 0.00259047190348\n",
      "Epoch 10::Minibatch 855::LR 0.0792307692308 --> Loss 0.00220688919226\n",
      "Epoch 10::Minibatch 856::LR 0.0792307692308 --> Loss 0.0018152252833\n",
      "Epoch 10::Minibatch 857::LR 0.0792307692308 --> Loss 0.00123816480239\n",
      "Epoch 10::Minibatch 858::LR 0.0792307692308 --> Loss 0.000618789792061\n",
      "Epoch 10::Minibatch 859::LR 0.0792307692308 --> Loss 0.00190625627836\n",
      "Epoch 10::Minibatch 860::LR 0.0792307692308 --> Loss 0.00123703410228\n",
      "Epoch 10::Minibatch 861::LR 0.0792307692308 --> Loss 0.000949319601059\n",
      "Epoch 10::Minibatch 862::LR 0.0792307692308 --> Loss 0.0036622095108\n",
      "Epoch 10::Minibatch 863::LR 0.0792307692308 --> Loss 0.00343423366547\n",
      "Epoch 10::Minibatch 864::LR 0.0792307692308 --> Loss 0.00300743997097\n",
      "Epoch 10::Minibatch 865::LR 0.0792307692308 --> Loss 0.000429189006488\n",
      "Epoch 10::Minibatch 866::LR 0.0792307692308 --> Loss 0.00219652593136\n",
      "Epoch 10::Minibatch 867::LR 0.0792307692308 --> Loss 0.00301617761453\n",
      "Epoch 10::Minibatch 868::LR 0.0792307692308 --> Loss 0.00250291566054\n",
      "Epoch 10::Minibatch 869::LR 0.0792307692308 --> Loss 0.00210721274217\n",
      "Epoch 10::Minibatch 870::LR 0.0792307692308 --> Loss 0.00367581486702\n",
      "Epoch 10::Minibatch 871::LR 0.0792307692308 --> Loss 0.00151954829693\n",
      "Epoch 10::Minibatch 872::LR 0.0792307692308 --> Loss 0.00233000616233\n",
      "Epoch 10::Minibatch 873::LR 0.0792307692308 --> Loss 0.00249396880468\n",
      "Epoch 10::Minibatch 874::LR 0.0792307692308 --> Loss 0.00642114082972\n",
      "Epoch 10::Minibatch 875::LR 0.0792307692308 --> Loss 0.000511464079221\n",
      "Epoch 10::Minibatch 876::LR 0.0792307692308 --> Loss 0.00358023643494\n",
      "Epoch 10::Minibatch 877::LR 0.0792307692308 --> Loss 0.00853032509486\n",
      "Epoch 10::Minibatch 878::LR 0.0792307692308 --> Loss 0.00338461915652\n",
      "Epoch 10::Minibatch 879::LR 0.0792307692308 --> Loss 0.00419046441714\n",
      "Epoch 10::Minibatch 880::LR 0.0792307692308 --> Loss 0.00500818928083\n",
      "Epoch 10::Minibatch 881::LR 0.0792307692308 --> Loss 0.00435807625453\n",
      "Epoch 10::Minibatch 882::LR 0.0792307692308 --> Loss 0.00203810771306\n",
      "Epoch 10::Minibatch 883::LR 0.0792307692308 --> Loss 0.00339942296346\n",
      "Epoch 10::Minibatch 884::LR 0.0792307692308 --> Loss 0.00272444705168\n",
      "Epoch 10::Minibatch 885::LR 0.0792307692308 --> Loss 0.00260688920816\n",
      "Epoch 10::Minibatch 886::LR 0.0792307692308 --> Loss 0.00081322123607\n",
      "Epoch 10::Minibatch 887::LR 0.0792307692308 --> Loss 0.00557548443476\n",
      "Epoch 10::Minibatch 888::LR 0.0792307692308 --> Loss 0.00271661758423\n",
      "Epoch 10::Minibatch 889::LR 0.0792307692308 --> Loss 0.00337848186493\n",
      "Epoch 10::Minibatch 890::LR 0.0792307692308 --> Loss 0.00487446904182\n",
      "Epoch 10::Minibatch 891::LR 0.0792307692308 --> Loss 0.00217938979467\n",
      "Epoch 10::Minibatch 892::LR 0.0792307692308 --> Loss 0.000975224971771\n",
      "Epoch 10::Minibatch 893::LR 0.0792307692308 --> Loss 0.00261152029037\n",
      "Epoch 10::Minibatch 894::LR 0.0792307692308 --> Loss 0.0023577696085\n",
      "Epoch 10::Minibatch 895::LR 0.0792307692308 --> Loss 0.00260344187419\n",
      "Epoch 10::Minibatch 896::LR 0.0792307692308 --> Loss 0.00153209199508\n",
      "Epoch 10::Minibatch 897::LR 0.0792307692308 --> Loss 0.00080325961113\n",
      "Epoch 10::Minibatch 898::LR 0.0792307692308 --> Loss 0.00233876049519\n",
      "Epoch 10::Minibatch 899::LR 0.0792307692308 --> Loss 0.00254236698151\n",
      "Epoch 10::Minibatch 900::LR 0.0792307692308 --> Loss 0.00343183120092\n",
      "Epoch 10::Minibatch 901::LR 0.0792307692308 --> Loss 0.000646055887143\n",
      "Epoch 10::Minibatch 902::LR 0.0792307692308 --> Loss 0.00145593434572\n",
      "Epoch 10::Minibatch 903::LR 0.0792307692308 --> Loss 0.00280540049076\n",
      "Epoch 10::Minibatch 904::LR 0.0792307692308 --> Loss 0.0022541085879\n",
      "Epoch 10::Minibatch 905::LR 0.0792307692308 --> Loss 0.00148134022951\n",
      "Epoch 10::Minibatch 906::LR 0.0792307692308 --> Loss 0.00113307724396\n",
      "Epoch 10::Minibatch 907::LR 0.0792307692308 --> Loss 0.00161053518454\n",
      "Epoch 10::Minibatch 908::LR 0.0792307692308 --> Loss 0.00250380198161\n",
      "Epoch 10::Minibatch 909::LR 0.0792307692308 --> Loss 0.00228537976742\n",
      "Epoch 10::Minibatch 910::LR 0.0792307692308 --> Loss 0.000862637062867\n",
      "Epoch 10::Minibatch 911::LR 0.0792307692308 --> Loss 0.00125367542108\n",
      "Epoch 10::Minibatch 912::LR 0.0792307692308 --> Loss 0.00220886985461\n",
      "Epoch 10::Minibatch 913::LR 0.0792307692308 --> Loss 0.00225822746754\n",
      "Epoch 10::Minibatch 914::LR 0.0792307692308 --> Loss 0.00133329858383\n",
      "Epoch 10::Minibatch 915::LR 0.0792307692308 --> Loss 0.000511474361022\n",
      "Epoch 10::Minibatch 916::LR 0.0792307692308 --> Loss 0.00270243227482\n",
      "Epoch 10::Minibatch 917::LR 0.0792307692308 --> Loss 0.00417411088943\n",
      "Epoch 10::Minibatch 918::LR 0.0792307692308 --> Loss 0.00599246223768\n",
      "Epoch 10::Minibatch 919::LR 0.0792307692308 --> Loss 0.000846740206083\n",
      "Epoch 10::Minibatch 920::LR 0.0792307692308 --> Loss 0.0109652638435\n",
      "Epoch 10::Minibatch 921::LR 0.0792307692308 --> Loss 0.00305967728297\n",
      "Epoch 10::Minibatch 922::LR 0.0792307692308 --> Loss 0.00329754273097\n",
      "Epoch 10::Minibatch 923::LR 0.0792307692308 --> Loss 0.00175507624944\n",
      "Epoch 10::Minibatch 924::LR 0.0792307692308 --> Loss 0.00373292009036\n",
      "Epoch 10::Minibatch 925::LR 0.0792307692308 --> Loss 0.00283994416396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10::Minibatch 926::LR 0.0792307692308 --> Loss 0.00557930231094\n",
      "Epoch 10::Minibatch 927::LR 0.0792307692308 --> Loss 0.00903089523315\n",
      "Epoch 10::Minibatch 928::LR 0.0792307692308 --> Loss 0.00693329731623\n",
      "Epoch 10::Minibatch 929::LR 0.0792307692308 --> Loss 0.00824098348618\n",
      "Epoch 10::Minibatch 930::LR 0.0792307692308 --> Loss 0.00778146107992\n",
      "Epoch 10::Minibatch 931::LR 0.0792307692308 --> Loss 0.00388188680013\n",
      "Epoch 10::Minibatch 932::LR 0.0792307692308 --> Loss 0.00843263864517\n",
      "Epoch 10::Minibatch 933::LR 0.0792307692308 --> Loss 0.00417167504628\n",
      "Epoch 10::Minibatch 934::LR 0.0792307692308 --> Loss 0.0054834763209\n",
      "Epoch 10::Minibatch 935::LR 0.0792307692308 --> Loss 0.00741251309713\n",
      "Epoch 10::Minibatch 936::LR 0.0792307692308 --> Loss 0.0018288731575\n",
      "Epoch 10::Minibatch 937::LR 0.0792307692308 --> Loss 0.00390251596769\n",
      "Epoch 10::Minibatch 938::LR 0.0792307692308 --> Loss 0.00370754679044\n",
      "Epoch 10::Minibatch 939::LR 0.0792307692308 --> Loss 0.00373827497164\n",
      "Epoch 10::Minibatch 940::LR 0.0792307692308 --> Loss 0.00113215674957\n",
      "Epoch 10::Minibatch 941::LR 0.0792307692308 --> Loss 0.00093665411075\n",
      "Epoch 10::Minibatch 942::LR 0.0792307692308 --> Loss 0.00248039662838\n",
      "Epoch 10::Minibatch 943::LR 0.0792307692308 --> Loss 0.00328428089619\n",
      "Epoch 10::Minibatch 944::LR 0.0792307692308 --> Loss 0.00238673885663\n",
      "Epoch 10::Minibatch 945::LR 0.0792307692308 --> Loss 0.0014198833704\n",
      "Epoch 10::Minibatch 946::LR 0.0792307692308 --> Loss 0.00358892798424\n",
      "Epoch 10::Minibatch 947::LR 0.0792307692308 --> Loss 0.00313549617926\n",
      "Epoch 10::Minibatch 948::LR 0.0792307692308 --> Loss 0.00563105742137\n",
      "Epoch 10::Minibatch 949::LR 0.0792307692308 --> Loss 0.00202519595623\n",
      "Epoch 10::Minibatch 950::LR 0.0792307692308 --> Loss 0.000752718895674\n",
      "Epoch 10::Minibatch 951::LR 0.0792307692308 --> Loss 0.00344076514244\n",
      "Epoch 10::Minibatch 952::LR 0.0792307692308 --> Loss 0.00251857062181\n",
      "Epoch 10::Minibatch 953::LR 0.0792307692308 --> Loss 0.00138332635164\n",
      "Epoch 10::Minibatch 954::LR 0.0792307692308 --> Loss 0.000974723994732\n",
      "Epoch 10::Minibatch 955::LR 0.0792307692308 --> Loss 0.00259537001451\n",
      "Epoch 10::Minibatch 956::LR 0.0792307692308 --> Loss 0.00420103867849\n",
      "Epoch 10::Minibatch 957::LR 0.0792307692308 --> Loss 0.00195679386457\n",
      "Epoch 10::Minibatch 958::LR 0.0792307692308 --> Loss 0.00254396339258\n",
      "Epoch 10::Minibatch 959::LR 0.0792307692308 --> Loss 0.00315746108691\n",
      "Epoch 10::Minibatch 960::LR 0.0792307692308 --> Loss 0.00696466207504\n",
      "Epoch 10::Minibatch 961::LR 0.0792307692308 --> Loss 0.00349612275759\n",
      "Epoch 10::Minibatch 962::LR 0.0792307692308 --> Loss 0.00312707165877\n",
      "Epoch 10::Minibatch 963::LR 0.0792307692308 --> Loss 0.00111132363478\n",
      "Epoch 10::Minibatch 964::LR 0.0792307692308 --> Loss 0.00251497944196\n",
      "Epoch 10::Minibatch 965::LR 0.0792307692308 --> Loss 0.00839321374893\n",
      "Epoch 10::Minibatch 966::LR 0.0792307692308 --> Loss 0.00570312460264\n",
      "Epoch 10::Minibatch 967::LR 0.0792307692308 --> Loss 0.00193353990714\n",
      "Epoch 10::Minibatch 968::LR 0.0792307692308 --> Loss 0.00177834133307\n",
      "Epoch 10::Minibatch 969::LR 0.0792307692308 --> Loss 0.00754187981288\n",
      "Epoch 10::Minibatch 970::LR 0.0792307692308 --> Loss 0.00616153915723\n",
      "Epoch 10::Minibatch 971::LR 0.0792307692308 --> Loss 0.00364048480988\n",
      "Epoch 10::Minibatch 972::LR 0.0792307692308 --> Loss 0.00953840653102\n",
      "Epoch 10::Minibatch 973::LR 0.0792307692308 --> Loss 0.00922785202662\n",
      "Epoch 10::Minibatch 974::LR 0.0792307692308 --> Loss 0.00649279554685\n",
      "Epoch 10::Minibatch 975::LR 0.0792307692308 --> Loss 0.00482858379682\n",
      "Epoch 10::Minibatch 976::LR 0.0792307692308 --> Loss 0.00434573252996\n",
      "Epoch 10::Minibatch 977::LR 0.0792307692308 --> Loss 0.00438001871109\n",
      "Epoch 10::Minibatch 978::LR 0.0792307692308 --> Loss 0.00426336725553\n",
      "Epoch 10::Minibatch 979::LR 0.0792307692308 --> Loss 0.0042395679156\n",
      "Epoch 10::Minibatch 980::LR 0.0792307692308 --> Loss 0.00412551363309\n",
      "Epoch 10::Minibatch 981::LR 0.0792307692308 --> Loss 0.00536992907524\n",
      "Epoch 10::Minibatch 982::LR 0.0792307692308 --> Loss 0.00715284585953\n",
      "Epoch 10::Minibatch 983::LR 0.0792307692308 --> Loss 0.00321911672751\n",
      "Epoch 10::Minibatch 984::LR 0.0792307692308 --> Loss 0.00308440983295\n",
      "Epoch 10::Minibatch 985::LR 0.0792307692308 --> Loss 0.00461394071579\n",
      "Epoch 10::Minibatch 986::LR 0.0792307692308 --> Loss 0.00416988889376\n",
      "Epoch 10::Minibatch 987::LR 0.0792307692308 --> Loss 0.00454149524371\n",
      "Epoch 10::Minibatch 988::LR 0.0792307692308 --> Loss 0.00342776815097\n",
      "Epoch 10::Minibatch 989::LR 0.0792307692308 --> Loss 0.00344527800878\n",
      "Epoch 10::Minibatch 990::LR 0.0792307692308 --> Loss 0.00330102185408\n",
      "Epoch 10::Minibatch 991::LR 0.0792307692308 --> Loss 0.00172687093417\n",
      "Epoch 10::Minibatch 992::LR 0.0792307692308 --> Loss 0.00196315626303\n",
      "Epoch 10::Minibatch 993::LR 0.0792307692308 --> Loss 0.0034382891655\n",
      "Epoch 10::Minibatch 994::LR 0.0792307692308 --> Loss 0.00204509238402\n",
      "Epoch 10::Minibatch 995::LR 0.0792307692308 --> Loss 0.000883801877499\n",
      "Epoch 10::Minibatch 996::LR 0.0792307692308 --> Loss 0.00327243963877\n",
      "Epoch 10::Minibatch 997::LR 0.0792307692308 --> Loss 0.00216950396697\n",
      "Epoch 10::Minibatch 998::LR 0.0792307692308 --> Loss 0.0022408982118\n",
      "Epoch 10::Minibatch 999::LR 0.0792307692308 --> Loss 0.00181471725305\n",
      "Epoch 10::Minibatch 1000::LR 0.0792307692308 --> Loss 0.00215079665184\n",
      "Epoch 10::Minibatch 1001::LR 0.0792307692308 --> Loss 0.00176018198331\n",
      "Epoch 10::Minibatch 1002::LR 0.0792307692308 --> Loss 0.00296602169673\n",
      "Epoch 10::Minibatch 1003::LR 0.0792307692308 --> Loss 0.00381531397502\n",
      "Epoch 10::Minibatch 1004::LR 0.0792307692308 --> Loss 0.00100663175186\n",
      "Epoch 10::Minibatch 1005::LR 0.0792307692308 --> Loss 0.00428280353546\n",
      "Epoch 10::Minibatch 1006::LR 0.0792307692308 --> Loss 0.00282176295916\n",
      "Epoch 10::Minibatch 1007::LR 0.0792307692308 --> Loss 0.00315773785114\n",
      "Epoch 10::Minibatch 1008::LR 0.0792307692308 --> Loss 0.000963674982389\n",
      "Epoch 10::Minibatch 1009::LR 0.0792307692308 --> Loss 0.00206501523654\n",
      "Epoch 10::Minibatch 1010::LR 0.0792307692308 --> Loss 0.00185480197271\n",
      "Epoch 10::Minibatch 1011::LR 0.0792307692308 --> Loss 0.00416254003843\n",
      "Epoch 10::Minibatch 1012::LR 0.0792307692308 --> Loss 0.0021810934941\n",
      "Epoch 10::Minibatch 1013::LR 0.0792307692308 --> Loss 0.00482346574465\n",
      "Epoch 10::Minibatch 1014::LR 0.0792307692308 --> Loss 0.00451669573784\n",
      "Epoch 10::Minibatch 1015::LR 0.0792307692308 --> Loss 0.00177225450675\n",
      "Epoch 10::Minibatch 1016::LR 0.0792307692308 --> Loss 0.00533563296\n",
      "Epoch 10::Minibatch 1017::LR 0.0792307692308 --> Loss 0.00357142051061\n",
      "Epoch 10::Minibatch 1018::LR 0.0792307692308 --> Loss 0.00329683383306\n",
      "Epoch 10::Minibatch 1019::LR 0.0792307692308 --> Loss 0.00245940725009\n",
      "Epoch 10::Minibatch 1020::LR 0.0792307692308 --> Loss 0.00242493669192\n",
      "Epoch 10::Minibatch 1021::LR 0.0792307692308 --> Loss 0.00234465797742\n",
      "Epoch 10::Minibatch 1022::LR 0.0792307692308 --> Loss 0.00182334681352\n",
      "Epoch 10::Minibatch 1023::LR 0.0792307692308 --> Loss 0.00147795250018\n",
      "Epoch 10::Minibatch 1024::LR 0.0792307692308 --> Loss 0.0014155515035\n",
      "Epoch 10::Minibatch 1025::LR 0.0792307692308 --> Loss 0.00155089060465\n",
      "Epoch 10::Minibatch 1026::LR 0.0792307692308 --> Loss 0.000984291831652\n",
      "Epoch 10::Minibatch 1027::LR 0.0792307692308 --> Loss 0.00114176203807\n",
      "Epoch 10::Minibatch 1028::LR 0.0792307692308 --> Loss 0.000887216230234\n",
      "Epoch 10::Minibatch 1029::LR 0.0792307692308 --> Loss 0.000848817626635\n",
      "Epoch 10::Minibatch 1030::LR 0.0792307692308 --> Loss 0.00105024844408\n",
      "Epoch 10::Minibatch 1031::LR 0.0792307692308 --> Loss 0.000834770699342\n",
      "Epoch 10::Minibatch 1032::LR 0.0792307692308 --> Loss 0.00082982664307\n",
      "Epoch 10::Minibatch 1033::LR 0.0792307692308 --> Loss 0.000694296658039\n",
      "Epoch 10::Minibatch 1034::LR 0.0792307692308 --> Loss 0.000704320867856\n",
      "Epoch 10::Minibatch 1035::LR 0.0792307692308 --> Loss 0.000538989504178\n",
      "Epoch 10::Minibatch 1036::LR 0.0792307692308 --> Loss 0.000434467395147\n",
      "Epoch 10::Minibatch 1037::LR 0.0792307692308 --> Loss 0.000599992722273\n",
      "Epoch 10::Minibatch 1038::LR 0.0792307692308 --> Loss 0.00135390112797\n",
      "Epoch 10::Minibatch 1039::LR 0.0792307692308 --> Loss 0.00112717906634\n",
      "Epoch 10::Minibatch 1040::LR 0.0792307692308 --> Loss 0.000503539045652\n",
      "Epoch 10::Minibatch 1041::LR 0.0792307692308 --> Loss 0.000651663740476\n",
      "Epoch 11::Minibatch 1::LR 0.0769230769231 --> Loss 0.0101513409615\n",
      "Epoch 11::Minibatch 2::LR 0.0769230769231 --> Loss 0.00615197658539\n",
      "Epoch 11::Minibatch 3::LR 0.0769230769231 --> Loss 0.00400559067726\n",
      "Epoch 11::Minibatch 4::LR 0.0769230769231 --> Loss 0.00424542427063\n",
      "Epoch 11::Minibatch 5::LR 0.0769230769231 --> Loss 0.00468575914701\n",
      "Epoch 11::Minibatch 6::LR 0.0769230769231 --> Loss 0.00245548963547\n",
      "Epoch 11::Minibatch 7::LR 0.0769230769231 --> Loss 0.00741888046265\n",
      "Epoch 11::Minibatch 8::LR 0.0769230769231 --> Loss 0.00735685586929\n",
      "Epoch 11::Minibatch 9::LR 0.0769230769231 --> Loss 0.00517913738887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 10::LR 0.0769230769231 --> Loss 0.00289876619975\n",
      "Epoch 11::Minibatch 11::LR 0.0769230769231 --> Loss 0.00235914289951\n",
      "Epoch 11::Minibatch 12::LR 0.0769230769231 --> Loss 0.00333616693815\n",
      "Epoch 11::Minibatch 13::LR 0.0769230769231 --> Loss 0.00498565793037\n",
      "Epoch 11::Minibatch 14::LR 0.0769230769231 --> Loss 0.00482701142629\n",
      "Epoch 11::Minibatch 15::LR 0.0769230769231 --> Loss 0.00379179000854\n",
      "Epoch 11::Minibatch 16::LR 0.0769230769231 --> Loss 0.000849148233732\n",
      "Epoch 11::Minibatch 17::LR 0.0769230769231 --> Loss 0.00282695074876\n",
      "Epoch 11::Minibatch 18::LR 0.0769230769231 --> Loss 0.00239961564541\n",
      "Epoch 11::Minibatch 19::LR 0.0769230769231 --> Loss 0.00108192841212\n",
      "Epoch 11::Minibatch 20::LR 0.0769230769231 --> Loss 0.00155105113983\n",
      "Epoch 11::Minibatch 21::LR 0.0769230769231 --> Loss 0.00322456697623\n",
      "Epoch 11::Minibatch 22::LR 0.0769230769231 --> Loss 0.00236563007037\n",
      "Epoch 11::Minibatch 23::LR 0.0769230769231 --> Loss 0.000770871539911\n",
      "Epoch 11::Minibatch 24::LR 0.0769230769231 --> Loss 0.000355420435468\n",
      "Epoch 11::Minibatch 25::LR 0.0769230769231 --> Loss 0.00107188483079\n",
      "Epoch 11::Minibatch 26::LR 0.0769230769231 --> Loss 0.00127714286248\n",
      "Epoch 11::Minibatch 27::LR 0.0769230769231 --> Loss 0.000894670983156\n",
      "Epoch 11::Minibatch 28::LR 0.0769230769231 --> Loss 0.000359170685212\n",
      "Epoch 11::Minibatch 29::LR 0.0769230769231 --> Loss 0.000335825333993\n",
      "Epoch 11::Minibatch 30::LR 0.0769230769231 --> Loss 0.000814159015814\n",
      "Epoch 11::Minibatch 31::LR 0.0769230769231 --> Loss 0.00128322949012\n",
      "Epoch 11::Minibatch 32::LR 0.0769230769231 --> Loss 0.00124710838\n",
      "Epoch 11::Minibatch 33::LR 0.0769230769231 --> Loss 0.000780195047458\n",
      "Epoch 11::Minibatch 34::LR 0.0769230769231 --> Loss 0.00249921560287\n",
      "Epoch 11::Minibatch 35::LR 0.0769230769231 --> Loss 0.00435591777166\n",
      "Epoch 11::Minibatch 36::LR 0.0769230769231 --> Loss 0.00217317918936\n",
      "Epoch 11::Minibatch 37::LR 0.0769230769231 --> Loss 0.000617510676384\n",
      "Epoch 11::Minibatch 38::LR 0.0769230769231 --> Loss 0.000796718001366\n",
      "Epoch 11::Minibatch 39::LR 0.0769230769231 --> Loss 0.0024784920613\n",
      "Epoch 11::Minibatch 40::LR 0.0769230769231 --> Loss 0.00386527895927\n",
      "Epoch 11::Minibatch 41::LR 0.0769230769231 --> Loss 0.00326050718625\n",
      "Epoch 11::Minibatch 42::LR 0.0769230769231 --> Loss 0.00633327404658\n",
      "Epoch 11::Minibatch 43::LR 0.0769230769231 --> Loss 0.0018601244688\n",
      "Epoch 11::Minibatch 44::LR 0.0769230769231 --> Loss 0.00313402791818\n",
      "Epoch 11::Minibatch 45::LR 0.0769230769231 --> Loss 0.00260388890902\n",
      "Epoch 11::Minibatch 46::LR 0.0769230769231 --> Loss 0.00367356936137\n",
      "Epoch 11::Minibatch 47::LR 0.0769230769231 --> Loss 0.00517865498861\n",
      "Epoch 11::Minibatch 48::LR 0.0769230769231 --> Loss 0.00627949515978\n",
      "Epoch 11::Minibatch 49::LR 0.0769230769231 --> Loss 0.00628370165825\n",
      "Epoch 11::Minibatch 50::LR 0.0769230769231 --> Loss 0.00597281416257\n",
      "Epoch 11::Minibatch 51::LR 0.0769230769231 --> Loss 0.00913874387741\n",
      "Epoch 11::Minibatch 52::LR 0.0769230769231 --> Loss 0.00362013419469\n",
      "Epoch 11::Minibatch 53::LR 0.0769230769231 --> Loss 0.0035518848896\n",
      "Epoch 11::Minibatch 54::LR 0.0769230769231 --> Loss 0.00402806162834\n",
      "Epoch 11::Minibatch 55::LR 0.0769230769231 --> Loss 0.00104500522216\n",
      "Epoch 11::Minibatch 56::LR 0.0769230769231 --> Loss 0.00282525877158\n",
      "Epoch 11::Minibatch 57::LR 0.0769230769231 --> Loss 0.00629956444105\n",
      "Epoch 11::Minibatch 58::LR 0.0769230769231 --> Loss 0.0034912610054\n",
      "Epoch 11::Minibatch 59::LR 0.0769230769231 --> Loss 0.00282494505246\n",
      "Epoch 11::Minibatch 60::LR 0.0769230769231 --> Loss 0.00247186104457\n",
      "Epoch 11::Minibatch 61::LR 0.0769230769231 --> Loss 0.00102773368359\n",
      "Epoch 11::Minibatch 62::LR 0.0769230769231 --> Loss 0.00359332362811\n",
      "Epoch 11::Minibatch 63::LR 0.0769230769231 --> Loss 0.00231354475021\n",
      "Epoch 11::Minibatch 64::LR 0.0769230769231 --> Loss 0.00101925820112\n",
      "Epoch 11::Minibatch 65::LR 0.0769230769231 --> Loss 0.0024801560243\n",
      "Epoch 11::Minibatch 66::LR 0.0769230769231 --> Loss 0.00306073307991\n",
      "Epoch 11::Minibatch 67::LR 0.0769230769231 --> Loss 0.0029224195083\n",
      "Epoch 11::Minibatch 68::LR 0.0769230769231 --> Loss 0.00208294490973\n",
      "Epoch 11::Minibatch 69::LR 0.0769230769231 --> Loss 0.00411850849787\n",
      "Epoch 11::Minibatch 70::LR 0.0769230769231 --> Loss 0.00353742321332\n",
      "Epoch 11::Minibatch 71::LR 0.0769230769231 --> Loss 0.00241092741489\n",
      "Epoch 11::Minibatch 72::LR 0.0769230769231 --> Loss 0.000567097812891\n",
      "Epoch 11::Minibatch 73::LR 0.0769230769231 --> Loss 0.00403507987658\n",
      "Epoch 11::Minibatch 74::LR 0.0769230769231 --> Loss 0.00425228993098\n",
      "Epoch 11::Minibatch 75::LR 0.0769230769231 --> Loss 0.00274959782759\n",
      "Epoch 11::Minibatch 76::LR 0.0769230769231 --> Loss 0.000693054397901\n",
      "Epoch 11::Minibatch 77::LR 0.0769230769231 --> Loss 0.00438566565514\n",
      "Epoch 11::Minibatch 78::LR 0.0769230769231 --> Loss 0.00396075725555\n",
      "Epoch 11::Minibatch 79::LR 0.0769230769231 --> Loss 0.00220071951548\n",
      "Epoch 11::Minibatch 80::LR 0.0769230769231 --> Loss 0.00354424794515\n",
      "Epoch 11::Minibatch 81::LR 0.0769230769231 --> Loss 0.00307779431343\n",
      "Epoch 11::Minibatch 82::LR 0.0769230769231 --> Loss 0.00210617661476\n",
      "Epoch 11::Minibatch 83::LR 0.0769230769231 --> Loss 0.00517924507459\n",
      "Epoch 11::Minibatch 84::LR 0.0769230769231 --> Loss 0.00215028345585\n",
      "Epoch 11::Minibatch 85::LR 0.0769230769231 --> Loss 0.00294674058755\n",
      "Epoch 11::Minibatch 86::LR 0.0769230769231 --> Loss 0.00239587525527\n",
      "Epoch 11::Minibatch 87::LR 0.0769230769231 --> Loss 0.00267842829227\n",
      "Epoch 11::Minibatch 88::LR 0.0769230769231 --> Loss 0.00196529646715\n",
      "Epoch 11::Minibatch 89::LR 0.0769230769231 --> Loss 0.00246474583944\n",
      "Epoch 11::Minibatch 90::LR 0.0769230769231 --> Loss 0.00131591886282\n",
      "Epoch 11::Minibatch 91::LR 0.0769230769231 --> Loss 0.00107846001784\n",
      "Epoch 11::Minibatch 92::LR 0.0769230769231 --> Loss 0.00277380267779\n",
      "Epoch 11::Minibatch 93::LR 0.0769230769231 --> Loss 0.00188892026742\n",
      "Epoch 11::Minibatch 94::LR 0.0769230769231 --> Loss 0.00185850719611\n",
      "Epoch 11::Minibatch 95::LR 0.0769230769231 --> Loss 0.00177794198195\n",
      "Epoch 11::Minibatch 96::LR 0.0769230769231 --> Loss 0.00629649798075\n",
      "Epoch 11::Minibatch 97::LR 0.0769230769231 --> Loss 0.00329768776894\n",
      "Epoch 11::Minibatch 98::LR 0.0769230769231 --> Loss 0.000970027844111\n",
      "Epoch 11::Minibatch 99::LR 0.0769230769231 --> Loss 0.00130102485418\n",
      "Epoch 11::Minibatch 100::LR 0.0769230769231 --> Loss 0.00562667767207\n",
      "Epoch 11::Minibatch 101::LR 0.0769230769231 --> Loss 0.00100179165602\n",
      "Epoch 11::Minibatch 102::LR 0.0769230769231 --> Loss 0.00385175506274\n",
      "Epoch 11::Minibatch 103::LR 0.0769230769231 --> Loss 0.00405863841375\n",
      "Epoch 11::Minibatch 104::LR 0.0769230769231 --> Loss 0.0028801548481\n",
      "Epoch 11::Minibatch 105::LR 0.0769230769231 --> Loss 0.00323450704416\n",
      "Epoch 11::Minibatch 106::LR 0.0769230769231 --> Loss 0.0191925207774\n",
      "Epoch 11::Minibatch 107::LR 0.0769230769231 --> Loss 0.00491329352061\n",
      "Epoch 11::Minibatch 108::LR 0.0769230769231 --> Loss 0.00122988363107\n",
      "Epoch 11::Minibatch 109::LR 0.0769230769231 --> Loss 0.00459174791972\n",
      "Epoch 11::Minibatch 110::LR 0.0769230769231 --> Loss 0.0026158696413\n",
      "Epoch 11::Minibatch 111::LR 0.0769230769231 --> Loss 0.00113965779543\n",
      "Epoch 11::Minibatch 112::LR 0.0769230769231 --> Loss 0.00381303071976\n",
      "Epoch 11::Minibatch 113::LR 0.0769230769231 --> Loss 0.00292749404907\n",
      "Epoch 11::Minibatch 114::LR 0.0769230769231 --> Loss 0.0016455167532\n",
      "Epoch 11::Minibatch 115::LR 0.0769230769231 --> Loss 0.00153295954069\n",
      "Epoch 11::Minibatch 116::LR 0.0769230769231 --> Loss 0.00301543295383\n",
      "Epoch 11::Minibatch 117::LR 0.0769230769231 --> Loss 0.00381704807281\n",
      "Epoch 11::Minibatch 118::LR 0.0769230769231 --> Loss 0.00708199898402\n",
      "Epoch 11::Minibatch 119::LR 0.0769230769231 --> Loss 0.000808417250713\n",
      "Epoch 11::Minibatch 120::LR 0.0769230769231 --> Loss 0.00202812512716\n",
      "Epoch 11::Minibatch 121::LR 0.0769230769231 --> Loss 0.00298902014891\n",
      "Epoch 11::Minibatch 122::LR 0.0769230769231 --> Loss 0.00377331495285\n",
      "Epoch 11::Minibatch 123::LR 0.0769230769231 --> Loss 0.00134260654449\n",
      "Epoch 11::Minibatch 124::LR 0.0769230769231 --> Loss 0.0029943193992\n",
      "Epoch 11::Minibatch 125::LR 0.0769230769231 --> Loss 0.00484676122665\n",
      "Epoch 11::Minibatch 126::LR 0.0769230769231 --> Loss 0.00293261508147\n",
      "Epoch 11::Minibatch 127::LR 0.0769230769231 --> Loss 0.00457035303116\n",
      "Epoch 11::Minibatch 128::LR 0.0769230769231 --> Loss 0.00373495340347\n",
      "Epoch 11::Minibatch 129::LR 0.0769230769231 --> Loss 0.00293752928575\n",
      "Epoch 11::Minibatch 130::LR 0.0769230769231 --> Loss 0.00439162254333\n",
      "Epoch 11::Minibatch 131::LR 0.0769230769231 --> Loss 0.00192497253418\n",
      "Epoch 11::Minibatch 132::LR 0.0769230769231 --> Loss 0.00331910947959\n",
      "Epoch 11::Minibatch 133::LR 0.0769230769231 --> Loss 0.00318794727325\n",
      "Epoch 11::Minibatch 134::LR 0.0769230769231 --> Loss 0.00261086980502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 135::LR 0.0769230769231 --> Loss 0.00183412293593\n",
      "Epoch 11::Minibatch 136::LR 0.0769230769231 --> Loss 0.00292592287064\n",
      "Epoch 11::Minibatch 137::LR 0.0769230769231 --> Loss 0.00383035222689\n",
      "Epoch 11::Minibatch 138::LR 0.0769230769231 --> Loss 0.00141298641761\n",
      "Epoch 11::Minibatch 139::LR 0.0769230769231 --> Loss 0.00195001542568\n",
      "Epoch 11::Minibatch 140::LR 0.0769230769231 --> Loss 0.00251283248266\n",
      "Epoch 11::Minibatch 141::LR 0.0769230769231 --> Loss 0.00306153098742\n",
      "Epoch 11::Minibatch 142::LR 0.0769230769231 --> Loss 0.00314452052116\n",
      "Epoch 11::Minibatch 143::LR 0.0769230769231 --> Loss 0.000674588779608\n",
      "Epoch 11::Minibatch 144::LR 0.0769230769231 --> Loss 0.0032059554259\n",
      "Epoch 11::Minibatch 145::LR 0.0769230769231 --> Loss 0.00442004799843\n",
      "Epoch 11::Minibatch 146::LR 0.0769230769231 --> Loss 0.00270315825939\n",
      "Epoch 11::Minibatch 147::LR 0.0769230769231 --> Loss 0.00186724384626\n",
      "Epoch 11::Minibatch 148::LR 0.0769230769231 --> Loss 0.00107128361861\n",
      "Epoch 11::Minibatch 149::LR 0.0769230769231 --> Loss 0.00287500103315\n",
      "Epoch 11::Minibatch 150::LR 0.0769230769231 --> Loss 0.00282061477502\n",
      "Epoch 11::Minibatch 151::LR 0.0769230769231 --> Loss 0.00429205020269\n",
      "Epoch 11::Minibatch 152::LR 0.0769230769231 --> Loss 0.000966457923253\n",
      "Epoch 11::Minibatch 153::LR 0.0769230769231 --> Loss 0.00193597038587\n",
      "Epoch 11::Minibatch 154::LR 0.0769230769231 --> Loss 0.00211636463801\n",
      "Epoch 11::Minibatch 155::LR 0.0769230769231 --> Loss 0.00485996882121\n",
      "Epoch 11::Minibatch 156::LR 0.0769230769231 --> Loss 0.00246767143408\n",
      "Epoch 11::Minibatch 157::LR 0.0769230769231 --> Loss 0.0007253130277\n",
      "Epoch 11::Minibatch 158::LR 0.0769230769231 --> Loss 0.00312587936719\n",
      "Epoch 11::Minibatch 159::LR 0.0769230769231 --> Loss 0.00281909902891\n",
      "Epoch 11::Minibatch 160::LR 0.0769230769231 --> Loss 0.00270979881287\n",
      "Epoch 11::Minibatch 161::LR 0.0769230769231 --> Loss 0.00106483250856\n",
      "Epoch 11::Minibatch 162::LR 0.0769230769231 --> Loss 0.00365510543187\n",
      "Epoch 11::Minibatch 163::LR 0.0769230769231 --> Loss 0.00245672384898\n",
      "Epoch 11::Minibatch 164::LR 0.0769230769231 --> Loss 0.00252710481485\n",
      "Epoch 11::Minibatch 165::LR 0.0769230769231 --> Loss 0.000569388916095\n",
      "Epoch 11::Minibatch 166::LR 0.0769230769231 --> Loss 0.00185583909353\n",
      "Epoch 11::Minibatch 167::LR 0.0769230769231 --> Loss 0.00249504586061\n",
      "Epoch 11::Minibatch 168::LR 0.0769230769231 --> Loss 0.00225396811962\n",
      "Epoch 11::Minibatch 169::LR 0.0769230769231 --> Loss 0.00105193734169\n",
      "Epoch 11::Minibatch 170::LR 0.0769230769231 --> Loss 0.001025839746\n",
      "Epoch 11::Minibatch 171::LR 0.0769230769231 --> Loss 0.00256695707639\n",
      "Epoch 11::Minibatch 172::LR 0.0769230769231 --> Loss 0.0048004368941\n",
      "Epoch 11::Minibatch 173::LR 0.0769230769231 --> Loss 0.0020015480121\n",
      "Epoch 11::Minibatch 174::LR 0.0769230769231 --> Loss 0.00109743227561\n",
      "Epoch 11::Minibatch 175::LR 0.0769230769231 --> Loss 0.00231325089931\n",
      "Epoch 11::Minibatch 176::LR 0.0769230769231 --> Loss 0.00335283358892\n",
      "Epoch 11::Minibatch 177::LR 0.0769230769231 --> Loss 0.00489916324615\n",
      "Epoch 11::Minibatch 178::LR 0.0769230769231 --> Loss 0.0017078067859\n",
      "Epoch 11::Minibatch 179::LR 0.0769230769231 --> Loss 0.00140791018804\n",
      "Epoch 11::Minibatch 180::LR 0.0769230769231 --> Loss 0.00368462483088\n",
      "Epoch 11::Minibatch 181::LR 0.0769230769231 --> Loss 0.00343549648921\n",
      "Epoch 11::Minibatch 182::LR 0.0769230769231 --> Loss 0.000845680634181\n",
      "Epoch 11::Minibatch 183::LR 0.0769230769231 --> Loss 0.00174935062726\n",
      "Epoch 11::Minibatch 184::LR 0.0769230769231 --> Loss 0.00343859314919\n",
      "Epoch 11::Minibatch 185::LR 0.0769230769231 --> Loss 0.00289078275363\n",
      "Epoch 11::Minibatch 186::LR 0.0769230769231 --> Loss 0.00102565556765\n",
      "Epoch 11::Minibatch 187::LR 0.0769230769231 --> Loss 0.00125711162885\n",
      "Epoch 11::Minibatch 188::LR 0.0769230769231 --> Loss 0.00416898449262\n",
      "Epoch 11::Minibatch 189::LR 0.0769230769231 --> Loss 0.00461126128832\n",
      "Epoch 11::Minibatch 190::LR 0.0769230769231 --> Loss 0.00234061717987\n",
      "Epoch 11::Minibatch 191::LR 0.0769230769231 --> Loss 0.000527229905128\n",
      "Epoch 11::Minibatch 192::LR 0.0769230769231 --> Loss 0.00269389609496\n",
      "Epoch 11::Minibatch 193::LR 0.0769230769231 --> Loss 0.00251222491264\n",
      "Epoch 11::Minibatch 194::LR 0.0769230769231 --> Loss 0.00183185954889\n",
      "Epoch 11::Minibatch 195::LR 0.0769230769231 --> Loss 0.000408145909508\n",
      "Epoch 11::Minibatch 196::LR 0.0769230769231 --> Loss 0.00121458172798\n",
      "Epoch 11::Minibatch 197::LR 0.0769230769231 --> Loss 0.00281396269798\n",
      "Epoch 11::Minibatch 198::LR 0.0769230769231 --> Loss 0.00218740801016\n",
      "Epoch 11::Minibatch 199::LR 0.0769230769231 --> Loss 0.000301996022463\n",
      "Epoch 11::Minibatch 200::LR 0.0769230769231 --> Loss 0.00211936573188\n",
      "Epoch 11::Minibatch 201::LR 0.0769230769231 --> Loss 0.00199580669403\n",
      "Epoch 11::Minibatch 202::LR 0.0769230769231 --> Loss 0.00193656206131\n",
      "Epoch 11::Minibatch 203::LR 0.0769230769231 --> Loss 0.0018530412515\n",
      "Epoch 11::Minibatch 204::LR 0.0769230769231 --> Loss 0.00157365848621\n",
      "Epoch 11::Minibatch 205::LR 0.0769230769231 --> Loss 0.00227778871854\n",
      "Epoch 11::Minibatch 206::LR 0.0769230769231 --> Loss 0.00714955409368\n",
      "Epoch 11::Minibatch 207::LR 0.0769230769231 --> Loss 0.00142430067062\n",
      "Epoch 11::Minibatch 208::LR 0.0769230769231 --> Loss 0.00119446893533\n",
      "Epoch 11::Minibatch 209::LR 0.0769230769231 --> Loss 0.00213752746582\n",
      "Epoch 11::Minibatch 210::LR 0.0769230769231 --> Loss 0.00199950734774\n",
      "Epoch 11::Minibatch 211::LR 0.0769230769231 --> Loss 0.00211438119411\n",
      "Epoch 11::Minibatch 212::LR 0.0769230769231 --> Loss 0.00422418475151\n",
      "Epoch 11::Minibatch 213::LR 0.0769230769231 --> Loss 0.00617831746737\n",
      "Epoch 11::Minibatch 214::LR 0.0769230769231 --> Loss 0.010148173968\n",
      "Epoch 11::Minibatch 215::LR 0.0769230769231 --> Loss 0.0014610572656\n",
      "Epoch 11::Minibatch 216::LR 0.0769230769231 --> Loss 0.00557386000951\n",
      "Epoch 11::Minibatch 217::LR 0.0769230769231 --> Loss 0.00611670176188\n",
      "Epoch 11::Minibatch 218::LR 0.0769230769231 --> Loss 0.00407945513725\n",
      "Epoch 11::Minibatch 219::LR 0.0769230769231 --> Loss 0.00384536703428\n",
      "Epoch 11::Minibatch 220::LR 0.0769230769231 --> Loss 0.00463668266932\n",
      "Epoch 11::Minibatch 221::LR 0.0769230769231 --> Loss 0.00432852784793\n",
      "Epoch 11::Minibatch 222::LR 0.0769230769231 --> Loss 0.00335861047109\n",
      "Epoch 11::Minibatch 223::LR 0.0769230769231 --> Loss 0.00147527903318\n",
      "Epoch 11::Minibatch 224::LR 0.0769230769231 --> Loss 0.0019087233146\n",
      "Epoch 11::Minibatch 225::LR 0.0769230769231 --> Loss 0.00709955533346\n",
      "Epoch 11::Minibatch 226::LR 0.0769230769231 --> Loss 0.00386173963547\n",
      "Epoch 11::Minibatch 227::LR 0.0769230769231 --> Loss 0.00174185772737\n",
      "Epoch 11::Minibatch 228::LR 0.0769230769231 --> Loss 0.000840915640195\n",
      "Epoch 11::Minibatch 229::LR 0.0769230769231 --> Loss 0.00492268164953\n",
      "Epoch 11::Minibatch 230::LR 0.0769230769231 --> Loss 0.00407729506493\n",
      "Epoch 11::Minibatch 231::LR 0.0769230769231 --> Loss 0.00266335705916\n",
      "Epoch 11::Minibatch 232::LR 0.0769230769231 --> Loss 0.00130581965049\n",
      "Epoch 11::Minibatch 233::LR 0.0769230769231 --> Loss 0.00243548115095\n",
      "Epoch 11::Minibatch 234::LR 0.0769230769231 --> Loss 0.006549517711\n",
      "Epoch 11::Minibatch 235::LR 0.0769230769231 --> Loss 0.00464789787928\n",
      "Epoch 11::Minibatch 236::LR 0.0769230769231 --> Loss 0.00185220321019\n",
      "Epoch 11::Minibatch 237::LR 0.0769230769231 --> Loss 0.000767916440964\n",
      "Epoch 11::Minibatch 238::LR 0.0769230769231 --> Loss 0.00345445036888\n",
      "Epoch 11::Minibatch 239::LR 0.0769230769231 --> Loss 0.00297972261906\n",
      "Epoch 11::Minibatch 240::LR 0.0769230769231 --> Loss 0.00326062480609\n",
      "Epoch 11::Minibatch 241::LR 0.0769230769231 --> Loss 0.000828750481208\n",
      "Epoch 11::Minibatch 242::LR 0.0769230769231 --> Loss 0.00730385303497\n",
      "Epoch 11::Minibatch 243::LR 0.0769230769231 --> Loss 0.00367974162102\n",
      "Epoch 11::Minibatch 244::LR 0.0769230769231 --> Loss 0.00307985683282\n",
      "Epoch 11::Minibatch 245::LR 0.0769230769231 --> Loss 0.000543915579716\n",
      "Epoch 11::Minibatch 246::LR 0.0769230769231 --> Loss 0.00217402418454\n",
      "Epoch 11::Minibatch 247::LR 0.0769230769231 --> Loss 0.0141479110718\n",
      "Epoch 11::Minibatch 248::LR 0.0769230769231 --> Loss 0.00467692375183\n",
      "Epoch 11::Minibatch 249::LR 0.0769230769231 --> Loss 0.00301871856054\n",
      "Epoch 11::Minibatch 250::LR 0.0769230769231 --> Loss 0.00290532886982\n",
      "Epoch 11::Minibatch 251::LR 0.0769230769231 --> Loss 0.0026766850551\n",
      "Epoch 11::Minibatch 252::LR 0.0769230769231 --> Loss 0.00197018583616\n",
      "Epoch 11::Minibatch 253::LR 0.0769230769231 --> Loss 0.00327456037203\n",
      "Epoch 11::Minibatch 254::LR 0.0769230769231 --> Loss 0.00543028712273\n",
      "Epoch 11::Minibatch 255::LR 0.0769230769231 --> Loss 0.00401940782865\n",
      "Epoch 11::Minibatch 256::LR 0.0769230769231 --> Loss 0.00184632897377\n",
      "Epoch 11::Minibatch 257::LR 0.0769230769231 --> Loss 0.00138766030471\n",
      "Epoch 11::Minibatch 258::LR 0.0769230769231 --> Loss 0.00368300040563\n",
      "Epoch 11::Minibatch 259::LR 0.0769230769231 --> Loss 0.001931275328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 260::LR 0.0769230769231 --> Loss 0.00196148475011\n",
      "Epoch 11::Minibatch 261::LR 0.0769230769231 --> Loss 0.00302427887917\n",
      "Epoch 11::Minibatch 262::LR 0.0769230769231 --> Loss 0.00203483084838\n",
      "Epoch 11::Minibatch 263::LR 0.0769230769231 --> Loss 0.00243885219097\n",
      "Epoch 11::Minibatch 264::LR 0.0769230769231 --> Loss 0.00371573090553\n",
      "Epoch 11::Minibatch 265::LR 0.0769230769231 --> Loss 0.0105062437057\n",
      "Epoch 11::Minibatch 266::LR 0.0769230769231 --> Loss 0.00110672533512\n",
      "Epoch 11::Minibatch 267::LR 0.0769230769231 --> Loss 0.0103375911713\n",
      "Epoch 11::Minibatch 268::LR 0.0769230769231 --> Loss 0.00130917012691\n",
      "Epoch 11::Minibatch 269::LR 0.0769230769231 --> Loss 0.0036525285244\n",
      "Epoch 11::Minibatch 270::LR 0.0769230769231 --> Loss 0.00643602609634\n",
      "Epoch 11::Minibatch 271::LR 0.0769230769231 --> Loss 0.00289795120557\n",
      "Epoch 11::Minibatch 272::LR 0.0769230769231 --> Loss 0.00408681670825\n",
      "Epoch 11::Minibatch 273::LR 0.0769230769231 --> Loss 0.0018268430233\n",
      "Epoch 11::Minibatch 274::LR 0.0769230769231 --> Loss 0.00185657819112\n",
      "Epoch 11::Minibatch 275::LR 0.0769230769231 --> Loss 0.00278805176417\n",
      "Epoch 11::Minibatch 276::LR 0.0769230769231 --> Loss 0.00353800217311\n",
      "Epoch 11::Minibatch 277::LR 0.0769230769231 --> Loss 0.00109187106291\n",
      "Epoch 11::Minibatch 278::LR 0.0769230769231 --> Loss 0.00269464075565\n",
      "Epoch 11::Minibatch 279::LR 0.0769230769231 --> Loss 0.00253378748894\n",
      "Epoch 11::Minibatch 280::LR 0.0769230769231 --> Loss 0.00219773769379\n",
      "Epoch 11::Minibatch 281::LR 0.0769230769231 --> Loss 0.00139210393031\n",
      "Epoch 11::Minibatch 282::LR 0.0769230769231 --> Loss 0.00229816436768\n",
      "Epoch 11::Minibatch 283::LR 0.0769230769231 --> Loss 0.00226862967014\n",
      "Epoch 11::Minibatch 284::LR 0.0769230769231 --> Loss 0.00180626114209\n",
      "Epoch 11::Minibatch 285::LR 0.0769230769231 --> Loss 0.00126198212306\n",
      "Epoch 11::Minibatch 286::LR 0.0769230769231 --> Loss 0.00219294369221\n",
      "Epoch 11::Minibatch 287::LR 0.0769230769231 --> Loss 0.00211307922999\n",
      "Epoch 11::Minibatch 288::LR 0.0769230769231 --> Loss 0.00114164054394\n",
      "Epoch 11::Minibatch 289::LR 0.0769230769231 --> Loss 0.00158147583405\n",
      "Epoch 11::Minibatch 290::LR 0.0769230769231 --> Loss 0.00197046955427\n",
      "Epoch 11::Minibatch 291::LR 0.0769230769231 --> Loss 0.00176048457623\n",
      "Epoch 11::Minibatch 292::LR 0.0769230769231 --> Loss 0.000630890130997\n",
      "Epoch 11::Minibatch 293::LR 0.0769230769231 --> Loss 0.00148607939482\n",
      "Epoch 11::Minibatch 294::LR 0.0769230769231 --> Loss 0.00156827151775\n",
      "Epoch 11::Minibatch 295::LR 0.0769230769231 --> Loss 0.00184613565604\n",
      "Epoch 11::Minibatch 296::LR 0.0769230769231 --> Loss 0.00159435053666\n",
      "Epoch 11::Minibatch 297::LR 0.0769230769231 --> Loss 0.00139444390933\n",
      "Epoch 11::Minibatch 298::LR 0.0769230769231 --> Loss 0.00137136846781\n",
      "Epoch 11::Minibatch 299::LR 0.0769230769231 --> Loss 0.000811728090048\n",
      "Epoch 11::Minibatch 300::LR 0.0769230769231 --> Loss 0.00289842804273\n",
      "Epoch 11::Minibatch 301::LR 0.0769230769231 --> Loss 0.00279535611471\n",
      "Epoch 11::Minibatch 302::LR 0.0769230769231 --> Loss 0.00260536313057\n",
      "Epoch 11::Minibatch 303::LR 0.0769230769231 --> Loss 0.000891341467698\n",
      "Epoch 11::Minibatch 304::LR 0.0769230769231 --> Loss 0.00316419442495\n",
      "Epoch 11::Minibatch 305::LR 0.0769230769231 --> Loss 0.00169682959716\n",
      "Epoch 11::Minibatch 306::LR 0.0769230769231 --> Loss 0.000941201945146\n",
      "Epoch 11::Minibatch 307::LR 0.0769230769231 --> Loss 0.00248870790005\n",
      "Epoch 11::Minibatch 308::LR 0.0769230769231 --> Loss 0.00197434405486\n",
      "Epoch 11::Minibatch 309::LR 0.0769230769231 --> Loss 0.000997460683187\n",
      "Epoch 11::Minibatch 310::LR 0.0769230769231 --> Loss 0.0010856633385\n",
      "Epoch 11::Minibatch 311::LR 0.0769230769231 --> Loss 0.00167033751806\n",
      "Epoch 11::Minibatch 312::LR 0.0769230769231 --> Loss 0.00303692956765\n",
      "Epoch 11::Minibatch 313::LR 0.0769230769231 --> Loss 0.00241429607073\n",
      "Epoch 11::Minibatch 314::LR 0.0769230769231 --> Loss 0.00192978342374\n",
      "Epoch 11::Minibatch 315::LR 0.0769230769231 --> Loss 0.000994963943958\n",
      "Epoch 11::Minibatch 316::LR 0.0769230769231 --> Loss 0.00233373939991\n",
      "Epoch 11::Minibatch 317::LR 0.0769230769231 --> Loss 0.00156321813663\n",
      "Epoch 11::Minibatch 318::LR 0.0769230769231 --> Loss 0.00120474100113\n",
      "Epoch 11::Minibatch 319::LR 0.0769230769231 --> Loss 0.00230243424575\n",
      "Epoch 11::Minibatch 320::LR 0.0769230769231 --> Loss 0.00332034329573\n",
      "Epoch 11::Minibatch 321::LR 0.0769230769231 --> Loss 0.000902401308219\n",
      "Epoch 11::Minibatch 322::LR 0.0769230769231 --> Loss 0.00370079716047\n",
      "Epoch 11::Minibatch 323::LR 0.0769230769231 --> Loss 0.00360543847084\n",
      "Epoch 11::Minibatch 324::LR 0.0769230769231 --> Loss 0.0026464976867\n",
      "Epoch 11::Minibatch 325::LR 0.0769230769231 --> Loss 0.002444926699\n",
      "Epoch 11::Minibatch 326::LR 0.0769230769231 --> Loss 0.00557446201642\n",
      "Epoch 11::Minibatch 327::LR 0.0769230769231 --> Loss 0.00229652782281\n",
      "Epoch 11::Minibatch 328::LR 0.0769230769231 --> Loss 0.00347079634666\n",
      "Epoch 11::Minibatch 329::LR 0.0769230769231 --> Loss 0.00127309809128\n",
      "Epoch 11::Minibatch 330::LR 0.0769230769231 --> Loss 0.00164796680212\n",
      "Epoch 11::Minibatch 331::LR 0.0769230769231 --> Loss 0.00258700271447\n",
      "Epoch 11::Minibatch 332::LR 0.0769230769231 --> Loss 0.00254722098509\n",
      "Epoch 11::Minibatch 333::LR 0.0769230769231 --> Loss 0.00149019261201\n",
      "Epoch 11::Minibatch 334::LR 0.0769230769231 --> Loss 0.00431537946065\n",
      "Epoch 11::Minibatch 335::LR 0.0769230769231 --> Loss 0.00192138155301\n",
      "Epoch 11::Minibatch 336::LR 0.0769230769231 --> Loss 0.00210198819637\n",
      "Epoch 11::Minibatch 337::LR 0.0769230769231 --> Loss 0.00333821415901\n",
      "Epoch 11::Minibatch 338::LR 0.0769230769231 --> Loss 0.000526577581962\n",
      "Epoch 11::Minibatch 339::LR 0.0769230769231 --> Loss 0.00332992255688\n",
      "Epoch 11::Minibatch 340::LR 0.0769230769231 --> Loss 0.00459831953049\n",
      "Epoch 11::Minibatch 341::LR 0.0769230769231 --> Loss 0.00513603448868\n",
      "Epoch 11::Minibatch 342::LR 0.0769230769231 --> Loss 0.00335071206093\n",
      "Epoch 11::Minibatch 343::LR 0.0769230769231 --> Loss 0.00176932275295\n",
      "Epoch 11::Minibatch 344::LR 0.0769230769231 --> Loss 0.00307934999466\n",
      "Epoch 11::Minibatch 345::LR 0.0769230769231 --> Loss 0.00438813408216\n",
      "Epoch 11::Minibatch 346::LR 0.0769230769231 --> Loss 0.00576235969861\n",
      "Epoch 11::Minibatch 347::LR 0.0769230769231 --> Loss 0.000923209985097\n",
      "Epoch 11::Minibatch 348::LR 0.0769230769231 --> Loss 0.00364909847577\n",
      "Epoch 11::Minibatch 349::LR 0.0769230769231 --> Loss 0.00355119824409\n",
      "Epoch 11::Minibatch 350::LR 0.0769230769231 --> Loss 0.00188576360544\n",
      "Epoch 11::Minibatch 351::LR 0.0769230769231 --> Loss 0.0035998972257\n",
      "Epoch 11::Minibatch 352::LR 0.0769230769231 --> Loss 0.00483467260997\n",
      "Epoch 11::Minibatch 353::LR 0.0769230769231 --> Loss 0.00358280181885\n",
      "Epoch 11::Minibatch 354::LR 0.0769230769231 --> Loss 0.00298368473848\n",
      "Epoch 11::Minibatch 355::LR 0.0769230769231 --> Loss 0.00619363149007\n",
      "Epoch 11::Minibatch 356::LR 0.0769230769231 --> Loss 0.00316758573055\n",
      "Epoch 11::Minibatch 357::LR 0.0769230769231 --> Loss 0.00120940258106\n",
      "Epoch 11::Minibatch 358::LR 0.0769230769231 --> Loss 0.00227954705556\n",
      "Epoch 11::Minibatch 359::LR 0.0769230769231 --> Loss 0.00278361896674\n",
      "Epoch 11::Minibatch 360::LR 0.0769230769231 --> Loss 0.00249676823616\n",
      "Epoch 11::Minibatch 361::LR 0.0769230769231 --> Loss 0.00249020338058\n",
      "Epoch 11::Minibatch 362::LR 0.0769230769231 --> Loss 0.00251378079255\n",
      "Epoch 11::Minibatch 363::LR 0.0769230769231 --> Loss 0.000708272357782\n",
      "Epoch 11::Minibatch 364::LR 0.0769230769231 --> Loss 0.0020517406861\n",
      "Epoch 11::Minibatch 365::LR 0.0769230769231 --> Loss 0.00215198894342\n",
      "Epoch 11::Minibatch 366::LR 0.0769230769231 --> Loss 0.00232805927595\n",
      "Epoch 11::Minibatch 367::LR 0.0769230769231 --> Loss 0.00114802290996\n",
      "Epoch 11::Minibatch 368::LR 0.0769230769231 --> Loss 0.00102486441533\n",
      "Epoch 11::Minibatch 369::LR 0.0769230769231 --> Loss 0.00292671104272\n",
      "Epoch 11::Minibatch 370::LR 0.0769230769231 --> Loss 0.00229699015617\n",
      "Epoch 11::Minibatch 371::LR 0.0769230769231 --> Loss 0.00190300583839\n",
      "Epoch 11::Minibatch 372::LR 0.0769230769231 --> Loss 0.000466000835101\n",
      "Epoch 11::Minibatch 373::LR 0.0769230769231 --> Loss 0.00176925778389\n",
      "Epoch 11::Minibatch 374::LR 0.0769230769231 --> Loss 0.00216676433881\n",
      "Epoch 11::Minibatch 375::LR 0.0769230769231 --> Loss 0.00184694031874\n",
      "Epoch 11::Minibatch 376::LR 0.0769230769231 --> Loss 0.00125957578421\n",
      "Epoch 11::Minibatch 377::LR 0.0769230769231 --> Loss 0.00197729329268\n",
      "Epoch 11::Minibatch 378::LR 0.0769230769231 --> Loss 0.00214492122332\n",
      "Epoch 11::Minibatch 379::LR 0.0769230769231 --> Loss 0.00241053481897\n",
      "Epoch 11::Minibatch 380::LR 0.0769230769231 --> Loss 0.00160874982675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 381::LR 0.0769230769231 --> Loss 0.00100183437268\n",
      "Epoch 11::Minibatch 382::LR 0.0769230769231 --> Loss 0.00202198763688\n",
      "Epoch 11::Minibatch 383::LR 0.0769230769231 --> Loss 0.00195290227731\n",
      "Epoch 11::Minibatch 384::LR 0.0769230769231 --> Loss 0.00105352242788\n",
      "Epoch 11::Minibatch 385::LR 0.0769230769231 --> Loss 0.00104827493429\n",
      "Epoch 11::Minibatch 386::LR 0.0769230769231 --> Loss 0.00219312687715\n",
      "Epoch 11::Minibatch 387::LR 0.0769230769231 --> Loss 0.0023333978653\n",
      "Epoch 11::Minibatch 388::LR 0.0769230769231 --> Loss 0.00114745289087\n",
      "Epoch 11::Minibatch 389::LR 0.0769230769231 --> Loss 0.00184333662192\n",
      "Epoch 11::Minibatch 390::LR 0.0769230769231 --> Loss 0.00372115691503\n",
      "Epoch 11::Minibatch 391::LR 0.0769230769231 --> Loss 0.00275232315063\n",
      "Epoch 11::Minibatch 392::LR 0.0769230769231 --> Loss 0.00271248598893\n",
      "Epoch 11::Minibatch 393::LR 0.0769230769231 --> Loss 0.00281643668811\n",
      "Epoch 11::Minibatch 394::LR 0.0769230769231 --> Loss 0.00218617637952\n",
      "Epoch 11::Minibatch 395::LR 0.0769230769231 --> Loss 0.00206470270952\n",
      "Epoch 11::Minibatch 396::LR 0.0769230769231 --> Loss 0.00198117554188\n",
      "Epoch 11::Minibatch 397::LR 0.0769230769231 --> Loss 0.00210661411285\n",
      "Epoch 11::Minibatch 398::LR 0.0769230769231 --> Loss 0.00208517531554\n",
      "Epoch 11::Minibatch 399::LR 0.0769230769231 --> Loss 0.00237468282382\n",
      "Epoch 11::Minibatch 400::LR 0.0769230769231 --> Loss 0.00203836639722\n",
      "Epoch 11::Minibatch 401::LR 0.0769230769231 --> Loss 0.0036380537351\n",
      "Epoch 11::Minibatch 402::LR 0.0769230769231 --> Loss 0.00196483413378\n",
      "Epoch 11::Minibatch 403::LR 0.0769230769231 --> Loss 0.00152545909087\n",
      "Epoch 11::Minibatch 404::LR 0.0769230769231 --> Loss 0.00160587171714\n",
      "Epoch 11::Minibatch 405::LR 0.0769230769231 --> Loss 0.00364130457242\n",
      "Epoch 11::Minibatch 406::LR 0.0769230769231 --> Loss 0.002524193724\n",
      "Epoch 11::Minibatch 407::LR 0.0769230769231 --> Loss 0.0017837391297\n",
      "Epoch 11::Minibatch 408::LR 0.0769230769231 --> Loss 0.000479835222165\n",
      "Epoch 11::Minibatch 409::LR 0.0769230769231 --> Loss 0.00246169944604\n",
      "Epoch 11::Minibatch 410::LR 0.0769230769231 --> Loss 0.00329421857993\n",
      "Epoch 11::Minibatch 411::LR 0.0769230769231 --> Loss 0.00166729211807\n",
      "Epoch 11::Minibatch 412::LR 0.0769230769231 --> Loss 0.00099654952685\n",
      "Epoch 11::Minibatch 413::LR 0.0769230769231 --> Loss 0.00201834082603\n",
      "Epoch 11::Minibatch 414::LR 0.0769230769231 --> Loss 0.00182764510314\n",
      "Epoch 11::Minibatch 415::LR 0.0769230769231 --> Loss 0.00115643163522\n",
      "Epoch 11::Minibatch 416::LR 0.0769230769231 --> Loss 0.00085569302241\n",
      "Epoch 11::Minibatch 417::LR 0.0769230769231 --> Loss 0.00173398355643\n",
      "Epoch 11::Minibatch 418::LR 0.0769230769231 --> Loss 0.00293327728907\n",
      "Epoch 11::Minibatch 419::LR 0.0769230769231 --> Loss 0.000553456147512\n",
      "Epoch 11::Minibatch 420::LR 0.0769230769231 --> Loss 0.00073729266723\n",
      "Epoch 11::Minibatch 421::LR 0.0769230769231 --> Loss 0.00200229962667\n",
      "Epoch 11::Minibatch 422::LR 0.0769230769231 --> Loss 0.00226151982943\n",
      "Epoch 11::Minibatch 423::LR 0.0769230769231 --> Loss 0.00101924926043\n",
      "Epoch 11::Minibatch 424::LR 0.0769230769231 --> Loss 0.00161531309287\n",
      "Epoch 11::Minibatch 425::LR 0.0769230769231 --> Loss 0.00289571324984\n",
      "Epoch 11::Minibatch 426::LR 0.0769230769231 --> Loss 0.00204372306665\n",
      "Epoch 11::Minibatch 427::LR 0.0769230769231 --> Loss 0.000747169504563\n",
      "Epoch 11::Minibatch 428::LR 0.0769230769231 --> Loss 0.00113832374414\n",
      "Epoch 11::Minibatch 429::LR 0.0769230769231 --> Loss 0.00251348376274\n",
      "Epoch 11::Minibatch 430::LR 0.0769230769231 --> Loss 0.00966297785441\n",
      "Epoch 11::Minibatch 431::LR 0.0769230769231 --> Loss 0.00405690630277\n",
      "Epoch 11::Minibatch 432::LR 0.0769230769231 --> Loss 0.00457898060481\n",
      "Epoch 11::Minibatch 433::LR 0.0769230769231 --> Loss 0.00260379552841\n",
      "Epoch 11::Minibatch 434::LR 0.0769230769231 --> Loss 0.00258305529753\n",
      "Epoch 11::Minibatch 435::LR 0.0769230769231 --> Loss 0.00243401288986\n",
      "Epoch 11::Minibatch 436::LR 0.0769230769231 --> Loss 0.00180191556613\n",
      "Epoch 11::Minibatch 437::LR 0.0769230769231 --> Loss 0.00350621302923\n",
      "Epoch 11::Minibatch 438::LR 0.0769230769231 --> Loss 0.00276734411716\n",
      "Epoch 11::Minibatch 439::LR 0.0769230769231 --> Loss 0.00221554974715\n",
      "Epoch 11::Minibatch 440::LR 0.0769230769231 --> Loss 0.00334831635157\n",
      "Epoch 11::Minibatch 441::LR 0.0769230769231 --> Loss 0.00316464026769\n",
      "Epoch 11::Minibatch 442::LR 0.0769230769231 --> Loss 0.00291035453478\n",
      "Epoch 11::Minibatch 443::LR 0.0769230769231 --> Loss 0.00384513934453\n",
      "Epoch 11::Minibatch 444::LR 0.0769230769231 --> Loss 0.00297080318133\n",
      "Epoch 11::Minibatch 445::LR 0.0769230769231 --> Loss 0.000927082796892\n",
      "Epoch 11::Minibatch 446::LR 0.0769230769231 --> Loss 0.00154997328917\n",
      "Epoch 11::Minibatch 447::LR 0.0769230769231 --> Loss 0.00250672479471\n",
      "Epoch 11::Minibatch 448::LR 0.0769230769231 --> Loss 0.00247559189796\n",
      "Epoch 11::Minibatch 449::LR 0.0769230769231 --> Loss 0.00379216512044\n",
      "Epoch 11::Minibatch 450::LR 0.0769230769231 --> Loss 0.00242250005404\n",
      "Epoch 11::Minibatch 451::LR 0.0769230769231 --> Loss 0.00415383458138\n",
      "Epoch 11::Minibatch 452::LR 0.0769230769231 --> Loss 0.00242948412895\n",
      "Epoch 11::Minibatch 453::LR 0.0769230769231 --> Loss 0.000416328559319\n",
      "Epoch 11::Minibatch 454::LR 0.0769230769231 --> Loss 0.00366515080134\n",
      "Epoch 11::Minibatch 455::LR 0.0769230769231 --> Loss 0.00274912734826\n",
      "Epoch 11::Minibatch 456::LR 0.0769230769231 --> Loss 0.00321446259816\n",
      "Epoch 11::Minibatch 457::LR 0.0769230769231 --> Loss 0.00201961457729\n",
      "Epoch 11::Minibatch 458::LR 0.0769230769231 --> Loss 0.000809646348159\n",
      "Epoch 11::Minibatch 459::LR 0.0769230769231 --> Loss 0.00428126970927\n",
      "Epoch 11::Minibatch 460::LR 0.0769230769231 --> Loss 0.00270946820577\n",
      "Epoch 11::Minibatch 461::LR 0.0769230769231 --> Loss 0.00400667508443\n",
      "Epoch 11::Minibatch 462::LR 0.0769230769231 --> Loss 0.000424105674028\n",
      "Epoch 11::Minibatch 463::LR 0.0769230769231 --> Loss 0.00475087841352\n",
      "Epoch 11::Minibatch 464::LR 0.0769230769231 --> Loss 0.00209931612015\n",
      "Epoch 11::Minibatch 465::LR 0.0769230769231 --> Loss 0.0055092728138\n",
      "Epoch 11::Minibatch 466::LR 0.0769230769231 --> Loss 0.00519744356473\n",
      "Epoch 11::Minibatch 467::LR 0.0769230769231 --> Loss 0.00619357983271\n",
      "Epoch 11::Minibatch 468::LR 0.0769230769231 --> Loss 0.00627888083458\n",
      "Epoch 11::Minibatch 469::LR 0.0769230769231 --> Loss 0.00681364695231\n",
      "Epoch 11::Minibatch 470::LR 0.0769230769231 --> Loss 0.00391035874685\n",
      "Epoch 11::Minibatch 471::LR 0.0769230769231 --> Loss 0.00182529906432\n",
      "Epoch 11::Minibatch 472::LR 0.0769230769231 --> Loss 0.00353993376096\n",
      "Epoch 11::Minibatch 473::LR 0.0769230769231 --> Loss 0.0022150494655\n",
      "Epoch 11::Minibatch 474::LR 0.0769230769231 --> Loss 0.000722432235877\n",
      "Epoch 11::Minibatch 475::LR 0.0769230769231 --> Loss 0.00507494688034\n",
      "Epoch 11::Minibatch 476::LR 0.0769230769231 --> Loss 0.00767347971598\n",
      "Epoch 11::Minibatch 477::LR 0.0769230769231 --> Loss 0.000965032776197\n",
      "Epoch 11::Minibatch 478::LR 0.0769230769231 --> Loss 0.00253522674243\n",
      "Epoch 11::Minibatch 479::LR 0.0769230769231 --> Loss 0.00195847888788\n",
      "Epoch 11::Minibatch 480::LR 0.0769230769231 --> Loss 0.00153421074152\n",
      "Epoch 11::Minibatch 481::LR 0.0769230769231 --> Loss 0.000968670149644\n",
      "Epoch 11::Minibatch 482::LR 0.0769230769231 --> Loss 0.0021129711469\n",
      "Epoch 11::Minibatch 483::LR 0.0769230769231 --> Loss 0.00331159253915\n",
      "Epoch 11::Minibatch 484::LR 0.0769230769231 --> Loss 0.00360920786858\n",
      "Epoch 11::Minibatch 485::LR 0.0769230769231 --> Loss 0.000768024971088\n",
      "Epoch 11::Minibatch 486::LR 0.0769230769231 --> Loss 0.00310414632161\n",
      "Epoch 11::Minibatch 487::LR 0.0769230769231 --> Loss 0.00345907489459\n",
      "Epoch 11::Minibatch 488::LR 0.0769230769231 --> Loss 0.00205389579137\n",
      "Epoch 11::Minibatch 489::LR 0.0769230769231 --> Loss 0.00325481891632\n",
      "Epoch 11::Minibatch 490::LR 0.0769230769231 --> Loss 0.000426235844692\n",
      "Epoch 11::Minibatch 491::LR 0.0769230769231 --> Loss 0.00412436842918\n",
      "Epoch 11::Minibatch 492::LR 0.0769230769231 --> Loss 0.00303872962793\n",
      "Epoch 11::Minibatch 493::LR 0.0769230769231 --> Loss 0.00301921407382\n",
      "Epoch 11::Minibatch 494::LR 0.0769230769231 --> Loss 0.000752199540536\n",
      "Epoch 11::Minibatch 495::LR 0.0769230769231 --> Loss 0.00192267815272\n",
      "Epoch 11::Minibatch 496::LR 0.0769230769231 --> Loss 0.00298010309537\n",
      "Epoch 11::Minibatch 497::LR 0.0769230769231 --> Loss 0.000957940022151\n",
      "Epoch 11::Minibatch 498::LR 0.0769230769231 --> Loss 0.000597904026508\n",
      "Epoch 11::Minibatch 499::LR 0.0769230769231 --> Loss 0.00383210023244\n",
      "Epoch 11::Minibatch 500::LR 0.0769230769231 --> Loss 0.00145137826602\n",
      "Epoch 11::Minibatch 501::LR 0.0769230769231 --> Loss 0.00230612754822\n",
      "Epoch 11::Minibatch 502::LR 0.0769230769231 --> Loss 0.00396943251292\n",
      "Epoch 11::Minibatch 503::LR 0.0769230769231 --> Loss 0.00951010942459\n",
      "Epoch 11::Minibatch 504::LR 0.0769230769231 --> Loss 0.00838650306066\n",
      "Epoch 11::Minibatch 505::LR 0.0769230769231 --> Loss 0.00446349302928\n",
      "Epoch 11::Minibatch 506::LR 0.0769230769231 --> Loss 0.0035507329305\n",
      "Epoch 11::Minibatch 507::LR 0.0769230769231 --> Loss 0.00610711574554\n",
      "Epoch 11::Minibatch 508::LR 0.0769230769231 --> Loss 0.00340390483538\n",
      "Epoch 11::Minibatch 509::LR 0.0769230769231 --> Loss 0.00474586685499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 510::LR 0.0769230769231 --> Loss 0.00473417957624\n",
      "Epoch 11::Minibatch 511::LR 0.0769230769231 --> Loss 0.00388424158096\n",
      "Epoch 11::Minibatch 512::LR 0.0769230769231 --> Loss 0.00273063222567\n",
      "Epoch 11::Minibatch 513::LR 0.0769230769231 --> Loss 0.000738658805688\n",
      "Epoch 11::Minibatch 514::LR 0.0769230769231 --> Loss 0.00274133821328\n",
      "Epoch 11::Minibatch 515::LR 0.0769230769231 --> Loss 0.00303680479527\n",
      "Epoch 11::Minibatch 516::LR 0.0769230769231 --> Loss 0.00418828805288\n",
      "Epoch 11::Minibatch 517::LR 0.0769230769231 --> Loss 0.00343942085902\n",
      "Epoch 11::Minibatch 518::LR 0.0769230769231 --> Loss 0.00257894655069\n",
      "Epoch 11::Minibatch 519::LR 0.0769230769231 --> Loss 0.00340903282166\n",
      "Epoch 11::Minibatch 520::LR 0.0769230769231 --> Loss 0.00534601887067\n",
      "Epoch 11::Minibatch 521::LR 0.0769230769231 --> Loss 0.0056960105896\n",
      "Epoch 11::Minibatch 522::LR 0.0769230769231 --> Loss 0.0081334122022\n",
      "Epoch 11::Minibatch 523::LR 0.0769230769231 --> Loss 0.000697929660479\n",
      "Epoch 11::Minibatch 524::LR 0.0769230769231 --> Loss 0.00145088722308\n",
      "Epoch 11::Minibatch 525::LR 0.0769230769231 --> Loss 0.00330498476823\n",
      "Epoch 11::Minibatch 526::LR 0.0769230769231 --> Loss 0.0042320728302\n",
      "Epoch 11::Minibatch 527::LR 0.0769230769231 --> Loss 0.00245490988096\n",
      "Epoch 11::Minibatch 528::LR 0.0769230769231 --> Loss 0.00122409383456\n",
      "Epoch 11::Minibatch 529::LR 0.0769230769231 --> Loss 0.0042924118042\n",
      "Epoch 11::Minibatch 530::LR 0.0769230769231 --> Loss 0.00436486919721\n",
      "Epoch 11::Minibatch 531::LR 0.0769230769231 --> Loss 0.00379956324895\n",
      "Epoch 11::Minibatch 532::LR 0.0769230769231 --> Loss 0.00277412633101\n",
      "Epoch 11::Minibatch 533::LR 0.0769230769231 --> Loss 0.00503302693367\n",
      "Epoch 11::Minibatch 534::LR 0.0769230769231 --> Loss 0.00389507015546\n",
      "Epoch 11::Minibatch 535::LR 0.0769230769231 --> Loss 0.00327891727289\n",
      "Epoch 11::Minibatch 536::LR 0.0769230769231 --> Loss 0.00211763660113\n",
      "Epoch 11::Minibatch 537::LR 0.0769230769231 --> Loss 0.000694779107968\n",
      "Epoch 11::Minibatch 538::LR 0.0769230769231 --> Loss 0.00173421621323\n",
      "Epoch 11::Minibatch 539::LR 0.0769230769231 --> Loss 0.00347710212072\n",
      "Epoch 11::Minibatch 540::LR 0.0769230769231 --> Loss 0.00342356920242\n",
      "Epoch 11::Minibatch 541::LR 0.0769230769231 --> Loss 0.00292628268401\n",
      "Epoch 11::Minibatch 542::LR 0.0769230769231 --> Loss 0.00259536206722\n",
      "Epoch 11::Minibatch 543::LR 0.0769230769231 --> Loss 0.00284390548865\n",
      "Epoch 11::Minibatch 544::LR 0.0769230769231 --> Loss 0.00395368337631\n",
      "Epoch 11::Minibatch 545::LR 0.0769230769231 --> Loss 0.00208250264327\n",
      "Epoch 11::Minibatch 546::LR 0.0769230769231 --> Loss 0.000676418493191\n",
      "Epoch 11::Minibatch 547::LR 0.0769230769231 --> Loss 0.0026656015714\n",
      "Epoch 11::Minibatch 548::LR 0.0769230769231 --> Loss 0.00395473519961\n",
      "Epoch 11::Minibatch 549::LR 0.0769230769231 --> Loss 0.00813723087311\n",
      "Epoch 11::Minibatch 550::LR 0.0769230769231 --> Loss 0.00118171761433\n",
      "Epoch 11::Minibatch 551::LR 0.0769230769231 --> Loss 0.00247796952724\n",
      "Epoch 11::Minibatch 552::LR 0.0769230769231 --> Loss 0.00366587082545\n",
      "Epoch 11::Minibatch 553::LR 0.0769230769231 --> Loss 0.00330824534098\n",
      "Epoch 11::Minibatch 554::LR 0.0769230769231 --> Loss 0.00386428991954\n",
      "Epoch 11::Minibatch 555::LR 0.0769230769231 --> Loss 0.00101656009754\n",
      "Epoch 11::Minibatch 556::LR 0.0769230769231 --> Loss 0.00206319173177\n",
      "Epoch 11::Minibatch 557::LR 0.0769230769231 --> Loss 0.00251866658529\n",
      "Epoch 11::Minibatch 558::LR 0.0769230769231 --> Loss 0.00390968044599\n",
      "Epoch 11::Minibatch 559::LR 0.0769230769231 --> Loss 0.0038040860494\n",
      "Epoch 11::Minibatch 560::LR 0.0769230769231 --> Loss 0.00320983866851\n",
      "Epoch 11::Minibatch 561::LR 0.0769230769231 --> Loss 0.00280215740204\n",
      "Epoch 11::Minibatch 562::LR 0.0769230769231 --> Loss 0.00242104192575\n",
      "Epoch 11::Minibatch 563::LR 0.0769230769231 --> Loss 0.00411791324615\n",
      "Epoch 11::Minibatch 564::LR 0.0769230769231 --> Loss 0.00319547454516\n",
      "Epoch 11::Minibatch 565::LR 0.0769230769231 --> Loss 0.00376407106717\n",
      "Epoch 11::Minibatch 566::LR 0.0769230769231 --> Loss 0.00235146045685\n",
      "Epoch 11::Minibatch 567::LR 0.0769230769231 --> Loss 0.00264689048131\n",
      "Epoch 11::Minibatch 568::LR 0.0769230769231 --> Loss 0.00185640513897\n",
      "Epoch 11::Minibatch 569::LR 0.0769230769231 --> Loss 0.000578830838203\n",
      "Epoch 11::Minibatch 570::LR 0.0769230769231 --> Loss 0.00175259749095\n",
      "Epoch 11::Minibatch 571::LR 0.0769230769231 --> Loss 0.00230554223061\n",
      "Epoch 11::Minibatch 572::LR 0.0769230769231 --> Loss 0.00244431257248\n",
      "Epoch 11::Minibatch 573::LR 0.0769230769231 --> Loss 0.00154260367155\n",
      "Epoch 11::Minibatch 574::LR 0.0769230769231 --> Loss 0.00105929722389\n",
      "Epoch 11::Minibatch 575::LR 0.0769230769231 --> Loss 0.00182236591975\n",
      "Epoch 11::Minibatch 576::LR 0.0769230769231 --> Loss 0.00218928337097\n",
      "Epoch 11::Minibatch 577::LR 0.0769230769231 --> Loss 0.00170560260614\n",
      "Epoch 11::Minibatch 578::LR 0.0769230769231 --> Loss 0.00130392481883\n",
      "Epoch 11::Minibatch 579::LR 0.0769230769231 --> Loss 0.00122008323669\n",
      "Epoch 11::Minibatch 580::LR 0.0769230769231 --> Loss 0.0019730947415\n",
      "Epoch 11::Minibatch 581::LR 0.0769230769231 --> Loss 0.00173427939415\n",
      "Epoch 11::Minibatch 582::LR 0.0769230769231 --> Loss 0.0041358757019\n",
      "Epoch 11::Minibatch 583::LR 0.0769230769231 --> Loss 0.000951561629772\n",
      "Epoch 11::Minibatch 584::LR 0.0769230769231 --> Loss 0.00132132798433\n",
      "Epoch 11::Minibatch 585::LR 0.0769230769231 --> Loss 0.00490762352943\n",
      "Epoch 11::Minibatch 586::LR 0.0769230769231 --> Loss 0.00416830221812\n",
      "Epoch 11::Minibatch 587::LR 0.0769230769231 --> Loss 0.00114931712548\n",
      "Epoch 11::Minibatch 588::LR 0.0769230769231 --> Loss 0.00144063462814\n",
      "Epoch 11::Minibatch 589::LR 0.0769230769231 --> Loss 0.00277895013491\n",
      "Epoch 11::Minibatch 590::LR 0.0769230769231 --> Loss 0.0020577788353\n",
      "Epoch 11::Minibatch 591::LR 0.0769230769231 --> Loss 0.00326285004616\n",
      "Epoch 11::Minibatch 592::LR 0.0769230769231 --> Loss 0.00120064914227\n",
      "Epoch 11::Minibatch 593::LR 0.0769230769231 --> Loss 0.00265099942684\n",
      "Epoch 11::Minibatch 594::LR 0.0769230769231 --> Loss 0.00285832544168\n",
      "Epoch 11::Minibatch 595::LR 0.0769230769231 --> Loss 0.00306580980619\n",
      "Epoch 11::Minibatch 596::LR 0.0769230769231 --> Loss 0.0019811753432\n",
      "Epoch 11::Minibatch 597::LR 0.0769230769231 --> Loss 0.00121131847302\n",
      "Epoch 11::Minibatch 598::LR 0.0769230769231 --> Loss 0.0031331127882\n",
      "Epoch 11::Minibatch 599::LR 0.0769230769231 --> Loss 0.00189644296964\n",
      "Epoch 11::Minibatch 600::LR 0.0769230769231 --> Loss 0.002292167147\n",
      "Epoch 11::Minibatch 601::LR 0.0769230769231 --> Loss 0.00394820928574\n",
      "Epoch 11::Minibatch 602::LR 0.0769230769231 --> Loss 0.00214795410633\n",
      "Epoch 11::Minibatch 603::LR 0.0769230769231 --> Loss 0.0026814921697\n",
      "Epoch 11::Minibatch 604::LR 0.0769230769231 --> Loss 0.00166426022847\n",
      "Epoch 11::Minibatch 605::LR 0.0769230769231 --> Loss 0.00243569453557\n",
      "Epoch 11::Minibatch 606::LR 0.0769230769231 --> Loss 0.00195993165175\n",
      "Epoch 11::Minibatch 607::LR 0.0769230769231 --> Loss 0.000857675969601\n",
      "Epoch 11::Minibatch 608::LR 0.0769230769231 --> Loss 0.00162366280953\n",
      "Epoch 11::Minibatch 609::LR 0.0769230769231 --> Loss 0.00237185676893\n",
      "Epoch 11::Minibatch 610::LR 0.0769230769231 --> Loss 0.00403406580289\n",
      "Epoch 11::Minibatch 611::LR 0.0769230769231 --> Loss 0.00269110381603\n",
      "Epoch 11::Minibatch 612::LR 0.0769230769231 --> Loss 0.000513244867325\n",
      "Epoch 11::Minibatch 613::LR 0.0769230769231 --> Loss 0.00132152269284\n",
      "Epoch 11::Minibatch 614::LR 0.0769230769231 --> Loss 0.00251601954301\n",
      "Epoch 11::Minibatch 615::LR 0.0769230769231 --> Loss 0.00171137432257\n",
      "Epoch 11::Minibatch 616::LR 0.0769230769231 --> Loss 0.000945619841417\n",
      "Epoch 11::Minibatch 617::LR 0.0769230769231 --> Loss 0.000526174803575\n",
      "Epoch 11::Minibatch 618::LR 0.0769230769231 --> Loss 0.00272027810415\n",
      "Epoch 11::Minibatch 619::LR 0.0769230769231 --> Loss 0.00193552354972\n",
      "Epoch 11::Minibatch 620::LR 0.0769230769231 --> Loss 0.00174610753854\n",
      "Epoch 11::Minibatch 621::LR 0.0769230769231 --> Loss 0.000873661239942\n",
      "Epoch 11::Minibatch 622::LR 0.0769230769231 --> Loss 0.000829989264409\n",
      "Epoch 11::Minibatch 623::LR 0.0769230769231 --> Loss 0.00221984346708\n",
      "Epoch 11::Minibatch 624::LR 0.0769230769231 --> Loss 0.0018255041043\n",
      "Epoch 11::Minibatch 625::LR 0.0769230769231 --> Loss 0.00316443284353\n",
      "Epoch 11::Minibatch 626::LR 0.0769230769231 --> Loss 0.0048797472318\n",
      "Epoch 11::Minibatch 627::LR 0.0769230769231 --> Loss 0.00138366927703\n",
      "Epoch 11::Minibatch 628::LR 0.0769230769231 --> Loss 0.000944435099761\n",
      "Epoch 11::Minibatch 629::LR 0.0769230769231 --> Loss 0.00355266769727\n",
      "Epoch 11::Minibatch 630::LR 0.0769230769231 --> Loss 0.00344005942345\n",
      "Epoch 11::Minibatch 631::LR 0.0769230769231 --> Loss 0.00724320252736\n",
      "Epoch 11::Minibatch 632::LR 0.0769230769231 --> Loss 0.000825826078653\n",
      "Epoch 11::Minibatch 633::LR 0.0769230769231 --> Loss 0.00170203626156\n",
      "Epoch 11::Minibatch 634::LR 0.0769230769231 --> Loss 0.00330001910528\n",
      "Epoch 11::Minibatch 635::LR 0.0769230769231 --> Loss 0.00493797183037\n",
      "Epoch 11::Minibatch 636::LR 0.0769230769231 --> Loss 0.00554707487424\n",
      "Epoch 11::Minibatch 637::LR 0.0769230769231 --> Loss 0.000898159344991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 638::LR 0.0769230769231 --> Loss 0.00160896897316\n",
      "Epoch 11::Minibatch 639::LR 0.0769230769231 --> Loss 0.0034013624986\n",
      "Epoch 11::Minibatch 640::LR 0.0769230769231 --> Loss 0.00516703248024\n",
      "Epoch 11::Minibatch 641::LR 0.0769230769231 --> Loss 0.00323195377986\n",
      "Epoch 11::Minibatch 642::LR 0.0769230769231 --> Loss 0.000593239665031\n",
      "Epoch 11::Minibatch 643::LR 0.0769230769231 --> Loss 0.00238680064678\n",
      "Epoch 11::Minibatch 644::LR 0.0769230769231 --> Loss 0.0040771873792\n",
      "Epoch 11::Minibatch 645::LR 0.0769230769231 --> Loss 0.00425429304441\n",
      "Epoch 11::Minibatch 646::LR 0.0769230769231 --> Loss 0.00159243841966\n",
      "Epoch 11::Minibatch 647::LR 0.0769230769231 --> Loss 0.000638296455145\n",
      "Epoch 11::Minibatch 648::LR 0.0769230769231 --> Loss 0.00310653487841\n",
      "Epoch 11::Minibatch 649::LR 0.0769230769231 --> Loss 0.00367911934853\n",
      "Epoch 11::Minibatch 650::LR 0.0769230769231 --> Loss 0.00340509057045\n",
      "Epoch 11::Minibatch 651::LR 0.0769230769231 --> Loss 0.0014494535327\n",
      "Epoch 11::Minibatch 652::LR 0.0769230769231 --> Loss 0.000889297922452\n",
      "Epoch 11::Minibatch 653::LR 0.0769230769231 --> Loss 0.00293161471685\n",
      "Epoch 11::Minibatch 654::LR 0.0769230769231 --> Loss 0.00313749432564\n",
      "Epoch 11::Minibatch 655::LR 0.0769230769231 --> Loss 0.00350065032641\n",
      "Epoch 11::Minibatch 656::LR 0.0769230769231 --> Loss 0.000799205154181\n",
      "Epoch 11::Minibatch 657::LR 0.0769230769231 --> Loss 0.00222493370374\n",
      "Epoch 11::Minibatch 658::LR 0.0769230769231 --> Loss 0.00508967081706\n",
      "Epoch 11::Minibatch 659::LR 0.0769230769231 --> Loss 0.00239014426867\n",
      "Epoch 11::Minibatch 660::LR 0.0769230769231 --> Loss 0.00263529717922\n",
      "Epoch 11::Minibatch 661::LR 0.0769230769231 --> Loss 0.0026088921229\n",
      "Epoch 11::Minibatch 662::LR 0.0769230769231 --> Loss 0.00185730616252\n",
      "Epoch 11::Minibatch 663::LR 0.0769230769231 --> Loss 0.00369324127833\n",
      "Epoch 11::Minibatch 664::LR 0.0769230769231 --> Loss 0.00358708143234\n",
      "Epoch 11::Minibatch 665::LR 0.0769230769231 --> Loss 0.000791568756104\n",
      "Epoch 11::Minibatch 666::LR 0.0769230769231 --> Loss 0.00397308389346\n",
      "Epoch 11::Minibatch 667::LR 0.0769230769231 --> Loss 0.00259559373061\n",
      "Epoch 11::Minibatch 668::LR 0.0769230769231 --> Loss 0.0073375805219\n",
      "Epoch 11::Minibatch 669::LR 0.0769230769231 --> Loss 0.00110574305058\n",
      "Epoch 11::Minibatch 670::LR 0.0769230769231 --> Loss 0.00139160682758\n",
      "Epoch 11::Minibatch 671::LR 0.0769230769231 --> Loss 0.00552412589391\n",
      "Epoch 11::Minibatch 672::LR 0.0769230769231 --> Loss 0.00393522103628\n",
      "Epoch 11::Minibatch 673::LR 0.0769230769231 --> Loss 0.00164020995299\n",
      "Epoch 11::Minibatch 674::LR 0.0769230769231 --> Loss 0.000546162724495\n",
      "Epoch 11::Minibatch 675::LR 0.0769230769231 --> Loss 0.00221861243248\n",
      "Epoch 11::Minibatch 676::LR 0.0769230769231 --> Loss 0.00213152527809\n",
      "Epoch 11::Minibatch 677::LR 0.0769230769231 --> Loss 0.00289095103741\n",
      "Epoch 11::Minibatch 678::LR 0.0769230769231 --> Loss 0.00197140494982\n",
      "Epoch 11::Minibatch 679::LR 0.0769230769231 --> Loss 0.00362290501595\n",
      "Epoch 11::Minibatch 680::LR 0.0769230769231 --> Loss 0.00216475089391\n",
      "Epoch 11::Minibatch 681::LR 0.0769230769231 --> Loss 0.00246377587318\n",
      "Epoch 11::Minibatch 682::LR 0.0769230769231 --> Loss 0.000781690080961\n",
      "Epoch 11::Minibatch 683::LR 0.0769230769231 --> Loss 0.00245146731536\n",
      "Epoch 11::Minibatch 684::LR 0.0769230769231 --> Loss 0.00237634400527\n",
      "Epoch 11::Minibatch 685::LR 0.0769230769231 --> Loss 0.00297585626443\n",
      "Epoch 11::Minibatch 686::LR 0.0769230769231 --> Loss 0.00153428077698\n",
      "Epoch 11::Minibatch 687::LR 0.0769230769231 --> Loss 0.000852181911469\n",
      "Epoch 11::Minibatch 688::LR 0.0769230769231 --> Loss 0.00277811586857\n",
      "Epoch 11::Minibatch 689::LR 0.0769230769231 --> Loss 0.00257060925166\n",
      "Epoch 11::Minibatch 690::LR 0.0769230769231 --> Loss 0.00194096604983\n",
      "Epoch 11::Minibatch 691::LR 0.0769230769231 --> Loss 0.000678543001413\n",
      "Epoch 11::Minibatch 692::LR 0.0769230769231 --> Loss 0.00251404325167\n",
      "Epoch 11::Minibatch 693::LR 0.0769230769231 --> Loss 0.00257898052533\n",
      "Epoch 11::Minibatch 694::LR 0.0769230769231 --> Loss 0.00304025908311\n",
      "Epoch 11::Minibatch 695::LR 0.0769230769231 --> Loss 0.00173192640146\n",
      "Epoch 11::Minibatch 696::LR 0.0769230769231 --> Loss 0.00204166809718\n",
      "Epoch 11::Minibatch 697::LR 0.0769230769231 --> Loss 0.00141651560863\n",
      "Epoch 11::Minibatch 698::LR 0.0769230769231 --> Loss 0.00161866714557\n",
      "Epoch 11::Minibatch 699::LR 0.0769230769231 --> Loss 0.00388065099716\n",
      "Epoch 11::Minibatch 700::LR 0.0769230769231 --> Loss 0.00272459407647\n",
      "Epoch 11::Minibatch 701::LR 0.0769230769231 --> Loss 0.00203907469908\n",
      "Epoch 11::Minibatch 702::LR 0.0769230769231 --> Loss 0.00167520682017\n",
      "Epoch 11::Minibatch 703::LR 0.0769230769231 --> Loss 0.00425424933434\n",
      "Epoch 11::Minibatch 704::LR 0.0769230769231 --> Loss 0.00181843101978\n",
      "Epoch 11::Minibatch 705::LR 0.0769230769231 --> Loss 0.0028622931242\n",
      "Epoch 11::Minibatch 706::LR 0.0769230769231 --> Loss 0.00223744034767\n",
      "Epoch 11::Minibatch 707::LR 0.0769230769231 --> Loss 0.00119533002377\n",
      "Epoch 11::Minibatch 708::LR 0.0769230769231 --> Loss 0.00174366752307\n",
      "Epoch 11::Minibatch 709::LR 0.0769230769231 --> Loss 0.00171146313349\n",
      "Epoch 11::Minibatch 710::LR 0.0769230769231 --> Loss 0.00250194847584\n",
      "Epoch 11::Minibatch 711::LR 0.0769230769231 --> Loss 0.0019034832716\n",
      "Epoch 11::Minibatch 712::LR 0.0769230769231 --> Loss 0.00133027513822\n",
      "Epoch 11::Minibatch 713::LR 0.0769230769231 --> Loss 0.00174976706505\n",
      "Epoch 11::Minibatch 714::LR 0.0769230769231 --> Loss 0.002715609471\n",
      "Epoch 11::Minibatch 715::LR 0.0769230769231 --> Loss 0.00296201109886\n",
      "Epoch 11::Minibatch 716::LR 0.0769230769231 --> Loss 0.00160653720299\n",
      "Epoch 11::Minibatch 717::LR 0.0769230769231 --> Loss 0.00160641322533\n",
      "Epoch 11::Minibatch 718::LR 0.0769230769231 --> Loss 0.00127017547687\n",
      "Epoch 11::Minibatch 719::LR 0.0769230769231 --> Loss 0.00166750828425\n",
      "Epoch 11::Minibatch 720::LR 0.0769230769231 --> Loss 0.00251822133859\n",
      "Epoch 11::Minibatch 721::LR 0.0769230769231 --> Loss 0.000650185694297\n",
      "Epoch 11::Minibatch 722::LR 0.0769230769231 --> Loss 0.00490519881248\n",
      "Epoch 11::Minibatch 723::LR 0.0769230769231 --> Loss 0.00492987990379\n",
      "Epoch 11::Minibatch 724::LR 0.0769230769231 --> Loss 0.000985725522041\n",
      "Epoch 11::Minibatch 725::LR 0.0769230769231 --> Loss 0.00228794256846\n",
      "Epoch 11::Minibatch 726::LR 0.0769230769231 --> Loss 0.00497685949008\n",
      "Epoch 11::Minibatch 727::LR 0.0769230769231 --> Loss 0.00315217196941\n",
      "Epoch 11::Minibatch 728::LR 0.0769230769231 --> Loss 0.000663177073002\n",
      "Epoch 11::Minibatch 729::LR 0.0769230769231 --> Loss 0.000784958998362\n",
      "Epoch 11::Minibatch 730::LR 0.0769230769231 --> Loss 0.00269355714321\n",
      "Epoch 11::Minibatch 731::LR 0.0769230769231 --> Loss 0.00246339400609\n",
      "Epoch 11::Minibatch 732::LR 0.0769230769231 --> Loss 0.00235257367293\n",
      "Epoch 11::Minibatch 733::LR 0.0769230769231 --> Loss 0.000756670931975\n",
      "Epoch 11::Minibatch 734::LR 0.0769230769231 --> Loss 0.00182173828284\n",
      "Epoch 11::Minibatch 735::LR 0.0769230769231 --> Loss 0.00235754628976\n",
      "Epoch 11::Minibatch 736::LR 0.0769230769231 --> Loss 0.00345734794935\n",
      "Epoch 11::Minibatch 737::LR 0.0769230769231 --> Loss 0.00313619832198\n",
      "Epoch 11::Minibatch 738::LR 0.0769230769231 --> Loss 0.00170312841733\n",
      "Epoch 11::Minibatch 739::LR 0.0769230769231 --> Loss 0.00252284705639\n",
      "Epoch 11::Minibatch 740::LR 0.0769230769231 --> Loss 0.00386918147405\n",
      "Epoch 11::Minibatch 741::LR 0.0769230769231 --> Loss 0.00277184049288\n",
      "Epoch 11::Minibatch 742::LR 0.0769230769231 --> Loss 0.00212838192781\n",
      "Epoch 11::Minibatch 743::LR 0.0769230769231 --> Loss 0.00136515537898\n",
      "Epoch 11::Minibatch 744::LR 0.0769230769231 --> Loss 0.00180739204089\n",
      "Epoch 11::Minibatch 745::LR 0.0769230769231 --> Loss 0.00287094394366\n",
      "Epoch 11::Minibatch 746::LR 0.0769230769231 --> Loss 0.00303339997927\n",
      "Epoch 11::Minibatch 747::LR 0.0769230769231 --> Loss 0.00180564026038\n",
      "Epoch 11::Minibatch 748::LR 0.0769230769231 --> Loss 0.000657822142045\n",
      "Epoch 11::Minibatch 749::LR 0.0769230769231 --> Loss 0.00166071693103\n",
      "Epoch 11::Minibatch 750::LR 0.0769230769231 --> Loss 0.00249328056971\n",
      "Epoch 11::Minibatch 751::LR 0.0769230769231 --> Loss 0.00270466307799\n",
      "Epoch 11::Minibatch 752::LR 0.0769230769231 --> Loss 0.00113203624884\n",
      "Epoch 11::Minibatch 753::LR 0.0769230769231 --> Loss 0.00226108789444\n",
      "Epoch 11::Minibatch 754::LR 0.0769230769231 --> Loss 0.00239327073097\n",
      "Epoch 11::Minibatch 755::LR 0.0769230769231 --> Loss 0.00267477035522\n",
      "Epoch 11::Minibatch 756::LR 0.0769230769231 --> Loss 0.00146283408006\n",
      "Epoch 11::Minibatch 757::LR 0.0769230769231 --> Loss 0.000904314120611\n",
      "Epoch 11::Minibatch 758::LR 0.0769230769231 --> Loss 0.00165955632925\n",
      "Epoch 11::Minibatch 759::LR 0.0769230769231 --> Loss 0.00384177128474\n",
      "Epoch 11::Minibatch 760::LR 0.0769230769231 --> Loss 0.00311647395293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 761::LR 0.0769230769231 --> Loss 0.00643153746923\n",
      "Epoch 11::Minibatch 762::LR 0.0769230769231 --> Loss 0.00381788730621\n",
      "Epoch 11::Minibatch 763::LR 0.0769230769231 --> Loss 0.00363566954931\n",
      "Epoch 11::Minibatch 764::LR 0.0769230769231 --> Loss 0.00325195491314\n",
      "Epoch 11::Minibatch 765::LR 0.0769230769231 --> Loss 0.00135235200326\n",
      "Epoch 11::Minibatch 766::LR 0.0769230769231 --> Loss 0.00227950513363\n",
      "Epoch 11::Minibatch 767::LR 0.0769230769231 --> Loss 0.00508726557096\n",
      "Epoch 11::Minibatch 768::LR 0.0769230769231 --> Loss 0.00357473929723\n",
      "Epoch 11::Minibatch 769::LR 0.0769230769231 --> Loss 0.00192728082339\n",
      "Epoch 11::Minibatch 770::LR 0.0769230769231 --> Loss 0.00150265604258\n",
      "Epoch 11::Minibatch 771::LR 0.0769230769231 --> Loss 0.00382918119431\n",
      "Epoch 11::Minibatch 772::LR 0.0769230769231 --> Loss 0.003357736667\n",
      "Epoch 11::Minibatch 773::LR 0.0769230769231 --> Loss 0.00314346194267\n",
      "Epoch 11::Minibatch 774::LR 0.0769230769231 --> Loss 0.00177293658257\n",
      "Epoch 11::Minibatch 775::LR 0.0769230769231 --> Loss 0.00416435281436\n",
      "Epoch 11::Minibatch 776::LR 0.0769230769231 --> Loss 0.00357272624969\n",
      "Epoch 11::Minibatch 777::LR 0.0769230769231 --> Loss 0.00792274792989\n",
      "Epoch 11::Minibatch 778::LR 0.0769230769231 --> Loss 0.0105908783277\n",
      "Epoch 11::Minibatch 779::LR 0.0769230769231 --> Loss 0.00209691961606\n",
      "Epoch 11::Minibatch 780::LR 0.0769230769231 --> Loss 0.00166748046875\n",
      "Epoch 11::Minibatch 781::LR 0.0769230769231 --> Loss 0.00355762680372\n",
      "Epoch 11::Minibatch 782::LR 0.0769230769231 --> Loss 0.00415903647741\n",
      "Epoch 11::Minibatch 783::LR 0.0769230769231 --> Loss 0.00236277739207\n",
      "Epoch 11::Minibatch 784::LR 0.0769230769231 --> Loss 0.000753242919842\n",
      "Epoch 11::Minibatch 785::LR 0.0769230769231 --> Loss 0.00384546875954\n",
      "Epoch 11::Minibatch 786::LR 0.0769230769231 --> Loss 0.00362240632375\n",
      "Epoch 11::Minibatch 787::LR 0.0769230769231 --> Loss 0.00285418232282\n",
      "Epoch 11::Minibatch 788::LR 0.0769230769231 --> Loss 0.00252232948939\n",
      "Epoch 11::Minibatch 789::LR 0.0769230769231 --> Loss 0.000757847627004\n",
      "Epoch 11::Minibatch 790::LR 0.0769230769231 --> Loss 0.00327390531699\n",
      "Epoch 11::Minibatch 791::LR 0.0769230769231 --> Loss 0.00376708587011\n",
      "Epoch 11::Minibatch 792::LR 0.0769230769231 --> Loss 0.00342326283455\n",
      "Epoch 11::Minibatch 793::LR 0.0769230769231 --> Loss 0.00193636139234\n",
      "Epoch 11::Minibatch 794::LR 0.0769230769231 --> Loss 0.00109604348739\n",
      "Epoch 11::Minibatch 795::LR 0.0769230769231 --> Loss 0.00330409069856\n",
      "Epoch 11::Minibatch 796::LR 0.0769230769231 --> Loss 0.00605374932289\n",
      "Epoch 11::Minibatch 797::LR 0.0769230769231 --> Loss 0.00815091689428\n",
      "Epoch 11::Minibatch 798::LR 0.0769230769231 --> Loss 0.00348630905151\n",
      "Epoch 11::Minibatch 799::LR 0.0769230769231 --> Loss 0.00250606536865\n",
      "Epoch 11::Minibatch 800::LR 0.0769230769231 --> Loss 0.00206423660119\n",
      "Epoch 11::Minibatch 801::LR 0.0769230769231 --> Loss 0.00419061859449\n",
      "Epoch 11::Minibatch 802::LR 0.0769230769231 --> Loss 0.00138826141755\n",
      "Epoch 11::Minibatch 803::LR 0.0769230769231 --> Loss 0.00281690339247\n",
      "Epoch 11::Minibatch 804::LR 0.0769230769231 --> Loss 0.00225326796373\n",
      "Epoch 11::Minibatch 805::LR 0.0769230769231 --> Loss 0.00233926991622\n",
      "Epoch 11::Minibatch 806::LR 0.0769230769231 --> Loss 0.00331669092178\n",
      "Epoch 11::Minibatch 807::LR 0.0769230769231 --> Loss 0.00305852254232\n",
      "Epoch 11::Minibatch 808::LR 0.0769230769231 --> Loss 0.00279108842214\n",
      "Epoch 11::Minibatch 809::LR 0.0769230769231 --> Loss 0.0041374194622\n",
      "Epoch 11::Minibatch 810::LR 0.0769230769231 --> Loss 0.00537348985672\n",
      "Epoch 11::Minibatch 811::LR 0.0769230769231 --> Loss 0.00504557212194\n",
      "Epoch 11::Minibatch 812::LR 0.0769230769231 --> Loss 0.00482293963432\n",
      "Epoch 11::Minibatch 813::LR 0.0769230769231 --> Loss 0.00459230383237\n",
      "Epoch 11::Minibatch 814::LR 0.0769230769231 --> Loss 0.00200044413408\n",
      "Epoch 11::Minibatch 815::LR 0.0769230769231 --> Loss 0.00406222343445\n",
      "Epoch 11::Minibatch 816::LR 0.0769230769231 --> Loss 0.0043100698789\n",
      "Epoch 11::Minibatch 817::LR 0.0769230769231 --> Loss 0.00556029200554\n",
      "Epoch 11::Minibatch 818::LR 0.0769230769231 --> Loss 0.00139652470748\n",
      "Epoch 11::Minibatch 819::LR 0.0769230769231 --> Loss 0.000784049580495\n",
      "Epoch 11::Minibatch 820::LR 0.0769230769231 --> Loss 0.00549701531728\n",
      "Epoch 11::Minibatch 821::LR 0.0769230769231 --> Loss 0.00330402890841\n",
      "Epoch 11::Minibatch 822::LR 0.0769230769231 --> Loss 0.00389207522074\n",
      "Epoch 11::Minibatch 823::LR 0.0769230769231 --> Loss 0.00133778393269\n",
      "Epoch 11::Minibatch 824::LR 0.0769230769231 --> Loss 0.00143421312173\n",
      "Epoch 11::Minibatch 825::LR 0.0769230769231 --> Loss 0.00380406737328\n",
      "Epoch 11::Minibatch 826::LR 0.0769230769231 --> Loss 0.00394858916601\n",
      "Epoch 11::Minibatch 827::LR 0.0769230769231 --> Loss 0.00233848154545\n",
      "Epoch 11::Minibatch 828::LR 0.0769230769231 --> Loss 0.00073598648111\n",
      "Epoch 11::Minibatch 829::LR 0.0769230769231 --> Loss 0.00250080764294\n",
      "Epoch 11::Minibatch 830::LR 0.0769230769231 --> Loss 0.0045055437088\n",
      "Epoch 11::Minibatch 831::LR 0.0769230769231 --> Loss 0.00261411368847\n",
      "Epoch 11::Minibatch 832::LR 0.0769230769231 --> Loss 0.00229825973511\n",
      "Epoch 11::Minibatch 833::LR 0.0769230769231 --> Loss 0.0018761797746\n",
      "Epoch 11::Minibatch 834::LR 0.0769230769231 --> Loss 0.000792306413253\n",
      "Epoch 11::Minibatch 835::LR 0.0769230769231 --> Loss 0.00386310060819\n",
      "Epoch 11::Minibatch 836::LR 0.0769230769231 --> Loss 0.00382873257001\n",
      "Epoch 11::Minibatch 837::LR 0.0769230769231 --> Loss 0.0022655570507\n",
      "Epoch 11::Minibatch 838::LR 0.0769230769231 --> Loss 0.000652404725552\n",
      "Epoch 11::Minibatch 839::LR 0.0769230769231 --> Loss 0.00250085075696\n",
      "Epoch 11::Minibatch 840::LR 0.0769230769231 --> Loss 0.00296610136827\n",
      "Epoch 11::Minibatch 841::LR 0.0769230769231 --> Loss 0.00293965617816\n",
      "Epoch 11::Minibatch 842::LR 0.0769230769231 --> Loss 0.00215079625448\n",
      "Epoch 11::Minibatch 843::LR 0.0769230769231 --> Loss 0.00102742622296\n",
      "Epoch 11::Minibatch 844::LR 0.0769230769231 --> Loss 0.00152226775885\n",
      "Epoch 11::Minibatch 845::LR 0.0769230769231 --> Loss 0.00443490902583\n",
      "Epoch 11::Minibatch 846::LR 0.0769230769231 --> Loss 0.00170740524928\n",
      "Epoch 11::Minibatch 847::LR 0.0769230769231 --> Loss 0.00233225961526\n",
      "Epoch 11::Minibatch 848::LR 0.0769230769231 --> Loss 0.00101019163926\n",
      "Epoch 11::Minibatch 849::LR 0.0769230769231 --> Loss 0.0018962798516\n",
      "Epoch 11::Minibatch 850::LR 0.0769230769231 --> Loss 0.00324186166128\n",
      "Epoch 11::Minibatch 851::LR 0.0769230769231 --> Loss 0.00281090041002\n",
      "Epoch 11::Minibatch 852::LR 0.0769230769231 --> Loss 0.00108031551043\n",
      "Epoch 11::Minibatch 853::LR 0.0769230769231 --> Loss 0.00133354276419\n",
      "Epoch 11::Minibatch 854::LR 0.0769230769231 --> Loss 0.00259047627449\n",
      "Epoch 11::Minibatch 855::LR 0.0769230769231 --> Loss 0.00219447791576\n",
      "Epoch 11::Minibatch 856::LR 0.0769230769231 --> Loss 0.00181164284547\n",
      "Epoch 11::Minibatch 857::LR 0.0769230769231 --> Loss 0.00122956991196\n",
      "Epoch 11::Minibatch 858::LR 0.0769230769231 --> Loss 0.000608209272226\n",
      "Epoch 11::Minibatch 859::LR 0.0769230769231 --> Loss 0.00190135717392\n",
      "Epoch 11::Minibatch 860::LR 0.0769230769231 --> Loss 0.00123740126689\n",
      "Epoch 11::Minibatch 861::LR 0.0769230769231 --> Loss 0.000942897399267\n",
      "Epoch 11::Minibatch 862::LR 0.0769230769231 --> Loss 0.00365097324053\n",
      "Epoch 11::Minibatch 863::LR 0.0769230769231 --> Loss 0.00347176710765\n",
      "Epoch 11::Minibatch 864::LR 0.0769230769231 --> Loss 0.00304662187894\n",
      "Epoch 11::Minibatch 865::LR 0.0769230769231 --> Loss 0.000519481251637\n",
      "Epoch 11::Minibatch 866::LR 0.0769230769231 --> Loss 0.00220340371132\n",
      "Epoch 11::Minibatch 867::LR 0.0769230769231 --> Loss 0.00307877143224\n",
      "Epoch 11::Minibatch 868::LR 0.0769230769231 --> Loss 0.00255675216516\n",
      "Epoch 11::Minibatch 869::LR 0.0769230769231 --> Loss 0.00213515659173\n",
      "Epoch 11::Minibatch 870::LR 0.0769230769231 --> Loss 0.00365097244581\n",
      "Epoch 11::Minibatch 871::LR 0.0769230769231 --> Loss 0.00153956631819\n",
      "Epoch 11::Minibatch 872::LR 0.0769230769231 --> Loss 0.00231779019038\n",
      "Epoch 11::Minibatch 873::LR 0.0769230769231 --> Loss 0.00250364085039\n",
      "Epoch 11::Minibatch 874::LR 0.0769230769231 --> Loss 0.00641501545906\n",
      "Epoch 11::Minibatch 875::LR 0.0769230769231 --> Loss 0.000550967901945\n",
      "Epoch 11::Minibatch 876::LR 0.0769230769231 --> Loss 0.00351006269455\n",
      "Epoch 11::Minibatch 877::LR 0.0769230769231 --> Loss 0.00464864571889\n",
      "Epoch 11::Minibatch 878::LR 0.0769230769231 --> Loss 0.003369358778\n",
      "Epoch 11::Minibatch 879::LR 0.0769230769231 --> Loss 0.0039631708463\n",
      "Epoch 11::Minibatch 880::LR 0.0769230769231 --> Loss 0.00465913414955\n",
      "Epoch 11::Minibatch 881::LR 0.0769230769231 --> Loss 0.00424219886462\n",
      "Epoch 11::Minibatch 882::LR 0.0769230769231 --> Loss 0.00199998239676\n",
      "Epoch 11::Minibatch 883::LR 0.0769230769231 --> Loss 0.00337330381076\n",
      "Epoch 11::Minibatch 884::LR 0.0769230769231 --> Loss 0.00269219259421\n",
      "Epoch 11::Minibatch 885::LR 0.0769230769231 --> Loss 0.00245573898156\n",
      "Epoch 11::Minibatch 886::LR 0.0769230769231 --> Loss 0.000528459101915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 887::LR 0.0769230769231 --> Loss 0.00524632533391\n",
      "Epoch 11::Minibatch 888::LR 0.0769230769231 --> Loss 0.00267703513304\n",
      "Epoch 11::Minibatch 889::LR 0.0769230769231 --> Loss 0.0029516261816\n",
      "Epoch 11::Minibatch 890::LR 0.0769230769231 --> Loss 0.00435323317846\n",
      "Epoch 11::Minibatch 891::LR 0.0769230769231 --> Loss 0.00193657795588\n",
      "Epoch 11::Minibatch 892::LR 0.0769230769231 --> Loss 0.000928504566352\n",
      "Epoch 11::Minibatch 893::LR 0.0769230769231 --> Loss 0.00251871287823\n",
      "Epoch 11::Minibatch 894::LR 0.0769230769231 --> Loss 0.00223975022634\n",
      "Epoch 11::Minibatch 895::LR 0.0769230769231 --> Loss 0.00244258582592\n",
      "Epoch 11::Minibatch 896::LR 0.0769230769231 --> Loss 0.00131778389215\n",
      "Epoch 11::Minibatch 897::LR 0.0769230769231 --> Loss 0.000759954998891\n",
      "Epoch 11::Minibatch 898::LR 0.0769230769231 --> Loss 0.00219848374526\n",
      "Epoch 11::Minibatch 899::LR 0.0769230769231 --> Loss 0.00248796880245\n",
      "Epoch 11::Minibatch 900::LR 0.0769230769231 --> Loss 0.00329079508781\n",
      "Epoch 11::Minibatch 901::LR 0.0769230769231 --> Loss 0.00062419573466\n",
      "Epoch 11::Minibatch 902::LR 0.0769230769231 --> Loss 0.00143675585588\n",
      "Epoch 11::Minibatch 903::LR 0.0769230769231 --> Loss 0.00257729172707\n",
      "Epoch 11::Minibatch 904::LR 0.0769230769231 --> Loss 0.00200241446495\n",
      "Epoch 11::Minibatch 905::LR 0.0769230769231 --> Loss 0.00145242373149\n",
      "Epoch 11::Minibatch 906::LR 0.0769230769231 --> Loss 0.00111522614956\n",
      "Epoch 11::Minibatch 907::LR 0.0769230769231 --> Loss 0.00159265716871\n",
      "Epoch 11::Minibatch 908::LR 0.0769230769231 --> Loss 0.0021742751201\n",
      "Epoch 11::Minibatch 909::LR 0.0769230769231 --> Loss 0.002002551953\n",
      "Epoch 11::Minibatch 910::LR 0.0769230769231 --> Loss 0.000844344198704\n",
      "Epoch 11::Minibatch 911::LR 0.0769230769231 --> Loss 0.00123353044192\n",
      "Epoch 11::Minibatch 912::LR 0.0769230769231 --> Loss 0.00196519196033\n",
      "Epoch 11::Minibatch 913::LR 0.0769230769231 --> Loss 0.00211980481942\n",
      "Epoch 11::Minibatch 914::LR 0.0769230769231 --> Loss 0.00116337140401\n",
      "Epoch 11::Minibatch 915::LR 0.0769230769231 --> Loss 0.000500700771809\n",
      "Epoch 11::Minibatch 916::LR 0.0769230769231 --> Loss 0.00234797537327\n",
      "Epoch 11::Minibatch 917::LR 0.0769230769231 --> Loss 0.00397668878237\n",
      "Epoch 11::Minibatch 918::LR 0.0769230769231 --> Loss 0.00694980223974\n",
      "Epoch 11::Minibatch 919::LR 0.0769230769231 --> Loss 0.000611695945263\n",
      "Epoch 11::Minibatch 920::LR 0.0769230769231 --> Loss 0.0108829657237\n",
      "Epoch 11::Minibatch 921::LR 0.0769230769231 --> Loss 0.00290606101354\n",
      "Epoch 11::Minibatch 922::LR 0.0769230769231 --> Loss 0.00315099497636\n",
      "Epoch 11::Minibatch 923::LR 0.0769230769231 --> Loss 0.00161806156238\n",
      "Epoch 11::Minibatch 924::LR 0.0769230769231 --> Loss 0.00360749363899\n",
      "Epoch 11::Minibatch 925::LR 0.0769230769231 --> Loss 0.00268397569656\n",
      "Epoch 11::Minibatch 926::LR 0.0769230769231 --> Loss 0.00547872145971\n",
      "Epoch 11::Minibatch 927::LR 0.0769230769231 --> Loss 0.00875912825267\n",
      "Epoch 11::Minibatch 928::LR 0.0769230769231 --> Loss 0.00677007595698\n",
      "Epoch 11::Minibatch 929::LR 0.0769230769231 --> Loss 0.00786418199539\n",
      "Epoch 11::Minibatch 930::LR 0.0769230769231 --> Loss 0.00900716384252\n",
      "Epoch 11::Minibatch 931::LR 0.0769230769231 --> Loss 0.00384959022204\n",
      "Epoch 11::Minibatch 932::LR 0.0769230769231 --> Loss 0.0082772731781\n",
      "Epoch 11::Minibatch 933::LR 0.0769230769231 --> Loss 0.00412410259247\n",
      "Epoch 11::Minibatch 934::LR 0.0769230769231 --> Loss 0.0054076898098\n",
      "Epoch 11::Minibatch 935::LR 0.0769230769231 --> Loss 0.00737194617589\n",
      "Epoch 11::Minibatch 936::LR 0.0769230769231 --> Loss 0.00184246579806\n",
      "Epoch 11::Minibatch 937::LR 0.0769230769231 --> Loss 0.00386473496755\n",
      "Epoch 11::Minibatch 938::LR 0.0769230769231 --> Loss 0.0036288022995\n",
      "Epoch 11::Minibatch 939::LR 0.0769230769231 --> Loss 0.00370981733004\n",
      "Epoch 11::Minibatch 940::LR 0.0769230769231 --> Loss 0.00112374931574\n",
      "Epoch 11::Minibatch 941::LR 0.0769230769231 --> Loss 0.000917286276817\n",
      "Epoch 11::Minibatch 942::LR 0.0769230769231 --> Loss 0.0024872670571\n",
      "Epoch 11::Minibatch 943::LR 0.0769230769231 --> Loss 0.00328940331936\n",
      "Epoch 11::Minibatch 944::LR 0.0769230769231 --> Loss 0.00239139914513\n",
      "Epoch 11::Minibatch 945::LR 0.0769230769231 --> Loss 0.00140822490056\n",
      "Epoch 11::Minibatch 946::LR 0.0769230769231 --> Loss 0.00354466875394\n",
      "Epoch 11::Minibatch 947::LR 0.0769230769231 --> Loss 0.00312706391017\n",
      "Epoch 11::Minibatch 948::LR 0.0769230769231 --> Loss 0.00568949182828\n",
      "Epoch 11::Minibatch 949::LR 0.0769230769231 --> Loss 0.00202280898889\n",
      "Epoch 11::Minibatch 950::LR 0.0769230769231 --> Loss 0.000748103608688\n",
      "Epoch 11::Minibatch 951::LR 0.0769230769231 --> Loss 0.00343303720156\n",
      "Epoch 11::Minibatch 952::LR 0.0769230769231 --> Loss 0.00253181775411\n",
      "Epoch 11::Minibatch 953::LR 0.0769230769231 --> Loss 0.00139296531677\n",
      "Epoch 11::Minibatch 954::LR 0.0769230769231 --> Loss 0.000970806380113\n",
      "Epoch 11::Minibatch 955::LR 0.0769230769231 --> Loss 0.0025852227211\n",
      "Epoch 11::Minibatch 956::LR 0.0769230769231 --> Loss 0.00419165253639\n",
      "Epoch 11::Minibatch 957::LR 0.0769230769231 --> Loss 0.00197950621446\n",
      "Epoch 11::Minibatch 958::LR 0.0769230769231 --> Loss 0.00252078294754\n",
      "Epoch 11::Minibatch 959::LR 0.0769230769231 --> Loss 0.00310862978299\n",
      "Epoch 11::Minibatch 960::LR 0.0769230769231 --> Loss 0.00691244522731\n",
      "Epoch 11::Minibatch 961::LR 0.0769230769231 --> Loss 0.00353076656659\n",
      "Epoch 11::Minibatch 962::LR 0.0769230769231 --> Loss 0.00311658044656\n",
      "Epoch 11::Minibatch 963::LR 0.0769230769231 --> Loss 0.00108463217815\n",
      "Epoch 11::Minibatch 964::LR 0.0769230769231 --> Loss 0.00244904955228\n",
      "Epoch 11::Minibatch 965::LR 0.0769230769231 --> Loss 0.00775822321574\n",
      "Epoch 11::Minibatch 966::LR 0.0769230769231 --> Loss 0.00538030823072\n",
      "Epoch 11::Minibatch 967::LR 0.0769230769231 --> Loss 0.00171933948994\n",
      "Epoch 11::Minibatch 968::LR 0.0769230769231 --> Loss 0.00150807430347\n",
      "Epoch 11::Minibatch 969::LR 0.0769230769231 --> Loss 0.00728357235591\n",
      "Epoch 11::Minibatch 970::LR 0.0769230769231 --> Loss 0.00617407759031\n",
      "Epoch 11::Minibatch 971::LR 0.0769230769231 --> Loss 0.00377524892489\n",
      "Epoch 11::Minibatch 972::LR 0.0769230769231 --> Loss 0.00944202740987\n",
      "Epoch 11::Minibatch 973::LR 0.0769230769231 --> Loss 0.00919814745585\n",
      "Epoch 11::Minibatch 974::LR 0.0769230769231 --> Loss 0.00715879996618\n",
      "Epoch 11::Minibatch 975::LR 0.0769230769231 --> Loss 0.00487873236338\n",
      "Epoch 11::Minibatch 976::LR 0.0769230769231 --> Loss 0.00443741003672\n",
      "Epoch 11::Minibatch 977::LR 0.0769230769231 --> Loss 0.00448532382647\n",
      "Epoch 11::Minibatch 978::LR 0.0769230769231 --> Loss 0.0044381916523\n",
      "Epoch 11::Minibatch 979::LR 0.0769230769231 --> Loss 0.00443039218585\n",
      "Epoch 11::Minibatch 980::LR 0.0769230769231 --> Loss 0.0042322186629\n",
      "Epoch 11::Minibatch 981::LR 0.0769230769231 --> Loss 0.00554419795672\n",
      "Epoch 11::Minibatch 982::LR 0.0769230769231 --> Loss 0.00735462029775\n",
      "Epoch 11::Minibatch 983::LR 0.0769230769231 --> Loss 0.00332748611768\n",
      "Epoch 11::Minibatch 984::LR 0.0769230769231 --> Loss 0.00307309269905\n",
      "Epoch 11::Minibatch 985::LR 0.0769230769231 --> Loss 0.00482642650604\n",
      "Epoch 11::Minibatch 986::LR 0.0769230769231 --> Loss 0.00440774639448\n",
      "Epoch 11::Minibatch 987::LR 0.0769230769231 --> Loss 0.00471432646116\n",
      "Epoch 11::Minibatch 988::LR 0.0769230769231 --> Loss 0.00367871085803\n",
      "Epoch 11::Minibatch 989::LR 0.0769230769231 --> Loss 0.00369028528531\n",
      "Epoch 11::Minibatch 990::LR 0.0769230769231 --> Loss 0.00341836929321\n",
      "Epoch 11::Minibatch 991::LR 0.0769230769231 --> Loss 0.00194812218348\n",
      "Epoch 11::Minibatch 992::LR 0.0769230769231 --> Loss 0.00212437490622\n",
      "Epoch 11::Minibatch 993::LR 0.0769230769231 --> Loss 0.00366620540619\n",
      "Epoch 11::Minibatch 994::LR 0.0769230769231 --> Loss 0.0022074709336\n",
      "Epoch 11::Minibatch 995::LR 0.0769230769231 --> Loss 0.000956276456515\n",
      "Epoch 11::Minibatch 996::LR 0.0769230769231 --> Loss 0.00337472915649\n",
      "Epoch 11::Minibatch 997::LR 0.0769230769231 --> Loss 0.00221925139427\n",
      "Epoch 11::Minibatch 998::LR 0.0769230769231 --> Loss 0.00244532803694\n",
      "Epoch 11::Minibatch 999::LR 0.0769230769231 --> Loss 0.00197523534298\n",
      "Epoch 11::Minibatch 1000::LR 0.0769230769231 --> Loss 0.00230367561181\n",
      "Epoch 11::Minibatch 1001::LR 0.0769230769231 --> Loss 0.00192298928897\n",
      "Epoch 11::Minibatch 1002::LR 0.0769230769231 --> Loss 0.00345232129097\n",
      "Epoch 11::Minibatch 1003::LR 0.0769230769231 --> Loss 0.00410031119982\n",
      "Epoch 11::Minibatch 1004::LR 0.0769230769231 --> Loss 0.00106586029132\n",
      "Epoch 11::Minibatch 1005::LR 0.0769230769231 --> Loss 0.00435172001521\n",
      "Epoch 11::Minibatch 1006::LR 0.0769230769231 --> Loss 0.00291064937909\n",
      "Epoch 11::Minibatch 1007::LR 0.0769230769231 --> Loss 0.00296638329824\n",
      "Epoch 11::Minibatch 1008::LR 0.0769230769231 --> Loss 0.000990068713824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11::Minibatch 1009::LR 0.0769230769231 --> Loss 0.0017423971494\n",
      "Epoch 11::Minibatch 1010::LR 0.0769230769231 --> Loss 0.00143641938766\n",
      "Epoch 11::Minibatch 1011::LR 0.0769230769231 --> Loss 0.00281723539035\n",
      "Epoch 11::Minibatch 1012::LR 0.0769230769231 --> Loss 0.00188059906165\n",
      "Epoch 11::Minibatch 1013::LR 0.0769230769231 --> Loss 0.00492136836052\n",
      "Epoch 11::Minibatch 1014::LR 0.0769230769231 --> Loss 0.0047102423509\n",
      "Epoch 11::Minibatch 1015::LR 0.0769230769231 --> Loss 0.00182114402453\n",
      "Epoch 11::Minibatch 1016::LR 0.0769230769231 --> Loss 0.00534074147542\n",
      "Epoch 11::Minibatch 1017::LR 0.0769230769231 --> Loss 0.00292032738527\n",
      "Epoch 11::Minibatch 1018::LR 0.0769230769231 --> Loss 0.00324545741081\n",
      "Epoch 11::Minibatch 1019::LR 0.0769230769231 --> Loss 0.00234091202418\n",
      "Epoch 11::Minibatch 1020::LR 0.0769230769231 --> Loss 0.00230083703995\n",
      "Epoch 11::Minibatch 1021::LR 0.0769230769231 --> Loss 0.002227927049\n",
      "Epoch 11::Minibatch 1022::LR 0.0769230769231 --> Loss 0.00170495172342\n",
      "Epoch 11::Minibatch 1023::LR 0.0769230769231 --> Loss 0.00136466046174\n",
      "Epoch 11::Minibatch 1024::LR 0.0769230769231 --> Loss 0.00131937066714\n",
      "Epoch 11::Minibatch 1025::LR 0.0769230769231 --> Loss 0.0014963405331\n",
      "Epoch 11::Minibatch 1026::LR 0.0769230769231 --> Loss 0.000933408637842\n",
      "Epoch 11::Minibatch 1027::LR 0.0769230769231 --> Loss 0.00110749443372\n",
      "Epoch 11::Minibatch 1028::LR 0.0769230769231 --> Loss 0.000856687327226\n",
      "Epoch 11::Minibatch 1029::LR 0.0769230769231 --> Loss 0.00083053847154\n",
      "Epoch 11::Minibatch 1030::LR 0.0769230769231 --> Loss 0.00102545330922\n",
      "Epoch 11::Minibatch 1031::LR 0.0769230769231 --> Loss 0.000804558197657\n",
      "Epoch 11::Minibatch 1032::LR 0.0769230769231 --> Loss 0.000807976474365\n",
      "Epoch 11::Minibatch 1033::LR 0.0769230769231 --> Loss 0.000684347798427\n",
      "Epoch 11::Minibatch 1034::LR 0.0769230769231 --> Loss 0.000681771139304\n",
      "Epoch 11::Minibatch 1035::LR 0.0769230769231 --> Loss 0.000514505157868\n",
      "Epoch 11::Minibatch 1036::LR 0.0769230769231 --> Loss 0.000404884542028\n",
      "Epoch 11::Minibatch 1037::LR 0.0769230769231 --> Loss 0.000589545667171\n",
      "Epoch 11::Minibatch 1038::LR 0.0769230769231 --> Loss 0.00134190847476\n",
      "Epoch 11::Minibatch 1039::LR 0.0769230769231 --> Loss 0.00108509381612\n",
      "Epoch 11::Minibatch 1040::LR 0.0769230769231 --> Loss 0.000483423471451\n",
      "Epoch 11::Minibatch 1041::LR 0.0769230769231 --> Loss 0.000637157360713\n",
      "Epoch 12::Minibatch 1::LR 0.0746153846154 --> Loss 0.0101584148407\n",
      "Epoch 12::Minibatch 2::LR 0.0746153846154 --> Loss 0.00670004606247\n",
      "Epoch 12::Minibatch 3::LR 0.0746153846154 --> Loss 0.00436192631721\n",
      "Epoch 12::Minibatch 4::LR 0.0746153846154 --> Loss 0.00457480589549\n",
      "Epoch 12::Minibatch 5::LR 0.0746153846154 --> Loss 0.0048123494784\n",
      "Epoch 12::Minibatch 6::LR 0.0746153846154 --> Loss 0.00253233194351\n",
      "Epoch 12::Minibatch 7::LR 0.0746153846154 --> Loss 0.00792673587799\n",
      "Epoch 12::Minibatch 8::LR 0.0746153846154 --> Loss 0.00778804222743\n",
      "Epoch 12::Minibatch 9::LR 0.0746153846154 --> Loss 0.00562055865924\n",
      "Epoch 12::Minibatch 10::LR 0.0746153846154 --> Loss 0.00299423158169\n",
      "Epoch 12::Minibatch 11::LR 0.0746153846154 --> Loss 0.00249924461047\n",
      "Epoch 12::Minibatch 12::LR 0.0746153846154 --> Loss 0.00360265374184\n",
      "Epoch 12::Minibatch 13::LR 0.0746153846154 --> Loss 0.00541989167531\n",
      "Epoch 12::Minibatch 14::LR 0.0746153846154 --> Loss 0.00513022661209\n",
      "Epoch 12::Minibatch 15::LR 0.0746153846154 --> Loss 0.0041363243262\n",
      "Epoch 12::Minibatch 16::LR 0.0746153846154 --> Loss 0.000927277108033\n",
      "Epoch 12::Minibatch 17::LR 0.0746153846154 --> Loss 0.00313567598661\n",
      "Epoch 12::Minibatch 18::LR 0.0746153846154 --> Loss 0.00248341739178\n",
      "Epoch 12::Minibatch 19::LR 0.0746153846154 --> Loss 0.00114053656658\n",
      "Epoch 12::Minibatch 20::LR 0.0746153846154 --> Loss 0.00159381786982\n",
      "Epoch 12::Minibatch 21::LR 0.0746153846154 --> Loss 0.00320015589396\n",
      "Epoch 12::Minibatch 22::LR 0.0746153846154 --> Loss 0.00236099421978\n",
      "Epoch 12::Minibatch 23::LR 0.0746153846154 --> Loss 0.000794420987368\n",
      "Epoch 12::Minibatch 24::LR 0.0746153846154 --> Loss 0.000359910801053\n",
      "Epoch 12::Minibatch 25::LR 0.0746153846154 --> Loss 0.00110305567582\n",
      "Epoch 12::Minibatch 26::LR 0.0746153846154 --> Loss 0.00128572324912\n",
      "Epoch 12::Minibatch 27::LR 0.0746153846154 --> Loss 0.000930993755658\n",
      "Epoch 12::Minibatch 28::LR 0.0746153846154 --> Loss 0.000369352201621\n",
      "Epoch 12::Minibatch 29::LR 0.0746153846154 --> Loss 0.000345485334595\n",
      "Epoch 12::Minibatch 30::LR 0.0746153846154 --> Loss 0.000828716556231\n",
      "Epoch 12::Minibatch 31::LR 0.0746153846154 --> Loss 0.00130113790433\n",
      "Epoch 12::Minibatch 32::LR 0.0746153846154 --> Loss 0.00127256135146\n",
      "Epoch 12::Minibatch 33::LR 0.0746153846154 --> Loss 0.000778903861841\n",
      "Epoch 12::Minibatch 34::LR 0.0746153846154 --> Loss 0.0026303867499\n",
      "Epoch 12::Minibatch 35::LR 0.0746153846154 --> Loss 0.00413578629494\n",
      "Epoch 12::Minibatch 36::LR 0.0746153846154 --> Loss 0.00215292135874\n",
      "Epoch 12::Minibatch 37::LR 0.0746153846154 --> Loss 0.000611455937227\n",
      "Epoch 12::Minibatch 38::LR 0.0746153846154 --> Loss 0.000763297577699\n",
      "Epoch 12::Minibatch 39::LR 0.0746153846154 --> Loss 0.00249889492989\n",
      "Epoch 12::Minibatch 40::LR 0.0746153846154 --> Loss 0.00356735308965\n",
      "Epoch 12::Minibatch 41::LR 0.0746153846154 --> Loss 0.00319711307685\n",
      "Epoch 12::Minibatch 42::LR 0.0746153846154 --> Loss 0.00627224763234\n",
      "Epoch 12::Minibatch 43::LR 0.0746153846154 --> Loss 0.00186168531577\n",
      "Epoch 12::Minibatch 44::LR 0.0746153846154 --> Loss 0.00311558743318\n",
      "Epoch 12::Minibatch 45::LR 0.0746153846154 --> Loss 0.00257556577524\n",
      "Epoch 12::Minibatch 46::LR 0.0746153846154 --> Loss 0.00362866918246\n",
      "Epoch 12::Minibatch 47::LR 0.0746153846154 --> Loss 0.00502594510714\n",
      "Epoch 12::Minibatch 48::LR 0.0746153846154 --> Loss 0.0062419851621\n",
      "Epoch 12::Minibatch 49::LR 0.0746153846154 --> Loss 0.00631258606911\n",
      "Epoch 12::Minibatch 50::LR 0.0746153846154 --> Loss 0.00599824349085\n",
      "Epoch 12::Minibatch 51::LR 0.0746153846154 --> Loss 0.00879816134771\n",
      "Epoch 12::Minibatch 52::LR 0.0746153846154 --> Loss 0.0035817249616\n",
      "Epoch 12::Minibatch 53::LR 0.0746153846154 --> Loss 0.00351664384206\n",
      "Epoch 12::Minibatch 54::LR 0.0746153846154 --> Loss 0.00400989532471\n",
      "Epoch 12::Minibatch 55::LR 0.0746153846154 --> Loss 0.00101931462685\n",
      "Epoch 12::Minibatch 56::LR 0.0746153846154 --> Loss 0.0027909519275\n",
      "Epoch 12::Minibatch 57::LR 0.0746153846154 --> Loss 0.0061692738533\n",
      "Epoch 12::Minibatch 58::LR 0.0746153846154 --> Loss 0.00346363464991\n",
      "Epoch 12::Minibatch 59::LR 0.0746153846154 --> Loss 0.00274453401566\n",
      "Epoch 12::Minibatch 60::LR 0.0746153846154 --> Loss 0.00245511392752\n",
      "Epoch 12::Minibatch 61::LR 0.0746153846154 --> Loss 0.00099404613177\n",
      "Epoch 12::Minibatch 62::LR 0.0746153846154 --> Loss 0.0035188571612\n",
      "Epoch 12::Minibatch 63::LR 0.0746153846154 --> Loss 0.00227286358674\n",
      "Epoch 12::Minibatch 64::LR 0.0746153846154 --> Loss 0.000988978942235\n",
      "Epoch 12::Minibatch 65::LR 0.0746153846154 --> Loss 0.00245458583037\n",
      "Epoch 12::Minibatch 66::LR 0.0746153846154 --> Loss 0.00301279266675\n",
      "Epoch 12::Minibatch 67::LR 0.0746153846154 --> Loss 0.00290236632029\n",
      "Epoch 12::Minibatch 68::LR 0.0746153846154 --> Loss 0.00205224454403\n",
      "Epoch 12::Minibatch 69::LR 0.0746153846154 --> Loss 0.00412289539973\n",
      "Epoch 12::Minibatch 70::LR 0.0746153846154 --> Loss 0.0035445590814\n",
      "Epoch 12::Minibatch 71::LR 0.0746153846154 --> Loss 0.00238356391589\n",
      "Epoch 12::Minibatch 72::LR 0.0746153846154 --> Loss 0.000551664978266\n",
      "Epoch 12::Minibatch 73::LR 0.0746153846154 --> Loss 0.00399392167727\n",
      "Epoch 12::Minibatch 74::LR 0.0746153846154 --> Loss 0.00423164486885\n",
      "Epoch 12::Minibatch 75::LR 0.0746153846154 --> Loss 0.00269221405188\n",
      "Epoch 12::Minibatch 76::LR 0.0746153846154 --> Loss 0.000679464836915\n",
      "Epoch 12::Minibatch 77::LR 0.0746153846154 --> Loss 0.00436545888583\n",
      "Epoch 12::Minibatch 78::LR 0.0746153846154 --> Loss 0.00394316911697\n",
      "Epoch 12::Minibatch 79::LR 0.0746153846154 --> Loss 0.00217494209607\n",
      "Epoch 12::Minibatch 80::LR 0.0746153846154 --> Loss 0.00350730935733\n",
      "Epoch 12::Minibatch 81::LR 0.0746153846154 --> Loss 0.00303152104219\n",
      "Epoch 12::Minibatch 82::LR 0.0746153846154 --> Loss 0.00208471258481\n",
      "Epoch 12::Minibatch 83::LR 0.0746153846154 --> Loss 0.0050727669398\n",
      "Epoch 12::Minibatch 84::LR 0.0746153846154 --> Loss 0.00211904406548\n",
      "Epoch 12::Minibatch 85::LR 0.0746153846154 --> Loss 0.0028669766585\n",
      "Epoch 12::Minibatch 86::LR 0.0746153846154 --> Loss 0.00236641903718\n",
      "Epoch 12::Minibatch 87::LR 0.0746153846154 --> Loss 0.00263944546382\n",
      "Epoch 12::Minibatch 88::LR 0.0746153846154 --> Loss 0.0019328002135\n",
      "Epoch 12::Minibatch 89::LR 0.0746153846154 --> Loss 0.002440777421\n",
      "Epoch 12::Minibatch 90::LR 0.0746153846154 --> Loss 0.0012867462635\n",
      "Epoch 12::Minibatch 91::LR 0.0746153846154 --> Loss 0.00104383339485\n",
      "Epoch 12::Minibatch 92::LR 0.0746153846154 --> Loss 0.00276780863603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 93::LR 0.0746153846154 --> Loss 0.00185579458872\n",
      "Epoch 12::Minibatch 94::LR 0.0746153846154 --> Loss 0.00185267468294\n",
      "Epoch 12::Minibatch 95::LR 0.0746153846154 --> Loss 0.00177800456683\n",
      "Epoch 12::Minibatch 96::LR 0.0746153846154 --> Loss 0.00623046557109\n",
      "Epoch 12::Minibatch 97::LR 0.0746153846154 --> Loss 0.00328347524007\n",
      "Epoch 12::Minibatch 98::LR 0.0746153846154 --> Loss 0.000967590113481\n",
      "Epoch 12::Minibatch 99::LR 0.0746153846154 --> Loss 0.00130032469829\n",
      "Epoch 12::Minibatch 100::LR 0.0746153846154 --> Loss 0.00555114865303\n",
      "Epoch 12::Minibatch 101::LR 0.0746153846154 --> Loss 0.000981824994087\n",
      "Epoch 12::Minibatch 102::LR 0.0746153846154 --> Loss 0.00382588426272\n",
      "Epoch 12::Minibatch 103::LR 0.0746153846154 --> Loss 0.00405447800954\n",
      "Epoch 12::Minibatch 104::LR 0.0746153846154 --> Loss 0.00285246789455\n",
      "Epoch 12::Minibatch 105::LR 0.0746153846154 --> Loss 0.00319600979487\n",
      "Epoch 12::Minibatch 106::LR 0.0746153846154 --> Loss 0.0186004082362\n",
      "Epoch 12::Minibatch 107::LR 0.0746153846154 --> Loss 0.00491938551267\n",
      "Epoch 12::Minibatch 108::LR 0.0746153846154 --> Loss 0.00119379351536\n",
      "Epoch 12::Minibatch 109::LR 0.0746153846154 --> Loss 0.00457011262576\n",
      "Epoch 12::Minibatch 110::LR 0.0746153846154 --> Loss 0.00257863859336\n",
      "Epoch 12::Minibatch 111::LR 0.0746153846154 --> Loss 0.00111208955447\n",
      "Epoch 12::Minibatch 112::LR 0.0746153846154 --> Loss 0.00376964767774\n",
      "Epoch 12::Minibatch 113::LR 0.0746153846154 --> Loss 0.00288113395373\n",
      "Epoch 12::Minibatch 114::LR 0.0746153846154 --> Loss 0.00159535030524\n",
      "Epoch 12::Minibatch 115::LR 0.0746153846154 --> Loss 0.00148612856865\n",
      "Epoch 12::Minibatch 116::LR 0.0746153846154 --> Loss 0.00297899822394\n",
      "Epoch 12::Minibatch 117::LR 0.0746153846154 --> Loss 0.00380146940549\n",
      "Epoch 12::Minibatch 118::LR 0.0746153846154 --> Loss 0.00704670111338\n",
      "Epoch 12::Minibatch 119::LR 0.0746153846154 --> Loss 0.000767759631077\n",
      "Epoch 12::Minibatch 120::LR 0.0746153846154 --> Loss 0.00197259267171\n",
      "Epoch 12::Minibatch 121::LR 0.0746153846154 --> Loss 0.00293012479941\n",
      "Epoch 12::Minibatch 122::LR 0.0746153846154 --> Loss 0.00376788377762\n",
      "Epoch 12::Minibatch 123::LR 0.0746153846154 --> Loss 0.00127995570501\n",
      "Epoch 12::Minibatch 124::LR 0.0746153846154 --> Loss 0.00294575790564\n",
      "Epoch 12::Minibatch 125::LR 0.0746153846154 --> Loss 0.00482273300489\n",
      "Epoch 12::Minibatch 126::LR 0.0746153846154 --> Loss 0.00287220776081\n",
      "Epoch 12::Minibatch 127::LR 0.0746153846154 --> Loss 0.00444751699766\n",
      "Epoch 12::Minibatch 128::LR 0.0746153846154 --> Loss 0.00371464729309\n",
      "Epoch 12::Minibatch 129::LR 0.0746153846154 --> Loss 0.00288389464219\n",
      "Epoch 12::Minibatch 130::LR 0.0746153846154 --> Loss 0.00440295537313\n",
      "Epoch 12::Minibatch 131::LR 0.0746153846154 --> Loss 0.00189497808615\n",
      "Epoch 12::Minibatch 132::LR 0.0746153846154 --> Loss 0.00327962478002\n",
      "Epoch 12::Minibatch 133::LR 0.0746153846154 --> Loss 0.00315288722515\n",
      "Epoch 12::Minibatch 134::LR 0.0746153846154 --> Loss 0.00257471263409\n",
      "Epoch 12::Minibatch 135::LR 0.0746153846154 --> Loss 0.00177817046642\n",
      "Epoch 12::Minibatch 136::LR 0.0746153846154 --> Loss 0.00289723912875\n",
      "Epoch 12::Minibatch 137::LR 0.0746153846154 --> Loss 0.00381355126699\n",
      "Epoch 12::Minibatch 138::LR 0.0746153846154 --> Loss 0.00138520608346\n",
      "Epoch 12::Minibatch 139::LR 0.0746153846154 --> Loss 0.00193823794524\n",
      "Epoch 12::Minibatch 140::LR 0.0746153846154 --> Loss 0.002490858833\n",
      "Epoch 12::Minibatch 141::LR 0.0746153846154 --> Loss 0.00304175833861\n",
      "Epoch 12::Minibatch 142::LR 0.0746153846154 --> Loss 0.00309723556042\n",
      "Epoch 12::Minibatch 143::LR 0.0746153846154 --> Loss 0.000652752319972\n",
      "Epoch 12::Minibatch 144::LR 0.0746153846154 --> Loss 0.00321668505669\n",
      "Epoch 12::Minibatch 145::LR 0.0746153846154 --> Loss 0.00441184242566\n",
      "Epoch 12::Minibatch 146::LR 0.0746153846154 --> Loss 0.00266952733199\n",
      "Epoch 12::Minibatch 147::LR 0.0746153846154 --> Loss 0.00185614188512\n",
      "Epoch 12::Minibatch 148::LR 0.0746153846154 --> Loss 0.00105282505353\n",
      "Epoch 12::Minibatch 149::LR 0.0746153846154 --> Loss 0.00286547482014\n",
      "Epoch 12::Minibatch 150::LR 0.0746153846154 --> Loss 0.00279045065244\n",
      "Epoch 12::Minibatch 151::LR 0.0746153846154 --> Loss 0.00428402304649\n",
      "Epoch 12::Minibatch 152::LR 0.0746153846154 --> Loss 0.000952388246854\n",
      "Epoch 12::Minibatch 153::LR 0.0746153846154 --> Loss 0.00190697729588\n",
      "Epoch 12::Minibatch 154::LR 0.0746153846154 --> Loss 0.00209492663542\n",
      "Epoch 12::Minibatch 155::LR 0.0746153846154 --> Loss 0.00475240111351\n",
      "Epoch 12::Minibatch 156::LR 0.0746153846154 --> Loss 0.00246217608452\n",
      "Epoch 12::Minibatch 157::LR 0.0746153846154 --> Loss 0.000714054952065\n",
      "Epoch 12::Minibatch 158::LR 0.0746153846154 --> Loss 0.00307026882966\n",
      "Epoch 12::Minibatch 159::LR 0.0746153846154 --> Loss 0.00279954969883\n",
      "Epoch 12::Minibatch 160::LR 0.0746153846154 --> Loss 0.00268797755241\n",
      "Epoch 12::Minibatch 161::LR 0.0746153846154 --> Loss 0.00105309089025\n",
      "Epoch 12::Minibatch 162::LR 0.0746153846154 --> Loss 0.00366376916567\n",
      "Epoch 12::Minibatch 163::LR 0.0746153846154 --> Loss 0.00244168500106\n",
      "Epoch 12::Minibatch 164::LR 0.0746153846154 --> Loss 0.00251575152079\n",
      "Epoch 12::Minibatch 165::LR 0.0746153846154 --> Loss 0.000556033899387\n",
      "Epoch 12::Minibatch 166::LR 0.0746153846154 --> Loss 0.00183624128501\n",
      "Epoch 12::Minibatch 167::LR 0.0746153846154 --> Loss 0.002475669384\n",
      "Epoch 12::Minibatch 168::LR 0.0746153846154 --> Loss 0.00222827196121\n",
      "Epoch 12::Minibatch 169::LR 0.0746153846154 --> Loss 0.00103790491819\n",
      "Epoch 12::Minibatch 170::LR 0.0746153846154 --> Loss 0.00101456393798\n",
      "Epoch 12::Minibatch 171::LR 0.0746153846154 --> Loss 0.00256218671799\n",
      "Epoch 12::Minibatch 172::LR 0.0746153846154 --> Loss 0.00475322763125\n",
      "Epoch 12::Minibatch 173::LR 0.0746153846154 --> Loss 0.00199406166871\n",
      "Epoch 12::Minibatch 174::LR 0.0746153846154 --> Loss 0.00108386476835\n",
      "Epoch 12::Minibatch 175::LR 0.0746153846154 --> Loss 0.00230587144693\n",
      "Epoch 12::Minibatch 176::LR 0.0746153846154 --> Loss 0.00339464505514\n",
      "Epoch 12::Minibatch 177::LR 0.0746153846154 --> Loss 0.00473258018494\n",
      "Epoch 12::Minibatch 178::LR 0.0746153846154 --> Loss 0.00170188963413\n",
      "Epoch 12::Minibatch 179::LR 0.0746153846154 --> Loss 0.00143558472395\n",
      "Epoch 12::Minibatch 180::LR 0.0746153846154 --> Loss 0.00374877969424\n",
      "Epoch 12::Minibatch 181::LR 0.0746153846154 --> Loss 0.00338938951492\n",
      "Epoch 12::Minibatch 182::LR 0.0746153846154 --> Loss 0.000834043224653\n",
      "Epoch 12::Minibatch 183::LR 0.0746153846154 --> Loss 0.00174554487069\n",
      "Epoch 12::Minibatch 184::LR 0.0746153846154 --> Loss 0.00342269023259\n",
      "Epoch 12::Minibatch 185::LR 0.0746153846154 --> Loss 0.00290185511112\n",
      "Epoch 12::Minibatch 186::LR 0.0746153846154 --> Loss 0.0010102284948\n",
      "Epoch 12::Minibatch 187::LR 0.0746153846154 --> Loss 0.00125909427802\n",
      "Epoch 12::Minibatch 188::LR 0.0746153846154 --> Loss 0.00420041720072\n",
      "Epoch 12::Minibatch 189::LR 0.0746153846154 --> Loss 0.0046033513546\n",
      "Epoch 12::Minibatch 190::LR 0.0746153846154 --> Loss 0.00233217338721\n",
      "Epoch 12::Minibatch 191::LR 0.0746153846154 --> Loss 0.00051726470391\n",
      "Epoch 12::Minibatch 192::LR 0.0746153846154 --> Loss 0.00269350548585\n",
      "Epoch 12::Minibatch 193::LR 0.0746153846154 --> Loss 0.00252154211203\n",
      "Epoch 12::Minibatch 194::LR 0.0746153846154 --> Loss 0.00182108322779\n",
      "Epoch 12::Minibatch 195::LR 0.0746153846154 --> Loss 0.000409906456868\n",
      "Epoch 12::Minibatch 196::LR 0.0746153846154 --> Loss 0.00122162868579\n",
      "Epoch 12::Minibatch 197::LR 0.0746153846154 --> Loss 0.00283009926478\n",
      "Epoch 12::Minibatch 198::LR 0.0746153846154 --> Loss 0.00220006227493\n",
      "Epoch 12::Minibatch 199::LR 0.0746153846154 --> Loss 0.000304196054737\n",
      "Epoch 12::Minibatch 200::LR 0.0746153846154 --> Loss 0.00210572699706\n",
      "Epoch 12::Minibatch 201::LR 0.0746153846154 --> Loss 0.0019878000021\n",
      "Epoch 12::Minibatch 202::LR 0.0746153846154 --> Loss 0.00191836078962\n",
      "Epoch 12::Minibatch 203::LR 0.0746153846154 --> Loss 0.00184864064058\n",
      "Epoch 12::Minibatch 204::LR 0.0746153846154 --> Loss 0.001554847459\n",
      "Epoch 12::Minibatch 205::LR 0.0746153846154 --> Loss 0.00226202627023\n",
      "Epoch 12::Minibatch 206::LR 0.0746153846154 --> Loss 0.00702736934026\n",
      "Epoch 12::Minibatch 207::LR 0.0746153846154 --> Loss 0.00141603549321\n",
      "Epoch 12::Minibatch 208::LR 0.0746153846154 --> Loss 0.00118026316166\n",
      "Epoch 12::Minibatch 209::LR 0.0746153846154 --> Loss 0.00213514328003\n",
      "Epoch 12::Minibatch 210::LR 0.0746153846154 --> Loss 0.00201792299747\n",
      "Epoch 12::Minibatch 211::LR 0.0746153846154 --> Loss 0.00213641305765\n",
      "Epoch 12::Minibatch 212::LR 0.0746153846154 --> Loss 0.0041888264815\n",
      "Epoch 12::Minibatch 213::LR 0.0746153846154 --> Loss 0.0061349316438\n",
      "Epoch 12::Minibatch 214::LR 0.0746153846154 --> Loss 0.010195072492\n",
      "Epoch 12::Minibatch 215::LR 0.0746153846154 --> Loss 0.00145867576202\n",
      "Epoch 12::Minibatch 216::LR 0.0746153846154 --> Loss 0.00559123078982\n",
      "Epoch 12::Minibatch 217::LR 0.0746153846154 --> Loss 0.00614907781283\n",
      "Epoch 12::Minibatch 218::LR 0.0746153846154 --> Loss 0.00404320597649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 219::LR 0.0746153846154 --> Loss 0.00388231714567\n",
      "Epoch 12::Minibatch 220::LR 0.0746153846154 --> Loss 0.0046362555027\n",
      "Epoch 12::Minibatch 221::LR 0.0746153846154 --> Loss 0.00432168205579\n",
      "Epoch 12::Minibatch 222::LR 0.0746153846154 --> Loss 0.00334118088086\n",
      "Epoch 12::Minibatch 223::LR 0.0746153846154 --> Loss 0.00146583547195\n",
      "Epoch 12::Minibatch 224::LR 0.0746153846154 --> Loss 0.00188965439796\n",
      "Epoch 12::Minibatch 225::LR 0.0746153846154 --> Loss 0.00712702115377\n",
      "Epoch 12::Minibatch 226::LR 0.0746153846154 --> Loss 0.00384854793549\n",
      "Epoch 12::Minibatch 227::LR 0.0746153846154 --> Loss 0.00173470755418\n",
      "Epoch 12::Minibatch 228::LR 0.0746153846154 --> Loss 0.000821411162615\n",
      "Epoch 12::Minibatch 229::LR 0.0746153846154 --> Loss 0.00485937436422\n",
      "Epoch 12::Minibatch 230::LR 0.0746153846154 --> Loss 0.00405165751775\n",
      "Epoch 12::Minibatch 231::LR 0.0746153846154 --> Loss 0.00264936784903\n",
      "Epoch 12::Minibatch 232::LR 0.0746153846154 --> Loss 0.00128923962514\n",
      "Epoch 12::Minibatch 233::LR 0.0746153846154 --> Loss 0.00243567784627\n",
      "Epoch 12::Minibatch 234::LR 0.0746153846154 --> Loss 0.00663485010465\n",
      "Epoch 12::Minibatch 235::LR 0.0746153846154 --> Loss 0.00489820480347\n",
      "Epoch 12::Minibatch 236::LR 0.0746153846154 --> Loss 0.00184181292852\n",
      "Epoch 12::Minibatch 237::LR 0.0746153846154 --> Loss 0.000748910208543\n",
      "Epoch 12::Minibatch 238::LR 0.0746153846154 --> Loss 0.00344690362612\n",
      "Epoch 12::Minibatch 239::LR 0.0746153846154 --> Loss 0.00297950963179\n",
      "Epoch 12::Minibatch 240::LR 0.0746153846154 --> Loss 0.00327299018701\n",
      "Epoch 12::Minibatch 241::LR 0.0746153846154 --> Loss 0.000812116911014\n",
      "Epoch 12::Minibatch 242::LR 0.0746153846154 --> Loss 0.00726825078328\n",
      "Epoch 12::Minibatch 243::LR 0.0746153846154 --> Loss 0.00365249633789\n",
      "Epoch 12::Minibatch 244::LR 0.0746153846154 --> Loss 0.00305044452349\n",
      "Epoch 12::Minibatch 245::LR 0.0746153846154 --> Loss 0.000513909459114\n",
      "Epoch 12::Minibatch 246::LR 0.0746153846154 --> Loss 0.00213538090388\n",
      "Epoch 12::Minibatch 247::LR 0.0746153846154 --> Loss 0.0140022246043\n",
      "Epoch 12::Minibatch 248::LR 0.0746153846154 --> Loss 0.00466066559156\n",
      "Epoch 12::Minibatch 249::LR 0.0746153846154 --> Loss 0.00296996196111\n",
      "Epoch 12::Minibatch 250::LR 0.0746153846154 --> Loss 0.00286007404327\n",
      "Epoch 12::Minibatch 251::LR 0.0746153846154 --> Loss 0.00267391045888\n",
      "Epoch 12::Minibatch 252::LR 0.0746153846154 --> Loss 0.00194935043653\n",
      "Epoch 12::Minibatch 253::LR 0.0746153846154 --> Loss 0.00325854579608\n",
      "Epoch 12::Minibatch 254::LR 0.0746153846154 --> Loss 0.00536111950874\n",
      "Epoch 12::Minibatch 255::LR 0.0746153846154 --> Loss 0.00404423634211\n",
      "Epoch 12::Minibatch 256::LR 0.0746153846154 --> Loss 0.00180968483289\n",
      "Epoch 12::Minibatch 257::LR 0.0746153846154 --> Loss 0.00135782043139\n",
      "Epoch 12::Minibatch 258::LR 0.0746153846154 --> Loss 0.00366984446843\n",
      "Epoch 12::Minibatch 259::LR 0.0746153846154 --> Loss 0.00191330273946\n",
      "Epoch 12::Minibatch 260::LR 0.0746153846154 --> Loss 0.00195513745149\n",
      "Epoch 12::Minibatch 261::LR 0.0746153846154 --> Loss 0.00304124951363\n",
      "Epoch 12::Minibatch 262::LR 0.0746153846154 --> Loss 0.00201961934566\n",
      "Epoch 12::Minibatch 263::LR 0.0746153846154 --> Loss 0.00242701053619\n",
      "Epoch 12::Minibatch 264::LR 0.0746153846154 --> Loss 0.00371441364288\n",
      "Epoch 12::Minibatch 265::LR 0.0746153846154 --> Loss 0.0103645269076\n",
      "Epoch 12::Minibatch 266::LR 0.0746153846154 --> Loss 0.00109250823657\n",
      "Epoch 12::Minibatch 267::LR 0.0746153846154 --> Loss 0.0103155994415\n",
      "Epoch 12::Minibatch 268::LR 0.0746153846154 --> Loss 0.00128971775373\n",
      "Epoch 12::Minibatch 269::LR 0.0746153846154 --> Loss 0.00358570814133\n",
      "Epoch 12::Minibatch 270::LR 0.0746153846154 --> Loss 0.00649071375529\n",
      "Epoch 12::Minibatch 271::LR 0.0746153846154 --> Loss 0.0028751351436\n",
      "Epoch 12::Minibatch 272::LR 0.0746153846154 --> Loss 0.00406179269155\n",
      "Epoch 12::Minibatch 273::LR 0.0746153846154 --> Loss 0.00180877526601\n",
      "Epoch 12::Minibatch 274::LR 0.0746153846154 --> Loss 0.00184559543928\n",
      "Epoch 12::Minibatch 275::LR 0.0746153846154 --> Loss 0.00277173082034\n",
      "Epoch 12::Minibatch 276::LR 0.0746153846154 --> Loss 0.00353609760602\n",
      "Epoch 12::Minibatch 277::LR 0.0746153846154 --> Loss 0.00107380350431\n",
      "Epoch 12::Minibatch 278::LR 0.0746153846154 --> Loss 0.00269125481447\n",
      "Epoch 12::Minibatch 279::LR 0.0746153846154 --> Loss 0.00251138567924\n",
      "Epoch 12::Minibatch 280::LR 0.0746153846154 --> Loss 0.00218340317408\n",
      "Epoch 12::Minibatch 281::LR 0.0746153846154 --> Loss 0.00137197544177\n",
      "Epoch 12::Minibatch 282::LR 0.0746153846154 --> Loss 0.00229449689388\n",
      "Epoch 12::Minibatch 283::LR 0.0746153846154 --> Loss 0.00225813388824\n",
      "Epoch 12::Minibatch 284::LR 0.0746153846154 --> Loss 0.00180222292741\n",
      "Epoch 12::Minibatch 285::LR 0.0746153846154 --> Loss 0.00125119199355\n",
      "Epoch 12::Minibatch 286::LR 0.0746153846154 --> Loss 0.00218925217787\n",
      "Epoch 12::Minibatch 287::LR 0.0746153846154 --> Loss 0.00211856087049\n",
      "Epoch 12::Minibatch 288::LR 0.0746153846154 --> Loss 0.00113707890113\n",
      "Epoch 12::Minibatch 289::LR 0.0746153846154 --> Loss 0.00158210545778\n",
      "Epoch 12::Minibatch 290::LR 0.0746153846154 --> Loss 0.00197051405907\n",
      "Epoch 12::Minibatch 291::LR 0.0746153846154 --> Loss 0.00176215926806\n",
      "Epoch 12::Minibatch 292::LR 0.0746153846154 --> Loss 0.000623067170382\n",
      "Epoch 12::Minibatch 293::LR 0.0746153846154 --> Loss 0.00149148424466\n",
      "Epoch 12::Minibatch 294::LR 0.0746153846154 --> Loss 0.00156779150168\n",
      "Epoch 12::Minibatch 295::LR 0.0746153846154 --> Loss 0.0018516254425\n",
      "Epoch 12::Minibatch 296::LR 0.0746153846154 --> Loss 0.00160329053799\n",
      "Epoch 12::Minibatch 297::LR 0.0746153846154 --> Loss 0.00139748265346\n",
      "Epoch 12::Minibatch 298::LR 0.0746153846154 --> Loss 0.00137870301803\n",
      "Epoch 12::Minibatch 299::LR 0.0746153846154 --> Loss 0.000807444453239\n",
      "Epoch 12::Minibatch 300::LR 0.0746153846154 --> Loss 0.00288048962752\n",
      "Epoch 12::Minibatch 301::LR 0.0746153846154 --> Loss 0.00278698166211\n",
      "Epoch 12::Minibatch 302::LR 0.0746153846154 --> Loss 0.00260277887185\n",
      "Epoch 12::Minibatch 303::LR 0.0746153846154 --> Loss 0.000876133243243\n",
      "Epoch 12::Minibatch 304::LR 0.0746153846154 --> Loss 0.00315781136354\n",
      "Epoch 12::Minibatch 305::LR 0.0746153846154 --> Loss 0.00169776479403\n",
      "Epoch 12::Minibatch 306::LR 0.0746153846154 --> Loss 0.000934464236101\n",
      "Epoch 12::Minibatch 307::LR 0.0746153846154 --> Loss 0.0024747077624\n",
      "Epoch 12::Minibatch 308::LR 0.0746153846154 --> Loss 0.00198356866837\n",
      "Epoch 12::Minibatch 309::LR 0.0746153846154 --> Loss 0.000997394224008\n",
      "Epoch 12::Minibatch 310::LR 0.0746153846154 --> Loss 0.00108949790398\n",
      "Epoch 12::Minibatch 311::LR 0.0746153846154 --> Loss 0.00168072442214\n",
      "Epoch 12::Minibatch 312::LR 0.0746153846154 --> Loss 0.00303263465563\n",
      "Epoch 12::Minibatch 313::LR 0.0746153846154 --> Loss 0.00240855733554\n",
      "Epoch 12::Minibatch 314::LR 0.0746153846154 --> Loss 0.0019250357151\n",
      "Epoch 12::Minibatch 315::LR 0.0746153846154 --> Loss 0.000982219278812\n",
      "Epoch 12::Minibatch 316::LR 0.0746153846154 --> Loss 0.00233408053716\n",
      "Epoch 12::Minibatch 317::LR 0.0746153846154 --> Loss 0.00154929270347\n",
      "Epoch 12::Minibatch 318::LR 0.0746153846154 --> Loss 0.00119124352932\n",
      "Epoch 12::Minibatch 319::LR 0.0746153846154 --> Loss 0.00229567289352\n",
      "Epoch 12::Minibatch 320::LR 0.0746153846154 --> Loss 0.00329040447871\n",
      "Epoch 12::Minibatch 321::LR 0.0746153846154 --> Loss 0.000891402363777\n",
      "Epoch 12::Minibatch 322::LR 0.0746153846154 --> Loss 0.0037037785848\n",
      "Epoch 12::Minibatch 323::LR 0.0746153846154 --> Loss 0.00360205332438\n",
      "Epoch 12::Minibatch 324::LR 0.0746153846154 --> Loss 0.00264670451482\n",
      "Epoch 12::Minibatch 325::LR 0.0746153846154 --> Loss 0.00243782659372\n",
      "Epoch 12::Minibatch 326::LR 0.0746153846154 --> Loss 0.00557057817777\n",
      "Epoch 12::Minibatch 327::LR 0.0746153846154 --> Loss 0.00228612025579\n",
      "Epoch 12::Minibatch 328::LR 0.0746153846154 --> Loss 0.00343847354253\n",
      "Epoch 12::Minibatch 329::LR 0.0746153846154 --> Loss 0.0012693459789\n",
      "Epoch 12::Minibatch 330::LR 0.0746153846154 --> Loss 0.00163672318061\n",
      "Epoch 12::Minibatch 331::LR 0.0746153846154 --> Loss 0.00258205771446\n",
      "Epoch 12::Minibatch 332::LR 0.0746153846154 --> Loss 0.00254010220369\n",
      "Epoch 12::Minibatch 333::LR 0.0746153846154 --> Loss 0.00147561818361\n",
      "Epoch 12::Minibatch 334::LR 0.0746153846154 --> Loss 0.00433105111122\n",
      "Epoch 12::Minibatch 335::LR 0.0746153846154 --> Loss 0.00191306253274\n",
      "Epoch 12::Minibatch 336::LR 0.0746153846154 --> Loss 0.00210585157077\n",
      "Epoch 12::Minibatch 337::LR 0.0746153846154 --> Loss 0.00334184845289\n",
      "Epoch 12::Minibatch 338::LR 0.0746153846154 --> Loss 0.000522368550301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 339::LR 0.0746153846154 --> Loss 0.0033197504282\n",
      "Epoch 12::Minibatch 340::LR 0.0746153846154 --> Loss 0.00449251015981\n",
      "Epoch 12::Minibatch 341::LR 0.0746153846154 --> Loss 0.00508773605029\n",
      "Epoch 12::Minibatch 342::LR 0.0746153846154 --> Loss 0.00329333702723\n",
      "Epoch 12::Minibatch 343::LR 0.0746153846154 --> Loss 0.00174666325251\n",
      "Epoch 12::Minibatch 344::LR 0.0746153846154 --> Loss 0.00308399061362\n",
      "Epoch 12::Minibatch 345::LR 0.0746153846154 --> Loss 0.00435636480649\n",
      "Epoch 12::Minibatch 346::LR 0.0746153846154 --> Loss 0.00573585589727\n",
      "Epoch 12::Minibatch 347::LR 0.0746153846154 --> Loss 0.000918245613575\n",
      "Epoch 12::Minibatch 348::LR 0.0746153846154 --> Loss 0.0036067756017\n",
      "Epoch 12::Minibatch 349::LR 0.0746153846154 --> Loss 0.00356434345245\n",
      "Epoch 12::Minibatch 350::LR 0.0746153846154 --> Loss 0.00187980254491\n",
      "Epoch 12::Minibatch 351::LR 0.0746153846154 --> Loss 0.00361233313878\n",
      "Epoch 12::Minibatch 352::LR 0.0746153846154 --> Loss 0.00483730236689\n",
      "Epoch 12::Minibatch 353::LR 0.0746153846154 --> Loss 0.00358023365339\n",
      "Epoch 12::Minibatch 354::LR 0.0746153846154 --> Loss 0.00296132524808\n",
      "Epoch 12::Minibatch 355::LR 0.0746153846154 --> Loss 0.00618928273519\n",
      "Epoch 12::Minibatch 356::LR 0.0746153846154 --> Loss 0.0031603650252\n",
      "Epoch 12::Minibatch 357::LR 0.0746153846154 --> Loss 0.001212195158\n",
      "Epoch 12::Minibatch 358::LR 0.0746153846154 --> Loss 0.00224968115489\n",
      "Epoch 12::Minibatch 359::LR 0.0746153846154 --> Loss 0.00277156273524\n",
      "Epoch 12::Minibatch 360::LR 0.0746153846154 --> Loss 0.0024834728241\n",
      "Epoch 12::Minibatch 361::LR 0.0746153846154 --> Loss 0.00247077067693\n",
      "Epoch 12::Minibatch 362::LR 0.0746153846154 --> Loss 0.00248897135258\n",
      "Epoch 12::Minibatch 363::LR 0.0746153846154 --> Loss 0.000697113275528\n",
      "Epoch 12::Minibatch 364::LR 0.0746153846154 --> Loss 0.00203857719898\n",
      "Epoch 12::Minibatch 365::LR 0.0746153846154 --> Loss 0.00213767210642\n",
      "Epoch 12::Minibatch 366::LR 0.0746153846154 --> Loss 0.00231088062127\n",
      "Epoch 12::Minibatch 367::LR 0.0746153846154 --> Loss 0.0011355065306\n",
      "Epoch 12::Minibatch 368::LR 0.0746153846154 --> Loss 0.0010083630681\n",
      "Epoch 12::Minibatch 369::LR 0.0746153846154 --> Loss 0.00291706939538\n",
      "Epoch 12::Minibatch 370::LR 0.0746153846154 --> Loss 0.00228965441386\n",
      "Epoch 12::Minibatch 371::LR 0.0746153846154 --> Loss 0.00189310650031\n",
      "Epoch 12::Minibatch 372::LR 0.0746153846154 --> Loss 0.00045673429966\n",
      "Epoch 12::Minibatch 373::LR 0.0746153846154 --> Loss 0.00176570296288\n",
      "Epoch 12::Minibatch 374::LR 0.0746153846154 --> Loss 0.00216805617015\n",
      "Epoch 12::Minibatch 375::LR 0.0746153846154 --> Loss 0.00184462726116\n",
      "Epoch 12::Minibatch 376::LR 0.0746153846154 --> Loss 0.00125576168299\n",
      "Epoch 12::Minibatch 377::LR 0.0746153846154 --> Loss 0.00196782112122\n",
      "Epoch 12::Minibatch 378::LR 0.0746153846154 --> Loss 0.0021387052536\n",
      "Epoch 12::Minibatch 379::LR 0.0746153846154 --> Loss 0.00240184982618\n",
      "Epoch 12::Minibatch 380::LR 0.0746153846154 --> Loss 0.00160944690307\n",
      "Epoch 12::Minibatch 381::LR 0.0746153846154 --> Loss 0.000994517803192\n",
      "Epoch 12::Minibatch 382::LR 0.0746153846154 --> Loss 0.00201700488726\n",
      "Epoch 12::Minibatch 383::LR 0.0746153846154 --> Loss 0.00195334931215\n",
      "Epoch 12::Minibatch 384::LR 0.0746153846154 --> Loss 0.00105509320895\n",
      "Epoch 12::Minibatch 385::LR 0.0746153846154 --> Loss 0.00104303210974\n",
      "Epoch 12::Minibatch 386::LR 0.0746153846154 --> Loss 0.00219017783801\n",
      "Epoch 12::Minibatch 387::LR 0.0746153846154 --> Loss 0.00233161052068\n",
      "Epoch 12::Minibatch 388::LR 0.0746153846154 --> Loss 0.00114476412535\n",
      "Epoch 12::Minibatch 389::LR 0.0746153846154 --> Loss 0.00182833135128\n",
      "Epoch 12::Minibatch 390::LR 0.0746153846154 --> Loss 0.00368898828824\n",
      "Epoch 12::Minibatch 391::LR 0.0746153846154 --> Loss 0.00272674838702\n",
      "Epoch 12::Minibatch 392::LR 0.0746153846154 --> Loss 0.00270158410072\n",
      "Epoch 12::Minibatch 393::LR 0.0746153846154 --> Loss 0.00279967566331\n",
      "Epoch 12::Minibatch 394::LR 0.0746153846154 --> Loss 0.0020929557085\n",
      "Epoch 12::Minibatch 395::LR 0.0746153846154 --> Loss 0.00206286052863\n",
      "Epoch 12::Minibatch 396::LR 0.0746153846154 --> Loss 0.00197413126628\n",
      "Epoch 12::Minibatch 397::LR 0.0746153846154 --> Loss 0.00209484477838\n",
      "Epoch 12::Minibatch 398::LR 0.0746153846154 --> Loss 0.00207804560661\n",
      "Epoch 12::Minibatch 399::LR 0.0746153846154 --> Loss 0.00237378239632\n",
      "Epoch 12::Minibatch 400::LR 0.0746153846154 --> Loss 0.00203561643759\n",
      "Epoch 12::Minibatch 401::LR 0.0746153846154 --> Loss 0.00359405080477\n",
      "Epoch 12::Minibatch 402::LR 0.0746153846154 --> Loss 0.00185654759407\n",
      "Epoch 12::Minibatch 403::LR 0.0746153846154 --> Loss 0.00147746900717\n",
      "Epoch 12::Minibatch 404::LR 0.0746153846154 --> Loss 0.00156972755988\n",
      "Epoch 12::Minibatch 405::LR 0.0746153846154 --> Loss 0.00361348390579\n",
      "Epoch 12::Minibatch 406::LR 0.0746153846154 --> Loss 0.00251665333907\n",
      "Epoch 12::Minibatch 407::LR 0.0746153846154 --> Loss 0.00177223344644\n",
      "Epoch 12::Minibatch 408::LR 0.0746153846154 --> Loss 0.000463468879461\n",
      "Epoch 12::Minibatch 409::LR 0.0746153846154 --> Loss 0.00241111596425\n",
      "Epoch 12::Minibatch 410::LR 0.0746153846154 --> Loss 0.00327937146028\n",
      "Epoch 12::Minibatch 411::LR 0.0746153846154 --> Loss 0.0016611708204\n",
      "Epoch 12::Minibatch 412::LR 0.0746153846154 --> Loss 0.000990323821704\n",
      "Epoch 12::Minibatch 413::LR 0.0746153846154 --> Loss 0.00200758039951\n",
      "Epoch 12::Minibatch 414::LR 0.0746153846154 --> Loss 0.00183216810226\n",
      "Epoch 12::Minibatch 415::LR 0.0746153846154 --> Loss 0.0011580367883\n",
      "Epoch 12::Minibatch 416::LR 0.0746153846154 --> Loss 0.000846917827924\n",
      "Epoch 12::Minibatch 417::LR 0.0746153846154 --> Loss 0.00172578295072\n",
      "Epoch 12::Minibatch 418::LR 0.0746153846154 --> Loss 0.00287684778372\n",
      "Epoch 12::Minibatch 419::LR 0.0746153846154 --> Loss 0.000513909409444\n",
      "Epoch 12::Minibatch 420::LR 0.0746153846154 --> Loss 0.000703708082438\n",
      "Epoch 12::Minibatch 421::LR 0.0746153846154 --> Loss 0.00194216628869\n",
      "Epoch 12::Minibatch 422::LR 0.0746153846154 --> Loss 0.00218112468719\n",
      "Epoch 12::Minibatch 423::LR 0.0746153846154 --> Loss 0.000963970323404\n",
      "Epoch 12::Minibatch 424::LR 0.0746153846154 --> Loss 0.00158453394969\n",
      "Epoch 12::Minibatch 425::LR 0.0746153846154 --> Loss 0.0028946596384\n",
      "Epoch 12::Minibatch 426::LR 0.0746153846154 --> Loss 0.00201697468758\n",
      "Epoch 12::Minibatch 427::LR 0.0746153846154 --> Loss 0.000711790720622\n",
      "Epoch 12::Minibatch 428::LR 0.0746153846154 --> Loss 0.00109982063373\n",
      "Epoch 12::Minibatch 429::LR 0.0746153846154 --> Loss 0.00246963699659\n",
      "Epoch 12::Minibatch 430::LR 0.0746153846154 --> Loss 0.00961790164312\n",
      "Epoch 12::Minibatch 431::LR 0.0746153846154 --> Loss 0.00381592432658\n",
      "Epoch 12::Minibatch 432::LR 0.0746153846154 --> Loss 0.00454034606616\n",
      "Epoch 12::Minibatch 433::LR 0.0746153846154 --> Loss 0.00260068098704\n",
      "Epoch 12::Minibatch 434::LR 0.0746153846154 --> Loss 0.00257031261921\n",
      "Epoch 12::Minibatch 435::LR 0.0746153846154 --> Loss 0.00241344670455\n",
      "Epoch 12::Minibatch 436::LR 0.0746153846154 --> Loss 0.00177888731162\n",
      "Epoch 12::Minibatch 437::LR 0.0746153846154 --> Loss 0.00347041447957\n",
      "Epoch 12::Minibatch 438::LR 0.0746153846154 --> Loss 0.0027556981643\n",
      "Epoch 12::Minibatch 439::LR 0.0746153846154 --> Loss 0.00220803042253\n",
      "Epoch 12::Minibatch 440::LR 0.0746153846154 --> Loss 0.00335076411565\n",
      "Epoch 12::Minibatch 441::LR 0.0746153846154 --> Loss 0.00315011898677\n",
      "Epoch 12::Minibatch 442::LR 0.0746153846154 --> Loss 0.00289893170198\n",
      "Epoch 12::Minibatch 443::LR 0.0746153846154 --> Loss 0.00380161245664\n",
      "Epoch 12::Minibatch 444::LR 0.0746153846154 --> Loss 0.00297382632891\n",
      "Epoch 12::Minibatch 445::LR 0.0746153846154 --> Loss 0.000925534466902\n",
      "Epoch 12::Minibatch 446::LR 0.0746153846154 --> Loss 0.00150962978601\n",
      "Epoch 12::Minibatch 447::LR 0.0746153846154 --> Loss 0.00250681519508\n",
      "Epoch 12::Minibatch 448::LR 0.0746153846154 --> Loss 0.0024724394083\n",
      "Epoch 12::Minibatch 449::LR 0.0746153846154 --> Loss 0.00380163908005\n",
      "Epoch 12::Minibatch 450::LR 0.0746153846154 --> Loss 0.00240832785765\n",
      "Epoch 12::Minibatch 451::LR 0.0746153846154 --> Loss 0.00414322773616\n",
      "Epoch 12::Minibatch 452::LR 0.0746153846154 --> Loss 0.00242505391439\n",
      "Epoch 12::Minibatch 453::LR 0.0746153846154 --> Loss 0.000407251566648\n",
      "Epoch 12::Minibatch 454::LR 0.0746153846154 --> Loss 0.00363580703735\n",
      "Epoch 12::Minibatch 455::LR 0.0746153846154 --> Loss 0.00274405837059\n",
      "Epoch 12::Minibatch 456::LR 0.0746153846154 --> Loss 0.00319815794627\n",
      "Epoch 12::Minibatch 457::LR 0.0746153846154 --> Loss 0.00201648791631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 458::LR 0.0746153846154 --> Loss 0.000801546971003\n",
      "Epoch 12::Minibatch 459::LR 0.0746153846154 --> Loss 0.00419663707415\n",
      "Epoch 12::Minibatch 460::LR 0.0746153846154 --> Loss 0.00267588496208\n",
      "Epoch 12::Minibatch 461::LR 0.0746153846154 --> Loss 0.0039935807387\n",
      "Epoch 12::Minibatch 462::LR 0.0746153846154 --> Loss 0.000416798790296\n",
      "Epoch 12::Minibatch 463::LR 0.0746153846154 --> Loss 0.00459912657738\n",
      "Epoch 12::Minibatch 464::LR 0.0746153846154 --> Loss 0.0020883812507\n",
      "Epoch 12::Minibatch 465::LR 0.0746153846154 --> Loss 0.00544263561567\n",
      "Epoch 12::Minibatch 466::LR 0.0746153846154 --> Loss 0.00519206325213\n",
      "Epoch 12::Minibatch 467::LR 0.0746153846154 --> Loss 0.00608555793762\n",
      "Epoch 12::Minibatch 468::LR 0.0746153846154 --> Loss 0.00624445319176\n",
      "Epoch 12::Minibatch 469::LR 0.0746153846154 --> Loss 0.00639036178589\n",
      "Epoch 12::Minibatch 470::LR 0.0746153846154 --> Loss 0.00388775746028\n",
      "Epoch 12::Minibatch 471::LR 0.0746153846154 --> Loss 0.00181368410587\n",
      "Epoch 12::Minibatch 472::LR 0.0746153846154 --> Loss 0.00354360898336\n",
      "Epoch 12::Minibatch 473::LR 0.0746153846154 --> Loss 0.00222407917182\n",
      "Epoch 12::Minibatch 474::LR 0.0746153846154 --> Loss 0.00072148775061\n",
      "Epoch 12::Minibatch 475::LR 0.0746153846154 --> Loss 0.00528486013412\n",
      "Epoch 12::Minibatch 476::LR 0.0746153846154 --> Loss 0.00774394273758\n",
      "Epoch 12::Minibatch 477::LR 0.0746153846154 --> Loss 0.000960687299569\n",
      "Epoch 12::Minibatch 478::LR 0.0746153846154 --> Loss 0.00249605556329\n",
      "Epoch 12::Minibatch 479::LR 0.0746153846154 --> Loss 0.00196374475956\n",
      "Epoch 12::Minibatch 480::LR 0.0746153846154 --> Loss 0.00153831541538\n",
      "Epoch 12::Minibatch 481::LR 0.0746153846154 --> Loss 0.000964232087135\n",
      "Epoch 12::Minibatch 482::LR 0.0746153846154 --> Loss 0.00211113631725\n",
      "Epoch 12::Minibatch 483::LR 0.0746153846154 --> Loss 0.00327160875003\n",
      "Epoch 12::Minibatch 484::LR 0.0746153846154 --> Loss 0.00362743695577\n",
      "Epoch 12::Minibatch 485::LR 0.0746153846154 --> Loss 0.00076958929499\n",
      "Epoch 12::Minibatch 486::LR 0.0746153846154 --> Loss 0.00307272990545\n",
      "Epoch 12::Minibatch 487::LR 0.0746153846154 --> Loss 0.00343778411547\n",
      "Epoch 12::Minibatch 488::LR 0.0746153846154 --> Loss 0.00205464184284\n",
      "Epoch 12::Minibatch 489::LR 0.0746153846154 --> Loss 0.00318419297536\n",
      "Epoch 12::Minibatch 490::LR 0.0746153846154 --> Loss 0.00042194639643\n",
      "Epoch 12::Minibatch 491::LR 0.0746153846154 --> Loss 0.00403355399768\n",
      "Epoch 12::Minibatch 492::LR 0.0746153846154 --> Loss 0.00304497877757\n",
      "Epoch 12::Minibatch 493::LR 0.0746153846154 --> Loss 0.00302892247836\n",
      "Epoch 12::Minibatch 494::LR 0.0746153846154 --> Loss 0.000749688843886\n",
      "Epoch 12::Minibatch 495::LR 0.0746153846154 --> Loss 0.00189888278643\n",
      "Epoch 12::Minibatch 496::LR 0.0746153846154 --> Loss 0.00296822408835\n",
      "Epoch 12::Minibatch 497::LR 0.0746153846154 --> Loss 0.000956475933393\n",
      "Epoch 12::Minibatch 498::LR 0.0746153846154 --> Loss 0.000591227908929\n",
      "Epoch 12::Minibatch 499::LR 0.0746153846154 --> Loss 0.00377619504929\n",
      "Epoch 12::Minibatch 500::LR 0.0746153846154 --> Loss 0.00145161439975\n",
      "Epoch 12::Minibatch 501::LR 0.0746153846154 --> Loss 0.00228098928928\n",
      "Epoch 12::Minibatch 502::LR 0.0746153846154 --> Loss 0.0039378798008\n",
      "Epoch 12::Minibatch 503::LR 0.0746153846154 --> Loss 0.00924253940582\n",
      "Epoch 12::Minibatch 504::LR 0.0746153846154 --> Loss 0.00825792868932\n",
      "Epoch 12::Minibatch 505::LR 0.0746153846154 --> Loss 0.004413027366\n",
      "Epoch 12::Minibatch 506::LR 0.0746153846154 --> Loss 0.0035385231177\n",
      "Epoch 12::Minibatch 507::LR 0.0746153846154 --> Loss 0.00609573602676\n",
      "Epoch 12::Minibatch 508::LR 0.0746153846154 --> Loss 0.00340820074081\n",
      "Epoch 12::Minibatch 509::LR 0.0746153846154 --> Loss 0.00471553285917\n",
      "Epoch 12::Minibatch 510::LR 0.0746153846154 --> Loss 0.00469277699788\n",
      "Epoch 12::Minibatch 511::LR 0.0746153846154 --> Loss 0.0038971889019\n",
      "Epoch 12::Minibatch 512::LR 0.0746153846154 --> Loss 0.00269077877204\n",
      "Epoch 12::Minibatch 513::LR 0.0746153846154 --> Loss 0.000670343240102\n",
      "Epoch 12::Minibatch 514::LR 0.0746153846154 --> Loss 0.00264492909114\n",
      "Epoch 12::Minibatch 515::LR 0.0746153846154 --> Loss 0.00303191781044\n",
      "Epoch 12::Minibatch 516::LR 0.0746153846154 --> Loss 0.00416775385539\n",
      "Epoch 12::Minibatch 517::LR 0.0746153846154 --> Loss 0.0034577981631\n",
      "Epoch 12::Minibatch 518::LR 0.0746153846154 --> Loss 0.00256623029709\n",
      "Epoch 12::Minibatch 519::LR 0.0746153846154 --> Loss 0.00342110117277\n",
      "Epoch 12::Minibatch 520::LR 0.0746153846154 --> Loss 0.00539009173711\n",
      "Epoch 12::Minibatch 521::LR 0.0746153846154 --> Loss 0.0055026781559\n",
      "Epoch 12::Minibatch 522::LR 0.0746153846154 --> Loss 0.00809554815292\n",
      "Epoch 12::Minibatch 523::LR 0.0746153846154 --> Loss 0.00068772042791\n",
      "Epoch 12::Minibatch 524::LR 0.0746153846154 --> Loss 0.00144973049561\n",
      "Epoch 12::Minibatch 525::LR 0.0746153846154 --> Loss 0.00327312648296\n",
      "Epoch 12::Minibatch 526::LR 0.0746153846154 --> Loss 0.00417793035507\n",
      "Epoch 12::Minibatch 527::LR 0.0746153846154 --> Loss 0.00231422086557\n",
      "Epoch 12::Minibatch 528::LR 0.0746153846154 --> Loss 0.00111692031225\n",
      "Epoch 12::Minibatch 529::LR 0.0746153846154 --> Loss 0.00415370027224\n",
      "Epoch 12::Minibatch 530::LR 0.0746153846154 --> Loss 0.0042725567023\n",
      "Epoch 12::Minibatch 531::LR 0.0746153846154 --> Loss 0.00366410692533\n",
      "Epoch 12::Minibatch 532::LR 0.0746153846154 --> Loss 0.00274978280067\n",
      "Epoch 12::Minibatch 533::LR 0.0746153846154 --> Loss 0.00495165427526\n",
      "Epoch 12::Minibatch 534::LR 0.0746153846154 --> Loss 0.003890482982\n",
      "Epoch 12::Minibatch 535::LR 0.0746153846154 --> Loss 0.00324569284916\n",
      "Epoch 12::Minibatch 536::LR 0.0746153846154 --> Loss 0.00211824278037\n",
      "Epoch 12::Minibatch 537::LR 0.0746153846154 --> Loss 0.000655753314495\n",
      "Epoch 12::Minibatch 538::LR 0.0746153846154 --> Loss 0.00172982692719\n",
      "Epoch 12::Minibatch 539::LR 0.0746153846154 --> Loss 0.00347611546516\n",
      "Epoch 12::Minibatch 540::LR 0.0746153846154 --> Loss 0.00343256115913\n",
      "Epoch 12::Minibatch 541::LR 0.0746153846154 --> Loss 0.00293045779069\n",
      "Epoch 12::Minibatch 542::LR 0.0746153846154 --> Loss 0.00257762531439\n",
      "Epoch 12::Minibatch 543::LR 0.0746153846154 --> Loss 0.00282142659028\n",
      "Epoch 12::Minibatch 544::LR 0.0746153846154 --> Loss 0.00393296837807\n",
      "Epoch 12::Minibatch 545::LR 0.0746153846154 --> Loss 0.00208108683427\n",
      "Epoch 12::Minibatch 546::LR 0.0746153846154 --> Loss 0.000674075235923\n",
      "Epoch 12::Minibatch 547::LR 0.0746153846154 --> Loss 0.00265682458878\n",
      "Epoch 12::Minibatch 548::LR 0.0746153846154 --> Loss 0.00382235010465\n",
      "Epoch 12::Minibatch 549::LR 0.0746153846154 --> Loss 0.00810762643814\n",
      "Epoch 12::Minibatch 550::LR 0.0746153846154 --> Loss 0.00117817153533\n",
      "Epoch 12::Minibatch 551::LR 0.0746153846154 --> Loss 0.00247540076574\n",
      "Epoch 12::Minibatch 552::LR 0.0746153846154 --> Loss 0.00363974372546\n",
      "Epoch 12::Minibatch 553::LR 0.0746153846154 --> Loss 0.00328879674276\n",
      "Epoch 12::Minibatch 554::LR 0.0746153846154 --> Loss 0.00383349657059\n",
      "Epoch 12::Minibatch 555::LR 0.0746153846154 --> Loss 0.0010113598903\n",
      "Epoch 12::Minibatch 556::LR 0.0746153846154 --> Loss 0.00205263475577\n",
      "Epoch 12::Minibatch 557::LR 0.0746153846154 --> Loss 0.00248417794704\n",
      "Epoch 12::Minibatch 558::LR 0.0746153846154 --> Loss 0.00377632220586\n",
      "Epoch 12::Minibatch 559::LR 0.0746153846154 --> Loss 0.00378855546316\n",
      "Epoch 12::Minibatch 560::LR 0.0746153846154 --> Loss 0.00313260515531\n",
      "Epoch 12::Minibatch 561::LR 0.0746153846154 --> Loss 0.00278142094612\n",
      "Epoch 12::Minibatch 562::LR 0.0746153846154 --> Loss 0.00241195817788\n",
      "Epoch 12::Minibatch 563::LR 0.0746153846154 --> Loss 0.0040440316995\n",
      "Epoch 12::Minibatch 564::LR 0.0746153846154 --> Loss 0.00316600203514\n",
      "Epoch 12::Minibatch 565::LR 0.0746153846154 --> Loss 0.00375565012296\n",
      "Epoch 12::Minibatch 566::LR 0.0746153846154 --> Loss 0.00234373788039\n",
      "Epoch 12::Minibatch 567::LR 0.0746153846154 --> Loss 0.00263283908367\n",
      "Epoch 12::Minibatch 568::LR 0.0746153846154 --> Loss 0.00185433824857\n",
      "Epoch 12::Minibatch 569::LR 0.0746153846154 --> Loss 0.000576638082663\n",
      "Epoch 12::Minibatch 570::LR 0.0746153846154 --> Loss 0.00174868265788\n",
      "Epoch 12::Minibatch 571::LR 0.0746153846154 --> Loss 0.00229808330536\n",
      "Epoch 12::Minibatch 572::LR 0.0746153846154 --> Loss 0.00243649542332\n",
      "Epoch 12::Minibatch 573::LR 0.0746153846154 --> Loss 0.00154310435057\n",
      "Epoch 12::Minibatch 574::LR 0.0746153846154 --> Loss 0.0010596310099\n",
      "Epoch 12::Minibatch 575::LR 0.0746153846154 --> Loss 0.00182201961676\n",
      "Epoch 12::Minibatch 576::LR 0.0746153846154 --> Loss 0.00217533727487\n",
      "Epoch 12::Minibatch 577::LR 0.0746153846154 --> Loss 0.00170187354088\n",
      "Epoch 12::Minibatch 578::LR 0.0746153846154 --> Loss 0.00130684663852\n",
      "Epoch 12::Minibatch 579::LR 0.0746153846154 --> Loss 0.00121892511845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 580::LR 0.0746153846154 --> Loss 0.00197540819645\n",
      "Epoch 12::Minibatch 581::LR 0.0746153846154 --> Loss 0.00173389792442\n",
      "Epoch 12::Minibatch 582::LR 0.0746153846154 --> Loss 0.00413503448168\n",
      "Epoch 12::Minibatch 583::LR 0.0746153846154 --> Loss 0.000951498448849\n",
      "Epoch 12::Minibatch 584::LR 0.0746153846154 --> Loss 0.00132123380899\n",
      "Epoch 12::Minibatch 585::LR 0.0746153846154 --> Loss 0.00477950890859\n",
      "Epoch 12::Minibatch 586::LR 0.0746153846154 --> Loss 0.00414677302043\n",
      "Epoch 12::Minibatch 587::LR 0.0746153846154 --> Loss 0.00114869554838\n",
      "Epoch 12::Minibatch 588::LR 0.0746153846154 --> Loss 0.00143689771493\n",
      "Epoch 12::Minibatch 589::LR 0.0746153846154 --> Loss 0.00278186003367\n",
      "Epoch 12::Minibatch 590::LR 0.0746153846154 --> Loss 0.00203519841035\n",
      "Epoch 12::Minibatch 591::LR 0.0746153846154 --> Loss 0.00320554991563\n",
      "Epoch 12::Minibatch 592::LR 0.0746153846154 --> Loss 0.0011985818545\n",
      "Epoch 12::Minibatch 593::LR 0.0746153846154 --> Loss 0.00265063345432\n",
      "Epoch 12::Minibatch 594::LR 0.0746153846154 --> Loss 0.00283255120118\n",
      "Epoch 12::Minibatch 595::LR 0.0746153846154 --> Loss 0.00306435306867\n",
      "Epoch 12::Minibatch 596::LR 0.0746153846154 --> Loss 0.00199027121067\n",
      "Epoch 12::Minibatch 597::LR 0.0746153846154 --> Loss 0.00121144413948\n",
      "Epoch 12::Minibatch 598::LR 0.0746153846154 --> Loss 0.00312965969245\n",
      "Epoch 12::Minibatch 599::LR 0.0746153846154 --> Loss 0.00188953538736\n",
      "Epoch 12::Minibatch 600::LR 0.0746153846154 --> Loss 0.00226893663406\n",
      "Epoch 12::Minibatch 601::LR 0.0746153846154 --> Loss 0.00394747336706\n",
      "Epoch 12::Minibatch 602::LR 0.0746153846154 --> Loss 0.00214473068714\n",
      "Epoch 12::Minibatch 603::LR 0.0746153846154 --> Loss 0.00267257293065\n",
      "Epoch 12::Minibatch 604::LR 0.0746153846154 --> Loss 0.00166037559509\n",
      "Epoch 12::Minibatch 605::LR 0.0746153846154 --> Loss 0.00242074231307\n",
      "Epoch 12::Minibatch 606::LR 0.0746153846154 --> Loss 0.00195329606533\n",
      "Epoch 12::Minibatch 607::LR 0.0746153846154 --> Loss 0.000854399303595\n",
      "Epoch 12::Minibatch 608::LR 0.0746153846154 --> Loss 0.00161418964465\n",
      "Epoch 12::Minibatch 609::LR 0.0746153846154 --> Loss 0.00237566153208\n",
      "Epoch 12::Minibatch 610::LR 0.0746153846154 --> Loss 0.00404086550077\n",
      "Epoch 12::Minibatch 611::LR 0.0746153846154 --> Loss 0.00268702308337\n",
      "Epoch 12::Minibatch 612::LR 0.0746153846154 --> Loss 0.000507456362247\n",
      "Epoch 12::Minibatch 613::LR 0.0746153846154 --> Loss 0.00132013042768\n",
      "Epoch 12::Minibatch 614::LR 0.0746153846154 --> Loss 0.00250148733457\n",
      "Epoch 12::Minibatch 615::LR 0.0746153846154 --> Loss 0.00169985373815\n",
      "Epoch 12::Minibatch 616::LR 0.0746153846154 --> Loss 0.000937873323758\n",
      "Epoch 12::Minibatch 617::LR 0.0746153846154 --> Loss 0.000520674139261\n",
      "Epoch 12::Minibatch 618::LR 0.0746153846154 --> Loss 0.00272797008355\n",
      "Epoch 12::Minibatch 619::LR 0.0746153846154 --> Loss 0.00192882200082\n",
      "Epoch 12::Minibatch 620::LR 0.0746153846154 --> Loss 0.00174689014753\n",
      "Epoch 12::Minibatch 621::LR 0.0746153846154 --> Loss 0.000873481829961\n",
      "Epoch 12::Minibatch 622::LR 0.0746153846154 --> Loss 0.000825716207425\n",
      "Epoch 12::Minibatch 623::LR 0.0746153846154 --> Loss 0.00221680502097\n",
      "Epoch 12::Minibatch 624::LR 0.0746153846154 --> Loss 0.0018036309878\n",
      "Epoch 12::Minibatch 625::LR 0.0746153846154 --> Loss 0.00310729205608\n",
      "Epoch 12::Minibatch 626::LR 0.0746153846154 --> Loss 0.00479272842407\n",
      "Epoch 12::Minibatch 627::LR 0.0746153846154 --> Loss 0.00137369294961\n",
      "Epoch 12::Minibatch 628::LR 0.0746153846154 --> Loss 0.000935036937396\n",
      "Epoch 12::Minibatch 629::LR 0.0746153846154 --> Loss 0.00352396130562\n",
      "Epoch 12::Minibatch 630::LR 0.0746153846154 --> Loss 0.00340072949727\n",
      "Epoch 12::Minibatch 631::LR 0.0746153846154 --> Loss 0.00706398248672\n",
      "Epoch 12::Minibatch 632::LR 0.0746153846154 --> Loss 0.00081769362092\n",
      "Epoch 12::Minibatch 633::LR 0.0746153846154 --> Loss 0.00168954531352\n",
      "Epoch 12::Minibatch 634::LR 0.0746153846154 --> Loss 0.00328323483467\n",
      "Epoch 12::Minibatch 635::LR 0.0746153846154 --> Loss 0.00499851663907\n",
      "Epoch 12::Minibatch 636::LR 0.0746153846154 --> Loss 0.0054600083828\n",
      "Epoch 12::Minibatch 637::LR 0.0746153846154 --> Loss 0.000860106945038\n",
      "Epoch 12::Minibatch 638::LR 0.0746153846154 --> Loss 0.00157164146503\n",
      "Epoch 12::Minibatch 639::LR 0.0746153846154 --> Loss 0.00338190515836\n",
      "Epoch 12::Minibatch 640::LR 0.0746153846154 --> Loss 0.00511762698491\n",
      "Epoch 12::Minibatch 641::LR 0.0746153846154 --> Loss 0.00320051749547\n",
      "Epoch 12::Minibatch 642::LR 0.0746153846154 --> Loss 0.000582704494397\n",
      "Epoch 12::Minibatch 643::LR 0.0746153846154 --> Loss 0.00237984796365\n",
      "Epoch 12::Minibatch 644::LR 0.0746153846154 --> Loss 0.00405185739199\n",
      "Epoch 12::Minibatch 645::LR 0.0746153846154 --> Loss 0.00421876549721\n",
      "Epoch 12::Minibatch 646::LR 0.0746153846154 --> Loss 0.00156120667855\n",
      "Epoch 12::Minibatch 647::LR 0.0746153846154 --> Loss 0.000587985813618\n",
      "Epoch 12::Minibatch 648::LR 0.0746153846154 --> Loss 0.00306771079699\n",
      "Epoch 12::Minibatch 649::LR 0.0746153846154 --> Loss 0.00364512284597\n",
      "Epoch 12::Minibatch 650::LR 0.0746153846154 --> Loss 0.00338589509328\n",
      "Epoch 12::Minibatch 651::LR 0.0746153846154 --> Loss 0.00143386493127\n",
      "Epoch 12::Minibatch 652::LR 0.0746153846154 --> Loss 0.000859714845816\n",
      "Epoch 12::Minibatch 653::LR 0.0746153846154 --> Loss 0.00291127920151\n",
      "Epoch 12::Minibatch 654::LR 0.0746153846154 --> Loss 0.00312681953112\n",
      "Epoch 12::Minibatch 655::LR 0.0746153846154 --> Loss 0.00349646091461\n",
      "Epoch 12::Minibatch 656::LR 0.0746153846154 --> Loss 0.000789284010728\n",
      "Epoch 12::Minibatch 657::LR 0.0746153846154 --> Loss 0.00222284714381\n",
      "Epoch 12::Minibatch 658::LR 0.0746153846154 --> Loss 0.00506684621175\n",
      "Epoch 12::Minibatch 659::LR 0.0746153846154 --> Loss 0.00237534423669\n",
      "Epoch 12::Minibatch 660::LR 0.0746153846154 --> Loss 0.00264039675395\n",
      "Epoch 12::Minibatch 661::LR 0.0746153846154 --> Loss 0.00259108801683\n",
      "Epoch 12::Minibatch 662::LR 0.0746153846154 --> Loss 0.00185492197673\n",
      "Epoch 12::Minibatch 663::LR 0.0746153846154 --> Loss 0.00368935743968\n",
      "Epoch 12::Minibatch 664::LR 0.0746153846154 --> Loss 0.0035224088033\n",
      "Epoch 12::Minibatch 665::LR 0.0746153846154 --> Loss 0.000774457703034\n",
      "Epoch 12::Minibatch 666::LR 0.0746153846154 --> Loss 0.00396629333496\n",
      "Epoch 12::Minibatch 667::LR 0.0746153846154 --> Loss 0.00257029096286\n",
      "Epoch 12::Minibatch 668::LR 0.0746153846154 --> Loss 0.00727164904277\n",
      "Epoch 12::Minibatch 669::LR 0.0746153846154 --> Loss 0.00110237717628\n",
      "Epoch 12::Minibatch 670::LR 0.0746153846154 --> Loss 0.00138364632924\n",
      "Epoch 12::Minibatch 671::LR 0.0746153846154 --> Loss 0.00549546678861\n",
      "Epoch 12::Minibatch 672::LR 0.0746153846154 --> Loss 0.00389759620031\n",
      "Epoch 12::Minibatch 673::LR 0.0746153846154 --> Loss 0.00163752684991\n",
      "Epoch 12::Minibatch 674::LR 0.0746153846154 --> Loss 0.000535462299983\n",
      "Epoch 12::Minibatch 675::LR 0.0746153846154 --> Loss 0.00220785816511\n",
      "Epoch 12::Minibatch 676::LR 0.0746153846154 --> Loss 0.00217332939307\n",
      "Epoch 12::Minibatch 677::LR 0.0746153846154 --> Loss 0.00287231127421\n",
      "Epoch 12::Minibatch 678::LR 0.0746153846154 --> Loss 0.00196511785189\n",
      "Epoch 12::Minibatch 679::LR 0.0746153846154 --> Loss 0.00360393007596\n",
      "Epoch 12::Minibatch 680::LR 0.0746153846154 --> Loss 0.00215685288111\n",
      "Epoch 12::Minibatch 681::LR 0.0746153846154 --> Loss 0.00246368467808\n",
      "Epoch 12::Minibatch 682::LR 0.0746153846154 --> Loss 0.000771576662858\n",
      "Epoch 12::Minibatch 683::LR 0.0746153846154 --> Loss 0.00243232727051\n",
      "Epoch 12::Minibatch 684::LR 0.0746153846154 --> Loss 0.00237569530805\n",
      "Epoch 12::Minibatch 685::LR 0.0746153846154 --> Loss 0.0029597568512\n",
      "Epoch 12::Minibatch 686::LR 0.0746153846154 --> Loss 0.00153918554386\n",
      "Epoch 12::Minibatch 687::LR 0.0746153846154 --> Loss 0.000851000050704\n",
      "Epoch 12::Minibatch 688::LR 0.0746153846154 --> Loss 0.00276064356168\n",
      "Epoch 12::Minibatch 689::LR 0.0746153846154 --> Loss 0.0025596221288\n",
      "Epoch 12::Minibatch 690::LR 0.0746153846154 --> Loss 0.00193470597267\n",
      "Epoch 12::Minibatch 691::LR 0.0746153846154 --> Loss 0.000667287657658\n",
      "Epoch 12::Minibatch 692::LR 0.0746153846154 --> Loss 0.0025037163496\n",
      "Epoch 12::Minibatch 693::LR 0.0746153846154 --> Loss 0.00257791161537\n",
      "Epoch 12::Minibatch 694::LR 0.0746153846154 --> Loss 0.00303296605746\n",
      "Epoch 12::Minibatch 695::LR 0.0746153846154 --> Loss 0.00172710021337\n",
      "Epoch 12::Minibatch 696::LR 0.0746153846154 --> Loss 0.00204411347707\n",
      "Epoch 12::Minibatch 697::LR 0.0746153846154 --> Loss 0.00141738067071\n",
      "Epoch 12::Minibatch 698::LR 0.0746153846154 --> Loss 0.00162525643905\n",
      "Epoch 12::Minibatch 699::LR 0.0746153846154 --> Loss 0.00387758692106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 700::LR 0.0746153846154 --> Loss 0.00271927595139\n",
      "Epoch 12::Minibatch 701::LR 0.0746153846154 --> Loss 0.0020263638099\n",
      "Epoch 12::Minibatch 702::LR 0.0746153846154 --> Loss 0.00167104283969\n",
      "Epoch 12::Minibatch 703::LR 0.0746153846154 --> Loss 0.00426529407501\n",
      "Epoch 12::Minibatch 704::LR 0.0746153846154 --> Loss 0.00180552681287\n",
      "Epoch 12::Minibatch 705::LR 0.0746153846154 --> Loss 0.00286297520002\n",
      "Epoch 12::Minibatch 706::LR 0.0746153846154 --> Loss 0.00224511166414\n",
      "Epoch 12::Minibatch 707::LR 0.0746153846154 --> Loss 0.00119844694932\n",
      "Epoch 12::Minibatch 708::LR 0.0746153846154 --> Loss 0.00174316684405\n",
      "Epoch 12::Minibatch 709::LR 0.0746153846154 --> Loss 0.00170797189077\n",
      "Epoch 12::Minibatch 710::LR 0.0746153846154 --> Loss 0.0025023941199\n",
      "Epoch 12::Minibatch 711::LR 0.0746153846154 --> Loss 0.00190973579884\n",
      "Epoch 12::Minibatch 712::LR 0.0746153846154 --> Loss 0.00132896025976\n",
      "Epoch 12::Minibatch 713::LR 0.0746153846154 --> Loss 0.00174348930518\n",
      "Epoch 12::Minibatch 714::LR 0.0746153846154 --> Loss 0.00272033631802\n",
      "Epoch 12::Minibatch 715::LR 0.0746153846154 --> Loss 0.00295870999495\n",
      "Epoch 12::Minibatch 716::LR 0.0746153846154 --> Loss 0.00160582184792\n",
      "Epoch 12::Minibatch 717::LR 0.0746153846154 --> Loss 0.00160540978114\n",
      "Epoch 12::Minibatch 718::LR 0.0746153846154 --> Loss 0.00126049975554\n",
      "Epoch 12::Minibatch 719::LR 0.0746153846154 --> Loss 0.00166169166565\n",
      "Epoch 12::Minibatch 720::LR 0.0746153846154 --> Loss 0.00252667089303\n",
      "Epoch 12::Minibatch 721::LR 0.0746153846154 --> Loss 0.000638605803251\n",
      "Epoch 12::Minibatch 722::LR 0.0746153846154 --> Loss 0.00488023797671\n",
      "Epoch 12::Minibatch 723::LR 0.0746153846154 --> Loss 0.00492567658424\n",
      "Epoch 12::Minibatch 724::LR 0.0746153846154 --> Loss 0.00097699423631\n",
      "Epoch 12::Minibatch 725::LR 0.0746153846154 --> Loss 0.00223910490672\n",
      "Epoch 12::Minibatch 726::LR 0.0746153846154 --> Loss 0.00490186731021\n",
      "Epoch 12::Minibatch 727::LR 0.0746153846154 --> Loss 0.00316609164079\n",
      "Epoch 12::Minibatch 728::LR 0.0746153846154 --> Loss 0.000657884627581\n",
      "Epoch 12::Minibatch 729::LR 0.0746153846154 --> Loss 0.000767344584068\n",
      "Epoch 12::Minibatch 730::LR 0.0746153846154 --> Loss 0.00271304666996\n",
      "Epoch 12::Minibatch 731::LR 0.0746153846154 --> Loss 0.0024640562137\n",
      "Epoch 12::Minibatch 732::LR 0.0746153846154 --> Loss 0.00226996600628\n",
      "Epoch 12::Minibatch 733::LR 0.0746153846154 --> Loss 0.000723776121934\n",
      "Epoch 12::Minibatch 734::LR 0.0746153846154 --> Loss 0.00177419463793\n",
      "Epoch 12::Minibatch 735::LR 0.0746153846154 --> Loss 0.00235665380955\n",
      "Epoch 12::Minibatch 736::LR 0.0746153846154 --> Loss 0.00345790108045\n",
      "Epoch 12::Minibatch 737::LR 0.0746153846154 --> Loss 0.00312086820602\n",
      "Epoch 12::Minibatch 738::LR 0.0746153846154 --> Loss 0.00167701224486\n",
      "Epoch 12::Minibatch 739::LR 0.0746153846154 --> Loss 0.00248030086358\n",
      "Epoch 12::Minibatch 740::LR 0.0746153846154 --> Loss 0.00382857759794\n",
      "Epoch 12::Minibatch 741::LR 0.0746153846154 --> Loss 0.00274935742219\n",
      "Epoch 12::Minibatch 742::LR 0.0746153846154 --> Loss 0.00212103625139\n",
      "Epoch 12::Minibatch 743::LR 0.0746153846154 --> Loss 0.00136351466179\n",
      "Epoch 12::Minibatch 744::LR 0.0746153846154 --> Loss 0.00180210590363\n",
      "Epoch 12::Minibatch 745::LR 0.0746153846154 --> Loss 0.00286399781704\n",
      "Epoch 12::Minibatch 746::LR 0.0746153846154 --> Loss 0.00302194515864\n",
      "Epoch 12::Minibatch 747::LR 0.0746153846154 --> Loss 0.00179799775283\n",
      "Epoch 12::Minibatch 748::LR 0.0746153846154 --> Loss 0.00065268745025\n",
      "Epoch 12::Minibatch 749::LR 0.0746153846154 --> Loss 0.00166184892257\n",
      "Epoch 12::Minibatch 750::LR 0.0746153846154 --> Loss 0.00248755892118\n",
      "Epoch 12::Minibatch 751::LR 0.0746153846154 --> Loss 0.00271219233672\n",
      "Epoch 12::Minibatch 752::LR 0.0746153846154 --> Loss 0.00114182899396\n",
      "Epoch 12::Minibatch 753::LR 0.0746153846154 --> Loss 0.00225109696388\n",
      "Epoch 12::Minibatch 754::LR 0.0746153846154 --> Loss 0.00239245295525\n",
      "Epoch 12::Minibatch 755::LR 0.0746153846154 --> Loss 0.00267258028189\n",
      "Epoch 12::Minibatch 756::LR 0.0746153846154 --> Loss 0.00139438182116\n",
      "Epoch 12::Minibatch 757::LR 0.0746153846154 --> Loss 0.000848340392113\n",
      "Epoch 12::Minibatch 758::LR 0.0746153846154 --> Loss 0.00162792364756\n",
      "Epoch 12::Minibatch 759::LR 0.0746153846154 --> Loss 0.00384547511737\n",
      "Epoch 12::Minibatch 760::LR 0.0746153846154 --> Loss 0.0030327351888\n",
      "Epoch 12::Minibatch 761::LR 0.0746153846154 --> Loss 0.00640278697014\n",
      "Epoch 12::Minibatch 762::LR 0.0746153846154 --> Loss 0.00381174047788\n",
      "Epoch 12::Minibatch 763::LR 0.0746153846154 --> Loss 0.00361413200696\n",
      "Epoch 12::Minibatch 764::LR 0.0746153846154 --> Loss 0.003259126544\n",
      "Epoch 12::Minibatch 765::LR 0.0746153846154 --> Loss 0.00134542028109\n",
      "Epoch 12::Minibatch 766::LR 0.0746153846154 --> Loss 0.00228669643402\n",
      "Epoch 12::Minibatch 767::LR 0.0746153846154 --> Loss 0.00506956537565\n",
      "Epoch 12::Minibatch 768::LR 0.0746153846154 --> Loss 0.00359512368838\n",
      "Epoch 12::Minibatch 769::LR 0.0746153846154 --> Loss 0.00192249715328\n",
      "Epoch 12::Minibatch 770::LR 0.0746153846154 --> Loss 0.00146545251211\n",
      "Epoch 12::Minibatch 771::LR 0.0746153846154 --> Loss 0.00379932403564\n",
      "Epoch 12::Minibatch 772::LR 0.0746153846154 --> Loss 0.0033684694767\n",
      "Epoch 12::Minibatch 773::LR 0.0746153846154 --> Loss 0.00313991069794\n",
      "Epoch 12::Minibatch 774::LR 0.0746153846154 --> Loss 0.00176584521929\n",
      "Epoch 12::Minibatch 775::LR 0.0746153846154 --> Loss 0.00407747308413\n",
      "Epoch 12::Minibatch 776::LR 0.0746153846154 --> Loss 0.00356394847234\n",
      "Epoch 12::Minibatch 777::LR 0.0746153846154 --> Loss 0.00782601992289\n",
      "Epoch 12::Minibatch 778::LR 0.0746153846154 --> Loss 0.0103515720367\n",
      "Epoch 12::Minibatch 779::LR 0.0746153846154 --> Loss 0.00216898898284\n",
      "Epoch 12::Minibatch 780::LR 0.0746153846154 --> Loss 0.00165633310874\n",
      "Epoch 12::Minibatch 781::LR 0.0746153846154 --> Loss 0.00353806296984\n",
      "Epoch 12::Minibatch 782::LR 0.0746153846154 --> Loss 0.00412170966466\n",
      "Epoch 12::Minibatch 783::LR 0.0746153846154 --> Loss 0.00234164019426\n",
      "Epoch 12::Minibatch 784::LR 0.0746153846154 --> Loss 0.000736412455638\n",
      "Epoch 12::Minibatch 785::LR 0.0746153846154 --> Loss 0.00375269492467\n",
      "Epoch 12::Minibatch 786::LR 0.0746153846154 --> Loss 0.00358516017596\n",
      "Epoch 12::Minibatch 787::LR 0.0746153846154 --> Loss 0.00281351864338\n",
      "Epoch 12::Minibatch 788::LR 0.0746153846154 --> Loss 0.00248774766922\n",
      "Epoch 12::Minibatch 789::LR 0.0746153846154 --> Loss 0.000755689293146\n",
      "Epoch 12::Minibatch 790::LR 0.0746153846154 --> Loss 0.00325588901838\n",
      "Epoch 12::Minibatch 791::LR 0.0746153846154 --> Loss 0.00372877955437\n",
      "Epoch 12::Minibatch 792::LR 0.0746153846154 --> Loss 0.00335772156715\n",
      "Epoch 12::Minibatch 793::LR 0.0746153846154 --> Loss 0.00189729809761\n",
      "Epoch 12::Minibatch 794::LR 0.0746153846154 --> Loss 0.00107732037703\n",
      "Epoch 12::Minibatch 795::LR 0.0746153846154 --> Loss 0.00322725991408\n",
      "Epoch 12::Minibatch 796::LR 0.0746153846154 --> Loss 0.00585299690564\n",
      "Epoch 12::Minibatch 797::LR 0.0746153846154 --> Loss 0.00797659476598\n",
      "Epoch 12::Minibatch 798::LR 0.0746153846154 --> Loss 0.00342469215393\n",
      "Epoch 12::Minibatch 799::LR 0.0746153846154 --> Loss 0.00245849688848\n",
      "Epoch 12::Minibatch 800::LR 0.0746153846154 --> Loss 0.00205525020758\n",
      "Epoch 12::Minibatch 801::LR 0.0746153846154 --> Loss 0.00417785644531\n",
      "Epoch 12::Minibatch 802::LR 0.0746153846154 --> Loss 0.00136959304412\n",
      "Epoch 12::Minibatch 803::LR 0.0746153846154 --> Loss 0.00282450576623\n",
      "Epoch 12::Minibatch 804::LR 0.0746153846154 --> Loss 0.0022338082393\n",
      "Epoch 12::Minibatch 805::LR 0.0746153846154 --> Loss 0.0023261431853\n",
      "Epoch 12::Minibatch 806::LR 0.0746153846154 --> Loss 0.00331975162029\n",
      "Epoch 12::Minibatch 807::LR 0.0746153846154 --> Loss 0.00305076897144\n",
      "Epoch 12::Minibatch 808::LR 0.0746153846154 --> Loss 0.00275542795658\n",
      "Epoch 12::Minibatch 809::LR 0.0746153846154 --> Loss 0.00404958844185\n",
      "Epoch 12::Minibatch 810::LR 0.0746153846154 --> Loss 0.00529489040375\n",
      "Epoch 12::Minibatch 811::LR 0.0746153846154 --> Loss 0.00497909108798\n",
      "Epoch 12::Minibatch 812::LR 0.0746153846154 --> Loss 0.00458391944567\n",
      "Epoch 12::Minibatch 813::LR 0.0746153846154 --> Loss 0.00394971847534\n",
      "Epoch 12::Minibatch 814::LR 0.0746153846154 --> Loss 0.00189750274022\n",
      "Epoch 12::Minibatch 815::LR 0.0746153846154 --> Loss 0.00393625537554\n",
      "Epoch 12::Minibatch 816::LR 0.0746153846154 --> Loss 0.0042167365551\n",
      "Epoch 12::Minibatch 817::LR 0.0746153846154 --> Loss 0.00546508669853\n",
      "Epoch 12::Minibatch 818::LR 0.0746153846154 --> Loss 0.00127007981141\n",
      "Epoch 12::Minibatch 819::LR 0.0746153846154 --> Loss 0.000687099993229\n",
      "Epoch 12::Minibatch 820::LR 0.0746153846154 --> Loss 0.00540682713191\n",
      "Epoch 12::Minibatch 821::LR 0.0746153846154 --> Loss 0.00320358633995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 822::LR 0.0746153846154 --> Loss 0.00378253698349\n",
      "Epoch 12::Minibatch 823::LR 0.0746153846154 --> Loss 0.00132716059685\n",
      "Epoch 12::Minibatch 824::LR 0.0746153846154 --> Loss 0.00141507407029\n",
      "Epoch 12::Minibatch 825::LR 0.0746153846154 --> Loss 0.00373439828555\n",
      "Epoch 12::Minibatch 826::LR 0.0746153846154 --> Loss 0.00386718074481\n",
      "Epoch 12::Minibatch 827::LR 0.0746153846154 --> Loss 0.00213303526243\n",
      "Epoch 12::Minibatch 828::LR 0.0746153846154 --> Loss 0.000582566062609\n",
      "Epoch 12::Minibatch 829::LR 0.0746153846154 --> Loss 0.00241428156694\n",
      "Epoch 12::Minibatch 830::LR 0.0746153846154 --> Loss 0.0044760509332\n",
      "Epoch 12::Minibatch 831::LR 0.0746153846154 --> Loss 0.00259799361229\n",
      "Epoch 12::Minibatch 832::LR 0.0746153846154 --> Loss 0.00228293597698\n",
      "Epoch 12::Minibatch 833::LR 0.0746153846154 --> Loss 0.00186574558417\n",
      "Epoch 12::Minibatch 834::LR 0.0746153846154 --> Loss 0.000786704222361\n",
      "Epoch 12::Minibatch 835::LR 0.0746153846154 --> Loss 0.00384576956431\n",
      "Epoch 12::Minibatch 836::LR 0.0746153846154 --> Loss 0.00375100374222\n",
      "Epoch 12::Minibatch 837::LR 0.0746153846154 --> Loss 0.00221223374208\n",
      "Epoch 12::Minibatch 838::LR 0.0746153846154 --> Loss 0.000639585852623\n",
      "Epoch 12::Minibatch 839::LR 0.0746153846154 --> Loss 0.00248081465562\n",
      "Epoch 12::Minibatch 840::LR 0.0746153846154 --> Loss 0.00293397764365\n",
      "Epoch 12::Minibatch 841::LR 0.0746153846154 --> Loss 0.00288948655128\n",
      "Epoch 12::Minibatch 842::LR 0.0746153846154 --> Loss 0.00211582283179\n",
      "Epoch 12::Minibatch 843::LR 0.0746153846154 --> Loss 0.00102242092292\n",
      "Epoch 12::Minibatch 844::LR 0.0746153846154 --> Loss 0.00151652812958\n",
      "Epoch 12::Minibatch 845::LR 0.0746153846154 --> Loss 0.00441272417704\n",
      "Epoch 12::Minibatch 846::LR 0.0746153846154 --> Loss 0.00169486006101\n",
      "Epoch 12::Minibatch 847::LR 0.0746153846154 --> Loss 0.002296312054\n",
      "Epoch 12::Minibatch 848::LR 0.0746153846154 --> Loss 0.00100246479114\n",
      "Epoch 12::Minibatch 849::LR 0.0746153846154 --> Loss 0.00186978121599\n",
      "Epoch 12::Minibatch 850::LR 0.0746153846154 --> Loss 0.003204322656\n",
      "Epoch 12::Minibatch 851::LR 0.0746153846154 --> Loss 0.00272903184096\n",
      "Epoch 12::Minibatch 852::LR 0.0746153846154 --> Loss 0.00107193579276\n",
      "Epoch 12::Minibatch 853::LR 0.0746153846154 --> Loss 0.00131900240978\n",
      "Epoch 12::Minibatch 854::LR 0.0746153846154 --> Loss 0.00258399685224\n",
      "Epoch 12::Minibatch 855::LR 0.0746153846154 --> Loss 0.00218911568324\n",
      "Epoch 12::Minibatch 856::LR 0.0746153846154 --> Loss 0.00180452545484\n",
      "Epoch 12::Minibatch 857::LR 0.0746153846154 --> Loss 0.00122670690219\n",
      "Epoch 12::Minibatch 858::LR 0.0746153846154 --> Loss 0.000605026086171\n",
      "Epoch 12::Minibatch 859::LR 0.0746153846154 --> Loss 0.00190557579199\n",
      "Epoch 12::Minibatch 860::LR 0.0746153846154 --> Loss 0.00123741219441\n",
      "Epoch 12::Minibatch 861::LR 0.0746153846154 --> Loss 0.000940436522166\n",
      "Epoch 12::Minibatch 862::LR 0.0746153846154 --> Loss 0.00364754756292\n",
      "Epoch 12::Minibatch 863::LR 0.0746153846154 --> Loss 0.00343217492104\n",
      "Epoch 12::Minibatch 864::LR 0.0746153846154 --> Loss 0.0029558634758\n",
      "Epoch 12::Minibatch 865::LR 0.0746153846154 --> Loss 0.000419275114934\n",
      "Epoch 12::Minibatch 866::LR 0.0746153846154 --> Loss 0.0021722928683\n",
      "Epoch 12::Minibatch 867::LR 0.0746153846154 --> Loss 0.00299441655477\n",
      "Epoch 12::Minibatch 868::LR 0.0746153846154 --> Loss 0.00247529188792\n",
      "Epoch 12::Minibatch 869::LR 0.0746153846154 --> Loss 0.00210468073686\n",
      "Epoch 12::Minibatch 870::LR 0.0746153846154 --> Loss 0.00362197518349\n",
      "Epoch 12::Minibatch 871::LR 0.0746153846154 --> Loss 0.00151394834121\n",
      "Epoch 12::Minibatch 872::LR 0.0746153846154 --> Loss 0.00230211039384\n",
      "Epoch 12::Minibatch 873::LR 0.0746153846154 --> Loss 0.002480062445\n",
      "Epoch 12::Minibatch 874::LR 0.0746153846154 --> Loss 0.00634560505549\n",
      "Epoch 12::Minibatch 875::LR 0.0746153846154 --> Loss 0.000507550189892\n",
      "Epoch 12::Minibatch 876::LR 0.0746153846154 --> Loss 0.00342706521352\n",
      "Epoch 12::Minibatch 877::LR 0.0746153846154 --> Loss 0.00786813656489\n",
      "Epoch 12::Minibatch 878::LR 0.0746153846154 --> Loss 0.00332086841265\n",
      "Epoch 12::Minibatch 879::LR 0.0746153846154 --> Loss 0.00412987112999\n",
      "Epoch 12::Minibatch 880::LR 0.0746153846154 --> Loss 0.00495103637377\n",
      "Epoch 12::Minibatch 881::LR 0.0746153846154 --> Loss 0.00433892528216\n",
      "Epoch 12::Minibatch 882::LR 0.0746153846154 --> Loss 0.0020074236393\n",
      "Epoch 12::Minibatch 883::LR 0.0746153846154 --> Loss 0.00339884797732\n",
      "Epoch 12::Minibatch 884::LR 0.0746153846154 --> Loss 0.00271247982979\n",
      "Epoch 12::Minibatch 885::LR 0.0746153846154 --> Loss 0.0025819247961\n",
      "Epoch 12::Minibatch 886::LR 0.0746153846154 --> Loss 0.000703117152055\n",
      "Epoch 12::Minibatch 887::LR 0.0746153846154 --> Loss 0.00547422329585\n",
      "Epoch 12::Minibatch 888::LR 0.0746153846154 --> Loss 0.00268290142218\n",
      "Epoch 12::Minibatch 889::LR 0.0746153846154 --> Loss 0.00318851470947\n",
      "Epoch 12::Minibatch 890::LR 0.0746153846154 --> Loss 0.00468029777209\n",
      "Epoch 12::Minibatch 891::LR 0.0746153846154 --> Loss 0.00206818123658\n",
      "Epoch 12::Minibatch 892::LR 0.0746153846154 --> Loss 0.000924693544706\n",
      "Epoch 12::Minibatch 893::LR 0.0746153846154 --> Loss 0.00254699885845\n",
      "Epoch 12::Minibatch 894::LR 0.0746153846154 --> Loss 0.00228206912676\n",
      "Epoch 12::Minibatch 895::LR 0.0746153846154 --> Loss 0.00253457844257\n",
      "Epoch 12::Minibatch 896::LR 0.0746153846154 --> Loss 0.00143408536911\n",
      "Epoch 12::Minibatch 897::LR 0.0746153846154 --> Loss 0.000763010780017\n",
      "Epoch 12::Minibatch 898::LR 0.0746153846154 --> Loss 0.00226802766323\n",
      "Epoch 12::Minibatch 899::LR 0.0746153846154 --> Loss 0.00251506427924\n",
      "Epoch 12::Minibatch 900::LR 0.0746153846154 --> Loss 0.00336312770844\n",
      "Epoch 12::Minibatch 901::LR 0.0746153846154 --> Loss 0.000621121277412\n",
      "Epoch 12::Minibatch 902::LR 0.0746153846154 --> Loss 0.00143764962753\n",
      "Epoch 12::Minibatch 903::LR 0.0746153846154 --> Loss 0.00272597769896\n",
      "Epoch 12::Minibatch 904::LR 0.0746153846154 --> Loss 0.00214508096377\n",
      "Epoch 12::Minibatch 905::LR 0.0746153846154 --> Loss 0.00146242469549\n",
      "Epoch 12::Minibatch 906::LR 0.0746153846154 --> Loss 0.00111090948184\n",
      "Epoch 12::Minibatch 907::LR 0.0746153846154 --> Loss 0.00160243262847\n",
      "Epoch 12::Minibatch 908::LR 0.0746153846154 --> Loss 0.00239212195079\n",
      "Epoch 12::Minibatch 909::LR 0.0746153846154 --> Loss 0.00218394994736\n",
      "Epoch 12::Minibatch 910::LR 0.0746153846154 --> Loss 0.000845682919025\n",
      "Epoch 12::Minibatch 911::LR 0.0746153846154 --> Loss 0.00124143660069\n",
      "Epoch 12::Minibatch 912::LR 0.0746153846154 --> Loss 0.00211931784948\n",
      "Epoch 12::Minibatch 913::LR 0.0746153846154 --> Loss 0.00222734649976\n",
      "Epoch 12::Minibatch 914::LR 0.0746153846154 --> Loss 0.00128016193708\n",
      "Epoch 12::Minibatch 915::LR 0.0746153846154 --> Loss 0.000499490400155\n",
      "Epoch 12::Minibatch 916::LR 0.0746153846154 --> Loss 0.00256208101908\n",
      "Epoch 12::Minibatch 917::LR 0.0746153846154 --> Loss 0.00404662489891\n",
      "Epoch 12::Minibatch 918::LR 0.0746153846154 --> Loss 0.0057855963707\n",
      "Epoch 12::Minibatch 919::LR 0.0746153846154 --> Loss 0.000737920304139\n",
      "Epoch 12::Minibatch 920::LR 0.0746153846154 --> Loss 0.0112064321836\n",
      "Epoch 12::Minibatch 921::LR 0.0746153846154 --> Loss 0.00295382539431\n",
      "Epoch 12::Minibatch 922::LR 0.0746153846154 --> Loss 0.00316865464052\n",
      "Epoch 12::Minibatch 923::LR 0.0746153846154 --> Loss 0.00164565612872\n",
      "Epoch 12::Minibatch 924::LR 0.0746153846154 --> Loss 0.00362382253011\n",
      "Epoch 12::Minibatch 925::LR 0.0746153846154 --> Loss 0.00265000124772\n",
      "Epoch 12::Minibatch 926::LR 0.0746153846154 --> Loss 0.00546837806702\n",
      "Epoch 12::Minibatch 927::LR 0.0746153846154 --> Loss 0.00857346932093\n",
      "Epoch 12::Minibatch 928::LR 0.0746153846154 --> Loss 0.00673513491948\n",
      "Epoch 12::Minibatch 929::LR 0.0746153846154 --> Loss 0.00763594706853\n",
      "Epoch 12::Minibatch 930::LR 0.0746153846154 --> Loss 0.00873027165731\n",
      "Epoch 12::Minibatch 931::LR 0.0746153846154 --> Loss 0.00376287221909\n",
      "Epoch 12::Minibatch 932::LR 0.0746153846154 --> Loss 0.00801782051722\n",
      "Epoch 12::Minibatch 933::LR 0.0746153846154 --> Loss 0.00397152105967\n",
      "Epoch 12::Minibatch 934::LR 0.0746153846154 --> Loss 0.00522483627001\n",
      "Epoch 12::Minibatch 935::LR 0.0746153846154 --> Loss 0.00716379404068\n",
      "Epoch 12::Minibatch 936::LR 0.0746153846154 --> Loss 0.00175099293391\n",
      "Epoch 12::Minibatch 937::LR 0.0746153846154 --> Loss 0.00374329328537\n",
      "Epoch 12::Minibatch 938::LR 0.0746153846154 --> Loss 0.00351571202278\n",
      "Epoch 12::Minibatch 939::LR 0.0746153846154 --> Loss 0.00355353196462\n",
      "Epoch 12::Minibatch 940::LR 0.0746153846154 --> Loss 0.00109174966812\n",
      "Epoch 12::Minibatch 941::LR 0.0746153846154 --> Loss 0.000897637804349\n",
      "Epoch 12::Minibatch 942::LR 0.0746153846154 --> Loss 0.00246610959371\n",
      "Epoch 12::Minibatch 943::LR 0.0746153846154 --> Loss 0.00317470808824\n",
      "Epoch 12::Minibatch 944::LR 0.0746153846154 --> Loss 0.00229856113593\n",
      "Epoch 12::Minibatch 945::LR 0.0746153846154 --> Loss 0.00135600745678\n",
      "Epoch 12::Minibatch 946::LR 0.0746153846154 --> Loss 0.00345540881157\n",
      "Epoch 12::Minibatch 947::LR 0.0746153846154 --> Loss 0.00304806530476\n",
      "Epoch 12::Minibatch 948::LR 0.0746153846154 --> Loss 0.00554196834564\n",
      "Epoch 12::Minibatch 949::LR 0.0746153846154 --> Loss 0.00197768092155\n",
      "Epoch 12::Minibatch 950::LR 0.0746153846154 --> Loss 0.000743529597918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12::Minibatch 951::LR 0.0746153846154 --> Loss 0.00341814120611\n",
      "Epoch 12::Minibatch 952::LR 0.0746153846154 --> Loss 0.00249276796977\n",
      "Epoch 12::Minibatch 953::LR 0.0746153846154 --> Loss 0.00138102581104\n",
      "Epoch 12::Minibatch 954::LR 0.0746153846154 --> Loss 0.000966504911582\n",
      "Epoch 12::Minibatch 955::LR 0.0746153846154 --> Loss 0.00257026970387\n",
      "Epoch 12::Minibatch 956::LR 0.0746153846154 --> Loss 0.00410071372986\n",
      "Epoch 12::Minibatch 957::LR 0.0746153846154 --> Loss 0.00194033463796\n",
      "Epoch 12::Minibatch 958::LR 0.0746153846154 --> Loss 0.00247525493304\n",
      "Epoch 12::Minibatch 959::LR 0.0746153846154 --> Loss 0.00307995080948\n",
      "Epoch 12::Minibatch 960::LR 0.0746153846154 --> Loss 0.00680566310883\n",
      "Epoch 12::Minibatch 961::LR 0.0746153846154 --> Loss 0.00346423427264\n",
      "Epoch 12::Minibatch 962::LR 0.0746153846154 --> Loss 0.00305169244607\n",
      "Epoch 12::Minibatch 963::LR 0.0746153846154 --> Loss 0.00106572965781\n",
      "Epoch 12::Minibatch 964::LR 0.0746153846154 --> Loss 0.00248492717743\n",
      "Epoch 12::Minibatch 965::LR 0.0746153846154 --> Loss 0.00791140635808\n",
      "Epoch 12::Minibatch 966::LR 0.0746153846154 --> Loss 0.00533515652021\n",
      "Epoch 12::Minibatch 967::LR 0.0746153846154 --> Loss 0.00179882407188\n",
      "Epoch 12::Minibatch 968::LR 0.0746153846154 --> Loss 0.00162324647109\n",
      "Epoch 12::Minibatch 969::LR 0.0746153846154 --> Loss 0.00715033372243\n",
      "Epoch 12::Minibatch 970::LR 0.0746153846154 --> Loss 0.00598069111506\n",
      "Epoch 12::Minibatch 971::LR 0.0746153846154 --> Loss 0.00354897379875\n",
      "Epoch 12::Minibatch 972::LR 0.0746153846154 --> Loss 0.00988866726557\n",
      "Epoch 12::Minibatch 973::LR 0.0746153846154 --> Loss 0.00904852231344\n",
      "Epoch 12::Minibatch 974::LR 0.0746153846154 --> Loss 0.00660638570786\n",
      "Epoch 12::Minibatch 975::LR 0.0746153846154 --> Loss 0.00475495258967\n",
      "Epoch 12::Minibatch 976::LR 0.0746153846154 --> Loss 0.0042741950353\n",
      "Epoch 12::Minibatch 977::LR 0.0746153846154 --> Loss 0.00430704315503\n",
      "Epoch 12::Minibatch 978::LR 0.0746153846154 --> Loss 0.00420310179392\n",
      "Epoch 12::Minibatch 979::LR 0.0746153846154 --> Loss 0.00417466044426\n",
      "Epoch 12::Minibatch 980::LR 0.0746153846154 --> Loss 0.00409967939059\n",
      "Epoch 12::Minibatch 981::LR 0.0746153846154 --> Loss 0.00533127943675\n",
      "Epoch 12::Minibatch 982::LR 0.0746153846154 --> Loss 0.00698272307714\n",
      "Epoch 12::Minibatch 983::LR 0.0746153846154 --> Loss 0.00313759287198\n",
      "Epoch 12::Minibatch 984::LR 0.0746153846154 --> Loss 0.00289352357388\n",
      "Epoch 12::Minibatch 985::LR 0.0746153846154 --> Loss 0.00453713019689\n",
      "Epoch 12::Minibatch 986::LR 0.0746153846154 --> Loss 0.00411000053088\n",
      "Epoch 12::Minibatch 987::LR 0.0746153846154 --> Loss 0.00444985747337\n",
      "Epoch 12::Minibatch 988::LR 0.0746153846154 --> Loss 0.00338537255923\n",
      "Epoch 12::Minibatch 989::LR 0.0746153846154 --> Loss 0.00343169728915\n",
      "Epoch 12::Minibatch 990::LR 0.0746153846154 --> Loss 0.00322071154912\n",
      "Epoch 12::Minibatch 991::LR 0.0746153846154 --> Loss 0.00169656614463\n",
      "Epoch 12::Minibatch 992::LR 0.0746153846154 --> Loss 0.00191842377186\n",
      "Epoch 12::Minibatch 993::LR 0.0746153846154 --> Loss 0.00339558164279\n",
      "Epoch 12::Minibatch 994::LR 0.0746153846154 --> Loss 0.00202574670315\n",
      "Epoch 12::Minibatch 995::LR 0.0746153846154 --> Loss 0.000860567589601\n",
      "Epoch 12::Minibatch 996::LR 0.0746153846154 --> Loss 0.00317821244399\n",
      "Epoch 12::Minibatch 997::LR 0.0746153846154 --> Loss 0.00212396740913\n",
      "Epoch 12::Minibatch 998::LR 0.0746153846154 --> Loss 0.00224805335204\n",
      "Epoch 12::Minibatch 999::LR 0.0746153846154 --> Loss 0.00182120621204\n",
      "Epoch 12::Minibatch 1000::LR 0.0746153846154 --> Loss 0.00216750522455\n",
      "Epoch 12::Minibatch 1001::LR 0.0746153846154 --> Loss 0.00175513267517\n",
      "Epoch 12::Minibatch 1002::LR 0.0746153846154 --> Loss 0.00274742643038\n",
      "Epoch 12::Minibatch 1003::LR 0.0746153846154 --> Loss 0.00368579705556\n",
      "Epoch 12::Minibatch 1004::LR 0.0746153846154 --> Loss 0.000994670192401\n",
      "Epoch 12::Minibatch 1005::LR 0.0746153846154 --> Loss 0.00397409558296\n",
      "Epoch 12::Minibatch 1006::LR 0.0746153846154 --> Loss 0.00252762218316\n",
      "Epoch 12::Minibatch 1007::LR 0.0746153846154 --> Loss 0.00291065295537\n",
      "Epoch 12::Minibatch 1008::LR 0.0746153846154 --> Loss 0.000938245157401\n",
      "Epoch 12::Minibatch 1009::LR 0.0746153846154 --> Loss 0.00181948204835\n",
      "Epoch 12::Minibatch 1010::LR 0.0746153846154 --> Loss 0.00166001826525\n",
      "Epoch 12::Minibatch 1011::LR 0.0746153846154 --> Loss 0.00377297441165\n",
      "Epoch 12::Minibatch 1012::LR 0.0746153846154 --> Loss 0.00195332189401\n",
      "Epoch 12::Minibatch 1013::LR 0.0746153846154 --> Loss 0.0046343990167\n",
      "Epoch 12::Minibatch 1014::LR 0.0746153846154 --> Loss 0.00432531793912\n",
      "Epoch 12::Minibatch 1015::LR 0.0746153846154 --> Loss 0.00171134213607\n",
      "Epoch 12::Minibatch 1016::LR 0.0746153846154 --> Loss 0.00517950216929\n",
      "Epoch 12::Minibatch 1017::LR 0.0746153846154 --> Loss 0.00360812822978\n",
      "Epoch 12::Minibatch 1018::LR 0.0746153846154 --> Loss 0.00318375885487\n",
      "Epoch 12::Minibatch 1019::LR 0.0746153846154 --> Loss 0.00231966773669\n",
      "Epoch 12::Minibatch 1020::LR 0.0746153846154 --> Loss 0.00230930785338\n",
      "Epoch 12::Minibatch 1021::LR 0.0746153846154 --> Loss 0.00227758646011\n",
      "Epoch 12::Minibatch 1022::LR 0.0746153846154 --> Loss 0.00176556626956\n",
      "Epoch 12::Minibatch 1023::LR 0.0746153846154 --> Loss 0.00140284121037\n",
      "Epoch 12::Minibatch 1024::LR 0.0746153846154 --> Loss 0.00134377996127\n",
      "Epoch 12::Minibatch 1025::LR 0.0746153846154 --> Loss 0.00151544511318\n",
      "Epoch 12::Minibatch 1026::LR 0.0746153846154 --> Loss 0.000925434331099\n",
      "Epoch 12::Minibatch 1027::LR 0.0746153846154 --> Loss 0.00110709319512\n",
      "Epoch 12::Minibatch 1028::LR 0.0746153846154 --> Loss 0.000851185321808\n",
      "Epoch 12::Minibatch 1029::LR 0.0746153846154 --> Loss 0.000822494477034\n",
      "Epoch 12::Minibatch 1030::LR 0.0746153846154 --> Loss 0.00101987153292\n",
      "Epoch 12::Minibatch 1031::LR 0.0746153846154 --> Loss 0.000811147292455\n",
      "Epoch 12::Minibatch 1032::LR 0.0746153846154 --> Loss 0.00081826304396\n",
      "Epoch 12::Minibatch 1033::LR 0.0746153846154 --> Loss 0.00068520506223\n",
      "Epoch 12::Minibatch 1034::LR 0.0746153846154 --> Loss 0.000685299138228\n",
      "Epoch 12::Minibatch 1035::LR 0.0746153846154 --> Loss 0.000503924985727\n",
      "Epoch 12::Minibatch 1036::LR 0.0746153846154 --> Loss 0.000405806005001\n",
      "Epoch 12::Minibatch 1037::LR 0.0746153846154 --> Loss 0.000594412932793\n",
      "Epoch 12::Minibatch 1038::LR 0.0746153846154 --> Loss 0.00133630394936\n",
      "Epoch 12::Minibatch 1039::LR 0.0746153846154 --> Loss 0.00108980685472\n",
      "Epoch 12::Minibatch 1040::LR 0.0746153846154 --> Loss 0.000471141934395\n",
      "Epoch 12::Minibatch 1041::LR 0.0746153846154 --> Loss 0.000629910777013\n",
      "Epoch 13::Minibatch 1::LR 0.0723076923077 --> Loss 0.0099781815211\n",
      "Epoch 13::Minibatch 2::LR 0.0723076923077 --> Loss 0.00601568142573\n",
      "Epoch 13::Minibatch 3::LR 0.0723076923077 --> Loss 0.00396992723147\n",
      "Epoch 13::Minibatch 4::LR 0.0723076923077 --> Loss 0.0042913154761\n",
      "Epoch 13::Minibatch 5::LR 0.0723076923077 --> Loss 0.0047168648243\n",
      "Epoch 13::Minibatch 6::LR 0.0723076923077 --> Loss 0.0024475868543\n",
      "Epoch 13::Minibatch 7::LR 0.0723076923077 --> Loss 0.00752564430237\n",
      "Epoch 13::Minibatch 8::LR 0.0723076923077 --> Loss 0.00739502112071\n",
      "Epoch 13::Minibatch 9::LR 0.0723076923077 --> Loss 0.00524580717087\n",
      "Epoch 13::Minibatch 10::LR 0.0723076923077 --> Loss 0.00284415602684\n",
      "Epoch 13::Minibatch 11::LR 0.0723076923077 --> Loss 0.00236136039098\n",
      "Epoch 13::Minibatch 12::LR 0.0723076923077 --> Loss 0.00340404272079\n",
      "Epoch 13::Minibatch 13::LR 0.0723076923077 --> Loss 0.00509400963783\n",
      "Epoch 13::Minibatch 14::LR 0.0723076923077 --> Loss 0.00500221649806\n",
      "Epoch 13::Minibatch 15::LR 0.0723076923077 --> Loss 0.00402230660121\n",
      "Epoch 13::Minibatch 16::LR 0.0723076923077 --> Loss 0.000871924658616\n",
      "Epoch 13::Minibatch 17::LR 0.0723076923077 --> Loss 0.00291133026282\n",
      "Epoch 13::Minibatch 18::LR 0.0723076923077 --> Loss 0.00245194037755\n",
      "Epoch 13::Minibatch 19::LR 0.0723076923077 --> Loss 0.0011634722352\n",
      "Epoch 13::Minibatch 20::LR 0.0723076923077 --> Loss 0.00162777413925\n",
      "Epoch 13::Minibatch 21::LR 0.0723076923077 --> Loss 0.00326668262482\n",
      "Epoch 13::Minibatch 22::LR 0.0723076923077 --> Loss 0.00234771748384\n",
      "Epoch 13::Minibatch 23::LR 0.0723076923077 --> Loss 0.00076182598869\n",
      "Epoch 13::Minibatch 24::LR 0.0723076923077 --> Loss 0.000353590870897\n",
      "Epoch 13::Minibatch 25::LR 0.0723076923077 --> Loss 0.00107259184122\n",
      "Epoch 13::Minibatch 26::LR 0.0723076923077 --> Loss 0.00127940853437\n",
      "Epoch 13::Minibatch 27::LR 0.0723076923077 --> Loss 0.000887993276119\n",
      "Epoch 13::Minibatch 28::LR 0.0723076923077 --> Loss 0.000361700008313\n",
      "Epoch 13::Minibatch 29::LR 0.0723076923077 --> Loss 0.000339842438698\n",
      "Epoch 13::Minibatch 30::LR 0.0723076923077 --> Loss 0.000818334917227\n",
      "Epoch 13::Minibatch 31::LR 0.0723076923077 --> Loss 0.00129398882389\n",
      "Epoch 13::Minibatch 32::LR 0.0723076923077 --> Loss 0.0012478150924\n",
      "Epoch 13::Minibatch 33::LR 0.0723076923077 --> Loss 0.000777351458867\n",
      "Epoch 13::Minibatch 34::LR 0.0723076923077 --> Loss 0.00242752154668\n",
      "Epoch 13::Minibatch 35::LR 0.0723076923077 --> Loss 0.00430384794871\n",
      "Epoch 13::Minibatch 36::LR 0.0723076923077 --> Loss 0.00221006294092\n",
      "Epoch 13::Minibatch 37::LR 0.0723076923077 --> Loss 0.000624512185653\n",
      "Epoch 13::Minibatch 38::LR 0.0723076923077 --> Loss 0.000777940948804\n",
      "Epoch 13::Minibatch 39::LR 0.0723076923077 --> Loss 0.00245066066583\n",
      "Epoch 13::Minibatch 40::LR 0.0723076923077 --> Loss 0.0037631436189\n",
      "Epoch 13::Minibatch 41::LR 0.0723076923077 --> Loss 0.00311212023099\n",
      "Epoch 13::Minibatch 42::LR 0.0723076923077 --> Loss 0.00625052014987\n",
      "Epoch 13::Minibatch 43::LR 0.0723076923077 --> Loss 0.00185783306758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 44::LR 0.0723076923077 --> Loss 0.00313897709052\n",
      "Epoch 13::Minibatch 45::LR 0.0723076923077 --> Loss 0.00256661693255\n",
      "Epoch 13::Minibatch 46::LR 0.0723076923077 --> Loss 0.00359434405963\n",
      "Epoch 13::Minibatch 47::LR 0.0723076923077 --> Loss 0.00490254759789\n",
      "Epoch 13::Minibatch 48::LR 0.0723076923077 --> Loss 0.0061851366361\n",
      "Epoch 13::Minibatch 49::LR 0.0723076923077 --> Loss 0.00629596789678\n",
      "Epoch 13::Minibatch 50::LR 0.0723076923077 --> Loss 0.00601310491562\n",
      "Epoch 13::Minibatch 51::LR 0.0723076923077 --> Loss 0.00840032498042\n",
      "Epoch 13::Minibatch 52::LR 0.0723076923077 --> Loss 0.00354330460231\n",
      "Epoch 13::Minibatch 53::LR 0.0723076923077 --> Loss 0.00351808627446\n",
      "Epoch 13::Minibatch 54::LR 0.0723076923077 --> Loss 0.00402965625127\n",
      "Epoch 13::Minibatch 55::LR 0.0723076923077 --> Loss 0.00100935091575\n",
      "Epoch 13::Minibatch 56::LR 0.0723076923077 --> Loss 0.0027611386776\n",
      "Epoch 13::Minibatch 57::LR 0.0723076923077 --> Loss 0.00606511751811\n",
      "Epoch 13::Minibatch 58::LR 0.0723076923077 --> Loss 0.00343466758728\n",
      "Epoch 13::Minibatch 59::LR 0.0723076923077 --> Loss 0.00266981502374\n",
      "Epoch 13::Minibatch 60::LR 0.0723076923077 --> Loss 0.00242720584075\n",
      "Epoch 13::Minibatch 61::LR 0.0723076923077 --> Loss 0.000962179998557\n",
      "Epoch 13::Minibatch 62::LR 0.0723076923077 --> Loss 0.00343815724055\n",
      "Epoch 13::Minibatch 63::LR 0.0723076923077 --> Loss 0.00223977108796\n",
      "Epoch 13::Minibatch 64::LR 0.0723076923077 --> Loss 0.000970077812672\n",
      "Epoch 13::Minibatch 65::LR 0.0723076923077 --> Loss 0.00244003315767\n",
      "Epoch 13::Minibatch 66::LR 0.0723076923077 --> Loss 0.00296866595745\n",
      "Epoch 13::Minibatch 67::LR 0.0723076923077 --> Loss 0.00286602636178\n",
      "Epoch 13::Minibatch 68::LR 0.0723076923077 --> Loss 0.00204926649729\n",
      "Epoch 13::Minibatch 69::LR 0.0723076923077 --> Loss 0.00409188548724\n",
      "Epoch 13::Minibatch 70::LR 0.0723076923077 --> Loss 0.00350145300229\n",
      "Epoch 13::Minibatch 71::LR 0.0723076923077 --> Loss 0.00238254785538\n",
      "Epoch 13::Minibatch 72::LR 0.0723076923077 --> Loss 0.000556176205476\n",
      "Epoch 13::Minibatch 73::LR 0.0723076923077 --> Loss 0.00401813745499\n",
      "Epoch 13::Minibatch 74::LR 0.0723076923077 --> Loss 0.00423085570335\n",
      "Epoch 13::Minibatch 75::LR 0.0723076923077 --> Loss 0.00261680563291\n",
      "Epoch 13::Minibatch 76::LR 0.0723076923077 --> Loss 0.000646444161733\n",
      "Epoch 13::Minibatch 77::LR 0.0723076923077 --> Loss 0.00426006237666\n",
      "Epoch 13::Minibatch 78::LR 0.0723076923077 --> Loss 0.00392050464948\n",
      "Epoch 13::Minibatch 79::LR 0.0723076923077 --> Loss 0.00211585521698\n",
      "Epoch 13::Minibatch 80::LR 0.0723076923077 --> Loss 0.00344598213832\n",
      "Epoch 13::Minibatch 81::LR 0.0723076923077 --> Loss 0.00297896663348\n",
      "Epoch 13::Minibatch 82::LR 0.0723076923077 --> Loss 0.00207336544991\n",
      "Epoch 13::Minibatch 83::LR 0.0723076923077 --> Loss 0.00498645742734\n",
      "Epoch 13::Minibatch 84::LR 0.0723076923077 --> Loss 0.00209477504094\n",
      "Epoch 13::Minibatch 85::LR 0.0723076923077 --> Loss 0.00288615206877\n",
      "Epoch 13::Minibatch 86::LR 0.0723076923077 --> Loss 0.00233368953069\n",
      "Epoch 13::Minibatch 87::LR 0.0723076923077 --> Loss 0.00261243283749\n",
      "Epoch 13::Minibatch 88::LR 0.0723076923077 --> Loss 0.00190246701241\n",
      "Epoch 13::Minibatch 89::LR 0.0723076923077 --> Loss 0.00242037157218\n",
      "Epoch 13::Minibatch 90::LR 0.0723076923077 --> Loss 0.00124388982852\n",
      "Epoch 13::Minibatch 91::LR 0.0723076923077 --> Loss 0.0010051219662\n",
      "Epoch 13::Minibatch 92::LR 0.0723076923077 --> Loss 0.00276220778624\n",
      "Epoch 13::Minibatch 93::LR 0.0723076923077 --> Loss 0.00184054950873\n",
      "Epoch 13::Minibatch 94::LR 0.0723076923077 --> Loss 0.00182170669238\n",
      "Epoch 13::Minibatch 95::LR 0.0723076923077 --> Loss 0.00178865373135\n",
      "Epoch 13::Minibatch 96::LR 0.0723076923077 --> Loss 0.0061696267128\n",
      "Epoch 13::Minibatch 97::LR 0.0723076923077 --> Loss 0.00326455175877\n",
      "Epoch 13::Minibatch 98::LR 0.0723076923077 --> Loss 0.00097020427386\n",
      "Epoch 13::Minibatch 99::LR 0.0723076923077 --> Loss 0.00130034834146\n",
      "Epoch 13::Minibatch 100::LR 0.0723076923077 --> Loss 0.00548304994901\n",
      "Epoch 13::Minibatch 101::LR 0.0723076923077 --> Loss 0.000971207122008\n",
      "Epoch 13::Minibatch 102::LR 0.0723076923077 --> Loss 0.00386564215024\n",
      "Epoch 13::Minibatch 103::LR 0.0723076923077 --> Loss 0.0040550049146\n",
      "Epoch 13::Minibatch 104::LR 0.0723076923077 --> Loss 0.00284125208855\n",
      "Epoch 13::Minibatch 105::LR 0.0723076923077 --> Loss 0.00303617954254\n",
      "Epoch 13::Minibatch 106::LR 0.0723076923077 --> Loss 0.0189881086349\n",
      "Epoch 13::Minibatch 107::LR 0.0723076923077 --> Loss 0.00491987228394\n",
      "Epoch 13::Minibatch 108::LR 0.0723076923077 --> Loss 0.00116631726424\n",
      "Epoch 13::Minibatch 109::LR 0.0723076923077 --> Loss 0.00451281189919\n",
      "Epoch 13::Minibatch 110::LR 0.0723076923077 --> Loss 0.0025442691644\n",
      "Epoch 13::Minibatch 111::LR 0.0723076923077 --> Loss 0.0010770552357\n",
      "Epoch 13::Minibatch 112::LR 0.0723076923077 --> Loss 0.00373236179352\n",
      "Epoch 13::Minibatch 113::LR 0.0723076923077 --> Loss 0.00284344712893\n",
      "Epoch 13::Minibatch 114::LR 0.0723076923077 --> Loss 0.00158757090569\n",
      "Epoch 13::Minibatch 115::LR 0.0723076923077 --> Loss 0.00146141091983\n",
      "Epoch 13::Minibatch 116::LR 0.0723076923077 --> Loss 0.00293833593527\n",
      "Epoch 13::Minibatch 117::LR 0.0723076923077 --> Loss 0.00381106336912\n",
      "Epoch 13::Minibatch 118::LR 0.0723076923077 --> Loss 0.00705232381821\n",
      "Epoch 13::Minibatch 119::LR 0.0723076923077 --> Loss 0.000752697487672\n",
      "Epoch 13::Minibatch 120::LR 0.0723076923077 --> Loss 0.00194647610188\n",
      "Epoch 13::Minibatch 121::LR 0.0723076923077 --> Loss 0.00288204133511\n",
      "Epoch 13::Minibatch 122::LR 0.0723076923077 --> Loss 0.00375322699547\n",
      "Epoch 13::Minibatch 123::LR 0.0723076923077 --> Loss 0.00123110602299\n",
      "Epoch 13::Minibatch 124::LR 0.0723076923077 --> Loss 0.00292757670085\n",
      "Epoch 13::Minibatch 125::LR 0.0723076923077 --> Loss 0.00478354493777\n",
      "Epoch 13::Minibatch 126::LR 0.0723076923077 --> Loss 0.00286112864812\n",
      "Epoch 13::Minibatch 127::LR 0.0723076923077 --> Loss 0.00451182524363\n",
      "Epoch 13::Minibatch 128::LR 0.0723076923077 --> Loss 0.00369950135549\n",
      "Epoch 13::Minibatch 129::LR 0.0723076923077 --> Loss 0.00286224424839\n",
      "Epoch 13::Minibatch 130::LR 0.0723076923077 --> Loss 0.00438357671102\n",
      "Epoch 13::Minibatch 131::LR 0.0723076923077 --> Loss 0.00187856177489\n",
      "Epoch 13::Minibatch 132::LR 0.0723076923077 --> Loss 0.00324023127556\n",
      "Epoch 13::Minibatch 133::LR 0.0723076923077 --> Loss 0.00309842189153\n",
      "Epoch 13::Minibatch 134::LR 0.0723076923077 --> Loss 0.0025280302763\n",
      "Epoch 13::Minibatch 135::LR 0.0723076923077 --> Loss 0.00173903882504\n",
      "Epoch 13::Minibatch 136::LR 0.0723076923077 --> Loss 0.00285489698251\n",
      "Epoch 13::Minibatch 137::LR 0.0723076923077 --> Loss 0.00378848830859\n",
      "Epoch 13::Minibatch 138::LR 0.0723076923077 --> Loss 0.00137428164482\n",
      "Epoch 13::Minibatch 139::LR 0.0723076923077 --> Loss 0.00193855245908\n",
      "Epoch 13::Minibatch 140::LR 0.0723076923077 --> Loss 0.00249928673108\n",
      "Epoch 13::Minibatch 141::LR 0.0723076923077 --> Loss 0.0030300650994\n",
      "Epoch 13::Minibatch 142::LR 0.0723076923077 --> Loss 0.00306082586447\n",
      "Epoch 13::Minibatch 143::LR 0.0723076923077 --> Loss 0.00064865420262\n",
      "Epoch 13::Minibatch 144::LR 0.0723076923077 --> Loss 0.00321944594383\n",
      "Epoch 13::Minibatch 145::LR 0.0723076923077 --> Loss 0.0043941283226\n",
      "Epoch 13::Minibatch 146::LR 0.0723076923077 --> Loss 0.00266250550747\n",
      "Epoch 13::Minibatch 147::LR 0.0723076923077 --> Loss 0.00185133039951\n",
      "Epoch 13::Minibatch 148::LR 0.0723076923077 --> Loss 0.00104678153992\n",
      "Epoch 13::Minibatch 149::LR 0.0723076923077 --> Loss 0.00286219437917\n",
      "Epoch 13::Minibatch 150::LR 0.0723076923077 --> Loss 0.00278766771158\n",
      "Epoch 13::Minibatch 151::LR 0.0723076923077 --> Loss 0.00427871823311\n",
      "Epoch 13::Minibatch 152::LR 0.0723076923077 --> Loss 0.000948242843151\n",
      "Epoch 13::Minibatch 153::LR 0.0723076923077 --> Loss 0.00190379559994\n",
      "Epoch 13::Minibatch 154::LR 0.0723076923077 --> Loss 0.00209565639496\n",
      "Epoch 13::Minibatch 155::LR 0.0723076923077 --> Loss 0.00473984201749\n",
      "Epoch 13::Minibatch 156::LR 0.0723076923077 --> Loss 0.0024462689956\n",
      "Epoch 13::Minibatch 157::LR 0.0723076923077 --> Loss 0.00071450556318\n",
      "Epoch 13::Minibatch 158::LR 0.0723076923077 --> Loss 0.00310243825118\n",
      "Epoch 13::Minibatch 159::LR 0.0723076923077 --> Loss 0.00279954910278\n",
      "Epoch 13::Minibatch 160::LR 0.0723076923077 --> Loss 0.00268380324046\n",
      "Epoch 13::Minibatch 161::LR 0.0723076923077 --> Loss 0.00104605386655\n",
      "Epoch 13::Minibatch 162::LR 0.0723076923077 --> Loss 0.00369602521261\n",
      "Epoch 13::Minibatch 163::LR 0.0723076923077 --> Loss 0.00243949989478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 164::LR 0.0723076923077 --> Loss 0.0025177504619\n",
      "Epoch 13::Minibatch 165::LR 0.0723076923077 --> Loss 0.000552814553181\n",
      "Epoch 13::Minibatch 166::LR 0.0723076923077 --> Loss 0.00183426976204\n",
      "Epoch 13::Minibatch 167::LR 0.0723076923077 --> Loss 0.00248294532299\n",
      "Epoch 13::Minibatch 168::LR 0.0723076923077 --> Loss 0.00223141153653\n",
      "Epoch 13::Minibatch 169::LR 0.0723076923077 --> Loss 0.00103677928448\n",
      "Epoch 13::Minibatch 170::LR 0.0723076923077 --> Loss 0.00101068109274\n",
      "Epoch 13::Minibatch 171::LR 0.0723076923077 --> Loss 0.00254948119322\n",
      "Epoch 13::Minibatch 172::LR 0.0723076923077 --> Loss 0.00470132907232\n",
      "Epoch 13::Minibatch 173::LR 0.0723076923077 --> Loss 0.00198187232018\n",
      "Epoch 13::Minibatch 174::LR 0.0723076923077 --> Loss 0.00108133206765\n",
      "Epoch 13::Minibatch 175::LR 0.0723076923077 --> Loss 0.00231128096581\n",
      "Epoch 13::Minibatch 176::LR 0.0723076923077 --> Loss 0.00331627865632\n",
      "Epoch 13::Minibatch 177::LR 0.0723076923077 --> Loss 0.00477123220762\n",
      "Epoch 13::Minibatch 178::LR 0.0723076923077 --> Loss 0.0016776518027\n",
      "Epoch 13::Minibatch 179::LR 0.0723076923077 --> Loss 0.00138148595889\n",
      "Epoch 13::Minibatch 180::LR 0.0723076923077 --> Loss 0.00363593260447\n",
      "Epoch 13::Minibatch 181::LR 0.0723076923077 --> Loss 0.00337689797084\n",
      "Epoch 13::Minibatch 182::LR 0.0723076923077 --> Loss 0.000816467752059\n",
      "Epoch 13::Minibatch 183::LR 0.0723076923077 --> Loss 0.00172627429167\n",
      "Epoch 13::Minibatch 184::LR 0.0723076923077 --> Loss 0.00343947370847\n",
      "Epoch 13::Minibatch 185::LR 0.0723076923077 --> Loss 0.00286297043165\n",
      "Epoch 13::Minibatch 186::LR 0.0723076923077 --> Loss 0.00100391258796\n",
      "Epoch 13::Minibatch 187::LR 0.0723076923077 --> Loss 0.00125236233075\n",
      "Epoch 13::Minibatch 188::LR 0.0723076923077 --> Loss 0.00417616208394\n",
      "Epoch 13::Minibatch 189::LR 0.0723076923077 --> Loss 0.00457181652387\n",
      "Epoch 13::Minibatch 190::LR 0.0723076923077 --> Loss 0.00232996682326\n",
      "Epoch 13::Minibatch 191::LR 0.0723076923077 --> Loss 0.00050424699982\n",
      "Epoch 13::Minibatch 192::LR 0.0723076923077 --> Loss 0.00270144283772\n",
      "Epoch 13::Minibatch 193::LR 0.0723076923077 --> Loss 0.00252422451973\n",
      "Epoch 13::Minibatch 194::LR 0.0723076923077 --> Loss 0.00181465645631\n",
      "Epoch 13::Minibatch 195::LR 0.0723076923077 --> Loss 0.000395024021467\n",
      "Epoch 13::Minibatch 196::LR 0.0723076923077 --> Loss 0.00121370345354\n",
      "Epoch 13::Minibatch 197::LR 0.0723076923077 --> Loss 0.00282630085945\n",
      "Epoch 13::Minibatch 198::LR 0.0723076923077 --> Loss 0.00218893865744\n",
      "Epoch 13::Minibatch 199::LR 0.0723076923077 --> Loss 0.000291620766123\n",
      "Epoch 13::Minibatch 200::LR 0.0723076923077 --> Loss 0.00209748605887\n",
      "Epoch 13::Minibatch 201::LR 0.0723076923077 --> Loss 0.00197559595108\n",
      "Epoch 13::Minibatch 202::LR 0.0723076923077 --> Loss 0.00190945506096\n",
      "Epoch 13::Minibatch 203::LR 0.0723076923077 --> Loss 0.00181309322516\n",
      "Epoch 13::Minibatch 204::LR 0.0723076923077 --> Loss 0.0015234708786\n",
      "Epoch 13::Minibatch 205::LR 0.0723076923077 --> Loss 0.00224704404672\n",
      "Epoch 13::Minibatch 206::LR 0.0723076923077 --> Loss 0.00691114664078\n",
      "Epoch 13::Minibatch 207::LR 0.0723076923077 --> Loss 0.0014082339406\n",
      "Epoch 13::Minibatch 208::LR 0.0723076923077 --> Loss 0.00116421600183\n",
      "Epoch 13::Minibatch 209::LR 0.0723076923077 --> Loss 0.00214930474758\n",
      "Epoch 13::Minibatch 210::LR 0.0723076923077 --> Loss 0.00202877402306\n",
      "Epoch 13::Minibatch 211::LR 0.0723076923077 --> Loss 0.00215320686499\n",
      "Epoch 13::Minibatch 212::LR 0.0723076923077 --> Loss 0.00413468122482\n",
      "Epoch 13::Minibatch 213::LR 0.0723076923077 --> Loss 0.00610562284787\n",
      "Epoch 13::Minibatch 214::LR 0.0723076923077 --> Loss 0.00989676793416\n",
      "Epoch 13::Minibatch 215::LR 0.0723076923077 --> Loss 0.00144022017717\n",
      "Epoch 13::Minibatch 216::LR 0.0723076923077 --> Loss 0.00556961894035\n",
      "Epoch 13::Minibatch 217::LR 0.0723076923077 --> Loss 0.00615800499916\n",
      "Epoch 13::Minibatch 218::LR 0.0723076923077 --> Loss 0.00403640627861\n",
      "Epoch 13::Minibatch 219::LR 0.0723076923077 --> Loss 0.0039485402902\n",
      "Epoch 13::Minibatch 220::LR 0.0723076923077 --> Loss 0.00460242350896\n",
      "Epoch 13::Minibatch 221::LR 0.0723076923077 --> Loss 0.00430900375048\n",
      "Epoch 13::Minibatch 222::LR 0.0723076923077 --> Loss 0.00332680145899\n",
      "Epoch 13::Minibatch 223::LR 0.0723076923077 --> Loss 0.00145301769177\n",
      "Epoch 13::Minibatch 224::LR 0.0723076923077 --> Loss 0.00186039527257\n",
      "Epoch 13::Minibatch 225::LR 0.0723076923077 --> Loss 0.00715834458669\n",
      "Epoch 13::Minibatch 226::LR 0.0723076923077 --> Loss 0.00383721590042\n",
      "Epoch 13::Minibatch 227::LR 0.0723076923077 --> Loss 0.00172195335229\n",
      "Epoch 13::Minibatch 228::LR 0.0723076923077 --> Loss 0.000803168813388\n",
      "Epoch 13::Minibatch 229::LR 0.0723076923077 --> Loss 0.00488421837489\n",
      "Epoch 13::Minibatch 230::LR 0.0723076923077 --> Loss 0.00403351624807\n",
      "Epoch 13::Minibatch 231::LR 0.0723076923077 --> Loss 0.00265183607737\n",
      "Epoch 13::Minibatch 232::LR 0.0723076923077 --> Loss 0.00126985241969\n",
      "Epoch 13::Minibatch 233::LR 0.0723076923077 --> Loss 0.00242954293887\n",
      "Epoch 13::Minibatch 234::LR 0.0723076923077 --> Loss 0.0066097621123\n",
      "Epoch 13::Minibatch 235::LR 0.0723076923077 --> Loss 0.00464883764585\n",
      "Epoch 13::Minibatch 236::LR 0.0723076923077 --> Loss 0.00182233790557\n",
      "Epoch 13::Minibatch 237::LR 0.0723076923077 --> Loss 0.000736379822095\n",
      "Epoch 13::Minibatch 238::LR 0.0723076923077 --> Loss 0.0034398106734\n",
      "Epoch 13::Minibatch 239::LR 0.0723076923077 --> Loss 0.00297242542108\n",
      "Epoch 13::Minibatch 240::LR 0.0723076923077 --> Loss 0.00325921952724\n",
      "Epoch 13::Minibatch 241::LR 0.0723076923077 --> Loss 0.000804673681657\n",
      "Epoch 13::Minibatch 242::LR 0.0723076923077 --> Loss 0.00723063230515\n",
      "Epoch 13::Minibatch 243::LR 0.0723076923077 --> Loss 0.00362688779831\n",
      "Epoch 13::Minibatch 244::LR 0.0723076923077 --> Loss 0.00303566614787\n",
      "Epoch 13::Minibatch 245::LR 0.0723076923077 --> Loss 0.000514287849267\n",
      "Epoch 13::Minibatch 246::LR 0.0723076923077 --> Loss 0.00213598191738\n",
      "Epoch 13::Minibatch 247::LR 0.0723076923077 --> Loss 0.0138323847453\n",
      "Epoch 13::Minibatch 248::LR 0.0723076923077 --> Loss 0.00461596012115\n",
      "Epoch 13::Minibatch 249::LR 0.0723076923077 --> Loss 0.00291222830613\n",
      "Epoch 13::Minibatch 250::LR 0.0723076923077 --> Loss 0.00279418448607\n",
      "Epoch 13::Minibatch 251::LR 0.0723076923077 --> Loss 0.002642745773\n",
      "Epoch 13::Minibatch 252::LR 0.0723076923077 --> Loss 0.00190651317437\n",
      "Epoch 13::Minibatch 253::LR 0.0723076923077 --> Loss 0.00321717003981\n",
      "Epoch 13::Minibatch 254::LR 0.0723076923077 --> Loss 0.00534732262293\n",
      "Epoch 13::Minibatch 255::LR 0.0723076923077 --> Loss 0.00396237452825\n",
      "Epoch 13::Minibatch 256::LR 0.0723076923077 --> Loss 0.00177120447159\n",
      "Epoch 13::Minibatch 257::LR 0.0723076923077 --> Loss 0.00132565329472\n",
      "Epoch 13::Minibatch 258::LR 0.0723076923077 --> Loss 0.00366564114889\n",
      "Epoch 13::Minibatch 259::LR 0.0723076923077 --> Loss 0.00188625295957\n",
      "Epoch 13::Minibatch 260::LR 0.0723076923077 --> Loss 0.00193560103575\n",
      "Epoch 13::Minibatch 261::LR 0.0723076923077 --> Loss 0.00297225733598\n",
      "Epoch 13::Minibatch 262::LR 0.0723076923077 --> Loss 0.00199905176957\n",
      "Epoch 13::Minibatch 263::LR 0.0723076923077 --> Loss 0.00241647104422\n",
      "Epoch 13::Minibatch 264::LR 0.0723076923077 --> Loss 0.00368866920471\n",
      "Epoch 13::Minibatch 265::LR 0.0723076923077 --> Loss 0.010485804081\n",
      "Epoch 13::Minibatch 266::LR 0.0723076923077 --> Loss 0.00106730331977\n",
      "Epoch 13::Minibatch 267::LR 0.0723076923077 --> Loss 0.0102701767286\n",
      "Epoch 13::Minibatch 268::LR 0.0723076923077 --> Loss 0.00125726481279\n",
      "Epoch 13::Minibatch 269::LR 0.0723076923077 --> Loss 0.00361291329066\n",
      "Epoch 13::Minibatch 270::LR 0.0723076923077 --> Loss 0.00650445063909\n",
      "Epoch 13::Minibatch 271::LR 0.0723076923077 --> Loss 0.00282642781734\n",
      "Epoch 13::Minibatch 272::LR 0.0723076923077 --> Loss 0.00409734288851\n",
      "Epoch 13::Minibatch 273::LR 0.0723076923077 --> Loss 0.00176469743252\n",
      "Epoch 13::Minibatch 274::LR 0.0723076923077 --> Loss 0.00182713826497\n",
      "Epoch 13::Minibatch 275::LR 0.0723076923077 --> Loss 0.0027369560798\n",
      "Epoch 13::Minibatch 276::LR 0.0723076923077 --> Loss 0.00350676655769\n",
      "Epoch 13::Minibatch 277::LR 0.0723076923077 --> Loss 0.00105329066515\n",
      "Epoch 13::Minibatch 278::LR 0.0723076923077 --> Loss 0.0026692144076\n",
      "Epoch 13::Minibatch 279::LR 0.0723076923077 --> Loss 0.00247481803099\n",
      "Epoch 13::Minibatch 280::LR 0.0723076923077 --> Loss 0.00214503824711\n",
      "Epoch 13::Minibatch 281::LR 0.0723076923077 --> Loss 0.00135189414024\n",
      "Epoch 13::Minibatch 282::LR 0.0723076923077 --> Loss 0.00226998507977\n",
      "Epoch 13::Minibatch 283::LR 0.0723076923077 --> Loss 0.00223433434963\n",
      "Epoch 13::Minibatch 284::LR 0.0723076923077 --> Loss 0.00177691419919\n",
      "Epoch 13::Minibatch 285::LR 0.0723076923077 --> Loss 0.00124083439509\n",
      "Epoch 13::Minibatch 286::LR 0.0723076923077 --> Loss 0.00217248698076\n",
      "Epoch 13::Minibatch 287::LR 0.0723076923077 --> Loss 0.0020959152778\n",
      "Epoch 13::Minibatch 288::LR 0.0723076923077 --> Loss 0.00112812270721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 289::LR 0.0723076923077 --> Loss 0.00158282379309\n",
      "Epoch 13::Minibatch 290::LR 0.0723076923077 --> Loss 0.00195869465669\n",
      "Epoch 13::Minibatch 291::LR 0.0723076923077 --> Loss 0.00174493968487\n",
      "Epoch 13::Minibatch 292::LR 0.0723076923077 --> Loss 0.000618213415146\n",
      "Epoch 13::Minibatch 293::LR 0.0723076923077 --> Loss 0.00148441036542\n",
      "Epoch 13::Minibatch 294::LR 0.0723076923077 --> Loss 0.0015652736028\n",
      "Epoch 13::Minibatch 295::LR 0.0723076923077 --> Loss 0.00184896012147\n",
      "Epoch 13::Minibatch 296::LR 0.0723076923077 --> Loss 0.001595916152\n",
      "Epoch 13::Minibatch 297::LR 0.0723076923077 --> Loss 0.0013917846481\n",
      "Epoch 13::Minibatch 298::LR 0.0723076923077 --> Loss 0.00137039770683\n",
      "Epoch 13::Minibatch 299::LR 0.0723076923077 --> Loss 0.000801566640536\n",
      "Epoch 13::Minibatch 300::LR 0.0723076923077 --> Loss 0.00286076466242\n",
      "Epoch 13::Minibatch 301::LR 0.0723076923077 --> Loss 0.00277000566324\n",
      "Epoch 13::Minibatch 302::LR 0.0723076923077 --> Loss 0.00257270475229\n",
      "Epoch 13::Minibatch 303::LR 0.0723076923077 --> Loss 0.000877780119578\n",
      "Epoch 13::Minibatch 304::LR 0.0723076923077 --> Loss 0.00314526220163\n",
      "Epoch 13::Minibatch 305::LR 0.0723076923077 --> Loss 0.00169091959794\n",
      "Epoch 13::Minibatch 306::LR 0.0723076923077 --> Loss 0.000933477183183\n",
      "Epoch 13::Minibatch 307::LR 0.0723076923077 --> Loss 0.00247824966908\n",
      "Epoch 13::Minibatch 308::LR 0.0723076923077 --> Loss 0.00197769780954\n",
      "Epoch 13::Minibatch 309::LR 0.0723076923077 --> Loss 0.000995348393917\n",
      "Epoch 13::Minibatch 310::LR 0.0723076923077 --> Loss 0.00109430700541\n",
      "Epoch 13::Minibatch 311::LR 0.0723076923077 --> Loss 0.00168702026208\n",
      "Epoch 13::Minibatch 312::LR 0.0723076923077 --> Loss 0.00300896644592\n",
      "Epoch 13::Minibatch 313::LR 0.0723076923077 --> Loss 0.00241116424402\n",
      "Epoch 13::Minibatch 314::LR 0.0723076923077 --> Loss 0.00192252417405\n",
      "Epoch 13::Minibatch 315::LR 0.0723076923077 --> Loss 0.00099195698897\n",
      "Epoch 13::Minibatch 316::LR 0.0723076923077 --> Loss 0.00232925713062\n",
      "Epoch 13::Minibatch 317::LR 0.0723076923077 --> Loss 0.00155275374651\n",
      "Epoch 13::Minibatch 318::LR 0.0723076923077 --> Loss 0.00120737582445\n",
      "Epoch 13::Minibatch 319::LR 0.0723076923077 --> Loss 0.00229651967684\n",
      "Epoch 13::Minibatch 320::LR 0.0723076923077 --> Loss 0.00327124794324\n",
      "Epoch 13::Minibatch 321::LR 0.0723076923077 --> Loss 0.000878805220127\n",
      "Epoch 13::Minibatch 322::LR 0.0723076923077 --> Loss 0.00369680205981\n",
      "Epoch 13::Minibatch 323::LR 0.0723076923077 --> Loss 0.00358739217122\n",
      "Epoch 13::Minibatch 324::LR 0.0723076923077 --> Loss 0.00264113108317\n",
      "Epoch 13::Minibatch 325::LR 0.0723076923077 --> Loss 0.00242726763089\n",
      "Epoch 13::Minibatch 326::LR 0.0723076923077 --> Loss 0.00556143800418\n",
      "Epoch 13::Minibatch 327::LR 0.0723076923077 --> Loss 0.00228207111359\n",
      "Epoch 13::Minibatch 328::LR 0.0723076923077 --> Loss 0.00340108036995\n",
      "Epoch 13::Minibatch 329::LR 0.0723076923077 --> Loss 0.00125383794308\n",
      "Epoch 13::Minibatch 330::LR 0.0723076923077 --> Loss 0.00163065612316\n",
      "Epoch 13::Minibatch 331::LR 0.0723076923077 --> Loss 0.00257126808167\n",
      "Epoch 13::Minibatch 332::LR 0.0723076923077 --> Loss 0.00253285725911\n",
      "Epoch 13::Minibatch 333::LR 0.0723076923077 --> Loss 0.00147053658962\n",
      "Epoch 13::Minibatch 334::LR 0.0723076923077 --> Loss 0.00434976299604\n",
      "Epoch 13::Minibatch 335::LR 0.0723076923077 --> Loss 0.00190493881702\n",
      "Epoch 13::Minibatch 336::LR 0.0723076923077 --> Loss 0.00212485531966\n",
      "Epoch 13::Minibatch 337::LR 0.0723076923077 --> Loss 0.00337011138598\n",
      "Epoch 13::Minibatch 338::LR 0.0723076923077 --> Loss 0.00052282611529\n",
      "Epoch 13::Minibatch 339::LR 0.0723076923077 --> Loss 0.00332867821058\n",
      "Epoch 13::Minibatch 340::LR 0.0723076923077 --> Loss 0.00440495491028\n",
      "Epoch 13::Minibatch 341::LR 0.0723076923077 --> Loss 0.00504820903142\n",
      "Epoch 13::Minibatch 342::LR 0.0723076923077 --> Loss 0.00326163848241\n",
      "Epoch 13::Minibatch 343::LR 0.0723076923077 --> Loss 0.00173080344995\n",
      "Epoch 13::Minibatch 344::LR 0.0723076923077 --> Loss 0.00309953947862\n",
      "Epoch 13::Minibatch 345::LR 0.0723076923077 --> Loss 0.00435255050659\n",
      "Epoch 13::Minibatch 346::LR 0.0723076923077 --> Loss 0.00573740084966\n",
      "Epoch 13::Minibatch 347::LR 0.0723076923077 --> Loss 0.000887845953306\n",
      "Epoch 13::Minibatch 348::LR 0.0723076923077 --> Loss 0.00355926950773\n",
      "Epoch 13::Minibatch 349::LR 0.0723076923077 --> Loss 0.00352918068568\n",
      "Epoch 13::Minibatch 350::LR 0.0723076923077 --> Loss 0.00183228751024\n",
      "Epoch 13::Minibatch 351::LR 0.0723076923077 --> Loss 0.00356414119403\n",
      "Epoch 13::Minibatch 352::LR 0.0723076923077 --> Loss 0.00485515634219\n",
      "Epoch 13::Minibatch 353::LR 0.0723076923077 --> Loss 0.00356891194979\n",
      "Epoch 13::Minibatch 354::LR 0.0723076923077 --> Loss 0.00297212084134\n",
      "Epoch 13::Minibatch 355::LR 0.0723076923077 --> Loss 0.00618312239647\n",
      "Epoch 13::Minibatch 356::LR 0.0723076923077 --> Loss 0.00314783871174\n",
      "Epoch 13::Minibatch 357::LR 0.0723076923077 --> Loss 0.00117822865645\n",
      "Epoch 13::Minibatch 358::LR 0.0723076923077 --> Loss 0.00222770412763\n",
      "Epoch 13::Minibatch 359::LR 0.0723076923077 --> Loss 0.00276282648245\n",
      "Epoch 13::Minibatch 360::LR 0.0723076923077 --> Loss 0.0024702634414\n",
      "Epoch 13::Minibatch 361::LR 0.0723076923077 --> Loss 0.00246770401796\n",
      "Epoch 13::Minibatch 362::LR 0.0723076923077 --> Loss 0.00246974309285\n",
      "Epoch 13::Minibatch 363::LR 0.0723076923077 --> Loss 0.000689433564742\n",
      "Epoch 13::Minibatch 364::LR 0.0723076923077 --> Loss 0.00203302105268\n",
      "Epoch 13::Minibatch 365::LR 0.0723076923077 --> Loss 0.0021304577589\n",
      "Epoch 13::Minibatch 366::LR 0.0723076923077 --> Loss 0.002295114398\n",
      "Epoch 13::Minibatch 367::LR 0.0723076923077 --> Loss 0.00112250546614\n",
      "Epoch 13::Minibatch 368::LR 0.0723076923077 --> Loss 0.00100789308548\n",
      "Epoch 13::Minibatch 369::LR 0.0723076923077 --> Loss 0.00290891508261\n",
      "Epoch 13::Minibatch 370::LR 0.0723076923077 --> Loss 0.00228566845258\n",
      "Epoch 13::Minibatch 371::LR 0.0723076923077 --> Loss 0.00189040005207\n",
      "Epoch 13::Minibatch 372::LR 0.0723076923077 --> Loss 0.000452141265074\n",
      "Epoch 13::Minibatch 373::LR 0.0723076923077 --> Loss 0.0017674857378\n",
      "Epoch 13::Minibatch 374::LR 0.0723076923077 --> Loss 0.00217260658741\n",
      "Epoch 13::Minibatch 375::LR 0.0723076923077 --> Loss 0.00184280872345\n",
      "Epoch 13::Minibatch 376::LR 0.0723076923077 --> Loss 0.00124972124894\n",
      "Epoch 13::Minibatch 377::LR 0.0723076923077 --> Loss 0.00196240365505\n",
      "Epoch 13::Minibatch 378::LR 0.0723076923077 --> Loss 0.00214001516501\n",
      "Epoch 13::Minibatch 379::LR 0.0723076923077 --> Loss 0.00239669859409\n",
      "Epoch 13::Minibatch 380::LR 0.0723076923077 --> Loss 0.00159883161386\n",
      "Epoch 13::Minibatch 381::LR 0.0723076923077 --> Loss 0.000991127490997\n",
      "Epoch 13::Minibatch 382::LR 0.0723076923077 --> Loss 0.00201571603616\n",
      "Epoch 13::Minibatch 383::LR 0.0723076923077 --> Loss 0.00195242842038\n",
      "Epoch 13::Minibatch 384::LR 0.0723076923077 --> Loss 0.00104921996593\n",
      "Epoch 13::Minibatch 385::LR 0.0723076923077 --> Loss 0.00104033013185\n",
      "Epoch 13::Minibatch 386::LR 0.0723076923077 --> Loss 0.00218421955903\n",
      "Epoch 13::Minibatch 387::LR 0.0723076923077 --> Loss 0.00233564237754\n",
      "Epoch 13::Minibatch 388::LR 0.0723076923077 --> Loss 0.00114661405484\n",
      "Epoch 13::Minibatch 389::LR 0.0723076923077 --> Loss 0.00182410418987\n",
      "Epoch 13::Minibatch 390::LR 0.0723076923077 --> Loss 0.00365153630575\n",
      "Epoch 13::Minibatch 391::LR 0.0723076923077 --> Loss 0.00272372682889\n",
      "Epoch 13::Minibatch 392::LR 0.0723076923077 --> Loss 0.00268059511979\n",
      "Epoch 13::Minibatch 393::LR 0.0723076923077 --> Loss 0.00279604156812\n",
      "Epoch 13::Minibatch 394::LR 0.0723076923077 --> Loss 0.00213463425636\n",
      "Epoch 13::Minibatch 395::LR 0.0723076923077 --> Loss 0.00205961783727\n",
      "Epoch 13::Minibatch 396::LR 0.0723076923077 --> Loss 0.00196321368217\n",
      "Epoch 13::Minibatch 397::LR 0.0723076923077 --> Loss 0.00209120313327\n",
      "Epoch 13::Minibatch 398::LR 0.0723076923077 --> Loss 0.00207192917665\n",
      "Epoch 13::Minibatch 399::LR 0.0723076923077 --> Loss 0.00236907422543\n",
      "Epoch 13::Minibatch 400::LR 0.0723076923077 --> Loss 0.00202534019947\n",
      "Epoch 13::Minibatch 401::LR 0.0723076923077 --> Loss 0.00355625430743\n",
      "Epoch 13::Minibatch 402::LR 0.0723076923077 --> Loss 0.0018953671058\n",
      "Epoch 13::Minibatch 403::LR 0.0723076923077 --> Loss 0.00148959100246\n",
      "Epoch 13::Minibatch 404::LR 0.0723076923077 --> Loss 0.00155515700579\n",
      "Epoch 13::Minibatch 405::LR 0.0723076923077 --> Loss 0.00359132329623\n",
      "Epoch 13::Minibatch 406::LR 0.0723076923077 --> Loss 0.00249557952086\n",
      "Epoch 13::Minibatch 407::LR 0.0723076923077 --> Loss 0.00176316082478\n",
      "Epoch 13::Minibatch 408::LR 0.0723076923077 --> Loss 0.00045900007089\n",
      "Epoch 13::Minibatch 409::LR 0.0723076923077 --> Loss 0.00241017103195\n",
      "Epoch 13::Minibatch 410::LR 0.0723076923077 --> Loss 0.00325745880604\n",
      "Epoch 13::Minibatch 411::LR 0.0723076923077 --> Loss 0.00164897382259\n",
      "Epoch 13::Minibatch 412::LR 0.0723076923077 --> Loss 0.00097742865483\n",
      "Epoch 13::Minibatch 413::LR 0.0723076923077 --> Loss 0.00199349542459\n",
      "Epoch 13::Minibatch 414::LR 0.0723076923077 --> Loss 0.00182525436083\n",
      "Epoch 13::Minibatch 415::LR 0.0723076923077 --> Loss 0.00114580571651\n",
      "Epoch 13::Minibatch 416::LR 0.0723076923077 --> Loss 0.000834458867709\n",
      "Epoch 13::Minibatch 417::LR 0.0723076923077 --> Loss 0.00171865324179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 418::LR 0.0723076923077 --> Loss 0.00286657810211\n",
      "Epoch 13::Minibatch 419::LR 0.0723076923077 --> Loss 0.000525165299575\n",
      "Epoch 13::Minibatch 420::LR 0.0723076923077 --> Loss 0.0007141127189\n",
      "Epoch 13::Minibatch 421::LR 0.0723076923077 --> Loss 0.00197094877561\n",
      "Epoch 13::Minibatch 422::LR 0.0723076923077 --> Loss 0.00221273859342\n",
      "Epoch 13::Minibatch 423::LR 0.0723076923077 --> Loss 0.000990797181924\n",
      "Epoch 13::Minibatch 424::LR 0.0723076923077 --> Loss 0.00158400734266\n",
      "Epoch 13::Minibatch 425::LR 0.0723076923077 --> Loss 0.00289815187454\n",
      "Epoch 13::Minibatch 426::LR 0.0723076923077 --> Loss 0.00202360530694\n",
      "Epoch 13::Minibatch 427::LR 0.0723076923077 --> Loss 0.000724945813417\n",
      "Epoch 13::Minibatch 428::LR 0.0723076923077 --> Loss 0.00109039366245\n",
      "Epoch 13::Minibatch 429::LR 0.0723076923077 --> Loss 0.00245789329211\n",
      "Epoch 13::Minibatch 430::LR 0.0723076923077 --> Loss 0.00957943598429\n",
      "Epoch 13::Minibatch 431::LR 0.0723076923077 --> Loss 0.00392663200696\n",
      "Epoch 13::Minibatch 432::LR 0.0723076923077 --> Loss 0.00452732205391\n",
      "Epoch 13::Minibatch 433::LR 0.0723076923077 --> Loss 0.00259137034416\n",
      "Epoch 13::Minibatch 434::LR 0.0723076923077 --> Loss 0.00256441056728\n",
      "Epoch 13::Minibatch 435::LR 0.0723076923077 --> Loss 0.00239245315393\n",
      "Epoch 13::Minibatch 436::LR 0.0723076923077 --> Loss 0.00175756275654\n",
      "Epoch 13::Minibatch 437::LR 0.0723076923077 --> Loss 0.00340015292168\n",
      "Epoch 13::Minibatch 438::LR 0.0723076923077 --> Loss 0.00269477228324\n",
      "Epoch 13::Minibatch 439::LR 0.0723076923077 --> Loss 0.0021597490708\n",
      "Epoch 13::Minibatch 440::LR 0.0723076923077 --> Loss 0.0032988746961\n",
      "Epoch 13::Minibatch 441::LR 0.0723076923077 --> Loss 0.00310607651869\n",
      "Epoch 13::Minibatch 442::LR 0.0723076923077 --> Loss 0.00284571011861\n",
      "Epoch 13::Minibatch 443::LR 0.0723076923077 --> Loss 0.003778039217\n",
      "Epoch 13::Minibatch 444::LR 0.0723076923077 --> Loss 0.00293880860011\n",
      "Epoch 13::Minibatch 445::LR 0.0723076923077 --> Loss 0.000914420187473\n",
      "Epoch 13::Minibatch 446::LR 0.0723076923077 --> Loss 0.0015072380503\n",
      "Epoch 13::Minibatch 447::LR 0.0723076923077 --> Loss 0.00247737288475\n",
      "Epoch 13::Minibatch 448::LR 0.0723076923077 --> Loss 0.00244692603747\n",
      "Epoch 13::Minibatch 449::LR 0.0723076923077 --> Loss 0.0037697939078\n",
      "Epoch 13::Minibatch 450::LR 0.0723076923077 --> Loss 0.00237396359444\n",
      "Epoch 13::Minibatch 451::LR 0.0723076923077 --> Loss 0.00410573919614\n",
      "Epoch 13::Minibatch 452::LR 0.0723076923077 --> Loss 0.0024094281594\n",
      "Epoch 13::Minibatch 453::LR 0.0723076923077 --> Loss 0.000398411651452\n",
      "Epoch 13::Minibatch 454::LR 0.0723076923077 --> Loss 0.00364491899808\n",
      "Epoch 13::Minibatch 455::LR 0.0723076923077 --> Loss 0.00273012797038\n",
      "Epoch 13::Minibatch 456::LR 0.0723076923077 --> Loss 0.00317851881186\n",
      "Epoch 13::Minibatch 457::LR 0.0723076923077 --> Loss 0.00199645698071\n",
      "Epoch 13::Minibatch 458::LR 0.0723076923077 --> Loss 0.000785397738218\n",
      "Epoch 13::Minibatch 459::LR 0.0723076923077 --> Loss 0.00421416481336\n",
      "Epoch 13::Minibatch 460::LR 0.0723076923077 --> Loss 0.0026563835144\n",
      "Epoch 13::Minibatch 461::LR 0.0723076923077 --> Loss 0.0039667348067\n",
      "Epoch 13::Minibatch 462::LR 0.0723076923077 --> Loss 0.000411792571346\n",
      "Epoch 13::Minibatch 463::LR 0.0723076923077 --> Loss 0.00466769536336\n",
      "Epoch 13::Minibatch 464::LR 0.0723076923077 --> Loss 0.00207369307677\n",
      "Epoch 13::Minibatch 465::LR 0.0723076923077 --> Loss 0.00537931839625\n",
      "Epoch 13::Minibatch 466::LR 0.0723076923077 --> Loss 0.00515138586362\n",
      "Epoch 13::Minibatch 467::LR 0.0723076923077 --> Loss 0.00598177194595\n",
      "Epoch 13::Minibatch 468::LR 0.0723076923077 --> Loss 0.00620027621587\n",
      "Epoch 13::Minibatch 469::LR 0.0723076923077 --> Loss 0.00676472345988\n",
      "Epoch 13::Minibatch 470::LR 0.0723076923077 --> Loss 0.00384188453356\n",
      "Epoch 13::Minibatch 471::LR 0.0723076923077 --> Loss 0.00177894532681\n",
      "Epoch 13::Minibatch 472::LR 0.0723076923077 --> Loss 0.00353348811467\n",
      "Epoch 13::Minibatch 473::LR 0.0723076923077 --> Loss 0.00222692489624\n",
      "Epoch 13::Minibatch 474::LR 0.0723076923077 --> Loss 0.000710559984048\n",
      "Epoch 13::Minibatch 475::LR 0.0723076923077 --> Loss 0.00494072993596\n",
      "Epoch 13::Minibatch 476::LR 0.0723076923077 --> Loss 0.00769027392069\n",
      "Epoch 13::Minibatch 477::LR 0.0723076923077 --> Loss 0.000948556562265\n",
      "Epoch 13::Minibatch 478::LR 0.0723076923077 --> Loss 0.0025065656503\n",
      "Epoch 13::Minibatch 479::LR 0.0723076923077 --> Loss 0.00195384542147\n",
      "Epoch 13::Minibatch 480::LR 0.0723076923077 --> Loss 0.00153174002965\n",
      "Epoch 13::Minibatch 481::LR 0.0723076923077 --> Loss 0.000962816079458\n",
      "Epoch 13::Minibatch 482::LR 0.0723076923077 --> Loss 0.00210204958916\n",
      "Epoch 13::Minibatch 483::LR 0.0723076923077 --> Loss 0.00325069804986\n",
      "Epoch 13::Minibatch 484::LR 0.0723076923077 --> Loss 0.00357697645823\n",
      "Epoch 13::Minibatch 485::LR 0.0723076923077 --> Loss 0.000760729312897\n",
      "Epoch 13::Minibatch 486::LR 0.0723076923077 --> Loss 0.00304016431173\n",
      "Epoch 13::Minibatch 487::LR 0.0723076923077 --> Loss 0.00341373165449\n",
      "Epoch 13::Minibatch 488::LR 0.0723076923077 --> Loss 0.00204954783122\n",
      "Epoch 13::Minibatch 489::LR 0.0723076923077 --> Loss 0.00323999901613\n",
      "Epoch 13::Minibatch 490::LR 0.0723076923077 --> Loss 0.000418584595124\n",
      "Epoch 13::Minibatch 491::LR 0.0723076923077 --> Loss 0.0039468840758\n",
      "Epoch 13::Minibatch 492::LR 0.0723076923077 --> Loss 0.00304254670938\n",
      "Epoch 13::Minibatch 493::LR 0.0723076923077 --> Loss 0.0030197228988\n",
      "Epoch 13::Minibatch 494::LR 0.0723076923077 --> Loss 0.000744921167692\n",
      "Epoch 13::Minibatch 495::LR 0.0723076923077 --> Loss 0.00190775553385\n",
      "Epoch 13::Minibatch 496::LR 0.0723076923077 --> Loss 0.00293770372868\n",
      "Epoch 13::Minibatch 497::LR 0.0723076923077 --> Loss 0.000944065153599\n",
      "Epoch 13::Minibatch 498::LR 0.0723076923077 --> Loss 0.000581543942293\n",
      "Epoch 13::Minibatch 499::LR 0.0723076923077 --> Loss 0.00374542792638\n",
      "Epoch 13::Minibatch 500::LR 0.0723076923077 --> Loss 0.00144852946202\n",
      "Epoch 13::Minibatch 501::LR 0.0723076923077 --> Loss 0.00227191666762\n",
      "Epoch 13::Minibatch 502::LR 0.0723076923077 --> Loss 0.00390663385391\n",
      "Epoch 13::Minibatch 503::LR 0.0723076923077 --> Loss 0.00898573080699\n",
      "Epoch 13::Minibatch 504::LR 0.0723076923077 --> Loss 0.00814322471619\n",
      "Epoch 13::Minibatch 505::LR 0.0723076923077 --> Loss 0.0043925456206\n",
      "Epoch 13::Minibatch 506::LR 0.0723076923077 --> Loss 0.0035108757019\n",
      "Epoch 13::Minibatch 507::LR 0.0723076923077 --> Loss 0.00607417583466\n",
      "Epoch 13::Minibatch 508::LR 0.0723076923077 --> Loss 0.0034098803997\n",
      "Epoch 13::Minibatch 509::LR 0.0723076923077 --> Loss 0.00467777212461\n",
      "Epoch 13::Minibatch 510::LR 0.0723076923077 --> Loss 0.00466494997342\n",
      "Epoch 13::Minibatch 511::LR 0.0723076923077 --> Loss 0.0038999525706\n",
      "Epoch 13::Minibatch 512::LR 0.0723076923077 --> Loss 0.00271552463373\n",
      "Epoch 13::Minibatch 513::LR 0.0723076923077 --> Loss 0.000701769093672\n",
      "Epoch 13::Minibatch 514::LR 0.0723076923077 --> Loss 0.0027155115207\n",
      "Epoch 13::Minibatch 515::LR 0.0723076923077 --> Loss 0.00302192012469\n",
      "Epoch 13::Minibatch 516::LR 0.0723076923077 --> Loss 0.00414470712344\n",
      "Epoch 13::Minibatch 517::LR 0.0723076923077 --> Loss 0.00346805612246\n",
      "Epoch 13::Minibatch 518::LR 0.0723076923077 --> Loss 0.00257939279079\n",
      "Epoch 13::Minibatch 519::LR 0.0723076923077 --> Loss 0.0034294227759\n",
      "Epoch 13::Minibatch 520::LR 0.0723076923077 --> Loss 0.00534068346024\n",
      "Epoch 13::Minibatch 521::LR 0.0723076923077 --> Loss 0.00554732322693\n",
      "Epoch 13::Minibatch 522::LR 0.0723076923077 --> Loss 0.00811209360758\n",
      "Epoch 13::Minibatch 523::LR 0.0723076923077 --> Loss 0.0006754809618\n",
      "Epoch 13::Minibatch 524::LR 0.0723076923077 --> Loss 0.00143796871106\n",
      "Epoch 13::Minibatch 525::LR 0.0723076923077 --> Loss 0.00327810307344\n",
      "Epoch 13::Minibatch 526::LR 0.0723076923077 --> Loss 0.00414676825205\n",
      "Epoch 13::Minibatch 527::LR 0.0723076923077 --> Loss 0.00238363365332\n",
      "Epoch 13::Minibatch 528::LR 0.0723076923077 --> Loss 0.00115408410629\n",
      "Epoch 13::Minibatch 529::LR 0.0723076923077 --> Loss 0.00422335068385\n",
      "Epoch 13::Minibatch 530::LR 0.0723076923077 --> Loss 0.00430807511012\n",
      "Epoch 13::Minibatch 531::LR 0.0723076923077 --> Loss 0.00376120487849\n",
      "Epoch 13::Minibatch 532::LR 0.0723076923077 --> Loss 0.00275396466255\n",
      "Epoch 13::Minibatch 533::LR 0.0723076923077 --> Loss 0.00503913283348\n",
      "Epoch 13::Minibatch 534::LR 0.0723076923077 --> Loss 0.00387761274974\n",
      "Epoch 13::Minibatch 535::LR 0.0723076923077 --> Loss 0.00327342192332\n",
      "Epoch 13::Minibatch 536::LR 0.0723076923077 --> Loss 0.00211272617181\n",
      "Epoch 13::Minibatch 537::LR 0.0723076923077 --> Loss 0.000663295537233\n",
      "Epoch 13::Minibatch 538::LR 0.0723076923077 --> Loss 0.00171340326468\n",
      "Epoch 13::Minibatch 539::LR 0.0723076923077 --> Loss 0.00345884958903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 540::LR 0.0723076923077 --> Loss 0.00342157681783\n",
      "Epoch 13::Minibatch 541::LR 0.0723076923077 --> Loss 0.00291844248772\n",
      "Epoch 13::Minibatch 542::LR 0.0723076923077 --> Loss 0.00256950894992\n",
      "Epoch 13::Minibatch 543::LR 0.0723076923077 --> Loss 0.0028007042408\n",
      "Epoch 13::Minibatch 544::LR 0.0723076923077 --> Loss 0.00392600893974\n",
      "Epoch 13::Minibatch 545::LR 0.0723076923077 --> Loss 0.00206410884857\n",
      "Epoch 13::Minibatch 546::LR 0.0723076923077 --> Loss 0.000663877129555\n",
      "Epoch 13::Minibatch 547::LR 0.0723076923077 --> Loss 0.00264793078105\n",
      "Epoch 13::Minibatch 548::LR 0.0723076923077 --> Loss 0.00384851654371\n",
      "Epoch 13::Minibatch 549::LR 0.0723076923077 --> Loss 0.00835117022196\n",
      "Epoch 13::Minibatch 550::LR 0.0723076923077 --> Loss 0.00117367774248\n",
      "Epoch 13::Minibatch 551::LR 0.0723076923077 --> Loss 0.00246652007103\n",
      "Epoch 13::Minibatch 552::LR 0.0723076923077 --> Loss 0.00361867467562\n",
      "Epoch 13::Minibatch 553::LR 0.0723076923077 --> Loss 0.00326762755712\n",
      "Epoch 13::Minibatch 554::LR 0.0723076923077 --> Loss 0.00380598187447\n",
      "Epoch 13::Minibatch 555::LR 0.0723076923077 --> Loss 0.000999986827374\n",
      "Epoch 13::Minibatch 556::LR 0.0723076923077 --> Loss 0.00203045288722\n",
      "Epoch 13::Minibatch 557::LR 0.0723076923077 --> Loss 0.00248887081941\n",
      "Epoch 13::Minibatch 558::LR 0.0723076923077 --> Loss 0.00385929028193\n",
      "Epoch 13::Minibatch 559::LR 0.0723076923077 --> Loss 0.00378137032191\n",
      "Epoch 13::Minibatch 560::LR 0.0723076923077 --> Loss 0.00317161202431\n",
      "Epoch 13::Minibatch 561::LR 0.0723076923077 --> Loss 0.00276143431664\n",
      "Epoch 13::Minibatch 562::LR 0.0723076923077 --> Loss 0.00240157047908\n",
      "Epoch 13::Minibatch 563::LR 0.0723076923077 --> Loss 0.00407837788264\n",
      "Epoch 13::Minibatch 564::LR 0.0723076923077 --> Loss 0.00316359937191\n",
      "Epoch 13::Minibatch 565::LR 0.0723076923077 --> Loss 0.00372575879097\n",
      "Epoch 13::Minibatch 566::LR 0.0723076923077 --> Loss 0.00232173999151\n",
      "Epoch 13::Minibatch 567::LR 0.0723076923077 --> Loss 0.00261318047841\n",
      "Epoch 13::Minibatch 568::LR 0.0723076923077 --> Loss 0.00183840314547\n",
      "Epoch 13::Minibatch 569::LR 0.0723076923077 --> Loss 0.00057033965985\n",
      "Epoch 13::Minibatch 570::LR 0.0723076923077 --> Loss 0.00172894179821\n",
      "Epoch 13::Minibatch 571::LR 0.0723076923077 --> Loss 0.00227193951607\n",
      "Epoch 13::Minibatch 572::LR 0.0723076923077 --> Loss 0.00241312603156\n",
      "Epoch 13::Minibatch 573::LR 0.0723076923077 --> Loss 0.00152675708135\n",
      "Epoch 13::Minibatch 574::LR 0.0723076923077 --> Loss 0.00105319221814\n",
      "Epoch 13::Minibatch 575::LR 0.0723076923077 --> Loss 0.00180418093999\n",
      "Epoch 13::Minibatch 576::LR 0.0723076923077 --> Loss 0.00215991377831\n",
      "Epoch 13::Minibatch 577::LR 0.0723076923077 --> Loss 0.00168488244216\n",
      "Epoch 13::Minibatch 578::LR 0.0723076923077 --> Loss 0.00129524320364\n",
      "Epoch 13::Minibatch 579::LR 0.0723076923077 --> Loss 0.00121070802212\n",
      "Epoch 13::Minibatch 580::LR 0.0723076923077 --> Loss 0.00195772349834\n",
      "Epoch 13::Minibatch 581::LR 0.0723076923077 --> Loss 0.00172491093477\n",
      "Epoch 13::Minibatch 582::LR 0.0723076923077 --> Loss 0.00412258466085\n",
      "Epoch 13::Minibatch 583::LR 0.0723076923077 --> Loss 0.00094498693943\n",
      "Epoch 13::Minibatch 584::LR 0.0723076923077 --> Loss 0.00131380567948\n",
      "Epoch 13::Minibatch 585::LR 0.0723076923077 --> Loss 0.00468340357145\n",
      "Epoch 13::Minibatch 586::LR 0.0723076923077 --> Loss 0.00409723639488\n",
      "Epoch 13::Minibatch 587::LR 0.0723076923077 --> Loss 0.00113937507073\n",
      "Epoch 13::Minibatch 588::LR 0.0723076923077 --> Loss 0.00142615169287\n",
      "Epoch 13::Minibatch 589::LR 0.0723076923077 --> Loss 0.00277234792709\n",
      "Epoch 13::Minibatch 590::LR 0.0723076923077 --> Loss 0.00201320767403\n",
      "Epoch 13::Minibatch 591::LR 0.0723076923077 --> Loss 0.00316103359063\n",
      "Epoch 13::Minibatch 592::LR 0.0723076923077 --> Loss 0.00119201759497\n",
      "Epoch 13::Minibatch 593::LR 0.0723076923077 --> Loss 0.00263539195061\n",
      "Epoch 13::Minibatch 594::LR 0.0723076923077 --> Loss 0.00281421820323\n",
      "Epoch 13::Minibatch 595::LR 0.0723076923077 --> Loss 0.00305840531985\n",
      "Epoch 13::Minibatch 596::LR 0.0723076923077 --> Loss 0.001962043643\n",
      "Epoch 13::Minibatch 597::LR 0.0723076923077 --> Loss 0.0012019059062\n",
      "Epoch 13::Minibatch 598::LR 0.0723076923077 --> Loss 0.00308038115501\n",
      "Epoch 13::Minibatch 599::LR 0.0723076923077 --> Loss 0.0018819663922\n",
      "Epoch 13::Minibatch 600::LR 0.0723076923077 --> Loss 0.00226251920064\n",
      "Epoch 13::Minibatch 601::LR 0.0723076923077 --> Loss 0.00393763343493\n",
      "Epoch 13::Minibatch 602::LR 0.0723076923077 --> Loss 0.0021370301644\n",
      "Epoch 13::Minibatch 603::LR 0.0723076923077 --> Loss 0.00266705274582\n",
      "Epoch 13::Minibatch 604::LR 0.0723076923077 --> Loss 0.00166010608276\n",
      "Epoch 13::Minibatch 605::LR 0.0723076923077 --> Loss 0.00241287569205\n",
      "Epoch 13::Minibatch 606::LR 0.0723076923077 --> Loss 0.00194499313831\n",
      "Epoch 13::Minibatch 607::LR 0.0723076923077 --> Loss 0.000852803885937\n",
      "Epoch 13::Minibatch 608::LR 0.0723076923077 --> Loss 0.00160556485256\n",
      "Epoch 13::Minibatch 609::LR 0.0723076923077 --> Loss 0.00237816492716\n",
      "Epoch 13::Minibatch 610::LR 0.0723076923077 --> Loss 0.00403856436412\n",
      "Epoch 13::Minibatch 611::LR 0.0723076923077 --> Loss 0.00267343223095\n",
      "Epoch 13::Minibatch 612::LR 0.0723076923077 --> Loss 0.000501120835543\n",
      "Epoch 13::Minibatch 613::LR 0.0723076923077 --> Loss 0.00131521026293\n",
      "Epoch 13::Minibatch 614::LR 0.0723076923077 --> Loss 0.00249252895514\n",
      "Epoch 13::Minibatch 615::LR 0.0723076923077 --> Loss 0.00169871528943\n",
      "Epoch 13::Minibatch 616::LR 0.0723076923077 --> Loss 0.000937530597051\n",
      "Epoch 13::Minibatch 617::LR 0.0723076923077 --> Loss 0.000516010820866\n",
      "Epoch 13::Minibatch 618::LR 0.0723076923077 --> Loss 0.00273666640123\n",
      "Epoch 13::Minibatch 619::LR 0.0723076923077 --> Loss 0.00192813734214\n",
      "Epoch 13::Minibatch 620::LR 0.0723076923077 --> Loss 0.00173383573691\n",
      "Epoch 13::Minibatch 621::LR 0.0723076923077 --> Loss 0.000864791770776\n",
      "Epoch 13::Minibatch 622::LR 0.0723076923077 --> Loss 0.000817052324613\n",
      "Epoch 13::Minibatch 623::LR 0.0723076923077 --> Loss 0.0022189617157\n",
      "Epoch 13::Minibatch 624::LR 0.0723076923077 --> Loss 0.00182080050309\n",
      "Epoch 13::Minibatch 625::LR 0.0723076923077 --> Loss 0.00308412690957\n",
      "Epoch 13::Minibatch 626::LR 0.0723076923077 --> Loss 0.00470576763153\n",
      "Epoch 13::Minibatch 627::LR 0.0723076923077 --> Loss 0.00135796626409\n",
      "Epoch 13::Minibatch 628::LR 0.0723076923077 --> Loss 0.000925685664018\n",
      "Epoch 13::Minibatch 629::LR 0.0723076923077 --> Loss 0.00349333961805\n",
      "Epoch 13::Minibatch 630::LR 0.0723076923077 --> Loss 0.00338793238004\n",
      "Epoch 13::Minibatch 631::LR 0.0723076923077 --> Loss 0.00690139770508\n",
      "Epoch 13::Minibatch 632::LR 0.0723076923077 --> Loss 0.000810281038284\n",
      "Epoch 13::Minibatch 633::LR 0.0723076923077 --> Loss 0.00168097376823\n",
      "Epoch 13::Minibatch 634::LR 0.0723076923077 --> Loss 0.00327591518561\n",
      "Epoch 13::Minibatch 635::LR 0.0723076923077 --> Loss 0.00506984710693\n",
      "Epoch 13::Minibatch 636::LR 0.0723076923077 --> Loss 0.00537341594696\n",
      "Epoch 13::Minibatch 637::LR 0.0723076923077 --> Loss 0.000848287741343\n",
      "Epoch 13::Minibatch 638::LR 0.0723076923077 --> Loss 0.00156688441833\n",
      "Epoch 13::Minibatch 639::LR 0.0723076923077 --> Loss 0.00336581667264\n",
      "Epoch 13::Minibatch 640::LR 0.0723076923077 --> Loss 0.00508648316065\n",
      "Epoch 13::Minibatch 641::LR 0.0723076923077 --> Loss 0.00319120844205\n",
      "Epoch 13::Minibatch 642::LR 0.0723076923077 --> Loss 0.000573094387849\n",
      "Epoch 13::Minibatch 643::LR 0.0723076923077 --> Loss 0.00236908932527\n",
      "Epoch 13::Minibatch 644::LR 0.0723076923077 --> Loss 0.00404104669889\n",
      "Epoch 13::Minibatch 645::LR 0.0723076923077 --> Loss 0.00422470331192\n",
      "Epoch 13::Minibatch 646::LR 0.0723076923077 --> Loss 0.00155828674634\n",
      "Epoch 13::Minibatch 647::LR 0.0723076923077 --> Loss 0.000587530930837\n",
      "Epoch 13::Minibatch 648::LR 0.0723076923077 --> Loss 0.00304893910885\n",
      "Epoch 13::Minibatch 649::LR 0.0723076923077 --> Loss 0.00362196207047\n",
      "Epoch 13::Minibatch 650::LR 0.0723076923077 --> Loss 0.0033650803566\n",
      "Epoch 13::Minibatch 651::LR 0.0723076923077 --> Loss 0.00142016033332\n",
      "Epoch 13::Minibatch 652::LR 0.0723076923077 --> Loss 0.000852412680785\n",
      "Epoch 13::Minibatch 653::LR 0.0723076923077 --> Loss 0.00289855976899\n",
      "Epoch 13::Minibatch 654::LR 0.0723076923077 --> Loss 0.00312186717987\n",
      "Epoch 13::Minibatch 655::LR 0.0723076923077 --> Loss 0.00349424123764\n",
      "Epoch 13::Minibatch 656::LR 0.0723076923077 --> Loss 0.000781548817952\n",
      "Epoch 13::Minibatch 657::LR 0.0723076923077 --> Loss 0.00222748398781\n",
      "Epoch 13::Minibatch 658::LR 0.0723076923077 --> Loss 0.00504087805748\n",
      "Epoch 13::Minibatch 659::LR 0.0723076923077 --> Loss 0.00236272652944\n",
      "Epoch 13::Minibatch 660::LR 0.0723076923077 --> Loss 0.00262611985207\n",
      "Epoch 13::Minibatch 661::LR 0.0723076923077 --> Loss 0.00256986161073\n",
      "Epoch 13::Minibatch 662::LR 0.0723076923077 --> Loss 0.0018407980601\n",
      "Epoch 13::Minibatch 663::LR 0.0723076923077 --> Loss 0.00367398142815\n",
      "Epoch 13::Minibatch 664::LR 0.0723076923077 --> Loss 0.00353259682655\n",
      "Epoch 13::Minibatch 665::LR 0.0723076923077 --> Loss 0.000767818937699\n",
      "Epoch 13::Minibatch 666::LR 0.0723076923077 --> Loss 0.00395712892214\n",
      "Epoch 13::Minibatch 667::LR 0.0723076923077 --> Loss 0.00257585823536\n",
      "Epoch 13::Minibatch 668::LR 0.0723076923077 --> Loss 0.00719878196716\n",
      "Epoch 13::Minibatch 669::LR 0.0723076923077 --> Loss 0.00109744369984\n",
      "Epoch 13::Minibatch 670::LR 0.0723076923077 --> Loss 0.00137539962928\n",
      "Epoch 13::Minibatch 671::LR 0.0723076923077 --> Loss 0.00546449104945\n",
      "Epoch 13::Minibatch 672::LR 0.0723076923077 --> Loss 0.00385426640511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 673::LR 0.0723076923077 --> Loss 0.00162963449955\n",
      "Epoch 13::Minibatch 674::LR 0.0723076923077 --> Loss 0.000531106392543\n",
      "Epoch 13::Minibatch 675::LR 0.0723076923077 --> Loss 0.00220055282116\n",
      "Epoch 13::Minibatch 676::LR 0.0723076923077 --> Loss 0.00212457319101\n",
      "Epoch 13::Minibatch 677::LR 0.0723076923077 --> Loss 0.00285311917464\n",
      "Epoch 13::Minibatch 678::LR 0.0723076923077 --> Loss 0.00195476710796\n",
      "Epoch 13::Minibatch 679::LR 0.0723076923077 --> Loss 0.00357925454775\n",
      "Epoch 13::Minibatch 680::LR 0.0723076923077 --> Loss 0.00215444246928\n",
      "Epoch 13::Minibatch 681::LR 0.0723076923077 --> Loss 0.00245124220848\n",
      "Epoch 13::Minibatch 682::LR 0.0723076923077 --> Loss 0.000771320909262\n",
      "Epoch 13::Minibatch 683::LR 0.0723076923077 --> Loss 0.00241964280605\n",
      "Epoch 13::Minibatch 684::LR 0.0723076923077 --> Loss 0.00236493925254\n",
      "Epoch 13::Minibatch 685::LR 0.0723076923077 --> Loss 0.0029489137729\n",
      "Epoch 13::Minibatch 686::LR 0.0723076923077 --> Loss 0.00153715928396\n",
      "Epoch 13::Minibatch 687::LR 0.0723076923077 --> Loss 0.000848038593928\n",
      "Epoch 13::Minibatch 688::LR 0.0723076923077 --> Loss 0.00276829659939\n",
      "Epoch 13::Minibatch 689::LR 0.0723076923077 --> Loss 0.00255342324575\n",
      "Epoch 13::Minibatch 690::LR 0.0723076923077 --> Loss 0.00193010151386\n",
      "Epoch 13::Minibatch 691::LR 0.0723076923077 --> Loss 0.000669709046682\n",
      "Epoch 13::Minibatch 692::LR 0.0723076923077 --> Loss 0.002493617932\n",
      "Epoch 13::Minibatch 693::LR 0.0723076923077 --> Loss 0.00257393380006\n",
      "Epoch 13::Minibatch 694::LR 0.0723076923077 --> Loss 0.00303190926711\n",
      "Epoch 13::Minibatch 695::LR 0.0723076923077 --> Loss 0.00173174460729\n",
      "Epoch 13::Minibatch 696::LR 0.0723076923077 --> Loss 0.00204239567121\n",
      "Epoch 13::Minibatch 697::LR 0.0723076923077 --> Loss 0.00141120205323\n",
      "Epoch 13::Minibatch 698::LR 0.0723076923077 --> Loss 0.00162118087212\n",
      "Epoch 13::Minibatch 699::LR 0.0723076923077 --> Loss 0.00386952718099\n",
      "Epoch 13::Minibatch 700::LR 0.0723076923077 --> Loss 0.0027083325386\n",
      "Epoch 13::Minibatch 701::LR 0.0723076923077 --> Loss 0.00201981226603\n",
      "Epoch 13::Minibatch 702::LR 0.0723076923077 --> Loss 0.00166790445646\n",
      "Epoch 13::Minibatch 703::LR 0.0723076923077 --> Loss 0.00427429119746\n",
      "Epoch 13::Minibatch 704::LR 0.0723076923077 --> Loss 0.00181150356929\n",
      "Epoch 13::Minibatch 705::LR 0.0723076923077 --> Loss 0.00286374767621\n",
      "Epoch 13::Minibatch 706::LR 0.0723076923077 --> Loss 0.00224406083425\n",
      "Epoch 13::Minibatch 707::LR 0.0723076923077 --> Loss 0.00118853876988\n",
      "Epoch 13::Minibatch 708::LR 0.0723076923077 --> Loss 0.00173859993617\n",
      "Epoch 13::Minibatch 709::LR 0.0723076923077 --> Loss 0.00169864515464\n",
      "Epoch 13::Minibatch 710::LR 0.0723076923077 --> Loss 0.00250764667988\n",
      "Epoch 13::Minibatch 711::LR 0.0723076923077 --> Loss 0.00191148817539\n",
      "Epoch 13::Minibatch 712::LR 0.0723076923077 --> Loss 0.00132786492507\n",
      "Epoch 13::Minibatch 713::LR 0.0723076923077 --> Loss 0.00175127784411\n",
      "Epoch 13::Minibatch 714::LR 0.0723076923077 --> Loss 0.00272745688756\n",
      "Epoch 13::Minibatch 715::LR 0.0723076923077 --> Loss 0.00295415739218\n",
      "Epoch 13::Minibatch 716::LR 0.0723076923077 --> Loss 0.00160807410876\n",
      "Epoch 13::Minibatch 717::LR 0.0723076923077 --> Loss 0.00160817643007\n",
      "Epoch 13::Minibatch 718::LR 0.0723076923077 --> Loss 0.00126331925392\n",
      "Epoch 13::Minibatch 719::LR 0.0723076923077 --> Loss 0.00166391263405\n",
      "Epoch 13::Minibatch 720::LR 0.0723076923077 --> Loss 0.00252877434095\n",
      "Epoch 13::Minibatch 721::LR 0.0723076923077 --> Loss 0.00063671524326\n",
      "Epoch 13::Minibatch 722::LR 0.0723076923077 --> Loss 0.00485883156459\n",
      "Epoch 13::Minibatch 723::LR 0.0723076923077 --> Loss 0.00492475748062\n",
      "Epoch 13::Minibatch 724::LR 0.0723076923077 --> Loss 0.000976275304953\n",
      "Epoch 13::Minibatch 725::LR 0.0723076923077 --> Loss 0.00224873284499\n",
      "Epoch 13::Minibatch 726::LR 0.0723076923077 --> Loss 0.00483051458995\n",
      "Epoch 13::Minibatch 727::LR 0.0723076923077 --> Loss 0.00318678855896\n",
      "Epoch 13::Minibatch 728::LR 0.0723076923077 --> Loss 0.0006542053322\n",
      "Epoch 13::Minibatch 729::LR 0.0723076923077 --> Loss 0.000767615238825\n",
      "Epoch 13::Minibatch 730::LR 0.0723076923077 --> Loss 0.0027264692386\n",
      "Epoch 13::Minibatch 731::LR 0.0723076923077 --> Loss 0.00246931970119\n",
      "Epoch 13::Minibatch 732::LR 0.0723076923077 --> Loss 0.0022998013099\n",
      "Epoch 13::Minibatch 733::LR 0.0723076923077 --> Loss 0.000723823060592\n",
      "Epoch 13::Minibatch 734::LR 0.0723076923077 --> Loss 0.00179141620795\n",
      "Epoch 13::Minibatch 735::LR 0.0723076923077 --> Loss 0.00235217591127\n",
      "Epoch 13::Minibatch 736::LR 0.0723076923077 --> Loss 0.00345955530802\n",
      "Epoch 13::Minibatch 737::LR 0.0723076923077 --> Loss 0.00311228295167\n",
      "Epoch 13::Minibatch 738::LR 0.0723076923077 --> Loss 0.00165453265111\n",
      "Epoch 13::Minibatch 739::LR 0.0723076923077 --> Loss 0.00250685671965\n",
      "Epoch 13::Minibatch 740::LR 0.0723076923077 --> Loss 0.00386047522227\n",
      "Epoch 13::Minibatch 741::LR 0.0723076923077 --> Loss 0.00273843248685\n",
      "Epoch 13::Minibatch 742::LR 0.0723076923077 --> Loss 0.00212011635303\n",
      "Epoch 13::Minibatch 743::LR 0.0723076923077 --> Loss 0.00137231886387\n",
      "Epoch 13::Minibatch 744::LR 0.0723076923077 --> Loss 0.00180096964041\n",
      "Epoch 13::Minibatch 745::LR 0.0723076923077 --> Loss 0.00286216795444\n",
      "Epoch 13::Minibatch 746::LR 0.0723076923077 --> Loss 0.00301555812359\n",
      "Epoch 13::Minibatch 747::LR 0.0723076923077 --> Loss 0.00180117448171\n",
      "Epoch 13::Minibatch 748::LR 0.0723076923077 --> Loss 0.000643503516912\n",
      "Epoch 13::Minibatch 749::LR 0.0723076923077 --> Loss 0.00165384441614\n",
      "Epoch 13::Minibatch 750::LR 0.0723076923077 --> Loss 0.00248422503471\n",
      "Epoch 13::Minibatch 751::LR 0.0723076923077 --> Loss 0.00271743118763\n",
      "Epoch 13::Minibatch 752::LR 0.0723076923077 --> Loss 0.00115108152231\n",
      "Epoch 13::Minibatch 753::LR 0.0723076923077 --> Loss 0.00224787036578\n",
      "Epoch 13::Minibatch 754::LR 0.0723076923077 --> Loss 0.00239441394806\n",
      "Epoch 13::Minibatch 755::LR 0.0723076923077 --> Loss 0.00267025947571\n",
      "Epoch 13::Minibatch 756::LR 0.0723076923077 --> Loss 0.00143147657315\n",
      "Epoch 13::Minibatch 757::LR 0.0723076923077 --> Loss 0.00085509310166\n",
      "Epoch 13::Minibatch 758::LR 0.0723076923077 --> Loss 0.00163929373026\n",
      "Epoch 13::Minibatch 759::LR 0.0723076923077 --> Loss 0.00380171934764\n",
      "Epoch 13::Minibatch 760::LR 0.0723076923077 --> Loss 0.00307505150636\n",
      "Epoch 13::Minibatch 761::LR 0.0723076923077 --> Loss 0.00637550036112\n",
      "Epoch 13::Minibatch 762::LR 0.0723076923077 --> Loss 0.00378867467244\n",
      "Epoch 13::Minibatch 763::LR 0.0723076923077 --> Loss 0.00359300772349\n",
      "Epoch 13::Minibatch 764::LR 0.0723076923077 --> Loss 0.00321532090505\n",
      "Epoch 13::Minibatch 765::LR 0.0723076923077 --> Loss 0.00133320103089\n",
      "Epoch 13::Minibatch 766::LR 0.0723076923077 --> Loss 0.00227554361025\n",
      "Epoch 13::Minibatch 767::LR 0.0723076923077 --> Loss 0.00504994471868\n",
      "Epoch 13::Minibatch 768::LR 0.0723076923077 --> Loss 0.00358591874441\n",
      "Epoch 13::Minibatch 769::LR 0.0723076923077 --> Loss 0.0019077471892\n",
      "Epoch 13::Minibatch 770::LR 0.0723076923077 --> Loss 0.00149490127961\n",
      "Epoch 13::Minibatch 771::LR 0.0723076923077 --> Loss 0.00377314329147\n",
      "Epoch 13::Minibatch 772::LR 0.0723076923077 --> Loss 0.00337082147598\n",
      "Epoch 13::Minibatch 773::LR 0.0723076923077 --> Loss 0.00313241362572\n",
      "Epoch 13::Minibatch 774::LR 0.0723076923077 --> Loss 0.00177553296089\n",
      "Epoch 13::Minibatch 775::LR 0.0723076923077 --> Loss 0.00401272058487\n",
      "Epoch 13::Minibatch 776::LR 0.0723076923077 --> Loss 0.00356715877851\n",
      "Epoch 13::Minibatch 777::LR 0.0723076923077 --> Loss 0.00775324344635\n",
      "Epoch 13::Minibatch 778::LR 0.0723076923077 --> Loss 0.0101060406367\n",
      "Epoch 13::Minibatch 779::LR 0.0723076923077 --> Loss 0.00221247990926\n",
      "Epoch 13::Minibatch 780::LR 0.0723076923077 --> Loss 0.00164008458455\n",
      "Epoch 13::Minibatch 781::LR 0.0723076923077 --> Loss 0.00350812872251\n",
      "Epoch 13::Minibatch 782::LR 0.0723076923077 --> Loss 0.004083228906\n",
      "Epoch 13::Minibatch 783::LR 0.0723076923077 --> Loss 0.00233676572641\n",
      "Epoch 13::Minibatch 784::LR 0.0723076923077 --> Loss 0.000736401428779\n",
      "Epoch 13::Minibatch 785::LR 0.0723076923077 --> Loss 0.00367387215296\n",
      "Epoch 13::Minibatch 786::LR 0.0723076923077 --> Loss 0.00354992588361\n",
      "Epoch 13::Minibatch 787::LR 0.0723076923077 --> Loss 0.00278696020444\n",
      "Epoch 13::Minibatch 788::LR 0.0723076923077 --> Loss 0.00246679166953\n",
      "Epoch 13::Minibatch 789::LR 0.0723076923077 --> Loss 0.000747366597255\n",
      "Epoch 13::Minibatch 790::LR 0.0723076923077 --> Loss 0.00322771628698\n",
      "Epoch 13::Minibatch 791::LR 0.0723076923077 --> Loss 0.00367432951927\n",
      "Epoch 13::Minibatch 792::LR 0.0723076923077 --> Loss 0.00330153783162\n",
      "Epoch 13::Minibatch 793::LR 0.0723076923077 --> Loss 0.0018619086345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 794::LR 0.0723076923077 --> Loss 0.00106080452601\n",
      "Epoch 13::Minibatch 795::LR 0.0723076923077 --> Loss 0.00317427655061\n",
      "Epoch 13::Minibatch 796::LR 0.0723076923077 --> Loss 0.00588845054309\n",
      "Epoch 13::Minibatch 797::LR 0.0723076923077 --> Loss 0.0078010614713\n",
      "Epoch 13::Minibatch 798::LR 0.0723076923077 --> Loss 0.00341217120488\n",
      "Epoch 13::Minibatch 799::LR 0.0723076923077 --> Loss 0.00243304351966\n",
      "Epoch 13::Minibatch 800::LR 0.0723076923077 --> Loss 0.0020401151975\n",
      "Epoch 13::Minibatch 801::LR 0.0723076923077 --> Loss 0.00417698303858\n",
      "Epoch 13::Minibatch 802::LR 0.0723076923077 --> Loss 0.00135038236777\n",
      "Epoch 13::Minibatch 803::LR 0.0723076923077 --> Loss 0.002830474178\n",
      "Epoch 13::Minibatch 804::LR 0.0723076923077 --> Loss 0.00221467832724\n",
      "Epoch 13::Minibatch 805::LR 0.0723076923077 --> Loss 0.00230580151081\n",
      "Epoch 13::Minibatch 806::LR 0.0723076923077 --> Loss 0.00331871072451\n",
      "Epoch 13::Minibatch 807::LR 0.0723076923077 --> Loss 0.00304027954737\n",
      "Epoch 13::Minibatch 808::LR 0.0723076923077 --> Loss 0.00273199955622\n",
      "Epoch 13::Minibatch 809::LR 0.0723076923077 --> Loss 0.00394844055176\n",
      "Epoch 13::Minibatch 810::LR 0.0723076923077 --> Loss 0.00521510044734\n",
      "Epoch 13::Minibatch 811::LR 0.0723076923077 --> Loss 0.0049114326636\n",
      "Epoch 13::Minibatch 812::LR 0.0723076923077 --> Loss 0.0045925672849\n",
      "Epoch 13::Minibatch 813::LR 0.0723076923077 --> Loss 0.00425398508708\n",
      "Epoch 13::Minibatch 814::LR 0.0723076923077 --> Loss 0.0018807220459\n",
      "Epoch 13::Minibatch 815::LR 0.0723076923077 --> Loss 0.00393073717753\n",
      "Epoch 13::Minibatch 816::LR 0.0723076923077 --> Loss 0.0042303999265\n",
      "Epoch 13::Minibatch 817::LR 0.0723076923077 --> Loss 0.00556498805682\n",
      "Epoch 13::Minibatch 818::LR 0.0723076923077 --> Loss 0.00133484244347\n",
      "Epoch 13::Minibatch 819::LR 0.0723076923077 --> Loss 0.000743977427483\n",
      "Epoch 13::Minibatch 820::LR 0.0723076923077 --> Loss 0.00541926662127\n",
      "Epoch 13::Minibatch 821::LR 0.0723076923077 --> Loss 0.00323259452979\n",
      "Epoch 13::Minibatch 822::LR 0.0723076923077 --> Loss 0.00380540688833\n",
      "Epoch 13::Minibatch 823::LR 0.0723076923077 --> Loss 0.0013184940815\n",
      "Epoch 13::Minibatch 824::LR 0.0723076923077 --> Loss 0.00140909622113\n",
      "Epoch 13::Minibatch 825::LR 0.0723076923077 --> Loss 0.00374069531759\n",
      "Epoch 13::Minibatch 826::LR 0.0723076923077 --> Loss 0.00393202026685\n",
      "Epoch 13::Minibatch 827::LR 0.0723076923077 --> Loss 0.00223922252655\n",
      "Epoch 13::Minibatch 828::LR 0.0723076923077 --> Loss 0.000645811259747\n",
      "Epoch 13::Minibatch 829::LR 0.0723076923077 --> Loss 0.00244565506776\n",
      "Epoch 13::Minibatch 830::LR 0.0723076923077 --> Loss 0.00444637815158\n",
      "Epoch 13::Minibatch 831::LR 0.0723076923077 --> Loss 0.00259195049604\n",
      "Epoch 13::Minibatch 832::LR 0.0723076923077 --> Loss 0.00227269232273\n",
      "Epoch 13::Minibatch 833::LR 0.0723076923077 --> Loss 0.0018617161115\n",
      "Epoch 13::Minibatch 834::LR 0.0723076923077 --> Loss 0.000781504114469\n",
      "Epoch 13::Minibatch 835::LR 0.0723076923077 --> Loss 0.00383237401644\n",
      "Epoch 13::Minibatch 836::LR 0.0723076923077 --> Loss 0.00377020478249\n",
      "Epoch 13::Minibatch 837::LR 0.0723076923077 --> Loss 0.00222199678421\n",
      "Epoch 13::Minibatch 838::LR 0.0723076923077 --> Loss 0.000638348062833\n",
      "Epoch 13::Minibatch 839::LR 0.0723076923077 --> Loss 0.00248400092125\n",
      "Epoch 13::Minibatch 840::LR 0.0723076923077 --> Loss 0.00293145954609\n",
      "Epoch 13::Minibatch 841::LR 0.0723076923077 --> Loss 0.0028851878643\n",
      "Epoch 13::Minibatch 842::LR 0.0723076923077 --> Loss 0.00211129208406\n",
      "Epoch 13::Minibatch 843::LR 0.0723076923077 --> Loss 0.00101635138194\n",
      "Epoch 13::Minibatch 844::LR 0.0723076923077 --> Loss 0.00150693486134\n",
      "Epoch 13::Minibatch 845::LR 0.0723076923077 --> Loss 0.0043931210041\n",
      "Epoch 13::Minibatch 846::LR 0.0723076923077 --> Loss 0.00169226388137\n",
      "Epoch 13::Minibatch 847::LR 0.0723076923077 --> Loss 0.00229690889517\n",
      "Epoch 13::Minibatch 848::LR 0.0723076923077 --> Loss 0.00100384265184\n",
      "Epoch 13::Minibatch 849::LR 0.0723076923077 --> Loss 0.00186733345191\n",
      "Epoch 13::Minibatch 850::LR 0.0723076923077 --> Loss 0.00320947090785\n",
      "Epoch 13::Minibatch 851::LR 0.0723076923077 --> Loss 0.0027428450187\n",
      "Epoch 13::Minibatch 852::LR 0.0723076923077 --> Loss 0.00107314437628\n",
      "Epoch 13::Minibatch 853::LR 0.0723076923077 --> Loss 0.0013185753425\n",
      "Epoch 13::Minibatch 854::LR 0.0723076923077 --> Loss 0.00258255561193\n",
      "Epoch 13::Minibatch 855::LR 0.0723076923077 --> Loss 0.00218323409557\n",
      "Epoch 13::Minibatch 856::LR 0.0723076923077 --> Loss 0.00180310050646\n",
      "Epoch 13::Minibatch 857::LR 0.0723076923077 --> Loss 0.00122120777766\n",
      "Epoch 13::Minibatch 858::LR 0.0723076923077 --> Loss 0.000599624713262\n",
      "Epoch 13::Minibatch 859::LR 0.0723076923077 --> Loss 0.00190395116806\n",
      "Epoch 13::Minibatch 860::LR 0.0723076923077 --> Loss 0.00123894363642\n",
      "Epoch 13::Minibatch 861::LR 0.0723076923077 --> Loss 0.000937507251898\n",
      "Epoch 13::Minibatch 862::LR 0.0723076923077 --> Loss 0.00364217480024\n",
      "Epoch 13::Minibatch 863::LR 0.0723076923077 --> Loss 0.00344771623611\n",
      "Epoch 13::Minibatch 864::LR 0.0723076923077 --> Loss 0.00297199249268\n",
      "Epoch 13::Minibatch 865::LR 0.0723076923077 --> Loss 0.000477323681116\n",
      "Epoch 13::Minibatch 866::LR 0.0723076923077 --> Loss 0.00217620531718\n",
      "Epoch 13::Minibatch 867::LR 0.0723076923077 --> Loss 0.0030299047629\n",
      "Epoch 13::Minibatch 868::LR 0.0723076923077 --> Loss 0.00250385204951\n",
      "Epoch 13::Minibatch 869::LR 0.0723076923077 --> Loss 0.00212291558584\n",
      "Epoch 13::Minibatch 870::LR 0.0723076923077 --> Loss 0.00360480705897\n",
      "Epoch 13::Minibatch 871::LR 0.0723076923077 --> Loss 0.00152845313152\n",
      "Epoch 13::Minibatch 872::LR 0.0723076923077 --> Loss 0.00229263504346\n",
      "Epoch 13::Minibatch 873::LR 0.0723076923077 --> Loss 0.00248622020086\n",
      "Epoch 13::Minibatch 874::LR 0.0723076923077 --> Loss 0.00631636102994\n",
      "Epoch 13::Minibatch 875::LR 0.0723076923077 --> Loss 0.000534269909064\n",
      "Epoch 13::Minibatch 876::LR 0.0723076923077 --> Loss 0.00336930354436\n",
      "Epoch 13::Minibatch 877::LR 0.0723076923077 --> Loss 0.00504508336385\n",
      "Epoch 13::Minibatch 878::LR 0.0723076923077 --> Loss 0.00331367015839\n",
      "Epoch 13::Minibatch 879::LR 0.0723076923077 --> Loss 0.00397577683131\n",
      "Epoch 13::Minibatch 880::LR 0.0723076923077 --> Loss 0.00471146941185\n",
      "Epoch 13::Minibatch 881::LR 0.0723076923077 --> Loss 0.00425876140594\n",
      "Epoch 13::Minibatch 882::LR 0.0723076923077 --> Loss 0.00198439538479\n",
      "Epoch 13::Minibatch 883::LR 0.0723076923077 --> Loss 0.00338705182076\n",
      "Epoch 13::Minibatch 884::LR 0.0723076923077 --> Loss 0.00269701341788\n",
      "Epoch 13::Minibatch 885::LR 0.0723076923077 --> Loss 0.00248287340005\n",
      "Epoch 13::Minibatch 886::LR 0.0723076923077 --> Loss 0.000514678955078\n",
      "Epoch 13::Minibatch 887::LR 0.0723076923077 --> Loss 0.00525153835615\n",
      "Epoch 13::Minibatch 888::LR 0.0723076923077 --> Loss 0.00265703678131\n",
      "Epoch 13::Minibatch 889::LR 0.0723076923077 --> Loss 0.0028961255153\n",
      "Epoch 13::Minibatch 890::LR 0.0723076923077 --> Loss 0.00429456114769\n",
      "Epoch 13::Minibatch 891::LR 0.0723076923077 --> Loss 0.00190093994141\n",
      "Epoch 13::Minibatch 892::LR 0.0723076923077 --> Loss 0.000897460480531\n",
      "Epoch 13::Minibatch 893::LR 0.0723076923077 --> Loss 0.00248669743538\n",
      "Epoch 13::Minibatch 894::LR 0.0723076923077 --> Loss 0.00220481435458\n",
      "Epoch 13::Minibatch 895::LR 0.0723076923077 --> Loss 0.00242593804995\n",
      "Epoch 13::Minibatch 896::LR 0.0723076923077 --> Loss 0.00129396041234\n",
      "Epoch 13::Minibatch 897::LR 0.0723076923077 --> Loss 0.000738003700972\n",
      "Epoch 13::Minibatch 898::LR 0.0723076923077 --> Loss 0.00217328647772\n",
      "Epoch 13::Minibatch 899::LR 0.0723076923077 --> Loss 0.00248280346394\n",
      "Epoch 13::Minibatch 900::LR 0.0723076923077 --> Loss 0.00326419552167\n",
      "Epoch 13::Minibatch 901::LR 0.0723076923077 --> Loss 0.000609068324169\n",
      "Epoch 13::Minibatch 902::LR 0.0723076923077 --> Loss 0.00142782131831\n",
      "Epoch 13::Minibatch 903::LR 0.0723076923077 --> Loss 0.00257066706816\n",
      "Epoch 13::Minibatch 904::LR 0.0723076923077 --> Loss 0.00197073558966\n",
      "Epoch 13::Minibatch 905::LR 0.0723076923077 --> Loss 0.00144560356935\n",
      "Epoch 13::Minibatch 906::LR 0.0723076923077 --> Loss 0.00110063652198\n",
      "Epoch 13::Minibatch 907::LR 0.0723076923077 --> Loss 0.00159174253543\n",
      "Epoch 13::Minibatch 908::LR 0.0723076923077 --> Loss 0.00217045287291\n",
      "Epoch 13::Minibatch 909::LR 0.0723076923077 --> Loss 0.0019990370671\n",
      "Epoch 13::Minibatch 910::LR 0.0723076923077 --> Loss 0.000838039418062\n",
      "Epoch 13::Minibatch 911::LR 0.0723076923077 --> Loss 0.00123140146335\n",
      "Epoch 13::Minibatch 912::LR 0.0723076923077 --> Loss 0.0019684479634\n",
      "Epoch 13::Minibatch 913::LR 0.0723076923077 --> Loss 0.00213395377\n",
      "Epoch 13::Minibatch 914::LR 0.0723076923077 --> Loss 0.00116431663434\n",
      "Epoch 13::Minibatch 915::LR 0.0723076923077 --> Loss 0.000494219660759\n",
      "Epoch 13::Minibatch 916::LR 0.0723076923077 --> Loss 0.00231693923473\n",
      "Epoch 13::Minibatch 917::LR 0.0723076923077 --> Loss 0.00388339161873\n",
      "Epoch 13::Minibatch 918::LR 0.0723076923077 --> Loss 0.00646047155062\n",
      "Epoch 13::Minibatch 919::LR 0.0723076923077 --> Loss 0.000592365463575\n",
      "Epoch 13::Minibatch 920::LR 0.0723076923077 --> Loss 0.0111676820119\n",
      "Epoch 13::Minibatch 921::LR 0.0723076923077 --> Loss 0.00285080969334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 922::LR 0.0723076923077 --> Loss 0.00306919078032\n",
      "Epoch 13::Minibatch 923::LR 0.0723076923077 --> Loss 0.00155905872583\n",
      "Epoch 13::Minibatch 924::LR 0.0723076923077 --> Loss 0.00354344010353\n",
      "Epoch 13::Minibatch 925::LR 0.0723076923077 --> Loss 0.00254715780417\n",
      "Epoch 13::Minibatch 926::LR 0.0723076923077 --> Loss 0.00539806723595\n",
      "Epoch 13::Minibatch 927::LR 0.0723076923077 --> Loss 0.00829920212428\n",
      "Epoch 13::Minibatch 928::LR 0.0723076923077 --> Loss 0.00661600430806\n",
      "Epoch 13::Minibatch 929::LR 0.0723076923077 --> Loss 0.00736167351405\n",
      "Epoch 13::Minibatch 930::LR 0.0723076923077 --> Loss 0.00966653903325\n",
      "Epoch 13::Minibatch 931::LR 0.0723076923077 --> Loss 0.00372991045316\n",
      "Epoch 13::Minibatch 932::LR 0.0723076923077 --> Loss 0.00784343878428\n",
      "Epoch 13::Minibatch 933::LR 0.0723076923077 --> Loss 0.00391440947851\n",
      "Epoch 13::Minibatch 934::LR 0.0723076923077 --> Loss 0.00513807932536\n",
      "Epoch 13::Minibatch 935::LR 0.0723076923077 --> Loss 0.0070769850413\n",
      "Epoch 13::Minibatch 936::LR 0.0723076923077 --> Loss 0.00175546228886\n",
      "Epoch 13::Minibatch 937::LR 0.0723076923077 --> Loss 0.00370380719503\n",
      "Epoch 13::Minibatch 938::LR 0.0723076923077 --> Loss 0.00344249327977\n",
      "Epoch 13::Minibatch 939::LR 0.0723076923077 --> Loss 0.00351464708646\n",
      "Epoch 13::Minibatch 940::LR 0.0723076923077 --> Loss 0.00109062413375\n",
      "Epoch 13::Minibatch 941::LR 0.0723076923077 --> Loss 0.000887125929197\n",
      "Epoch 13::Minibatch 942::LR 0.0723076923077 --> Loss 0.00247891128063\n",
      "Epoch 13::Minibatch 943::LR 0.0723076923077 --> Loss 0.00317223668098\n",
      "Epoch 13::Minibatch 944::LR 0.0723076923077 --> Loss 0.00230343262355\n",
      "Epoch 13::Minibatch 945::LR 0.0723076923077 --> Loss 0.00135688453913\n",
      "Epoch 13::Minibatch 946::LR 0.0723076923077 --> Loss 0.00341745972633\n",
      "Epoch 13::Minibatch 947::LR 0.0723076923077 --> Loss 0.00303479890029\n",
      "Epoch 13::Minibatch 948::LR 0.0723076923077 --> Loss 0.00555681268374\n",
      "Epoch 13::Minibatch 949::LR 0.0723076923077 --> Loss 0.00197820643584\n",
      "Epoch 13::Minibatch 950::LR 0.0723076923077 --> Loss 0.000743438402812\n",
      "Epoch 13::Minibatch 951::LR 0.0723076923077 --> Loss 0.00342053572337\n",
      "Epoch 13::Minibatch 952::LR 0.0723076923077 --> Loss 0.00250831584136\n",
      "Epoch 13::Minibatch 953::LR 0.0723076923077 --> Loss 0.00139342576265\n",
      "Epoch 13::Minibatch 954::LR 0.0723076923077 --> Loss 0.000967281361421\n",
      "Epoch 13::Minibatch 955::LR 0.0723076923077 --> Loss 0.00256747066975\n",
      "Epoch 13::Minibatch 956::LR 0.0723076923077 --> Loss 0.0040846033891\n",
      "Epoch 13::Minibatch 957::LR 0.0723076923077 --> Loss 0.00196076194445\n",
      "Epoch 13::Minibatch 958::LR 0.0723076923077 --> Loss 0.00246518830458\n",
      "Epoch 13::Minibatch 959::LR 0.0723076923077 --> Loss 0.00304949998856\n",
      "Epoch 13::Minibatch 960::LR 0.0723076923077 --> Loss 0.0067489306132\n",
      "Epoch 13::Minibatch 961::LR 0.0723076923077 --> Loss 0.00348730961482\n",
      "Epoch 13::Minibatch 962::LR 0.0723076923077 --> Loss 0.0030395813783\n",
      "Epoch 13::Minibatch 963::LR 0.0723076923077 --> Loss 0.00105746358633\n",
      "Epoch 13::Minibatch 964::LR 0.0723076923077 --> Loss 0.00244945645332\n",
      "Epoch 13::Minibatch 965::LR 0.0723076923077 --> Loss 0.00750705003738\n",
      "Epoch 13::Minibatch 966::LR 0.0723076923077 --> Loss 0.00519594629606\n",
      "Epoch 13::Minibatch 967::LR 0.0723076923077 --> Loss 0.00166678448518\n",
      "Epoch 13::Minibatch 968::LR 0.0723076923077 --> Loss 0.00146427551905\n",
      "Epoch 13::Minibatch 969::LR 0.0723076923077 --> Loss 0.00694090604782\n",
      "Epoch 13::Minibatch 970::LR 0.0723076923077 --> Loss 0.00598438342412\n",
      "Epoch 13::Minibatch 971::LR 0.0723076923077 --> Loss 0.00363697568576\n",
      "Epoch 13::Minibatch 972::LR 0.0723076923077 --> Loss 0.00963433504105\n",
      "Epoch 13::Minibatch 973::LR 0.0723076923077 --> Loss 0.009094795386\n",
      "Epoch 13::Minibatch 974::LR 0.0723076923077 --> Loss 0.00754304011663\n",
      "Epoch 13::Minibatch 975::LR 0.0723076923077 --> Loss 0.00483142534892\n",
      "Epoch 13::Minibatch 976::LR 0.0723076923077 --> Loss 0.00439588507016\n",
      "Epoch 13::Minibatch 977::LR 0.0723076923077 --> Loss 0.00444652398427\n",
      "Epoch 13::Minibatch 978::LR 0.0723076923077 --> Loss 0.00442450165749\n",
      "Epoch 13::Minibatch 979::LR 0.0723076923077 --> Loss 0.00441782911619\n",
      "Epoch 13::Minibatch 980::LR 0.0723076923077 --> Loss 0.00422896742821\n",
      "Epoch 13::Minibatch 981::LR 0.0723076923077 --> Loss 0.00555862228076\n",
      "Epoch 13::Minibatch 982::LR 0.0723076923077 --> Loss 0.0072508875529\n",
      "Epoch 13::Minibatch 983::LR 0.0723076923077 --> Loss 0.00328290025393\n",
      "Epoch 13::Minibatch 984::LR 0.0723076923077 --> Loss 0.0030283121268\n",
      "Epoch 13::Minibatch 985::LR 0.0723076923077 --> Loss 0.00480327049891\n",
      "Epoch 13::Minibatch 986::LR 0.0723076923077 --> Loss 0.00441253582637\n",
      "Epoch 13::Minibatch 987::LR 0.0723076923077 --> Loss 0.00471279501915\n",
      "Epoch 13::Minibatch 988::LR 0.0723076923077 --> Loss 0.00370043635368\n",
      "Epoch 13::Minibatch 989::LR 0.0723076923077 --> Loss 0.00373282710711\n",
      "Epoch 13::Minibatch 990::LR 0.0723076923077 --> Loss 0.00339321454366\n",
      "Epoch 13::Minibatch 991::LR 0.0723076923077 --> Loss 0.00198003172874\n",
      "Epoch 13::Minibatch 992::LR 0.0723076923077 --> Loss 0.00214168071747\n",
      "Epoch 13::Minibatch 993::LR 0.0723076923077 --> Loss 0.00369643529256\n",
      "Epoch 13::Minibatch 994::LR 0.0723076923077 --> Loss 0.00224367817243\n",
      "Epoch 13::Minibatch 995::LR 0.0723076923077 --> Loss 0.000965555707614\n",
      "Epoch 13::Minibatch 996::LR 0.0723076923077 --> Loss 0.00333381970723\n",
      "Epoch 13::Minibatch 997::LR 0.0723076923077 --> Loss 0.00230508883794\n",
      "Epoch 13::Minibatch 998::LR 0.0723076923077 --> Loss 0.00253517210484\n",
      "Epoch 13::Minibatch 999::LR 0.0723076923077 --> Loss 0.00204723954201\n",
      "Epoch 13::Minibatch 1000::LR 0.0723076923077 --> Loss 0.00240651031335\n",
      "Epoch 13::Minibatch 1001::LR 0.0723076923077 --> Loss 0.00199552933375\n",
      "Epoch 13::Minibatch 1002::LR 0.0723076923077 --> Loss 0.00315078854561\n",
      "Epoch 13::Minibatch 1003::LR 0.0723076923077 --> Loss 0.00394598285357\n",
      "Epoch 13::Minibatch 1004::LR 0.0723076923077 --> Loss 0.00109605203072\n",
      "Epoch 13::Minibatch 1005::LR 0.0723076923077 --> Loss 0.00423589070638\n",
      "Epoch 13::Minibatch 1006::LR 0.0723076923077 --> Loss 0.00276796360811\n",
      "Epoch 13::Minibatch 1007::LR 0.0723076923077 --> Loss 0.00295282642047\n",
      "Epoch 13::Minibatch 1008::LR 0.0723076923077 --> Loss 0.00101564625899\n",
      "Epoch 13::Minibatch 1009::LR 0.0723076923077 --> Loss 0.00177873512109\n",
      "Epoch 13::Minibatch 1010::LR 0.0723076923077 --> Loss 0.00148919413487\n",
      "Epoch 13::Minibatch 1011::LR 0.0723076923077 --> Loss 0.00261167426904\n",
      "Epoch 13::Minibatch 1012::LR 0.0723076923077 --> Loss 0.00181012868881\n",
      "Epoch 13::Minibatch 1013::LR 0.0723076923077 --> Loss 0.00469881693522\n",
      "Epoch 13::Minibatch 1014::LR 0.0723076923077 --> Loss 0.00446634173393\n",
      "Epoch 13::Minibatch 1015::LR 0.0723076923077 --> Loss 0.00179040769736\n",
      "Epoch 13::Minibatch 1016::LR 0.0723076923077 --> Loss 0.00520055969556\n",
      "Epoch 13::Minibatch 1017::LR 0.0723076923077 --> Loss 0.00275916119417\n",
      "Epoch 13::Minibatch 1018::LR 0.0723076923077 --> Loss 0.00311731537183\n",
      "Epoch 13::Minibatch 1019::LR 0.0723076923077 --> Loss 0.00218950847785\n",
      "Epoch 13::Minibatch 1020::LR 0.0723076923077 --> Loss 0.00216423491637\n",
      "Epoch 13::Minibatch 1021::LR 0.0723076923077 --> Loss 0.0021251954635\n",
      "Epoch 13::Minibatch 1022::LR 0.0723076923077 --> Loss 0.00161039024591\n",
      "Epoch 13::Minibatch 1023::LR 0.0723076923077 --> Loss 0.0012708418568\n",
      "Epoch 13::Minibatch 1024::LR 0.0723076923077 --> Loss 0.00123733788729\n",
      "Epoch 13::Minibatch 1025::LR 0.0723076923077 --> Loss 0.00145291060209\n",
      "Epoch 13::Minibatch 1026::LR 0.0723076923077 --> Loss 0.000882144868374\n",
      "Epoch 13::Minibatch 1027::LR 0.0723076923077 --> Loss 0.00107627997796\n",
      "Epoch 13::Minibatch 1028::LR 0.0723076923077 --> Loss 0.000826793909073\n",
      "Epoch 13::Minibatch 1029::LR 0.0723076923077 --> Loss 0.000807707111041\n",
      "Epoch 13::Minibatch 1030::LR 0.0723076923077 --> Loss 0.000998399953047\n",
      "Epoch 13::Minibatch 1031::LR 0.0723076923077 --> Loss 0.000780149549246\n",
      "Epoch 13::Minibatch 1032::LR 0.0723076923077 --> Loss 0.000794231494268\n",
      "Epoch 13::Minibatch 1033::LR 0.0723076923077 --> Loss 0.00067511215806\n",
      "Epoch 13::Minibatch 1034::LR 0.0723076923077 --> Loss 0.000663696080446\n",
      "Epoch 13::Minibatch 1035::LR 0.0723076923077 --> Loss 0.000486863851547\n",
      "Epoch 13::Minibatch 1036::LR 0.0723076923077 --> Loss 0.000384114881357\n",
      "Epoch 13::Minibatch 1037::LR 0.0723076923077 --> Loss 0.000583294431369\n",
      "Epoch 13::Minibatch 1038::LR 0.0723076923077 --> Loss 0.00132180641095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13::Minibatch 1039::LR 0.0723076923077 --> Loss 0.00104393770297\n",
      "Epoch 13::Minibatch 1040::LR 0.0723076923077 --> Loss 0.000455005715291\n",
      "Epoch 13::Minibatch 1041::LR 0.0723076923077 --> Loss 0.000616702040037\n",
      "Epoch 14::Minibatch 1::LR 0.07 --> Loss 0.0099099500974\n",
      "Epoch 14::Minibatch 2::LR 0.07 --> Loss 0.0063373541832\n",
      "Epoch 14::Minibatch 3::LR 0.07 --> Loss 0.00421539465586\n",
      "Epoch 14::Minibatch 4::LR 0.07 --> Loss 0.00447508255641\n",
      "Epoch 14::Minibatch 5::LR 0.07 --> Loss 0.0047827343146\n",
      "Epoch 14::Minibatch 6::LR 0.07 --> Loss 0.00248221139113\n",
      "Epoch 14::Minibatch 7::LR 0.07 --> Loss 0.00784235636393\n",
      "Epoch 14::Minibatch 8::LR 0.07 --> Loss 0.00763230403264\n",
      "Epoch 14::Minibatch 9::LR 0.07 --> Loss 0.00552884976069\n",
      "Epoch 14::Minibatch 10::LR 0.07 --> Loss 0.00289335270723\n",
      "Epoch 14::Minibatch 11::LR 0.07 --> Loss 0.00247194985549\n",
      "Epoch 14::Minibatch 12::LR 0.07 --> Loss 0.00355804045995\n",
      "Epoch 14::Minibatch 13::LR 0.07 --> Loss 0.00535127480825\n",
      "Epoch 14::Minibatch 14::LR 0.07 --> Loss 0.00517867525419\n",
      "Epoch 14::Minibatch 15::LR 0.07 --> Loss 0.00423921465874\n",
      "Epoch 14::Minibatch 16::LR 0.07 --> Loss 0.000921095609665\n",
      "Epoch 14::Minibatch 17::LR 0.07 --> Loss 0.00310933033625\n",
      "Epoch 14::Minibatch 18::LR 0.07 --> Loss 0.00250122507413\n",
      "Epoch 14::Minibatch 19::LR 0.07 --> Loss 0.0012123627464\n",
      "Epoch 14::Minibatch 20::LR 0.07 --> Loss 0.0016759343942\n",
      "Epoch 14::Minibatch 21::LR 0.07 --> Loss 0.00323371052742\n",
      "Epoch 14::Minibatch 22::LR 0.07 --> Loss 0.0023311295112\n",
      "Epoch 14::Minibatch 23::LR 0.07 --> Loss 0.000780612727006\n",
      "Epoch 14::Minibatch 24::LR 0.07 --> Loss 0.000363442848126\n",
      "Epoch 14::Minibatch 25::LR 0.07 --> Loss 0.00110645304124\n",
      "Epoch 14::Minibatch 26::LR 0.07 --> Loss 0.00129479438066\n",
      "Epoch 14::Minibatch 27::LR 0.07 --> Loss 0.000913582940896\n",
      "Epoch 14::Minibatch 28::LR 0.07 --> Loss 0.000371018300454\n",
      "Epoch 14::Minibatch 29::LR 0.07 --> Loss 0.000354130168756\n",
      "Epoch 14::Minibatch 30::LR 0.07 --> Loss 0.000836725234985\n",
      "Epoch 14::Minibatch 31::LR 0.07 --> Loss 0.00131114910046\n",
      "Epoch 14::Minibatch 32::LR 0.07 --> Loss 0.00126426210006\n",
      "Epoch 14::Minibatch 33::LR 0.07 --> Loss 0.000777026017507\n",
      "Epoch 14::Minibatch 34::LR 0.07 --> Loss 0.0024846525987\n",
      "Epoch 14::Minibatch 35::LR 0.07 --> Loss 0.00407712499301\n",
      "Epoch 14::Minibatch 36::LR 0.07 --> Loss 0.00218545019627\n",
      "Epoch 14::Minibatch 37::LR 0.07 --> Loss 0.0006193823119\n",
      "Epoch 14::Minibatch 38::LR 0.07 --> Loss 0.000756362428268\n",
      "Epoch 14::Minibatch 39::LR 0.07 --> Loss 0.00246164639791\n",
      "Epoch 14::Minibatch 40::LR 0.07 --> Loss 0.00354801257451\n",
      "Epoch 14::Minibatch 41::LR 0.07 --> Loss 0.00305453638236\n",
      "Epoch 14::Minibatch 42::LR 0.07 --> Loss 0.00617552161217\n",
      "Epoch 14::Minibatch 43::LR 0.07 --> Loss 0.00185846666495\n",
      "Epoch 14::Minibatch 44::LR 0.07 --> Loss 0.00312457680702\n",
      "Epoch 14::Minibatch 45::LR 0.07 --> Loss 0.00254071374734\n",
      "Epoch 14::Minibatch 46::LR 0.07 --> Loss 0.00354907751083\n",
      "Epoch 14::Minibatch 47::LR 0.07 --> Loss 0.00476075371106\n",
      "Epoch 14::Minibatch 48::LR 0.07 --> Loss 0.00612588882446\n",
      "Epoch 14::Minibatch 49::LR 0.07 --> Loss 0.00628391981125\n",
      "Epoch 14::Minibatch 50::LR 0.07 --> Loss 0.00602660576502\n",
      "Epoch 14::Minibatch 51::LR 0.07 --> Loss 0.00804541110992\n",
      "Epoch 14::Minibatch 52::LR 0.07 --> Loss 0.00351942459742\n",
      "Epoch 14::Minibatch 53::LR 0.07 --> Loss 0.00348745425542\n",
      "Epoch 14::Minibatch 54::LR 0.07 --> Loss 0.00402237693469\n",
      "Epoch 14::Minibatch 55::LR 0.07 --> Loss 0.000997927486897\n",
      "Epoch 14::Minibatch 56::LR 0.07 --> Loss 0.00275122880936\n",
      "Epoch 14::Minibatch 57::LR 0.07 --> Loss 0.0059396358331\n",
      "Epoch 14::Minibatch 58::LR 0.07 --> Loss 0.00341109871864\n",
      "Epoch 14::Minibatch 59::LR 0.07 --> Loss 0.00261495669683\n",
      "Epoch 14::Minibatch 60::LR 0.07 --> Loss 0.00241454859575\n",
      "Epoch 14::Minibatch 61::LR 0.07 --> Loss 0.000938606957595\n",
      "Epoch 14::Minibatch 62::LR 0.07 --> Loss 0.00337004184723\n",
      "Epoch 14::Minibatch 63::LR 0.07 --> Loss 0.00220412015915\n",
      "Epoch 14::Minibatch 64::LR 0.07 --> Loss 0.000950644810994\n",
      "Epoch 14::Minibatch 65::LR 0.07 --> Loss 0.00241891781489\n",
      "Epoch 14::Minibatch 66::LR 0.07 --> Loss 0.00293688078721\n",
      "Epoch 14::Minibatch 67::LR 0.07 --> Loss 0.00285030802091\n",
      "Epoch 14::Minibatch 68::LR 0.07 --> Loss 0.00202483773232\n",
      "Epoch 14::Minibatch 69::LR 0.07 --> Loss 0.00407865762711\n",
      "Epoch 14::Minibatch 70::LR 0.07 --> Loss 0.00350046873093\n",
      "Epoch 14::Minibatch 71::LR 0.07 --> Loss 0.00236669103305\n",
      "Epoch 14::Minibatch 72::LR 0.07 --> Loss 0.000547056396802\n",
      "Epoch 14::Minibatch 73::LR 0.07 --> Loss 0.00395867784818\n",
      "Epoch 14::Minibatch 74::LR 0.07 --> Loss 0.00420621395111\n",
      "Epoch 14::Minibatch 75::LR 0.07 --> Loss 0.00256768345833\n",
      "Epoch 14::Minibatch 76::LR 0.07 --> Loss 0.000635657260815\n",
      "Epoch 14::Minibatch 77::LR 0.07 --> Loss 0.00418409029643\n",
      "Epoch 14::Minibatch 78::LR 0.07 --> Loss 0.00390544096629\n",
      "Epoch 14::Minibatch 79::LR 0.07 --> Loss 0.00208882153034\n",
      "Epoch 14::Minibatch 80::LR 0.07 --> Loss 0.0034035384655\n",
      "Epoch 14::Minibatch 81::LR 0.07 --> Loss 0.00293698231379\n",
      "Epoch 14::Minibatch 82::LR 0.07 --> Loss 0.0020553813378\n",
      "Epoch 14::Minibatch 83::LR 0.07 --> Loss 0.00488876223564\n",
      "Epoch 14::Minibatch 84::LR 0.07 --> Loss 0.00207030077775\n",
      "Epoch 14::Minibatch 85::LR 0.07 --> Loss 0.00282792588075\n",
      "Epoch 14::Minibatch 86::LR 0.07 --> Loss 0.00230765422185\n",
      "Epoch 14::Minibatch 87::LR 0.07 --> Loss 0.0025763074557\n",
      "Epoch 14::Minibatch 88::LR 0.07 --> Loss 0.00187522629897\n",
      "Epoch 14::Minibatch 89::LR 0.07 --> Loss 0.00239784499009\n",
      "Epoch 14::Minibatch 90::LR 0.07 --> Loss 0.00121569663286\n",
      "Epoch 14::Minibatch 91::LR 0.07 --> Loss 0.000976246198018\n",
      "Epoch 14::Minibatch 92::LR 0.07 --> Loss 0.00275124569734\n",
      "Epoch 14::Minibatch 93::LR 0.07 --> Loss 0.00181468526522\n",
      "Epoch 14::Minibatch 94::LR 0.07 --> Loss 0.00181200146675\n",
      "Epoch 14::Minibatch 95::LR 0.07 --> Loss 0.00178984324137\n",
      "Epoch 14::Minibatch 96::LR 0.07 --> Loss 0.00608726859093\n",
      "Epoch 14::Minibatch 97::LR 0.07 --> Loss 0.00324170748393\n",
      "Epoch 14::Minibatch 98::LR 0.07 --> Loss 0.000970836381118\n",
      "Epoch 14::Minibatch 99::LR 0.07 --> Loss 0.00130338281393\n",
      "Epoch 14::Minibatch 100::LR 0.07 --> Loss 0.00540539622307\n",
      "Epoch 14::Minibatch 101::LR 0.07 --> Loss 0.000959044198195\n",
      "Epoch 14::Minibatch 102::LR 0.07 --> Loss 0.00383786876996\n",
      "Epoch 14::Minibatch 103::LR 0.07 --> Loss 0.00404710372289\n",
      "Epoch 14::Minibatch 104::LR 0.07 --> Loss 0.00281929115454\n",
      "Epoch 14::Minibatch 105::LR 0.07 --> Loss 0.00299409329891\n",
      "Epoch 14::Minibatch 106::LR 0.07 --> Loss 0.0182444572449\n",
      "Epoch 14::Minibatch 107::LR 0.07 --> Loss 0.00491695483526\n",
      "Epoch 14::Minibatch 108::LR 0.07 --> Loss 0.00113912413518\n",
      "Epoch 14::Minibatch 109::LR 0.07 --> Loss 0.00449734767278\n",
      "Epoch 14::Minibatch 110::LR 0.07 --> Loss 0.00251061121623\n",
      "Epoch 14::Minibatch 111::LR 0.07 --> Loss 0.00105330655972\n",
      "Epoch 14::Minibatch 112::LR 0.07 --> Loss 0.00369104186694\n",
      "Epoch 14::Minibatch 113::LR 0.07 --> Loss 0.0028008500735\n",
      "Epoch 14::Minibatch 114::LR 0.07 --> Loss 0.00154637684425\n",
      "Epoch 14::Minibatch 115::LR 0.07 --> Loss 0.00142466952403\n",
      "Epoch 14::Minibatch 116::LR 0.07 --> Loss 0.00290295283\n",
      "Epoch 14::Minibatch 117::LR 0.07 --> Loss 0.00380080064138\n",
      "Epoch 14::Minibatch 118::LR 0.07 --> Loss 0.00701539675395\n",
      "Epoch 14::Minibatch 119::LR 0.07 --> Loss 0.000719532718261\n",
      "Epoch 14::Minibatch 120::LR 0.07 --> Loss 0.00189857403437\n",
      "Epoch 14::Minibatch 121::LR 0.07 --> Loss 0.0028276860714\n",
      "Epoch 14::Minibatch 122::LR 0.07 --> Loss 0.00374589323997\n",
      "Epoch 14::Minibatch 123::LR 0.07 --> Loss 0.00117848783731\n",
      "Epoch 14::Minibatch 124::LR 0.07 --> Loss 0.00288379271825\n",
      "Epoch 14::Minibatch 125::LR 0.07 --> Loss 0.00475387771924\n",
      "Epoch 14::Minibatch 126::LR 0.07 --> Loss 0.00281762361526\n",
      "Epoch 14::Minibatch 127::LR 0.07 --> Loss 0.0044001921018\n",
      "Epoch 14::Minibatch 128::LR 0.07 --> Loss 0.00368294835091\n",
      "Epoch 14::Minibatch 129::LR 0.07 --> Loss 0.00282133102417\n",
      "Epoch 14::Minibatch 130::LR 0.07 --> Loss 0.00439262111982\n",
      "Epoch 14::Minibatch 131::LR 0.07 --> Loss 0.00185531556606\n",
      "Epoch 14::Minibatch 132::LR 0.07 --> Loss 0.00320518891017\n",
      "Epoch 14::Minibatch 133::LR 0.07 --> Loss 0.00306510667006\n",
      "Epoch 14::Minibatch 134::LR 0.07 --> Loss 0.00249468366305\n",
      "Epoch 14::Minibatch 135::LR 0.07 --> Loss 0.00169375042121\n",
      "Epoch 14::Minibatch 136::LR 0.07 --> Loss 0.00282646020253\n",
      "Epoch 14::Minibatch 137::LR 0.07 --> Loss 0.00376782735189\n",
      "Epoch 14::Minibatch 138::LR 0.07 --> Loss 0.00135376244783\n",
      "Epoch 14::Minibatch 139::LR 0.07 --> Loss 0.00193048099677\n",
      "Epoch 14::Minibatch 140::LR 0.07 --> Loss 0.0024841294686\n",
      "Epoch 14::Minibatch 141::LR 0.07 --> Loss 0.00301467259725\n",
      "Epoch 14::Minibatch 142::LR 0.07 --> Loss 0.00301817397277\n",
      "Epoch 14::Minibatch 143::LR 0.07 --> Loss 0.000632774680853\n",
      "Epoch 14::Minibatch 144::LR 0.07 --> Loss 0.00322707772255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 145::LR 0.07 --> Loss 0.00438457369804\n",
      "Epoch 14::Minibatch 146::LR 0.07 --> Loss 0.00263751745224\n",
      "Epoch 14::Minibatch 147::LR 0.07 --> Loss 0.00184285422166\n",
      "Epoch 14::Minibatch 148::LR 0.07 --> Loss 0.00103499412537\n",
      "Epoch 14::Minibatch 149::LR 0.07 --> Loss 0.00285664995511\n",
      "Epoch 14::Minibatch 150::LR 0.07 --> Loss 0.00276565293471\n",
      "Epoch 14::Minibatch 151::LR 0.07 --> Loss 0.00427112460136\n",
      "Epoch 14::Minibatch 152::LR 0.07 --> Loss 0.000938561360041\n",
      "Epoch 14::Minibatch 153::LR 0.07 --> Loss 0.00187703430653\n",
      "Epoch 14::Minibatch 154::LR 0.07 --> Loss 0.00208115736643\n",
      "Epoch 14::Minibatch 155::LR 0.07 --> Loss 0.00463601271311\n",
      "Epoch 14::Minibatch 156::LR 0.07 --> Loss 0.00244252403577\n",
      "Epoch 14::Minibatch 157::LR 0.07 --> Loss 0.00070669790109\n",
      "Epoch 14::Minibatch 158::LR 0.07 --> Loss 0.00305685063203\n",
      "Epoch 14::Minibatch 159::LR 0.07 --> Loss 0.00278510789076\n",
      "Epoch 14::Minibatch 160::LR 0.07 --> Loss 0.00266706208388\n",
      "Epoch 14::Minibatch 161::LR 0.07 --> Loss 0.00103888054689\n",
      "Epoch 14::Minibatch 162::LR 0.07 --> Loss 0.00370249032974\n",
      "Epoch 14::Minibatch 163::LR 0.07 --> Loss 0.00242739399274\n",
      "Epoch 14::Minibatch 164::LR 0.07 --> Loss 0.00250926574071\n",
      "Epoch 14::Minibatch 165::LR 0.07 --> Loss 0.000544063250224\n",
      "Epoch 14::Minibatch 166::LR 0.07 --> Loss 0.00181936323643\n",
      "Epoch 14::Minibatch 167::LR 0.07 --> Loss 0.00246997952461\n",
      "Epoch 14::Minibatch 168::LR 0.07 --> Loss 0.002212215662\n",
      "Epoch 14::Minibatch 169::LR 0.07 --> Loss 0.00102748095989\n",
      "Epoch 14::Minibatch 170::LR 0.07 --> Loss 0.00100277602673\n",
      "Epoch 14::Minibatch 171::LR 0.07 --> Loss 0.00254109760125\n",
      "Epoch 14::Minibatch 172::LR 0.07 --> Loss 0.00465504248937\n",
      "Epoch 14::Minibatch 173::LR 0.07 --> Loss 0.00197534958522\n",
      "Epoch 14::Minibatch 174::LR 0.07 --> Loss 0.00107023547093\n",
      "Epoch 14::Minibatch 175::LR 0.07 --> Loss 0.00230641444524\n",
      "Epoch 14::Minibatch 176::LR 0.07 --> Loss 0.00334271828334\n",
      "Epoch 14::Minibatch 177::LR 0.07 --> Loss 0.00467272520065\n",
      "Epoch 14::Minibatch 178::LR 0.07 --> Loss 0.00167433460553\n",
      "Epoch 14::Minibatch 179::LR 0.07 --> Loss 0.00139924178521\n",
      "Epoch 14::Minibatch 180::LR 0.07 --> Loss 0.0036781680584\n",
      "Epoch 14::Minibatch 181::LR 0.07 --> Loss 0.00333651860555\n",
      "Epoch 14::Minibatch 182::LR 0.07 --> Loss 0.000807074109713\n",
      "Epoch 14::Minibatch 183::LR 0.07 --> Loss 0.00172354638577\n",
      "Epoch 14::Minibatch 184::LR 0.07 --> Loss 0.00342569192251\n",
      "Epoch 14::Minibatch 185::LR 0.07 --> Loss 0.00287366251151\n",
      "Epoch 14::Minibatch 186::LR 0.07 --> Loss 0.000993819336096\n",
      "Epoch 14::Minibatch 187::LR 0.07 --> Loss 0.00125692933798\n",
      "Epoch 14::Minibatch 188::LR 0.07 --> Loss 0.00419434269269\n",
      "Epoch 14::Minibatch 189::LR 0.07 --> Loss 0.00454925616582\n",
      "Epoch 14::Minibatch 190::LR 0.07 --> Loss 0.00232564111551\n",
      "Epoch 14::Minibatch 191::LR 0.07 --> Loss 0.000497659593821\n",
      "Epoch 14::Minibatch 192::LR 0.07 --> Loss 0.00270074725151\n",
      "Epoch 14::Minibatch 193::LR 0.07 --> Loss 0.00253520389398\n",
      "Epoch 14::Minibatch 194::LR 0.07 --> Loss 0.00180606802305\n",
      "Epoch 14::Minibatch 195::LR 0.07 --> Loss 0.000395870283246\n",
      "Epoch 14::Minibatch 196::LR 0.07 --> Loss 0.00122157722712\n",
      "Epoch 14::Minibatch 197::LR 0.07 --> Loss 0.00284213105838\n",
      "Epoch 14::Minibatch 198::LR 0.07 --> Loss 0.00220030943553\n",
      "Epoch 14::Minibatch 199::LR 0.07 --> Loss 0.000293328861396\n",
      "Epoch 14::Minibatch 200::LR 0.07 --> Loss 0.00208740393321\n",
      "Epoch 14::Minibatch 201::LR 0.07 --> Loss 0.00197391609351\n",
      "Epoch 14::Minibatch 202::LR 0.07 --> Loss 0.0018988887469\n",
      "Epoch 14::Minibatch 203::LR 0.07 --> Loss 0.00181156973044\n",
      "Epoch 14::Minibatch 204::LR 0.07 --> Loss 0.00151214222113\n",
      "Epoch 14::Minibatch 205::LR 0.07 --> Loss 0.00223823726177\n",
      "Epoch 14::Minibatch 206::LR 0.07 --> Loss 0.00680641889572\n",
      "Epoch 14::Minibatch 207::LR 0.07 --> Loss 0.00140497763952\n",
      "Epoch 14::Minibatch 208::LR 0.07 --> Loss 0.00115634004275\n",
      "Epoch 14::Minibatch 209::LR 0.07 --> Loss 0.00215487599373\n",
      "Epoch 14::Minibatch 210::LR 0.07 --> Loss 0.00204822520415\n",
      "Epoch 14::Minibatch 211::LR 0.07 --> Loss 0.00217958966891\n",
      "Epoch 14::Minibatch 212::LR 0.07 --> Loss 0.00410871704419\n",
      "Epoch 14::Minibatch 213::LR 0.07 --> Loss 0.00605939428012\n",
      "Epoch 14::Minibatch 214::LR 0.07 --> Loss 0.00987369298935\n",
      "Epoch 14::Minibatch 215::LR 0.07 --> Loss 0.00143102437258\n",
      "Epoch 14::Minibatch 216::LR 0.07 --> Loss 0.00556761145592\n",
      "Epoch 14::Minibatch 217::LR 0.07 --> Loss 0.00617041548093\n",
      "Epoch 14::Minibatch 218::LR 0.07 --> Loss 0.00400928854942\n",
      "Epoch 14::Minibatch 219::LR 0.07 --> Loss 0.00396752516429\n",
      "Epoch 14::Minibatch 220::LR 0.07 --> Loss 0.00459453304609\n",
      "Epoch 14::Minibatch 221::LR 0.07 --> Loss 0.0043005100886\n",
      "Epoch 14::Minibatch 222::LR 0.07 --> Loss 0.00331149836381\n",
      "Epoch 14::Minibatch 223::LR 0.07 --> Loss 0.00144726922115\n",
      "Epoch 14::Minibatch 224::LR 0.07 --> Loss 0.00184337735176\n",
      "Epoch 14::Minibatch 225::LR 0.07 --> Loss 0.00718157847722\n",
      "Epoch 14::Minibatch 226::LR 0.07 --> Loss 0.00382635951042\n",
      "Epoch 14::Minibatch 227::LR 0.07 --> Loss 0.00171848078569\n",
      "Epoch 14::Minibatch 228::LR 0.07 --> Loss 0.000790590643883\n",
      "Epoch 14::Minibatch 229::LR 0.07 --> Loss 0.00482073346774\n",
      "Epoch 14::Minibatch 230::LR 0.07 --> Loss 0.00401214996974\n",
      "Epoch 14::Minibatch 231::LR 0.07 --> Loss 0.00264551897844\n",
      "Epoch 14::Minibatch 232::LR 0.07 --> Loss 0.00125981509686\n",
      "Epoch 14::Minibatch 233::LR 0.07 --> Loss 0.00243095537027\n",
      "Epoch 14::Minibatch 234::LR 0.07 --> Loss 0.00670772790909\n",
      "Epoch 14::Minibatch 235::LR 0.07 --> Loss 0.00484506289164\n",
      "Epoch 14::Minibatch 236::LR 0.07 --> Loss 0.00181413769722\n",
      "Epoch 14::Minibatch 237::LR 0.07 --> Loss 0.000723514606555\n",
      "Epoch 14::Minibatch 238::LR 0.07 --> Loss 0.00343618273735\n",
      "Epoch 14::Minibatch 239::LR 0.07 --> Loss 0.00297332684199\n",
      "Epoch 14::Minibatch 240::LR 0.07 --> Loss 0.00326576828957\n",
      "Epoch 14::Minibatch 241::LR 0.07 --> Loss 0.000793780485789\n",
      "Epoch 14::Minibatch 242::LR 0.07 --> Loss 0.00719519853592\n",
      "Epoch 14::Minibatch 243::LR 0.07 --> Loss 0.00360685507456\n",
      "Epoch 14::Minibatch 244::LR 0.07 --> Loss 0.00301136930784\n",
      "Epoch 14::Minibatch 245::LR 0.07 --> Loss 0.00049794425567\n",
      "Epoch 14::Minibatch 246::LR 0.07 --> Loss 0.00210970799128\n",
      "Epoch 14::Minibatch 247::LR 0.07 --> Loss 0.013656244278\n",
      "Epoch 14::Minibatch 248::LR 0.07 --> Loss 0.00460058252017\n",
      "Epoch 14::Minibatch 249::LR 0.07 --> Loss 0.00287175814311\n",
      "Epoch 14::Minibatch 250::LR 0.07 --> Loss 0.0027555056413\n",
      "Epoch 14::Minibatch 251::LR 0.07 --> Loss 0.00262937049071\n",
      "Epoch 14::Minibatch 252::LR 0.07 --> Loss 0.00188715279102\n",
      "Epoch 14::Minibatch 253::LR 0.07 --> Loss 0.00319854140282\n",
      "Epoch 14::Minibatch 254::LR 0.07 --> Loss 0.00528718431791\n",
      "Epoch 14::Minibatch 255::LR 0.07 --> Loss 0.00397478222847\n",
      "Epoch 14::Minibatch 256::LR 0.07 --> Loss 0.00174146632353\n",
      "Epoch 14::Minibatch 257::LR 0.07 --> Loss 0.00130502839883\n",
      "Epoch 14::Minibatch 258::LR 0.07 --> Loss 0.00365539431572\n",
      "Epoch 14::Minibatch 259::LR 0.07 --> Loss 0.0018683218956\n",
      "Epoch 14::Minibatch 260::LR 0.07 --> Loss 0.00193172872066\n",
      "Epoch 14::Minibatch 261::LR 0.07 --> Loss 0.00298228144646\n",
      "Epoch 14::Minibatch 262::LR 0.07 --> Loss 0.00198750933011\n",
      "Epoch 14::Minibatch 263::LR 0.07 --> Loss 0.00240687827269\n",
      "Epoch 14::Minibatch 264::LR 0.07 --> Loss 0.00368686358134\n",
      "Epoch 14::Minibatch 265::LR 0.07 --> Loss 0.0103001570702\n",
      "Epoch 14::Minibatch 266::LR 0.07 --> Loss 0.00105754166842\n",
      "Epoch 14::Minibatch 267::LR 0.07 --> Loss 0.0102218453089\n",
      "Epoch 14::Minibatch 268::LR 0.07 --> Loss 0.0012435773015\n",
      "Epoch 14::Minibatch 269::LR 0.07 --> Loss 0.00356297930082\n",
      "Epoch 14::Minibatch 270::LR 0.07 --> Loss 0.00654945731163\n",
      "Epoch 14::Minibatch 271::LR 0.07 --> Loss 0.0028052932024\n",
      "Epoch 14::Minibatch 272::LR 0.07 --> Loss 0.00407932678858\n",
      "Epoch 14::Minibatch 273::LR 0.07 --> Loss 0.00174819429715\n",
      "Epoch 14::Minibatch 274::LR 0.07 --> Loss 0.00182112872601\n",
      "Epoch 14::Minibatch 275::LR 0.07 --> Loss 0.00272164185842\n",
      "Epoch 14::Minibatch 276::LR 0.07 --> Loss 0.00350365360578\n",
      "Epoch 14::Minibatch 277::LR 0.07 --> Loss 0.00104000608126\n",
      "Epoch 14::Minibatch 278::LR 0.07 --> Loss 0.00266534050306\n",
      "Epoch 14::Minibatch 279::LR 0.07 --> Loss 0.00245273947716\n",
      "Epoch 14::Minibatch 280::LR 0.07 --> Loss 0.00213046014309\n",
      "Epoch 14::Minibatch 281::LR 0.07 --> Loss 0.00133733451366\n",
      "Epoch 14::Minibatch 282::LR 0.07 --> Loss 0.00226444343726\n",
      "Epoch 14::Minibatch 283::LR 0.07 --> Loss 0.00222215950489\n",
      "Epoch 14::Minibatch 284::LR 0.07 --> Loss 0.00177176256975\n",
      "Epoch 14::Minibatch 285::LR 0.07 --> Loss 0.0012333698074\n",
      "Epoch 14::Minibatch 286::LR 0.07 --> Loss 0.00216785391172\n",
      "Epoch 14::Minibatch 287::LR 0.07 --> Loss 0.00209792554379\n",
      "Epoch 14::Minibatch 288::LR 0.07 --> Loss 0.00112543980281\n",
      "Epoch 14::Minibatch 289::LR 0.07 --> Loss 0.00158481518428\n",
      "Epoch 14::Minibatch 290::LR 0.07 --> Loss 0.0019577930371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 291::LR 0.07 --> Loss 0.00174458662669\n",
      "Epoch 14::Minibatch 292::LR 0.07 --> Loss 0.000613277554512\n",
      "Epoch 14::Minibatch 293::LR 0.07 --> Loss 0.00148850301901\n",
      "Epoch 14::Minibatch 294::LR 0.07 --> Loss 0.00156657387813\n",
      "Epoch 14::Minibatch 295::LR 0.07 --> Loss 0.0018522053957\n",
      "Epoch 14::Minibatch 296::LR 0.07 --> Loss 0.00160300622384\n",
      "Epoch 14::Minibatch 297::LR 0.07 --> Loss 0.00139475266139\n",
      "Epoch 14::Minibatch 298::LR 0.07 --> Loss 0.00137660294771\n",
      "Epoch 14::Minibatch 299::LR 0.07 --> Loss 0.000799924681584\n",
      "Epoch 14::Minibatch 300::LR 0.07 --> Loss 0.00285030980905\n",
      "Epoch 14::Minibatch 301::LR 0.07 --> Loss 0.00276311298211\n",
      "Epoch 14::Minibatch 302::LR 0.07 --> Loss 0.00256711681684\n",
      "Epoch 14::Minibatch 303::LR 0.07 --> Loss 0.000870116055012\n",
      "Epoch 14::Minibatch 304::LR 0.07 --> Loss 0.00314047535261\n",
      "Epoch 14::Minibatch 305::LR 0.07 --> Loss 0.00169360478719\n",
      "Epoch 14::Minibatch 306::LR 0.07 --> Loss 0.000931740005811\n",
      "Epoch 14::Minibatch 307::LR 0.07 --> Loss 0.00247045397758\n",
      "Epoch 14::Minibatch 308::LR 0.07 --> Loss 0.00198574463526\n",
      "Epoch 14::Minibatch 309::LR 0.07 --> Loss 0.000997559328874\n",
      "Epoch 14::Minibatch 310::LR 0.07 --> Loss 0.0011003224055\n",
      "Epoch 14::Minibatch 311::LR 0.07 --> Loss 0.00169872105122\n",
      "Epoch 14::Minibatch 312::LR 0.07 --> Loss 0.00300181825956\n",
      "Epoch 14::Minibatch 313::LR 0.07 --> Loss 0.00240608155727\n",
      "Epoch 14::Minibatch 314::LR 0.07 --> Loss 0.00192097008228\n",
      "Epoch 14::Minibatch 315::LR 0.07 --> Loss 0.000987979670366\n",
      "Epoch 14::Minibatch 316::LR 0.07 --> Loss 0.0023326943318\n",
      "Epoch 14::Minibatch 317::LR 0.07 --> Loss 0.0015479584535\n",
      "Epoch 14::Minibatch 318::LR 0.07 --> Loss 0.00120443989833\n",
      "Epoch 14::Minibatch 319::LR 0.07 --> Loss 0.00229409853617\n",
      "Epoch 14::Minibatch 320::LR 0.07 --> Loss 0.00324701348941\n",
      "Epoch 14::Minibatch 321::LR 0.07 --> Loss 0.000871782203515\n",
      "Epoch 14::Minibatch 322::LR 0.07 --> Loss 0.00369293212891\n",
      "Epoch 14::Minibatch 323::LR 0.07 --> Loss 0.00358024080594\n",
      "Epoch 14::Minibatch 324::LR 0.07 --> Loss 0.00263982752959\n",
      "Epoch 14::Minibatch 325::LR 0.07 --> Loss 0.00242226580779\n",
      "Epoch 14::Minibatch 326::LR 0.07 --> Loss 0.00555381536484\n",
      "Epoch 14::Minibatch 327::LR 0.07 --> Loss 0.00227450589339\n",
      "Epoch 14::Minibatch 328::LR 0.07 --> Loss 0.00337032079697\n",
      "Epoch 14::Minibatch 329::LR 0.07 --> Loss 0.00125003278255\n",
      "Epoch 14::Minibatch 330::LR 0.07 --> Loss 0.00162337362766\n",
      "Epoch 14::Minibatch 331::LR 0.07 --> Loss 0.00256937702497\n",
      "Epoch 14::Minibatch 332::LR 0.07 --> Loss 0.00252714256446\n",
      "Epoch 14::Minibatch 333::LR 0.07 --> Loss 0.0014621151487\n",
      "Epoch 14::Minibatch 334::LR 0.07 --> Loss 0.00435791015625\n",
      "Epoch 14::Minibatch 335::LR 0.07 --> Loss 0.00189947783947\n",
      "Epoch 14::Minibatch 336::LR 0.07 --> Loss 0.00212913274765\n",
      "Epoch 14::Minibatch 337::LR 0.07 --> Loss 0.0033781349659\n",
      "Epoch 14::Minibatch 338::LR 0.07 --> Loss 0.000520872374376\n",
      "Epoch 14::Minibatch 339::LR 0.07 --> Loss 0.00332368095716\n",
      "Epoch 14::Minibatch 340::LR 0.07 --> Loss 0.00432332634926\n",
      "Epoch 14::Minibatch 341::LR 0.07 --> Loss 0.0049961121877\n",
      "Epoch 14::Minibatch 342::LR 0.07 --> Loss 0.00321904778481\n",
      "Epoch 14::Minibatch 343::LR 0.07 --> Loss 0.00171601593494\n",
      "Epoch 14::Minibatch 344::LR 0.07 --> Loss 0.00310582359632\n",
      "Epoch 14::Minibatch 345::LR 0.07 --> Loss 0.0043265457948\n",
      "Epoch 14::Minibatch 346::LR 0.07 --> Loss 0.00571332971255\n",
      "Epoch 14::Minibatch 347::LR 0.07 --> Loss 0.000892378985882\n",
      "Epoch 14::Minibatch 348::LR 0.07 --> Loss 0.00351841807365\n",
      "Epoch 14::Minibatch 349::LR 0.07 --> Loss 0.00353722016017\n",
      "Epoch 14::Minibatch 350::LR 0.07 --> Loss 0.00183332264423\n",
      "Epoch 14::Minibatch 351::LR 0.07 --> Loss 0.00357449650764\n",
      "Epoch 14::Minibatch 352::LR 0.07 --> Loss 0.00486069003741\n",
      "Epoch 14::Minibatch 353::LR 0.07 --> Loss 0.0035647670428\n",
      "Epoch 14::Minibatch 354::LR 0.07 --> Loss 0.00295592745145\n",
      "Epoch 14::Minibatch 355::LR 0.07 --> Loss 0.00617987672488\n",
      "Epoch 14::Minibatch 356::LR 0.07 --> Loss 0.00314519663652\n",
      "Epoch 14::Minibatch 357::LR 0.07 --> Loss 0.00118189195792\n",
      "Epoch 14::Minibatch 358::LR 0.07 --> Loss 0.00220483024915\n",
      "Epoch 14::Minibatch 359::LR 0.07 --> Loss 0.00275289058685\n",
      "Epoch 14::Minibatch 360::LR 0.07 --> Loss 0.00246072908243\n",
      "Epoch 14::Minibatch 361::LR 0.07 --> Loss 0.00245153645674\n",
      "Epoch 14::Minibatch 362::LR 0.07 --> Loss 0.00244971017043\n",
      "Epoch 14::Minibatch 363::LR 0.07 --> Loss 0.000681632707516\n",
      "Epoch 14::Minibatch 364::LR 0.07 --> Loss 0.00202491541704\n",
      "Epoch 14::Minibatch 365::LR 0.07 --> Loss 0.00211980005105\n",
      "Epoch 14::Minibatch 366::LR 0.07 --> Loss 0.002280930082\n",
      "Epoch 14::Minibatch 367::LR 0.07 --> Loss 0.00111198763053\n",
      "Epoch 14::Minibatch 368::LR 0.07 --> Loss 0.000997785727183\n",
      "Epoch 14::Minibatch 369::LR 0.07 --> Loss 0.00290079474449\n",
      "Epoch 14::Minibatch 370::LR 0.07 --> Loss 0.00227964282036\n",
      "Epoch 14::Minibatch 371::LR 0.07 --> Loss 0.00188385049502\n",
      "Epoch 14::Minibatch 372::LR 0.07 --> Loss 0.000446426620086\n",
      "Epoch 14::Minibatch 373::LR 0.07 --> Loss 0.00176719824473\n",
      "Epoch 14::Minibatch 374::LR 0.07 --> Loss 0.00217570324739\n",
      "Epoch 14::Minibatch 375::LR 0.07 --> Loss 0.00184214433034\n",
      "Epoch 14::Minibatch 376::LR 0.07 --> Loss 0.00124689429998\n",
      "Epoch 14::Minibatch 377::LR 0.07 --> Loss 0.00195649445057\n",
      "Epoch 14::Minibatch 378::LR 0.07 --> Loss 0.00213548223178\n",
      "Epoch 14::Minibatch 379::LR 0.07 --> Loss 0.00239062428474\n",
      "Epoch 14::Minibatch 380::LR 0.07 --> Loss 0.00159888744354\n",
      "Epoch 14::Minibatch 381::LR 0.07 --> Loss 0.000987440447013\n",
      "Epoch 14::Minibatch 382::LR 0.07 --> Loss 0.00201389273008\n",
      "Epoch 14::Minibatch 383::LR 0.07 --> Loss 0.00195351560911\n",
      "Epoch 14::Minibatch 384::LR 0.07 --> Loss 0.00105170985063\n",
      "Epoch 14::Minibatch 385::LR 0.07 --> Loss 0.00103811740875\n",
      "Epoch 14::Minibatch 386::LR 0.07 --> Loss 0.00218280593554\n",
      "Epoch 14::Minibatch 387::LR 0.07 --> Loss 0.00233530501525\n",
      "Epoch 14::Minibatch 388::LR 0.07 --> Loss 0.00114616056283\n",
      "Epoch 14::Minibatch 389::LR 0.07 --> Loss 0.00181525190671\n",
      "Epoch 14::Minibatch 390::LR 0.07 --> Loss 0.00362554232279\n",
      "Epoch 14::Minibatch 391::LR 0.07 --> Loss 0.00270412246386\n",
      "Epoch 14::Minibatch 392::LR 0.07 --> Loss 0.00267071863015\n",
      "Epoch 14::Minibatch 393::LR 0.07 --> Loss 0.0027851575613\n",
      "Epoch 14::Minibatch 394::LR 0.07 --> Loss 0.00208151956399\n",
      "Epoch 14::Minibatch 395::LR 0.07 --> Loss 0.00205964565277\n",
      "Epoch 14::Minibatch 396::LR 0.07 --> Loss 0.00195910294851\n",
      "Epoch 14::Minibatch 397::LR 0.07 --> Loss 0.0020842285951\n",
      "Epoch 14::Minibatch 398::LR 0.07 --> Loss 0.00206824938456\n",
      "Epoch 14::Minibatch 399::LR 0.07 --> Loss 0.00236989657084\n",
      "Epoch 14::Minibatch 400::LR 0.07 --> Loss 0.00202391008536\n",
      "Epoch 14::Minibatch 401::LR 0.07 --> Loss 0.00353151043256\n",
      "Epoch 14::Minibatch 402::LR 0.07 --> Loss 0.00182895600796\n",
      "Epoch 14::Minibatch 403::LR 0.07 --> Loss 0.00146694660187\n",
      "Epoch 14::Minibatch 404::LR 0.07 --> Loss 0.00152708431085\n",
      "Epoch 14::Minibatch 405::LR 0.07 --> Loss 0.00356551369031\n",
      "Epoch 14::Minibatch 406::LR 0.07 --> Loss 0.00248565793037\n",
      "Epoch 14::Minibatch 407::LR 0.07 --> Loss 0.00175467530886\n",
      "Epoch 14::Minibatch 408::LR 0.07 --> Loss 0.000450833886862\n",
      "Epoch 14::Minibatch 409::LR 0.07 --> Loss 0.0023681606849\n",
      "Epoch 14::Minibatch 410::LR 0.07 --> Loss 0.00324441512426\n",
      "Epoch 14::Minibatch 411::LR 0.07 --> Loss 0.00164585997661\n",
      "Epoch 14::Minibatch 412::LR 0.07 --> Loss 0.000973441501458\n",
      "Epoch 14::Minibatch 413::LR 0.07 --> Loss 0.00198575079441\n",
      "Epoch 14::Minibatch 414::LR 0.07 --> Loss 0.00182840764523\n",
      "Epoch 14::Minibatch 415::LR 0.07 --> Loss 0.00114712725083\n",
      "Epoch 14::Minibatch 416::LR 0.07 --> Loss 0.000827776640654\n",
      "Epoch 14::Minibatch 417::LR 0.07 --> Loss 0.00171074608962\n",
      "Epoch 14::Minibatch 418::LR 0.07 --> Loss 0.00282137135665\n",
      "Epoch 14::Minibatch 419::LR 0.07 --> Loss 0.000503327399492\n",
      "Epoch 14::Minibatch 420::LR 0.07 --> Loss 0.000695187797149\n",
      "Epoch 14::Minibatch 421::LR 0.07 --> Loss 0.00193168342113\n",
      "Epoch 14::Minibatch 422::LR 0.07 --> Loss 0.00215787549814\n",
      "Epoch 14::Minibatch 423::LR 0.07 --> Loss 0.000959496100744\n",
      "Epoch 14::Minibatch 424::LR 0.07 --> Loss 0.00156507780155\n",
      "Epoch 14::Minibatch 425::LR 0.07 --> Loss 0.00289682606856\n",
      "Epoch 14::Minibatch 426::LR 0.07 --> Loss 0.00200507084529\n",
      "Epoch 14::Minibatch 427::LR 0.07 --> Loss 0.000707017878691\n",
      "Epoch 14::Minibatch 428::LR 0.07 --> Loss 0.00106744478146\n",
      "Epoch 14::Minibatch 429::LR 0.07 --> Loss 0.00242401858171\n",
      "Epoch 14::Minibatch 430::LR 0.07 --> Loss 0.00951706171036\n",
      "Epoch 14::Minibatch 431::LR 0.07 --> Loss 0.00378053267797\n",
      "Epoch 14::Minibatch 432::LR 0.07 --> Loss 0.00449331482251\n",
      "Epoch 14::Minibatch 433::LR 0.07 --> Loss 0.00258817672729\n",
      "Epoch 14::Minibatch 434::LR 0.07 --> Loss 0.00255660573641\n",
      "Epoch 14::Minibatch 435::LR 0.07 --> Loss 0.00237609465917\n",
      "Epoch 14::Minibatch 436::LR 0.07 --> Loss 0.0017387642463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 437::LR 0.07 --> Loss 0.00336899280548\n",
      "Epoch 14::Minibatch 438::LR 0.07 --> Loss 0.00268251876036\n",
      "Epoch 14::Minibatch 439::LR 0.07 --> Loss 0.00215359767278\n",
      "Epoch 14::Minibatch 440::LR 0.07 --> Loss 0.00329720298449\n",
      "Epoch 14::Minibatch 441::LR 0.07 --> Loss 0.00308962881565\n",
      "Epoch 14::Minibatch 442::LR 0.07 --> Loss 0.00283569574356\n",
      "Epoch 14::Minibatch 443::LR 0.07 --> Loss 0.00374008138975\n",
      "Epoch 14::Minibatch 444::LR 0.07 --> Loss 0.00293490509192\n",
      "Epoch 14::Minibatch 445::LR 0.07 --> Loss 0.000912476380666\n",
      "Epoch 14::Minibatch 446::LR 0.07 --> Loss 0.00148551235596\n",
      "Epoch 14::Minibatch 447::LR 0.07 --> Loss 0.00247624496619\n",
      "Epoch 14::Minibatch 448::LR 0.07 --> Loss 0.00244510670503\n",
      "Epoch 14::Minibatch 449::LR 0.07 --> Loss 0.00377626379331\n",
      "Epoch 14::Minibatch 450::LR 0.07 --> Loss 0.00236182312171\n",
      "Epoch 14::Minibatch 451::LR 0.07 --> Loss 0.00409633715947\n",
      "Epoch 14::Minibatch 452::LR 0.07 --> Loss 0.00240563432376\n",
      "Epoch 14::Minibatch 453::LR 0.07 --> Loss 0.000391953016321\n",
      "Epoch 14::Minibatch 454::LR 0.07 --> Loss 0.0036199426651\n",
      "Epoch 14::Minibatch 455::LR 0.07 --> Loss 0.00272460440795\n",
      "Epoch 14::Minibatch 456::LR 0.07 --> Loss 0.00316735804081\n",
      "Epoch 14::Minibatch 457::LR 0.07 --> Loss 0.00199291626612\n",
      "Epoch 14::Minibatch 458::LR 0.07 --> Loss 0.000780197481314\n",
      "Epoch 14::Minibatch 459::LR 0.07 --> Loss 0.00414024392764\n",
      "Epoch 14::Minibatch 460::LR 0.07 --> Loss 0.0026347609361\n",
      "Epoch 14::Minibatch 461::LR 0.07 --> Loss 0.00395388126373\n",
      "Epoch 14::Minibatch 462::LR 0.07 --> Loss 0.000406108597914\n",
      "Epoch 14::Minibatch 463::LR 0.07 --> Loss 0.00453963955243\n",
      "Epoch 14::Minibatch 464::LR 0.07 --> Loss 0.00206550518672\n",
      "Epoch 14::Minibatch 465::LR 0.07 --> Loss 0.00532480478287\n",
      "Epoch 14::Minibatch 466::LR 0.07 --> Loss 0.00515892306964\n",
      "Epoch 14::Minibatch 467::LR 0.07 --> Loss 0.00589951038361\n",
      "Epoch 14::Minibatch 468::LR 0.07 --> Loss 0.00616862575213\n",
      "Epoch 14::Minibatch 469::LR 0.07 --> Loss 0.00623994509379\n",
      "Epoch 14::Minibatch 470::LR 0.07 --> Loss 0.00382597168287\n",
      "Epoch 14::Minibatch 471::LR 0.07 --> Loss 0.00177596509457\n",
      "Epoch 14::Minibatch 472::LR 0.07 --> Loss 0.00353835384051\n",
      "Epoch 14::Minibatch 473::LR 0.07 --> Loss 0.00223420639833\n",
      "Epoch 14::Minibatch 474::LR 0.07 --> Loss 0.000711212307215\n",
      "Epoch 14::Minibatch 475::LR 0.07 --> Loss 0.00526085058848\n",
      "Epoch 14::Minibatch 476::LR 0.07 --> Loss 0.00779334465663\n",
      "Epoch 14::Minibatch 477::LR 0.07 --> Loss 0.000945992966493\n",
      "Epoch 14::Minibatch 478::LR 0.07 --> Loss 0.00247098167737\n",
      "Epoch 14::Minibatch 479::LR 0.07 --> Loss 0.00195974608262\n",
      "Epoch 14::Minibatch 480::LR 0.07 --> Loss 0.00153571456671\n",
      "Epoch 14::Minibatch 481::LR 0.07 --> Loss 0.000960921943188\n",
      "Epoch 14::Minibatch 482::LR 0.07 --> Loss 0.00210453530153\n",
      "Epoch 14::Minibatch 483::LR 0.07 --> Loss 0.00322532097499\n",
      "Epoch 14::Minibatch 484::LR 0.07 --> Loss 0.00358706394831\n",
      "Epoch 14::Minibatch 485::LR 0.07 --> Loss 0.00076305458943\n",
      "Epoch 14::Minibatch 486::LR 0.07 --> Loss 0.00301753044128\n",
      "Epoch 14::Minibatch 487::LR 0.07 --> Loss 0.00340234239896\n",
      "Epoch 14::Minibatch 488::LR 0.07 --> Loss 0.00205104331175\n",
      "Epoch 14::Minibatch 489::LR 0.07 --> Loss 0.00316956619422\n",
      "Epoch 14::Minibatch 490::LR 0.07 --> Loss 0.000416263590256\n",
      "Epoch 14::Minibatch 491::LR 0.07 --> Loss 0.00387776811918\n",
      "Epoch 14::Minibatch 492::LR 0.07 --> Loss 0.00304963827133\n",
      "Epoch 14::Minibatch 493::LR 0.07 --> Loss 0.00303033828735\n",
      "Epoch 14::Minibatch 494::LR 0.07 --> Loss 0.000744518538316\n",
      "Epoch 14::Minibatch 495::LR 0.07 --> Loss 0.00188659667969\n",
      "Epoch 14::Minibatch 496::LR 0.07 --> Loss 0.00293302794298\n",
      "Epoch 14::Minibatch 497::LR 0.07 --> Loss 0.000943596164385\n",
      "Epoch 14::Minibatch 498::LR 0.07 --> Loss 0.000577744543552\n",
      "Epoch 14::Minibatch 499::LR 0.07 --> Loss 0.00370802561442\n",
      "Epoch 14::Minibatch 500::LR 0.07 --> Loss 0.00144938548406\n",
      "Epoch 14::Minibatch 501::LR 0.07 --> Loss 0.00225130677223\n",
      "Epoch 14::Minibatch 502::LR 0.07 --> Loss 0.00388655821482\n",
      "Epoch 14::Minibatch 503::LR 0.07 --> Loss 0.00875597556432\n",
      "Epoch 14::Minibatch 504::LR 0.07 --> Loss 0.00801047086716\n",
      "Epoch 14::Minibatch 505::LR 0.07 --> Loss 0.00434695045153\n",
      "Epoch 14::Minibatch 506::LR 0.07 --> Loss 0.00350317358971\n",
      "Epoch 14::Minibatch 507::LR 0.07 --> Loss 0.00606312036514\n",
      "Epoch 14::Minibatch 508::LR 0.07 --> Loss 0.00341279029846\n",
      "Epoch 14::Minibatch 509::LR 0.07 --> Loss 0.00464976708094\n",
      "Epoch 14::Minibatch 510::LR 0.07 --> Loss 0.0046350924174\n",
      "Epoch 14::Minibatch 511::LR 0.07 --> Loss 0.00391150156657\n",
      "Epoch 14::Minibatch 512::LR 0.07 --> Loss 0.00269071896871\n",
      "Epoch 14::Minibatch 513::LR 0.07 --> Loss 0.000658389627934\n",
      "Epoch 14::Minibatch 514::LR 0.07 --> Loss 0.00262235045433\n",
      "Epoch 14::Minibatch 515::LR 0.07 --> Loss 0.00302144169807\n",
      "Epoch 14::Minibatch 516::LR 0.07 --> Loss 0.00412863453229\n",
      "Epoch 14::Minibatch 517::LR 0.07 --> Loss 0.00348324577014\n",
      "Epoch 14::Minibatch 518::LR 0.07 --> Loss 0.00256724337737\n",
      "Epoch 14::Minibatch 519::LR 0.07 --> Loss 0.00344192028046\n",
      "Epoch 14::Minibatch 520::LR 0.07 --> Loss 0.00538853208224\n",
      "Epoch 14::Minibatch 521::LR 0.07 --> Loss 0.0054516518116\n",
      "Epoch 14::Minibatch 522::LR 0.07 --> Loss 0.00807241360346\n",
      "Epoch 14::Minibatch 523::LR 0.07 --> Loss 0.000668874979019\n",
      "Epoch 14::Minibatch 524::LR 0.07 --> Loss 0.00143831580877\n",
      "Epoch 14::Minibatch 525::LR 0.07 --> Loss 0.0032553233703\n",
      "Epoch 14::Minibatch 526::LR 0.07 --> Loss 0.00410434007645\n",
      "Epoch 14::Minibatch 527::LR 0.07 --> Loss 0.00228954235713\n",
      "Epoch 14::Minibatch 528::LR 0.07 --> Loss 0.00108626534541\n",
      "Epoch 14::Minibatch 529::LR 0.07 --> Loss 0.00413595716159\n",
      "Epoch 14::Minibatch 530::LR 0.07 --> Loss 0.00421839872996\n",
      "Epoch 14::Minibatch 531::LR 0.07 --> Loss 0.00365803162257\n",
      "Epoch 14::Minibatch 532::LR 0.07 --> Loss 0.00273252109687\n",
      "Epoch 14::Minibatch 533::LR 0.07 --> Loss 0.00497683445613\n",
      "Epoch 14::Minibatch 534::LR 0.07 --> Loss 0.00385864416758\n",
      "Epoch 14::Minibatch 535::LR 0.07 --> Loss 0.00324610809485\n",
      "Epoch 14::Minibatch 536::LR 0.07 --> Loss 0.00211531142394\n",
      "Epoch 14::Minibatch 537::LR 0.07 --> Loss 0.000640894273917\n",
      "Epoch 14::Minibatch 538::LR 0.07 --> Loss 0.0017117802302\n",
      "Epoch 14::Minibatch 539::LR 0.07 --> Loss 0.0034559349219\n",
      "Epoch 14::Minibatch 540::LR 0.07 --> Loss 0.00342798153559\n",
      "Epoch 14::Minibatch 541::LR 0.07 --> Loss 0.00292110582193\n",
      "Epoch 14::Minibatch 542::LR 0.07 --> Loss 0.00255286812782\n",
      "Epoch 14::Minibatch 543::LR 0.07 --> Loss 0.00278520564238\n",
      "Epoch 14::Minibatch 544::LR 0.07 --> Loss 0.00391755461693\n",
      "Epoch 14::Minibatch 545::LR 0.07 --> Loss 0.00206292450428\n",
      "Epoch 14::Minibatch 546::LR 0.07 --> Loss 0.000663950145245\n",
      "Epoch 14::Minibatch 547::LR 0.07 --> Loss 0.00264252344767\n",
      "Epoch 14::Minibatch 548::LR 0.07 --> Loss 0.00375612894694\n",
      "Epoch 14::Minibatch 549::LR 0.07 --> Loss 0.00837287425995\n",
      "Epoch 14::Minibatch 550::LR 0.07 --> Loss 0.00117293417454\n",
      "Epoch 14::Minibatch 551::LR 0.07 --> Loss 0.00246567924817\n",
      "Epoch 14::Minibatch 552::LR 0.07 --> Loss 0.00360071619352\n",
      "Epoch 14::Minibatch 553::LR 0.07 --> Loss 0.00325103481611\n",
      "Epoch 14::Minibatch 554::LR 0.07 --> Loss 0.00378590703011\n",
      "Epoch 14::Minibatch 555::LR 0.07 --> Loss 0.00099660774072\n",
      "Epoch 14::Minibatch 556::LR 0.07 --> Loss 0.0020234922568\n",
      "Epoch 14::Minibatch 557::LR 0.07 --> Loss 0.00246315836906\n",
      "Epoch 14::Minibatch 558::LR 0.07 --> Loss 0.00372899731\n",
      "Epoch 14::Minibatch 559::LR 0.07 --> Loss 0.00376687407494\n",
      "Epoch 14::Minibatch 560::LR 0.07 --> Loss 0.00309766948223\n",
      "Epoch 14::Minibatch 561::LR 0.07 --> Loss 0.00274686714013\n",
      "Epoch 14::Minibatch 562::LR 0.07 --> Loss 0.00239438990752\n",
      "Epoch 14::Minibatch 563::LR 0.07 --> Loss 0.00404019912084\n",
      "Epoch 14::Minibatch 564::LR 0.07 --> Loss 0.00314640899499\n",
      "Epoch 14::Minibatch 565::LR 0.07 --> Loss 0.00371904452642\n",
      "Epoch 14::Minibatch 566::LR 0.07 --> Loss 0.00231580038865\n",
      "Epoch 14::Minibatch 567::LR 0.07 --> Loss 0.00260297993819\n",
      "Epoch 14::Minibatch 568::LR 0.07 --> Loss 0.0018361200889\n",
      "Epoch 14::Minibatch 569::LR 0.07 --> Loss 0.000570258200169\n",
      "Epoch 14::Minibatch 570::LR 0.07 --> Loss 0.00172737995783\n",
      "Epoch 14::Minibatch 571::LR 0.07 --> Loss 0.0022651642561\n",
      "Epoch 14::Minibatch 572::LR 0.07 --> Loss 0.00240466256936\n",
      "Epoch 14::Minibatch 573::LR 0.07 --> Loss 0.00152707745632\n",
      "Epoch 14::Minibatch 574::LR 0.07 --> Loss 0.00105498373508\n",
      "Epoch 14::Minibatch 575::LR 0.07 --> Loss 0.00180479427179\n",
      "Epoch 14::Minibatch 576::LR 0.07 --> Loss 0.0021488704284\n",
      "Epoch 14::Minibatch 577::LR 0.07 --> Loss 0.00168283045292\n",
      "Epoch 14::Minibatch 578::LR 0.07 --> Loss 0.00129825194677\n",
      "Epoch 14::Minibatch 579::LR 0.07 --> Loss 0.0012112719814\n",
      "Epoch 14::Minibatch 580::LR 0.07 --> Loss 0.00196155289809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 581::LR 0.07 --> Loss 0.00172617952029\n",
      "Epoch 14::Minibatch 582::LR 0.07 --> Loss 0.00412777940432\n",
      "Epoch 14::Minibatch 583::LR 0.07 --> Loss 0.000946681698163\n",
      "Epoch 14::Minibatch 584::LR 0.07 --> Loss 0.00131571471691\n",
      "Epoch 14::Minibatch 585::LR 0.07 --> Loss 0.00459333618482\n",
      "Epoch 14::Minibatch 586::LR 0.07 --> Loss 0.00407766977946\n",
      "Epoch 14::Minibatch 587::LR 0.07 --> Loss 0.00113976975282\n",
      "Epoch 14::Minibatch 588::LR 0.07 --> Loss 0.00142454057932\n",
      "Epoch 14::Minibatch 589::LR 0.07 --> Loss 0.00277697066466\n",
      "Epoch 14::Minibatch 590::LR 0.07 --> Loss 0.00199581106504\n",
      "Epoch 14::Minibatch 591::LR 0.07 --> Loss 0.00312398950259\n",
      "Epoch 14::Minibatch 592::LR 0.07 --> Loss 0.0011909198761\n",
      "Epoch 14::Minibatch 593::LR 0.07 --> Loss 0.00263336340586\n",
      "Epoch 14::Minibatch 594::LR 0.07 --> Loss 0.00279552261035\n",
      "Epoch 14::Minibatch 595::LR 0.07 --> Loss 0.00305812021097\n",
      "Epoch 14::Minibatch 596::LR 0.07 --> Loss 0.00196995417277\n",
      "Epoch 14::Minibatch 597::LR 0.07 --> Loss 0.00120274742444\n",
      "Epoch 14::Minibatch 598::LR 0.07 --> Loss 0.00307376643022\n",
      "Epoch 14::Minibatch 599::LR 0.07 --> Loss 0.0018777324756\n",
      "Epoch 14::Minibatch 600::LR 0.07 --> Loss 0.00224796414375\n",
      "Epoch 14::Minibatch 601::LR 0.07 --> Loss 0.00393086155256\n",
      "Epoch 14::Minibatch 602::LR 0.07 --> Loss 0.00213491857052\n",
      "Epoch 14::Minibatch 603::LR 0.07 --> Loss 0.00266165057818\n",
      "Epoch 14::Minibatch 604::LR 0.07 --> Loss 0.00165933340788\n",
      "Epoch 14::Minibatch 605::LR 0.07 --> Loss 0.00240367174149\n",
      "Epoch 14::Minibatch 606::LR 0.07 --> Loss 0.00194215854009\n",
      "Epoch 14::Minibatch 607::LR 0.07 --> Loss 0.000851112206777\n",
      "Epoch 14::Minibatch 608::LR 0.07 --> Loss 0.00160077492396\n",
      "Epoch 14::Minibatch 609::LR 0.07 --> Loss 0.002384014527\n",
      "Epoch 14::Minibatch 610::LR 0.07 --> Loss 0.00404453158379\n",
      "Epoch 14::Minibatch 611::LR 0.07 --> Loss 0.00267044027646\n",
      "Epoch 14::Minibatch 612::LR 0.07 --> Loss 0.000497911721468\n",
      "Epoch 14::Minibatch 613::LR 0.07 --> Loss 0.00131684452295\n",
      "Epoch 14::Minibatch 614::LR 0.07 --> Loss 0.00248403767745\n",
      "Epoch 14::Minibatch 615::LR 0.07 --> Loss 0.00169311344624\n",
      "Epoch 14::Minibatch 616::LR 0.07 --> Loss 0.000933450361093\n",
      "Epoch 14::Minibatch 617::LR 0.07 --> Loss 0.000513160924117\n",
      "Epoch 14::Minibatch 618::LR 0.07 --> Loss 0.00274561107159\n",
      "Epoch 14::Minibatch 619::LR 0.07 --> Loss 0.00192673921585\n",
      "Epoch 14::Minibatch 620::LR 0.07 --> Loss 0.00173546671867\n",
      "Epoch 14::Minibatch 621::LR 0.07 --> Loss 0.000865354935328\n",
      "Epoch 14::Minibatch 622::LR 0.07 --> Loss 0.000815033316612\n",
      "Epoch 14::Minibatch 623::LR 0.07 --> Loss 0.00221919596195\n",
      "Epoch 14::Minibatch 624::LR 0.07 --> Loss 0.00180909176668\n",
      "Epoch 14::Minibatch 625::LR 0.07 --> Loss 0.0030414223671\n",
      "Epoch 14::Minibatch 626::LR 0.07 --> Loss 0.00462716062864\n",
      "Epoch 14::Minibatch 627::LR 0.07 --> Loss 0.00135051329931\n",
      "Epoch 14::Minibatch 628::LR 0.07 --> Loss 0.000919542908669\n",
      "Epoch 14::Minibatch 629::LR 0.07 --> Loss 0.00346837480863\n",
      "Epoch 14::Minibatch 630::LR 0.07 --> Loss 0.00336050828298\n",
      "Epoch 14::Minibatch 631::LR 0.07 --> Loss 0.00675531148911\n",
      "Epoch 14::Minibatch 632::LR 0.07 --> Loss 0.00080600515008\n",
      "Epoch 14::Minibatch 633::LR 0.07 --> Loss 0.00167358557383\n",
      "Epoch 14::Minibatch 634::LR 0.07 --> Loss 0.00326616267363\n",
      "Epoch 14::Minibatch 635::LR 0.07 --> Loss 0.00512247045835\n",
      "Epoch 14::Minibatch 636::LR 0.07 --> Loss 0.0053035235405\n",
      "Epoch 14::Minibatch 637::LR 0.07 --> Loss 0.000825449724992\n",
      "Epoch 14::Minibatch 638::LR 0.07 --> Loss 0.00154636532068\n",
      "Epoch 14::Minibatch 639::LR 0.07 --> Loss 0.00335001866023\n",
      "Epoch 14::Minibatch 640::LR 0.07 --> Loss 0.00505306442579\n",
      "Epoch 14::Minibatch 641::LR 0.07 --> Loss 0.00316457192103\n",
      "Epoch 14::Minibatch 642::LR 0.07 --> Loss 0.000566345800956\n",
      "Epoch 14::Minibatch 643::LR 0.07 --> Loss 0.00236536224683\n",
      "Epoch 14::Minibatch 644::LR 0.07 --> Loss 0.00402484138807\n",
      "Epoch 14::Minibatch 645::LR 0.07 --> Loss 0.00420946915944\n",
      "Epoch 14::Minibatch 646::LR 0.07 --> Loss 0.00153984606266\n",
      "Epoch 14::Minibatch 647::LR 0.07 --> Loss 0.000559428433577\n",
      "Epoch 14::Minibatch 648::LR 0.07 --> Loss 0.00302273392677\n",
      "Epoch 14::Minibatch 649::LR 0.07 --> Loss 0.00359672586123\n",
      "Epoch 14::Minibatch 650::LR 0.07 --> Loss 0.00335329214732\n",
      "Epoch 14::Minibatch 651::LR 0.07 --> Loss 0.00141103118658\n",
      "Epoch 14::Minibatch 652::LR 0.07 --> Loss 0.000835405190786\n",
      "Epoch 14::Minibatch 653::LR 0.07 --> Loss 0.00288690825303\n",
      "Epoch 14::Minibatch 654::LR 0.07 --> Loss 0.00311855018139\n",
      "Epoch 14::Minibatch 655::LR 0.07 --> Loss 0.00349553902944\n",
      "Epoch 14::Minibatch 656::LR 0.07 --> Loss 0.000775619496902\n",
      "Epoch 14::Minibatch 657::LR 0.07 --> Loss 0.00222947279612\n",
      "Epoch 14::Minibatch 658::LR 0.07 --> Loss 0.00500877221425\n",
      "Epoch 14::Minibatch 659::LR 0.07 --> Loss 0.00235029498736\n",
      "Epoch 14::Minibatch 660::LR 0.07 --> Loss 0.00263295471668\n",
      "Epoch 14::Minibatch 661::LR 0.07 --> Loss 0.0025501726071\n",
      "Epoch 14::Minibatch 662::LR 0.07 --> Loss 0.00183925191561\n",
      "Epoch 14::Minibatch 663::LR 0.07 --> Loss 0.0036767466863\n",
      "Epoch 14::Minibatch 664::LR 0.07 --> Loss 0.00347781260808\n",
      "Epoch 14::Minibatch 665::LR 0.07 --> Loss 0.000756543676058\n",
      "Epoch 14::Minibatch 666::LR 0.07 --> Loss 0.00395165244738\n",
      "Epoch 14::Minibatch 667::LR 0.07 --> Loss 0.00256117204825\n",
      "Epoch 14::Minibatch 668::LR 0.07 --> Loss 0.00714220921199\n",
      "Epoch 14::Minibatch 669::LR 0.07 --> Loss 0.00109764983257\n",
      "Epoch 14::Minibatch 670::LR 0.07 --> Loss 0.00137069006761\n",
      "Epoch 14::Minibatch 671::LR 0.07 --> Loss 0.00544167677561\n",
      "Epoch 14::Minibatch 672::LR 0.07 --> Loss 0.00382399837176\n",
      "Epoch 14::Minibatch 673::LR 0.07 --> Loss 0.00162981490294\n",
      "Epoch 14::Minibatch 674::LR 0.07 --> Loss 0.000525403817495\n",
      "Epoch 14::Minibatch 675::LR 0.07 --> Loss 0.00219644745191\n",
      "Epoch 14::Minibatch 676::LR 0.07 --> Loss 0.0021552157402\n",
      "Epoch 14::Minibatch 677::LR 0.07 --> Loss 0.00284123996894\n",
      "Epoch 14::Minibatch 678::LR 0.07 --> Loss 0.00195094962915\n",
      "Epoch 14::Minibatch 679::LR 0.07 --> Loss 0.00356304009755\n",
      "Epoch 14::Minibatch 680::LR 0.07 --> Loss 0.00215173681577\n",
      "Epoch 14::Minibatch 681::LR 0.07 --> Loss 0.00245289683342\n",
      "Epoch 14::Minibatch 682::LR 0.07 --> Loss 0.000766243139903\n",
      "Epoch 14::Minibatch 683::LR 0.07 --> Loss 0.00240695536137\n",
      "Epoch 14::Minibatch 684::LR 0.07 --> Loss 0.00236678302288\n",
      "Epoch 14::Minibatch 685::LR 0.07 --> Loss 0.00293807148933\n",
      "Epoch 14::Minibatch 686::LR 0.07 --> Loss 0.00154331107934\n",
      "Epoch 14::Minibatch 687::LR 0.07 --> Loss 0.000849268138409\n",
      "Epoch 14::Minibatch 688::LR 0.07 --> Loss 0.0027592553695\n",
      "Epoch 14::Minibatch 689::LR 0.07 --> Loss 0.00254697024822\n",
      "Epoch 14::Minibatch 690::LR 0.07 --> Loss 0.0019270414114\n",
      "Epoch 14::Minibatch 691::LR 0.07 --> Loss 0.00066330442826\n",
      "Epoch 14::Minibatch 692::LR 0.07 --> Loss 0.00248705347379\n",
      "Epoch 14::Minibatch 693::LR 0.07 --> Loss 0.00257674813271\n",
      "Epoch 14::Minibatch 694::LR 0.07 --> Loss 0.00302862286568\n",
      "Epoch 14::Minibatch 695::LR 0.07 --> Loss 0.00173166314761\n",
      "Epoch 14::Minibatch 696::LR 0.07 --> Loss 0.00204509357611\n",
      "Epoch 14::Minibatch 697::LR 0.07 --> Loss 0.00141339073579\n",
      "Epoch 14::Minibatch 698::LR 0.07 --> Loss 0.00162864883741\n",
      "Epoch 14::Minibatch 699::LR 0.07 --> Loss 0.00386552095413\n",
      "Epoch 14::Minibatch 700::LR 0.07 --> Loss 0.00270168105761\n",
      "Epoch 14::Minibatch 701::LR 0.07 --> Loss 0.0020091509819\n",
      "Epoch 14::Minibatch 702::LR 0.07 --> Loss 0.00166702985764\n",
      "Epoch 14::Minibatch 703::LR 0.07 --> Loss 0.00428411006927\n",
      "Epoch 14::Minibatch 704::LR 0.07 --> Loss 0.00180417716503\n",
      "Epoch 14::Minibatch 705::LR 0.07 --> Loss 0.00286494334539\n",
      "Epoch 14::Minibatch 706::LR 0.07 --> Loss 0.00224780837695\n",
      "Epoch 14::Minibatch 707::LR 0.07 --> Loss 0.00119222611189\n",
      "Epoch 14::Minibatch 708::LR 0.07 --> Loss 0.00173958003521\n",
      "Epoch 14::Minibatch 709::LR 0.07 --> Loss 0.00169719894727\n",
      "Epoch 14::Minibatch 710::LR 0.07 --> Loss 0.00250927666823\n",
      "Epoch 14::Minibatch 711::LR 0.07 --> Loss 0.00191817561785\n",
      "Epoch 14::Minibatch 712::LR 0.07 --> Loss 0.00132932802041\n",
      "Epoch 14::Minibatch 713::LR 0.07 --> Loss 0.00174937884013\n",
      "Epoch 14::Minibatch 714::LR 0.07 --> Loss 0.00273389697075\n",
      "Epoch 14::Minibatch 715::LR 0.07 --> Loss 0.00295153001944\n",
      "Epoch 14::Minibatch 716::LR 0.07 --> Loss 0.00160946329435\n",
      "Epoch 14::Minibatch 717::LR 0.07 --> Loss 0.00160966296991\n",
      "Epoch 14::Minibatch 718::LR 0.07 --> Loss 0.0012581790487\n",
      "Epoch 14::Minibatch 719::LR 0.07 --> Loss 0.00166319469611\n",
      "Epoch 14::Minibatch 720::LR 0.07 --> Loss 0.00253804107507\n",
      "Epoch 14::Minibatch 721::LR 0.07 --> Loss 0.00063022573789\n",
      "Epoch 14::Minibatch 722::LR 0.07 --> Loss 0.00483950455983\n",
      "Epoch 14::Minibatch 723::LR 0.07 --> Loss 0.00491998910904\n",
      "Epoch 14::Minibatch 724::LR 0.07 --> Loss 0.000971896549066\n",
      "Epoch 14::Minibatch 725::LR 0.07 --> Loss 0.00220474918683\n",
      "Epoch 14::Minibatch 726::LR 0.07 --> Loss 0.00476017991702\n",
      "Epoch 14::Minibatch 727::LR 0.07 --> Loss 0.00319707433383\n",
      "Epoch 14::Minibatch 728::LR 0.07 --> Loss 0.000651771674554\n",
      "Epoch 14::Minibatch 729::LR 0.07 --> Loss 0.00075669725736\n",
      "Epoch 14::Minibatch 730::LR 0.07 --> Loss 0.00274554272493\n",
      "Epoch 14::Minibatch 731::LR 0.07 --> Loss 0.00247590561708\n",
      "Epoch 14::Minibatch 732::LR 0.07 --> Loss 0.00224246462186\n",
      "Epoch 14::Minibatch 733::LR 0.07 --> Loss 0.000702514946461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 734::LR 0.07 --> Loss 0.00174921035767\n",
      "Epoch 14::Minibatch 735::LR 0.07 --> Loss 0.00235657095909\n",
      "Epoch 14::Minibatch 736::LR 0.07 --> Loss 0.0034623392423\n",
      "Epoch 14::Minibatch 737::LR 0.07 --> Loss 0.0031005726258\n",
      "Epoch 14::Minibatch 738::LR 0.07 --> Loss 0.0016334455212\n",
      "Epoch 14::Minibatch 739::LR 0.07 --> Loss 0.0024642209212\n",
      "Epoch 14::Minibatch 740::LR 0.07 --> Loss 0.00384037812551\n",
      "Epoch 14::Minibatch 741::LR 0.07 --> Loss 0.00271984398365\n",
      "Epoch 14::Minibatch 742::LR 0.07 --> Loss 0.00211697181066\n",
      "Epoch 14::Minibatch 743::LR 0.07 --> Loss 0.00137457748254\n",
      "Epoch 14::Minibatch 744::LR 0.07 --> Loss 0.00179958840211\n",
      "Epoch 14::Minibatch 745::LR 0.07 --> Loss 0.00285473028819\n",
      "Epoch 14::Minibatch 746::LR 0.07 --> Loss 0.00300233046214\n",
      "Epoch 14::Minibatch 747::LR 0.07 --> Loss 0.00179527123769\n",
      "Epoch 14::Minibatch 748::LR 0.07 --> Loss 0.000641211767991\n",
      "Epoch 14::Minibatch 749::LR 0.07 --> Loss 0.00165608336528\n",
      "Epoch 14::Minibatch 750::LR 0.07 --> Loss 0.00247808337212\n",
      "Epoch 14::Minibatch 751::LR 0.07 --> Loss 0.00272745172183\n",
      "Epoch 14::Minibatch 752::LR 0.07 --> Loss 0.00116309255362\n",
      "Epoch 14::Minibatch 753::LR 0.07 --> Loss 0.0022407613198\n",
      "Epoch 14::Minibatch 754::LR 0.07 --> Loss 0.00239548961322\n",
      "Epoch 14::Minibatch 755::LR 0.07 --> Loss 0.00266882856687\n",
      "Epoch 14::Minibatch 756::LR 0.07 --> Loss 0.00138419290384\n",
      "Epoch 14::Minibatch 757::LR 0.07 --> Loss 0.000814504822095\n",
      "Epoch 14::Minibatch 758::LR 0.07 --> Loss 0.00161727845669\n",
      "Epoch 14::Minibatch 759::LR 0.07 --> Loss 0.00380246480306\n",
      "Epoch 14::Minibatch 760::LR 0.07 --> Loss 0.0029939075311\n",
      "Epoch 14::Minibatch 761::LR 0.07 --> Loss 0.0063428580761\n",
      "Epoch 14::Minibatch 762::LR 0.07 --> Loss 0.00378287434578\n",
      "Epoch 14::Minibatch 763::LR 0.07 --> Loss 0.00357967774073\n",
      "Epoch 14::Minibatch 764::LR 0.07 --> Loss 0.00321841915449\n",
      "Epoch 14::Minibatch 765::LR 0.07 --> Loss 0.00132861018181\n",
      "Epoch 14::Minibatch 766::LR 0.07 --> Loss 0.00227953116099\n",
      "Epoch 14::Minibatch 767::LR 0.07 --> Loss 0.00503219723701\n",
      "Epoch 14::Minibatch 768::LR 0.07 --> Loss 0.00360567609469\n",
      "Epoch 14::Minibatch 769::LR 0.07 --> Loss 0.00190590719382\n",
      "Epoch 14::Minibatch 770::LR 0.07 --> Loss 0.00145767688751\n",
      "Epoch 14::Minibatch 771::LR 0.07 --> Loss 0.00374585191409\n",
      "Epoch 14::Minibatch 772::LR 0.07 --> Loss 0.00338799794515\n",
      "Epoch 14::Minibatch 773::LR 0.07 --> Loss 0.00313413957755\n",
      "Epoch 14::Minibatch 774::LR 0.07 --> Loss 0.00177045623461\n",
      "Epoch 14::Minibatch 775::LR 0.07 --> Loss 0.00394241293271\n",
      "Epoch 14::Minibatch 776::LR 0.07 --> Loss 0.0035636862119\n",
      "Epoch 14::Minibatch 777::LR 0.07 --> Loss 0.0076464955012\n",
      "Epoch 14::Minibatch 778::LR 0.07 --> Loss 0.00988723595937\n",
      "Epoch 14::Minibatch 779::LR 0.07 --> Loss 0.00225083529949\n",
      "Epoch 14::Minibatch 780::LR 0.07 --> Loss 0.00163213670254\n",
      "Epoch 14::Minibatch 781::LR 0.07 --> Loss 0.00349480628967\n",
      "Epoch 14::Minibatch 782::LR 0.07 --> Loss 0.00405146718025\n",
      "Epoch 14::Minibatch 783::LR 0.07 --> Loss 0.00232070068518\n",
      "Epoch 14::Minibatch 784::LR 0.07 --> Loss 0.000724545915922\n",
      "Epoch 14::Minibatch 785::LR 0.07 --> Loss 0.00359962383906\n",
      "Epoch 14::Minibatch 786::LR 0.07 --> Loss 0.00352321902911\n",
      "Epoch 14::Minibatch 787::LR 0.07 --> Loss 0.00275761663914\n",
      "Epoch 14::Minibatch 788::LR 0.07 --> Loss 0.00244082689285\n",
      "Epoch 14::Minibatch 789::LR 0.07 --> Loss 0.000747648229202\n",
      "Epoch 14::Minibatch 790::LR 0.07 --> Loss 0.00321035405\n",
      "Epoch 14::Minibatch 791::LR 0.07 --> Loss 0.0036442399025\n",
      "Epoch 14::Minibatch 792::LR 0.07 --> Loss 0.00325347840786\n",
      "Epoch 14::Minibatch 793::LR 0.07 --> Loss 0.00183634638786\n",
      "Epoch 14::Minibatch 794::LR 0.07 --> Loss 0.00104994197687\n",
      "Epoch 14::Minibatch 795::LR 0.07 --> Loss 0.00311656037966\n",
      "Epoch 14::Minibatch 796::LR 0.07 --> Loss 0.00573393702507\n",
      "Epoch 14::Minibatch 797::LR 0.07 --> Loss 0.00761654138565\n",
      "Epoch 14::Minibatch 798::LR 0.07 --> Loss 0.00336371819178\n",
      "Epoch 14::Minibatch 799::LR 0.07 --> Loss 0.00240353206793\n",
      "Epoch 14::Minibatch 800::LR 0.07 --> Loss 0.00203702370326\n",
      "Epoch 14::Minibatch 801::LR 0.07 --> Loss 0.00416280269623\n",
      "Epoch 14::Minibatch 802::LR 0.07 --> Loss 0.00133601556222\n",
      "Epoch 14::Minibatch 803::LR 0.07 --> Loss 0.00283933500449\n",
      "Epoch 14::Minibatch 804::LR 0.07 --> Loss 0.00220006068548\n",
      "Epoch 14::Minibatch 805::LR 0.07 --> Loss 0.00229577064514\n",
      "Epoch 14::Minibatch 806::LR 0.07 --> Loss 0.00332445561886\n",
      "Epoch 14::Minibatch 807::LR 0.07 --> Loss 0.0030356502533\n",
      "Epoch 14::Minibatch 808::LR 0.07 --> Loss 0.00270996352037\n",
      "Epoch 14::Minibatch 809::LR 0.07 --> Loss 0.00387681563695\n",
      "Epoch 14::Minibatch 810::LR 0.07 --> Loss 0.00514784216881\n",
      "Epoch 14::Minibatch 811::LR 0.07 --> Loss 0.00485365947088\n",
      "Epoch 14::Minibatch 812::LR 0.07 --> Loss 0.00444288929303\n",
      "Epoch 14::Minibatch 813::LR 0.07 --> Loss 0.0038146007061\n",
      "Epoch 14::Minibatch 814::LR 0.07 --> Loss 0.00181688447793\n",
      "Epoch 14::Minibatch 815::LR 0.07 --> Loss 0.00385144551595\n",
      "Epoch 14::Minibatch 816::LR 0.07 --> Loss 0.00417402029037\n",
      "Epoch 14::Minibatch 817::LR 0.07 --> Loss 0.00550231695175\n",
      "Epoch 14::Minibatch 818::LR 0.07 --> Loss 0.0012593810757\n",
      "Epoch 14::Minibatch 819::LR 0.07 --> Loss 0.00068791170915\n",
      "Epoch 14::Minibatch 820::LR 0.07 --> Loss 0.00536446849505\n",
      "Epoch 14::Minibatch 821::LR 0.07 --> Loss 0.00317069252332\n",
      "Epoch 14::Minibatch 822::LR 0.07 --> Loss 0.00374203960101\n",
      "Epoch 14::Minibatch 823::LR 0.07 --> Loss 0.00131134470304\n",
      "Epoch 14::Minibatch 824::LR 0.07 --> Loss 0.00139828672012\n",
      "Epoch 14::Minibatch 825::LR 0.07 --> Loss 0.00370202183723\n",
      "Epoch 14::Minibatch 826::LR 0.07 --> Loss 0.00389219443003\n",
      "Epoch 14::Minibatch 827::LR 0.07 --> Loss 0.00210579117139\n",
      "Epoch 14::Minibatch 828::LR 0.07 --> Loss 0.000555947870016\n",
      "Epoch 14::Minibatch 829::LR 0.07 --> Loss 0.00239116311073\n",
      "Epoch 14::Minibatch 830::LR 0.07 --> Loss 0.00441575606664\n",
      "Epoch 14::Minibatch 831::LR 0.07 --> Loss 0.00257512867451\n",
      "Epoch 14::Minibatch 832::LR 0.07 --> Loss 0.00225806772709\n",
      "Epoch 14::Minibatch 833::LR 0.07 --> Loss 0.00185460150242\n",
      "Epoch 14::Minibatch 834::LR 0.07 --> Loss 0.000779335796833\n",
      "Epoch 14::Minibatch 835::LR 0.07 --> Loss 0.00382008314133\n",
      "Epoch 14::Minibatch 836::LR 0.07 --> Loss 0.00372275869052\n",
      "Epoch 14::Minibatch 837::LR 0.07 --> Loss 0.00219516376654\n",
      "Epoch 14::Minibatch 838::LR 0.07 --> Loss 0.000632691582044\n",
      "Epoch 14::Minibatch 839::LR 0.07 --> Loss 0.00247226874034\n",
      "Epoch 14::Minibatch 840::LR 0.07 --> Loss 0.00291301151117\n",
      "Epoch 14::Minibatch 841::LR 0.07 --> Loss 0.00285665492217\n",
      "Epoch 14::Minibatch 842::LR 0.07 --> Loss 0.00209354420503\n",
      "Epoch 14::Minibatch 843::LR 0.07 --> Loss 0.00101373334726\n",
      "Epoch 14::Minibatch 844::LR 0.07 --> Loss 0.00150394956271\n",
      "Epoch 14::Minibatch 845::LR 0.07 --> Loss 0.00436706662178\n",
      "Epoch 14::Minibatch 846::LR 0.07 --> Loss 0.00168433447679\n",
      "Epoch 14::Minibatch 847::LR 0.07 --> Loss 0.00228191713492\n",
      "Epoch 14::Minibatch 848::LR 0.07 --> Loss 0.00100262184938\n",
      "Epoch 14::Minibatch 849::LR 0.07 --> Loss 0.00185119748116\n",
      "Epoch 14::Minibatch 850::LR 0.07 --> Loss 0.00318818589052\n",
      "Epoch 14::Minibatch 851::LR 0.07 --> Loss 0.0026920747757\n",
      "Epoch 14::Minibatch 852::LR 0.07 --> Loss 0.00107102175554\n",
      "Epoch 14::Minibatch 853::LR 0.07 --> Loss 0.00131092210611\n",
      "Epoch 14::Minibatch 854::LR 0.07 --> Loss 0.00257741292318\n",
      "Epoch 14::Minibatch 855::LR 0.07 --> Loss 0.00217609564463\n",
      "Epoch 14::Minibatch 856::LR 0.07 --> Loss 0.00179601073265\n",
      "Epoch 14::Minibatch 857::LR 0.07 --> Loss 0.00121841967106\n",
      "Epoch 14::Minibatch 858::LR 0.07 --> Loss 0.000598827302456\n",
      "Epoch 14::Minibatch 859::LR 0.07 --> Loss 0.00190690060457\n",
      "Epoch 14::Minibatch 860::LR 0.07 --> Loss 0.00124057203531\n",
      "Epoch 14::Minibatch 861::LR 0.07 --> Loss 0.000937016010284\n",
      "Epoch 14::Minibatch 862::LR 0.07 --> Loss 0.00364020466805\n",
      "Epoch 14::Minibatch 863::LR 0.07 --> Loss 0.00342312256495\n",
      "Epoch 14::Minibatch 864::LR 0.07 --> Loss 0.00290892124176\n",
      "Epoch 14::Minibatch 865::LR 0.07 --> Loss 0.000420073668162\n",
      "Epoch 14::Minibatch 866::LR 0.07 --> Loss 0.00215356429418\n",
      "Epoch 14::Minibatch 867::LR 0.07 --> Loss 0.00297690828641\n",
      "Epoch 14::Minibatch 868::LR 0.07 --> Loss 0.00245424787203\n",
      "Epoch 14::Minibatch 869::LR 0.07 --> Loss 0.00210246662299\n",
      "Epoch 14::Minibatch 870::LR 0.07 --> Loss 0.00357348283132\n",
      "Epoch 14::Minibatch 871::LR 0.07 --> Loss 0.00151501089334\n",
      "Epoch 14::Minibatch 872::LR 0.07 --> Loss 0.00228106319904\n",
      "Epoch 14::Minibatch 873::LR 0.07 --> Loss 0.00247257510821\n",
      "Epoch 14::Minibatch 874::LR 0.07 --> Loss 0.00625136772792\n",
      "Epoch 14::Minibatch 875::LR 0.07 --> Loss 0.000509914805492\n",
      "Epoch 14::Minibatch 876::LR 0.07 --> Loss 0.00330415089925\n",
      "Epoch 14::Minibatch 877::LR 0.07 --> Loss 0.00714028517405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 878::LR 0.07 --> Loss 0.00326569676399\n",
      "Epoch 14::Minibatch 879::LR 0.07 --> Loss 0.00407299518585\n",
      "Epoch 14::Minibatch 880::LR 0.07 --> Loss 0.00489213983218\n",
      "Epoch 14::Minibatch 881::LR 0.07 --> Loss 0.00431440750758\n",
      "Epoch 14::Minibatch 882::LR 0.07 --> Loss 0.00198714395364\n",
      "Epoch 14::Minibatch 883::LR 0.07 --> Loss 0.00340532461802\n",
      "Epoch 14::Minibatch 884::LR 0.07 --> Loss 0.00270663181941\n",
      "Epoch 14::Minibatch 885::LR 0.07 --> Loss 0.00255914171537\n",
      "Epoch 14::Minibatch 886::LR 0.07 --> Loss 0.00060996328791\n",
      "Epoch 14::Minibatch 887::LR 0.07 --> Loss 0.00538591663043\n",
      "Epoch 14::Minibatch 888::LR 0.07 --> Loss 0.00264978210131\n",
      "Epoch 14::Minibatch 889::LR 0.07 --> Loss 0.00302542885145\n",
      "Epoch 14::Minibatch 890::LR 0.07 --> Loss 0.00447421709696\n",
      "Epoch 14::Minibatch 891::LR 0.07 --> Loss 0.00197202285131\n",
      "Epoch 14::Minibatch 892::LR 0.07 --> Loss 0.00089045325915\n",
      "Epoch 14::Minibatch 893::LR 0.07 --> Loss 0.0024911570549\n",
      "Epoch 14::Minibatch 894::LR 0.07 --> Loss 0.002218927145\n",
      "Epoch 14::Minibatch 895::LR 0.07 --> Loss 0.00246962606907\n",
      "Epoch 14::Minibatch 896::LR 0.07 --> Loss 0.00135225256284\n",
      "Epoch 14::Minibatch 897::LR 0.07 --> Loss 0.000736301342646\n",
      "Epoch 14::Minibatch 898::LR 0.07 --> Loss 0.00220479865869\n",
      "Epoch 14::Minibatch 899::LR 0.07 --> Loss 0.00249150276184\n",
      "Epoch 14::Minibatch 900::LR 0.07 --> Loss 0.00329767068227\n",
      "Epoch 14::Minibatch 901::LR 0.07 --> Loss 0.000605795681477\n",
      "Epoch 14::Minibatch 902::LR 0.07 --> Loss 0.00142532219489\n",
      "Epoch 14::Minibatch 903::LR 0.07 --> Loss 0.00265132546425\n",
      "Epoch 14::Minibatch 904::LR 0.07 --> Loss 0.00204768399398\n",
      "Epoch 14::Minibatch 905::LR 0.07 --> Loss 0.00144673973322\n",
      "Epoch 14::Minibatch 906::LR 0.07 --> Loss 0.0010939976573\n",
      "Epoch 14::Minibatch 907::LR 0.07 --> Loss 0.00159543226163\n",
      "Epoch 14::Minibatch 908::LR 0.07 --> Loss 0.00230006436507\n",
      "Epoch 14::Minibatch 909::LR 0.07 --> Loss 0.00210072040558\n",
      "Epoch 14::Minibatch 910::LR 0.07 --> Loss 0.00083728402853\n",
      "Epoch 14::Minibatch 911::LR 0.07 --> Loss 0.00123510301113\n",
      "Epoch 14::Minibatch 912::LR 0.07 --> Loss 0.0020534046491\n",
      "Epoch 14::Minibatch 913::LR 0.07 --> Loss 0.00219792366028\n",
      "Epoch 14::Minibatch 914::LR 0.07 --> Loss 0.00123041987419\n",
      "Epoch 14::Minibatch 915::LR 0.07 --> Loss 0.000493750472864\n",
      "Epoch 14::Minibatch 916::LR 0.07 --> Loss 0.0024321136872\n",
      "Epoch 14::Minibatch 917::LR 0.07 --> Loss 0.00389766176542\n",
      "Epoch 14::Minibatch 918::LR 0.07 --> Loss 0.00563710689545\n",
      "Epoch 14::Minibatch 919::LR 0.07 --> Loss 0.000656098276377\n",
      "Epoch 14::Minibatch 920::LR 0.07 --> Loss 0.0114069755872\n",
      "Epoch 14::Minibatch 921::LR 0.07 --> Loss 0.00286983648936\n",
      "Epoch 14::Minibatch 922::LR 0.07 --> Loss 0.00306202312311\n",
      "Epoch 14::Minibatch 923::LR 0.07 --> Loss 0.00155932257573\n",
      "Epoch 14::Minibatch 924::LR 0.07 --> Loss 0.00353926618894\n",
      "Epoch 14::Minibatch 925::LR 0.07 --> Loss 0.00250849505266\n",
      "Epoch 14::Minibatch 926::LR 0.07 --> Loss 0.0053719552358\n",
      "Epoch 14::Minibatch 927::LR 0.07 --> Loss 0.00809237718582\n",
      "Epoch 14::Minibatch 928::LR 0.07 --> Loss 0.00656986991564\n",
      "Epoch 14::Minibatch 929::LR 0.07 --> Loss 0.00717525164286\n",
      "Epoch 14::Minibatch 930::LR 0.07 --> Loss 0.00965683698654\n",
      "Epoch 14::Minibatch 931::LR 0.07 --> Loss 0.00366242726644\n",
      "Epoch 14::Minibatch 932::LR 0.07 --> Loss 0.0076057656606\n",
      "Epoch 14::Minibatch 933::LR 0.07 --> Loss 0.00379730939865\n",
      "Epoch 14::Minibatch 934::LR 0.07 --> Loss 0.00499280532201\n",
      "Epoch 14::Minibatch 935::LR 0.07 --> Loss 0.00690106550852\n",
      "Epoch 14::Minibatch 936::LR 0.07 --> Loss 0.001693734924\n",
      "Epoch 14::Minibatch 937::LR 0.07 --> Loss 0.00361202677091\n",
      "Epoch 14::Minibatch 938::LR 0.07 --> Loss 0.00335365811984\n",
      "Epoch 14::Minibatch 939::LR 0.07 --> Loss 0.00340149919192\n",
      "Epoch 14::Minibatch 940::LR 0.07 --> Loss 0.00106704831123\n",
      "Epoch 14::Minibatch 941::LR 0.07 --> Loss 0.000872412919998\n",
      "Epoch 14::Minibatch 942::LR 0.07 --> Loss 0.00246081054211\n",
      "Epoch 14::Minibatch 943::LR 0.07 --> Loss 0.00308934708436\n",
      "Epoch 14::Minibatch 944::LR 0.07 --> Loss 0.00224306046963\n",
      "Epoch 14::Minibatch 945::LR 0.07 --> Loss 0.00132460802794\n",
      "Epoch 14::Minibatch 946::LR 0.07 --> Loss 0.00334861397743\n",
      "Epoch 14::Minibatch 947::LR 0.07 --> Loss 0.00297873000304\n",
      "Epoch 14::Minibatch 948::LR 0.07 --> Loss 0.0054466176033\n",
      "Epoch 14::Minibatch 949::LR 0.07 --> Loss 0.00194105108579\n",
      "Epoch 14::Minibatch 950::LR 0.07 --> Loss 0.00074119001627\n",
      "Epoch 14::Minibatch 951::LR 0.07 --> Loss 0.00340607364972\n",
      "Epoch 14::Minibatch 952::LR 0.07 --> Loss 0.0024768614769\n",
      "Epoch 14::Minibatch 953::LR 0.07 --> Loss 0.00138442536195\n",
      "Epoch 14::Minibatch 954::LR 0.07 --> Loss 0.00096496462822\n",
      "Epoch 14::Minibatch 955::LR 0.07 --> Loss 0.00255058427652\n",
      "Epoch 14::Minibatch 956::LR 0.07 --> Loss 0.00401582717896\n",
      "Epoch 14::Minibatch 957::LR 0.07 --> Loss 0.00193116505941\n",
      "Epoch 14::Minibatch 958::LR 0.07 --> Loss 0.0024350998799\n",
      "Epoch 14::Minibatch 959::LR 0.07 --> Loss 0.00302347183228\n",
      "Epoch 14::Minibatch 960::LR 0.07 --> Loss 0.00664995272954\n",
      "Epoch 14::Minibatch 961::LR 0.07 --> Loss 0.00343826452891\n",
      "Epoch 14::Minibatch 962::LR 0.07 --> Loss 0.00298610210419\n",
      "Epoch 14::Minibatch 963::LR 0.07 --> Loss 0.00105000466108\n",
      "Epoch 14::Minibatch 964::LR 0.07 --> Loss 0.00247474571069\n",
      "Epoch 14::Minibatch 965::LR 0.07 --> Loss 0.00757366816203\n",
      "Epoch 14::Minibatch 966::LR 0.07 --> Loss 0.00515207012494\n",
      "Epoch 14::Minibatch 967::LR 0.07 --> Loss 0.00170750498772\n",
      "Epoch 14::Minibatch 968::LR 0.07 --> Loss 0.00152804722389\n",
      "Epoch 14::Minibatch 969::LR 0.07 --> Loss 0.00681090116501\n",
      "Epoch 14::Minibatch 970::LR 0.07 --> Loss 0.0058614730835\n",
      "Epoch 14::Minibatch 971::LR 0.07 --> Loss 0.00351727286975\n",
      "Epoch 14::Minibatch 972::LR 0.07 --> Loss 0.0101147063573\n",
      "Epoch 14::Minibatch 973::LR 0.07 --> Loss 0.0089528520902\n",
      "Epoch 14::Minibatch 974::LR 0.07 --> Loss 0.00671710173289\n",
      "Epoch 14::Minibatch 975::LR 0.07 --> Loss 0.00469558238983\n",
      "Epoch 14::Minibatch 976::LR 0.07 --> Loss 0.0042123858134\n",
      "Epoch 14::Minibatch 977::LR 0.07 --> Loss 0.00423147241275\n",
      "Epoch 14::Minibatch 978::LR 0.07 --> Loss 0.0041502682368\n",
      "Epoch 14::Minibatch 979::LR 0.07 --> Loss 0.00411070783933\n",
      "Epoch 14::Minibatch 980::LR 0.07 --> Loss 0.00406033635139\n",
      "Epoch 14::Minibatch 981::LR 0.07 --> Loss 0.00528421322505\n",
      "Epoch 14::Minibatch 982::LR 0.07 --> Loss 0.006806965669\n",
      "Epoch 14::Minibatch 983::LR 0.07 --> Loss 0.00306199610233\n",
      "Epoch 14::Minibatch 984::LR 0.07 --> Loss 0.00273390988509\n",
      "Epoch 14::Minibatch 985::LR 0.07 --> Loss 0.00444857676824\n",
      "Epoch 14::Minibatch 986::LR 0.07 --> Loss 0.00404108206431\n",
      "Epoch 14::Minibatch 987::LR 0.07 --> Loss 0.00435347000758\n",
      "Epoch 14::Minibatch 988::LR 0.07 --> Loss 0.00333450118701\n",
      "Epoch 14::Minibatch 989::LR 0.07 --> Loss 0.00340706666311\n",
      "Epoch 14::Minibatch 990::LR 0.07 --> Loss 0.00315670967102\n",
      "Epoch 14::Minibatch 991::LR 0.07 --> Loss 0.00165738771359\n",
      "Epoch 14::Minibatch 992::LR 0.07 --> Loss 0.00187909344832\n",
      "Epoch 14::Minibatch 993::LR 0.07 --> Loss 0.00335064808528\n",
      "Epoch 14::Minibatch 994::LR 0.07 --> Loss 0.00201107641061\n",
      "Epoch 14::Minibatch 995::LR 0.07 --> Loss 0.000842757125696\n",
      "Epoch 14::Minibatch 996::LR 0.07 --> Loss 0.00309311687946\n",
      "Epoch 14::Minibatch 997::LR 0.07 --> Loss 0.00209563374519\n",
      "Epoch 14::Minibatch 998::LR 0.07 --> Loss 0.00226341187954\n",
      "Epoch 14::Minibatch 999::LR 0.07 --> Loss 0.00184270401796\n",
      "Epoch 14::Minibatch 1000::LR 0.07 --> Loss 0.00220119496187\n",
      "Epoch 14::Minibatch 1001::LR 0.07 --> Loss 0.00176302393277\n",
      "Epoch 14::Minibatch 1002::LR 0.07 --> Loss 0.00248440742493\n",
      "Epoch 14::Minibatch 1003::LR 0.07 --> Loss 0.00351784626643\n",
      "Epoch 14::Minibatch 1004::LR 0.07 --> Loss 0.000989278256893\n",
      "Epoch 14::Minibatch 1005::LR 0.07 --> Loss 0.00380554755529\n",
      "Epoch 14::Minibatch 1006::LR 0.07 --> Loss 0.00231793185075\n",
      "Epoch 14::Minibatch 1007::LR 0.07 --> Loss 0.00277117053668\n",
      "Epoch 14::Minibatch 1008::LR 0.07 --> Loss 0.000923851529757\n",
      "Epoch 14::Minibatch 1009::LR 0.07 --> Loss 0.00172448277473\n",
      "Epoch 14::Minibatch 1010::LR 0.07 --> Loss 0.00158705343803\n",
      "Epoch 14::Minibatch 1011::LR 0.07 --> Loss 0.00334977984428\n",
      "Epoch 14::Minibatch 1012::LR 0.07 --> Loss 0.00180642346541\n",
      "Epoch 14::Minibatch 1013::LR 0.07 --> Loss 0.00444647987684\n",
      "Epoch 14::Minibatch 1014::LR 0.07 --> Loss 0.00413507501284\n",
      "Epoch 14::Minibatch 1015::LR 0.07 --> Loss 0.00166491419077\n",
      "Epoch 14::Minibatch 1016::LR 0.07 --> Loss 0.00504948973656\n",
      "Epoch 14::Minibatch 1017::LR 0.07 --> Loss 0.00368620872498\n",
      "Epoch 14::Minibatch 1018::LR 0.07 --> Loss 0.00308330436548\n",
      "Epoch 14::Minibatch 1019::LR 0.07 --> Loss 0.0022058125337\n",
      "Epoch 14::Minibatch 1020::LR 0.07 --> Loss 0.00221584598223\n",
      "Epoch 14::Minibatch 1021::LR 0.07 --> Loss 0.00222013235092\n",
      "Epoch 14::Minibatch 1022::LR 0.07 --> Loss 0.00171905934811\n",
      "Epoch 14::Minibatch 1023::LR 0.07 --> Loss 0.00134569664796\n",
      "Epoch 14::Minibatch 1024::LR 0.07 --> Loss 0.00128914654255\n",
      "Epoch 14::Minibatch 1025::LR 0.07 --> Loss 0.0014915817976\n",
      "Epoch 14::Minibatch 1026::LR 0.07 --> Loss 0.000885215500991\n",
      "Epoch 14::Minibatch 1027::LR 0.07 --> Loss 0.00108221838872\n",
      "Epoch 14::Minibatch 1028::LR 0.07 --> Loss 0.000829624036948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14::Minibatch 1029::LR 0.07 --> Loss 0.000804966390133\n",
      "Epoch 14::Minibatch 1030::LR 0.07 --> Loss 0.000997926791509\n",
      "Epoch 14::Minibatch 1031::LR 0.07 --> Loss 0.00079346259435\n",
      "Epoch 14::Minibatch 1032::LR 0.07 --> Loss 0.000810709148645\n",
      "Epoch 14::Minibatch 1033::LR 0.07 --> Loss 0.000679350445668\n",
      "Epoch 14::Minibatch 1034::LR 0.07 --> Loss 0.0006733289361\n",
      "Epoch 14::Minibatch 1035::LR 0.07 --> Loss 0.00048113634189\n",
      "Epoch 14::Minibatch 1036::LR 0.07 --> Loss 0.000387789085507\n",
      "Epoch 14::Minibatch 1037::LR 0.07 --> Loss 0.000591618071\n",
      "Epoch 14::Minibatch 1038::LR 0.07 --> Loss 0.00131799985965\n",
      "Epoch 14::Minibatch 1039::LR 0.07 --> Loss 0.00105853021145\n",
      "Epoch 14::Minibatch 1040::LR 0.07 --> Loss 0.000446134706338\n",
      "Epoch 14::Minibatch 1041::LR 0.07 --> Loss 0.000611139734586\n",
      "Epoch 15::Minibatch 1::LR 0.0676923076923 --> Loss 0.00974443833033\n",
      "Epoch 15::Minibatch 2::LR 0.0676923076923 --> Loss 0.00589054783185\n",
      "Epoch 15::Minibatch 3::LR 0.0676923076923 --> Loss 0.00389276425044\n",
      "Epoch 15::Minibatch 4::LR 0.0676923076923 --> Loss 0.00427122513453\n",
      "Epoch 15::Minibatch 5::LR 0.0676923076923 --> Loss 0.0047144083182\n",
      "Epoch 15::Minibatch 6::LR 0.0676923076923 --> Loss 0.00241506675879\n",
      "Epoch 15::Minibatch 7::LR 0.0676923076923 --> Loss 0.00756668885549\n",
      "Epoch 15::Minibatch 8::LR 0.0676923076923 --> Loss 0.00735597928365\n",
      "Epoch 15::Minibatch 9::LR 0.0676923076923 --> Loss 0.00527554949125\n",
      "Epoch 15::Minibatch 10::LR 0.0676923076923 --> Loss 0.00278971493244\n",
      "Epoch 15::Minibatch 11::LR 0.0676923076923 --> Loss 0.00235687673092\n",
      "Epoch 15::Minibatch 12::LR 0.0676923076923 --> Loss 0.00343327760696\n",
      "Epoch 15::Minibatch 13::LR 0.0676923076923 --> Loss 0.00514406045278\n",
      "Epoch 15::Minibatch 14::LR 0.0676923076923 --> Loss 0.00511266708374\n",
      "Epoch 15::Minibatch 15::LR 0.0676923076923 --> Loss 0.00419207930565\n",
      "Epoch 15::Minibatch 16::LR 0.0676923076923 --> Loss 0.000865347286065\n",
      "Epoch 15::Minibatch 17::LR 0.0676923076923 --> Loss 0.00296640018622\n",
      "Epoch 15::Minibatch 18::LR 0.0676923076923 --> Loss 0.00249168932438\n",
      "Epoch 15::Minibatch 19::LR 0.0676923076923 --> Loss 0.00123068581025\n",
      "Epoch 15::Minibatch 20::LR 0.0676923076923 --> Loss 0.00168791194757\n",
      "Epoch 15::Minibatch 21::LR 0.0676923076923 --> Loss 0.00327785710494\n",
      "Epoch 15::Minibatch 22::LR 0.0676923076923 --> Loss 0.00231622258822\n",
      "Epoch 15::Minibatch 23::LR 0.0676923076923 --> Loss 0.000770214547714\n",
      "Epoch 15::Minibatch 24::LR 0.0676923076923 --> Loss 0.000359585831563\n",
      "Epoch 15::Minibatch 25::LR 0.0676923076923 --> Loss 0.00108543008566\n",
      "Epoch 15::Minibatch 26::LR 0.0676923076923 --> Loss 0.00129585723082\n",
      "Epoch 15::Minibatch 27::LR 0.0676923076923 --> Loss 0.000895622372627\n",
      "Epoch 15::Minibatch 28::LR 0.0676923076923 --> Loss 0.000370353634159\n",
      "Epoch 15::Minibatch 29::LR 0.0676923076923 --> Loss 0.000353272383412\n",
      "Epoch 15::Minibatch 30::LR 0.0676923076923 --> Loss 0.00083135475715\n",
      "Epoch 15::Minibatch 31::LR 0.0676923076923 --> Loss 0.00131245583296\n",
      "Epoch 15::Minibatch 32::LR 0.0676923076923 --> Loss 0.00125159362952\n",
      "Epoch 15::Minibatch 33::LR 0.0676923076923 --> Loss 0.000776191651821\n",
      "Epoch 15::Minibatch 34::LR 0.0676923076923 --> Loss 0.0023482743899\n",
      "Epoch 15::Minibatch 35::LR 0.0676923076923 --> Loss 0.00418077111244\n",
      "Epoch 15::Minibatch 36::LR 0.0676923076923 --> Loss 0.00224057674408\n",
      "Epoch 15::Minibatch 37::LR 0.0676923076923 --> Loss 0.000630714644988\n",
      "Epoch 15::Minibatch 38::LR 0.0676923076923 --> Loss 0.000761961986621\n",
      "Epoch 15::Minibatch 39::LR 0.0676923076923 --> Loss 0.00240760346254\n",
      "Epoch 15::Minibatch 40::LR 0.0676923076923 --> Loss 0.003676019907\n",
      "Epoch 15::Minibatch 41::LR 0.0676923076923 --> Loss 0.00297648310661\n",
      "Epoch 15::Minibatch 42::LR 0.0676923076923 --> Loss 0.00612937370936\n",
      "Epoch 15::Minibatch 43::LR 0.0676923076923 --> Loss 0.00185705880324\n",
      "Epoch 15::Minibatch 44::LR 0.0676923076923 --> Loss 0.00312879244486\n",
      "Epoch 15::Minibatch 45::LR 0.0676923076923 --> Loss 0.00252671202024\n",
      "Epoch 15::Minibatch 46::LR 0.0676923076923 --> Loss 0.00351179560026\n",
      "Epoch 15::Minibatch 47::LR 0.0676923076923 --> Loss 0.0046505288283\n",
      "Epoch 15::Minibatch 48::LR 0.0676923076923 --> Loss 0.00605469544729\n",
      "Epoch 15::Minibatch 49::LR 0.0676923076923 --> Loss 0.00625224192937\n",
      "Epoch 15::Minibatch 50::LR 0.0676923076923 --> Loss 0.00606648127238\n",
      "Epoch 15::Minibatch 51::LR 0.0676923076923 --> Loss 0.00768978198369\n",
      "Epoch 15::Minibatch 52::LR 0.0676923076923 --> Loss 0.00349901715914\n",
      "Epoch 15::Minibatch 53::LR 0.0676923076923 --> Loss 0.0034813050429\n",
      "Epoch 15::Minibatch 54::LR 0.0676923076923 --> Loss 0.00403453071912\n",
      "Epoch 15::Minibatch 55::LR 0.0676923076923 --> Loss 0.000994196534157\n",
      "Epoch 15::Minibatch 56::LR 0.0676923076923 --> Loss 0.00272527595361\n",
      "Epoch 15::Minibatch 57::LR 0.0676923076923 --> Loss 0.00583883285522\n",
      "Epoch 15::Minibatch 58::LR 0.0676923076923 --> Loss 0.00338885505994\n",
      "Epoch 15::Minibatch 59::LR 0.0676923076923 --> Loss 0.00256889661153\n",
      "Epoch 15::Minibatch 60::LR 0.0676923076923 --> Loss 0.00239819029967\n",
      "Epoch 15::Minibatch 61::LR 0.0676923076923 --> Loss 0.000914468169212\n",
      "Epoch 15::Minibatch 62::LR 0.0676923076923 --> Loss 0.00329887092113\n",
      "Epoch 15::Minibatch 63::LR 0.0676923076923 --> Loss 0.00217707018058\n",
      "Epoch 15::Minibatch 64::LR 0.0676923076923 --> Loss 0.00093641102314\n",
      "Epoch 15::Minibatch 65::LR 0.0676923076923 --> Loss 0.00240050653617\n",
      "Epoch 15::Minibatch 66::LR 0.0676923076923 --> Loss 0.00290258069833\n",
      "Epoch 15::Minibatch 67::LR 0.0676923076923 --> Loss 0.00282127122084\n",
      "Epoch 15::Minibatch 68::LR 0.0676923076923 --> Loss 0.00201836407185\n",
      "Epoch 15::Minibatch 69::LR 0.0676923076923 --> Loss 0.00404689153035\n",
      "Epoch 15::Minibatch 70::LR 0.0676923076923 --> Loss 0.00347262501717\n",
      "Epoch 15::Minibatch 71::LR 0.0676923076923 --> Loss 0.00236100137234\n",
      "Epoch 15::Minibatch 72::LR 0.0676923076923 --> Loss 0.000549195061127\n",
      "Epoch 15::Minibatch 73::LR 0.0676923076923 --> Loss 0.00398619572322\n",
      "Epoch 15::Minibatch 74::LR 0.0676923076923 --> Loss 0.0041981959343\n",
      "Epoch 15::Minibatch 75::LR 0.0676923076923 --> Loss 0.00251984298229\n",
      "Epoch 15::Minibatch 76::LR 0.0676923076923 --> Loss 0.00061362862587\n",
      "Epoch 15::Minibatch 77::LR 0.0676923076923 --> Loss 0.00407992362976\n",
      "Epoch 15::Minibatch 78::LR 0.0676923076923 --> Loss 0.00389093995094\n",
      "Epoch 15::Minibatch 79::LR 0.0676923076923 --> Loss 0.00204503456752\n",
      "Epoch 15::Minibatch 80::LR 0.0676923076923 --> Loss 0.00335499445597\n",
      "Epoch 15::Minibatch 81::LR 0.0676923076923 --> Loss 0.00289615571499\n",
      "Epoch 15::Minibatch 82::LR 0.0676923076923 --> Loss 0.00204347113768\n",
      "Epoch 15::Minibatch 83::LR 0.0676923076923 --> Loss 0.00481293876966\n",
      "Epoch 15::Minibatch 84::LR 0.0676923076923 --> Loss 0.00205109794935\n",
      "Epoch 15::Minibatch 85::LR 0.0676923076923 --> Loss 0.00282979170481\n",
      "Epoch 15::Minibatch 86::LR 0.0676923076923 --> Loss 0.00228285014629\n",
      "Epoch 15::Minibatch 87::LR 0.0676923076923 --> Loss 0.00255033771197\n",
      "Epoch 15::Minibatch 88::LR 0.0676923076923 --> Loss 0.00185124615828\n",
      "Epoch 15::Minibatch 89::LR 0.0676923076923 --> Loss 0.00238057593505\n",
      "Epoch 15::Minibatch 90::LR 0.0676923076923 --> Loss 0.00118386824926\n",
      "Epoch 15::Minibatch 91::LR 0.0676923076923 --> Loss 0.000948827366034\n",
      "Epoch 15::Minibatch 92::LR 0.0676923076923 --> Loss 0.00274039824804\n",
      "Epoch 15::Minibatch 93::LR 0.0676923076923 --> Loss 0.00180434405804\n",
      "Epoch 15::Minibatch 94::LR 0.0676923076923 --> Loss 0.00179282724857\n",
      "Epoch 15::Minibatch 95::LR 0.0676923076923 --> Loss 0.0017986057202\n",
      "Epoch 15::Minibatch 96::LR 0.0676923076923 --> Loss 0.00601219614347\n",
      "Epoch 15::Minibatch 97::LR 0.0676923076923 --> Loss 0.00322169999282\n",
      "Epoch 15::Minibatch 98::LR 0.0676923076923 --> Loss 0.000975574354331\n",
      "Epoch 15::Minibatch 99::LR 0.0676923076923 --> Loss 0.00130417327086\n",
      "Epoch 15::Minibatch 100::LR 0.0676923076923 --> Loss 0.00533248066902\n",
      "Epoch 15::Minibatch 101::LR 0.0676923076923 --> Loss 0.000951907038689\n",
      "Epoch 15::Minibatch 102::LR 0.0676923076923 --> Loss 0.00387432058652\n",
      "Epoch 15::Minibatch 103::LR 0.0676923076923 --> Loss 0.00404354055723\n",
      "Epoch 15::Minibatch 104::LR 0.0676923076923 --> Loss 0.00280922750632\n",
      "Epoch 15::Minibatch 105::LR 0.0676923076923 --> Loss 0.00287502189477\n",
      "Epoch 15::Minibatch 106::LR 0.0676923076923 --> Loss 0.0185256195068\n",
      "Epoch 15::Minibatch 107::LR 0.0676923076923 --> Loss 0.00491097132365\n",
      "Epoch 15::Minibatch 108::LR 0.0676923076923 --> Loss 0.001115625302\n",
      "Epoch 15::Minibatch 109::LR 0.0676923076923 --> Loss 0.00444916685422\n",
      "Epoch 15::Minibatch 110::LR 0.0676923076923 --> Loss 0.0024806813399\n",
      "Epoch 15::Minibatch 111::LR 0.0676923076923 --> Loss 0.00102581689755\n",
      "Epoch 15::Minibatch 112::LR 0.0676923076923 --> Loss 0.0036577697595\n",
      "Epoch 15::Minibatch 113::LR 0.0676923076923 --> Loss 0.00276573260625\n",
      "Epoch 15::Minibatch 114::LR 0.0676923076923 --> Loss 0.00153849750757\n",
      "Epoch 15::Minibatch 115::LR 0.0676923076923 --> Loss 0.00140407641729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 116::LR 0.0676923076923 --> Loss 0.00287252644698\n",
      "Epoch 15::Minibatch 117::LR 0.0676923076923 --> Loss 0.00381509025892\n",
      "Epoch 15::Minibatch 118::LR 0.0676923076923 --> Loss 0.00700567960739\n",
      "Epoch 15::Minibatch 119::LR 0.0676923076923 --> Loss 0.000706648031871\n",
      "Epoch 15::Minibatch 120::LR 0.0676923076923 --> Loss 0.00187739511331\n",
      "Epoch 15::Minibatch 121::LR 0.0676923076923 --> Loss 0.00278735816479\n",
      "Epoch 15::Minibatch 122::LR 0.0676923076923 --> Loss 0.00373823602994\n",
      "Epoch 15::Minibatch 123::LR 0.0676923076923 --> Loss 0.00113952924808\n",
      "Epoch 15::Minibatch 124::LR 0.0676923076923 --> Loss 0.00286703248819\n",
      "Epoch 15::Minibatch 125::LR 0.0676923076923 --> Loss 0.00472255587578\n",
      "Epoch 15::Minibatch 126::LR 0.0676923076923 --> Loss 0.00280051251252\n",
      "Epoch 15::Minibatch 127::LR 0.0676923076923 --> Loss 0.00447446386019\n",
      "Epoch 15::Minibatch 128::LR 0.0676923076923 --> Loss 0.00366758942604\n",
      "Epoch 15::Minibatch 129::LR 0.0676923076923 --> Loss 0.0027980752786\n",
      "Epoch 15::Minibatch 130::LR 0.0676923076923 --> Loss 0.00438162843386\n",
      "Epoch 15::Minibatch 131::LR 0.0676923076923 --> Loss 0.00184307893117\n",
      "Epoch 15::Minibatch 132::LR 0.0676923076923 --> Loss 0.00317392726739\n",
      "Epoch 15::Minibatch 133::LR 0.0676923076923 --> Loss 0.00302549441655\n",
      "Epoch 15::Minibatch 134::LR 0.0676923076923 --> Loss 0.00245967507362\n",
      "Epoch 15::Minibatch 135::LR 0.0676923076923 --> Loss 0.00166513492664\n",
      "Epoch 15::Minibatch 136::LR 0.0676923076923 --> Loss 0.00279349307219\n",
      "Epoch 15::Minibatch 137::LR 0.0676923076923 --> Loss 0.00374575694402\n",
      "Epoch 15::Minibatch 138::LR 0.0676923076923 --> Loss 0.00134587109089\n",
      "Epoch 15::Minibatch 139::LR 0.0676923076923 --> Loss 0.00193013846874\n",
      "Epoch 15::Minibatch 140::LR 0.0676923076923 --> Loss 0.00248660624027\n",
      "Epoch 15::Minibatch 141::LR 0.0676923076923 --> Loss 0.00300693710645\n",
      "Epoch 15::Minibatch 142::LR 0.0676923076923 --> Loss 0.00298556009928\n",
      "Epoch 15::Minibatch 143::LR 0.0676923076923 --> Loss 0.000630483378967\n",
      "Epoch 15::Minibatch 144::LR 0.0676923076923 --> Loss 0.00322939912478\n",
      "Epoch 15::Minibatch 145::LR 0.0676923076923 --> Loss 0.00436618169149\n",
      "Epoch 15::Minibatch 146::LR 0.0676923076923 --> Loss 0.00262921631336\n",
      "Epoch 15::Minibatch 147::LR 0.0676923076923 --> Loss 0.00183861494064\n",
      "Epoch 15::Minibatch 148::LR 0.0676923076923 --> Loss 0.00103146662315\n",
      "Epoch 15::Minibatch 149::LR 0.0676923076923 --> Loss 0.00285383562247\n",
      "Epoch 15::Minibatch 150::LR 0.0676923076923 --> Loss 0.00276119728883\n",
      "Epoch 15::Minibatch 151::LR 0.0676923076923 --> Loss 0.00426545699437\n",
      "Epoch 15::Minibatch 152::LR 0.0676923076923 --> Loss 0.00093632509311\n",
      "Epoch 15::Minibatch 153::LR 0.0676923076923 --> Loss 0.00187062402566\n",
      "Epoch 15::Minibatch 154::LR 0.0676923076923 --> Loss 0.0020804921786\n",
      "Epoch 15::Minibatch 155::LR 0.0676923076923 --> Loss 0.0046257130305\n",
      "Epoch 15::Minibatch 156::LR 0.0676923076923 --> Loss 0.00242652654648\n",
      "Epoch 15::Minibatch 157::LR 0.0676923076923 --> Loss 0.000707921137412\n",
      "Epoch 15::Minibatch 158::LR 0.0676923076923 --> Loss 0.0030894635121\n",
      "Epoch 15::Minibatch 159::LR 0.0676923076923 --> Loss 0.00278276542823\n",
      "Epoch 15::Minibatch 160::LR 0.0676923076923 --> Loss 0.00266265352567\n",
      "Epoch 15::Minibatch 161::LR 0.0676923076923 --> Loss 0.00103481113911\n",
      "Epoch 15::Minibatch 162::LR 0.0676923076923 --> Loss 0.00373182892799\n",
      "Epoch 15::Minibatch 163::LR 0.0676923076923 --> Loss 0.00242466489474\n",
      "Epoch 15::Minibatch 164::LR 0.0676923076923 --> Loss 0.00251038869222\n",
      "Epoch 15::Minibatch 165::LR 0.0676923076923 --> Loss 0.000542034506798\n",
      "Epoch 15::Minibatch 166::LR 0.0676923076923 --> Loss 0.00181645433108\n",
      "Epoch 15::Minibatch 167::LR 0.0676923076923 --> Loss 0.00247367978096\n",
      "Epoch 15::Minibatch 168::LR 0.0676923076923 --> Loss 0.00221247156461\n",
      "Epoch 15::Minibatch 169::LR 0.0676923076923 --> Loss 0.00102667987347\n",
      "Epoch 15::Minibatch 170::LR 0.0676923076923 --> Loss 0.00100073297819\n",
      "Epoch 15::Minibatch 171::LR 0.0676923076923 --> Loss 0.0025328185161\n",
      "Epoch 15::Minibatch 172::LR 0.0676923076923 --> Loss 0.00460926572482\n",
      "Epoch 15::Minibatch 173::LR 0.0676923076923 --> Loss 0.00196821053823\n",
      "Epoch 15::Minibatch 174::LR 0.0676923076923 --> Loss 0.00106689622005\n",
      "Epoch 15::Minibatch 175::LR 0.0676923076923 --> Loss 0.00231055001418\n",
      "Epoch 15::Minibatch 176::LR 0.0676923076923 --> Loss 0.00329218327999\n",
      "Epoch 15::Minibatch 177::LR 0.0676923076923 --> Loss 0.00471659501394\n",
      "Epoch 15::Minibatch 178::LR 0.0676923076923 --> Loss 0.00165778676669\n",
      "Epoch 15::Minibatch 179::LR 0.0676923076923 --> Loss 0.00136402795712\n",
      "Epoch 15::Minibatch 180::LR 0.0676923076923 --> Loss 0.00360629280408\n",
      "Epoch 15::Minibatch 181::LR 0.0676923076923 --> Loss 0.00332878430684\n",
      "Epoch 15::Minibatch 182::LR 0.0676923076923 --> Loss 0.000797277738651\n",
      "Epoch 15::Minibatch 183::LR 0.0676923076923 --> Loss 0.00170841813087\n",
      "Epoch 15::Minibatch 184::LR 0.0676923076923 --> Loss 0.0034397816658\n",
      "Epoch 15::Minibatch 185::LR 0.0676923076923 --> Loss 0.00284555613995\n",
      "Epoch 15::Minibatch 186::LR 0.0676923076923 --> Loss 0.000991248190403\n",
      "Epoch 15::Minibatch 187::LR 0.0676923076923 --> Loss 0.00125426650047\n",
      "Epoch 15::Minibatch 188::LR 0.0676923076923 --> Loss 0.00417915344238\n",
      "Epoch 15::Minibatch 189::LR 0.0676923076923 --> Loss 0.00451843659083\n",
      "Epoch 15::Minibatch 190::LR 0.0676923076923 --> Loss 0.00232545336088\n",
      "Epoch 15::Minibatch 191::LR 0.0676923076923 --> Loss 0.000491193036238\n",
      "Epoch 15::Minibatch 192::LR 0.0676923076923 --> Loss 0.0027081400156\n",
      "Epoch 15::Minibatch 193::LR 0.0676923076923 --> Loss 0.00253982424736\n",
      "Epoch 15::Minibatch 194::LR 0.0676923076923 --> Loss 0.0018014361461\n",
      "Epoch 15::Minibatch 195::LR 0.0676923076923 --> Loss 0.000388660058379\n",
      "Epoch 15::Minibatch 196::LR 0.0676923076923 --> Loss 0.00121878832579\n",
      "Epoch 15::Minibatch 197::LR 0.0676923076923 --> Loss 0.00284107764562\n",
      "Epoch 15::Minibatch 198::LR 0.0676923076923 --> Loss 0.00219437102477\n",
      "Epoch 15::Minibatch 199::LR 0.0676923076923 --> Loss 0.000287562062343\n",
      "Epoch 15::Minibatch 200::LR 0.0676923076923 --> Loss 0.00208135445913\n",
      "Epoch 15::Minibatch 201::LR 0.0676923076923 --> Loss 0.00196538170179\n",
      "Epoch 15::Minibatch 202::LR 0.0676923076923 --> Loss 0.00189183314641\n",
      "Epoch 15::Minibatch 203::LR 0.0676923076923 --> Loss 0.00178965648015\n",
      "Epoch 15::Minibatch 204::LR 0.0676923076923 --> Loss 0.00149194061756\n",
      "Epoch 15::Minibatch 205::LR 0.0676923076923 --> Loss 0.00222848494848\n",
      "Epoch 15::Minibatch 206::LR 0.0676923076923 --> Loss 0.00670831680298\n",
      "Epoch 15::Minibatch 207::LR 0.0676923076923 --> Loss 0.00140068332354\n",
      "Epoch 15::Minibatch 208::LR 0.0676923076923 --> Loss 0.00114665418863\n",
      "Epoch 15::Minibatch 209::LR 0.0676923076923 --> Loss 0.00217020610968\n",
      "Epoch 15::Minibatch 210::LR 0.0676923076923 --> Loss 0.00206061959267\n",
      "Epoch 15::Minibatch 211::LR 0.0676923076923 --> Loss 0.00219890693823\n",
      "Epoch 15::Minibatch 212::LR 0.0676923076923 --> Loss 0.00407213449478\n",
      "Epoch 15::Minibatch 213::LR 0.0676923076923 --> Loss 0.00602276603381\n",
      "Epoch 15::Minibatch 214::LR 0.0676923076923 --> Loss 0.00959566275279\n",
      "Epoch 15::Minibatch 215::LR 0.0676923076923 --> Loss 0.00141550680002\n",
      "Epoch 15::Minibatch 216::LR 0.0676923076923 --> Loss 0.00554945985476\n",
      "Epoch 15::Minibatch 217::LR 0.0676923076923 --> Loss 0.00616944789886\n",
      "Epoch 15::Minibatch 218::LR 0.0676923076923 --> Loss 0.00400071700414\n",
      "Epoch 15::Minibatch 219::LR 0.0676923076923 --> Loss 0.00402182102203\n",
      "Epoch 15::Minibatch 220::LR 0.0676923076923 --> Loss 0.00456764022509\n",
      "Epoch 15::Minibatch 221::LR 0.0676923076923 --> Loss 0.00428991039594\n",
      "Epoch 15::Minibatch 222::LR 0.0676923076923 --> Loss 0.00329876045386\n",
      "Epoch 15::Minibatch 223::LR 0.0676923076923 --> Loss 0.00143759111563\n",
      "Epoch 15::Minibatch 224::LR 0.0676923076923 --> Loss 0.0018176261584\n",
      "Epoch 15::Minibatch 225::LR 0.0676923076923 --> Loss 0.00721043348312\n",
      "Epoch 15::Minibatch 226::LR 0.0676923076923 --> Loss 0.003816943566\n",
      "Epoch 15::Minibatch 227::LR 0.0676923076923 --> Loss 0.00170923988024\n",
      "Epoch 15::Minibatch 228::LR 0.0676923076923 --> Loss 0.000776307235161\n",
      "Epoch 15::Minibatch 229::LR 0.0676923076923 --> Loss 0.00484918951988\n",
      "Epoch 15::Minibatch 230::LR 0.0676923076923 --> Loss 0.00399373571078\n",
      "Epoch 15::Minibatch 231::LR 0.0676923076923 --> Loss 0.00264657000701\n",
      "Epoch 15::Minibatch 232::LR 0.0676923076923 --> Loss 0.00124579687913\n",
      "Epoch 15::Minibatch 233::LR 0.0676923076923 --> Loss 0.00242622077465\n",
      "Epoch 15::Minibatch 234::LR 0.0676923076923 --> Loss 0.00670536438624\n",
      "Epoch 15::Minibatch 235::LR 0.0676923076923 --> Loss 0.00469723939896\n",
      "Epoch 15::Minibatch 236::LR 0.0676923076923 --> Loss 0.00179824491342\n",
      "Epoch 15::Minibatch 237::LR 0.0676923076923 --> Loss 0.000713358720144\n",
      "Epoch 15::Minibatch 238::LR 0.0676923076923 --> Loss 0.00343051393827\n",
      "Epoch 15::Minibatch 239::LR 0.0676923076923 --> Loss 0.00296811103821\n",
      "Epoch 15::Minibatch 240::LR 0.0676923076923 --> Loss 0.00325506369273\n",
      "Epoch 15::Minibatch 241::LR 0.0676923076923 --> Loss 0.000787284473578\n",
      "Epoch 15::Minibatch 242::LR 0.0676923076923 --> Loss 0.00716167370478\n",
      "Epoch 15::Minibatch 243::LR 0.0676923076923 --> Loss 0.00358239173889\n",
      "Epoch 15::Minibatch 244::LR 0.0676923076923 --> Loss 0.00299707035224\n",
      "Epoch 15::Minibatch 245::LR 0.0676923076923 --> Loss 0.00049480954806\n",
      "Epoch 15::Minibatch 246::LR 0.0676923076923 --> Loss 0.00210511823495\n",
      "Epoch 15::Minibatch 247::LR 0.0676923076923 --> Loss 0.0134776115417\n",
      "Epoch 15::Minibatch 248::LR 0.0676923076923 --> Loss 0.00456484079361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 249::LR 0.0676923076923 --> Loss 0.00282673180103\n",
      "Epoch 15::Minibatch 250::LR 0.0676923076923 --> Loss 0.00270686467489\n",
      "Epoch 15::Minibatch 251::LR 0.0676923076923 --> Loss 0.00259993155797\n",
      "Epoch 15::Minibatch 252::LR 0.0676923076923 --> Loss 0.00185522099336\n",
      "Epoch 15::Minibatch 253::LR 0.0676923076923 --> Loss 0.00316509306431\n",
      "Epoch 15::Minibatch 254::LR 0.0676923076923 --> Loss 0.00526565392812\n",
      "Epoch 15::Minibatch 255::LR 0.0676923076923 --> Loss 0.00392177303632\n",
      "Epoch 15::Minibatch 256::LR 0.0676923076923 --> Loss 0.00171299040318\n",
      "Epoch 15::Minibatch 257::LR 0.0676923076923 --> Loss 0.00128283530474\n",
      "Epoch 15::Minibatch 258::LR 0.0676923076923 --> Loss 0.00365329265594\n",
      "Epoch 15::Minibatch 259::LR 0.0676923076923 --> Loss 0.00184584041437\n",
      "Epoch 15::Minibatch 260::LR 0.0676923076923 --> Loss 0.00191709578037\n",
      "Epoch 15::Minibatch 261::LR 0.0676923076923 --> Loss 0.00293262402217\n",
      "Epoch 15::Minibatch 262::LR 0.0676923076923 --> Loss 0.00197022438049\n",
      "Epoch 15::Minibatch 263::LR 0.0676923076923 --> Loss 0.00239800433318\n",
      "Epoch 15::Minibatch 264::LR 0.0676923076923 --> Loss 0.00366998990377\n",
      "Epoch 15::Minibatch 265::LR 0.0676923076923 --> Loss 0.0103952598572\n",
      "Epoch 15::Minibatch 266::LR 0.0676923076923 --> Loss 0.00104049384594\n",
      "Epoch 15::Minibatch 267::LR 0.0676923076923 --> Loss 0.0101693336169\n",
      "Epoch 15::Minibatch 268::LR 0.0676923076923 --> Loss 0.00122142742078\n",
      "Epoch 15::Minibatch 269::LR 0.0676923076923 --> Loss 0.00358448346456\n",
      "Epoch 15::Minibatch 270::LR 0.0676923076923 --> Loss 0.00657203912735\n",
      "Epoch 15::Minibatch 271::LR 0.0676923076923 --> Loss 0.00276954631011\n",
      "Epoch 15::Minibatch 272::LR 0.0676923076923 --> Loss 0.00411167263985\n",
      "Epoch 15::Minibatch 273::LR 0.0676923076923 --> Loss 0.00171601990859\n",
      "Epoch 15::Minibatch 274::LR 0.0676923076923 --> Loss 0.00181038558483\n",
      "Epoch 15::Minibatch 275::LR 0.0676923076923 --> Loss 0.00269666910172\n",
      "Epoch 15::Minibatch 276::LR 0.0676923076923 --> Loss 0.00348499218623\n",
      "Epoch 15::Minibatch 277::LR 0.0676923076923 --> Loss 0.00102596958478\n",
      "Epoch 15::Minibatch 278::LR 0.0676923076923 --> Loss 0.00265070776145\n",
      "Epoch 15::Minibatch 279::LR 0.0676923076923 --> Loss 0.00242318828901\n",
      "Epoch 15::Minibatch 280::LR 0.0676923076923 --> Loss 0.00210245569547\n",
      "Epoch 15::Minibatch 281::LR 0.0676923076923 --> Loss 0.00132300694784\n",
      "Epoch 15::Minibatch 282::LR 0.0676923076923 --> Loss 0.00224637508392\n",
      "Epoch 15::Minibatch 283::LR 0.0676923076923 --> Loss 0.00220362842083\n",
      "Epoch 15::Minibatch 284::LR 0.0676923076923 --> Loss 0.00175417999427\n",
      "Epoch 15::Minibatch 285::LR 0.0676923076923 --> Loss 0.00122677137454\n",
      "Epoch 15::Minibatch 286::LR 0.0676923076923 --> Loss 0.00215543210506\n",
      "Epoch 15::Minibatch 287::LR 0.0676923076923 --> Loss 0.00208318491777\n",
      "Epoch 15::Minibatch 288::LR 0.0676923076923 --> Loss 0.00112043758233\n",
      "Epoch 15::Minibatch 289::LR 0.0676923076923 --> Loss 0.00158733993769\n",
      "Epoch 15::Minibatch 290::LR 0.0676923076923 --> Loss 0.00195041100184\n",
      "Epoch 15::Minibatch 291::LR 0.0676923076923 --> Loss 0.00173458774885\n",
      "Epoch 15::Minibatch 292::LR 0.0676923076923 --> Loss 0.000611280103525\n",
      "Epoch 15::Minibatch 293::LR 0.0676923076923 --> Loss 0.00148612856865\n",
      "Epoch 15::Minibatch 294::LR 0.0676923076923 --> Loss 0.00156701763471\n",
      "Epoch 15::Minibatch 295::LR 0.0676923076923 --> Loss 0.00185302396615\n",
      "Epoch 15::Minibatch 296::LR 0.0676923076923 --> Loss 0.00160103370746\n",
      "Epoch 15::Minibatch 297::LR 0.0676923076923 --> Loss 0.00139324476322\n",
      "Epoch 15::Minibatch 298::LR 0.0676923076923 --> Loss 0.00137400497993\n",
      "Epoch 15::Minibatch 299::LR 0.0676923076923 --> Loss 0.000797565976779\n",
      "Epoch 15::Minibatch 300::LR 0.0676923076923 --> Loss 0.00283488710721\n",
      "Epoch 15::Minibatch 301::LR 0.0676923076923 --> Loss 0.00274935126305\n",
      "Epoch 15::Minibatch 302::LR 0.0676923076923 --> Loss 0.00254284838835\n",
      "Epoch 15::Minibatch 303::LR 0.0676923076923 --> Loss 0.000868701636791\n",
      "Epoch 15::Minibatch 304::LR 0.0676923076923 --> Loss 0.00312690496445\n",
      "Epoch 15::Minibatch 305::LR 0.0676923076923 --> Loss 0.0016891392072\n",
      "Epoch 15::Minibatch 306::LR 0.0676923076923 --> Loss 0.000931042035421\n",
      "Epoch 15::Minibatch 307::LR 0.0676923076923 --> Loss 0.00247032006582\n",
      "Epoch 15::Minibatch 308::LR 0.0676923076923 --> Loss 0.00198320746422\n",
      "Epoch 15::Minibatch 309::LR 0.0676923076923 --> Loss 0.000997471412023\n",
      "Epoch 15::Minibatch 310::LR 0.0676923076923 --> Loss 0.00110561311245\n",
      "Epoch 15::Minibatch 311::LR 0.0676923076923 --> Loss 0.00170386632284\n",
      "Epoch 15::Minibatch 312::LR 0.0676923076923 --> Loss 0.00298283259074\n",
      "Epoch 15::Minibatch 313::LR 0.0676923076923 --> Loss 0.00240584472815\n",
      "Epoch 15::Minibatch 314::LR 0.0676923076923 --> Loss 0.00191863854726\n",
      "Epoch 15::Minibatch 315::LR 0.0676923076923 --> Loss 0.000993917584419\n",
      "Epoch 15::Minibatch 316::LR 0.0676923076923 --> Loss 0.00232880791028\n",
      "Epoch 15::Minibatch 317::LR 0.0676923076923 --> Loss 0.00154921203852\n",
      "Epoch 15::Minibatch 318::LR 0.0676923076923 --> Loss 0.00121593922377\n",
      "Epoch 15::Minibatch 319::LR 0.0676923076923 --> Loss 0.00229509731134\n",
      "Epoch 15::Minibatch 320::LR 0.0676923076923 --> Loss 0.00323228657246\n",
      "Epoch 15::Minibatch 321::LR 0.0676923076923 --> Loss 0.000863906443119\n",
      "Epoch 15::Minibatch 322::LR 0.0676923076923 --> Loss 0.00368198037148\n",
      "Epoch 15::Minibatch 323::LR 0.0676923076923 --> Loss 0.00356611053149\n",
      "Epoch 15::Minibatch 324::LR 0.0676923076923 --> Loss 0.00263765990734\n",
      "Epoch 15::Minibatch 325::LR 0.0676923076923 --> Loss 0.00241584996382\n",
      "Epoch 15::Minibatch 326::LR 0.0676923076923 --> Loss 0.0055424284935\n",
      "Epoch 15::Minibatch 327::LR 0.0676923076923 --> Loss 0.00227203289668\n",
      "Epoch 15::Minibatch 328::LR 0.0676923076923 --> Loss 0.00333571314812\n",
      "Epoch 15::Minibatch 329::LR 0.0676923076923 --> Loss 0.00123942087094\n",
      "Epoch 15::Minibatch 330::LR 0.0676923076923 --> Loss 0.00161795467138\n",
      "Epoch 15::Minibatch 331::LR 0.0676923076923 --> Loss 0.00255997220675\n",
      "Epoch 15::Minibatch 332::LR 0.0676923076923 --> Loss 0.00251976867517\n",
      "Epoch 15::Minibatch 333::LR 0.0676923076923 --> Loss 0.00145876944065\n",
      "Epoch 15::Minibatch 334::LR 0.0676923076923 --> Loss 0.00437552849452\n",
      "Epoch 15::Minibatch 335::LR 0.0676923076923 --> Loss 0.00189410070578\n",
      "Epoch 15::Minibatch 336::LR 0.0676923076923 --> Loss 0.0021439832449\n",
      "Epoch 15::Minibatch 337::LR 0.0676923076923 --> Loss 0.00340796907743\n",
      "Epoch 15::Minibatch 338::LR 0.0676923076923 --> Loss 0.000521476517121\n",
      "Epoch 15::Minibatch 339::LR 0.0676923076923 --> Loss 0.00332581937313\n",
      "Epoch 15::Minibatch 340::LR 0.0676923076923 --> Loss 0.0042561507225\n",
      "Epoch 15::Minibatch 341::LR 0.0676923076923 --> Loss 0.00495163202286\n",
      "Epoch 15::Minibatch 342::LR 0.0676923076923 --> Loss 0.00319350083669\n",
      "Epoch 15::Minibatch 343::LR 0.0676923076923 --> Loss 0.00170464754105\n",
      "Epoch 15::Minibatch 344::LR 0.0676923076923 --> Loss 0.00311768134435\n",
      "Epoch 15::Minibatch 345::LR 0.0676923076923 --> Loss 0.00431503534317\n",
      "Epoch 15::Minibatch 346::LR 0.0676923076923 --> Loss 0.00570499181747\n",
      "Epoch 15::Minibatch 347::LR 0.0676923076923 --> Loss 0.000871443748474\n",
      "Epoch 15::Minibatch 348::LR 0.0676923076923 --> Loss 0.00347870429357\n",
      "Epoch 15::Minibatch 349::LR 0.0676923076923 --> Loss 0.00351342717806\n",
      "Epoch 15::Minibatch 350::LR 0.0676923076923 --> Loss 0.00180016160011\n",
      "Epoch 15::Minibatch 351::LR 0.0676923076923 --> Loss 0.00354173501333\n",
      "Epoch 15::Minibatch 352::LR 0.0676923076923 --> Loss 0.00487540245056\n",
      "Epoch 15::Minibatch 353::LR 0.0676923076923 --> Loss 0.00355932394663\n",
      "Epoch 15::Minibatch 354::LR 0.0676923076923 --> Loss 0.00296346008778\n",
      "Epoch 15::Minibatch 355::LR 0.0676923076923 --> Loss 0.00617589751879\n",
      "Epoch 15::Minibatch 356::LR 0.0676923076923 --> Loss 0.00313785076141\n",
      "Epoch 15::Minibatch 357::LR 0.0676923076923 --> Loss 0.00115966588259\n",
      "Epoch 15::Minibatch 358::LR 0.0676923076923 --> Loss 0.00218514740467\n",
      "Epoch 15::Minibatch 359::LR 0.0676923076923 --> Loss 0.00274625102679\n",
      "Epoch 15::Minibatch 360::LR 0.0676923076923 --> Loss 0.00244901319345\n",
      "Epoch 15::Minibatch 361::LR 0.0676923076923 --> Loss 0.00244500617186\n",
      "Epoch 15::Minibatch 362::LR 0.0676923076923 --> Loss 0.00243210156759\n",
      "Epoch 15::Minibatch 363::LR 0.0676923076923 --> Loss 0.000675344566504\n",
      "Epoch 15::Minibatch 364::LR 0.0676923076923 --> Loss 0.0020199706157\n",
      "Epoch 15::Minibatch 365::LR 0.0676923076923 --> Loss 0.00211261212826\n",
      "Epoch 15::Minibatch 366::LR 0.0676923076923 --> Loss 0.00226725677649\n",
      "Epoch 15::Minibatch 367::LR 0.0676923076923 --> Loss 0.00110109746456\n",
      "Epoch 15::Minibatch 368::LR 0.0676923076923 --> Loss 0.000996562143167\n",
      "Epoch 15::Minibatch 369::LR 0.0676923076923 --> Loss 0.00289229353269\n",
      "Epoch 15::Minibatch 370::LR 0.0676923076923 --> Loss 0.00227541148663\n",
      "Epoch 15::Minibatch 371::LR 0.0676923076923 --> Loss 0.00188105662664\n",
      "Epoch 15::Minibatch 372::LR 0.0676923076923 --> Loss 0.000443213830392\n",
      "Epoch 15::Minibatch 373::LR 0.0676923076923 --> Loss 0.0017689371109\n",
      "Epoch 15::Minibatch 374::LR 0.0676923076923 --> Loss 0.00218005915483\n",
      "Epoch 15::Minibatch 375::LR 0.0676923076923 --> Loss 0.0018415047725\n",
      "Epoch 15::Minibatch 376::LR 0.0676923076923 --> Loss 0.00124245226383\n",
      "Epoch 15::Minibatch 377::LR 0.0676923076923 --> Loss 0.00195201774438\n",
      "Epoch 15::Minibatch 378::LR 0.0676923076923 --> Loss 0.00213502546151\n",
      "Epoch 15::Minibatch 379::LR 0.0676923076923 --> Loss 0.00238462209702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 380::LR 0.0676923076923 --> Loss 0.0015898368756\n",
      "Epoch 15::Minibatch 381::LR 0.0676923076923 --> Loss 0.000985702772935\n",
      "Epoch 15::Minibatch 382::LR 0.0676923076923 --> Loss 0.00201340893904\n",
      "Epoch 15::Minibatch 383::LR 0.0676923076923 --> Loss 0.00195344487826\n",
      "Epoch 15::Minibatch 384::LR 0.0676923076923 --> Loss 0.00104905813932\n",
      "Epoch 15::Minibatch 385::LR 0.0676923076923 --> Loss 0.0010370456179\n",
      "Epoch 15::Minibatch 386::LR 0.0676923076923 --> Loss 0.00218144337336\n",
      "Epoch 15::Minibatch 387::LR 0.0676923076923 --> Loss 0.00233851492405\n",
      "Epoch 15::Minibatch 388::LR 0.0676923076923 --> Loss 0.00114844014247\n",
      "Epoch 15::Minibatch 389::LR 0.0676923076923 --> Loss 0.00181222160657\n",
      "Epoch 15::Minibatch 390::LR 0.0676923076923 --> Loss 0.00359668652217\n",
      "Epoch 15::Minibatch 391::LR 0.0676923076923 --> Loss 0.00269996364911\n",
      "Epoch 15::Minibatch 392::LR 0.0676923076923 --> Loss 0.00265506426493\n",
      "Epoch 15::Minibatch 393::LR 0.0676923076923 --> Loss 0.00278148849805\n",
      "Epoch 15::Minibatch 394::LR 0.0676923076923 --> Loss 0.00210628847281\n",
      "Epoch 15::Minibatch 395::LR 0.0676923076923 --> Loss 0.00205812672774\n",
      "Epoch 15::Minibatch 396::LR 0.0676923076923 --> Loss 0.00195226430893\n",
      "Epoch 15::Minibatch 397::LR 0.0676923076923 --> Loss 0.00208264549573\n",
      "Epoch 15::Minibatch 398::LR 0.0676923076923 --> Loss 0.0020649745067\n",
      "Epoch 15::Minibatch 399::LR 0.0676923076923 --> Loss 0.00236702620983\n",
      "Epoch 15::Minibatch 400::LR 0.0676923076923 --> Loss 0.00201796432336\n",
      "Epoch 15::Minibatch 401::LR 0.0676923076923 --> Loss 0.00350928028425\n",
      "Epoch 15::Minibatch 402::LR 0.0676923076923 --> Loss 0.00184445977211\n",
      "Epoch 15::Minibatch 403::LR 0.0676923076923 --> Loss 0.00147035628557\n",
      "Epoch 15::Minibatch 404::LR 0.0676923076923 --> Loss 0.00151237587134\n",
      "Epoch 15::Minibatch 405::LR 0.0676923076923 --> Loss 0.00354475696882\n",
      "Epoch 15::Minibatch 406::LR 0.0676923076923 --> Loss 0.00246940573057\n",
      "Epoch 15::Minibatch 407::LR 0.0676923076923 --> Loss 0.0017455859979\n",
      "Epoch 15::Minibatch 408::LR 0.0676923076923 --> Loss 0.000446095317602\n",
      "Epoch 15::Minibatch 409::LR 0.0676923076923 --> Loss 0.00236334562302\n",
      "Epoch 15::Minibatch 410::LR 0.0676923076923 --> Loss 0.00322751979033\n",
      "Epoch 15::Minibatch 411::LR 0.0676923076923 --> Loss 0.00163898587227\n",
      "Epoch 15::Minibatch 412::LR 0.0676923076923 --> Loss 0.000965263942877\n",
      "Epoch 15::Minibatch 413::LR 0.0676923076923 --> Loss 0.00197715163231\n",
      "Epoch 15::Minibatch 414::LR 0.0676923076923 --> Loss 0.00182534416517\n",
      "Epoch 15::Minibatch 415::LR 0.0676923076923 --> Loss 0.00114038864772\n",
      "Epoch 15::Minibatch 416::LR 0.0676923076923 --> Loss 0.000819424788157\n",
      "Epoch 15::Minibatch 417::LR 0.0676923076923 --> Loss 0.00170508722464\n",
      "Epoch 15::Minibatch 418::LR 0.0676923076923 --> Loss 0.0028050605456\n",
      "Epoch 15::Minibatch 419::LR 0.0676923076923 --> Loss 0.000507329255342\n",
      "Epoch 15::Minibatch 420::LR 0.0676923076923 --> Loss 0.000700260450443\n",
      "Epoch 15::Minibatch 421::LR 0.0676923076923 --> Loss 0.0019476767381\n",
      "Epoch 15::Minibatch 422::LR 0.0676923076923 --> Loss 0.00217340826988\n",
      "Epoch 15::Minibatch 423::LR 0.0676923076923 --> Loss 0.000972714424133\n",
      "Epoch 15::Minibatch 424::LR 0.0676923076923 --> Loss 0.00156252503395\n",
      "Epoch 15::Minibatch 425::LR 0.0676923076923 --> Loss 0.00289813975493\n",
      "Epoch 15::Minibatch 426::LR 0.0676923076923 --> Loss 0.00200736860434\n",
      "Epoch 15::Minibatch 427::LR 0.0676923076923 --> Loss 0.000711528559526\n",
      "Epoch 15::Minibatch 428::LR 0.0676923076923 --> Loss 0.00105554640293\n",
      "Epoch 15::Minibatch 429::LR 0.0676923076923 --> Loss 0.00241450428963\n",
      "Epoch 15::Minibatch 430::LR 0.0676923076923 --> Loss 0.00946358521779\n",
      "Epoch 15::Minibatch 431::LR 0.0676923076923 --> Loss 0.00382847825686\n",
      "Epoch 15::Minibatch 432::LR 0.0676923076923 --> Loss 0.00447426795959\n",
      "Epoch 15::Minibatch 433::LR 0.0676923076923 --> Loss 0.00258071998755\n",
      "Epoch 15::Minibatch 434::LR 0.0676923076923 --> Loss 0.00254863202572\n",
      "Epoch 15::Minibatch 435::LR 0.0676923076923 --> Loss 0.00236048579216\n",
      "Epoch 15::Minibatch 436::LR 0.0676923076923 --> Loss 0.0017220890522\n",
      "Epoch 15::Minibatch 437::LR 0.0676923076923 --> Loss 0.00330288887024\n",
      "Epoch 15::Minibatch 438::LR 0.0676923076923 --> Loss 0.00262645661831\n",
      "Epoch 15::Minibatch 439::LR 0.0676923076923 --> Loss 0.00211099823316\n",
      "Epoch 15::Minibatch 440::LR 0.0676923076923 --> Loss 0.00324840247631\n",
      "Epoch 15::Minibatch 441::LR 0.0676923076923 --> Loss 0.00304982721806\n",
      "Epoch 15::Minibatch 442::LR 0.0676923076923 --> Loss 0.00278606553872\n",
      "Epoch 15::Minibatch 443::LR 0.0676923076923 --> Loss 0.00372021436691\n",
      "Epoch 15::Minibatch 444::LR 0.0676923076923 --> Loss 0.00289921522141\n",
      "Epoch 15::Minibatch 445::LR 0.0676923076923 --> Loss 0.000901897350947\n",
      "Epoch 15::Minibatch 446::LR 0.0676923076923 --> Loss 0.00147301505009\n",
      "Epoch 15::Minibatch 447::LR 0.0676923076923 --> Loss 0.00244809250037\n",
      "Epoch 15::Minibatch 448::LR 0.0676923076923 --> Loss 0.00242028594017\n",
      "Epoch 15::Minibatch 449::LR 0.0676923076923 --> Loss 0.00374291737874\n",
      "Epoch 15::Minibatch 450::LR 0.0676923076923 --> Loss 0.00233041067918\n",
      "Epoch 15::Minibatch 451::LR 0.0676923076923 --> Loss 0.00406028787295\n",
      "Epoch 15::Minibatch 452::LR 0.0676923076923 --> Loss 0.00239065229893\n",
      "Epoch 15::Minibatch 453::LR 0.0676923076923 --> Loss 0.000385581602653\n",
      "Epoch 15::Minibatch 454::LR 0.0676923076923 --> Loss 0.00362835129102\n",
      "Epoch 15::Minibatch 455::LR 0.0676923076923 --> Loss 0.0027103660504\n",
      "Epoch 15::Minibatch 456::LR 0.0676923076923 --> Loss 0.00314791361491\n",
      "Epoch 15::Minibatch 457::LR 0.0676923076923 --> Loss 0.00197395523389\n",
      "Epoch 15::Minibatch 458::LR 0.0676923076923 --> Loss 0.000766759465138\n",
      "Epoch 15::Minibatch 459::LR 0.0676923076923 --> Loss 0.00415877580643\n",
      "Epoch 15::Minibatch 460::LR 0.0676923076923 --> Loss 0.00261311769485\n",
      "Epoch 15::Minibatch 461::LR 0.0676923076923 --> Loss 0.00392739772797\n",
      "Epoch 15::Minibatch 462::LR 0.0676923076923 --> Loss 0.00040188493828\n",
      "Epoch 15::Minibatch 463::LR 0.0676923076923 --> Loss 0.00460874517759\n",
      "Epoch 15::Minibatch 464::LR 0.0676923076923 --> Loss 0.00205135504405\n",
      "Epoch 15::Minibatch 465::LR 0.0676923076923 --> Loss 0.00526944557826\n",
      "Epoch 15::Minibatch 466::LR 0.0676923076923 --> Loss 0.00511717557907\n",
      "Epoch 15::Minibatch 467::LR 0.0676923076923 --> Loss 0.00581796725591\n",
      "Epoch 15::Minibatch 468::LR 0.0676923076923 --> Loss 0.00612592061361\n",
      "Epoch 15::Minibatch 469::LR 0.0676923076923 --> Loss 0.0067450205485\n",
      "Epoch 15::Minibatch 470::LR 0.0676923076923 --> Loss 0.00378560463587\n",
      "Epoch 15::Minibatch 471::LR 0.0676923076923 --> Loss 0.00174680431684\n",
      "Epoch 15::Minibatch 472::LR 0.0676923076923 --> Loss 0.0035330983003\n",
      "Epoch 15::Minibatch 473::LR 0.0676923076923 --> Loss 0.00223873714606\n",
      "Epoch 15::Minibatch 474::LR 0.0676923076923 --> Loss 0.000703030526638\n",
      "Epoch 15::Minibatch 475::LR 0.0676923076923 --> Loss 0.00484491745631\n",
      "Epoch 15::Minibatch 476::LR 0.0676923076923 --> Loss 0.00768388271332\n",
      "Epoch 15::Minibatch 477::LR 0.0676923076923 --> Loss 0.000937112371127\n",
      "Epoch 15::Minibatch 478::LR 0.0676923076923 --> Loss 0.00248531897863\n",
      "Epoch 15::Minibatch 479::LR 0.0676923076923 --> Loss 0.00195272902648\n",
      "Epoch 15::Minibatch 480::LR 0.0676923076923 --> Loss 0.00152910282214\n",
      "Epoch 15::Minibatch 481::LR 0.0676923076923 --> Loss 0.000959221820037\n",
      "Epoch 15::Minibatch 482::LR 0.0676923076923 --> Loss 0.00209582448006\n",
      "Epoch 15::Minibatch 483::LR 0.0676923076923 --> Loss 0.00320667545001\n",
      "Epoch 15::Minibatch 484::LR 0.0676923076923 --> Loss 0.00355296691259\n",
      "Epoch 15::Minibatch 485::LR 0.0676923076923 --> Loss 0.000757263402144\n",
      "Epoch 15::Minibatch 486::LR 0.0676923076923 --> Loss 0.00299157977104\n",
      "Epoch 15::Minibatch 487::LR 0.0676923076923 --> Loss 0.00338401317596\n",
      "Epoch 15::Minibatch 488::LR 0.0676923076923 --> Loss 0.00204582889875\n",
      "Epoch 15::Minibatch 489::LR 0.0676923076923 --> Loss 0.00322191317876\n",
      "Epoch 15::Minibatch 490::LR 0.0676923076923 --> Loss 0.000414047737916\n",
      "Epoch 15::Minibatch 491::LR 0.0676923076923 --> Loss 0.00380969723066\n",
      "Epoch 15::Minibatch 492::LR 0.0676923076923 --> Loss 0.00304696122805\n",
      "Epoch 15::Minibatch 493::LR 0.0676923076923 --> Loss 0.0030224275589\n",
      "Epoch 15::Minibatch 494::LR 0.0676923076923 --> Loss 0.000740831891696\n",
      "Epoch 15::Minibatch 495::LR 0.0676923076923 --> Loss 0.00189536531766\n",
      "Epoch 15::Minibatch 496::LR 0.0676923076923 --> Loss 0.00290506223838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 497::LR 0.0676923076923 --> Loss 0.000934687157472\n",
      "Epoch 15::Minibatch 498::LR 0.0676923076923 --> Loss 0.000570990939935\n",
      "Epoch 15::Minibatch 499::LR 0.0676923076923 --> Loss 0.0036795369784\n",
      "Epoch 15::Minibatch 500::LR 0.0676923076923 --> Loss 0.00144665847222\n",
      "Epoch 15::Minibatch 501::LR 0.0676923076923 --> Loss 0.00223940571149\n",
      "Epoch 15::Minibatch 502::LR 0.0676923076923 --> Loss 0.00386326948802\n",
      "Epoch 15::Minibatch 503::LR 0.0676923076923 --> Loss 0.00854299386342\n",
      "Epoch 15::Minibatch 504::LR 0.0676923076923 --> Loss 0.00789341131846\n",
      "Epoch 15::Minibatch 505::LR 0.0676923076923 --> Loss 0.00432958682378\n",
      "Epoch 15::Minibatch 506::LR 0.0676923076923 --> Loss 0.00347860614459\n",
      "Epoch 15::Minibatch 507::LR 0.0676923076923 --> Loss 0.00604294776917\n",
      "Epoch 15::Minibatch 508::LR 0.0676923076923 --> Loss 0.00341189702352\n",
      "Epoch 15::Minibatch 509::LR 0.0676923076923 --> Loss 0.00461648344994\n",
      "Epoch 15::Minibatch 510::LR 0.0676923076923 --> Loss 0.00461238304774\n",
      "Epoch 15::Minibatch 511::LR 0.0676923076923 --> Loss 0.00391302466393\n",
      "Epoch 15::Minibatch 512::LR 0.0676923076923 --> Loss 0.00270379304886\n",
      "Epoch 15::Minibatch 513::LR 0.0676923076923 --> Loss 0.000672866553068\n",
      "Epoch 15::Minibatch 514::LR 0.0676923076923 --> Loss 0.00268948773543\n",
      "Epoch 15::Minibatch 515::LR 0.0676923076923 --> Loss 0.00301430622737\n",
      "Epoch 15::Minibatch 516::LR 0.0676923076923 --> Loss 0.0041086490949\n",
      "Epoch 15::Minibatch 517::LR 0.0676923076923 --> Loss 0.00349132259687\n",
      "Epoch 15::Minibatch 518::LR 0.0676923076923 --> Loss 0.00257923523585\n",
      "Epoch 15::Minibatch 519::LR 0.0676923076923 --> Loss 0.00344768921534\n",
      "Epoch 15::Minibatch 520::LR 0.0676923076923 --> Loss 0.00534813642502\n",
      "Epoch 15::Minibatch 521::LR 0.0676923076923 --> Loss 0.00544168631236\n",
      "Epoch 15::Minibatch 522::LR 0.0676923076923 --> Loss 0.00805913050969\n",
      "Epoch 15::Minibatch 523::LR 0.0676923076923 --> Loss 0.000660568724076\n",
      "Epoch 15::Minibatch 524::LR 0.0676923076923 --> Loss 0.00142902334531\n",
      "Epoch 15::Minibatch 525::LR 0.0676923076923 --> Loss 0.00325226247311\n",
      "Epoch 15::Minibatch 526::LR 0.0676923076923 --> Loss 0.00407543420792\n",
      "Epoch 15::Minibatch 527::LR 0.0676923076923 --> Loss 0.00232183178266\n",
      "Epoch 15::Minibatch 528::LR 0.0676923076923 --> Loss 0.00109929462274\n",
      "Epoch 15::Minibatch 529::LR 0.0676923076923 --> Loss 0.00416215936343\n",
      "Epoch 15::Minibatch 530::LR 0.0676923076923 --> Loss 0.00422822157542\n",
      "Epoch 15::Minibatch 531::LR 0.0676923076923 --> Loss 0.00371277848879\n",
      "Epoch 15::Minibatch 532::LR 0.0676923076923 --> Loss 0.002732112209\n",
      "Epoch 15::Minibatch 533::LR 0.0676923076923 --> Loss 0.0050277809302\n",
      "Epoch 15::Minibatch 534::LR 0.0676923076923 --> Loss 0.00384492635727\n",
      "Epoch 15::Minibatch 535::LR 0.0676923076923 --> Loss 0.00326507588228\n",
      "Epoch 15::Minibatch 536::LR 0.0676923076923 --> Loss 0.00210994760195\n",
      "Epoch 15::Minibatch 537::LR 0.0676923076923 --> Loss 0.000641780445973\n",
      "Epoch 15::Minibatch 538::LR 0.0676923076923 --> Loss 0.00169845660528\n",
      "Epoch 15::Minibatch 539::LR 0.0676923076923 --> Loss 0.00344081878662\n",
      "Epoch 15::Minibatch 540::LR 0.0676923076923 --> Loss 0.00341892560323\n",
      "Epoch 15::Minibatch 541::LR 0.0676923076923 --> Loss 0.00290973901749\n",
      "Epoch 15::Minibatch 542::LR 0.0676923076923 --> Loss 0.0025442336003\n",
      "Epoch 15::Minibatch 543::LR 0.0676923076923 --> Loss 0.00276509304841\n",
      "Epoch 15::Minibatch 544::LR 0.0676923076923 --> Loss 0.00391470074654\n",
      "Epoch 15::Minibatch 545::LR 0.0676923076923 --> Loss 0.0020499308904\n",
      "Epoch 15::Minibatch 546::LR 0.0676923076923 --> Loss 0.000657099634409\n",
      "Epoch 15::Minibatch 547::LR 0.0676923076923 --> Loss 0.00263462603092\n",
      "Epoch 15::Minibatch 548::LR 0.0676923076923 --> Loss 0.00376343886058\n",
      "Epoch 15::Minibatch 549::LR 0.0676923076923 --> Loss 0.00858604192734\n",
      "Epoch 15::Minibatch 550::LR 0.0676923076923 --> Loss 0.00116969068845\n",
      "Epoch 15::Minibatch 551::LR 0.0676923076923 --> Loss 0.00245854278406\n",
      "Epoch 15::Minibatch 552::LR 0.0676923076923 --> Loss 0.00358320991198\n",
      "Epoch 15::Minibatch 553::LR 0.0676923076923 --> Loss 0.00323012451331\n",
      "Epoch 15::Minibatch 554::LR 0.0676923076923 --> Loss 0.00376582304637\n",
      "Epoch 15::Minibatch 555::LR 0.0676923076923 --> Loss 0.000987841784954\n",
      "Epoch 15::Minibatch 556::LR 0.0676923076923 --> Loss 0.00200653751691\n",
      "Epoch 15::Minibatch 557::LR 0.0676923076923 --> Loss 0.00246498684088\n",
      "Epoch 15::Minibatch 558::LR 0.0676923076923 --> Loss 0.0038064746062\n",
      "Epoch 15::Minibatch 559::LR 0.0676923076923 --> Loss 0.00375989675522\n",
      "Epoch 15::Minibatch 560::LR 0.0676923076923 --> Loss 0.00313956320286\n",
      "Epoch 15::Minibatch 561::LR 0.0676923076923 --> Loss 0.002731158336\n",
      "Epoch 15::Minibatch 562::LR 0.0676923076923 --> Loss 0.00238730390867\n",
      "Epoch 15::Minibatch 563::LR 0.0676923076923 --> Loss 0.0040617064635\n",
      "Epoch 15::Minibatch 564::LR 0.0676923076923 --> Loss 0.00314250310262\n",
      "Epoch 15::Minibatch 565::LR 0.0676923076923 --> Loss 0.00369660218557\n",
      "Epoch 15::Minibatch 566::LR 0.0676923076923 --> Loss 0.00229728957017\n",
      "Epoch 15::Minibatch 567::LR 0.0676923076923 --> Loss 0.00258926173051\n",
      "Epoch 15::Minibatch 568::LR 0.0676923076923 --> Loss 0.00182306150595\n",
      "Epoch 15::Minibatch 569::LR 0.0676923076923 --> Loss 0.000566044648488\n",
      "Epoch 15::Minibatch 570::LR 0.0676923076923 --> Loss 0.00171159724394\n",
      "Epoch 15::Minibatch 571::LR 0.0676923076923 --> Loss 0.00224340299765\n",
      "Epoch 15::Minibatch 572::LR 0.0676923076923 --> Loss 0.00238531847795\n",
      "Epoch 15::Minibatch 573::LR 0.0676923076923 --> Loss 0.00151353607575\n",
      "Epoch 15::Minibatch 574::LR 0.0676923076923 --> Loss 0.00105007598797\n",
      "Epoch 15::Minibatch 575::LR 0.0676923076923 --> Loss 0.00179091870785\n",
      "Epoch 15::Minibatch 576::LR 0.0676923076923 --> Loss 0.00213621556759\n",
      "Epoch 15::Minibatch 577::LR 0.0676923076923 --> Loss 0.00166986723741\n",
      "Epoch 15::Minibatch 578::LR 0.0676923076923 --> Loss 0.00128936549028\n",
      "Epoch 15::Minibatch 579::LR 0.0676923076923 --> Loss 0.00120470801989\n",
      "Epoch 15::Minibatch 580::LR 0.0676923076923 --> Loss 0.00194845199585\n",
      "Epoch 15::Minibatch 581::LR 0.0676923076923 --> Loss 0.00171925942103\n",
      "Epoch 15::Minibatch 582::LR 0.0676923076923 --> Loss 0.00412167867025\n",
      "Epoch 15::Minibatch 583::LR 0.0676923076923 --> Loss 0.000942406157653\n",
      "Epoch 15::Minibatch 584::LR 0.0676923076923 --> Loss 0.00130992362897\n",
      "Epoch 15::Minibatch 585::LR 0.0676923076923 --> Loss 0.00451856096586\n",
      "Epoch 15::Minibatch 586::LR 0.0676923076923 --> Loss 0.00403907378515\n",
      "Epoch 15::Minibatch 587::LR 0.0676923076923 --> Loss 0.00113317966461\n",
      "Epoch 15::Minibatch 588::LR 0.0676923076923 --> Loss 0.00141614556313\n",
      "Epoch 15::Minibatch 589::LR 0.0676923076923 --> Loss 0.0027696788311\n",
      "Epoch 15::Minibatch 590::LR 0.0676923076923 --> Loss 0.00197742243608\n",
      "Epoch 15::Minibatch 591::LR 0.0676923076923 --> Loss 0.00308930496375\n",
      "Epoch 15::Minibatch 592::LR 0.0676923076923 --> Loss 0.00118559340636\n",
      "Epoch 15::Minibatch 593::LR 0.0676923076923 --> Loss 0.00261905054251\n",
      "Epoch 15::Minibatch 594::LR 0.0676923076923 --> Loss 0.00277969717979\n",
      "Epoch 15::Minibatch 595::LR 0.0676923076923 --> Loss 0.00305429836114\n",
      "Epoch 15::Minibatch 596::LR 0.0676923076923 --> Loss 0.00195030848185\n",
      "Epoch 15::Minibatch 597::LR 0.0676923076923 --> Loss 0.00119684805473\n",
      "Epoch 15::Minibatch 598::LR 0.0676923076923 --> Loss 0.00303954362869\n",
      "Epoch 15::Minibatch 599::LR 0.0676923076923 --> Loss 0.00187128702799\n",
      "Epoch 15::Minibatch 600::LR 0.0676923076923 --> Loss 0.00224008361499\n",
      "Epoch 15::Minibatch 601::LR 0.0676923076923 --> Loss 0.0039180568854\n",
      "Epoch 15::Minibatch 602::LR 0.0676923076923 --> Loss 0.00212842643261\n",
      "Epoch 15::Minibatch 603::LR 0.0676923076923 --> Loss 0.00265825966994\n",
      "Epoch 15::Minibatch 604::LR 0.0676923076923 --> Loss 0.00165807803472\n",
      "Epoch 15::Minibatch 605::LR 0.0676923076923 --> Loss 0.00239572842916\n",
      "Epoch 15::Minibatch 606::LR 0.0676923076923 --> Loss 0.00193424940109\n",
      "Epoch 15::Minibatch 607::LR 0.0676923076923 --> Loss 0.000848957995574\n",
      "Epoch 15::Minibatch 608::LR 0.0676923076923 --> Loss 0.00159474819899\n",
      "Epoch 15::Minibatch 609::LR 0.0676923076923 --> Loss 0.00238597671191\n",
      "Epoch 15::Minibatch 610::LR 0.0676923076923 --> Loss 0.00404129624367\n",
      "Epoch 15::Minibatch 611::LR 0.0676923076923 --> Loss 0.00265995264053\n",
      "Epoch 15::Minibatch 612::LR 0.0676923076923 --> Loss 0.000493554621935\n",
      "Epoch 15::Minibatch 613::LR 0.0676923076923 --> Loss 0.0013140608867\n",
      "Epoch 15::Minibatch 614::LR 0.0676923076923 --> Loss 0.00247579395771\n",
      "Epoch 15::Minibatch 615::LR 0.0676923076923 --> Loss 0.00169089516004\n",
      "Epoch 15::Minibatch 616::LR 0.0676923076923 --> Loss 0.000931869546572\n",
      "Epoch 15::Minibatch 617::LR 0.0676923076923 --> Loss 0.000509619812171\n",
      "Epoch 15::Minibatch 618::LR 0.0676923076923 --> Loss 0.00275250633558\n",
      "Epoch 15::Minibatch 619::LR 0.0676923076923 --> Loss 0.00192672630151\n",
      "Epoch 15::Minibatch 620::LR 0.0676923076923 --> Loss 0.00172481159369\n",
      "Epoch 15::Minibatch 621::LR 0.0676923076923 --> Loss 0.000858849585056\n",
      "Epoch 15::Minibatch 622::LR 0.0676923076923 --> Loss 0.000808385858933\n",
      "Epoch 15::Minibatch 623::LR 0.0676923076923 --> Loss 0.00222026785215\n",
      "Epoch 15::Minibatch 624::LR 0.0676923076923 --> Loss 0.00181829075019\n",
      "Epoch 15::Minibatch 625::LR 0.0676923076923 --> Loss 0.00301724890868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 626::LR 0.0676923076923 --> Loss 0.00454748829206\n",
      "Epoch 15::Minibatch 627::LR 0.0676923076923 --> Loss 0.00133916934331\n",
      "Epoch 15::Minibatch 628::LR 0.0676923076923 --> Loss 0.000913260579109\n",
      "Epoch 15::Minibatch 629::LR 0.0676923076923 --> Loss 0.00344023187955\n",
      "Epoch 15::Minibatch 630::LR 0.0676923076923 --> Loss 0.00334721724192\n",
      "Epoch 15::Minibatch 631::LR 0.0676923076923 --> Loss 0.00661780238152\n",
      "Epoch 15::Minibatch 632::LR 0.0676923076923 --> Loss 0.000801624556382\n",
      "Epoch 15::Minibatch 633::LR 0.0676923076923 --> Loss 0.00166746358077\n",
      "Epoch 15::Minibatch 634::LR 0.0676923076923 --> Loss 0.00326028982798\n",
      "Epoch 15::Minibatch 635::LR 0.0676923076923 --> Loss 0.00518381953239\n",
      "Epoch 15::Minibatch 636::LR 0.0676923076923 --> Loss 0.00523208340009\n",
      "Epoch 15::Minibatch 637::LR 0.0676923076923 --> Loss 0.000814851125081\n",
      "Epoch 15::Minibatch 638::LR 0.0676923076923 --> Loss 0.00154078364372\n",
      "Epoch 15::Minibatch 639::LR 0.0676923076923 --> Loss 0.00333779295286\n",
      "Epoch 15::Minibatch 640::LR 0.0676923076923 --> Loss 0.00503602822622\n",
      "Epoch 15::Minibatch 641::LR 0.0676923076923 --> Loss 0.00316184441249\n",
      "Epoch 15::Minibatch 642::LR 0.0676923076923 --> Loss 0.000560098638137\n",
      "Epoch 15::Minibatch 643::LR 0.0676923076923 --> Loss 0.00235721151034\n",
      "Epoch 15::Minibatch 644::LR 0.0676923076923 --> Loss 0.00401413003604\n",
      "Epoch 15::Minibatch 645::LR 0.0676923076923 --> Loss 0.00421690583229\n",
      "Epoch 15::Minibatch 646::LR 0.0676923076923 --> Loss 0.0015361019969\n",
      "Epoch 15::Minibatch 647::LR 0.0676923076923 --> Loss 0.000554940849543\n",
      "Epoch 15::Minibatch 648::LR 0.0676923076923 --> Loss 0.0030067072312\n",
      "Epoch 15::Minibatch 649::LR 0.0676923076923 --> Loss 0.00357606291771\n",
      "Epoch 15::Minibatch 650::LR 0.0676923076923 --> Loss 0.00333796143532\n",
      "Epoch 15::Minibatch 651::LR 0.0676923076923 --> Loss 0.00140106280645\n",
      "Epoch 15::Minibatch 652::LR 0.0676923076923 --> Loss 0.000829364707073\n",
      "Epoch 15::Minibatch 653::LR 0.0676923076923 --> Loss 0.00287900050481\n",
      "Epoch 15::Minibatch 654::LR 0.0676923076923 --> Loss 0.00311660647392\n",
      "Epoch 15::Minibatch 655::LR 0.0676923076923 --> Loss 0.00349633812904\n",
      "Epoch 15::Minibatch 656::LR 0.0676923076923 --> Loss 0.000770944605271\n",
      "Epoch 15::Minibatch 657::LR 0.0676923076923 --> Loss 0.002233680288\n",
      "Epoch 15::Minibatch 658::LR 0.0676923076923 --> Loss 0.00497485756874\n",
      "Epoch 15::Minibatch 659::LR 0.0676923076923 --> Loss 0.00233878095945\n",
      "Epoch 15::Minibatch 660::LR 0.0676923076923 --> Loss 0.00261367539565\n",
      "Epoch 15::Minibatch 661::LR 0.0676923076923 --> Loss 0.00253263612588\n",
      "Epoch 15::Minibatch 662::LR 0.0676923076923 --> Loss 0.00182850996653\n",
      "Epoch 15::Minibatch 663::LR 0.0676923076923 --> Loss 0.00367040832837\n",
      "Epoch 15::Minibatch 664::LR 0.0676923076923 --> Loss 0.00348016579946\n",
      "Epoch 15::Minibatch 665::LR 0.0676923076923 --> Loss 0.000751443902651\n",
      "Epoch 15::Minibatch 666::LR 0.0676923076923 --> Loss 0.0039437464873\n",
      "Epoch 15::Minibatch 667::LR 0.0676923076923 --> Loss 0.00256439407667\n",
      "Epoch 15::Minibatch 668::LR 0.0676923076923 --> Loss 0.00707603136698\n",
      "Epoch 15::Minibatch 669::LR 0.0676923076923 --> Loss 0.0010942765077\n",
      "Epoch 15::Minibatch 670::LR 0.0676923076923 --> Loss 0.00136459817489\n",
      "Epoch 15::Minibatch 671::LR 0.0676923076923 --> Loss 0.00541476607323\n",
      "Epoch 15::Minibatch 672::LR 0.0676923076923 --> Loss 0.00378869255384\n",
      "Epoch 15::Minibatch 673::LR 0.0676923076923 --> Loss 0.0016245140632\n",
      "Epoch 15::Minibatch 674::LR 0.0676923076923 --> Loss 0.000522563358148\n",
      "Epoch 15::Minibatch 675::LR 0.0676923076923 --> Loss 0.00219229876995\n",
      "Epoch 15::Minibatch 676::LR 0.0676923076923 --> Loss 0.0021248827378\n",
      "Epoch 15::Minibatch 677::LR 0.0676923076923 --> Loss 0.00282717724641\n",
      "Epoch 15::Minibatch 678::LR 0.0676923076923 --> Loss 0.00194234251976\n",
      "Epoch 15::Minibatch 679::LR 0.0676923076923 --> Loss 0.00354025363922\n",
      "Epoch 15::Minibatch 680::LR 0.0676923076923 --> Loss 0.00215007265409\n",
      "Epoch 15::Minibatch 681::LR 0.0676923076923 --> Loss 0.00244322538376\n",
      "Epoch 15::Minibatch 682::LR 0.0676923076923 --> Loss 0.000765595734119\n",
      "Epoch 15::Minibatch 683::LR 0.0676923076923 --> Loss 0.00239639381568\n",
      "Epoch 15::Minibatch 684::LR 0.0676923076923 --> Loss 0.00235891898473\n",
      "Epoch 15::Minibatch 685::LR 0.0676923076923 --> Loss 0.00292839427789\n",
      "Epoch 15::Minibatch 686::LR 0.0676923076923 --> Loss 0.00154302537441\n",
      "Epoch 15::Minibatch 687::LR 0.0676923076923 --> Loss 0.000848027865092\n",
      "Epoch 15::Minibatch 688::LR 0.0676923076923 --> Loss 0.00276479780674\n",
      "Epoch 15::Minibatch 689::LR 0.0676923076923 --> Loss 0.00254217763742\n",
      "Epoch 15::Minibatch 690::LR 0.0676923076923 --> Loss 0.00192248682181\n",
      "Epoch 15::Minibatch 691::LR 0.0676923076923 --> Loss 0.000664240668217\n",
      "Epoch 15::Minibatch 692::LR 0.0676923076923 --> Loss 0.00247968018055\n",
      "Epoch 15::Minibatch 693::LR 0.0676923076923 --> Loss 0.00257555266221\n",
      "Epoch 15::Minibatch 694::LR 0.0676923076923 --> Loss 0.00302697300911\n",
      "Epoch 15::Minibatch 695::LR 0.0676923076923 --> Loss 0.00173601269722\n",
      "Epoch 15::Minibatch 696::LR 0.0676923076923 --> Loss 0.00204374631246\n",
      "Epoch 15::Minibatch 697::LR 0.0676923076923 --> Loss 0.00140848726034\n",
      "Epoch 15::Minibatch 698::LR 0.0676923076923 --> Loss 0.00162589212259\n",
      "Epoch 15::Minibatch 699::LR 0.0676923076923 --> Loss 0.00385720332464\n",
      "Epoch 15::Minibatch 700::LR 0.0676923076923 --> Loss 0.0026924286286\n",
      "Epoch 15::Minibatch 701::LR 0.0676923076923 --> Loss 0.00200291315715\n",
      "Epoch 15::Minibatch 702::LR 0.0676923076923 --> Loss 0.00166559656461\n",
      "Epoch 15::Minibatch 703::LR 0.0676923076923 --> Loss 0.00429134726524\n",
      "Epoch 15::Minibatch 704::LR 0.0676923076923 --> Loss 0.00180772264798\n",
      "Epoch 15::Minibatch 705::LR 0.0676923076923 --> Loss 0.00286457419395\n",
      "Epoch 15::Minibatch 706::LR 0.0676923076923 --> Loss 0.0022457631429\n",
      "Epoch 15::Minibatch 707::LR 0.0676923076923 --> Loss 0.00118540743987\n",
      "Epoch 15::Minibatch 708::LR 0.0676923076923 --> Loss 0.00173634668191\n",
      "Epoch 15::Minibatch 709::LR 0.0676923076923 --> Loss 0.00169201294581\n",
      "Epoch 15::Minibatch 710::LR 0.0676923076923 --> Loss 0.00251445094744\n",
      "Epoch 15::Minibatch 711::LR 0.0676923076923 --> Loss 0.00191952784856\n",
      "Epoch 15::Minibatch 712::LR 0.0676923076923 --> Loss 0.00132938484351\n",
      "Epoch 15::Minibatch 713::LR 0.0676923076923 --> Loss 0.00175554990768\n",
      "Epoch 15::Minibatch 714::LR 0.0676923076923 --> Loss 0.00274133463701\n",
      "Epoch 15::Minibatch 715::LR 0.0676923076923 --> Loss 0.00294734179974\n",
      "Epoch 15::Minibatch 716::LR 0.0676923076923 --> Loss 0.00161218543847\n",
      "Epoch 15::Minibatch 717::LR 0.0676923076923 --> Loss 0.00161298195521\n",
      "Epoch 15::Minibatch 718::LR 0.0676923076923 --> Loss 0.0012607717514\n",
      "Epoch 15::Minibatch 719::LR 0.0676923076923 --> Loss 0.00166588614384\n",
      "Epoch 15::Minibatch 720::LR 0.0676923076923 --> Loss 0.00254199663798\n",
      "Epoch 15::Minibatch 721::LR 0.0676923076923 --> Loss 0.000628303686778\n",
      "Epoch 15::Minibatch 722::LR 0.0676923076923 --> Loss 0.00482133944829\n",
      "Epoch 15::Minibatch 723::LR 0.0676923076923 --> Loss 0.00491670449575\n",
      "Epoch 15::Minibatch 724::LR 0.0676923076923 --> Loss 0.000971650679906\n",
      "Epoch 15::Minibatch 725::LR 0.0676923076923 --> Loss 0.00221542437871\n",
      "Epoch 15::Minibatch 726::LR 0.0676923076923 --> Loss 0.00469100554784\n",
      "Epoch 15::Minibatch 727::LR 0.0676923076923 --> Loss 0.00320932805538\n",
      "Epoch 15::Minibatch 728::LR 0.0676923076923 --> Loss 0.000649509429932\n",
      "Epoch 15::Minibatch 729::LR 0.0676923076923 --> Loss 0.000756516257922\n",
      "Epoch 15::Minibatch 730::LR 0.0676923076923 --> Loss 0.00275970717271\n",
      "Epoch 15::Minibatch 731::LR 0.0676923076923 --> Loss 0.00248281419277\n",
      "Epoch 15::Minibatch 732::LR 0.0676923076923 --> Loss 0.00225535988808\n",
      "Epoch 15::Minibatch 733::LR 0.0676923076923 --> Loss 0.000699245284001\n",
      "Epoch 15::Minibatch 734::LR 0.0676923076923 --> Loss 0.00176580131054\n",
      "Epoch 15::Minibatch 735::LR 0.0676923076923 --> Loss 0.00235570450624\n",
      "Epoch 15::Minibatch 736::LR 0.0676923076923 --> Loss 0.00346403797468\n",
      "Epoch 15::Minibatch 737::LR 0.0676923076923 --> Loss 0.00309206664562\n",
      "Epoch 15::Minibatch 738::LR 0.0676923076923 --> Loss 0.00161438385646\n",
      "Epoch 15::Minibatch 739::LR 0.0676923076923 --> Loss 0.00248909652233\n",
      "Epoch 15::Minibatch 740::LR 0.0676923076923 --> Loss 0.0038617114226\n",
      "Epoch 15::Minibatch 741::LR 0.0676923076923 --> Loss 0.00270874023438\n",
      "Epoch 15::Minibatch 742::LR 0.0676923076923 --> Loss 0.0021158494552\n",
      "Epoch 15::Minibatch 743::LR 0.0676923076923 --> Loss 0.00138305356105\n",
      "Epoch 15::Minibatch 744::LR 0.0676923076923 --> Loss 0.00180017550786\n",
      "Epoch 15::Minibatch 745::LR 0.0676923076923 --> Loss 0.00285227000713\n",
      "Epoch 15::Minibatch 746::LR 0.0676923076923 --> Loss 0.0029985187451\n",
      "Epoch 15::Minibatch 747::LR 0.0676923076923 --> Loss 0.0017975761493\n",
      "Epoch 15::Minibatch 748::LR 0.0676923076923 --> Loss 0.000634619245927\n",
      "Epoch 15::Minibatch 749::LR 0.0676923076923 --> Loss 0.00165124018987\n",
      "Epoch 15::Minibatch 750::LR 0.0676923076923 --> Loss 0.00247579932213\n",
      "Epoch 15::Minibatch 751::LR 0.0676923076923 --> Loss 0.00273473183314\n",
      "Epoch 15::Minibatch 752::LR 0.0676923076923 --> Loss 0.00117410769065\n",
      "Epoch 15::Minibatch 753::LR 0.0676923076923 --> Loss 0.00223752498627\n",
      "Epoch 15::Minibatch 754::LR 0.0676923076923 --> Loss 0.00239738444487\n",
      "Epoch 15::Minibatch 755::LR 0.0676923076923 --> Loss 0.00266823172569\n",
      "Epoch 15::Minibatch 756::LR 0.0676923076923 --> Loss 0.00140580326319\n",
      "Epoch 15::Minibatch 757::LR 0.0676923076923 --> Loss 0.000813432633877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 758::LR 0.0676923076923 --> Loss 0.00162484894196\n",
      "Epoch 15::Minibatch 759::LR 0.0676923076923 --> Loss 0.00376568277677\n",
      "Epoch 15::Minibatch 760::LR 0.0676923076923 --> Loss 0.00303087830544\n",
      "Epoch 15::Minibatch 761::LR 0.0676923076923 --> Loss 0.0063121787707\n",
      "Epoch 15::Minibatch 762::LR 0.0676923076923 --> Loss 0.00376698454221\n",
      "Epoch 15::Minibatch 763::LR 0.0676923076923 --> Loss 0.00356401801109\n",
      "Epoch 15::Minibatch 764::LR 0.0676923076923 --> Loss 0.00318810304006\n",
      "Epoch 15::Minibatch 765::LR 0.0676923076923 --> Loss 0.00131911168496\n",
      "Epoch 15::Minibatch 766::LR 0.0676923076923 --> Loss 0.00227277457714\n",
      "Epoch 15::Minibatch 767::LR 0.0676923076923 --> Loss 0.00501404166222\n",
      "Epoch 15::Minibatch 768::LR 0.0676923076923 --> Loss 0.00360174020131\n",
      "Epoch 15::Minibatch 769::LR 0.0676923076923 --> Loss 0.00189491430918\n",
      "Epoch 15::Minibatch 770::LR 0.0676923076923 --> Loss 0.00148557494084\n",
      "Epoch 15::Minibatch 771::LR 0.0676923076923 --> Loss 0.00372274875641\n",
      "Epoch 15::Minibatch 772::LR 0.0676923076923 --> Loss 0.0033901421229\n",
      "Epoch 15::Minibatch 773::LR 0.0676923076923 --> Loss 0.00313014904658\n",
      "Epoch 15::Minibatch 774::LR 0.0676923076923 --> Loss 0.0017818860213\n",
      "Epoch 15::Minibatch 775::LR 0.0676923076923 --> Loss 0.00389126022657\n",
      "Epoch 15::Minibatch 776::LR 0.0676923076923 --> Loss 0.00357137560844\n",
      "Epoch 15::Minibatch 777::LR 0.0676923076923 --> Loss 0.00756589253743\n",
      "Epoch 15::Minibatch 778::LR 0.0676923076923 --> Loss 0.00967575947444\n",
      "Epoch 15::Minibatch 779::LR 0.0676923076923 --> Loss 0.00227096537749\n",
      "Epoch 15::Minibatch 780::LR 0.0676923076923 --> Loss 0.0016184425354\n",
      "Epoch 15::Minibatch 781::LR 0.0676923076923 --> Loss 0.00347503741582\n",
      "Epoch 15::Minibatch 782::LR 0.0676923076923 --> Loss 0.00401979207993\n",
      "Epoch 15::Minibatch 783::LR 0.0676923076923 --> Loss 0.00231805562973\n",
      "Epoch 15::Minibatch 784::LR 0.0676923076923 --> Loss 0.000725602308909\n",
      "Epoch 15::Minibatch 785::LR 0.0676923076923 --> Loss 0.00353863239288\n",
      "Epoch 15::Minibatch 786::LR 0.0676923076923 --> Loss 0.00349684158961\n",
      "Epoch 15::Minibatch 787::LR 0.0676923076923 --> Loss 0.00273639698823\n",
      "Epoch 15::Minibatch 788::LR 0.0676923076923 --> Loss 0.00242566386859\n",
      "Epoch 15::Minibatch 789::LR 0.0676923076923 --> Loss 0.000741325865189\n",
      "Epoch 15::Minibatch 790::LR 0.0676923076923 --> Loss 0.00319146633148\n",
      "Epoch 15::Minibatch 791::LR 0.0676923076923 --> Loss 0.00360301097234\n",
      "Epoch 15::Minibatch 792::LR 0.0676923076923 --> Loss 0.0032110106945\n",
      "Epoch 15::Minibatch 793::LR 0.0676923076923 --> Loss 0.00181033392747\n",
      "Epoch 15::Minibatch 794::LR 0.0676923076923 --> Loss 0.00103876411915\n",
      "Epoch 15::Minibatch 795::LR 0.0676923076923 --> Loss 0.00307219525178\n",
      "Epoch 15::Minibatch 796::LR 0.0676923076923 --> Loss 0.00573009729385\n",
      "Epoch 15::Minibatch 797::LR 0.0676923076923 --> Loss 0.00748054822286\n",
      "Epoch 15::Minibatch 798::LR 0.0676923076923 --> Loss 0.00334485093753\n",
      "Epoch 15::Minibatch 799::LR 0.0676923076923 --> Loss 0.00238443175952\n",
      "Epoch 15::Minibatch 800::LR 0.0676923076923 --> Loss 0.00202629009883\n",
      "Epoch 15::Minibatch 801::LR 0.0676923076923 --> Loss 0.00416388551394\n",
      "Epoch 15::Minibatch 802::LR 0.0676923076923 --> Loss 0.00132287273804\n",
      "Epoch 15::Minibatch 803::LR 0.0676923076923 --> Loss 0.00284643113613\n",
      "Epoch 15::Minibatch 804::LR 0.0676923076923 --> Loss 0.00218698720137\n",
      "Epoch 15::Minibatch 805::LR 0.0676923076923 --> Loss 0.00228103121122\n",
      "Epoch 15::Minibatch 806::LR 0.0676923076923 --> Loss 0.00332785646121\n",
      "Epoch 15::Minibatch 807::LR 0.0676923076923 --> Loss 0.00303216079871\n",
      "Epoch 15::Minibatch 808::LR 0.0676923076923 --> Loss 0.00269752045472\n",
      "Epoch 15::Minibatch 809::LR 0.0676923076923 --> Loss 0.00379487872124\n",
      "Epoch 15::Minibatch 810::LR 0.0676923076923 --> Loss 0.00507859110832\n",
      "Epoch 15::Minibatch 811::LR 0.0676923076923 --> Loss 0.00479296843211\n",
      "Epoch 15::Minibatch 812::LR 0.0676923076923 --> Loss 0.00441995938619\n",
      "Epoch 15::Minibatch 813::LR 0.0676923076923 --> Loss 0.00396576484044\n",
      "Epoch 15::Minibatch 814::LR 0.0676923076923 --> Loss 0.00179897487164\n",
      "Epoch 15::Minibatch 815::LR 0.0676923076923 --> Loss 0.00383706927299\n",
      "Epoch 15::Minibatch 816::LR 0.0676923076923 --> Loss 0.00417282422384\n",
      "Epoch 15::Minibatch 817::LR 0.0676923076923 --> Loss 0.00554690996806\n",
      "Epoch 15::Minibatch 818::LR 0.0676923076923 --> Loss 0.00129162808259\n",
      "Epoch 15::Minibatch 819::LR 0.0676923076923 --> Loss 0.000719758768876\n",
      "Epoch 15::Minibatch 820::LR 0.0676923076923 --> Loss 0.00535961389542\n",
      "Epoch 15::Minibatch 821::LR 0.0676923076923 --> Loss 0.00317982296149\n",
      "Epoch 15::Minibatch 822::LR 0.0676923076923 --> Loss 0.00374655564626\n",
      "Epoch 15::Minibatch 823::LR 0.0676923076923 --> Loss 0.00130433082581\n",
      "Epoch 15::Minibatch 824::LR 0.0676923076923 --> Loss 0.00139265547196\n",
      "Epoch 15::Minibatch 825::LR 0.0676923076923 --> Loss 0.00369948426882\n",
      "Epoch 15::Minibatch 826::LR 0.0676923076923 --> Loss 0.00393416404724\n",
      "Epoch 15::Minibatch 827::LR 0.0676923076923 --> Loss 0.00216190159321\n",
      "Epoch 15::Minibatch 828::LR 0.0676923076923 --> Loss 0.000582422415415\n",
      "Epoch 15::Minibatch 829::LR 0.0676923076923 --> Loss 0.00240195274353\n",
      "Epoch 15::Minibatch 830::LR 0.0676923076923 --> Loss 0.00438968817393\n",
      "Epoch 15::Minibatch 831::LR 0.0676923076923 --> Loss 0.00257004062335\n",
      "Epoch 15::Minibatch 832::LR 0.0676923076923 --> Loss 0.00225087205569\n",
      "Epoch 15::Minibatch 833::LR 0.0676923076923 --> Loss 0.00185042599837\n",
      "Epoch 15::Minibatch 834::LR 0.0676923076923 --> Loss 0.000776233822107\n",
      "Epoch 15::Minibatch 835::LR 0.0676923076923 --> Loss 0.00380761901538\n",
      "Epoch 15::Minibatch 836::LR 0.0676923076923 --> Loss 0.00372547705968\n",
      "Epoch 15::Minibatch 837::LR 0.0676923076923 --> Loss 0.00219849745433\n",
      "Epoch 15::Minibatch 838::LR 0.0676923076923 --> Loss 0.000631979008516\n",
      "Epoch 15::Minibatch 839::LR 0.0676923076923 --> Loss 0.00247090717157\n",
      "Epoch 15::Minibatch 840::LR 0.0676923076923 --> Loss 0.00290869474411\n",
      "Epoch 15::Minibatch 841::LR 0.0676923076923 --> Loss 0.00284809788068\n",
      "Epoch 15::Minibatch 842::LR 0.0676923076923 --> Loss 0.0020877935489\n",
      "Epoch 15::Minibatch 843::LR 0.0676923076923 --> Loss 0.00100923309724\n",
      "Epoch 15::Minibatch 844::LR 0.0676923076923 --> Loss 0.0014970233043\n",
      "Epoch 15::Minibatch 845::LR 0.0676923076923 --> Loss 0.0043487795194\n",
      "Epoch 15::Minibatch 846::LR 0.0676923076923 --> Loss 0.00168215711912\n",
      "Epoch 15::Minibatch 847::LR 0.0676923076923 --> Loss 0.0022798405091\n",
      "Epoch 15::Minibatch 848::LR 0.0676923076923 --> Loss 0.00100506474574\n",
      "Epoch 15::Minibatch 849::LR 0.0676923076923 --> Loss 0.00184710741043\n",
      "Epoch 15::Minibatch 850::LR 0.0676923076923 --> Loss 0.00318760375182\n",
      "Epoch 15::Minibatch 851::LR 0.0676923076923 --> Loss 0.00268928428491\n",
      "Epoch 15::Minibatch 852::LR 0.0676923076923 --> Loss 0.00107244869073\n",
      "Epoch 15::Minibatch 853::LR 0.0676923076923 --> Loss 0.00131011346976\n",
      "Epoch 15::Minibatch 854::LR 0.0676923076923 --> Loss 0.00257503708204\n",
      "Epoch 15::Minibatch 855::LR 0.0676923076923 --> Loss 0.00217364410559\n",
      "Epoch 15::Minibatch 856::LR 0.0676923076923 --> Loss 0.00179680367311\n",
      "Epoch 15::Minibatch 857::LR 0.0676923076923 --> Loss 0.00121581832568\n",
      "Epoch 15::Minibatch 858::LR 0.0676923076923 --> Loss 0.000595486511787\n",
      "Epoch 15::Minibatch 859::LR 0.0676923076923 --> Loss 0.0019067243735\n",
      "Epoch 15::Minibatch 860::LR 0.0676923076923 --> Loss 0.00124209463596\n",
      "Epoch 15::Minibatch 861::LR 0.0676923076923 --> Loss 0.000935356318951\n",
      "Epoch 15::Minibatch 862::LR 0.0676923076923 --> Loss 0.00363898237546\n",
      "Epoch 15::Minibatch 863::LR 0.0676923076923 --> Loss 0.00343201716741\n",
      "Epoch 15::Minibatch 864::LR 0.0676923076923 --> Loss 0.00290778835615\n",
      "Epoch 15::Minibatch 865::LR 0.0676923076923 --> Loss 0.000452930231889\n",
      "Epoch 15::Minibatch 866::LR 0.0676923076923 --> Loss 0.00215568840504\n",
      "Epoch 15::Minibatch 867::LR 0.0676923076923 --> Loss 0.00299255927404\n",
      "Epoch 15::Minibatch 868::LR 0.0676923076923 --> Loss 0.00246460298697\n",
      "Epoch 15::Minibatch 869::LR 0.0676923076923 --> Loss 0.0021150102218\n",
      "Epoch 15::Minibatch 870::LR 0.0676923076923 --> Loss 0.00356328288714\n",
      "Epoch 15::Minibatch 871::LR 0.0676923076923 --> Loss 0.00152518381675\n",
      "Epoch 15::Minibatch 872::LR 0.0676923076923 --> Loss 0.00227297385534\n",
      "Epoch 15::Minibatch 873::LR 0.0676923076923 --> Loss 0.00247549931208\n",
      "Epoch 15::Minibatch 874::LR 0.0676923076923 --> Loss 0.00620852788289\n",
      "Epoch 15::Minibatch 875::LR 0.0676923076923 --> Loss 0.000526468008757\n",
      "Epoch 15::Minibatch 876::LR 0.0676923076923 --> Loss 0.00325595160325\n",
      "Epoch 15::Minibatch 877::LR 0.0676923076923 --> Loss 0.00542873819669\n",
      "Epoch 15::Minibatch 878::LR 0.0676923076923 --> Loss 0.0032610831658\n",
      "Epoch 15::Minibatch 879::LR 0.0676923076923 --> Loss 0.00398662726084\n",
      "Epoch 15::Minibatch 880::LR 0.0676923076923 --> Loss 0.00475861986478\n",
      "Epoch 15::Minibatch 881::LR 0.0676923076923 --> Loss 0.00426906188329\n",
      "Epoch 15::Minibatch 882::LR 0.0676923076923 --> Loss 0.00197405616442\n",
      "Epoch 15::Minibatch 883::LR 0.0676923076923 --> Loss 0.00340312401454\n",
      "Epoch 15::Minibatch 884::LR 0.0676923076923 --> Loss 0.00270304123561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 885::LR 0.0676923076923 --> Loss 0.00250851710637\n",
      "Epoch 15::Minibatch 886::LR 0.0676923076923 --> Loss 0.000508271257083\n",
      "Epoch 15::Minibatch 887::LR 0.0676923076923 --> Loss 0.00526304960251\n",
      "Epoch 15::Minibatch 888::LR 0.0676923076923 --> Loss 0.00263599256674\n",
      "Epoch 15::Minibatch 889::LR 0.0676923076923 --> Loss 0.0028556684653\n",
      "Epoch 15::Minibatch 890::LR 0.0676923076923 --> Loss 0.00423275033633\n",
      "Epoch 15::Minibatch 891::LR 0.0676923076923 --> Loss 0.00187430421511\n",
      "Epoch 15::Minibatch 892::LR 0.0676923076923 --> Loss 0.000875386893749\n",
      "Epoch 15::Minibatch 893::LR 0.0676923076923 --> Loss 0.00245786150297\n",
      "Epoch 15::Minibatch 894::LR 0.0676923076923 --> Loss 0.00217656751474\n",
      "Epoch 15::Minibatch 895::LR 0.0676923076923 --> Loss 0.00241079628468\n",
      "Epoch 15::Minibatch 896::LR 0.0676923076923 --> Loss 0.001278167665\n",
      "Epoch 15::Minibatch 897::LR 0.0676923076923 --> Loss 0.000722841819127\n",
      "Epoch 15::Minibatch 898::LR 0.0676923076923 --> Loss 0.0021510318915\n",
      "Epoch 15::Minibatch 899::LR 0.0676923076923 --> Loss 0.00247880121072\n",
      "Epoch 15::Minibatch 900::LR 0.0676923076923 --> Loss 0.00323993166288\n",
      "Epoch 15::Minibatch 901::LR 0.0676923076923 --> Loss 0.000599735975266\n",
      "Epoch 15::Minibatch 902::LR 0.0676923076923 --> Loss 0.00142156511545\n",
      "Epoch 15::Minibatch 903::LR 0.0676923076923 --> Loss 0.00256677965323\n",
      "Epoch 15::Minibatch 904::LR 0.0676923076923 --> Loss 0.00194643676281\n",
      "Epoch 15::Minibatch 905::LR 0.0676923076923 --> Loss 0.00144016325474\n",
      "Epoch 15::Minibatch 906::LR 0.0676923076923 --> Loss 0.00108853032192\n",
      "Epoch 15::Minibatch 907::LR 0.0676923076923 --> Loss 0.00158855885267\n",
      "Epoch 15::Minibatch 908::LR 0.0676923076923 --> Loss 0.00217463473479\n",
      "Epoch 15::Minibatch 909::LR 0.0676923076923 --> Loss 0.00199905971686\n",
      "Epoch 15::Minibatch 910::LR 0.0676923076923 --> Loss 0.000834665199121\n",
      "Epoch 15::Minibatch 911::LR 0.0676923076923 --> Loss 0.00123225241899\n",
      "Epoch 15::Minibatch 912::LR 0.0676923076923 --> Loss 0.00197833955288\n",
      "Epoch 15::Minibatch 913::LR 0.0676923076923 --> Loss 0.00214808007081\n",
      "Epoch 15::Minibatch 914::LR 0.0676923076923 --> Loss 0.00116734902064\n",
      "Epoch 15::Minibatch 915::LR 0.0676923076923 --> Loss 0.000491908888022\n",
      "Epoch 15::Minibatch 916::LR 0.0676923076923 --> Loss 0.00228968282541\n",
      "Epoch 15::Minibatch 917::LR 0.0676923076923 --> Loss 0.00380673368772\n",
      "Epoch 15::Minibatch 918::LR 0.0676923076923 --> Loss 0.00605407317479\n",
      "Epoch 15::Minibatch 919::LR 0.0676923076923 --> Loss 0.000582251350085\n",
      "Epoch 15::Minibatch 920::LR 0.0676923076923 --> Loss 0.0114284451803\n",
      "Epoch 15::Minibatch 921::LR 0.0676923076923 --> Loss 0.00282069166501\n",
      "Epoch 15::Minibatch 922::LR 0.0676923076923 --> Loss 0.00301160613696\n",
      "Epoch 15::Minibatch 923::LR 0.0676923076923 --> Loss 0.00151080618302\n",
      "Epoch 15::Minibatch 924::LR 0.0676923076923 --> Loss 0.00349437475204\n",
      "Epoch 15::Minibatch 925::LR 0.0676923076923 --> Loss 0.00244785745939\n",
      "Epoch 15::Minibatch 926::LR 0.0676923076923 --> Loss 0.00532518863678\n",
      "Epoch 15::Minibatch 927::LR 0.0676923076923 --> Loss 0.00786956548691\n",
      "Epoch 15::Minibatch 928::LR 0.0676923076923 --> Loss 0.00649499813716\n",
      "Epoch 15::Minibatch 929::LR 0.0676923076923 --> Loss 0.00697956244151\n",
      "Epoch 15::Minibatch 930::LR 0.0676923076923 --> Loss 0.00981043656667\n",
      "Epoch 15::Minibatch 931::LR 0.0676923076923 --> Loss 0.00360537290573\n",
      "Epoch 15::Minibatch 932::LR 0.0676923076923 --> Loss 0.00739402373632\n",
      "Epoch 15::Minibatch 933::LR 0.0676923076923 --> Loss 0.00368185480436\n",
      "Epoch 15::Minibatch 934::LR 0.0676923076923 --> Loss 0.00483838438988\n",
      "Epoch 15::Minibatch 935::LR 0.0676923076923 --> Loss 0.00672691583633\n",
      "Epoch 15::Minibatch 936::LR 0.0676923076923 --> Loss 0.00163326611121\n",
      "Epoch 15::Minibatch 937::LR 0.0676923076923 --> Loss 0.00351050456365\n",
      "Epoch 15::Minibatch 938::LR 0.0676923076923 --> Loss 0.00322526196639\n",
      "Epoch 15::Minibatch 939::LR 0.0676923076923 --> Loss 0.0032958082358\n",
      "Epoch 15::Minibatch 940::LR 0.0676923076923 --> Loss 0.00105881909529\n",
      "Epoch 15::Minibatch 941::LR 0.0676923076923 --> Loss 0.000863492488861\n",
      "Epoch 15::Minibatch 942::LR 0.0676923076923 --> Loss 0.00246606906255\n",
      "Epoch 15::Minibatch 943::LR 0.0676923076923 --> Loss 0.00303148627281\n",
      "Epoch 15::Minibatch 944::LR 0.0676923076923 --> Loss 0.00219284574191\n",
      "Epoch 15::Minibatch 945::LR 0.0676923076923 --> Loss 0.00128401209911\n",
      "Epoch 15::Minibatch 946::LR 0.0676923076923 --> Loss 0.00325797716777\n",
      "Epoch 15::Minibatch 947::LR 0.0676923076923 --> Loss 0.00290282547474\n",
      "Epoch 15::Minibatch 948::LR 0.0676923076923 --> Loss 0.00535700559616\n",
      "Epoch 15::Minibatch 949::LR 0.0676923076923 --> Loss 0.0019285184145\n",
      "Epoch 15::Minibatch 950::LR 0.0676923076923 --> Loss 0.00073948909839\n",
      "Epoch 15::Minibatch 951::LR 0.0676923076923 --> Loss 0.00341093579928\n",
      "Epoch 15::Minibatch 952::LR 0.0676923076923 --> Loss 0.00247315267722\n",
      "Epoch 15::Minibatch 953::LR 0.0676923076923 --> Loss 0.0013917952776\n",
      "Epoch 15::Minibatch 954::LR 0.0676923076923 --> Loss 0.000964395006498\n",
      "Epoch 15::Minibatch 955::LR 0.0676923076923 --> Loss 0.00255280673504\n",
      "Epoch 15::Minibatch 956::LR 0.0676923076923 --> Loss 0.00393060207367\n",
      "Epoch 15::Minibatch 957::LR 0.0676923076923 --> Loss 0.00192810455958\n",
      "Epoch 15::Minibatch 958::LR 0.0676923076923 --> Loss 0.00239035348097\n",
      "Epoch 15::Minibatch 959::LR 0.0676923076923 --> Loss 0.00295287172\n",
      "Epoch 15::Minibatch 960::LR 0.0676923076923 --> Loss 0.00654526631037\n",
      "Epoch 15::Minibatch 961::LR 0.0676923076923 --> Loss 0.00340644637744\n",
      "Epoch 15::Minibatch 962::LR 0.0676923076923 --> Loss 0.00294701099396\n",
      "Epoch 15::Minibatch 963::LR 0.0676923076923 --> Loss 0.00104080120722\n",
      "Epoch 15::Minibatch 964::LR 0.0676923076923 --> Loss 0.00242680728436\n",
      "Epoch 15::Minibatch 965::LR 0.0676923076923 --> Loss 0.00740724007289\n",
      "Epoch 15::Minibatch 966::LR 0.0676923076923 --> Loss 0.00513761560122\n",
      "Epoch 15::Minibatch 967::LR 0.0676923076923 --> Loss 0.00160979459683\n",
      "Epoch 15::Minibatch 968::LR 0.0676923076923 --> Loss 0.00142770260572\n",
      "Epoch 15::Minibatch 969::LR 0.0676923076923 --> Loss 0.00662973205249\n",
      "Epoch 15::Minibatch 970::LR 0.0676923076923 --> Loss 0.00583633542061\n",
      "Epoch 15::Minibatch 971::LR 0.0676923076923 --> Loss 0.00359192172686\n",
      "Epoch 15::Minibatch 972::LR 0.0676923076923 --> Loss 0.00971589883169\n",
      "Epoch 15::Minibatch 973::LR 0.0676923076923 --> Loss 0.00905354817708\n",
      "Epoch 15::Minibatch 974::LR 0.0676923076923 --> Loss 0.00790710051854\n",
      "Epoch 15::Minibatch 975::LR 0.0676923076923 --> Loss 0.00478605270386\n",
      "Epoch 15::Minibatch 976::LR 0.0676923076923 --> Loss 0.00435048858325\n",
      "Epoch 15::Minibatch 977::LR 0.0676923076923 --> Loss 0.00439352909724\n",
      "Epoch 15::Minibatch 978::LR 0.0676923076923 --> Loss 0.00439332445463\n",
      "Epoch 15::Minibatch 979::LR 0.0676923076923 --> Loss 0.00438078641891\n",
      "Epoch 15::Minibatch 980::LR 0.0676923076923 --> Loss 0.00420966068904\n",
      "Epoch 15::Minibatch 981::LR 0.0676923076923 --> Loss 0.00554379781087\n",
      "Epoch 15::Minibatch 982::LR 0.0676923076923 --> Loss 0.00711218357086\n",
      "Epoch 15::Minibatch 983::LR 0.0676923076923 --> Loss 0.00324354171753\n",
      "Epoch 15::Minibatch 984::LR 0.0676923076923 --> Loss 0.00297006467978\n",
      "Epoch 15::Minibatch 985::LR 0.0676923076923 --> Loss 0.00475185195605\n",
      "Epoch 15::Minibatch 986::LR 0.0676923076923 --> Loss 0.00438745220502\n",
      "Epoch 15::Minibatch 987::LR 0.0676923076923 --> Loss 0.00468025684357\n",
      "Epoch 15::Minibatch 988::LR 0.0676923076923 --> Loss 0.00369847218196\n",
      "Epoch 15::Minibatch 989::LR 0.0676923076923 --> Loss 0.00375157276789\n",
      "Epoch 15::Minibatch 990::LR 0.0676923076923 --> Loss 0.00337271054586\n",
      "Epoch 15::Minibatch 991::LR 0.0676923076923 --> Loss 0.00199261109034\n",
      "Epoch 15::Minibatch 992::LR 0.0676923076923 --> Loss 0.00214666048686\n",
      "Epoch 15::Minibatch 993::LR 0.0676923076923 --> Loss 0.00370768825213\n",
      "Epoch 15::Minibatch 994::LR 0.0676923076923 --> Loss 0.00227317333221\n",
      "Epoch 15::Minibatch 995::LR 0.0676923076923 --> Loss 0.000972456733386\n",
      "Epoch 15::Minibatch 996::LR 0.0676923076923 --> Loss 0.00329245090485\n",
      "Epoch 15::Minibatch 997::LR 0.0676923076923 --> Loss 0.00237818837166\n",
      "Epoch 15::Minibatch 998::LR 0.0676923076923 --> Loss 0.0026134087642\n",
      "Epoch 15::Minibatch 999::LR 0.0676923076923 --> Loss 0.00212059477965\n",
      "Epoch 15::Minibatch 1000::LR 0.0676923076923 --> Loss 0.00250149627527\n",
      "Epoch 15::Minibatch 1001::LR 0.0676923076923 --> Loss 0.00206419030825\n",
      "Epoch 15::Minibatch 1002::LR 0.0676923076923 --> Loss 0.00283209840457\n",
      "Epoch 15::Minibatch 1003::LR 0.0676923076923 --> Loss 0.00373948335648\n",
      "Epoch 15::Minibatch 1004::LR 0.0676923076923 --> Loss 0.00112246831258\n",
      "Epoch 15::Minibatch 1005::LR 0.0676923076923 --> Loss 0.00390663464864\n",
      "Epoch 15::Minibatch 1006::LR 0.0676923076923 --> Loss 0.0024739609162\n",
      "Epoch 15::Minibatch 1007::LR 0.0676923076923 --> Loss 0.00275145073732\n",
      "Epoch 15::Minibatch 1008::LR 0.0676923076923 --> Loss 0.00103231668472\n",
      "Epoch 15::Minibatch 1009::LR 0.0676923076923 --> Loss 0.00163165251414\n",
      "Epoch 15::Minibatch 1010::LR 0.0676923076923 --> Loss 0.00139044781526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15::Minibatch 1011::LR 0.0676923076923 --> Loss 0.00249385535717\n",
      "Epoch 15::Minibatch 1012::LR 0.0676923076923 --> Loss 0.00172313849131\n",
      "Epoch 15::Minibatch 1013::LR 0.0676923076923 --> Loss 0.00454305847486\n",
      "Epoch 15::Minibatch 1014::LR 0.0676923076923 --> Loss 0.00431985616684\n",
      "Epoch 15::Minibatch 1015::LR 0.0676923076923 --> Loss 0.00177728394667\n",
      "Epoch 15::Minibatch 1016::LR 0.0676923076923 --> Loss 0.0051043065389\n",
      "Epoch 15::Minibatch 1017::LR 0.0676923076923 --> Loss 0.00266722361247\n",
      "Epoch 15::Minibatch 1018::LR 0.0676923076923 --> Loss 0.00303461531798\n",
      "Epoch 15::Minibatch 1019::LR 0.0676923076923 --> Loss 0.00209127187729\n",
      "Epoch 15::Minibatch 1020::LR 0.0676923076923 --> Loss 0.00208083649476\n",
      "Epoch 15::Minibatch 1021::LR 0.0676923076923 --> Loss 0.00206953724225\n",
      "Epoch 15::Minibatch 1022::LR 0.0676923076923 --> Loss 0.00156310508649\n",
      "Epoch 15::Minibatch 1023::LR 0.0676923076923 --> Loss 0.00121851682663\n",
      "Epoch 15::Minibatch 1024::LR 0.0676923076923 --> Loss 0.00119121750196\n",
      "Epoch 15::Minibatch 1025::LR 0.0676923076923 --> Loss 0.0014330119888\n",
      "Epoch 15::Minibatch 1026::LR 0.0676923076923 --> Loss 0.000849789877733\n",
      "Epoch 15::Minibatch 1027::LR 0.0676923076923 --> Loss 0.00105611046155\n",
      "Epoch 15::Minibatch 1028::LR 0.0676923076923 --> Loss 0.000809874236584\n",
      "Epoch 15::Minibatch 1029::LR 0.0676923076923 --> Loss 0.000793114205201\n",
      "Epoch 15::Minibatch 1030::LR 0.0676923076923 --> Loss 0.000979353785515\n",
      "Epoch 15::Minibatch 1031::LR 0.0676923076923 --> Loss 0.000763926357031\n",
      "Epoch 15::Minibatch 1032::LR 0.0676923076923 --> Loss 0.000786857753992\n",
      "Epoch 15::Minibatch 1033::LR 0.0676923076923 --> Loss 0.000669733484586\n",
      "Epoch 15::Minibatch 1034::LR 0.0676923076923 --> Loss 0.000652520308892\n",
      "Epoch 15::Minibatch 1035::LR 0.0676923076923 --> Loss 0.000468623936176\n",
      "Epoch 15::Minibatch 1036::LR 0.0676923076923 --> Loss 0.000371763408184\n",
      "Epoch 15::Minibatch 1037::LR 0.0676923076923 --> Loss 0.000580720603466\n",
      "Epoch 15::Minibatch 1038::LR 0.0676923076923 --> Loss 0.00130228588978\n",
      "Epoch 15::Minibatch 1039::LR 0.0676923076923 --> Loss 0.00101202984651\n",
      "Epoch 15::Minibatch 1040::LR 0.0676923076923 --> Loss 0.000433106372754\n",
      "Epoch 15::Minibatch 1041::LR 0.0676923076923 --> Loss 0.000599278906981\n",
      "Epoch 16::Minibatch 1::LR 0.0653846153846 --> Loss 0.00962972482045\n",
      "Epoch 16::Minibatch 2::LR 0.0653846153846 --> Loss 0.00628036260605\n",
      "Epoch 16::Minibatch 3::LR 0.0653846153846 --> Loss 0.00407981316249\n",
      "Epoch 16::Minibatch 4::LR 0.0653846153846 --> Loss 0.00445379853249\n",
      "Epoch 16::Minibatch 5::LR 0.0653846153846 --> Loss 0.00476256688436\n",
      "Epoch 16::Minibatch 6::LR 0.0653846153846 --> Loss 0.00244325459003\n",
      "Epoch 16::Minibatch 7::LR 0.0653846153846 --> Loss 0.00784187873205\n",
      "Epoch 16::Minibatch 8::LR 0.0653846153846 --> Loss 0.00760285377502\n",
      "Epoch 16::Minibatch 9::LR 0.0653846153846 --> Loss 0.0055465511481\n",
      "Epoch 16::Minibatch 10::LR 0.0653846153846 --> Loss 0.0028483436505\n",
      "Epoch 16::Minibatch 11::LR 0.0653846153846 --> Loss 0.00245813250542\n",
      "Epoch 16::Minibatch 12::LR 0.0653846153846 --> Loss 0.00359093705813\n",
      "Epoch 16::Minibatch 13::LR 0.0653846153846 --> Loss 0.00541934370995\n",
      "Epoch 16::Minibatch 14::LR 0.0653846153846 --> Loss 0.00526582082113\n",
      "Epoch 16::Minibatch 15::LR 0.0653846153846 --> Loss 0.00436009764671\n",
      "Epoch 16::Minibatch 16::LR 0.0653846153846 --> Loss 0.000903929571311\n",
      "Epoch 16::Minibatch 17::LR 0.0653846153846 --> Loss 0.00316632390022\n",
      "Epoch 16::Minibatch 18::LR 0.0653846153846 --> Loss 0.00253393868605\n",
      "Epoch 16::Minibatch 19::LR 0.0653846153846 --> Loss 0.00126429329316\n",
      "Epoch 16::Minibatch 20::LR 0.0653846153846 --> Loss 0.0017452510198\n",
      "Epoch 16::Minibatch 21::LR 0.0653846153846 --> Loss 0.00326257586479\n",
      "Epoch 16::Minibatch 22::LR 0.0653846153846 --> Loss 0.00230384707451\n",
      "Epoch 16::Minibatch 23::LR 0.0653846153846 --> Loss 0.000793555726608\n",
      "Epoch 16::Minibatch 24::LR 0.0653846153846 --> Loss 0.000371017456055\n",
      "Epoch 16::Minibatch 25::LR 0.0653846153846 --> Loss 0.00111898342768\n",
      "Epoch 16::Minibatch 26::LR 0.0653846153846 --> Loss 0.00131241897742\n",
      "Epoch 16::Minibatch 27::LR 0.0653846153846 --> Loss 0.00092609534661\n",
      "Epoch 16::Minibatch 28::LR 0.0653846153846 --> Loss 0.000381913209955\n",
      "Epoch 16::Minibatch 29::LR 0.0653846153846 --> Loss 0.000369672824939\n",
      "Epoch 16::Minibatch 30::LR 0.0653846153846 --> Loss 0.000851141611735\n",
      "Epoch 16::Minibatch 31::LR 0.0653846153846 --> Loss 0.00133092443148\n",
      "Epoch 16::Minibatch 32::LR 0.0653846153846 --> Loss 0.00127075324456\n",
      "Epoch 16::Minibatch 33::LR 0.0653846153846 --> Loss 0.000776244004567\n",
      "Epoch 16::Minibatch 34::LR 0.0653846153846 --> Loss 0.00243489821752\n",
      "Epoch 16::Minibatch 35::LR 0.0653846153846 --> Loss 0.00393914818764\n",
      "Epoch 16::Minibatch 36::LR 0.0653846153846 --> Loss 0.00219423611959\n",
      "Epoch 16::Minibatch 37::LR 0.0653846153846 --> Loss 0.000622632453839\n",
      "Epoch 16::Minibatch 38::LR 0.0653846153846 --> Loss 0.000739339540402\n",
      "Epoch 16::Minibatch 39::LR 0.0653846153846 --> Loss 0.00242669562499\n",
      "Epoch 16::Minibatch 40::LR 0.0653846153846 --> Loss 0.00351471781731\n",
      "Epoch 16::Minibatch 41::LR 0.0653846153846 --> Loss 0.0029189479351\n",
      "Epoch 16::Minibatch 42::LR 0.0653846153846 --> Loss 0.00603577772776\n",
      "Epoch 16::Minibatch 43::LR 0.0653846153846 --> Loss 0.00186249057452\n",
      "Epoch 16::Minibatch 44::LR 0.0653846153846 --> Loss 0.00311409076055\n",
      "Epoch 16::Minibatch 45::LR 0.0653846153846 --> Loss 0.00250926355521\n",
      "Epoch 16::Minibatch 46::LR 0.0653846153846 --> Loss 0.00346871097883\n",
      "Epoch 16::Minibatch 47::LR 0.0653846153846 --> Loss 0.00453222672145\n",
      "Epoch 16::Minibatch 48::LR 0.0653846153846 --> Loss 0.00598960439364\n",
      "Epoch 16::Minibatch 49::LR 0.0653846153846 --> Loss 0.00622592171033\n",
      "Epoch 16::Minibatch 50::LR 0.0653846153846 --> Loss 0.00606485168139\n",
      "Epoch 16::Minibatch 51::LR 0.0653846153846 --> Loss 0.00738496462504\n",
      "Epoch 16::Minibatch 52::LR 0.0653846153846 --> Loss 0.0034768307209\n",
      "Epoch 16::Minibatch 53::LR 0.0653846153846 --> Loss 0.00344761252403\n",
      "Epoch 16::Minibatch 54::LR 0.0653846153846 --> Loss 0.00401993672053\n",
      "Epoch 16::Minibatch 55::LR 0.0653846153846 --> Loss 0.000987580617269\n",
      "Epoch 16::Minibatch 56::LR 0.0653846153846 --> Loss 0.0027083359162\n",
      "Epoch 16::Minibatch 57::LR 0.0653846153846 --> Loss 0.00572167754173\n",
      "Epoch 16::Minibatch 58::LR 0.0653846153846 --> Loss 0.00336896896362\n",
      "Epoch 16::Minibatch 59::LR 0.0653846153846 --> Loss 0.00253303150336\n",
      "Epoch 16::Minibatch 60::LR 0.0653846153846 --> Loss 0.00239383955797\n",
      "Epoch 16::Minibatch 61::LR 0.0653846153846 --> Loss 0.000896360576153\n",
      "Epoch 16::Minibatch 62::LR 0.0653846153846 --> Loss 0.00323784609636\n",
      "Epoch 16::Minibatch 63::LR 0.0653846153846 --> Loss 0.00215097824732\n",
      "Epoch 16::Minibatch 64::LR 0.0653846153846 --> Loss 0.000921101868153\n",
      "Epoch 16::Minibatch 65::LR 0.0653846153846 --> Loss 0.00237634082635\n",
      "Epoch 16::Minibatch 66::LR 0.0653846153846 --> Loss 0.00286616901557\n",
      "Epoch 16::Minibatch 67::LR 0.0653846153846 --> Loss 0.00280578394731\n",
      "Epoch 16::Minibatch 68::LR 0.0653846153846 --> Loss 0.00199352482955\n",
      "Epoch 16::Minibatch 69::LR 0.0653846153846 --> Loss 0.00402694622676\n",
      "Epoch 16::Minibatch 70::LR 0.0653846153846 --> Loss 0.0034849747022\n",
      "Epoch 16::Minibatch 71::LR 0.0653846153846 --> Loss 0.00234452843666\n",
      "Epoch 16::Minibatch 72::LR 0.0653846153846 --> Loss 0.00053989653786\n",
      "Epoch 16::Minibatch 73::LR 0.0653846153846 --> Loss 0.00394035379092\n",
      "Epoch 16::Minibatch 74::LR 0.0653846153846 --> Loss 0.00417065302531\n",
      "Epoch 16::Minibatch 75::LR 0.0653846153846 --> Loss 0.00248308261236\n",
      "Epoch 16::Minibatch 76::LR 0.0653846153846 --> Loss 0.000607616702716\n",
      "Epoch 16::Minibatch 77::LR 0.0653846153846 --> Loss 0.00400979320208\n",
      "Epoch 16::Minibatch 78::LR 0.0653846153846 --> Loss 0.00387731909752\n",
      "Epoch 16::Minibatch 79::LR 0.0653846153846 --> Loss 0.00202519973119\n",
      "Epoch 16::Minibatch 80::LR 0.0653846153846 --> Loss 0.00331303616365\n",
      "Epoch 16::Minibatch 81::LR 0.0653846153846 --> Loss 0.00285994708538\n",
      "Epoch 16::Minibatch 82::LR 0.0653846153846 --> Loss 0.00202584683895\n",
      "Epoch 16::Minibatch 83::LR 0.0653846153846 --> Loss 0.00472530206045\n",
      "Epoch 16::Minibatch 84::LR 0.0653846153846 --> Loss 0.00203011870384\n",
      "Epoch 16::Minibatch 85::LR 0.0653846153846 --> Loss 0.00279234846433\n",
      "Epoch 16::Minibatch 86::LR 0.0653846153846 --> Loss 0.00226421097914\n",
      "Epoch 16::Minibatch 87::LR 0.0653846153846 --> Loss 0.00251639107863\n",
      "Epoch 16::Minibatch 88::LR 0.0653846153846 --> Loss 0.00182772835096\n",
      "Epoch 16::Minibatch 89::LR 0.0653846153846 --> Loss 0.00236060500145\n",
      "Epoch 16::Minibatch 90::LR 0.0653846153846 --> Loss 0.00116460472345\n",
      "Epoch 16::Minibatch 91::LR 0.0653846153846 --> Loss 0.000930237074693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 92::LR 0.0653846153846 --> Loss 0.00272535204887\n",
      "Epoch 16::Minibatch 93::LR 0.0653846153846 --> Loss 0.00178396979968\n",
      "Epoch 16::Minibatch 94::LR 0.0653846153846 --> Loss 0.00178884426753\n",
      "Epoch 16::Minibatch 95::LR 0.0653846153846 --> Loss 0.00179919064045\n",
      "Epoch 16::Minibatch 96::LR 0.0653846153846 --> Loss 0.00592496037483\n",
      "Epoch 16::Minibatch 97::LR 0.0653846153846 --> Loss 0.00320072849592\n",
      "Epoch 16::Minibatch 98::LR 0.0653846153846 --> Loss 0.000977800687154\n",
      "Epoch 16::Minibatch 99::LR 0.0653846153846 --> Loss 0.00130757927895\n",
      "Epoch 16::Minibatch 100::LR 0.0653846153846 --> Loss 0.00524898529053\n",
      "Epoch 16::Minibatch 101::LR 0.0653846153846 --> Loss 0.000942108134429\n",
      "Epoch 16::Minibatch 102::LR 0.0653846153846 --> Loss 0.00385238925616\n",
      "Epoch 16::Minibatch 103::LR 0.0653846153846 --> Loss 0.00403312484423\n",
      "Epoch 16::Minibatch 104::LR 0.0653846153846 --> Loss 0.00278922736645\n",
      "Epoch 16::Minibatch 105::LR 0.0653846153846 --> Loss 0.00285106519858\n",
      "Epoch 16::Minibatch 106::LR 0.0653846153846 --> Loss 0.0178458166122\n",
      "Epoch 16::Minibatch 107::LR 0.0653846153846 --> Loss 0.00490344723066\n",
      "Epoch 16::Minibatch 108::LR 0.0653846153846 --> Loss 0.00109247088432\n",
      "Epoch 16::Minibatch 109::LR 0.0653846153846 --> Loss 0.00443484663963\n",
      "Epoch 16::Minibatch 110::LR 0.0653846153846 --> Loss 0.00245205243429\n",
      "Epoch 16::Minibatch 111::LR 0.0653846153846 --> Loss 0.00100843509038\n",
      "Epoch 16::Minibatch 112::LR 0.0653846153846 --> Loss 0.00362253864606\n",
      "Epoch 16::Minibatch 113::LR 0.0653846153846 --> Loss 0.00272797087828\n",
      "Epoch 16::Minibatch 114::LR 0.0653846153846 --> Loss 0.00150591959556\n",
      "Epoch 16::Minibatch 115::LR 0.0653846153846 --> Loss 0.00137372861306\n",
      "Epoch 16::Minibatch 116::LR 0.0653846153846 --> Loss 0.00284793059031\n",
      "Epoch 16::Minibatch 117::LR 0.0653846153846 --> Loss 0.00380711952845\n",
      "Epoch 16::Minibatch 118::LR 0.0653846153846 --> Loss 0.00696169137955\n",
      "Epoch 16::Minibatch 119::LR 0.0653846153846 --> Loss 0.000679791420698\n",
      "Epoch 16::Minibatch 120::LR 0.0653846153846 --> Loss 0.00183756947517\n",
      "Epoch 16::Minibatch 121::LR 0.0653846153846 --> Loss 0.00274001876513\n",
      "Epoch 16::Minibatch 122::LR 0.0653846153846 --> Loss 0.00373424728711\n",
      "Epoch 16::Minibatch 123::LR 0.0653846153846 --> Loss 0.0010967596372\n",
      "Epoch 16::Minibatch 124::LR 0.0653846153846 --> Loss 0.00282869239648\n",
      "Epoch 16::Minibatch 125::LR 0.0653846153846 --> Loss 0.0046932609876\n",
      "Epoch 16::Minibatch 126::LR 0.0653846153846 --> Loss 0.0027643730243\n",
      "Epoch 16::Minibatch 127::LR 0.0653846153846 --> Loss 0.00440043290456\n",
      "Epoch 16::Minibatch 128::LR 0.0653846153846 --> Loss 0.00365486939748\n",
      "Epoch 16::Minibatch 129::LR 0.0653846153846 --> Loss 0.00276227831841\n",
      "Epoch 16::Minibatch 130::LR 0.0653846153846 --> Loss 0.00438683311145\n",
      "Epoch 16::Minibatch 131::LR 0.0653846153846 --> Loss 0.0018247127533\n",
      "Epoch 16::Minibatch 132::LR 0.0653846153846 --> Loss 0.00314490218957\n",
      "Epoch 16::Minibatch 133::LR 0.0653846153846 --> Loss 0.00300199190776\n",
      "Epoch 16::Minibatch 134::LR 0.0653846153846 --> Loss 0.0024334269762\n",
      "Epoch 16::Minibatch 135::LR 0.0653846153846 --> Loss 0.0016287218531\n",
      "Epoch 16::Minibatch 136::LR 0.0653846153846 --> Loss 0.00277020275593\n",
      "Epoch 16::Minibatch 137::LR 0.0653846153846 --> Loss 0.00372714360555\n",
      "Epoch 16::Minibatch 138::LR 0.0653846153846 --> Loss 0.00132967780034\n",
      "Epoch 16::Minibatch 139::LR 0.0653846153846 --> Loss 0.00192428807418\n",
      "Epoch 16::Minibatch 140::LR 0.0653846153846 --> Loss 0.00247432092826\n",
      "Epoch 16::Minibatch 141::LR 0.0653846153846 --> Loss 0.00299700578054\n",
      "Epoch 16::Minibatch 142::LR 0.0653846153846 --> Loss 0.00295108218988\n",
      "Epoch 16::Minibatch 143::LR 0.0653846153846 --> Loss 0.000617525279522\n",
      "Epoch 16::Minibatch 144::LR 0.0653846153846 --> Loss 0.00323568642139\n",
      "Epoch 16::Minibatch 145::LR 0.0653846153846 --> Loss 0.00435338973999\n",
      "Epoch 16::Minibatch 146::LR 0.0653846153846 --> Loss 0.00260857582092\n",
      "Epoch 16::Minibatch 147::LR 0.0653846153846 --> Loss 0.00183078726133\n",
      "Epoch 16::Minibatch 148::LR 0.0653846153846 --> Loss 0.00102281371752\n",
      "Epoch 16::Minibatch 149::LR 0.0653846153846 --> Loss 0.00284717698892\n",
      "Epoch 16::Minibatch 150::LR 0.0653846153846 --> Loss 0.00274185419083\n",
      "Epoch 16::Minibatch 151::LR 0.0653846153846 --> Loss 0.00425765474637\n",
      "Epoch 16::Minibatch 152::LR 0.0653846153846 --> Loss 0.000928995907307\n",
      "Epoch 16::Minibatch 153::LR 0.0653846153846 --> Loss 0.00184563040733\n",
      "Epoch 16::Minibatch 154::LR 0.0653846153846 --> Loss 0.00206796487172\n",
      "Epoch 16::Minibatch 155::LR 0.0653846153846 --> Loss 0.00457854151726\n",
      "Epoch 16::Minibatch 156::LR 0.0653846153846 --> Loss 0.00241546650728\n",
      "Epoch 16::Minibatch 157::LR 0.0653846153846 --> Loss 0.000702013472716\n",
      "Epoch 16::Minibatch 158::LR 0.0653846153846 --> Loss 0.00305683513482\n",
      "Epoch 16::Minibatch 159::LR 0.0653846153846 --> Loss 0.00277072628339\n",
      "Epoch 16::Minibatch 160::LR 0.0653846153846 --> Loss 0.00264998137951\n",
      "Epoch 16::Minibatch 161::LR 0.0653846153846 --> Loss 0.00102929800749\n",
      "Epoch 16::Minibatch 162::LR 0.0653846153846 --> Loss 0.00373713413874\n",
      "Epoch 16::Minibatch 163::LR 0.0653846153846 --> Loss 0.00241451501846\n",
      "Epoch 16::Minibatch 164::LR 0.0653846153846 --> Loss 0.00250370085239\n",
      "Epoch 16::Minibatch 165::LR 0.0653846153846 --> Loss 0.000535093396902\n",
      "Epoch 16::Minibatch 166::LR 0.0653846153846 --> Loss 0.00180356283983\n",
      "Epoch 16::Minibatch 167::LR 0.0653846153846 --> Loss 0.00246424734592\n",
      "Epoch 16::Minibatch 168::LR 0.0653846153846 --> Loss 0.00219785749912\n",
      "Epoch 16::Minibatch 169::LR 0.0653846153846 --> Loss 0.00101950536172\n",
      "Epoch 16::Minibatch 170::LR 0.0653846153846 --> Loss 0.00099511663119\n",
      "Epoch 16::Minibatch 171::LR 0.0653846153846 --> Loss 0.00252696533998\n",
      "Epoch 16::Minibatch 172::LR 0.0653846153846 --> Loss 0.00456486582756\n",
      "Epoch 16::Minibatch 173::LR 0.0653846153846 --> Loss 0.00196343859037\n",
      "Epoch 16::Minibatch 174::LR 0.0653846153846 --> Loss 0.00105664014816\n",
      "Epoch 16::Minibatch 175::LR 0.0653846153846 --> Loss 0.00230701863766\n",
      "Epoch 16::Minibatch 176::LR 0.0653846153846 --> Loss 0.00331682066123\n",
      "Epoch 16::Minibatch 177::LR 0.0653846153846 --> Loss 0.00460666139921\n",
      "Epoch 16::Minibatch 178::LR 0.0653846153846 --> Loss 0.00165338814259\n",
      "Epoch 16::Minibatch 179::LR 0.0653846153846 --> Loss 0.00138614535332\n",
      "Epoch 16::Minibatch 180::LR 0.0653846153846 --> Loss 0.00366030732791\n",
      "Epoch 16::Minibatch 181::LR 0.0653846153846 --> Loss 0.00329615930716\n",
      "Epoch 16::Minibatch 182::LR 0.0653846153846 --> Loss 0.000791494299968\n",
      "Epoch 16::Minibatch 183::LR 0.0653846153846 --> Loss 0.00170614957809\n",
      "Epoch 16::Minibatch 184::LR 0.0653846153846 --> Loss 0.00342780709267\n",
      "Epoch 16::Minibatch 185::LR 0.0653846153846 --> Loss 0.00286052823067\n",
      "Epoch 16::Minibatch 186::LR 0.0653846153846 --> Loss 0.000982289413611\n",
      "Epoch 16::Minibatch 187::LR 0.0653846153846 --> Loss 0.00125988115867\n",
      "Epoch 16::Minibatch 188::LR 0.0653846153846 --> Loss 0.00419693191846\n",
      "Epoch 16::Minibatch 189::LR 0.0653846153846 --> Loss 0.00449988722801\n",
      "Epoch 16::Minibatch 190::LR 0.0653846153846 --> Loss 0.00232235491276\n",
      "Epoch 16::Minibatch 191::LR 0.0653846153846 --> Loss 0.000487706114848\n",
      "Epoch 16::Minibatch 192::LR 0.0653846153846 --> Loss 0.0027089035511\n",
      "Epoch 16::Minibatch 193::LR 0.0653846153846 --> Loss 0.00254950165749\n",
      "Epoch 16::Minibatch 194::LR 0.0653846153846 --> Loss 0.00179378926754\n",
      "Epoch 16::Minibatch 195::LR 0.0653846153846 --> Loss 0.000391996602217\n",
      "Epoch 16::Minibatch 196::LR 0.0653846153846 --> Loss 0.00122984558344\n",
      "Epoch 16::Minibatch 197::LR 0.0653846153846 --> Loss 0.00285561680794\n",
      "Epoch 16::Minibatch 198::LR 0.0653846153846 --> Loss 0.00220526218414\n",
      "Epoch 16::Minibatch 199::LR 0.0653846153846 --> Loss 0.000291261772315\n",
      "Epoch 16::Minibatch 200::LR 0.0653846153846 --> Loss 0.00207289596399\n",
      "Epoch 16::Minibatch 201::LR 0.0653846153846 --> Loss 0.00196392635504\n",
      "Epoch 16::Minibatch 202::LR 0.0653846153846 --> Loss 0.00188144902388\n",
      "Epoch 16::Minibatch 203::LR 0.0653846153846 --> Loss 0.0017918886741\n",
      "Epoch 16::Minibatch 204::LR 0.0653846153846 --> Loss 0.00148465573788\n",
      "Epoch 16::Minibatch 205::LR 0.0653846153846 --> Loss 0.0022213323911\n",
      "Epoch 16::Minibatch 206::LR 0.0653846153846 --> Loss 0.00661604603132\n",
      "Epoch 16::Minibatch 207::LR 0.0653846153846 --> Loss 0.0013991244634\n",
      "Epoch 16::Minibatch 208::LR 0.0653846153846 --> Loss 0.00114091306925\n",
      "Epoch 16::Minibatch 209::LR 0.0653846153846 --> Loss 0.00217954198519\n",
      "Epoch 16::Minibatch 210::LR 0.0653846153846 --> Loss 0.00207951426506\n",
      "Epoch 16::Minibatch 211::LR 0.0653846153846 --> Loss 0.00222556849321\n",
      "Epoch 16::Minibatch 212::LR 0.0653846153846 --> Loss 0.00405098835627\n",
      "Epoch 16::Minibatch 213::LR 0.0653846153846 --> Loss 0.00597444176674\n",
      "Epoch 16::Minibatch 214::LR 0.0653846153846 --> Loss 0.00954403956731\n",
      "Epoch 16::Minibatch 215::LR 0.0653846153846 --> Loss 0.00141355593999\n",
      "Epoch 16::Minibatch 216::LR 0.0653846153846 --> Loss 0.00555041750272\n",
      "Epoch 16::Minibatch 217::LR 0.0653846153846 --> Loss 0.00617687424024\n",
      "Epoch 16::Minibatch 218::LR 0.0653846153846 --> Loss 0.00397584279378\n",
      "Epoch 16::Minibatch 219::LR 0.0653846153846 --> Loss 0.00404371023178\n",
      "Epoch 16::Minibatch 220::LR 0.0653846153846 --> Loss 0.0045638247331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 221::LR 0.0653846153846 --> Loss 0.00428530653318\n",
      "Epoch 16::Minibatch 222::LR 0.0653846153846 --> Loss 0.00328519999981\n",
      "Epoch 16::Minibatch 223::LR 0.0653846153846 --> Loss 0.00143217593431\n",
      "Epoch 16::Minibatch 224::LR 0.0653846153846 --> Loss 0.00180234511693\n",
      "Epoch 16::Minibatch 225::LR 0.0653846153846 --> Loss 0.00723545471827\n",
      "Epoch 16::Minibatch 226::LR 0.0653846153846 --> Loss 0.00380777398745\n",
      "Epoch 16::Minibatch 227::LR 0.0653846153846 --> Loss 0.0017068318526\n",
      "Epoch 16::Minibatch 228::LR 0.0653846153846 --> Loss 0.000764886836211\n",
      "Epoch 16::Minibatch 229::LR 0.0653846153846 --> Loss 0.00480238755544\n",
      "Epoch 16::Minibatch 230::LR 0.0653846153846 --> Loss 0.00397420525551\n",
      "Epoch 16::Minibatch 231::LR 0.0653846153846 --> Loss 0.00264065961043\n",
      "Epoch 16::Minibatch 232::LR 0.0653846153846 --> Loss 0.00123838524024\n",
      "Epoch 16::Minibatch 233::LR 0.0653846153846 --> Loss 0.00242909550667\n",
      "Epoch 16::Minibatch 234::LR 0.0653846153846 --> Loss 0.00682397047679\n",
      "Epoch 16::Minibatch 235::LR 0.0653846153846 --> Loss 0.0048214773337\n",
      "Epoch 16::Minibatch 236::LR 0.0653846153846 --> Loss 0.00179048915704\n",
      "Epoch 16::Minibatch 237::LR 0.0653846153846 --> Loss 0.000701697369417\n",
      "Epoch 16::Minibatch 238::LR 0.0653846153846 --> Loss 0.00342659115791\n",
      "Epoch 16::Minibatch 239::LR 0.0653846153846 --> Loss 0.00296820104122\n",
      "Epoch 16::Minibatch 240::LR 0.0653846153846 --> Loss 0.00325794200102\n",
      "Epoch 16::Minibatch 241::LR 0.0653846153846 --> Loss 0.000779305994511\n",
      "Epoch 16::Minibatch 242::LR 0.0653846153846 --> Loss 0.00712606112162\n",
      "Epoch 16::Minibatch 243::LR 0.0653846153846 --> Loss 0.00357107281685\n",
      "Epoch 16::Minibatch 244::LR 0.0653846153846 --> Loss 0.0029816442728\n",
      "Epoch 16::Minibatch 245::LR 0.0653846153846 --> Loss 0.000485667437315\n",
      "Epoch 16::Minibatch 246::LR 0.0653846153846 --> Loss 0.00208495299021\n",
      "Epoch 16::Minibatch 247::LR 0.0653846153846 --> Loss 0.0132999332746\n",
      "Epoch 16::Minibatch 248::LR 0.0653846153846 --> Loss 0.00454343040784\n",
      "Epoch 16::Minibatch 249::LR 0.0653846153846 --> Loss 0.00279228925705\n",
      "Epoch 16::Minibatch 250::LR 0.0653846153846 --> Loss 0.00267586628596\n",
      "Epoch 16::Minibatch 251::LR 0.0653846153846 --> Loss 0.00258490383625\n",
      "Epoch 16::Minibatch 252::LR 0.0653846153846 --> Loss 0.00183991750081\n",
      "Epoch 16::Minibatch 253::LR 0.0653846153846 --> Loss 0.00314720392227\n",
      "Epoch 16::Minibatch 254::LR 0.0653846153846 --> Loss 0.00521354715029\n",
      "Epoch 16::Minibatch 255::LR 0.0653846153846 --> Loss 0.0039497979482\n",
      "Epoch 16::Minibatch 256::LR 0.0653846153846 --> Loss 0.00168834070365\n",
      "Epoch 16::Minibatch 257::LR 0.0653846153846 --> Loss 0.00126873791218\n",
      "Epoch 16::Minibatch 258::LR 0.0653846153846 --> Loss 0.00364613175392\n",
      "Epoch 16::Minibatch 259::LR 0.0653846153846 --> Loss 0.00182901163896\n",
      "Epoch 16::Minibatch 260::LR 0.0653846153846 --> Loss 0.00191449761391\n",
      "Epoch 16::Minibatch 261::LR 0.0653846153846 --> Loss 0.00294443766276\n",
      "Epoch 16::Minibatch 262::LR 0.0653846153846 --> Loss 0.00196128845215\n",
      "Epoch 16::Minibatch 263::LR 0.0653846153846 --> Loss 0.00238907714685\n",
      "Epoch 16::Minibatch 264::LR 0.0653846153846 --> Loss 0.00366698384285\n",
      "Epoch 16::Minibatch 265::LR 0.0653846153846 --> Loss 0.0102425217628\n",
      "Epoch 16::Minibatch 266::LR 0.0653846153846 --> Loss 0.00103409975767\n",
      "Epoch 16::Minibatch 267::LR 0.0653846153846 --> Loss 0.0101121870677\n",
      "Epoch 16::Minibatch 268::LR 0.0653846153846 --> Loss 0.00121273477872\n",
      "Epoch 16::Minibatch 269::LR 0.0653846153846 --> Loss 0.00352804899216\n",
      "Epoch 16::Minibatch 270::LR 0.0653846153846 --> Loss 0.00661521673203\n",
      "Epoch 16::Minibatch 271::LR 0.0653846153846 --> Loss 0.00275504549344\n",
      "Epoch 16::Minibatch 272::LR 0.0653846153846 --> Loss 0.00409315427144\n",
      "Epoch 16::Minibatch 273::LR 0.0653846153846 --> Loss 0.00170420885086\n",
      "Epoch 16::Minibatch 274::LR 0.0653846153846 --> Loss 0.00180841048559\n",
      "Epoch 16::Minibatch 275::LR 0.0653846153846 --> Loss 0.00268653372924\n",
      "Epoch 16::Minibatch 276::LR 0.0653846153846 --> Loss 0.00348436037699\n",
      "Epoch 16::Minibatch 277::LR 0.0653846153846 --> Loss 0.00101648042599\n",
      "Epoch 16::Minibatch 278::LR 0.0653846153846 --> Loss 0.00265034635862\n",
      "Epoch 16::Minibatch 279::LR 0.0653846153846 --> Loss 0.00240413427353\n",
      "Epoch 16::Minibatch 280::LR 0.0653846153846 --> Loss 0.00209102431933\n",
      "Epoch 16::Minibatch 281::LR 0.0653846153846 --> Loss 0.00131185740232\n",
      "Epoch 16::Minibatch 282::LR 0.0653846153846 --> Loss 0.00224325656891\n",
      "Epoch 16::Minibatch 283::LR 0.0653846153846 --> Loss 0.00219325939814\n",
      "Epoch 16::Minibatch 284::LR 0.0653846153846 --> Loss 0.0017511844635\n",
      "Epoch 16::Minibatch 285::LR 0.0653846153846 --> Loss 0.00122148861488\n",
      "Epoch 16::Minibatch 286::LR 0.0653846153846 --> Loss 0.00215128918489\n",
      "Epoch 16::Minibatch 287::LR 0.0653846153846 --> Loss 0.00208649237951\n",
      "Epoch 16::Minibatch 288::LR 0.0653846153846 --> Loss 0.00111959566673\n",
      "Epoch 16::Minibatch 289::LR 0.0653846153846 --> Loss 0.0015899309516\n",
      "Epoch 16::Minibatch 290::LR 0.0653846153846 --> Loss 0.00195003509521\n",
      "Epoch 16::Minibatch 291::LR 0.0653846153846 --> Loss 0.00173615038395\n",
      "Epoch 16::Minibatch 292::LR 0.0653846153846 --> Loss 0.000608409841855\n",
      "Epoch 16::Minibatch 293::LR 0.0653846153846 --> Loss 0.00149209707975\n",
      "Epoch 16::Minibatch 294::LR 0.0653846153846 --> Loss 0.00157014409701\n",
      "Epoch 16::Minibatch 295::LR 0.0653846153846 --> Loss 0.00185814897219\n",
      "Epoch 16::Minibatch 296::LR 0.0653846153846 --> Loss 0.00160899450382\n",
      "Epoch 16::Minibatch 297::LR 0.0653846153846 --> Loss 0.00139803608259\n",
      "Epoch 16::Minibatch 298::LR 0.0653846153846 --> Loss 0.00138227105141\n",
      "Epoch 16::Minibatch 299::LR 0.0653846153846 --> Loss 0.000798000892003\n",
      "Epoch 16::Minibatch 300::LR 0.0653846153846 --> Loss 0.00282726744811\n",
      "Epoch 16::Minibatch 301::LR 0.0653846153846 --> Loss 0.00274058183034\n",
      "Epoch 16::Minibatch 302::LR 0.0653846153846 --> Loss 0.00253778835138\n",
      "Epoch 16::Minibatch 303::LR 0.0653846153846 --> Loss 0.000863413413366\n",
      "Epoch 16::Minibatch 304::LR 0.0653846153846 --> Loss 0.00311921954155\n",
      "Epoch 16::Minibatch 305::LR 0.0653846153846 --> Loss 0.00169210890929\n",
      "Epoch 16::Minibatch 306::LR 0.0653846153846 --> Loss 0.000930064618587\n",
      "Epoch 16::Minibatch 307::LR 0.0653846153846 --> Loss 0.00246282279491\n",
      "Epoch 16::Minibatch 308::LR 0.0653846153846 --> Loss 0.00198887526989\n",
      "Epoch 16::Minibatch 309::LR 0.0653846153846 --> Loss 0.00100063016017\n",
      "Epoch 16::Minibatch 310::LR 0.0653846153846 --> Loss 0.00111177325249\n",
      "Epoch 16::Minibatch 311::LR 0.0653846153846 --> Loss 0.0017130680879\n",
      "Epoch 16::Minibatch 312::LR 0.0653846153846 --> Loss 0.00297734340032\n",
      "Epoch 16::Minibatch 313::LR 0.0653846153846 --> Loss 0.00239973247051\n",
      "Epoch 16::Minibatch 314::LR 0.0653846153846 --> Loss 0.00191897710164\n",
      "Epoch 16::Minibatch 315::LR 0.0653846153846 --> Loss 0.000993370513121\n",
      "Epoch 16::Minibatch 316::LR 0.0653846153846 --> Loss 0.00233155767123\n",
      "Epoch 16::Minibatch 317::LR 0.0653846153846 --> Loss 0.00154725839694\n",
      "Epoch 16::Minibatch 318::LR 0.0653846153846 --> Loss 0.00121722280979\n",
      "Epoch 16::Minibatch 319::LR 0.0653846153846 --> Loss 0.00229437232018\n",
      "Epoch 16::Minibatch 320::LR 0.0653846153846 --> Loss 0.0032145567735\n",
      "Epoch 16::Minibatch 321::LR 0.0653846153846 --> Loss 0.00086029668649\n",
      "Epoch 16::Minibatch 322::LR 0.0653846153846 --> Loss 0.00367457191149\n",
      "Epoch 16::Minibatch 323::LR 0.0653846153846 --> Loss 0.00355800350507\n",
      "Epoch 16::Minibatch 324::LR 0.0653846153846 --> Loss 0.00263511796792\n",
      "Epoch 16::Minibatch 325::LR 0.0653846153846 --> Loss 0.0024116307497\n",
      "Epoch 16::Minibatch 326::LR 0.0653846153846 --> Loss 0.00553416132927\n",
      "Epoch 16::Minibatch 327::LR 0.0653846153846 --> Loss 0.00226503610611\n",
      "Epoch 16::Minibatch 328::LR 0.0653846153846 --> Loss 0.00330866217613\n",
      "Epoch 16::Minibatch 329::LR 0.0653846153846 --> Loss 0.00123828470707\n",
      "Epoch 16::Minibatch 330::LR 0.0653846153846 --> Loss 0.00161281297604\n",
      "Epoch 16::Minibatch 331::LR 0.0653846153846 --> Loss 0.00255734304587\n",
      "Epoch 16::Minibatch 332::LR 0.0653846153846 --> Loss 0.00251409928004\n",
      "Epoch 16::Minibatch 333::LR 0.0653846153846 --> Loss 0.00145580460628\n",
      "Epoch 16::Minibatch 334::LR 0.0653846153846 --> Loss 0.00437727133433\n",
      "Epoch 16::Minibatch 335::LR 0.0653846153846 --> Loss 0.00189332862695\n",
      "Epoch 16::Minibatch 336::LR 0.0653846153846 --> Loss 0.0021484619379\n",
      "Epoch 16::Minibatch 337::LR 0.0653846153846 --> Loss 0.00341644446055\n",
      "Epoch 16::Minibatch 338::LR 0.0653846153846 --> Loss 0.000521432459354\n",
      "Epoch 16::Minibatch 339::LR 0.0653846153846 --> Loss 0.0033218918244\n",
      "Epoch 16::Minibatch 340::LR 0.0653846153846 --> Loss 0.00419216752052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 341::LR 0.0653846153846 --> Loss 0.00490008354187\n",
      "Epoch 16::Minibatch 342::LR 0.0653846153846 --> Loss 0.00316453119119\n",
      "Epoch 16::Minibatch 343::LR 0.0653846153846 --> Loss 0.00169410308202\n",
      "Epoch 16::Minibatch 344::LR 0.0653846153846 --> Loss 0.00312332749367\n",
      "Epoch 16::Minibatch 345::LR 0.0653846153846 --> Loss 0.00429366787275\n",
      "Epoch 16::Minibatch 346::LR 0.0653846153846 --> Loss 0.00568000157674\n",
      "Epoch 16::Minibatch 347::LR 0.0653846153846 --> Loss 0.000878948271275\n",
      "Epoch 16::Minibatch 348::LR 0.0653846153846 --> Loss 0.00344720959663\n",
      "Epoch 16::Minibatch 349::LR 0.0653846153846 --> Loss 0.00352403004964\n",
      "Epoch 16::Minibatch 350::LR 0.0653846153846 --> Loss 0.00180305679639\n",
      "Epoch 16::Minibatch 351::LR 0.0653846153846 --> Loss 0.00355822960536\n",
      "Epoch 16::Minibatch 352::LR 0.0653846153846 --> Loss 0.00487487792969\n",
      "Epoch 16::Minibatch 353::LR 0.0653846153846 --> Loss 0.00355686624845\n",
      "Epoch 16::Minibatch 354::LR 0.0653846153846 --> Loss 0.00294585208098\n",
      "Epoch 16::Minibatch 355::LR 0.0653846153846 --> Loss 0.0061695766449\n",
      "Epoch 16::Minibatch 356::LR 0.0653846153846 --> Loss 0.00313567916552\n",
      "Epoch 16::Minibatch 357::LR 0.0653846153846 --> Loss 0.00117004354795\n",
      "Epoch 16::Minibatch 358::LR 0.0653846153846 --> Loss 0.00216381331285\n",
      "Epoch 16::Minibatch 359::LR 0.0653846153846 --> Loss 0.00273692945639\n",
      "Epoch 16::Minibatch 360::LR 0.0653846153846 --> Loss 0.00244111935298\n",
      "Epoch 16::Minibatch 361::LR 0.0653846153846 --> Loss 0.00242740313212\n",
      "Epoch 16::Minibatch 362::LR 0.0653846153846 --> Loss 0.00241791387399\n",
      "Epoch 16::Minibatch 363::LR 0.0653846153846 --> Loss 0.000669317692518\n",
      "Epoch 16::Minibatch 364::LR 0.0653846153846 --> Loss 0.00201295336088\n",
      "Epoch 16::Minibatch 365::LR 0.0653846153846 --> Loss 0.00210133751233\n",
      "Epoch 16::Minibatch 366::LR 0.0653846153846 --> Loss 0.00225566546122\n",
      "Epoch 16::Minibatch 367::LR 0.0653846153846 --> Loss 0.00109226495028\n",
      "Epoch 16::Minibatch 368::LR 0.0653846153846 --> Loss 0.000989245772362\n",
      "Epoch 16::Minibatch 369::LR 0.0653846153846 --> Loss 0.00288459102313\n",
      "Epoch 16::Minibatch 370::LR 0.0653846153846 --> Loss 0.00226927280426\n",
      "Epoch 16::Minibatch 371::LR 0.0653846153846 --> Loss 0.00187897622585\n",
      "Epoch 16::Minibatch 372::LR 0.0653846153846 --> Loss 0.000439219921827\n",
      "Epoch 16::Minibatch 373::LR 0.0653846153846 --> Loss 0.0017691163222\n",
      "Epoch 16::Minibatch 374::LR 0.0653846153846 --> Loss 0.00218317230543\n",
      "Epoch 16::Minibatch 375::LR 0.0653846153846 --> Loss 0.00184257706006\n",
      "Epoch 16::Minibatch 376::LR 0.0653846153846 --> Loss 0.00124050875505\n",
      "Epoch 16::Minibatch 377::LR 0.0653846153846 --> Loss 0.0019470624129\n",
      "Epoch 16::Minibatch 378::LR 0.0653846153846 --> Loss 0.0021299892664\n",
      "Epoch 16::Minibatch 379::LR 0.0653846153846 --> Loss 0.00237850030263\n",
      "Epoch 16::Minibatch 380::LR 0.0653846153846 --> Loss 0.001590282619\n",
      "Epoch 16::Minibatch 381::LR 0.0653846153846 --> Loss 0.00098334501187\n",
      "Epoch 16::Minibatch 382::LR 0.0653846153846 --> Loss 0.00201253632704\n",
      "Epoch 16::Minibatch 383::LR 0.0653846153846 --> Loss 0.00195407052835\n",
      "Epoch 16::Minibatch 384::LR 0.0653846153846 --> Loss 0.00105353643497\n",
      "Epoch 16::Minibatch 385::LR 0.0653846153846 --> Loss 0.00103588342667\n",
      "Epoch 16::Minibatch 386::LR 0.0653846153846 --> Loss 0.00218169887861\n",
      "Epoch 16::Minibatch 387::LR 0.0653846153846 --> Loss 0.00233696997166\n",
      "Epoch 16::Minibatch 388::LR 0.0653846153846 --> Loss 0.00114962130785\n",
      "Epoch 16::Minibatch 389::LR 0.0653846153846 --> Loss 0.0018057201306\n",
      "Epoch 16::Minibatch 390::LR 0.0653846153846 --> Loss 0.00357185403506\n",
      "Epoch 16::Minibatch 391::LR 0.0653846153846 --> Loss 0.00268326560656\n",
      "Epoch 16::Minibatch 392::LR 0.0653846153846 --> Loss 0.00264604945978\n",
      "Epoch 16::Minibatch 393::LR 0.0653846153846 --> Loss 0.00277480145295\n",
      "Epoch 16::Minibatch 394::LR 0.0653846153846 --> Loss 0.00208054701487\n",
      "Epoch 16::Minibatch 395::LR 0.0653846153846 --> Loss 0.00205768565337\n",
      "Epoch 16::Minibatch 396::LR 0.0653846153846 --> Loss 0.00194874624411\n",
      "Epoch 16::Minibatch 397::LR 0.0653846153846 --> Loss 0.00207762340705\n",
      "Epoch 16::Minibatch 398::LR 0.0653846153846 --> Loss 0.00206183930238\n",
      "Epoch 16::Minibatch 399::LR 0.0653846153846 --> Loss 0.00236698349317\n",
      "Epoch 16::Minibatch 400::LR 0.0653846153846 --> Loss 0.00201603631179\n",
      "Epoch 16::Minibatch 401::LR 0.0653846153846 --> Loss 0.00349959174792\n",
      "Epoch 16::Minibatch 402::LR 0.0653846153846 --> Loss 0.00181174695492\n",
      "Epoch 16::Minibatch 403::LR 0.0653846153846 --> Loss 0.00145371129115\n",
      "Epoch 16::Minibatch 404::LR 0.0653846153846 --> Loss 0.00149125754833\n",
      "Epoch 16::Minibatch 405::LR 0.0653846153846 --> Loss 0.0035212747256\n",
      "Epoch 16::Minibatch 406::LR 0.0653846153846 --> Loss 0.00246609946092\n",
      "Epoch 16::Minibatch 407::LR 0.0653846153846 --> Loss 0.00174374242624\n",
      "Epoch 16::Minibatch 408::LR 0.0653846153846 --> Loss 0.000442421038946\n",
      "Epoch 16::Minibatch 409::LR 0.0653846153846 --> Loss 0.00232517162959\n",
      "Epoch 16::Minibatch 410::LR 0.0653846153846 --> Loss 0.00321649948756\n",
      "Epoch 16::Minibatch 411::LR 0.0653846153846 --> Loss 0.00163778573275\n",
      "Epoch 16::Minibatch 412::LR 0.0653846153846 --> Loss 0.00096312781175\n",
      "Epoch 16::Minibatch 413::LR 0.0653846153846 --> Loss 0.00197205245495\n",
      "Epoch 16::Minibatch 414::LR 0.0653846153846 --> Loss 0.00182933648427\n",
      "Epoch 16::Minibatch 415::LR 0.0653846153846 --> Loss 0.00114405085643\n",
      "Epoch 16::Minibatch 416::LR 0.0653846153846 --> Loss 0.000815254449844\n",
      "Epoch 16::Minibatch 417::LR 0.0653846153846 --> Loss 0.00170011003812\n",
      "Epoch 16::Minibatch 418::LR 0.0653846153846 --> Loss 0.00277073045572\n",
      "Epoch 16::Minibatch 419::LR 0.0653846153846 --> Loss 0.000496084491412\n",
      "Epoch 16::Minibatch 420::LR 0.0653846153846 --> Loss 0.000688145409028\n",
      "Epoch 16::Minibatch 421::LR 0.0653846153846 --> Loss 0.00192294637362\n",
      "Epoch 16::Minibatch 422::LR 0.0653846153846 --> Loss 0.00213916877906\n",
      "Epoch 16::Minibatch 423::LR 0.0653846153846 --> Loss 0.000958082079887\n",
      "Epoch 16::Minibatch 424::LR 0.0653846153846 --> Loss 0.0015505284071\n",
      "Epoch 16::Minibatch 425::LR 0.0653846153846 --> Loss 0.00289586265882\n",
      "Epoch 16::Minibatch 426::LR 0.0653846153846 --> Loss 0.00199629505475\n",
      "Epoch 16::Minibatch 427::LR 0.0653846153846 --> Loss 0.000705666790406\n",
      "Epoch 16::Minibatch 428::LR 0.0653846153846 --> Loss 0.0010430119435\n",
      "Epoch 16::Minibatch 429::LR 0.0653846153846 --> Loss 0.00238853772481\n",
      "Epoch 16::Minibatch 430::LR 0.0653846153846 --> Loss 0.00939130544662\n",
      "Epoch 16::Minibatch 431::LR 0.0653846153846 --> Loss 0.00377904375394\n",
      "Epoch 16::Minibatch 432::LR 0.0653846153846 --> Loss 0.00444225589434\n",
      "Epoch 16::Minibatch 433::LR 0.0653846153846 --> Loss 0.00257846593857\n",
      "Epoch 16::Minibatch 434::LR 0.0653846153846 --> Loss 0.0025424549977\n",
      "Epoch 16::Minibatch 435::LR 0.0653846153846 --> Loss 0.00234756807486\n",
      "Epoch 16::Minibatch 436::LR 0.0653846153846 --> Loss 0.00170669694742\n",
      "Epoch 16::Minibatch 437::LR 0.0653846153846 --> Loss 0.00327422618866\n",
      "Epoch 16::Minibatch 438::LR 0.0653846153846 --> Loss 0.00261281728745\n",
      "Epoch 16::Minibatch 439::LR 0.0653846153846 --> Loss 0.00210443437099\n",
      "Epoch 16::Minibatch 440::LR 0.0653846153846 --> Loss 0.00324315647284\n",
      "Epoch 16::Minibatch 441::LR 0.0653846153846 --> Loss 0.00303294281165\n",
      "Epoch 16::Minibatch 442::LR 0.0653846153846 --> Loss 0.00277556637923\n",
      "Epoch 16::Minibatch 443::LR 0.0653846153846 --> Loss 0.00368749817212\n",
      "Epoch 16::Minibatch 444::LR 0.0653846153846 --> Loss 0.00289130349954\n",
      "Epoch 16::Minibatch 445::LR 0.0653846153846 --> Loss 0.000899448494116\n",
      "Epoch 16::Minibatch 446::LR 0.0653846153846 --> Loss 0.00146259834369\n",
      "Epoch 16::Minibatch 447::LR 0.0653846153846 --> Loss 0.00244583487511\n",
      "Epoch 16::Minibatch 448::LR 0.0653846153846 --> Loss 0.00241841316223\n",
      "Epoch 16::Minibatch 449::LR 0.0653846153846 --> Loss 0.00374203046163\n",
      "Epoch 16::Minibatch 450::LR 0.0653846153846 --> Loss 0.00231953124205\n",
      "Epoch 16::Minibatch 451::LR 0.0653846153846 --> Loss 0.00405081152916\n",
      "Epoch 16::Minibatch 452::LR 0.0653846153846 --> Loss 0.00238620440165\n",
      "Epoch 16::Minibatch 453::LR 0.0653846153846 --> Loss 0.000380651255449\n",
      "Epoch 16::Minibatch 454::LR 0.0653846153846 --> Loss 0.0036060988903\n",
      "Epoch 16::Minibatch 455::LR 0.0653846153846 --> Loss 0.00270490030448\n",
      "Epoch 16::Minibatch 456::LR 0.0653846153846 --> Loss 0.00314118027687\n",
      "Epoch 16::Minibatch 457::LR 0.0653846153846 --> Loss 0.00196977118651\n",
      "Epoch 16::Minibatch 458::LR 0.0653846153846 --> Loss 0.000762894302607\n",
      "Epoch 16::Minibatch 459::LR 0.0653846153846 --> Loss 0.00409547924995\n",
      "Epoch 16::Minibatch 460::LR 0.0653846153846 --> Loss 0.0025956817468\n",
      "Epoch 16::Minibatch 461::LR 0.0653846153846 --> Loss 0.00391470352809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 462::LR 0.0653846153846 --> Loss 0.000397262225548\n",
      "Epoch 16::Minibatch 463::LR 0.0653846153846 --> Loss 0.00449935634931\n",
      "Epoch 16::Minibatch 464::LR 0.0653846153846 --> Loss 0.00204472382863\n",
      "Epoch 16::Minibatch 465::LR 0.0653846153846 --> Loss 0.00521982709567\n",
      "Epoch 16::Minibatch 466::LR 0.0653846153846 --> Loss 0.0051378317674\n",
      "Epoch 16::Minibatch 467::LR 0.0653846153846 --> Loss 0.00575264294942\n",
      "Epoch 16::Minibatch 468::LR 0.0653846153846 --> Loss 0.00609555204709\n",
      "Epoch 16::Minibatch 469::LR 0.0653846153846 --> Loss 0.00615315635999\n",
      "Epoch 16::Minibatch 470::LR 0.0653846153846 --> Loss 0.0037772333622\n",
      "Epoch 16::Minibatch 471::LR 0.0653846153846 --> Loss 0.00175022582213\n",
      "Epoch 16::Minibatch 472::LR 0.0653846153846 --> Loss 0.0035392888387\n",
      "Epoch 16::Minibatch 473::LR 0.0653846153846 --> Loss 0.00224510212739\n",
      "Epoch 16::Minibatch 474::LR 0.0653846153846 --> Loss 0.000704089105129\n",
      "Epoch 16::Minibatch 475::LR 0.0653846153846 --> Loss 0.00526321609815\n",
      "Epoch 16::Minibatch 476::LR 0.0653846153846 --> Loss 0.00783785025279\n",
      "Epoch 16::Minibatch 477::LR 0.0653846153846 --> Loss 0.000935917297999\n",
      "Epoch 16::Minibatch 478::LR 0.0653846153846 --> Loss 0.00245919167995\n",
      "Epoch 16::Minibatch 479::LR 0.0653846153846 --> Loss 0.00195996065934\n",
      "Epoch 16::Minibatch 480::LR 0.0653846153846 --> Loss 0.00153356581926\n",
      "Epoch 16::Minibatch 481::LR 0.0653846153846 --> Loss 0.000958563586076\n",
      "Epoch 16::Minibatch 482::LR 0.0653846153846 --> Loss 0.00209954679012\n",
      "Epoch 16::Minibatch 483::LR 0.0653846153846 --> Loss 0.0031893603007\n",
      "Epoch 16::Minibatch 484::LR 0.0653846153846 --> Loss 0.00355615258217\n",
      "Epoch 16::Minibatch 485::LR 0.0653846153846 --> Loss 0.000760833670696\n",
      "Epoch 16::Minibatch 486::LR 0.0653846153846 --> Loss 0.00297272225221\n",
      "Epoch 16::Minibatch 487::LR 0.0653846153846 --> Loss 0.0033772512277\n",
      "Epoch 16::Minibatch 488::LR 0.0653846153846 --> Loss 0.00204757392406\n",
      "Epoch 16::Minibatch 489::LR 0.0653846153846 --> Loss 0.00316525777181\n",
      "Epoch 16::Minibatch 490::LR 0.0653846153846 --> Loss 0.000412561943134\n",
      "Epoch 16::Minibatch 491::LR 0.0653846153846 --> Loss 0.00375380118688\n",
      "Epoch 16::Minibatch 492::LR 0.0653846153846 --> Loss 0.0030535197258\n",
      "Epoch 16::Minibatch 493::LR 0.0653846153846 --> Loss 0.00303400337696\n",
      "Epoch 16::Minibatch 494::LR 0.0653846153846 --> Loss 0.000740567495426\n",
      "Epoch 16::Minibatch 495::LR 0.0653846153846 --> Loss 0.00187755425771\n",
      "Epoch 16::Minibatch 496::LR 0.0653846153846 --> Loss 0.00290347774824\n",
      "Epoch 16::Minibatch 497::LR 0.0653846153846 --> Loss 0.000935435096423\n",
      "Epoch 16::Minibatch 498::LR 0.0653846153846 --> Loss 0.000568722635508\n",
      "Epoch 16::Minibatch 499::LR 0.0653846153846 --> Loss 0.0036471092701\n",
      "Epoch 16::Minibatch 500::LR 0.0653846153846 --> Loss 0.00144624163707\n",
      "Epoch 16::Minibatch 501::LR 0.0653846153846 --> Loss 0.00221937139829\n",
      "Epoch 16::Minibatch 502::LR 0.0653846153846 --> Loss 0.0038495751222\n",
      "Epoch 16::Minibatch 503::LR 0.0653846153846 --> Loss 0.0083576631546\n",
      "Epoch 16::Minibatch 504::LR 0.0653846153846 --> Loss 0.00777582009633\n",
      "Epoch 16::Minibatch 505::LR 0.0653846153846 --> Loss 0.00429097851117\n",
      "Epoch 16::Minibatch 506::LR 0.0653846153846 --> Loss 0.00347267230352\n",
      "Epoch 16::Minibatch 507::LR 0.0653846153846 --> Loss 0.00603114485741\n",
      "Epoch 16::Minibatch 508::LR 0.0653846153846 --> Loss 0.00341357111931\n",
      "Epoch 16::Minibatch 509::LR 0.0653846153846 --> Loss 0.00459110339483\n",
      "Epoch 16::Minibatch 510::LR 0.0653846153846 --> Loss 0.00459283312162\n",
      "Epoch 16::Minibatch 511::LR 0.0653846153846 --> Loss 0.0039226102829\n",
      "Epoch 16::Minibatch 512::LR 0.0653846153846 --> Loss 0.00269060472647\n",
      "Epoch 16::Minibatch 513::LR 0.0653846153846 --> Loss 0.000649273643891\n",
      "Epoch 16::Minibatch 514::LR 0.0653846153846 --> Loss 0.0026267439127\n",
      "Epoch 16::Minibatch 515::LR 0.0653846153846 --> Loss 0.00301521162192\n",
      "Epoch 16::Minibatch 516::LR 0.0653846153846 --> Loss 0.00409596602122\n",
      "Epoch 16::Minibatch 517::LR 0.0653846153846 --> Loss 0.00350378235181\n",
      "Epoch 16::Minibatch 518::LR 0.0653846153846 --> Loss 0.00257018268108\n",
      "Epoch 16::Minibatch 519::LR 0.0653846153846 --> Loss 0.0034584180514\n",
      "Epoch 16::Minibatch 520::LR 0.0653846153846 --> Loss 0.00538637518883\n",
      "Epoch 16::Minibatch 521::LR 0.0653846153846 --> Loss 0.00543271740278\n",
      "Epoch 16::Minibatch 522::LR 0.0653846153846 --> Loss 0.00799750725428\n",
      "Epoch 16::Minibatch 523::LR 0.0653846153846 --> Loss 0.000656140595675\n",
      "Epoch 16::Minibatch 524::LR 0.0653846153846 --> Loss 0.00142925808827\n",
      "Epoch 16::Minibatch 525::LR 0.0653846153846 --> Loss 0.00323637684186\n",
      "Epoch 16::Minibatch 526::LR 0.0653846153846 --> Loss 0.00404422561328\n",
      "Epoch 16::Minibatch 527::LR 0.0653846153846 --> Loss 0.00227029045423\n",
      "Epoch 16::Minibatch 528::LR 0.0653846153846 --> Loss 0.00106092661619\n",
      "Epoch 16::Minibatch 529::LR 0.0653846153846 --> Loss 0.00408726294835\n",
      "Epoch 16::Minibatch 530::LR 0.0653846153846 --> Loss 0.00414297660192\n",
      "Epoch 16::Minibatch 531::LR 0.0653846153846 --> Loss 0.00359449823697\n",
      "Epoch 16::Minibatch 532::LR 0.0653846153846 --> Loss 0.00270897746086\n",
      "Epoch 16::Minibatch 533::LR 0.0653846153846 --> Loss 0.00494854966799\n",
      "Epoch 16::Minibatch 534::LR 0.0653846153846 --> Loss 0.00382860859235\n",
      "Epoch 16::Minibatch 535::LR 0.0653846153846 --> Loss 0.0032421964407\n",
      "Epoch 16::Minibatch 536::LR 0.0653846153846 --> Loss 0.00211385051409\n",
      "Epoch 16::Minibatch 537::LR 0.0653846153846 --> Loss 0.000629086246093\n",
      "Epoch 16::Minibatch 538::LR 0.0653846153846 --> Loss 0.00169695297877\n",
      "Epoch 16::Minibatch 539::LR 0.0653846153846 --> Loss 0.00343689044317\n",
      "Epoch 16::Minibatch 540::LR 0.0653846153846 --> Loss 0.00342500686646\n",
      "Epoch 16::Minibatch 541::LR 0.0653846153846 --> Loss 0.00291085481644\n",
      "Epoch 16::Minibatch 542::LR 0.0653846153846 --> Loss 0.00252722044786\n",
      "Epoch 16::Minibatch 543::LR 0.0653846153846 --> Loss 0.00275364478429\n",
      "Epoch 16::Minibatch 544::LR 0.0653846153846 --> Loss 0.00391192873319\n",
      "Epoch 16::Minibatch 545::LR 0.0653846153846 --> Loss 0.00204919616381\n",
      "Epoch 16::Minibatch 546::LR 0.0653846153846 --> Loss 0.000658331414064\n",
      "Epoch 16::Minibatch 547::LR 0.0653846153846 --> Loss 0.00263052225113\n",
      "Epoch 16::Minibatch 548::LR 0.0653846153846 --> Loss 0.00370230317116\n",
      "Epoch 16::Minibatch 549::LR 0.0653846153846 --> Loss 0.00859184741974\n",
      "Epoch 16::Minibatch 550::LR 0.0653846153846 --> Loss 0.00117140442133\n",
      "Epoch 16::Minibatch 551::LR 0.0653846153846 --> Loss 0.00245828489463\n",
      "Epoch 16::Minibatch 552::LR 0.0653846153846 --> Loss 0.00356961965561\n",
      "Epoch 16::Minibatch 553::LR 0.0653846153846 --> Loss 0.00321305334568\n",
      "Epoch 16::Minibatch 554::LR 0.0653846153846 --> Loss 0.00375503659248\n",
      "Epoch 16::Minibatch 555::LR 0.0653846153846 --> Loss 0.000985492070516\n",
      "Epoch 16::Minibatch 556::LR 0.0653846153846 --> Loss 0.0020020031929\n",
      "Epoch 16::Minibatch 557::LR 0.0653846153846 --> Loss 0.00243928492069\n",
      "Epoch 16::Minibatch 558::LR 0.0653846153846 --> Loss 0.00370687405268\n",
      "Epoch 16::Minibatch 559::LR 0.0653846153846 --> Loss 0.00374686519305\n",
      "Epoch 16::Minibatch 560::LR 0.0653846153846 --> Loss 0.00308280070623\n",
      "Epoch 16::Minibatch 561::LR 0.0653846153846 --> Loss 0.00271884083748\n",
      "Epoch 16::Minibatch 562::LR 0.0653846153846 --> Loss 0.00238148589929\n",
      "Epoch 16::Minibatch 563::LR 0.0653846153846 --> Loss 0.00402658462524\n",
      "Epoch 16::Minibatch 564::LR 0.0653846153846 --> Loss 0.00312661210696\n",
      "Epoch 16::Minibatch 565::LR 0.0653846153846 --> Loss 0.00369419693947\n",
      "Epoch 16::Minibatch 566::LR 0.0653846153846 --> Loss 0.0022918343544\n",
      "Epoch 16::Minibatch 567::LR 0.0653846153846 --> Loss 0.00258230865002\n",
      "Epoch 16::Minibatch 568::LR 0.0653846153846 --> Loss 0.00182130177816\n",
      "Epoch 16::Minibatch 569::LR 0.0653846153846 --> Loss 0.000566591421763\n",
      "Epoch 16::Minibatch 570::LR 0.0653846153846 --> Loss 0.00171067734559\n",
      "Epoch 16::Minibatch 571::LR 0.0653846153846 --> Loss 0.00223711073399\n",
      "Epoch 16::Minibatch 572::LR 0.0653846153846 --> Loss 0.00237863798936\n",
      "Epoch 16::Minibatch 573::LR 0.0653846153846 --> Loss 0.00151440829039\n",
      "Epoch 16::Minibatch 574::LR 0.0653846153846 --> Loss 0.00105170696974\n",
      "Epoch 16::Minibatch 575::LR 0.0653846153846 --> Loss 0.00179177681605\n",
      "Epoch 16::Minibatch 576::LR 0.0653846153846 --> Loss 0.00212684611479\n",
      "Epoch 16::Minibatch 577::LR 0.0653846153846 --> Loss 0.00166925251484\n",
      "Epoch 16::Minibatch 578::LR 0.0653846153846 --> Loss 0.00129260331392\n",
      "Epoch 16::Minibatch 579::LR 0.0653846153846 --> Loss 0.00120523075263\n",
      "Epoch 16::Minibatch 580::LR 0.0653846153846 --> Loss 0.00195302466551\n",
      "Epoch 16::Minibatch 581::LR 0.0653846153846 --> Loss 0.00172157843908\n",
      "Epoch 16::Minibatch 582::LR 0.0653846153846 --> Loss 0.00412961880366\n",
      "Epoch 16::Minibatch 583::LR 0.0653846153846 --> Loss 0.000944441159566\n",
      "Epoch 16::Minibatch 584::LR 0.0653846153846 --> Loss 0.0013120179375\n",
      "Epoch 16::Minibatch 585::LR 0.0653846153846 --> Loss 0.00445155262947\n",
      "Epoch 16::Minibatch 586::LR 0.0653846153846 --> Loss 0.00401992122332\n",
      "Epoch 16::Minibatch 587::LR 0.0653846153846 --> Loss 0.00113416463137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 588::LR 0.0653846153846 --> Loss 0.00141499300798\n",
      "Epoch 16::Minibatch 589::LR 0.0653846153846 --> Loss 0.00277295152346\n",
      "Epoch 16::Minibatch 590::LR 0.0653846153846 --> Loss 0.00196271737417\n",
      "Epoch 16::Minibatch 591::LR 0.0653846153846 --> Loss 0.00306050340335\n",
      "Epoch 16::Minibatch 592::LR 0.0653846153846 --> Loss 0.00118390649557\n",
      "Epoch 16::Minibatch 593::LR 0.0653846153846 --> Loss 0.00261365155379\n",
      "Epoch 16::Minibatch 594::LR 0.0653846153846 --> Loss 0.00276432871819\n",
      "Epoch 16::Minibatch 595::LR 0.0653846153846 --> Loss 0.0030535719792\n",
      "Epoch 16::Minibatch 596::LR 0.0653846153846 --> Loss 0.00195098618666\n",
      "Epoch 16::Minibatch 597::LR 0.0653846153846 --> Loss 0.00119644115369\n",
      "Epoch 16::Minibatch 598::LR 0.0653846153846 --> Loss 0.00302873750528\n",
      "Epoch 16::Minibatch 599::LR 0.0653846153846 --> Loss 0.00186579167843\n",
      "Epoch 16::Minibatch 600::LR 0.0653846153846 --> Loss 0.00223039408525\n",
      "Epoch 16::Minibatch 601::LR 0.0653846153846 --> Loss 0.00390805204709\n",
      "Epoch 16::Minibatch 602::LR 0.0653846153846 --> Loss 0.00212649285793\n",
      "Epoch 16::Minibatch 603::LR 0.0653846153846 --> Loss 0.00265391866366\n",
      "Epoch 16::Minibatch 604::LR 0.0653846153846 --> Loss 0.00165691892306\n",
      "Epoch 16::Minibatch 605::LR 0.0653846153846 --> Loss 0.00238886674245\n",
      "Epoch 16::Minibatch 606::LR 0.0653846153846 --> Loss 0.00193185428778\n",
      "Epoch 16::Minibatch 607::LR 0.0653846153846 --> Loss 0.000847192207972\n",
      "Epoch 16::Minibatch 608::LR 0.0653846153846 --> Loss 0.00159168660641\n",
      "Epoch 16::Minibatch 609::LR 0.0653846153846 --> Loss 0.00239079932372\n",
      "Epoch 16::Minibatch 610::LR 0.0653846153846 --> Loss 0.00404380520185\n",
      "Epoch 16::Minibatch 611::LR 0.0653846153846 --> Loss 0.00265654901663\n",
      "Epoch 16::Minibatch 612::LR 0.0653846153846 --> Loss 0.0004907883207\n",
      "Epoch 16::Minibatch 613::LR 0.0653846153846 --> Loss 0.00131524026394\n",
      "Epoch 16::Minibatch 614::LR 0.0653846153846 --> Loss 0.00246983428796\n",
      "Epoch 16::Minibatch 615::LR 0.0653846153846 --> Loss 0.00168829023838\n",
      "Epoch 16::Minibatch 616::LR 0.0653846153846 --> Loss 0.00093005468448\n",
      "Epoch 16::Minibatch 617::LR 0.0653846153846 --> Loss 0.000507377882799\n",
      "Epoch 16::Minibatch 618::LR 0.0653846153846 --> Loss 0.00276016175747\n",
      "Epoch 16::Minibatch 619::LR 0.0653846153846 --> Loss 0.00192630767822\n",
      "Epoch 16::Minibatch 620::LR 0.0653846153846 --> Loss 0.00172767341137\n",
      "Epoch 16::Minibatch 621::LR 0.0653846153846 --> Loss 0.000860001643499\n",
      "Epoch 16::Minibatch 622::LR 0.0653846153846 --> Loss 0.000806835492452\n",
      "Epoch 16::Minibatch 623::LR 0.0653846153846 --> Loss 0.00222089032332\n",
      "Epoch 16::Minibatch 624::LR 0.0653846153846 --> Loss 0.00181209901969\n",
      "Epoch 16::Minibatch 625::LR 0.0653846153846 --> Loss 0.00298376500607\n",
      "Epoch 16::Minibatch 626::LR 0.0653846153846 --> Loss 0.00447728951772\n",
      "Epoch 16::Minibatch 627::LR 0.0653846153846 --> Loss 0.00133339991172\n",
      "Epoch 16::Minibatch 628::LR 0.0653846153846 --> Loss 0.000908663769563\n",
      "Epoch 16::Minibatch 629::LR 0.0653846153846 --> Loss 0.00341726541519\n",
      "Epoch 16::Minibatch 630::LR 0.0653846153846 --> Loss 0.00332148849964\n",
      "Epoch 16::Minibatch 631::LR 0.0653846153846 --> Loss 0.00649209658305\n",
      "Epoch 16::Minibatch 632::LR 0.0653846153846 --> Loss 0.000799339016279\n",
      "Epoch 16::Minibatch 633::LR 0.0653846153846 --> Loss 0.00166219900052\n",
      "Epoch 16::Minibatch 634::LR 0.0653846153846 --> Loss 0.00325433929761\n",
      "Epoch 16::Minibatch 635::LR 0.0653846153846 --> Loss 0.00523490111033\n",
      "Epoch 16::Minibatch 636::LR 0.0653846153846 --> Loss 0.00517288843791\n",
      "Epoch 16::Minibatch 637::LR 0.0653846153846 --> Loss 0.000800492266814\n",
      "Epoch 16::Minibatch 638::LR 0.0653846153846 --> Loss 0.00152884165446\n",
      "Epoch 16::Minibatch 639::LR 0.0653846153846 --> Loss 0.00332339187463\n",
      "Epoch 16::Minibatch 640::LR 0.0653846153846 --> Loss 0.00500450452169\n",
      "Epoch 16::Minibatch 641::LR 0.0653846153846 --> Loss 0.00314260780811\n",
      "Epoch 16::Minibatch 642::LR 0.0653846153846 --> Loss 0.000555385649204\n",
      "Epoch 16::Minibatch 643::LR 0.0653846153846 --> Loss 0.00235425511996\n",
      "Epoch 16::Minibatch 644::LR 0.0653846153846 --> Loss 0.00400011301041\n",
      "Epoch 16::Minibatch 645::LR 0.0653846153846 --> Loss 0.00421546379725\n",
      "Epoch 16::Minibatch 646::LR 0.0653846153846 --> Loss 0.00152640342712\n",
      "Epoch 16::Minibatch 647::LR 0.0653846153846 --> Loss 0.000539162009954\n",
      "Epoch 16::Minibatch 648::LR 0.0653846153846 --> Loss 0.00298743387063\n",
      "Epoch 16::Minibatch 649::LR 0.0653846153846 --> Loss 0.00355489651362\n",
      "Epoch 16::Minibatch 650::LR 0.0653846153846 --> Loss 0.00332988242308\n",
      "Epoch 16::Minibatch 651::LR 0.0653846153846 --> Loss 0.00139515727758\n",
      "Epoch 16::Minibatch 652::LR 0.0653846153846 --> Loss 0.00081925312678\n",
      "Epoch 16::Minibatch 653::LR 0.0653846153846 --> Loss 0.00287109831969\n",
      "Epoch 16::Minibatch 654::LR 0.0653846153846 --> Loss 0.00311767498652\n",
      "Epoch 16::Minibatch 655::LR 0.0653846153846 --> Loss 0.00350183526675\n",
      "Epoch 16::Minibatch 656::LR 0.0653846153846 --> Loss 0.000767208238443\n",
      "Epoch 16::Minibatch 657::LR 0.0653846153846 --> Loss 0.00223672012488\n",
      "Epoch 16::Minibatch 658::LR 0.0653846153846 --> Loss 0.00493999123573\n",
      "Epoch 16::Minibatch 659::LR 0.0653846153846 --> Loss 0.00232751766841\n",
      "Epoch 16::Minibatch 660::LR 0.0653846153846 --> Loss 0.00262520412604\n",
      "Epoch 16::Minibatch 661::LR 0.0653846153846 --> Loss 0.00251295646032\n",
      "Epoch 16::Minibatch 662::LR 0.0653846153846 --> Loss 0.00182882328828\n",
      "Epoch 16::Minibatch 663::LR 0.0653846153846 --> Loss 0.00367636164029\n",
      "Epoch 16::Minibatch 664::LR 0.0653846153846 --> Loss 0.00343246221542\n",
      "Epoch 16::Minibatch 665::LR 0.0653846153846 --> Loss 0.000743221839269\n",
      "Epoch 16::Minibatch 666::LR 0.0653846153846 --> Loss 0.00393881837527\n",
      "Epoch 16::Minibatch 667::LR 0.0653846153846 --> Loss 0.0025568151474\n",
      "Epoch 16::Minibatch 668::LR 0.0653846153846 --> Loss 0.00702744722366\n",
      "Epoch 16::Minibatch 669::LR 0.0653846153846 --> Loss 0.00109515964985\n",
      "Epoch 16::Minibatch 670::LR 0.0653846153846 --> Loss 0.00136142164469\n",
      "Epoch 16::Minibatch 671::LR 0.0653846153846 --> Loss 0.00539198001226\n",
      "Epoch 16::Minibatch 672::LR 0.0653846153846 --> Loss 0.00376012523969\n",
      "Epoch 16::Minibatch 673::LR 0.0653846153846 --> Loss 0.00162515650193\n",
      "Epoch 16::Minibatch 674::LR 0.0653846153846 --> Loss 0.000519314557314\n",
      "Epoch 16::Minibatch 675::LR 0.0653846153846 --> Loss 0.00219063500563\n",
      "Epoch 16::Minibatch 676::LR 0.0653846153846 --> Loss 0.00214110056559\n",
      "Epoch 16::Minibatch 677::LR 0.0653846153846 --> Loss 0.00281736135483\n",
      "Epoch 16::Minibatch 678::LR 0.0653846153846 --> Loss 0.00193839331468\n",
      "Epoch 16::Minibatch 679::LR 0.0653846153846 --> Loss 0.00352681477865\n",
      "Epoch 16::Minibatch 680::LR 0.0653846153846 --> Loss 0.00214820981026\n",
      "Epoch 16::Minibatch 681::LR 0.0653846153846 --> Loss 0.0024428598086\n",
      "Epoch 16::Minibatch 682::LR 0.0653846153846 --> Loss 0.000763130535682\n",
      "Epoch 16::Minibatch 683::LR 0.0653846153846 --> Loss 0.00238808910052\n",
      "Epoch 16::Minibatch 684::LR 0.0653846153846 --> Loss 0.00235991140207\n",
      "Epoch 16::Minibatch 685::LR 0.0653846153846 --> Loss 0.00292047421137\n",
      "Epoch 16::Minibatch 686::LR 0.0653846153846 --> Loss 0.00154869904121\n",
      "Epoch 16::Minibatch 687::LR 0.0653846153846 --> Loss 0.000849761664867\n",
      "Epoch 16::Minibatch 688::LR 0.0653846153846 --> Loss 0.0027615793546\n",
      "Epoch 16::Minibatch 689::LR 0.0653846153846 --> Loss 0.00253720879555\n",
      "Epoch 16::Minibatch 690::LR 0.0653846153846 --> Loss 0.00192135492961\n",
      "Epoch 16::Minibatch 691::LR 0.0653846153846 --> Loss 0.000661019980907\n",
      "Epoch 16::Minibatch 692::LR 0.0653846153846 --> Loss 0.00247651616732\n",
      "Epoch 16::Minibatch 693::LR 0.0653846153846 --> Loss 0.00257905900478\n",
      "Epoch 16::Minibatch 694::LR 0.0653846153846 --> Loss 0.00302509486675\n",
      "Epoch 16::Minibatch 695::LR 0.0653846153846 --> Loss 0.0017377058665\n",
      "Epoch 16::Minibatch 696::LR 0.0653846153846 --> Loss 0.0020455600818\n",
      "Epoch 16::Minibatch 697::LR 0.0653846153846 --> Loss 0.00141016463439\n",
      "Epoch 16::Minibatch 698::LR 0.0653846153846 --> Loss 0.00163242409627\n",
      "Epoch 16::Minibatch 699::LR 0.0653846153846 --> Loss 0.00385187307994\n",
      "Epoch 16::Minibatch 700::LR 0.0653846153846 --> Loss 0.00268609027068\n",
      "Epoch 16::Minibatch 701::LR 0.0653846153846 --> Loss 0.0019933650891\n",
      "Epoch 16::Minibatch 702::LR 0.0653846153846 --> Loss 0.00166540592909\n",
      "Epoch 16::Minibatch 703::LR 0.0653846153846 --> Loss 0.00429917693138\n",
      "Epoch 16::Minibatch 704::LR 0.0653846153846 --> Loss 0.00180379410585\n",
      "Epoch 16::Minibatch 705::LR 0.0653846153846 --> Loss 0.0028664479653\n",
      "Epoch 16::Minibatch 706::LR 0.0653846153846 --> Loss 0.0022482919693\n",
      "Epoch 16::Minibatch 707::LR 0.0653846153846 --> Loss 0.00118994812171\n",
      "Epoch 16::Minibatch 708::LR 0.0653846153846 --> Loss 0.00173697332541\n",
      "Epoch 16::Minibatch 709::LR 0.0653846153846 --> Loss 0.00169047852357\n",
      "Epoch 16::Minibatch 710::LR 0.0653846153846 --> Loss 0.00251777768135\n",
      "Epoch 16::Minibatch 711::LR 0.0653846153846 --> Loss 0.0019251737992\n",
      "Epoch 16::Minibatch 712::LR 0.0653846153846 --> Loss 0.00133129805326\n",
      "Epoch 16::Minibatch 713::LR 0.0653846153846 --> Loss 0.0017559081316\n",
      "Epoch 16::Minibatch 714::LR 0.0653846153846 --> Loss 0.0027484112978\n",
      "Epoch 16::Minibatch 715::LR 0.0653846153846 --> Loss 0.00294555485249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 716::LR 0.0653846153846 --> Loss 0.00161433130503\n",
      "Epoch 16::Minibatch 717::LR 0.0653846153846 --> Loss 0.0016151685516\n",
      "Epoch 16::Minibatch 718::LR 0.0653846153846 --> Loss 0.00125777542591\n",
      "Epoch 16::Minibatch 719::LR 0.0653846153846 --> Loss 0.00166812936465\n",
      "Epoch 16::Minibatch 720::LR 0.0653846153846 --> Loss 0.00255225698153\n",
      "Epoch 16::Minibatch 721::LR 0.0653846153846 --> Loss 0.000624431421359\n",
      "Epoch 16::Minibatch 722::LR 0.0653846153846 --> Loss 0.00480462114016\n",
      "Epoch 16::Minibatch 723::LR 0.0653846153846 --> Loss 0.00491112589836\n",
      "Epoch 16::Minibatch 724::LR 0.0653846153846 --> Loss 0.000969066123168\n",
      "Epoch 16::Minibatch 725::LR 0.0653846153846 --> Loss 0.00218081454436\n",
      "Epoch 16::Minibatch 726::LR 0.0653846153846 --> Loss 0.00462340275447\n",
      "Epoch 16::Minibatch 727::LR 0.0653846153846 --> Loss 0.00321509857972\n",
      "Epoch 16::Minibatch 728::LR 0.0653846153846 --> Loss 0.000648104200761\n",
      "Epoch 16::Minibatch 729::LR 0.0653846153846 --> Loss 0.000749844213327\n",
      "Epoch 16::Minibatch 730::LR 0.0653846153846 --> Loss 0.00277848482132\n",
      "Epoch 16::Minibatch 731::LR 0.0653846153846 --> Loss 0.00249134898186\n",
      "Epoch 16::Minibatch 732::LR 0.0653846153846 --> Loss 0.00222143332163\n",
      "Epoch 16::Minibatch 733::LR 0.0653846153846 --> Loss 0.00068694571654\n",
      "Epoch 16::Minibatch 734::LR 0.0653846153846 --> Loss 0.00173415621122\n",
      "Epoch 16::Minibatch 735::LR 0.0653846153846 --> Loss 0.00236185789108\n",
      "Epoch 16::Minibatch 736::LR 0.0653846153846 --> Loss 0.00346611579259\n",
      "Epoch 16::Minibatch 737::LR 0.0653846153846 --> Loss 0.00308249115944\n",
      "Epoch 16::Minibatch 738::LR 0.0653846153846 --> Loss 0.00159728527069\n",
      "Epoch 16::Minibatch 739::LR 0.0653846153846 --> Loss 0.00245485166709\n",
      "Epoch 16::Minibatch 740::LR 0.0653846153846 --> Loss 0.00383819023768\n",
      "Epoch 16::Minibatch 741::LR 0.0653846153846 --> Loss 0.00269245584806\n",
      "Epoch 16::Minibatch 742::LR 0.0653846153846 --> Loss 0.00211477458477\n",
      "Epoch 16::Minibatch 743::LR 0.0653846153846 --> Loss 0.00138815551996\n",
      "Epoch 16::Minibatch 744::LR 0.0653846153846 --> Loss 0.00180101950963\n",
      "Epoch 16::Minibatch 745::LR 0.0653846153846 --> Loss 0.00284460981687\n",
      "Epoch 16::Minibatch 746::LR 0.0653846153846 --> Loss 0.0029843433698\n",
      "Epoch 16::Minibatch 747::LR 0.0653846153846 --> Loss 0.00179315467676\n",
      "Epoch 16::Minibatch 748::LR 0.0653846153846 --> Loss 0.000633346388737\n",
      "Epoch 16::Minibatch 749::LR 0.0653846153846 --> Loss 0.00165371318658\n",
      "Epoch 16::Minibatch 750::LR 0.0653846153846 --> Loss 0.00246907333533\n",
      "Epoch 16::Minibatch 751::LR 0.0653846153846 --> Loss 0.00274559458097\n",
      "Epoch 16::Minibatch 752::LR 0.0653846153846 --> Loss 0.00118740727504\n",
      "Epoch 16::Minibatch 753::LR 0.0653846153846 --> Loss 0.00223134855429\n",
      "Epoch 16::Minibatch 754::LR 0.0653846153846 --> Loss 0.00239879270395\n",
      "Epoch 16::Minibatch 755::LR 0.0653846153846 --> Loss 0.00266645709674\n",
      "Epoch 16::Minibatch 756::LR 0.0653846153846 --> Loss 0.00137843499581\n",
      "Epoch 16::Minibatch 757::LR 0.0653846153846 --> Loss 0.000785610179106\n",
      "Epoch 16::Minibatch 758::LR 0.0653846153846 --> Loss 0.00161105811596\n",
      "Epoch 16::Minibatch 759::LR 0.0653846153846 --> Loss 0.00376109162966\n",
      "Epoch 16::Minibatch 760::LR 0.0653846153846 --> Loss 0.00296421031157\n",
      "Epoch 16::Minibatch 761::LR 0.0653846153846 --> Loss 0.00627946297328\n",
      "Epoch 16::Minibatch 762::LR 0.0653846153846 --> Loss 0.00376221179962\n",
      "Epoch 16::Minibatch 763::LR 0.0653846153846 --> Loss 0.00355710148811\n",
      "Epoch 16::Minibatch 764::LR 0.0653846153846 --> Loss 0.00320051570733\n",
      "Epoch 16::Minibatch 765::LR 0.0653846153846 --> Loss 0.00131551494201\n",
      "Epoch 16::Minibatch 766::LR 0.0653846153846 --> Loss 0.0022798871994\n",
      "Epoch 16::Minibatch 767::LR 0.0653846153846 --> Loss 0.00499792218208\n",
      "Epoch 16::Minibatch 768::LR 0.0653846153846 --> Loss 0.00361744880676\n",
      "Epoch 16::Minibatch 769::LR 0.0653846153846 --> Loss 0.00189528206984\n",
      "Epoch 16::Minibatch 770::LR 0.0653846153846 --> Loss 0.00145846784115\n",
      "Epoch 16::Minibatch 771::LR 0.0653846153846 --> Loss 0.00369785110156\n",
      "Epoch 16::Minibatch 772::LR 0.0653846153846 --> Loss 0.00340617537498\n",
      "Epoch 16::Minibatch 773::LR 0.0653846153846 --> Loss 0.00313406566779\n",
      "Epoch 16::Minibatch 774::LR 0.0653846153846 --> Loss 0.00177996536096\n",
      "Epoch 16::Minibatch 775::LR 0.0653846153846 --> Loss 0.00383326450984\n",
      "Epoch 16::Minibatch 776::LR 0.0653846153846 --> Loss 0.00357175946236\n",
      "Epoch 16::Minibatch 777::LR 0.0653846153846 --> Loss 0.00745784918467\n",
      "Epoch 16::Minibatch 778::LR 0.0653846153846 --> Loss 0.00949313322703\n",
      "Epoch 16::Minibatch 779::LR 0.0653846153846 --> Loss 0.00229413767656\n",
      "Epoch 16::Minibatch 780::LR 0.0653846153846 --> Loss 0.00161137421926\n",
      "Epoch 16::Minibatch 781::LR 0.0653846153846 --> Loss 0.00347058931986\n",
      "Epoch 16::Minibatch 782::LR 0.0653846153846 --> Loss 0.00399298826853\n",
      "Epoch 16::Minibatch 783::LR 0.0653846153846 --> Loss 0.00230714857578\n",
      "Epoch 16::Minibatch 784::LR 0.0653846153846 --> Loss 0.000717412183682\n",
      "Epoch 16::Minibatch 785::LR 0.0653846153846 --> Loss 0.00348083257675\n",
      "Epoch 16::Minibatch 786::LR 0.0653846153846 --> Loss 0.00347746928533\n",
      "Epoch 16::Minibatch 787::LR 0.0653846153846 --> Loss 0.00271464705467\n",
      "Epoch 16::Minibatch 788::LR 0.0653846153846 --> Loss 0.00240779240926\n",
      "Epoch 16::Minibatch 789::LR 0.0653846153846 --> Loss 0.000741757452488\n",
      "Epoch 16::Minibatch 790::LR 0.0653846153846 --> Loss 0.00318196952343\n",
      "Epoch 16::Minibatch 791::LR 0.0653846153846 --> Loss 0.00358260472616\n",
      "Epoch 16::Minibatch 792::LR 0.0653846153846 --> Loss 0.00317694981893\n",
      "Epoch 16::Minibatch 793::LR 0.0653846153846 --> Loss 0.00179264207681\n",
      "Epoch 16::Minibatch 794::LR 0.0653846153846 --> Loss 0.00103110839923\n",
      "Epoch 16::Minibatch 795::LR 0.0653846153846 --> Loss 0.00302606562773\n",
      "Epoch 16::Minibatch 796::LR 0.0653846153846 --> Loss 0.0056199880441\n",
      "Epoch 16::Minibatch 797::LR 0.0653846153846 --> Loss 0.00729005654653\n",
      "Epoch 16::Minibatch 798::LR 0.0653846153846 --> Loss 0.00330899079641\n",
      "Epoch 16::Minibatch 799::LR 0.0653846153846 --> Loss 0.00236701389154\n",
      "Epoch 16::Minibatch 800::LR 0.0653846153846 --> Loss 0.00202617565791\n",
      "Epoch 16::Minibatch 801::LR 0.0653846153846 --> Loss 0.00415026982625\n",
      "Epoch 16::Minibatch 802::LR 0.0653846153846 --> Loss 0.00131077418725\n",
      "Epoch 16::Minibatch 803::LR 0.0653846153846 --> Loss 0.00285382648309\n",
      "Epoch 16::Minibatch 804::LR 0.0653846153846 --> Loss 0.00217513481776\n",
      "Epoch 16::Minibatch 805::LR 0.0653846153846 --> Loss 0.00227284034093\n",
      "Epoch 16::Minibatch 806::LR 0.0653846153846 --> Loss 0.00333473126094\n",
      "Epoch 16::Minibatch 807::LR 0.0653846153846 --> Loss 0.00303077697754\n",
      "Epoch 16::Minibatch 808::LR 0.0653846153846 --> Loss 0.00268621385098\n",
      "Epoch 16::Minibatch 809::LR 0.0653846153846 --> Loss 0.00373670061429\n",
      "Epoch 16::Minibatch 810::LR 0.0653846153846 --> Loss 0.00502012093862\n",
      "Epoch 16::Minibatch 811::LR 0.0653846153846 --> Loss 0.0047433245182\n",
      "Epoch 16::Minibatch 812::LR 0.0653846153846 --> Loss 0.00433428406715\n",
      "Epoch 16::Minibatch 813::LR 0.0653846153846 --> Loss 0.00375206073125\n",
      "Epoch 16::Minibatch 814::LR 0.0653846153846 --> Loss 0.00175832609336\n",
      "Epoch 16::Minibatch 815::LR 0.0653846153846 --> Loss 0.0037907965978\n",
      "Epoch 16::Minibatch 816::LR 0.0653846153846 --> Loss 0.00414702653885\n",
      "Epoch 16::Minibatch 817::LR 0.0653846153846 --> Loss 0.00551665425301\n",
      "Epoch 16::Minibatch 818::LR 0.0653846153846 --> Loss 0.0012608580788\n",
      "Epoch 16::Minibatch 819::LR 0.0653846153846 --> Loss 0.000695769886176\n",
      "Epoch 16::Minibatch 820::LR 0.0653846153846 --> Loss 0.00532961686452\n",
      "Epoch 16::Minibatch 821::LR 0.0653846153846 --> Loss 0.00314880470435\n",
      "Epoch 16::Minibatch 822::LR 0.0653846153846 --> Loss 0.00372019966443\n",
      "Epoch 16::Minibatch 823::LR 0.0653846153846 --> Loss 0.00130133628845\n",
      "Epoch 16::Minibatch 824::LR 0.0653846153846 --> Loss 0.00138665338357\n",
      "Epoch 16::Minibatch 825::LR 0.0653846153846 --> Loss 0.00368216236432\n",
      "Epoch 16::Minibatch 826::LR 0.0653846153846 --> Loss 0.00392926136653\n",
      "Epoch 16::Minibatch 827::LR 0.0653846153846 --> Loss 0.00209546168645\n",
      "Epoch 16::Minibatch 828::LR 0.0653846153846 --> Loss 0.000539645602306\n",
      "Epoch 16::Minibatch 829::LR 0.0653846153846 --> Loss 0.00237220088641\n",
      "Epoch 16::Minibatch 830::LR 0.0653846153846 --> Loss 0.0043596124649\n",
      "Epoch 16::Minibatch 831::LR 0.0653846153846 --> Loss 0.00255344986916\n",
      "Epoch 16::Minibatch 832::LR 0.0653846153846 --> Loss 0.00223701298237\n",
      "Epoch 16::Minibatch 833::LR 0.0653846153846 --> Loss 0.00184582829475\n",
      "Epoch 16::Minibatch 834::LR 0.0653846153846 --> Loss 0.000775565604369\n",
      "Epoch 16::Minibatch 835::LR 0.0653846153846 --> Loss 0.00380097309748\n",
      "Epoch 16::Minibatch 836::LR 0.0653846153846 --> Loss 0.0037030172348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 837::LR 0.0653846153846 --> Loss 0.00219070116679\n",
      "Epoch 16::Minibatch 838::LR 0.0653846153846 --> Loss 0.000630182027817\n",
      "Epoch 16::Minibatch 839::LR 0.0653846153846 --> Loss 0.00246433655421\n",
      "Epoch 16::Minibatch 840::LR 0.0653846153846 --> Loss 0.00289870083332\n",
      "Epoch 16::Minibatch 841::LR 0.0653846153846 --> Loss 0.0028348249197\n",
      "Epoch 16::Minibatch 842::LR 0.0653846153846 --> Loss 0.00208295206229\n",
      "Epoch 16::Minibatch 843::LR 0.0653846153846 --> Loss 0.00100734323263\n",
      "Epoch 16::Minibatch 844::LR 0.0653846153846 --> Loss 0.00149513304234\n",
      "Epoch 16::Minibatch 845::LR 0.0653846153846 --> Loss 0.0043221950531\n",
      "Epoch 16::Minibatch 846::LR 0.0653846153846 --> Loss 0.00167761941751\n",
      "Epoch 16::Minibatch 847::LR 0.0653846153846 --> Loss 0.0022797669967\n",
      "Epoch 16::Minibatch 848::LR 0.0653846153846 --> Loss 0.00100758781036\n",
      "Epoch 16::Minibatch 849::LR 0.0653846153846 --> Loss 0.00183755298456\n",
      "Epoch 16::Minibatch 850::LR 0.0653846153846 --> Loss 0.0031780531009\n",
      "Epoch 16::Minibatch 851::LR 0.0653846153846 --> Loss 0.00266387144725\n",
      "Epoch 16::Minibatch 852::LR 0.0653846153846 --> Loss 0.00107394178708\n",
      "Epoch 16::Minibatch 853::LR 0.0653846153846 --> Loss 0.00130660583576\n",
      "Epoch 16::Minibatch 854::LR 0.0653846153846 --> Loss 0.00257158339024\n",
      "Epoch 16::Minibatch 855::LR 0.0653846153846 --> Loss 0.00216607451439\n",
      "Epoch 16::Minibatch 856::LR 0.0653846153846 --> Loss 0.00179132501284\n",
      "Epoch 16::Minibatch 857::LR 0.0653846153846 --> Loss 0.00121382613977\n",
      "Epoch 16::Minibatch 858::LR 0.0653846153846 --> Loss 0.000595516761144\n",
      "Epoch 16::Minibatch 859::LR 0.0653846153846 --> Loss 0.00190948148568\n",
      "Epoch 16::Minibatch 860::LR 0.0653846153846 --> Loss 0.00124551524719\n",
      "Epoch 16::Minibatch 861::LR 0.0653846153846 --> Loss 0.0009355550011\n",
      "Epoch 16::Minibatch 862::LR 0.0653846153846 --> Loss 0.00363870183627\n",
      "Epoch 16::Minibatch 863::LR 0.0653846153846 --> Loss 0.00341360886892\n",
      "Epoch 16::Minibatch 864::LR 0.0653846153846 --> Loss 0.00286930263042\n",
      "Epoch 16::Minibatch 865::LR 0.0653846153846 --> Loss 0.000427731027206\n",
      "Epoch 16::Minibatch 866::LR 0.0653846153846 --> Loss 0.0021414488554\n",
      "Epoch 16::Minibatch 867::LR 0.0653846153846 --> Loss 0.00296373565992\n",
      "Epoch 16::Minibatch 868::LR 0.0653846153846 --> Loss 0.00244093120098\n",
      "Epoch 16::Minibatch 869::LR 0.0653846153846 --> Loss 0.00210416535536\n",
      "Epoch 16::Minibatch 870::LR 0.0653846153846 --> Loss 0.00353190700213\n",
      "Epoch 16::Minibatch 871::LR 0.0653846153846 --> Loss 0.00152200231949\n",
      "Epoch 16::Minibatch 872::LR 0.0653846153846 --> Loss 0.00226366122564\n",
      "Epoch 16::Minibatch 873::LR 0.0653846153846 --> Loss 0.00246893386046\n",
      "Epoch 16::Minibatch 874::LR 0.0653846153846 --> Loss 0.00615095059077\n",
      "Epoch 16::Minibatch 875::LR 0.0653846153846 --> Loss 0.000516943335533\n",
      "Epoch 16::Minibatch 876::LR 0.0653846153846 --> Loss 0.00320568541686\n",
      "Epoch 16::Minibatch 877::LR 0.0653846153846 --> Loss 0.00635813395182\n",
      "Epoch 16::Minibatch 878::LR 0.0653846153846 --> Loss 0.00322409808636\n",
      "Epoch 16::Minibatch 879::LR 0.0653846153846 --> Loss 0.00402398546537\n",
      "Epoch 16::Minibatch 880::LR 0.0653846153846 --> Loss 0.00483843485514\n",
      "Epoch 16::Minibatch 881::LR 0.0653846153846 --> Loss 0.00429069161415\n",
      "Epoch 16::Minibatch 882::LR 0.0653846153846 --> Loss 0.00197286685308\n",
      "Epoch 16::Minibatch 883::LR 0.0653846153846 --> Loss 0.00341685334841\n",
      "Epoch 16::Minibatch 884::LR 0.0653846153846 --> Loss 0.00270573159059\n",
      "Epoch 16::Minibatch 885::LR 0.0653846153846 --> Loss 0.00254086236159\n",
      "Epoch 16::Minibatch 886::LR 0.0653846153846 --> Loss 0.0005386069417\n",
      "Epoch 16::Minibatch 887::LR 0.0653846153846 --> Loss 0.00531543334325\n",
      "Epoch 16::Minibatch 888::LR 0.0653846153846 --> Loss 0.00262021541595\n",
      "Epoch 16::Minibatch 889::LR 0.0653846153846 --> Loss 0.00289404372374\n",
      "Epoch 16::Minibatch 890::LR 0.0653846153846 --> Loss 0.00428648511569\n",
      "Epoch 16::Minibatch 891::LR 0.0653846153846 --> Loss 0.00189616203308\n",
      "Epoch 16::Minibatch 892::LR 0.0653846153846 --> Loss 0.000867483417193\n",
      "Epoch 16::Minibatch 893::LR 0.0653846153846 --> Loss 0.00245016356309\n",
      "Epoch 16::Minibatch 894::LR 0.0653846153846 --> Loss 0.00216944038868\n",
      "Epoch 16::Minibatch 895::LR 0.0653846153846 --> Loss 0.00241661608219\n",
      "Epoch 16::Minibatch 896::LR 0.0653846153846 --> Loss 0.00129480491082\n",
      "Epoch 16::Minibatch 897::LR 0.0653846153846 --> Loss 0.000718749513229\n",
      "Epoch 16::Minibatch 898::LR 0.0653846153846 --> Loss 0.0021556832393\n",
      "Epoch 16::Minibatch 899::LR 0.0653846153846 --> Loss 0.00247502187888\n",
      "Epoch 16::Minibatch 900::LR 0.0653846153846 --> Loss 0.00324478904406\n",
      "Epoch 16::Minibatch 901::LR 0.0653846153846 --> Loss 0.000596610705058\n",
      "Epoch 16::Minibatch 902::LR 0.0653846153846 --> Loss 0.00141687264045\n",
      "Epoch 16::Minibatch 903::LR 0.0653846153846 --> Loss 0.00259685893854\n",
      "Epoch 16::Minibatch 904::LR 0.0653846153846 --> Loss 0.00196849147479\n",
      "Epoch 16::Minibatch 905::LR 0.0653846153846 --> Loss 0.00143487373988\n",
      "Epoch 16::Minibatch 906::LR 0.0653846153846 --> Loss 0.00108078618844\n",
      "Epoch 16::Minibatch 907::LR 0.0653846153846 --> Loss 0.00158853312333\n",
      "Epoch 16::Minibatch 908::LR 0.0653846153846 --> Loss 0.00222445944945\n",
      "Epoch 16::Minibatch 909::LR 0.0653846153846 --> Loss 0.00203784247239\n",
      "Epoch 16::Minibatch 910::LR 0.0653846153846 --> Loss 0.000832391679287\n",
      "Epoch 16::Minibatch 911::LR 0.0653846153846 --> Loss 0.00123314311107\n",
      "Epoch 16::Minibatch 912::LR 0.0653846153846 --> Loss 0.00201186259588\n",
      "Epoch 16::Minibatch 913::LR 0.0653846153846 --> Loss 0.00217648009459\n",
      "Epoch 16::Minibatch 914::LR 0.0653846153846 --> Loss 0.00119391938051\n",
      "Epoch 16::Minibatch 915::LR 0.0653846153846 --> Loss 0.000491937597593\n",
      "Epoch 16::Minibatch 916::LR 0.0653846153846 --> Loss 0.00232517520587\n",
      "Epoch 16::Minibatch 917::LR 0.0653846153846 --> Loss 0.00380345582962\n",
      "Epoch 16::Minibatch 918::LR 0.0653846153846 --> Loss 0.00558006286621\n",
      "Epoch 16::Minibatch 919::LR 0.0653846153846 --> Loss 0.000598842302958\n",
      "Epoch 16::Minibatch 920::LR 0.0653846153846 --> Loss 0.0115990447998\n",
      "Epoch 16::Minibatch 921::LR 0.0653846153846 --> Loss 0.00282672365506\n",
      "Epoch 16::Minibatch 922::LR 0.0653846153846 --> Loss 0.00299075384935\n",
      "Epoch 16::Minibatch 923::LR 0.0653846153846 --> Loss 0.00149317254623\n",
      "Epoch 16::Minibatch 924::LR 0.0653846153846 --> Loss 0.00347579638163\n",
      "Epoch 16::Minibatch 925::LR 0.0653846153846 --> Loss 0.00241235395273\n",
      "Epoch 16::Minibatch 926::LR 0.0653846153846 --> Loss 0.00529110272725\n",
      "Epoch 16::Minibatch 927::LR 0.0653846153846 --> Loss 0.00767859299978\n",
      "Epoch 16::Minibatch 928::LR 0.0653846153846 --> Loss 0.00644512454669\n",
      "Epoch 16::Minibatch 929::LR 0.0653846153846 --> Loss 0.00682457447052\n",
      "Epoch 16::Minibatch 930::LR 0.0653846153846 --> Loss 0.0100704399745\n",
      "Epoch 16::Minibatch 931::LR 0.0653846153846 --> Loss 0.00355779131254\n",
      "Epoch 16::Minibatch 932::LR 0.0653846153846 --> Loss 0.00719832976659\n",
      "Epoch 16::Minibatch 933::LR 0.0653846153846 --> Loss 0.00360188206037\n",
      "Epoch 16::Minibatch 934::LR 0.0653846153846 --> Loss 0.0047345495224\n",
      "Epoch 16::Minibatch 935::LR 0.0653846153846 --> Loss 0.00659728566806\n",
      "Epoch 16::Minibatch 936::LR 0.0653846153846 --> Loss 0.00160153836012\n",
      "Epoch 16::Minibatch 937::LR 0.0653846153846 --> Loss 0.00345224539439\n",
      "Epoch 16::Minibatch 938::LR 0.0653846153846 --> Loss 0.00316650370757\n",
      "Epoch 16::Minibatch 939::LR 0.0653846153846 --> Loss 0.00322963555654\n",
      "Epoch 16::Minibatch 940::LR 0.0653846153846 --> Loss 0.00104385952155\n",
      "Epoch 16::Minibatch 941::LR 0.0653846153846 --> Loss 0.000851788818836\n",
      "Epoch 16::Minibatch 942::LR 0.0653846153846 --> Loss 0.00245639602343\n",
      "Epoch 16::Minibatch 943::LR 0.0653846153846 --> Loss 0.0029848865668\n",
      "Epoch 16::Minibatch 944::LR 0.0653846153846 --> Loss 0.00216999212901\n",
      "Epoch 16::Minibatch 945::LR 0.0653846153846 --> Loss 0.00127516557773\n",
      "Epoch 16::Minibatch 946::LR 0.0653846153846 --> Loss 0.00321842869123\n",
      "Epoch 16::Minibatch 947::LR 0.0653846153846 --> Loss 0.00287853896618\n",
      "Epoch 16::Minibatch 948::LR 0.0653846153846 --> Loss 0.00529802083969\n",
      "Epoch 16::Minibatch 949::LR 0.0653846153846 --> Loss 0.00190440515677\n",
      "Epoch 16::Minibatch 950::LR 0.0653846153846 --> Loss 0.000738607694705\n",
      "Epoch 16::Minibatch 951::LR 0.0653846153846 --> Loss 0.00339775443077\n",
      "Epoch 16::Minibatch 952::LR 0.0653846153846 --> Loss 0.00245432893435\n",
      "Epoch 16::Minibatch 953::LR 0.0653846153846 --> Loss 0.00138676206271\n",
      "Epoch 16::Minibatch 954::LR 0.0653846153846 --> Loss 0.000963328977426\n",
      "Epoch 16::Minibatch 955::LR 0.0653846153846 --> Loss 0.00253679811954\n",
      "Epoch 16::Minibatch 956::LR 0.0653846153846 --> Loss 0.00389492988586\n",
      "Epoch 16::Minibatch 957::LR 0.0653846153846 --> Loss 0.0019133212169\n",
      "Epoch 16::Minibatch 958::LR 0.0653846153846 --> Loss 0.00238254547119\n",
      "Epoch 16::Minibatch 959::LR 0.0653846153846 --> Loss 0.00295101583004\n",
      "Epoch 16::Minibatch 960::LR 0.0653846153846 --> Loss 0.00647324045499\n",
      "Epoch 16::Minibatch 961::LR 0.0653846153846 --> Loss 0.00338897744815\n",
      "Epoch 16::Minibatch 962::LR 0.0653846153846 --> Loss 0.00291442096233\n",
      "Epoch 16::Minibatch 963::LR 0.0653846153846 --> Loss 0.00104229956865\n",
      "Epoch 16::Minibatch 964::LR 0.0653846153846 --> Loss 0.00244689087073\n",
      "Epoch 16::Minibatch 965::LR 0.0653846153846 --> Loss 0.00734693288803\n",
      "Epoch 16::Minibatch 966::LR 0.0653846153846 --> Loss 0.00507439017296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16::Minibatch 967::LR 0.0653846153846 --> Loss 0.00161568204562\n",
      "Epoch 16::Minibatch 968::LR 0.0653846153846 --> Loss 0.00143914749225\n",
      "Epoch 16::Minibatch 969::LR 0.0653846153846 --> Loss 0.00650978247325\n",
      "Epoch 16::Minibatch 970::LR 0.0653846153846 --> Loss 0.00573469082514\n",
      "Epoch 16::Minibatch 971::LR 0.0653846153846 --> Loss 0.00347830255826\n",
      "Epoch 16::Minibatch 972::LR 0.0653846153846 --> Loss 0.0101864647865\n",
      "Epoch 16::Minibatch 973::LR 0.0653846153846 --> Loss 0.0089231244723\n",
      "Epoch 16::Minibatch 974::LR 0.0653846153846 --> Loss 0.00687039772669\n",
      "Epoch 16::Minibatch 975::LR 0.0653846153846 --> Loss 0.00463892817497\n",
      "Epoch 16::Minibatch 976::LR 0.0653846153846 --> Loss 0.00415144880613\n",
      "Epoch 16::Minibatch 977::LR 0.0653846153846 --> Loss 0.00415218909582\n",
      "Epoch 16::Minibatch 978::LR 0.0653846153846 --> Loss 0.00408934315046\n",
      "Epoch 16::Minibatch 979::LR 0.0653846153846 --> Loss 0.00403583725293\n",
      "Epoch 16::Minibatch 980::LR 0.0653846153846 --> Loss 0.00401591539383\n",
      "Epoch 16::Minibatch 981::LR 0.0653846153846 --> Loss 0.00522355238597\n",
      "Epoch 16::Minibatch 982::LR 0.0653846153846 --> Loss 0.00661563634872\n",
      "Epoch 16::Minibatch 983::LR 0.0653846153846 --> Loss 0.00300280908744\n",
      "Epoch 16::Minibatch 984::LR 0.0653846153846 --> Loss 0.00258736232917\n",
      "Epoch 16::Minibatch 985::LR 0.0653846153846 --> Loss 0.00435395598412\n",
      "Epoch 16::Minibatch 986::LR 0.0653846153846 --> Loss 0.00396532773972\n",
      "Epoch 16::Minibatch 987::LR 0.0653846153846 --> Loss 0.00425955096881\n",
      "Epoch 16::Minibatch 988::LR 0.0653846153846 --> Loss 0.00328457891941\n",
      "Epoch 16::Minibatch 989::LR 0.0653846153846 --> Loss 0.00338437159856\n",
      "Epoch 16::Minibatch 990::LR 0.0653846153846 --> Loss 0.00311370015144\n",
      "Epoch 16::Minibatch 991::LR 0.0653846153846 --> Loss 0.0016323552529\n",
      "Epoch 16::Minibatch 992::LR 0.0653846153846 --> Loss 0.00185016949972\n",
      "Epoch 16::Minibatch 993::LR 0.0653846153846 --> Loss 0.00331830441952\n",
      "Epoch 16::Minibatch 994::LR 0.0653846153846 --> Loss 0.00201199352741\n",
      "Epoch 16::Minibatch 995::LR 0.0653846153846 --> Loss 0.000834415058295\n",
      "Epoch 16::Minibatch 996::LR 0.0653846153846 --> Loss 0.00302754124006\n",
      "Epoch 16::Minibatch 997::LR 0.0653846153846 --> Loss 0.0020873606205\n",
      "Epoch 16::Minibatch 998::LR 0.0653846153846 --> Loss 0.00229747116566\n",
      "Epoch 16::Minibatch 999::LR 0.0653846153846 --> Loss 0.00188305000464\n",
      "Epoch 16::Minibatch 1000::LR 0.0653846153846 --> Loss 0.00224905172984\n",
      "Epoch 16::Minibatch 1001::LR 0.0653846153846 --> Loss 0.0017905096213\n",
      "Epoch 16::Minibatch 1002::LR 0.0653846153846 --> Loss 0.0023004925251\n",
      "Epoch 16::Minibatch 1003::LR 0.0653846153846 --> Loss 0.00338080128034\n",
      "Epoch 16::Minibatch 1004::LR 0.0653846153846 --> Loss 0.000992903908094\n",
      "Epoch 16::Minibatch 1005::LR 0.0653846153846 --> Loss 0.00358912030856\n",
      "Epoch 16::Minibatch 1006::LR 0.0653846153846 --> Loss 0.00212847073873\n",
      "Epoch 16::Minibatch 1007::LR 0.0653846153846 --> Loss 0.00260097940763\n",
      "Epoch 16::Minibatch 1008::LR 0.0653846153846 --> Loss 0.000915181835492\n",
      "Epoch 16::Minibatch 1009::LR 0.0653846153846 --> Loss 0.00159520228704\n",
      "Epoch 16::Minibatch 1010::LR 0.0653846153846 --> Loss 0.00146692802509\n",
      "Epoch 16::Minibatch 1011::LR 0.0653846153846 --> Loss 0.00301434954007\n",
      "Epoch 16::Minibatch 1012::LR 0.0653846153846 --> Loss 0.00167388240496\n",
      "Epoch 16::Minibatch 1013::LR 0.0653846153846 --> Loss 0.00429475903511\n",
      "Epoch 16::Minibatch 1014::LR 0.0653846153846 --> Loss 0.00400676965714\n",
      "Epoch 16::Minibatch 1015::LR 0.0653846153846 --> Loss 0.00163252482812\n",
      "Epoch 16::Minibatch 1016::LR 0.0653846153846 --> Loss 0.00494527339935\n",
      "Epoch 16::Minibatch 1017::LR 0.0653846153846 --> Loss 0.00366627732913\n",
      "Epoch 16::Minibatch 1018::LR 0.0653846153846 --> Loss 0.00299241046111\n",
      "Epoch 16::Minibatch 1019::LR 0.0653846153846 --> Loss 0.00210157295068\n",
      "Epoch 16::Minibatch 1020::LR 0.0653846153846 --> Loss 0.00212674101194\n",
      "Epoch 16::Minibatch 1021::LR 0.0653846153846 --> Loss 0.00215550621351\n",
      "Epoch 16::Minibatch 1022::LR 0.0653846153846 --> Loss 0.00166394253572\n",
      "Epoch 16::Minibatch 1023::LR 0.0653846153846 --> Loss 0.00128648201625\n",
      "Epoch 16::Minibatch 1024::LR 0.0653846153846 --> Loss 0.00123414138953\n",
      "Epoch 16::Minibatch 1025::LR 0.0653846153846 --> Loss 0.0014642722408\n",
      "Epoch 16::Minibatch 1026::LR 0.0653846153846 --> Loss 0.000848810970783\n",
      "Epoch 16::Minibatch 1027::LR 0.0653846153846 --> Loss 0.00105855951707\n",
      "Epoch 16::Minibatch 1028::LR 0.0653846153846 --> Loss 0.000811641116937\n",
      "Epoch 16::Minibatch 1029::LR 0.0653846153846 --> Loss 0.000790841976802\n",
      "Epoch 16::Minibatch 1030::LR 0.0653846153846 --> Loss 0.000979061524073\n",
      "Epoch 16::Minibatch 1031::LR 0.0653846153846 --> Loss 0.000775732845068\n",
      "Epoch 16::Minibatch 1032::LR 0.0653846153846 --> Loss 0.000802146444718\n",
      "Epoch 16::Minibatch 1033::LR 0.0653846153846 --> Loss 0.000674065152804\n",
      "Epoch 16::Minibatch 1034::LR 0.0653846153846 --> Loss 0.000662988970677\n",
      "Epoch 16::Minibatch 1035::LR 0.0653846153846 --> Loss 0.00046456048886\n",
      "Epoch 16::Minibatch 1036::LR 0.0653846153846 --> Loss 0.00037399413685\n",
      "Epoch 16::Minibatch 1037::LR 0.0653846153846 --> Loss 0.000589437633753\n",
      "Epoch 16::Minibatch 1038::LR 0.0653846153846 --> Loss 0.00129837493102\n",
      "Epoch 16::Minibatch 1039::LR 0.0653846153846 --> Loss 0.00102850119273\n",
      "Epoch 16::Minibatch 1040::LR 0.0653846153846 --> Loss 0.000425643275181\n",
      "Epoch 16::Minibatch 1041::LR 0.0653846153846 --> Loss 0.000593816637993\n",
      "Epoch 17::Minibatch 1::LR 0.0630769230769 --> Loss 0.00948667764664\n",
      "Epoch 17::Minibatch 2::LR 0.0630769230769 --> Loss 0.00571505864461\n",
      "Epoch 17::Minibatch 3::LR 0.0630769230769 --> Loss 0.00380240917206\n",
      "Epoch 17::Minibatch 4::LR 0.0630769230769 --> Loss 0.00424040873845\n",
      "Epoch 17::Minibatch 5::LR 0.0630769230769 --> Loss 0.00469675103823\n",
      "Epoch 17::Minibatch 6::LR 0.0630769230769 --> Loss 0.00237725059191\n",
      "Epoch 17::Minibatch 7::LR 0.0630769230769 --> Loss 0.00758084932963\n",
      "Epoch 17::Minibatch 8::LR 0.0630769230769 --> Loss 0.00729850610097\n",
      "Epoch 17::Minibatch 9::LR 0.0630769230769 --> Loss 0.00529566208522\n",
      "Epoch 17::Minibatch 10::LR 0.0630769230769 --> Loss 0.00274174133937\n",
      "Epoch 17::Minibatch 11::LR 0.0630769230769 --> Loss 0.00235752900441\n",
      "Epoch 17::Minibatch 12::LR 0.0630769230769 --> Loss 0.00344878196716\n",
      "Epoch 17::Minibatch 13::LR 0.0630769230769 --> Loss 0.00518427729607\n",
      "Epoch 17::Minibatch 14::LR 0.0630769230769 --> Loss 0.00517867287\n",
      "Epoch 17::Minibatch 15::LR 0.0630769230769 --> Loss 0.00429887851079\n",
      "Epoch 17::Minibatch 16::LR 0.0630769230769 --> Loss 0.000853214859962\n",
      "Epoch 17::Minibatch 17::LR 0.0630769230769 --> Loss 0.00301001052062\n",
      "Epoch 17::Minibatch 18::LR 0.0630769230769 --> Loss 0.00252069075902\n",
      "Epoch 17::Minibatch 19::LR 0.0630769230769 --> Loss 0.00128465175629\n",
      "Epoch 17::Minibatch 20::LR 0.0630769230769 --> Loss 0.00174713989099\n",
      "Epoch 17::Minibatch 21::LR 0.0630769230769 --> Loss 0.0032870666186\n",
      "Epoch 17::Minibatch 22::LR 0.0630769230769 --> Loss 0.00229350030422\n",
      "Epoch 17::Minibatch 23::LR 0.0630769230769 --> Loss 0.000773121615251\n",
      "Epoch 17::Minibatch 24::LR 0.0630769230769 --> Loss 0.000369728431106\n",
      "Epoch 17::Minibatch 25::LR 0.0630769230769 --> Loss 0.00110417614381\n",
      "Epoch 17::Minibatch 26::LR 0.0630769230769 --> Loss 0.00131442407767\n",
      "Epoch 17::Minibatch 27::LR 0.0630769230769 --> Loss 0.00090973953406\n",
      "Epoch 17::Minibatch 28::LR 0.0630769230769 --> Loss 0.000381356875102\n",
      "Epoch 17::Minibatch 29::LR 0.0630769230769 --> Loss 0.000372486462196\n",
      "Epoch 17::Minibatch 30::LR 0.0630769230769 --> Loss 0.000848958889643\n",
      "Epoch 17::Minibatch 31::LR 0.0630769230769 --> Loss 0.00133318046729\n",
      "Epoch 17::Minibatch 32::LR 0.0630769230769 --> Loss 0.00125701238712\n",
      "Epoch 17::Minibatch 33::LR 0.0630769230769 --> Loss 0.00077592809995\n",
      "Epoch 17::Minibatch 34::LR 0.0630769230769 --> Loss 0.00228552599748\n",
      "Epoch 17::Minibatch 35::LR 0.0630769230769 --> Loss 0.00405946969986\n",
      "Epoch 17::Minibatch 36::LR 0.0630769230769 --> Loss 0.00225608547529\n",
      "Epoch 17::Minibatch 37::LR 0.0630769230769 --> Loss 0.000636640886466\n",
      "Epoch 17::Minibatch 38::LR 0.0630769230769 --> Loss 0.000748407791058\n",
      "Epoch 17::Minibatch 39::LR 0.0630769230769 --> Loss 0.00238974710306\n",
      "Epoch 17::Minibatch 40::LR 0.0630769230769 --> Loss 0.00353721539179\n",
      "Epoch 17::Minibatch 41::LR 0.0630769230769 --> Loss 0.00286836624146\n",
      "Epoch 17::Minibatch 42::LR 0.0630769230769 --> Loss 0.00598401427269\n",
      "Epoch 17::Minibatch 43::LR 0.0630769230769 --> Loss 0.00186344345411\n",
      "Epoch 17::Minibatch 44::LR 0.0630769230769 --> Loss 0.00312089165052\n",
      "Epoch 17::Minibatch 45::LR 0.0630769230769 --> Loss 0.00249014099439\n",
      "Epoch 17::Minibatch 46::LR 0.0630769230769 --> Loss 0.003437008063\n",
      "Epoch 17::Minibatch 47::LR 0.0630769230769 --> Loss 0.00444399674733\n",
      "Epoch 17::Minibatch 48::LR 0.0630769230769 --> Loss 0.00591406901677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 49::LR 0.0630769230769 --> Loss 0.00618614991506\n",
      "Epoch 17::Minibatch 50::LR 0.0630769230769 --> Loss 0.00608929514885\n",
      "Epoch 17::Minibatch 51::LR 0.0630769230769 --> Loss 0.0070754981041\n",
      "Epoch 17::Minibatch 52::LR 0.0630769230769 --> Loss 0.00347223877907\n",
      "Epoch 17::Minibatch 53::LR 0.0630769230769 --> Loss 0.00344839294751\n",
      "Epoch 17::Minibatch 54::LR 0.0630769230769 --> Loss 0.00403260946274\n",
      "Epoch 17::Minibatch 55::LR 0.0630769230769 --> Loss 0.000987984836102\n",
      "Epoch 17::Minibatch 56::LR 0.0630769230769 --> Loss 0.00270542184512\n",
      "Epoch 17::Minibatch 57::LR 0.0630769230769 --> Loss 0.00563139557838\n",
      "Epoch 17::Minibatch 58::LR 0.0630769230769 --> Loss 0.00335360805194\n",
      "Epoch 17::Minibatch 59::LR 0.0630769230769 --> Loss 0.00250207702319\n",
      "Epoch 17::Minibatch 60::LR 0.0630769230769 --> Loss 0.0023829249541\n",
      "Epoch 17::Minibatch 61::LR 0.0630769230769 --> Loss 0.000876805583636\n",
      "Epoch 17::Minibatch 62::LR 0.0630769230769 --> Loss 0.00317248046398\n",
      "Epoch 17::Minibatch 63::LR 0.0630769230769 --> Loss 0.00212630669276\n",
      "Epoch 17::Minibatch 64::LR 0.0630769230769 --> Loss 0.000911140839259\n",
      "Epoch 17::Minibatch 65::LR 0.0630769230769 --> Loss 0.00236213028431\n",
      "Epoch 17::Minibatch 66::LR 0.0630769230769 --> Loss 0.00284741183122\n",
      "Epoch 17::Minibatch 67::LR 0.0630769230769 --> Loss 0.00277795831362\n",
      "Epoch 17::Minibatch 68::LR 0.0630769230769 --> Loss 0.00198917746544\n",
      "Epoch 17::Minibatch 69::LR 0.0630769230769 --> Loss 0.00399414976438\n",
      "Epoch 17::Minibatch 70::LR 0.0630769230769 --> Loss 0.00343613783518\n",
      "Epoch 17::Minibatch 71::LR 0.0630769230769 --> Loss 0.0023379522562\n",
      "Epoch 17::Minibatch 72::LR 0.0630769230769 --> Loss 0.000546135256688\n",
      "Epoch 17::Minibatch 73::LR 0.0630769230769 --> Loss 0.00394737958908\n",
      "Epoch 17::Minibatch 74::LR 0.0630769230769 --> Loss 0.00416599273682\n",
      "Epoch 17::Minibatch 75::LR 0.0630769230769 --> Loss 0.00245067934195\n",
      "Epoch 17::Minibatch 76::LR 0.0630769230769 --> Loss 0.000590158353249\n",
      "Epoch 17::Minibatch 77::LR 0.0630769230769 --> Loss 0.00392584085464\n",
      "Epoch 17::Minibatch 78::LR 0.0630769230769 --> Loss 0.00386927127838\n",
      "Epoch 17::Minibatch 79::LR 0.0630769230769 --> Loss 0.00198729117711\n",
      "Epoch 17::Minibatch 80::LR 0.0630769230769 --> Loss 0.00327413856983\n",
      "Epoch 17::Minibatch 81::LR 0.0630769230769 --> Loss 0.00282831350962\n",
      "Epoch 17::Minibatch 82::LR 0.0630769230769 --> Loss 0.0020169677337\n",
      "Epoch 17::Minibatch 83::LR 0.0630769230769 --> Loss 0.00466260671616\n",
      "Epoch 17::Minibatch 84::LR 0.0630769230769 --> Loss 0.00201586405436\n",
      "Epoch 17::Minibatch 85::LR 0.0630769230769 --> Loss 0.00278335014979\n",
      "Epoch 17::Minibatch 86::LR 0.0630769230769 --> Loss 0.00224392135938\n",
      "Epoch 17::Minibatch 87::LR 0.0630769230769 --> Loss 0.00249486943086\n",
      "Epoch 17::Minibatch 88::LR 0.0630769230769 --> Loss 0.00181254029274\n",
      "Epoch 17::Minibatch 89::LR 0.0630769230769 --> Loss 0.00234694421291\n",
      "Epoch 17::Minibatch 90::LR 0.0630769230769 --> Loss 0.00114088435968\n",
      "Epoch 17::Minibatch 91::LR 0.0630769230769 --> Loss 0.000913029809793\n",
      "Epoch 17::Minibatch 92::LR 0.0630769230769 --> Loss 0.00271640121937\n",
      "Epoch 17::Minibatch 93::LR 0.0630769230769 --> Loss 0.00177880267302\n",
      "Epoch 17::Minibatch 94::LR 0.0630769230769 --> Loss 0.00177413543065\n",
      "Epoch 17::Minibatch 95::LR 0.0630769230769 --> Loss 0.00181008478006\n",
      "Epoch 17::Minibatch 96::LR 0.0630769230769 --> Loss 0.00584845304489\n",
      "Epoch 17::Minibatch 97::LR 0.0630769230769 --> Loss 0.0031830928723\n",
      "Epoch 17::Minibatch 98::LR 0.0630769230769 --> Loss 0.000984444419543\n",
      "Epoch 17::Minibatch 99::LR 0.0630769230769 --> Loss 0.00131102055311\n",
      "Epoch 17::Minibatch 100::LR 0.0630769230769 --> Loss 0.0051845395565\n",
      "Epoch 17::Minibatch 101::LR 0.0630769230769 --> Loss 0.000937821368376\n",
      "Epoch 17::Minibatch 102::LR 0.0630769230769 --> Loss 0.00388122280439\n",
      "Epoch 17::Minibatch 103::LR 0.0630769230769 --> Loss 0.0040302157402\n",
      "Epoch 17::Minibatch 104::LR 0.0630769230769 --> Loss 0.00278311769168\n",
      "Epoch 17::Minibatch 105::LR 0.0630769230769 --> Loss 0.00273858984311\n",
      "Epoch 17::Minibatch 106::LR 0.0630769230769 --> Loss 0.0180158392588\n",
      "Epoch 17::Minibatch 107::LR 0.0630769230769 --> Loss 0.00489509145419\n",
      "Epoch 17::Minibatch 108::LR 0.0630769230769 --> Loss 0.00107812672853\n",
      "Epoch 17::Minibatch 109::LR 0.0630769230769 --> Loss 0.00440152565638\n",
      "Epoch 17::Minibatch 110::LR 0.0630769230769 --> Loss 0.00242599725723\n",
      "Epoch 17::Minibatch 111::LR 0.0630769230769 --> Loss 0.000983732243379\n",
      "Epoch 17::Minibatch 112::LR 0.0630769230769 --> Loss 0.00359129746755\n",
      "Epoch 17::Minibatch 113::LR 0.0630769230769 --> Loss 0.00269870817661\n",
      "Epoch 17::Minibatch 114::LR 0.0630769230769 --> Loss 0.0014978826046\n",
      "Epoch 17::Minibatch 115::LR 0.0630769230769 --> Loss 0.00135724355777\n",
      "Epoch 17::Minibatch 116::LR 0.0630769230769 --> Loss 0.00281818807125\n",
      "Epoch 17::Minibatch 117::LR 0.0630769230769 --> Loss 0.00382510304451\n",
      "Epoch 17::Minibatch 118::LR 0.0630769230769 --> Loss 0.00694822788239\n",
      "Epoch 17::Minibatch 119::LR 0.0630769230769 --> Loss 0.000668758749962\n",
      "Epoch 17::Minibatch 120::LR 0.0630769230769 --> Loss 0.00181979199251\n",
      "Epoch 17::Minibatch 121::LR 0.0630769230769 --> Loss 0.00270804862181\n",
      "Epoch 17::Minibatch 122::LR 0.0630769230769 --> Loss 0.00372970024745\n",
      "Epoch 17::Minibatch 123::LR 0.0630769230769 --> Loss 0.00106185515722\n",
      "Epoch 17::Minibatch 124::LR 0.0630769230769 --> Loss 0.00281309644381\n",
      "Epoch 17::Minibatch 125::LR 0.0630769230769 --> Loss 0.00466865698497\n",
      "Epoch 17::Minibatch 126::LR 0.0630769230769 --> Loss 0.0027483022213\n",
      "Epoch 17::Minibatch 127::LR 0.0630769230769 --> Loss 0.00445972601573\n",
      "Epoch 17::Minibatch 128::LR 0.0630769230769 --> Loss 0.00364083091418\n",
      "Epoch 17::Minibatch 129::LR 0.0630769230769 --> Loss 0.0027407169342\n",
      "Epoch 17::Minibatch 130::LR 0.0630769230769 --> Loss 0.00437385042508\n",
      "Epoch 17::Minibatch 131::LR 0.0630769230769 --> Loss 0.0018154279391\n",
      "Epoch 17::Minibatch 132::LR 0.0630769230769 --> Loss 0.0031179757913\n",
      "Epoch 17::Minibatch 133::LR 0.0630769230769 --> Loss 0.00296640753746\n",
      "Epoch 17::Minibatch 134::LR 0.0630769230769 --> Loss 0.0024012285471\n",
      "Epoch 17::Minibatch 135::LR 0.0630769230769 --> Loss 0.00160479625066\n",
      "Epoch 17::Minibatch 136::LR 0.0630769230769 --> Loss 0.0027404888471\n",
      "Epoch 17::Minibatch 137::LR 0.0630769230769 --> Loss 0.00370379924774\n",
      "Epoch 17::Minibatch 138::LR 0.0630769230769 --> Loss 0.00132341603438\n",
      "Epoch 17::Minibatch 139::LR 0.0630769230769 --> Loss 0.00192366600037\n",
      "Epoch 17::Minibatch 140::LR 0.0630769230769 --> Loss 0.00247562547525\n",
      "Epoch 17::Minibatch 141::LR 0.0630769230769 --> Loss 0.00298992772897\n",
      "Epoch 17::Minibatch 142::LR 0.0630769230769 --> Loss 0.00292074541251\n",
      "Epoch 17::Minibatch 143::LR 0.0630769230769 --> Loss 0.000616196791331\n",
      "Epoch 17::Minibatch 144::LR 0.0630769230769 --> Loss 0.00324000616868\n",
      "Epoch 17::Minibatch 145::LR 0.0630769230769 --> Loss 0.00433506051699\n",
      "Epoch 17::Minibatch 146::LR 0.0630769230769 --> Loss 0.00260188639164\n",
      "Epoch 17::Minibatch 147::LR 0.0630769230769 --> Loss 0.00182814399401\n",
      "Epoch 17::Minibatch 148::LR 0.0630769230769 --> Loss 0.00102079540491\n",
      "Epoch 17::Minibatch 149::LR 0.0630769230769 --> Loss 0.00284732341766\n",
      "Epoch 17::Minibatch 150::LR 0.0630769230769 --> Loss 0.00274027804534\n",
      "Epoch 17::Minibatch 151::LR 0.0630769230769 --> Loss 0.00425709803899\n",
      "Epoch 17::Minibatch 152::LR 0.0630769230769 --> Loss 0.000928513109684\n",
      "Epoch 17::Minibatch 153::LR 0.0630769230769 --> Loss 0.00183971444766\n",
      "Epoch 17::Minibatch 154::LR 0.0630769230769 --> Loss 0.00206824441751\n",
      "Epoch 17::Minibatch 155::LR 0.0630769230769 --> Loss 0.004509866635\n",
      "Epoch 17::Minibatch 156::LR 0.0630769230769 --> Loss 0.00241181413333\n",
      "Epoch 17::Minibatch 157::LR 0.0630769230769 --> Loss 0.00070408642292\n",
      "Epoch 17::Minibatch 158::LR 0.0630769230769 --> Loss 0.00308713436127\n",
      "Epoch 17::Minibatch 159::LR 0.0630769230769 --> Loss 0.00276884933313\n",
      "Epoch 17::Minibatch 160::LR 0.0630769230769 --> Loss 0.0026470965147\n",
      "Epoch 17::Minibatch 161::LR 0.0630769230769 --> Loss 0.00102740228176\n",
      "Epoch 17::Minibatch 162::LR 0.0630769230769 --> Loss 0.00375769297282\n",
      "Epoch 17::Minibatch 163::LR 0.0630769230769 --> Loss 0.0024126692613\n",
      "Epoch 17::Minibatch 164::LR 0.0630769230769 --> Loss 0.00250520408154\n",
      "Epoch 17::Minibatch 165::LR 0.0630769230769 --> Loss 0.000534425377846\n",
      "Epoch 17::Minibatch 166::LR 0.0630769230769 --> Loss 0.00180074214935\n",
      "Epoch 17::Minibatch 167::LR 0.0630769230769 --> Loss 0.00246792197227\n",
      "Epoch 17::Minibatch 168::LR 0.0630769230769 --> Loss 0.00219711681207\n",
      "Epoch 17::Minibatch 169::LR 0.0630769230769 --> Loss 0.00101974199216\n",
      "Epoch 17::Minibatch 170::LR 0.0630769230769 --> Loss 0.000994015932083\n",
      "Epoch 17::Minibatch 171::LR 0.0630769230769 --> Loss 0.00252046724161\n",
      "Epoch 17::Minibatch 172::LR 0.0630769230769 --> Loss 0.00452758789063\n",
      "Epoch 17::Minibatch 173::LR 0.0630769230769 --> Loss 0.00195966502031\n",
      "Epoch 17::Minibatch 174::LR 0.0630769230769 --> Loss 0.00105325251818\n",
      "Epoch 17::Minibatch 175::LR 0.0630769230769 --> Loss 0.00231104791164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 176::LR 0.0630769230769 --> Loss 0.00326985577742\n",
      "Epoch 17::Minibatch 177::LR 0.0630769230769 --> Loss 0.00463971376419\n",
      "Epoch 17::Minibatch 178::LR 0.0630769230769 --> Loss 0.001638712883\n",
      "Epoch 17::Minibatch 179::LR 0.0630769230769 --> Loss 0.00134593586127\n",
      "Epoch 17::Minibatch 180::LR 0.0630769230769 --> Loss 0.00357756614685\n",
      "Epoch 17::Minibatch 181::LR 0.0630769230769 --> Loss 0.0032870421807\n",
      "Epoch 17::Minibatch 182::LR 0.0630769230769 --> Loss 0.000782816658417\n",
      "Epoch 17::Minibatch 183::LR 0.0630769230769 --> Loss 0.001690736413\n",
      "Epoch 17::Minibatch 184::LR 0.0630769230769 --> Loss 0.00343987703323\n",
      "Epoch 17::Minibatch 185::LR 0.0630769230769 --> Loss 0.0028259452184\n",
      "Epoch 17::Minibatch 186::LR 0.0630769230769 --> Loss 0.00098131308953\n",
      "Epoch 17::Minibatch 187::LR 0.0630769230769 --> Loss 0.0012580854694\n",
      "Epoch 17::Minibatch 188::LR 0.0630769230769 --> Loss 0.00417929927508\n",
      "Epoch 17::Minibatch 189::LR 0.0630769230769 --> Loss 0.00446739912033\n",
      "Epoch 17::Minibatch 190::LR 0.0630769230769 --> Loss 0.00232408046722\n",
      "Epoch 17::Minibatch 191::LR 0.0630769230769 --> Loss 0.000482367972533\n",
      "Epoch 17::Minibatch 192::LR 0.0630769230769 --> Loss 0.00271445314089\n",
      "Epoch 17::Minibatch 193::LR 0.0630769230769 --> Loss 0.00255599578222\n",
      "Epoch 17::Minibatch 194::LR 0.0630769230769 --> Loss 0.00179107646147\n",
      "Epoch 17::Minibatch 195::LR 0.0630769230769 --> Loss 0.000384999761979\n",
      "Epoch 17::Minibatch 196::LR 0.0630769230769 --> Loss 0.00122704376777\n",
      "Epoch 17::Minibatch 197::LR 0.0630769230769 --> Loss 0.00285528381666\n",
      "Epoch 17::Minibatch 198::LR 0.0630769230769 --> Loss 0.00220199306806\n",
      "Epoch 17::Minibatch 199::LR 0.0630769230769 --> Loss 0.000285851384203\n",
      "Epoch 17::Minibatch 200::LR 0.0630769230769 --> Loss 0.00206946094831\n",
      "Epoch 17::Minibatch 201::LR 0.0630769230769 --> Loss 0.00195808390776\n",
      "Epoch 17::Minibatch 202::LR 0.0630769230769 --> Loss 0.00187782824039\n",
      "Epoch 17::Minibatch 203::LR 0.0630769230769 --> Loss 0.00177421470483\n",
      "Epoch 17::Minibatch 204::LR 0.0630769230769 --> Loss 0.0014703292648\n",
      "Epoch 17::Minibatch 205::LR 0.0630769230769 --> Loss 0.00221619983514\n",
      "Epoch 17::Minibatch 206::LR 0.0630769230769 --> Loss 0.00653399030368\n",
      "Epoch 17::Minibatch 207::LR 0.0630769230769 --> Loss 0.00139640410741\n",
      "Epoch 17::Minibatch 208::LR 0.0630769230769 --> Loss 0.00113445947568\n",
      "Epoch 17::Minibatch 209::LR 0.0630769230769 --> Loss 0.00219580988089\n",
      "Epoch 17::Minibatch 210::LR 0.0630769230769 --> Loss 0.00209291736285\n",
      "Epoch 17::Minibatch 211::LR 0.0630769230769 --> Loss 0.00224773367246\n",
      "Epoch 17::Minibatch 212::LR 0.0630769230769 --> Loss 0.00402060627937\n",
      "Epoch 17::Minibatch 213::LR 0.0630769230769 --> Loss 0.00593684077263\n",
      "Epoch 17::Minibatch 214::LR 0.0630769230769 --> Loss 0.00929205497106\n",
      "Epoch 17::Minibatch 215::LR 0.0630769230769 --> Loss 0.00140113294125\n",
      "Epoch 17::Minibatch 216::LR 0.0630769230769 --> Loss 0.00552585919698\n",
      "Epoch 17::Minibatch 217::LR 0.0630769230769 --> Loss 0.00616658409437\n",
      "Epoch 17::Minibatch 218::LR 0.0630769230769 --> Loss 0.00397404313087\n",
      "Epoch 17::Minibatch 219::LR 0.0630769230769 --> Loss 0.00408691048622\n",
      "Epoch 17::Minibatch 220::LR 0.0630769230769 --> Loss 0.00453499078751\n",
      "Epoch 17::Minibatch 221::LR 0.0630769230769 --> Loss 0.00427391926448\n",
      "Epoch 17::Minibatch 222::LR 0.0630769230769 --> Loss 0.00327419261138\n",
      "Epoch 17::Minibatch 223::LR 0.0630769230769 --> Loss 0.00142547875643\n",
      "Epoch 17::Minibatch 224::LR 0.0630769230769 --> Loss 0.00178070644538\n",
      "Epoch 17::Minibatch 225::LR 0.0630769230769 --> Loss 0.00726473251979\n",
      "Epoch 17::Minibatch 226::LR 0.0630769230769 --> Loss 0.0037983751297\n",
      "Epoch 17::Minibatch 227::LR 0.0630769230769 --> Loss 0.00170053680738\n",
      "Epoch 17::Minibatch 228::LR 0.0630769230769 --> Loss 0.000754506985346\n",
      "Epoch 17::Minibatch 229::LR 0.0630769230769 --> Loss 0.00482112129529\n",
      "Epoch 17::Minibatch 230::LR 0.0630769230769 --> Loss 0.00395721991857\n",
      "Epoch 17::Minibatch 231::LR 0.0630769230769 --> Loss 0.00264591097832\n",
      "Epoch 17::Minibatch 232::LR 0.0630769230769 --> Loss 0.00122796426217\n",
      "Epoch 17::Minibatch 233::LR 0.0630769230769 --> Loss 0.00242645899455\n",
      "Epoch 17::Minibatch 234::LR 0.0630769230769 --> Loss 0.00682036399841\n",
      "Epoch 17::Minibatch 235::LR 0.0630769230769 --> Loss 0.00472908814748\n",
      "Epoch 17::Minibatch 236::LR 0.0630769230769 --> Loss 0.00177758653959\n",
      "Epoch 17::Minibatch 237::LR 0.0630769230769 --> Loss 0.00069440672795\n",
      "Epoch 17::Minibatch 238::LR 0.0630769230769 --> Loss 0.00342351833979\n",
      "Epoch 17::Minibatch 239::LR 0.0630769230769 --> Loss 0.002964737614\n",
      "Epoch 17::Minibatch 240::LR 0.0630769230769 --> Loss 0.00325013935566\n",
      "Epoch 17::Minibatch 241::LR 0.0630769230769 --> Loss 0.000774762531122\n",
      "Epoch 17::Minibatch 242::LR 0.0630769230769 --> Loss 0.00709675788879\n",
      "Epoch 17::Minibatch 243::LR 0.0630769230769 --> Loss 0.00353864868482\n",
      "Epoch 17::Minibatch 244::LR 0.0630769230769 --> Loss 0.00296026527882\n",
      "Epoch 17::Minibatch 245::LR 0.0630769230769 --> Loss 0.000482718547185\n",
      "Epoch 17::Minibatch 246::LR 0.0630769230769 --> Loss 0.0020790964365\n",
      "Epoch 17::Minibatch 247::LR 0.0630769230769 --> Loss 0.013127810955\n",
      "Epoch 17::Minibatch 248::LR 0.0630769230769 --> Loss 0.00452215115229\n",
      "Epoch 17::Minibatch 249::LR 0.0630769230769 --> Loss 0.00275546709696\n",
      "Epoch 17::Minibatch 250::LR 0.0630769230769 --> Loss 0.00263650854429\n",
      "Epoch 17::Minibatch 251::LR 0.0630769230769 --> Loss 0.0025553526481\n",
      "Epoch 17::Minibatch 252::LR 0.0630769230769 --> Loss 0.00181335747242\n",
      "Epoch 17::Minibatch 253::LR 0.0630769230769 --> Loss 0.00311752518018\n",
      "Epoch 17::Minibatch 254::LR 0.0630769230769 --> Loss 0.0051973203818\n",
      "Epoch 17::Minibatch 255::LR 0.0630769230769 --> Loss 0.00388615687688\n",
      "Epoch 17::Minibatch 256::LR 0.0630769230769 --> Loss 0.00166576266289\n",
      "Epoch 17::Minibatch 257::LR 0.0630769230769 --> Loss 0.00125104775031\n",
      "Epoch 17::Minibatch 258::LR 0.0630769230769 --> Loss 0.00364576657613\n",
      "Epoch 17::Minibatch 259::LR 0.0630769230769 --> Loss 0.00181061506271\n",
      "Epoch 17::Minibatch 260::LR 0.0630769230769 --> Loss 0.0019010579586\n",
      "Epoch 17::Minibatch 261::LR 0.0630769230769 --> Loss 0.00288806021214\n",
      "Epoch 17::Minibatch 262::LR 0.0630769230769 --> Loss 0.00194496651491\n",
      "Epoch 17::Minibatch 263::LR 0.0630769230769 --> Loss 0.00238330344359\n",
      "Epoch 17::Minibatch 264::LR 0.0630769230769 --> Loss 0.00365444501241\n",
      "Epoch 17::Minibatch 265::LR 0.0630769230769 --> Loss 0.0103028909365\n",
      "Epoch 17::Minibatch 266::LR 0.0630769230769 --> Loss 0.00101954579353\n",
      "Epoch 17::Minibatch 267::LR 0.0630769230769 --> Loss 0.0100534057617\n",
      "Epoch 17::Minibatch 268::LR 0.0630769230769 --> Loss 0.00119409193595\n",
      "Epoch 17::Minibatch 269::LR 0.0630769230769 --> Loss 0.00356108983358\n",
      "Epoch 17::Minibatch 270::LR 0.0630769230769 --> Loss 0.00664173007011\n",
      "Epoch 17::Minibatch 271::LR 0.0630769230769 --> Loss 0.00272286236286\n",
      "Epoch 17::Minibatch 272::LR 0.0630769230769 --> Loss 0.00413730581601\n",
      "Epoch 17::Minibatch 273::LR 0.0630769230769 --> Loss 0.00167432983716\n",
      "Epoch 17::Minibatch 274::LR 0.0630769230769 --> Loss 0.00180037736893\n",
      "Epoch 17::Minibatch 275::LR 0.0630769230769 --> Loss 0.00266458690166\n",
      "Epoch 17::Minibatch 276::LR 0.0630769230769 --> Loss 0.00346878608068\n",
      "Epoch 17::Minibatch 277::LR 0.0630769230769 --> Loss 0.00100435535113\n",
      "Epoch 17::Minibatch 278::LR 0.0630769230769 --> Loss 0.002637343208\n",
      "Epoch 17::Minibatch 279::LR 0.0630769230769 --> Loss 0.00237660507361\n",
      "Epoch 17::Minibatch 280::LR 0.0630769230769 --> Loss 0.0020656166474\n",
      "Epoch 17::Minibatch 281::LR 0.0630769230769 --> Loss 0.00129969457785\n",
      "Epoch 17::Minibatch 282::LR 0.0630769230769 --> Loss 0.00222567737103\n",
      "Epoch 17::Minibatch 283::LR 0.0630769230769 --> Loss 0.00217590292295\n",
      "Epoch 17::Minibatch 284::LR 0.0630769230769 --> Loss 0.0017351581653\n",
      "Epoch 17::Minibatch 285::LR 0.0630769230769 --> Loss 0.00121608277162\n",
      "Epoch 17::Minibatch 286::LR 0.0630769230769 --> Loss 0.00213955044746\n",
      "Epoch 17::Minibatch 287::LR 0.0630769230769 --> Loss 0.00207275489966\n",
      "Epoch 17::Minibatch 288::LR 0.0630769230769 --> Loss 0.00111542016268\n",
      "Epoch 17::Minibatch 289::LR 0.0630769230769 --> Loss 0.00159249732892\n",
      "Epoch 17::Minibatch 290::LR 0.0630769230769 --> Loss 0.00194372971853\n",
      "Epoch 17::Minibatch 291::LR 0.0630769230769 --> Loss 0.00172828058402\n",
      "Epoch 17::Minibatch 292::LR 0.0630769230769 --> Loss 0.000607364326715\n",
      "Epoch 17::Minibatch 293::LR 0.0630769230769 --> Loss 0.00149030337731\n",
      "Epoch 17::Minibatch 294::LR 0.0630769230769 --> Loss 0.0015717536211\n",
      "Epoch 17::Minibatch 295::LR 0.0630769230769 --> Loss 0.00185959657033\n",
      "Epoch 17::Minibatch 296::LR 0.0630769230769 --> Loss 0.00160839011272\n",
      "Epoch 17::Minibatch 297::LR 0.0630769230769 --> Loss 0.00139771769444\n",
      "Epoch 17::Minibatch 298::LR 0.0630769230769 --> Loss 0.0013811553518\n",
      "Epoch 17::Minibatch 299::LR 0.0630769230769 --> Loss 0.00079748009642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 300::LR 0.0630769230769 --> Loss 0.00281394183636\n",
      "Epoch 17::Minibatch 301::LR 0.0630769230769 --> Loss 0.00273078918457\n",
      "Epoch 17::Minibatch 302::LR 0.0630769230769 --> Loss 0.00251708865166\n",
      "Epoch 17::Minibatch 303::LR 0.0630769230769 --> Loss 0.000862676799297\n",
      "Epoch 17::Minibatch 304::LR 0.0630769230769 --> Loss 0.0031080108881\n",
      "Epoch 17::Minibatch 305::LR 0.0630769230769 --> Loss 0.00169051627318\n",
      "Epoch 17::Minibatch 306::LR 0.0630769230769 --> Loss 0.000931281745434\n",
      "Epoch 17::Minibatch 307::LR 0.0630769230769 --> Loss 0.00246314803759\n",
      "Epoch 17::Minibatch 308::LR 0.0630769230769 --> Loss 0.00198949694633\n",
      "Epoch 17::Minibatch 309::LR 0.0630769230769 --> Loss 0.00100204914808\n",
      "Epoch 17::Minibatch 310::LR 0.0630769230769 --> Loss 0.00111794859171\n",
      "Epoch 17::Minibatch 311::LR 0.0630769230769 --> Loss 0.00171951413155\n",
      "Epoch 17::Minibatch 312::LR 0.0630769230769 --> Loss 0.00296155949434\n",
      "Epoch 17::Minibatch 313::LR 0.0630769230769 --> Loss 0.00239922185739\n",
      "Epoch 17::Minibatch 314::LR 0.0630769230769 --> Loss 0.0019174015522\n",
      "Epoch 17::Minibatch 315::LR 0.0630769230769 --> Loss 0.00099890857935\n",
      "Epoch 17::Minibatch 316::LR 0.0630769230769 --> Loss 0.0023297448953\n",
      "Epoch 17::Minibatch 317::LR 0.0630769230769 --> Loss 0.00154906123877\n",
      "Epoch 17::Minibatch 318::LR 0.0630769230769 --> Loss 0.00122713337342\n",
      "Epoch 17::Minibatch 319::LR 0.0630769230769 --> Loss 0.00229552785556\n",
      "Epoch 17::Minibatch 320::LR 0.0630769230769 --> Loss 0.00320076088111\n",
      "Epoch 17::Minibatch 321::LR 0.0630769230769 --> Loss 0.000854512949785\n",
      "Epoch 17::Minibatch 322::LR 0.0630769230769 --> Loss 0.00366180419922\n",
      "Epoch 17::Minibatch 323::LR 0.0630769230769 --> Loss 0.0035434349378\n",
      "Epoch 17::Minibatch 324::LR 0.0630769230769 --> Loss 0.00263731598854\n",
      "Epoch 17::Minibatch 325::LR 0.0630769230769 --> Loss 0.00240570803483\n",
      "Epoch 17::Minibatch 326::LR 0.0630769230769 --> Loss 0.00552065014839\n",
      "Epoch 17::Minibatch 327::LR 0.0630769230769 --> Loss 0.00226560592651\n",
      "Epoch 17::Minibatch 328::LR 0.0630769230769 --> Loss 0.00328086475531\n",
      "Epoch 17::Minibatch 329::LR 0.0630769230769 --> Loss 0.00122903277477\n",
      "Epoch 17::Minibatch 330::LR 0.0630769230769 --> Loss 0.00160929133495\n",
      "Epoch 17::Minibatch 331::LR 0.0630769230769 --> Loss 0.00255187729994\n",
      "Epoch 17::Minibatch 332::LR 0.0630769230769 --> Loss 0.00250998616219\n",
      "Epoch 17::Minibatch 333::LR 0.0630769230769 --> Loss 0.00145309060812\n",
      "Epoch 17::Minibatch 334::LR 0.0630769230769 --> Loss 0.0043934071064\n",
      "Epoch 17::Minibatch 335::LR 0.0630769230769 --> Loss 0.00188884735107\n",
      "Epoch 17::Minibatch 336::LR 0.0630769230769 --> Loss 0.00216139495373\n",
      "Epoch 17::Minibatch 337::LR 0.0630769230769 --> Loss 0.00344595869382\n",
      "Epoch 17::Minibatch 338::LR 0.0630769230769 --> Loss 0.00052364786466\n",
      "Epoch 17::Minibatch 339::LR 0.0630769230769 --> Loss 0.00332140425841\n",
      "Epoch 17::Minibatch 340::LR 0.0630769230769 --> Loss 0.00413815418879\n",
      "Epoch 17::Minibatch 341::LR 0.0630769230769 --> Loss 0.00485641360283\n",
      "Epoch 17::Minibatch 342::LR 0.0630769230769 --> Loss 0.00314733207226\n",
      "Epoch 17::Minibatch 343::LR 0.0630769230769 --> Loss 0.00168617288272\n",
      "Epoch 17::Minibatch 344::LR 0.0630769230769 --> Loss 0.00313085416953\n",
      "Epoch 17::Minibatch 345::LR 0.0630769230769 --> Loss 0.00427897810936\n",
      "Epoch 17::Minibatch 346::LR 0.0630769230769 --> Loss 0.00566705902418\n",
      "Epoch 17::Minibatch 347::LR 0.0630769230769 --> Loss 0.000854467054208\n",
      "Epoch 17::Minibatch 348::LR 0.0630769230769 --> Loss 0.00340730667114\n",
      "Epoch 17::Minibatch 349::LR 0.0630769230769 --> Loss 0.00349693099658\n",
      "Epoch 17::Minibatch 350::LR 0.0630769230769 --> Loss 0.00176607092222\n",
      "Epoch 17::Minibatch 351::LR 0.0630769230769 --> Loss 0.00351988712947\n",
      "Epoch 17::Minibatch 352::LR 0.0630769230769 --> Loss 0.00489215652148\n",
      "Epoch 17::Minibatch 353::LR 0.0630769230769 --> Loss 0.0035527408123\n",
      "Epoch 17::Minibatch 354::LR 0.0630769230769 --> Loss 0.00295793970426\n",
      "Epoch 17::Minibatch 355::LR 0.0630769230769 --> Loss 0.00617078185081\n",
      "Epoch 17::Minibatch 356::LR 0.0630769230769 --> Loss 0.00313187380632\n",
      "Epoch 17::Minibatch 357::LR 0.0630769230769 --> Loss 0.00114634950956\n",
      "Epoch 17::Minibatch 358::LR 0.0630769230769 --> Loss 0.0021473834912\n",
      "Epoch 17::Minibatch 359::LR 0.0630769230769 --> Loss 0.0027322636048\n",
      "Epoch 17::Minibatch 360::LR 0.0630769230769 --> Loss 0.0024298932155\n",
      "Epoch 17::Minibatch 361::LR 0.0630769230769 --> Loss 0.00242229183515\n",
      "Epoch 17::Minibatch 362::LR 0.0630769230769 --> Loss 0.00240111867587\n",
      "Epoch 17::Minibatch 363::LR 0.0630769230769 --> Loss 0.000665335208178\n",
      "Epoch 17::Minibatch 364::LR 0.0630769230769 --> Loss 0.00200999299685\n",
      "Epoch 17::Minibatch 365::LR 0.0630769230769 --> Loss 0.00209695140521\n",
      "Epoch 17::Minibatch 366::LR 0.0630769230769 --> Loss 0.00224356452624\n",
      "Epoch 17::Minibatch 367::LR 0.0630769230769 --> Loss 0.00108367900054\n",
      "Epoch 17::Minibatch 368::LR 0.0630769230769 --> Loss 0.000988929271698\n",
      "Epoch 17::Minibatch 369::LR 0.0630769230769 --> Loss 0.00287747542063\n",
      "Epoch 17::Minibatch 370::LR 0.0630769230769 --> Loss 0.00226647833983\n",
      "Epoch 17::Minibatch 371::LR 0.0630769230769 --> Loss 0.00187522669633\n",
      "Epoch 17::Minibatch 372::LR 0.0630769230769 --> Loss 0.00043770129482\n",
      "Epoch 17::Minibatch 373::LR 0.0630769230769 --> Loss 0.00177227636178\n",
      "Epoch 17::Minibatch 374::LR 0.0630769230769 --> Loss 0.00218884249528\n",
      "Epoch 17::Minibatch 375::LR 0.0630769230769 --> Loss 0.00184279461702\n",
      "Epoch 17::Minibatch 376::LR 0.0630769230769 --> Loss 0.00123763163884\n",
      "Epoch 17::Minibatch 377::LR 0.0630769230769 --> Loss 0.00194421152274\n",
      "Epoch 17::Minibatch 378::LR 0.0630769230769 --> Loss 0.00213045835495\n",
      "Epoch 17::Minibatch 379::LR 0.0630769230769 --> Loss 0.00237628698349\n",
      "Epoch 17::Minibatch 380::LR 0.0630769230769 --> Loss 0.00158611257871\n",
      "Epoch 17::Minibatch 381::LR 0.0630769230769 --> Loss 0.0009834420681\n",
      "Epoch 17::Minibatch 382::LR 0.0630769230769 --> Loss 0.00201347609361\n",
      "Epoch 17::Minibatch 383::LR 0.0630769230769 --> Loss 0.00195571184158\n",
      "Epoch 17::Minibatch 384::LR 0.0630769230769 --> Loss 0.00105251471202\n",
      "Epoch 17::Minibatch 385::LR 0.0630769230769 --> Loss 0.0010364039739\n",
      "Epoch 17::Minibatch 386::LR 0.0630769230769 --> Loss 0.00218304157257\n",
      "Epoch 17::Minibatch 387::LR 0.0630769230769 --> Loss 0.00234136799971\n",
      "Epoch 17::Minibatch 388::LR 0.0630769230769 --> Loss 0.00115269352992\n",
      "Epoch 17::Minibatch 389::LR 0.0630769230769 --> Loss 0.00180402557055\n",
      "Epoch 17::Minibatch 390::LR 0.0630769230769 --> Loss 0.0035483956337\n",
      "Epoch 17::Minibatch 391::LR 0.0630769230769 --> Loss 0.00267756521702\n",
      "Epoch 17::Minibatch 392::LR 0.0630769230769 --> Loss 0.00263398766518\n",
      "Epoch 17::Minibatch 393::LR 0.0630769230769 --> Loss 0.00277141968409\n",
      "Epoch 17::Minibatch 394::LR 0.0630769230769 --> Loss 0.00209284087022\n",
      "Epoch 17::Minibatch 395::LR 0.0630769230769 --> Loss 0.00205765148004\n",
      "Epoch 17::Minibatch 396::LR 0.0630769230769 --> Loss 0.00194436371326\n",
      "Epoch 17::Minibatch 397::LR 0.0630769230769 --> Loss 0.00207689901193\n",
      "Epoch 17::Minibatch 398::LR 0.0630769230769 --> Loss 0.00206084688505\n",
      "Epoch 17::Minibatch 399::LR 0.0630769230769 --> Loss 0.00236634333928\n",
      "Epoch 17::Minibatch 400::LR 0.0630769230769 --> Loss 0.00201304574807\n",
      "Epoch 17::Minibatch 401::LR 0.0630769230769 --> Loss 0.00347889145215\n",
      "Epoch 17::Minibatch 402::LR 0.0630769230769 --> Loss 0.00180316984653\n",
      "Epoch 17::Minibatch 403::LR 0.0630769230769 --> Loss 0.00145315070947\n",
      "Epoch 17::Minibatch 404::LR 0.0630769230769 --> Loss 0.00147743582726\n",
      "Epoch 17::Minibatch 405::LR 0.0630769230769 --> Loss 0.00350340326627\n",
      "Epoch 17::Minibatch 406::LR 0.0630769230769 --> Loss 0.00244763016701\n",
      "Epoch 17::Minibatch 407::LR 0.0630769230769 --> Loss 0.00173320392768\n",
      "Epoch 17::Minibatch 408::LR 0.0630769230769 --> Loss 0.000438945790132\n",
      "Epoch 17::Minibatch 409::LR 0.0630769230769 --> Loss 0.00232997675737\n",
      "Epoch 17::Minibatch 410::LR 0.0630769230769 --> Loss 0.0032025317351\n",
      "Epoch 17::Minibatch 411::LR 0.0630769230769 --> Loss 0.00163348595301\n",
      "Epoch 17::Minibatch 412::LR 0.0630769230769 --> Loss 0.000956461131573\n",
      "Epoch 17::Minibatch 413::LR 0.0630769230769 --> Loss 0.00196611781915\n",
      "Epoch 17::Minibatch 414::LR 0.0630769230769 --> Loss 0.00182696183523\n",
      "Epoch 17::Minibatch 415::LR 0.0630769230769 --> Loss 0.00113828013341\n",
      "Epoch 17::Minibatch 416::LR 0.0630769230769 --> Loss 0.000808883706729\n",
      "Epoch 17::Minibatch 417::LR 0.0630769230769 --> Loss 0.00169437050819\n",
      "Epoch 17::Minibatch 418::LR 0.0630769230769 --> Loss 0.00275300482909\n",
      "Epoch 17::Minibatch 419::LR 0.0630769230769 --> Loss 0.000496635635694\n",
      "Epoch 17::Minibatch 420::LR 0.0630769230769 --> Loss 0.000691708226999\n",
      "Epoch 17::Minibatch 421::LR 0.0630769230769 --> Loss 0.00192828873793\n",
      "Epoch 17::Minibatch 422::LR 0.0630769230769 --> Loss 0.00214065273603\n",
      "Epoch 17::Minibatch 423::LR 0.0630769230769 --> Loss 0.000962020059427\n",
      "Epoch 17::Minibatch 424::LR 0.0630769230769 --> Loss 0.00154711653789\n",
      "Epoch 17::Minibatch 425::LR 0.0630769230769 --> Loss 0.00289662897587\n",
      "Epoch 17::Minibatch 426::LR 0.0630769230769 --> Loss 0.00199554920197\n",
      "Epoch 17::Minibatch 427::LR 0.0630769230769 --> Loss 0.000705862293641\n",
      "Epoch 17::Minibatch 428::LR 0.0630769230769 --> Loss 0.0010309740901\n",
      "Epoch 17::Minibatch 429::LR 0.0630769230769 --> Loss 0.00237911423047\n",
      "Epoch 17::Minibatch 430::LR 0.0630769230769 --> Loss 0.0093231789271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 431::LR 0.0630769230769 --> Loss 0.00377995212873\n",
      "Epoch 17::Minibatch 432::LR 0.0630769230769 --> Loss 0.00441773533821\n",
      "Epoch 17::Minibatch 433::LR 0.0630769230769 --> Loss 0.00257143656413\n",
      "Epoch 17::Minibatch 434::LR 0.0630769230769 --> Loss 0.00253332138062\n",
      "Epoch 17::Minibatch 435::LR 0.0630769230769 --> Loss 0.00233515560627\n",
      "Epoch 17::Minibatch 436::LR 0.0630769230769 --> Loss 0.00169331709544\n",
      "Epoch 17::Minibatch 437::LR 0.0630769230769 --> Loss 0.00321756581465\n",
      "Epoch 17::Minibatch 438::LR 0.0630769230769 --> Loss 0.00256654322147\n",
      "Epoch 17::Minibatch 439::LR 0.0630769230769 --> Loss 0.00207148869832\n",
      "Epoch 17::Minibatch 440::LR 0.0630769230769 --> Loss 0.00320301552614\n",
      "Epoch 17::Minibatch 441::LR 0.0630769230769 --> Loss 0.00300044159094\n",
      "Epoch 17::Minibatch 442::LR 0.0630769230769 --> Loss 0.0027343916893\n",
      "Epoch 17::Minibatch 443::LR 0.0630769230769 --> Loss 0.00366912444433\n",
      "Epoch 17::Minibatch 444::LR 0.0630769230769 --> Loss 0.00286033709844\n",
      "Epoch 17::Minibatch 445::LR 0.0630769230769 --> Loss 0.000890921056271\n",
      "Epoch 17::Minibatch 446::LR 0.0630769230769 --> Loss 0.0014475051562\n",
      "Epoch 17::Minibatch 447::LR 0.0630769230769 --> Loss 0.0024219695727\n",
      "Epoch 17::Minibatch 448::LR 0.0630769230769 --> Loss 0.0023971581459\n",
      "Epoch 17::Minibatch 449::LR 0.0630769230769 --> Loss 0.00371920267741\n",
      "Epoch 17::Minibatch 450::LR 0.0630769230769 --> Loss 0.00229292670886\n",
      "Epoch 17::Minibatch 451::LR 0.0630769230769 --> Loss 0.00401984214783\n",
      "Epoch 17::Minibatch 452::LR 0.0630769230769 --> Loss 0.00237326741219\n",
      "Epoch 17::Minibatch 453::LR 0.0630769230769 --> Loss 0.000376166775823\n",
      "Epoch 17::Minibatch 454::LR 0.0630769230769 --> Loss 0.00360874215762\n",
      "Epoch 17::Minibatch 455::LR 0.0630769230769 --> Loss 0.00269130766392\n",
      "Epoch 17::Minibatch 456::LR 0.0630769230769 --> Loss 0.00312389194965\n",
      "Epoch 17::Minibatch 457::LR 0.0630769230769 --> Loss 0.00195392429829\n",
      "Epoch 17::Minibatch 458::LR 0.0630769230769 --> Loss 0.000752901832263\n",
      "Epoch 17::Minibatch 459::LR 0.0630769230769 --> Loss 0.00410392165184\n",
      "Epoch 17::Minibatch 460::LR 0.0630769230769 --> Loss 0.00257500787576\n",
      "Epoch 17::Minibatch 461::LR 0.0630769230769 --> Loss 0.00389006853104\n",
      "Epoch 17::Minibatch 462::LR 0.0630769230769 --> Loss 0.000393660962582\n",
      "Epoch 17::Minibatch 463::LR 0.0630769230769 --> Loss 0.00454484144847\n",
      "Epoch 17::Minibatch 464::LR 0.0630769230769 --> Loss 0.0020319288969\n",
      "Epoch 17::Minibatch 465::LR 0.0630769230769 --> Loss 0.00516694506009\n",
      "Epoch 17::Minibatch 466::LR 0.0630769230769 --> Loss 0.00509101231893\n",
      "Epoch 17::Minibatch 467::LR 0.0630769230769 --> Loss 0.0056837439537\n",
      "Epoch 17::Minibatch 468::LR 0.0630769230769 --> Loss 0.00605448881785\n",
      "Epoch 17::Minibatch 469::LR 0.0630769230769 --> Loss 0.00668619473775\n",
      "Epoch 17::Minibatch 470::LR 0.0630769230769 --> Loss 0.00373871246974\n",
      "Epoch 17::Minibatch 471::LR 0.0630769230769 --> Loss 0.00172348380089\n",
      "Epoch 17::Minibatch 472::LR 0.0630769230769 --> Loss 0.00353476961454\n",
      "Epoch 17::Minibatch 473::LR 0.0630769230769 --> Loss 0.00224967996279\n",
      "Epoch 17::Minibatch 474::LR 0.0630769230769 --> Loss 0.000697895437479\n",
      "Epoch 17::Minibatch 475::LR 0.0630769230769 --> Loss 0.00479633808136\n",
      "Epoch 17::Minibatch 476::LR 0.0630769230769 --> Loss 0.0076659822464\n",
      "Epoch 17::Minibatch 477::LR 0.0630769230769 --> Loss 0.000929133892059\n",
      "Epoch 17::Minibatch 478::LR 0.0630769230769 --> Loss 0.00246915062269\n",
      "Epoch 17::Minibatch 479::LR 0.0630769230769 --> Loss 0.00195298214753\n",
      "Epoch 17::Minibatch 480::LR 0.0630769230769 --> Loss 0.00152636835972\n",
      "Epoch 17::Minibatch 481::LR 0.0630769230769 --> Loss 0.000956850449244\n",
      "Epoch 17::Minibatch 482::LR 0.0630769230769 --> Loss 0.00209020833174\n",
      "Epoch 17::Minibatch 483::LR 0.0630769230769 --> Loss 0.00317019780477\n",
      "Epoch 17::Minibatch 484::LR 0.0630769230769 --> Loss 0.00353089014689\n",
      "Epoch 17::Minibatch 485::LR 0.0630769230769 --> Loss 0.000755543907483\n",
      "Epoch 17::Minibatch 486::LR 0.0630769230769 --> Loss 0.00295068919659\n",
      "Epoch 17::Minibatch 487::LR 0.0630769230769 --> Loss 0.0033630390962\n",
      "Epoch 17::Minibatch 488::LR 0.0630769230769 --> Loss 0.00204166928927\n",
      "Epoch 17::Minibatch 489::LR 0.0630769230769 --> Loss 0.00320360481739\n",
      "Epoch 17::Minibatch 490::LR 0.0630769230769 --> Loss 0.000411323855321\n",
      "Epoch 17::Minibatch 491::LR 0.0630769230769 --> Loss 0.00369755546252\n",
      "Epoch 17::Minibatch 492::LR 0.0630769230769 --> Loss 0.00305076579253\n",
      "Epoch 17::Minibatch 493::LR 0.0630769230769 --> Loss 0.00302459816138\n",
      "Epoch 17::Minibatch 494::LR 0.0630769230769 --> Loss 0.000738052328428\n",
      "Epoch 17::Minibatch 495::LR 0.0630769230769 --> Loss 0.00188418885072\n",
      "Epoch 17::Minibatch 496::LR 0.0630769230769 --> Loss 0.00287888427575\n",
      "Epoch 17::Minibatch 497::LR 0.0630769230769 --> Loss 0.000927810072899\n",
      "Epoch 17::Minibatch 498::LR 0.0630769230769 --> Loss 0.000563800384601\n",
      "Epoch 17::Minibatch 499::LR 0.0630769230769 --> Loss 0.00362541278203\n",
      "Epoch 17::Minibatch 500::LR 0.0630769230769 --> Loss 0.00144382884105\n",
      "Epoch 17::Minibatch 501::LR 0.0630769230769 --> Loss 0.00220937291781\n",
      "Epoch 17::Minibatch 502::LR 0.0630769230769 --> Loss 0.00383210619291\n",
      "Epoch 17::Minibatch 503::LR 0.0630769230769 --> Loss 0.00818185647329\n",
      "Epoch 17::Minibatch 504::LR 0.0630769230769 --> Loss 0.00767058134079\n",
      "Epoch 17::Minibatch 505::LR 0.0630769230769 --> Loss 0.00427284240723\n",
      "Epoch 17::Minibatch 506::LR 0.0630769230769 --> Loss 0.0034505991141\n",
      "Epoch 17::Minibatch 507::LR 0.0630769230769 --> Loss 0.00601077516874\n",
      "Epoch 17::Minibatch 508::LR 0.0630769230769 --> Loss 0.00341071009636\n",
      "Epoch 17::Minibatch 509::LR 0.0630769230769 --> Loss 0.00456004659335\n",
      "Epoch 17::Minibatch 510::LR 0.0630769230769 --> Loss 0.00457085728645\n",
      "Epoch 17::Minibatch 511::LR 0.0630769230769 --> Loss 0.00392325321833\n",
      "Epoch 17::Minibatch 512::LR 0.0630769230769 --> Loss 0.00269421080748\n",
      "Epoch 17::Minibatch 513::LR 0.0630769230769 --> Loss 0.000650027493636\n",
      "Epoch 17::Minibatch 514::LR 0.0630769230769 --> Loss 0.00267681717873\n",
      "Epoch 17::Minibatch 515::LR 0.0630769230769 --> Loss 0.00300953944524\n",
      "Epoch 17::Minibatch 516::LR 0.0630769230769 --> Loss 0.00407660961151\n",
      "Epoch 17::Minibatch 517::LR 0.0630769230769 --> Loss 0.00351029276848\n",
      "Epoch 17::Minibatch 518::LR 0.0630769230769 --> Loss 0.00257950921853\n",
      "Epoch 17::Minibatch 519::LR 0.0630769230769 --> Loss 0.00346135179202\n",
      "Epoch 17::Minibatch 520::LR 0.0630769230769 --> Loss 0.00535929004351\n",
      "Epoch 17::Minibatch 521::LR 0.0630769230769 --> Loss 0.00541521310806\n",
      "Epoch 17::Minibatch 522::LR 0.0630769230769 --> Loss 0.00797580957413\n",
      "Epoch 17::Minibatch 523::LR 0.0630769230769 --> Loss 0.000649855434895\n",
      "Epoch 17::Minibatch 524::LR 0.0630769230769 --> Loss 0.00142183423042\n",
      "Epoch 17::Minibatch 525::LR 0.0630769230769 --> Loss 0.00322563767433\n",
      "Epoch 17::Minibatch 526::LR 0.0630769230769 --> Loss 0.0040132856369\n",
      "Epoch 17::Minibatch 527::LR 0.0630769230769 --> Loss 0.00226768692334\n",
      "Epoch 17::Minibatch 528::LR 0.0630769230769 --> Loss 0.00105504175027\n",
      "Epoch 17::Minibatch 529::LR 0.0630769230769 --> Loss 0.00410521745682\n",
      "Epoch 17::Minibatch 530::LR 0.0630769230769 --> Loss 0.00417240182559\n",
      "Epoch 17::Minibatch 531::LR 0.0630769230769 --> Loss 0.00367208719254\n",
      "Epoch 17::Minibatch 532::LR 0.0630769230769 --> Loss 0.002713859876\n",
      "Epoch 17::Minibatch 533::LR 0.0630769230769 --> Loss 0.00501683910688\n",
      "Epoch 17::Minibatch 534::LR 0.0630769230769 --> Loss 0.00382278323174\n",
      "Epoch 17::Minibatch 535::LR 0.0630769230769 --> Loss 0.00326608479023\n",
      "Epoch 17::Minibatch 536::LR 0.0630769230769 --> Loss 0.00210785051187\n",
      "Epoch 17::Minibatch 537::LR 0.0630769230769 --> Loss 0.000626029074192\n",
      "Epoch 17::Minibatch 538::LR 0.0630769230769 --> Loss 0.00168609281381\n",
      "Epoch 17::Minibatch 539::LR 0.0630769230769 --> Loss 0.0034225098292\n",
      "Epoch 17::Minibatch 540::LR 0.0630769230769 --> Loss 0.00341615597407\n",
      "Epoch 17::Minibatch 541::LR 0.0630769230769 --> Loss 0.00290066738923\n",
      "Epoch 17::Minibatch 542::LR 0.0630769230769 --> Loss 0.00252547899882\n",
      "Epoch 17::Minibatch 543::LR 0.0630769230769 --> Loss 0.00273427546024\n",
      "Epoch 17::Minibatch 544::LR 0.0630769230769 --> Loss 0.00391282757123\n",
      "Epoch 17::Minibatch 545::LR 0.0630769230769 --> Loss 0.00203861097495\n",
      "Epoch 17::Minibatch 546::LR 0.0630769230769 --> Loss 0.00065351848801\n",
      "Epoch 17::Minibatch 547::LR 0.0630769230769 --> Loss 0.00262395977974\n",
      "Epoch 17::Minibatch 548::LR 0.0630769230769 --> Loss 0.00369116187096\n",
      "Epoch 17::Minibatch 549::LR 0.0630769230769 --> Loss 0.00872704823812\n",
      "Epoch 17::Minibatch 550::LR 0.0630769230769 --> Loss 0.00116812884808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 551::LR 0.0630769230769 --> Loss 0.00245332956314\n",
      "Epoch 17::Minibatch 552::LR 0.0630769230769 --> Loss 0.00355316718419\n",
      "Epoch 17::Minibatch 553::LR 0.0630769230769 --> Loss 0.00319321672122\n",
      "Epoch 17::Minibatch 554::LR 0.0630769230769 --> Loss 0.0037395131588\n",
      "Epoch 17::Minibatch 555::LR 0.0630769230769 --> Loss 0.000978344380856\n",
      "Epoch 17::Minibatch 556::LR 0.0630769230769 --> Loss 0.0019883843263\n",
      "Epoch 17::Minibatch 557::LR 0.0630769230769 --> Loss 0.00244946082433\n",
      "Epoch 17::Minibatch 558::LR 0.0630769230769 --> Loss 0.00376519083977\n",
      "Epoch 17::Minibatch 559::LR 0.0630769230769 --> Loss 0.00373953819275\n",
      "Epoch 17::Minibatch 560::LR 0.0630769230769 --> Loss 0.00311689317226\n",
      "Epoch 17::Minibatch 561::LR 0.0630769230769 --> Loss 0.00270740509033\n",
      "Epoch 17::Minibatch 562::LR 0.0630769230769 --> Loss 0.00237698932489\n",
      "Epoch 17::Minibatch 563::LR 0.0630769230769 --> Loss 0.00404052337011\n",
      "Epoch 17::Minibatch 564::LR 0.0630769230769 --> Loss 0.00312279701233\n",
      "Epoch 17::Minibatch 565::LR 0.0630769230769 --> Loss 0.0036743358771\n",
      "Epoch 17::Minibatch 566::LR 0.0630769230769 --> Loss 0.00227612992128\n",
      "Epoch 17::Minibatch 567::LR 0.0630769230769 --> Loss 0.00257149259249\n",
      "Epoch 17::Minibatch 568::LR 0.0630769230769 --> Loss 0.001809669137\n",
      "Epoch 17::Minibatch 569::LR 0.0630769230769 --> Loss 0.000563668310642\n",
      "Epoch 17::Minibatch 570::LR 0.0630769230769 --> Loss 0.00169705867767\n",
      "Epoch 17::Minibatch 571::LR 0.0630769230769 --> Loss 0.00221698760986\n",
      "Epoch 17::Minibatch 572::LR 0.0630769230769 --> Loss 0.00236017286777\n",
      "Epoch 17::Minibatch 573::LR 0.0630769230769 --> Loss 0.00150191773971\n",
      "Epoch 17::Minibatch 574::LR 0.0630769230769 --> Loss 0.00104810535908\n",
      "Epoch 17::Minibatch 575::LR 0.0630769230769 --> Loss 0.00177950580915\n",
      "Epoch 17::Minibatch 576::LR 0.0630769230769 --> Loss 0.00211607972781\n",
      "Epoch 17::Minibatch 577::LR 0.0630769230769 --> Loss 0.00165823549032\n",
      "Epoch 17::Minibatch 578::LR 0.0630769230769 --> Loss 0.00128479401271\n",
      "Epoch 17::Minibatch 579::LR 0.0630769230769 --> Loss 0.00120010852814\n",
      "Epoch 17::Minibatch 580::LR 0.0630769230769 --> Loss 0.00194176117579\n",
      "Epoch 17::Minibatch 581::LR 0.0630769230769 --> Loss 0.00171581904093\n",
      "Epoch 17::Minibatch 582::LR 0.0630769230769 --> Loss 0.004126714468\n",
      "Epoch 17::Minibatch 583::LR 0.0630769230769 --> Loss 0.000941794017951\n",
      "Epoch 17::Minibatch 584::LR 0.0630769230769 --> Loss 0.00130784293016\n",
      "Epoch 17::Minibatch 585::LR 0.0630769230769 --> Loss 0.00439105590185\n",
      "Epoch 17::Minibatch 586::LR 0.0630769230769 --> Loss 0.00398890376091\n",
      "Epoch 17::Minibatch 587::LR 0.0630769230769 --> Loss 0.00112873931726\n",
      "Epoch 17::Minibatch 588::LR 0.0630769230769 --> Loss 0.00140825341145\n",
      "Epoch 17::Minibatch 589::LR 0.0630769230769 --> Loss 0.00276791552703\n",
      "Epoch 17::Minibatch 590::LR 0.0630769230769 --> Loss 0.00194710572561\n",
      "Epoch 17::Minibatch 591::LR 0.0630769230769 --> Loss 0.00302924195925\n",
      "Epoch 17::Minibatch 592::LR 0.0630769230769 --> Loss 0.00118013938268\n",
      "Epoch 17::Minibatch 593::LR 0.0630769230769 --> Loss 0.00260080397129\n",
      "Epoch 17::Minibatch 594::LR 0.0630769230769 --> Loss 0.00274953603745\n",
      "Epoch 17::Minibatch 595::LR 0.0630769230769 --> Loss 0.00305128117402\n",
      "Epoch 17::Minibatch 596::LR 0.0630769230769 --> Loss 0.00193955421448\n",
      "Epoch 17::Minibatch 597::LR 0.0630769230769 --> Loss 0.00119335234165\n",
      "Epoch 17::Minibatch 598::LR 0.0630769230769 --> Loss 0.00300384700298\n",
      "Epoch 17::Minibatch 599::LR 0.0630769230769 --> Loss 0.00186130921046\n",
      "Epoch 17::Minibatch 600::LR 0.0630769230769 --> Loss 0.00222204665343\n",
      "Epoch 17::Minibatch 601::LR 0.0630769230769 --> Loss 0.00389355818431\n",
      "Epoch 17::Minibatch 602::LR 0.0630769230769 --> Loss 0.00212091326714\n",
      "Epoch 17::Minibatch 603::LR 0.0630769230769 --> Loss 0.0026509976387\n",
      "Epoch 17::Minibatch 604::LR 0.0630769230769 --> Loss 0.00165589749813\n",
      "Epoch 17::Minibatch 605::LR 0.0630769230769 --> Loss 0.00237938821316\n",
      "Epoch 17::Minibatch 606::LR 0.0630769230769 --> Loss 0.00192483385404\n",
      "Epoch 17::Minibatch 607::LR 0.0630769230769 --> Loss 0.000845469236374\n",
      "Epoch 17::Minibatch 608::LR 0.0630769230769 --> Loss 0.0015873148044\n",
      "Epoch 17::Minibatch 609::LR 0.0630769230769 --> Loss 0.00239308973153\n",
      "Epoch 17::Minibatch 610::LR 0.0630769230769 --> Loss 0.00404141505559\n",
      "Epoch 17::Minibatch 611::LR 0.0630769230769 --> Loss 0.00264971156915\n",
      "Epoch 17::Minibatch 612::LR 0.0630769230769 --> Loss 0.000488023211559\n",
      "Epoch 17::Minibatch 613::LR 0.0630769230769 --> Loss 0.0013137704134\n",
      "Epoch 17::Minibatch 614::LR 0.0630769230769 --> Loss 0.00246263583501\n",
      "Epoch 17::Minibatch 615::LR 0.0630769230769 --> Loss 0.00168568690618\n",
      "Epoch 17::Minibatch 616::LR 0.0630769230769 --> Loss 0.000928070048491\n",
      "Epoch 17::Minibatch 617::LR 0.0630769230769 --> Loss 0.000505015999079\n",
      "Epoch 17::Minibatch 618::LR 0.0630769230769 --> Loss 0.00276662230492\n",
      "Epoch 17::Minibatch 619::LR 0.0630769230769 --> Loss 0.00192745804787\n",
      "Epoch 17::Minibatch 620::LR 0.0630769230769 --> Loss 0.00171854396661\n",
      "Epoch 17::Minibatch 621::LR 0.0630769230769 --> Loss 0.000854829748472\n",
      "Epoch 17::Minibatch 622::LR 0.0630769230769 --> Loss 0.000801939268907\n",
      "Epoch 17::Minibatch 623::LR 0.0630769230769 --> Loss 0.00222176551819\n",
      "Epoch 17::Minibatch 624::LR 0.0630769230769 --> Loss 0.00181222816308\n",
      "Epoch 17::Minibatch 625::LR 0.0630769230769 --> Loss 0.00295603454113\n",
      "Epoch 17::Minibatch 626::LR 0.0630769230769 --> Loss 0.00440466165543\n",
      "Epoch 17::Minibatch 627::LR 0.0630769230769 --> Loss 0.00132476131121\n",
      "Epoch 17::Minibatch 628::LR 0.0630769230769 --> Loss 0.000904295245806\n",
      "Epoch 17::Minibatch 629::LR 0.0630769230769 --> Loss 0.00339144706726\n",
      "Epoch 17::Minibatch 630::LR 0.0630769230769 --> Loss 0.00330534199874\n",
      "Epoch 17::Minibatch 631::LR 0.0630769230769 --> Loss 0.00637116233508\n",
      "Epoch 17::Minibatch 632::LR 0.0630769230769 --> Loss 0.000796692123016\n",
      "Epoch 17::Minibatch 633::LR 0.0630769230769 --> Loss 0.00165805160999\n",
      "Epoch 17::Minibatch 634::LR 0.0630769230769 --> Loss 0.00324909726779\n",
      "Epoch 17::Minibatch 635::LR 0.0630769230769 --> Loss 0.00528793295225\n",
      "Epoch 17::Minibatch 636::LR 0.0630769230769 --> Loss 0.00511328895887\n",
      "Epoch 17::Minibatch 637::LR 0.0630769230769 --> Loss 0.000790718297164\n",
      "Epoch 17::Minibatch 638::LR 0.0630769230769 --> Loss 0.00152308762074\n",
      "Epoch 17::Minibatch 639::LR 0.0630769230769 --> Loss 0.00331332306067\n",
      "Epoch 17::Minibatch 640::LR 0.0630769230769 --> Loss 0.00498739004135\n",
      "Epoch 17::Minibatch 641::LR 0.0630769230769 --> Loss 0.00314046800137\n",
      "Epoch 17::Minibatch 642::LR 0.0630769230769 --> Loss 0.000551127543052\n",
      "Epoch 17::Minibatch 643::LR 0.0630769230769 --> Loss 0.00234808146954\n",
      "Epoch 17::Minibatch 644::LR 0.0630769230769 --> Loss 0.00398968180021\n",
      "Epoch 17::Minibatch 645::LR 0.0630769230769 --> Loss 0.00422318379084\n",
      "Epoch 17::Minibatch 646::LR 0.0630769230769 --> Loss 0.00152166624864\n",
      "Epoch 17::Minibatch 647::LR 0.0630769230769 --> Loss 0.000532471835613\n",
      "Epoch 17::Minibatch 648::LR 0.0630769230769 --> Loss 0.00297226091226\n",
      "Epoch 17::Minibatch 649::LR 0.0630769230769 --> Loss 0.00353472709656\n",
      "Epoch 17::Minibatch 650::LR 0.0630769230769 --> Loss 0.00331760327021\n",
      "Epoch 17::Minibatch 651::LR 0.0630769230769 --> Loss 0.00138748109341\n",
      "Epoch 17::Minibatch 652::LR 0.0630769230769 --> Loss 0.000813840727011\n",
      "Epoch 17::Minibatch 653::LR 0.0630769230769 --> Loss 0.00286585410436\n",
      "Epoch 17::Minibatch 654::LR 0.0630769230769 --> Loss 0.00311678469181\n",
      "Epoch 17::Minibatch 655::LR 0.0630769230769 --> Loss 0.00350460290909\n",
      "Epoch 17::Minibatch 656::LR 0.0630769230769 --> Loss 0.000764237642288\n",
      "Epoch 17::Minibatch 657::LR 0.0630769230769 --> Loss 0.00224032084147\n",
      "Epoch 17::Minibatch 658::LR 0.0630769230769 --> Loss 0.00490611235301\n",
      "Epoch 17::Minibatch 659::LR 0.0630769230769 --> Loss 0.00231871604919\n",
      "Epoch 17::Minibatch 660::LR 0.0630769230769 --> Loss 0.00260712424914\n",
      "Epoch 17::Minibatch 661::LR 0.0630769230769 --> Loss 0.00249682505925\n",
      "Epoch 17::Minibatch 662::LR 0.0630769230769 --> Loss 0.00181968530019\n",
      "Epoch 17::Minibatch 663::LR 0.0630769230769 --> Loss 0.00367462356885\n",
      "Epoch 17::Minibatch 664::LR 0.0630769230769 --> Loss 0.00343106667201\n",
      "Epoch 17::Minibatch 665::LR 0.0630769230769 --> Loss 0.000738040258487\n",
      "Epoch 17::Minibatch 666::LR 0.0630769230769 --> Loss 0.0039327398936\n",
      "Epoch 17::Minibatch 667::LR 0.0630769230769 --> Loss 0.00255707840125\n",
      "Epoch 17::Minibatch 668::LR 0.0630769230769 --> Loss 0.00696778138479\n",
      "Epoch 17::Minibatch 669::LR 0.0630769230769 --> Loss 0.00109345803658\n",
      "Epoch 17::Minibatch 670::LR 0.0630769230769 --> Loss 0.00135687788328\n",
      "Epoch 17::Minibatch 671::LR 0.0630769230769 --> Loss 0.00536801934242\n",
      "Epoch 17::Minibatch 672::LR 0.0630769230769 --> Loss 0.0037310441335\n",
      "Epoch 17::Minibatch 673::LR 0.0630769230769 --> Loss 0.00162233223518\n",
      "Epoch 17::Minibatch 674::LR 0.0630769230769 --> Loss 0.000517428268989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 675::LR 0.0630769230769 --> Loss 0.0021888701121\n",
      "Epoch 17::Minibatch 676::LR 0.0630769230769 --> Loss 0.00212845146656\n",
      "Epoch 17::Minibatch 677::LR 0.0630769230769 --> Loss 0.00280668139458\n",
      "Epoch 17::Minibatch 678::LR 0.0630769230769 --> Loss 0.00193149209023\n",
      "Epoch 17::Minibatch 679::LR 0.0630769230769 --> Loss 0.00350542545319\n",
      "Epoch 17::Minibatch 680::LR 0.0630769230769 --> Loss 0.00214728792508\n",
      "Epoch 17::Minibatch 681::LR 0.0630769230769 --> Loss 0.00243770937125\n",
      "Epoch 17::Minibatch 682::LR 0.0630769230769 --> Loss 0.000762524207433\n",
      "Epoch 17::Minibatch 683::LR 0.0630769230769 --> Loss 0.00238022446632\n",
      "Epoch 17::Minibatch 684::LR 0.0630769230769 --> Loss 0.0023547077179\n",
      "Epoch 17::Minibatch 685::LR 0.0630769230769 --> Loss 0.00291144430637\n",
      "Epoch 17::Minibatch 686::LR 0.0630769230769 --> Loss 0.00154994348685\n",
      "Epoch 17::Minibatch 687::LR 0.0630769230769 --> Loss 0.000850126047929\n",
      "Epoch 17::Minibatch 688::LR 0.0630769230769 --> Loss 0.00276461521784\n",
      "Epoch 17::Minibatch 689::LR 0.0630769230769 --> Loss 0.00253302415212\n",
      "Epoch 17::Minibatch 690::LR 0.0630769230769 --> Loss 0.00191670139631\n",
      "Epoch 17::Minibatch 691::LR 0.0630769230769 --> Loss 0.000660845190287\n",
      "Epoch 17::Minibatch 692::LR 0.0630769230769 --> Loss 0.00247025728226\n",
      "Epoch 17::Minibatch 693::LR 0.0630769230769 --> Loss 0.00257952908675\n",
      "Epoch 17::Minibatch 694::LR 0.0630769230769 --> Loss 0.00302359720071\n",
      "Epoch 17::Minibatch 695::LR 0.0630769230769 --> Loss 0.00174283206463\n",
      "Epoch 17::Minibatch 696::LR 0.0630769230769 --> Loss 0.00204508463542\n",
      "Epoch 17::Minibatch 697::LR 0.0630769230769 --> Loss 0.00140668551127\n",
      "Epoch 17::Minibatch 698::LR 0.0630769230769 --> Loss 0.00163140018781\n",
      "Epoch 17::Minibatch 699::LR 0.0630769230769 --> Loss 0.00384322206179\n",
      "Epoch 17::Minibatch 700::LR 0.0630769230769 --> Loss 0.00267779032389\n",
      "Epoch 17::Minibatch 701::LR 0.0630769230769 --> Loss 0.00198720733325\n",
      "Epoch 17::Minibatch 702::LR 0.0630769230769 --> Loss 0.00166506260633\n",
      "Epoch 17::Minibatch 703::LR 0.0630769230769 --> Loss 0.00430517514547\n",
      "Epoch 17::Minibatch 704::LR 0.0630769230769 --> Loss 0.00180612723033\n",
      "Epoch 17::Minibatch 705::LR 0.0630769230769 --> Loss 0.00286498685678\n",
      "Epoch 17::Minibatch 706::LR 0.0630769230769 --> Loss 0.00224438587825\n",
      "Epoch 17::Minibatch 707::LR 0.0630769230769 --> Loss 0.00118395696084\n",
      "Epoch 17::Minibatch 708::LR 0.0630769230769 --> Loss 0.00173516829809\n",
      "Epoch 17::Minibatch 709::LR 0.0630769230769 --> Loss 0.00168835838636\n",
      "Epoch 17::Minibatch 710::LR 0.0630769230769 --> Loss 0.00252260128657\n",
      "Epoch 17::Minibatch 711::LR 0.0630769230769 --> Loss 0.00192639112473\n",
      "Epoch 17::Minibatch 712::LR 0.0630769230769 --> Loss 0.0013325792551\n",
      "Epoch 17::Minibatch 713::LR 0.0630769230769 --> Loss 0.0017610390981\n",
      "Epoch 17::Minibatch 714::LR 0.0630769230769 --> Loss 0.00275672654311\n",
      "Epoch 17::Minibatch 715::LR 0.0630769230769 --> Loss 0.00294215182463\n",
      "Epoch 17::Minibatch 716::LR 0.0630769230769 --> Loss 0.00161741316319\n",
      "Epoch 17::Minibatch 717::LR 0.0630769230769 --> Loss 0.00161931077639\n",
      "Epoch 17::Minibatch 718::LR 0.0630769230769 --> Loss 0.00126061240832\n",
      "Epoch 17::Minibatch 719::LR 0.0630769230769 --> Loss 0.00167092978954\n",
      "Epoch 17::Minibatch 720::LR 0.0630769230769 --> Loss 0.00255868514379\n",
      "Epoch 17::Minibatch 721::LR 0.0630769230769 --> Loss 0.000622388968865\n",
      "Epoch 17::Minibatch 722::LR 0.0630769230769 --> Loss 0.0047886856397\n",
      "Epoch 17::Minibatch 723::LR 0.0630769230769 --> Loss 0.00490767677625\n",
      "Epoch 17::Minibatch 724::LR 0.0630769230769 --> Loss 0.000969139238199\n",
      "Epoch 17::Minibatch 725::LR 0.0630769230769 --> Loss 0.00218890368938\n",
      "Epoch 17::Minibatch 726::LR 0.0630769230769 --> Loss 0.00455683072408\n",
      "Epoch 17::Minibatch 727::LR 0.0630769230769 --> Loss 0.00322051942348\n",
      "Epoch 17::Minibatch 728::LR 0.0630769230769 --> Loss 0.000646932969491\n",
      "Epoch 17::Minibatch 729::LR 0.0630769230769 --> Loss 0.000748325983683\n",
      "Epoch 17::Minibatch 730::LR 0.0630769230769 --> Loss 0.00279243131479\n",
      "Epoch 17::Minibatch 731::LR 0.0630769230769 --> Loss 0.00249984363715\n",
      "Epoch 17::Minibatch 732::LR 0.0630769230769 --> Loss 0.00221739649773\n",
      "Epoch 17::Minibatch 733::LR 0.0630769230769 --> Loss 0.000678310543299\n",
      "Epoch 17::Minibatch 734::LR 0.0630769230769 --> Loss 0.00174530386925\n",
      "Epoch 17::Minibatch 735::LR 0.0630769230769 --> Loss 0.00236408829689\n",
      "Epoch 17::Minibatch 736::LR 0.0630769230769 --> Loss 0.00346840063731\n",
      "Epoch 17::Minibatch 737::LR 0.0630769230769 --> Loss 0.00307364920775\n",
      "Epoch 17::Minibatch 738::LR 0.0630769230769 --> Loss 0.00158099253972\n",
      "Epoch 17::Minibatch 739::LR 0.0630769230769 --> Loss 0.00247492631276\n",
      "Epoch 17::Minibatch 740::LR 0.0630769230769 --> Loss 0.00385123133659\n",
      "Epoch 17::Minibatch 741::LR 0.0630769230769 --> Loss 0.0026811559995\n",
      "Epoch 17::Minibatch 742::LR 0.0630769230769 --> Loss 0.00211260974407\n",
      "Epoch 17::Minibatch 743::LR 0.0630769230769 --> Loss 0.00139621327321\n",
      "Epoch 17::Minibatch 744::LR 0.0630769230769 --> Loss 0.0018029542764\n",
      "Epoch 17::Minibatch 745::LR 0.0630769230769 --> Loss 0.00284169256687\n",
      "Epoch 17::Minibatch 746::LR 0.0630769230769 --> Loss 0.00298069953918\n",
      "Epoch 17::Minibatch 747::LR 0.0630769230769 --> Loss 0.00179345031579\n",
      "Epoch 17::Minibatch 748::LR 0.0630769230769 --> Loss 0.00062880858779\n",
      "Epoch 17::Minibatch 749::LR 0.0630769230769 --> Loss 0.00165103137493\n",
      "Epoch 17::Minibatch 750::LR 0.0630769230769 --> Loss 0.00246753633022\n",
      "Epoch 17::Minibatch 751::LR 0.0630769230769 --> Loss 0.00275432209174\n",
      "Epoch 17::Minibatch 752::LR 0.0630769230769 --> Loss 0.00120020459096\n",
      "Epoch 17::Minibatch 753::LR 0.0630769230769 --> Loss 0.00222830136617\n",
      "Epoch 17::Minibatch 754::LR 0.0630769230769 --> Loss 0.00240041732788\n",
      "Epoch 17::Minibatch 755::LR 0.0630769230769 --> Loss 0.00266738633315\n",
      "Epoch 17::Minibatch 756::LR 0.0630769230769 --> Loss 0.00138353168964\n",
      "Epoch 17::Minibatch 757::LR 0.0630769230769 --> Loss 0.000775885234276\n",
      "Epoch 17::Minibatch 758::LR 0.0630769230769 --> Loss 0.00161245505015\n",
      "Epoch 17::Minibatch 759::LR 0.0630769230769 --> Loss 0.00373001178106\n",
      "Epoch 17::Minibatch 760::LR 0.0630769230769 --> Loss 0.00299652357896\n",
      "Epoch 17::Minibatch 761::LR 0.0630769230769 --> Loss 0.00624394536018\n",
      "Epoch 17::Minibatch 762::LR 0.0630769230769 --> Loss 0.00374614715576\n",
      "Epoch 17::Minibatch 763::LR 0.0630769230769 --> Loss 0.00354338447253\n",
      "Epoch 17::Minibatch 764::LR 0.0630769230769 --> Loss 0.0031655673186\n",
      "Epoch 17::Minibatch 765::LR 0.0630769230769 --> Loss 0.00130783071121\n",
      "Epoch 17::Minibatch 766::LR 0.0630769230769 --> Loss 0.0022756177187\n",
      "Epoch 17::Minibatch 767::LR 0.0630769230769 --> Loss 0.00498207012812\n",
      "Epoch 17::Minibatch 768::LR 0.0630769230769 --> Loss 0.00361952821414\n",
      "Epoch 17::Minibatch 769::LR 0.0630769230769 --> Loss 0.00188526749611\n",
      "Epoch 17::Minibatch 770::LR 0.0630769230769 --> Loss 0.00148195664088\n",
      "Epoch 17::Minibatch 771::LR 0.0630769230769 --> Loss 0.00367714802424\n",
      "Epoch 17::Minibatch 772::LR 0.0630769230769 --> Loss 0.00341339151065\n",
      "Epoch 17::Minibatch 773::LR 0.0630769230769 --> Loss 0.00313254217307\n",
      "Epoch 17::Minibatch 774::LR 0.0630769230769 --> Loss 0.00179197470347\n",
      "Epoch 17::Minibatch 775::LR 0.0630769230769 --> Loss 0.00379008491834\n",
      "Epoch 17::Minibatch 776::LR 0.0630769230769 --> Loss 0.00358181277911\n",
      "Epoch 17::Minibatch 777::LR 0.0630769230769 --> Loss 0.00737186988195\n",
      "Epoch 17::Minibatch 778::LR 0.0630769230769 --> Loss 0.00931253592173\n",
      "Epoch 17::Minibatch 779::LR 0.0630769230769 --> Loss 0.0023076881965\n",
      "Epoch 17::Minibatch 780::LR 0.0630769230769 --> Loss 0.00160007725159\n",
      "Epoch 17::Minibatch 781::LR 0.0630769230769 --> Loss 0.00345442374547\n",
      "Epoch 17::Minibatch 782::LR 0.0630769230769 --> Loss 0.00396725575129\n",
      "Epoch 17::Minibatch 783::LR 0.0630769230769 --> Loss 0.00230517625809\n",
      "Epoch 17::Minibatch 784::LR 0.0630769230769 --> Loss 0.000718713253736\n",
      "Epoch 17::Minibatch 785::LR 0.0630769230769 --> Loss 0.00343447208405\n",
      "Epoch 17::Minibatch 786::LR 0.0630769230769 --> Loss 0.00345955570539\n",
      "Epoch 17::Minibatch 787::LR 0.0630769230769 --> Loss 0.00269769529502\n",
      "Epoch 17::Minibatch 788::LR 0.0630769230769 --> Loss 0.00239656786124\n",
      "Epoch 17::Minibatch 789::LR 0.0630769230769 --> Loss 0.000737242897352\n",
      "Epoch 17::Minibatch 790::LR 0.0630769230769 --> Loss 0.00316768924395\n",
      "Epoch 17::Minibatch 791::LR 0.0630769230769 --> Loss 0.0035445868969\n",
      "Epoch 17::Minibatch 792::LR 0.0630769230769 --> Loss 0.00314371724923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 793::LR 0.0630769230769 --> Loss 0.00177250126998\n",
      "Epoch 17::Minibatch 794::LR 0.0630769230769 --> Loss 0.00102365771929\n",
      "Epoch 17::Minibatch 795::LR 0.0630769230769 --> Loss 0.00298802236716\n",
      "Epoch 17::Minibatch 796::LR 0.0630769230769 --> Loss 0.00558332641919\n",
      "Epoch 17::Minibatch 797::LR 0.0630769230769 --> Loss 0.00719243367513\n",
      "Epoch 17::Minibatch 798::LR 0.0630769230769 --> Loss 0.00328520139058\n",
      "Epoch 17::Minibatch 799::LR 0.0630769230769 --> Loss 0.0023505906264\n",
      "Epoch 17::Minibatch 800::LR 0.0630769230769 --> Loss 0.00201834738255\n",
      "Epoch 17::Minibatch 801::LR 0.0630769230769 --> Loss 0.00414861480395\n",
      "Epoch 17::Minibatch 802::LR 0.0630769230769 --> Loss 0.00130138268073\n",
      "Epoch 17::Minibatch 803::LR 0.0630769230769 --> Loss 0.00286174277465\n",
      "Epoch 17::Minibatch 804::LR 0.0630769230769 --> Loss 0.00216597000758\n",
      "Epoch 17::Minibatch 805::LR 0.0630769230769 --> Loss 0.00226175487041\n",
      "Epoch 17::Minibatch 806::LR 0.0630769230769 --> Loss 0.00334126989047\n",
      "Epoch 17::Minibatch 807::LR 0.0630769230769 --> Loss 0.00303141792615\n",
      "Epoch 17::Minibatch 808::LR 0.0630769230769 --> Loss 0.00268167297045\n",
      "Epoch 17::Minibatch 809::LR 0.0630769230769 --> Loss 0.00366894761721\n",
      "Epoch 17::Minibatch 810::LR 0.0630769230769 --> Loss 0.0049582072099\n",
      "Epoch 17::Minibatch 811::LR 0.0630769230769 --> Loss 0.00468707879384\n",
      "Epoch 17::Minibatch 812::LR 0.0630769230769 --> Loss 0.00429314533869\n",
      "Epoch 17::Minibatch 813::LR 0.0630769230769 --> Loss 0.00376599470774\n",
      "Epoch 17::Minibatch 814::LR 0.0630769230769 --> Loss 0.00173843383789\n",
      "Epoch 17::Minibatch 815::LR 0.0630769230769 --> Loss 0.00376917004585\n",
      "Epoch 17::Minibatch 816::LR 0.0630769230769 --> Loss 0.00413324753443\n",
      "Epoch 17::Minibatch 817::LR 0.0630769230769 --> Loss 0.00551888982455\n",
      "Epoch 17::Minibatch 818::LR 0.0630769230769 --> Loss 0.00126674711704\n",
      "Epoch 17::Minibatch 819::LR 0.0630769230769 --> Loss 0.000707125862439\n",
      "Epoch 17::Minibatch 820::LR 0.0630769230769 --> Loss 0.00531568368276\n",
      "Epoch 17::Minibatch 821::LR 0.0630769230769 --> Loss 0.00314440369606\n",
      "Epoch 17::Minibatch 822::LR 0.0630769230769 --> Loss 0.00371281107267\n",
      "Epoch 17::Minibatch 823::LR 0.0630769230769 --> Loss 0.00129494478305\n",
      "Epoch 17::Minibatch 824::LR 0.0630769230769 --> Loss 0.00138188362122\n",
      "Epoch 17::Minibatch 825::LR 0.0630769230769 --> Loss 0.00367581645648\n",
      "Epoch 17::Minibatch 826::LR 0.0630769230769 --> Loss 0.00395530700684\n",
      "Epoch 17::Minibatch 827::LR 0.0630769230769 --> Loss 0.00210891902447\n",
      "Epoch 17::Minibatch 828::LR 0.0630769230769 --> Loss 0.000542532503605\n",
      "Epoch 17::Minibatch 829::LR 0.0630769230769 --> Loss 0.00236905594667\n",
      "Epoch 17::Minibatch 830::LR 0.0630769230769 --> Loss 0.00433744311333\n",
      "Epoch 17::Minibatch 831::LR 0.0630769230769 --> Loss 0.00254908263683\n",
      "Epoch 17::Minibatch 832::LR 0.0630769230769 --> Loss 0.0022318259875\n",
      "Epoch 17::Minibatch 833::LR 0.0630769230769 --> Loss 0.00184270560741\n",
      "Epoch 17::Minibatch 834::LR 0.0630769230769 --> Loss 0.000774135291576\n",
      "Epoch 17::Minibatch 835::LR 0.0630769230769 --> Loss 0.00379130562147\n",
      "Epoch 17::Minibatch 836::LR 0.0630769230769 --> Loss 0.00369490742683\n",
      "Epoch 17::Minibatch 837::LR 0.0630769230769 --> Loss 0.00218958934148\n",
      "Epoch 17::Minibatch 838::LR 0.0630769230769 --> Loss 0.000629986425241\n",
      "Epoch 17::Minibatch 839::LR 0.0630769230769 --> Loss 0.00246064503988\n",
      "Epoch 17::Minibatch 840::LR 0.0630769230769 --> Loss 0.00289342323939\n",
      "Epoch 17::Minibatch 841::LR 0.0630769230769 --> Loss 0.00282351116339\n",
      "Epoch 17::Minibatch 842::LR 0.0630769230769 --> Loss 0.00207659463088\n",
      "Epoch 17::Minibatch 843::LR 0.0630769230769 --> Loss 0.00100392808517\n",
      "Epoch 17::Minibatch 844::LR 0.0630769230769 --> Loss 0.00149010618528\n",
      "Epoch 17::Minibatch 845::LR 0.0630769230769 --> Loss 0.00430561820666\n",
      "Epoch 17::Minibatch 846::LR 0.0630769230769 --> Loss 0.00167583703995\n",
      "Epoch 17::Minibatch 847::LR 0.0630769230769 --> Loss 0.00227579176426\n",
      "Epoch 17::Minibatch 848::LR 0.0630769230769 --> Loss 0.00101112902164\n",
      "Epoch 17::Minibatch 849::LR 0.0630769230769 --> Loss 0.00183257520199\n",
      "Epoch 17::Minibatch 850::LR 0.0630769230769 --> Loss 0.00317398428917\n",
      "Epoch 17::Minibatch 851::LR 0.0630769230769 --> Loss 0.00265223503113\n",
      "Epoch 17::Minibatch 852::LR 0.0630769230769 --> Loss 0.00107557535172\n",
      "Epoch 17::Minibatch 853::LR 0.0630769230769 --> Loss 0.00130558629831\n",
      "Epoch 17::Minibatch 854::LR 0.0630769230769 --> Loss 0.00256924331188\n",
      "Epoch 17::Minibatch 855::LR 0.0630769230769 --> Loss 0.00216580490271\n",
      "Epoch 17::Minibatch 856::LR 0.0630769230769 --> Loss 0.00179350713889\n",
      "Epoch 17::Minibatch 857::LR 0.0630769230769 --> Loss 0.00121302892764\n",
      "Epoch 17::Minibatch 858::LR 0.0630769230769 --> Loss 0.000593646665414\n",
      "Epoch 17::Minibatch 859::LR 0.0630769230769 --> Loss 0.00191089630127\n",
      "Epoch 17::Minibatch 860::LR 0.0630769230769 --> Loss 0.00124738017718\n",
      "Epoch 17::Minibatch 861::LR 0.0630769230769 --> Loss 0.000934811631838\n",
      "Epoch 17::Minibatch 862::LR 0.0630769230769 --> Loss 0.00364095131556\n",
      "Epoch 17::Minibatch 863::LR 0.0630769230769 --> Loss 0.00341413299243\n",
      "Epoch 17::Minibatch 864::LR 0.0630769230769 --> Loss 0.00285476505756\n",
      "Epoch 17::Minibatch 865::LR 0.0630769230769 --> Loss 0.000441167404254\n",
      "Epoch 17::Minibatch 866::LR 0.0630769230769 --> Loss 0.00214022874832\n",
      "Epoch 17::Minibatch 867::LR 0.0630769230769 --> Loss 0.0029644972086\n",
      "Epoch 17::Minibatch 868::LR 0.0630769230769 --> Loss 0.00243904749552\n",
      "Epoch 17::Minibatch 869::LR 0.0630769230769 --> Loss 0.00211190720399\n",
      "Epoch 17::Minibatch 870::LR 0.0630769230769 --> Loss 0.00352589845657\n",
      "Epoch 17::Minibatch 871::LR 0.0630769230769 --> Loss 0.00152841935555\n",
      "Epoch 17::Minibatch 872::LR 0.0630769230769 --> Loss 0.00225632091363\n",
      "Epoch 17::Minibatch 873::LR 0.0630769230769 --> Loss 0.00246945440769\n",
      "Epoch 17::Minibatch 874::LR 0.0630769230769 --> Loss 0.0060991704464\n",
      "Epoch 17::Minibatch 875::LR 0.0630769230769 --> Loss 0.000525297025839\n",
      "Epoch 17::Minibatch 876::LR 0.0630769230769 --> Loss 0.00316505650679\n",
      "Epoch 17::Minibatch 877::LR 0.0630769230769 --> Loss 0.00569614926974\n",
      "Epoch 17::Minibatch 878::LR 0.0630769230769 --> Loss 0.00321477969488\n",
      "Epoch 17::Minibatch 879::LR 0.0630769230769 --> Loss 0.00399325927099\n",
      "Epoch 17::Minibatch 880::LR 0.0630769230769 --> Loss 0.00479594508807\n",
      "Epoch 17::Minibatch 881::LR 0.0630769230769 --> Loss 0.00427467465401\n",
      "Epoch 17::Minibatch 882::LR 0.0630769230769 --> Loss 0.00196647683779\n",
      "Epoch 17::Minibatch 883::LR 0.0630769230769 --> Loss 0.00342288970947\n",
      "Epoch 17::Minibatch 884::LR 0.0630769230769 --> Loss 0.00271114806334\n",
      "Epoch 17::Minibatch 885::LR 0.0630769230769 --> Loss 0.00253004670143\n",
      "Epoch 17::Minibatch 886::LR 0.0630769230769 --> Loss 0.00050242587924\n",
      "Epoch 17::Minibatch 887::LR 0.0630769230769 --> Loss 0.00527483423551\n",
      "Epoch 17::Minibatch 888::LR 0.0630769230769 --> Loss 0.00261497735977\n",
      "Epoch 17::Minibatch 889::LR 0.0630769230769 --> Loss 0.00281814038754\n",
      "Epoch 17::Minibatch 890::LR 0.0630769230769 --> Loss 0.00416992863019\n",
      "Epoch 17::Minibatch 891::LR 0.0630769230769 --> Loss 0.00185332357883\n",
      "Epoch 17::Minibatch 892::LR 0.0630769230769 --> Loss 0.000858968993028\n",
      "Epoch 17::Minibatch 893::LR 0.0630769230769 --> Loss 0.00243294099967\n",
      "Epoch 17::Minibatch 894::LR 0.0630769230769 --> Loss 0.00215256849925\n",
      "Epoch 17::Minibatch 895::LR 0.0630769230769 --> Loss 0.00239669640859\n",
      "Epoch 17::Minibatch 896::LR 0.0630769230769 --> Loss 0.00126738488674\n",
      "Epoch 17::Minibatch 897::LR 0.0630769230769 --> Loss 0.000711881071329\n",
      "Epoch 17::Minibatch 898::LR 0.0630769230769 --> Loss 0.00213147540887\n",
      "Epoch 17::Minibatch 899::LR 0.0630769230769 --> Loss 0.00247639020284\n",
      "Epoch 17::Minibatch 900::LR 0.0630769230769 --> Loss 0.00321854372819\n",
      "Epoch 17::Minibatch 901::LR 0.0630769230769 --> Loss 0.000593898892403\n",
      "Epoch 17::Minibatch 902::LR 0.0630769230769 --> Loss 0.00141705920299\n",
      "Epoch 17::Minibatch 903::LR 0.0630769230769 --> Loss 0.00256426513195\n",
      "Epoch 17::Minibatch 904::LR 0.0630769230769 --> Loss 0.0019260464112\n",
      "Epoch 17::Minibatch 905::LR 0.0630769230769 --> Loss 0.00143545687199\n",
      "Epoch 17::Minibatch 906::LR 0.0630769230769 --> Loss 0.00107864568631\n",
      "Epoch 17::Minibatch 907::LR 0.0630769230769 --> Loss 0.0015852205952\n",
      "Epoch 17::Minibatch 908::LR 0.0630769230769 --> Loss 0.0021767604351\n",
      "Epoch 17::Minibatch 909::LR 0.0630769230769 --> Loss 0.00199786067009\n",
      "Epoch 17::Minibatch 910::LR 0.0630769230769 --> Loss 0.000833547115326\n",
      "Epoch 17::Minibatch 911::LR 0.0630769230769 --> Loss 0.00123494774103\n",
      "Epoch 17::Minibatch 912::LR 0.0630769230769 --> Loss 0.00198983987172\n",
      "Epoch 17::Minibatch 913::LR 0.0630769230769 --> Loss 0.00216246525447\n",
      "Epoch 17::Minibatch 914::LR 0.0630769230769 --> Loss 0.00117245147626\n",
      "Epoch 17::Minibatch 915::LR 0.0630769230769 --> Loss 0.000492318520943\n",
      "Epoch 17::Minibatch 916::LR 0.0630769230769 --> Loss 0.00226271053155\n",
      "Epoch 17::Minibatch 917::LR 0.0630769230769 --> Loss 0.0037346971035\n",
      "Epoch 17::Minibatch 918::LR 0.0630769230769 --> Loss 0.00575965563456\n",
      "Epoch 17::Minibatch 919::LR 0.0630769230769 --> Loss 0.000574594140053\n",
      "Epoch 17::Minibatch 920::LR 0.0630769230769 --> Loss 0.0116703335444\n",
      "Epoch 17::Minibatch 921::LR 0.0630769230769 --> Loss 0.00280797123909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17::Minibatch 922::LR 0.0630769230769 --> Loss 0.00297551631927\n",
      "Epoch 17::Minibatch 923::LR 0.0630769230769 --> Loss 0.00146839360396\n",
      "Epoch 17::Minibatch 924::LR 0.0630769230769 --> Loss 0.00345237096151\n",
      "Epoch 17::Minibatch 925::LR 0.0630769230769 --> Loss 0.00237490534782\n",
      "Epoch 17::Minibatch 926::LR 0.0630769230769 --> Loss 0.00525688529015\n",
      "Epoch 17::Minibatch 927::LR 0.0630769230769 --> Loss 0.00749924103419\n",
      "Epoch 17::Minibatch 928::LR 0.0630769230769 --> Loss 0.00639940897624\n",
      "Epoch 17::Minibatch 929::LR 0.0630769230769 --> Loss 0.00668045759201\n",
      "Epoch 17::Minibatch 930::LR 0.0630769230769 --> Loss 0.00961574713389\n",
      "Epoch 17::Minibatch 931::LR 0.0630769230769 --> Loss 0.00348981698354\n",
      "Epoch 17::Minibatch 932::LR 0.0630769230769 --> Loss 0.00697757323583\n",
      "Epoch 17::Minibatch 933::LR 0.0630769230769 --> Loss 0.00345464984576\n",
      "Epoch 17::Minibatch 934::LR 0.0630769230769 --> Loss 0.00454529086749\n",
      "Epoch 17::Minibatch 935::LR 0.0630769230769 --> Loss 0.0063781106472\n",
      "Epoch 17::Minibatch 936::LR 0.0630769230769 --> Loss 0.00150502085686\n",
      "Epoch 17::Minibatch 937::LR 0.0630769230769 --> Loss 0.00331767082214\n",
      "Epoch 17::Minibatch 938::LR 0.0630769230769 --> Loss 0.00301252146562\n",
      "Epoch 17::Minibatch 939::LR 0.0630769230769 --> Loss 0.0030879487594\n",
      "Epoch 17::Minibatch 940::LR 0.0630769230769 --> Loss 0.00103119065364\n",
      "Epoch 17::Minibatch 941::LR 0.0630769230769 --> Loss 0.000844494005044\n",
      "Epoch 17::Minibatch 942::LR 0.0630769230769 --> Loss 0.00245716015498\n",
      "Epoch 17::Minibatch 943::LR 0.0630769230769 --> Loss 0.00289491136869\n",
      "Epoch 17::Minibatch 944::LR 0.0630769230769 --> Loss 0.00208741724491\n",
      "Epoch 17::Minibatch 945::LR 0.0630769230769 --> Loss 0.00121242503325\n",
      "Epoch 17::Minibatch 946::LR 0.0630769230769 --> Loss 0.00309954424699\n",
      "Epoch 17::Minibatch 947::LR 0.0630769230769 --> Loss 0.00276804327965\n",
      "Epoch 17::Minibatch 948::LR 0.0630769230769 --> Loss 0.00514657775561\n",
      "Epoch 17::Minibatch 949::LR 0.0630769230769 --> Loss 0.00188371062279\n",
      "Epoch 17::Minibatch 950::LR 0.0630769230769 --> Loss 0.000735979576906\n",
      "Epoch 17::Minibatch 951::LR 0.0630769230769 --> Loss 0.00340338587761\n",
      "Epoch 17::Minibatch 952::LR 0.0630769230769 --> Loss 0.00243885179361\n",
      "Epoch 17::Minibatch 953::LR 0.0630769230769 --> Loss 0.00139071116845\n",
      "Epoch 17::Minibatch 954::LR 0.0630769230769 --> Loss 0.000961914559205\n",
      "Epoch 17::Minibatch 955::LR 0.0630769230769 --> Loss 0.00254302521547\n",
      "Epoch 17::Minibatch 956::LR 0.0630769230769 --> Loss 0.00377017855644\n",
      "Epoch 17::Minibatch 957::LR 0.0630769230769 --> Loss 0.00189545651277\n",
      "Epoch 17::Minibatch 958::LR 0.0630769230769 --> Loss 0.00231775144736\n",
      "Epoch 17::Minibatch 959::LR 0.0630769230769 --> Loss 0.00285913864772\n",
      "Epoch 17::Minibatch 960::LR 0.0630769230769 --> Loss 0.00634209156036\n",
      "Epoch 17::Minibatch 961::LR 0.0630769230769 --> Loss 0.0033232764403\n",
      "Epoch 17::Minibatch 962::LR 0.0630769230769 --> Loss 0.00285850842794\n",
      "Epoch 17::Minibatch 963::LR 0.0630769230769 --> Loss 0.00103195856015\n",
      "Epoch 17::Minibatch 964::LR 0.0630769230769 --> Loss 0.00239607175191\n",
      "Epoch 17::Minibatch 965::LR 0.0630769230769 --> Loss 0.00734444538752\n",
      "Epoch 17::Minibatch 966::LR 0.0630769230769 --> Loss 0.00514420787493\n",
      "Epoch 17::Minibatch 967::LR 0.0630769230769 --> Loss 0.00154870112737\n",
      "Epoch 17::Minibatch 968::LR 0.0630769230769 --> Loss 0.00138357629379\n",
      "Epoch 17::Minibatch 969::LR 0.0630769230769 --> Loss 0.00634845574697\n",
      "Epoch 17::Minibatch 970::LR 0.0630769230769 --> Loss 0.00568414648374\n",
      "Epoch 17::Minibatch 971::LR 0.0630769230769 --> Loss 0.0035289033254\n",
      "Epoch 17::Minibatch 972::LR 0.0630769230769 --> Loss 0.00972756147385\n",
      "Epoch 17::Minibatch 973::LR 0.0630769230769 --> Loss 0.00903300046921\n",
      "Epoch 17::Minibatch 974::LR 0.0630769230769 --> Loss 0.00814218600591\n",
      "Epoch 17::Minibatch 975::LR 0.0630769230769 --> Loss 0.00471639235814\n",
      "Epoch 17::Minibatch 976::LR 0.0630769230769 --> Loss 0.00427616039912\n",
      "Epoch 17::Minibatch 977::LR 0.0630769230769 --> Loss 0.00429988781611\n",
      "Epoch 17::Minibatch 978::LR 0.0630769230769 --> Loss 0.00430818239848\n",
      "Epoch 17::Minibatch 979::LR 0.0630769230769 --> Loss 0.00427916208903\n",
      "Epoch 17::Minibatch 980::LR 0.0630769230769 --> Loss 0.00415526032448\n",
      "Epoch 17::Minibatch 981::LR 0.0630769230769 --> Loss 0.00546545664469\n",
      "Epoch 17::Minibatch 982::LR 0.0630769230769 --> Loss 0.0068851463\n",
      "Epoch 17::Minibatch 983::LR 0.0630769230769 --> Loss 0.00317781349023\n",
      "Epoch 17::Minibatch 984::LR 0.0630769230769 --> Loss 0.00285165727139\n",
      "Epoch 17::Minibatch 985::LR 0.0630769230769 --> Loss 0.00463373144468\n",
      "Epoch 17::Minibatch 986::LR 0.0630769230769 --> Loss 0.00428714474042\n",
      "Epoch 17::Minibatch 987::LR 0.0630769230769 --> Loss 0.00457706530889\n",
      "Epoch 17::Minibatch 988::LR 0.0630769230769 --> Loss 0.00362831751506\n",
      "Epoch 17::Minibatch 989::LR 0.0630769230769 --> Loss 0.00370964606603\n",
      "Epoch 17::Minibatch 990::LR 0.0630769230769 --> Loss 0.00332573473454\n",
      "Epoch 17::Minibatch 991::LR 0.0630769230769 --> Loss 0.00195499519507\n",
      "Epoch 17::Minibatch 992::LR 0.0630769230769 --> Loss 0.00210792601109\n",
      "Epoch 17::Minibatch 993::LR 0.0630769230769 --> Loss 0.00366369167964\n",
      "Epoch 17::Minibatch 994::LR 0.0630769230769 --> Loss 0.00226952672005\n",
      "Epoch 17::Minibatch 995::LR 0.0630769230769 --> Loss 0.000962561865648\n",
      "Epoch 17::Minibatch 996::LR 0.0630769230769 --> Loss 0.00322628657023\n",
      "Epoch 17::Minibatch 997::LR 0.0630769230769 --> Loss 0.00240020314852\n",
      "Epoch 17::Minibatch 998::LR 0.0630769230769 --> Loss 0.00264433940252\n",
      "Epoch 17::Minibatch 999::LR 0.0630769230769 --> Loss 0.00216028908888\n",
      "Epoch 17::Minibatch 1000::LR 0.0630769230769 --> Loss 0.00255073964596\n",
      "Epoch 17::Minibatch 1001::LR 0.0630769230769 --> Loss 0.00209407190482\n",
      "Epoch 17::Minibatch 1002::LR 0.0630769230769 --> Loss 0.00257108926773\n",
      "Epoch 17::Minibatch 1003::LR 0.0630769230769 --> Loss 0.00356504122416\n",
      "Epoch 17::Minibatch 1004::LR 0.0630769230769 --> Loss 0.00113245596488\n",
      "Epoch 17::Minibatch 1005::LR 0.0630769230769 --> Loss 0.00370285828908\n",
      "Epoch 17::Minibatch 1006::LR 0.0630769230769 --> Loss 0.00226855258147\n",
      "Epoch 17::Minibatch 1007::LR 0.0630769230769 --> Loss 0.00262011190255\n",
      "Epoch 17::Minibatch 1008::LR 0.0630769230769 --> Loss 0.00103429704905\n",
      "Epoch 17::Minibatch 1009::LR 0.0630769230769 --> Loss 0.00156810422738\n",
      "Epoch 17::Minibatch 1010::LR 0.0630769230769 --> Loss 0.00135730445385\n",
      "Epoch 17::Minibatch 1011::LR 0.0630769230769 --> Loss 0.002387723128\n",
      "Epoch 17::Minibatch 1012::LR 0.0630769230769 --> Loss 0.00169003864129\n",
      "Epoch 17::Minibatch 1013::LR 0.0630769230769 --> Loss 0.00437863032023\n",
      "Epoch 17::Minibatch 1014::LR 0.0630769230769 --> Loss 0.00415422399839\n",
      "Epoch 17::Minibatch 1015::LR 0.0630769230769 --> Loss 0.00175177097321\n",
      "Epoch 17::Minibatch 1016::LR 0.0630769230769 --> Loss 0.00501182874044\n",
      "Epoch 17::Minibatch 1017::LR 0.0630769230769 --> Loss 0.0026554509004\n",
      "Epoch 17::Minibatch 1018::LR 0.0630769230769 --> Loss 0.00295583049456\n",
      "Epoch 17::Minibatch 1019::LR 0.0630769230769 --> Loss 0.00200714568297\n",
      "Epoch 17::Minibatch 1020::LR 0.0630769230769 --> Loss 0.00201331694921\n",
      "Epoch 17::Minibatch 1021::LR 0.0630769230769 --> Loss 0.00202579140663\n",
      "Epoch 17::Minibatch 1022::LR 0.0630769230769 --> Loss 0.00152752796809\n",
      "Epoch 17::Minibatch 1023::LR 0.0630769230769 --> Loss 0.00117943247159\n",
      "Epoch 17::Minibatch 1024::LR 0.0630769230769 --> Loss 0.00115589052439\n",
      "Epoch 17::Minibatch 1025::LR 0.0630769230769 --> Loss 0.00141799072425\n",
      "Epoch 17::Minibatch 1026::LR 0.0630769230769 --> Loss 0.000823509742816\n",
      "Epoch 17::Minibatch 1027::LR 0.0630769230769 --> Loss 0.00104010810455\n",
      "Epoch 17::Minibatch 1028::LR 0.0630769230769 --> Loss 0.000797421435515\n",
      "Epoch 17::Minibatch 1029::LR 0.0630769230769 --> Loss 0.000782080044349\n",
      "Epoch 17::Minibatch 1030::LR 0.0630769230769 --> Loss 0.000964798132579\n",
      "Epoch 17::Minibatch 1031::LR 0.0630769230769 --> Loss 0.000751671592395\n",
      "Epoch 17::Minibatch 1032::LR 0.0630769230769 --> Loss 0.000782609581947\n",
      "Epoch 17::Minibatch 1033::LR 0.0630769230769 --> Loss 0.000666214724382\n",
      "Epoch 17::Minibatch 1034::LR 0.0630769230769 --> Loss 0.000645238856475\n",
      "Epoch 17::Minibatch 1035::LR 0.0630769230769 --> Loss 0.000455393145482\n",
      "Epoch 17::Minibatch 1036::LR 0.0630769230769 --> Loss 0.000362935413917\n",
      "Epoch 17::Minibatch 1037::LR 0.0630769230769 --> Loss 0.000580231597026\n",
      "Epoch 17::Minibatch 1038::LR 0.0630769230769 --> Loss 0.00128244370222\n",
      "Epoch 17::Minibatch 1039::LR 0.0630769230769 --> Loss 0.000986501177152\n",
      "Epoch 17::Minibatch 1040::LR 0.0630769230769 --> Loss 0.000415193587542\n",
      "Epoch 17::Minibatch 1041::LR 0.0630769230769 --> Loss 0.000583371520042\n",
      "Epoch 18::Minibatch 1::LR 0.0607692307692 --> Loss 0.00933805306753\n",
      "Epoch 18::Minibatch 2::LR 0.0607692307692 --> Loss 0.00598983208338\n",
      "Epoch 18::Minibatch 3::LR 0.0607692307692 --> Loss 0.00391916116079\n",
      "Epoch 18::Minibatch 4::LR 0.0607692307692 --> Loss 0.00434550444285\n",
      "Epoch 18::Minibatch 5::LR 0.0607692307692 --> Loss 0.0047143471241\n",
      "Epoch 18::Minibatch 6::LR 0.0607692307692 --> Loss 0.00238607486089\n",
      "Epoch 18::Minibatch 7::LR 0.0607692307692 --> Loss 0.00775156180064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 8::LR 0.0607692307692 --> Loss 0.00744590441386\n",
      "Epoch 18::Minibatch 9::LR 0.0607692307692 --> Loss 0.00547447999318\n",
      "Epoch 18::Minibatch 10::LR 0.0607692307692 --> Loss 0.00277085761229\n",
      "Epoch 18::Minibatch 11::LR 0.0607692307692 --> Loss 0.00242952863375\n",
      "Epoch 18::Minibatch 12::LR 0.0607692307692 --> Loss 0.00354637861252\n",
      "Epoch 18::Minibatch 13::LR 0.0607692307692 --> Loss 0.00536814212799\n",
      "Epoch 18::Minibatch 14::LR 0.0607692307692 --> Loss 0.00527255177498\n",
      "Epoch 18::Minibatch 15::LR 0.0607692307692 --> Loss 0.00440006017685\n",
      "Epoch 18::Minibatch 16::LR 0.0607692307692 --> Loss 0.000874253114065\n",
      "Epoch 18::Minibatch 17::LR 0.0607692307692 --> Loss 0.00314867516359\n",
      "Epoch 18::Minibatch 18::LR 0.0607692307692 --> Loss 0.00254294772943\n",
      "Epoch 18::Minibatch 19::LR 0.0607692307692 --> Loss 0.00131087432305\n",
      "Epoch 18::Minibatch 20::LR 0.0607692307692 --> Loss 0.00180022239685\n",
      "Epoch 18::Minibatch 21::LR 0.0607692307692 --> Loss 0.0032741155227\n",
      "Epoch 18::Minibatch 22::LR 0.0607692307692 --> Loss 0.00228560129801\n",
      "Epoch 18::Minibatch 23::LR 0.0607692307692 --> Loss 0.000794345537821\n",
      "Epoch 18::Minibatch 24::LR 0.0607692307692 --> Loss 0.000381604532401\n",
      "Epoch 18::Minibatch 25::LR 0.0607692307692 --> Loss 0.00113480180502\n",
      "Epoch 18::Minibatch 26::LR 0.0607692307692 --> Loss 0.0013320355614\n",
      "Epoch 18::Minibatch 27::LR 0.0607692307692 --> Loss 0.000934775968393\n",
      "Epoch 18::Minibatch 28::LR 0.0607692307692 --> Loss 0.000391377061605\n",
      "Epoch 18::Minibatch 29::LR 0.0607692307692 --> Loss 0.000389958769083\n",
      "Epoch 18::Minibatch 30::LR 0.0607692307692 --> Loss 0.000869002838929\n",
      "Epoch 18::Minibatch 31::LR 0.0607692307692 --> Loss 0.00135132571061\n",
      "Epoch 18::Minibatch 32::LR 0.0607692307692 --> Loss 0.0012732359767\n",
      "Epoch 18::Minibatch 33::LR 0.0607692307692 --> Loss 0.00077625071009\n",
      "Epoch 18::Minibatch 34::LR 0.0607692307692 --> Loss 0.00233990649382\n",
      "Epoch 18::Minibatch 35::LR 0.0607692307692 --> Loss 0.00384407202403\n",
      "Epoch 18::Minibatch 36::LR 0.0607692307692 --> Loss 0.00221670170625\n",
      "Epoch 18::Minibatch 37::LR 0.0607692307692 --> Loss 0.000630413343509\n",
      "Epoch 18::Minibatch 38::LR 0.0607692307692 --> Loss 0.000732295811176\n",
      "Epoch 18::Minibatch 39::LR 0.0607692307692 --> Loss 0.00237743496895\n",
      "Epoch 18::Minibatch 40::LR 0.0607692307692 --> Loss 0.00344826896985\n",
      "Epoch 18::Minibatch 41::LR 0.0607692307692 --> Loss 0.00281340579192\n",
      "Epoch 18::Minibatch 42::LR 0.0607692307692 --> Loss 0.00588921864827\n",
      "Epoch 18::Minibatch 43::LR 0.0607692307692 --> Loss 0.00186637779077\n",
      "Epoch 18::Minibatch 44::LR 0.0607692307692 --> Loss 0.00310811916987\n",
      "Epoch 18::Minibatch 45::LR 0.0607692307692 --> Loss 0.00247264444828\n",
      "Epoch 18::Minibatch 46::LR 0.0607692307692 --> Loss 0.00339658021927\n",
      "Epoch 18::Minibatch 47::LR 0.0607692307692 --> Loss 0.00434201399485\n",
      "Epoch 18::Minibatch 48::LR 0.0607692307692 --> Loss 0.00584435979525\n",
      "Epoch 18::Minibatch 49::LR 0.0607692307692 --> Loss 0.00615172942479\n",
      "Epoch 18::Minibatch 50::LR 0.0607692307692 --> Loss 0.00608379721642\n",
      "Epoch 18::Minibatch 51::LR 0.0607692307692 --> Loss 0.00681017080943\n",
      "Epoch 18::Minibatch 52::LR 0.0607692307692 --> Loss 0.00346438805262\n",
      "Epoch 18::Minibatch 53::LR 0.0607692307692 --> Loss 0.00341922044754\n",
      "Epoch 18::Minibatch 54::LR 0.0607692307692 --> Loss 0.00401755650838\n",
      "Epoch 18::Minibatch 55::LR 0.0607692307692 --> Loss 0.000984315077464\n",
      "Epoch 18::Minibatch 56::LR 0.0607692307692 --> Loss 0.00269539197286\n",
      "Epoch 18::Minibatch 57::LR 0.0607692307692 --> Loss 0.00552589972814\n",
      "Epoch 18::Minibatch 58::LR 0.0607692307692 --> Loss 0.00333585977554\n",
      "Epoch 18::Minibatch 59::LR 0.0607692307692 --> Loss 0.00248022596041\n",
      "Epoch 18::Minibatch 60::LR 0.0607692307692 --> Loss 0.00238218307495\n",
      "Epoch 18::Minibatch 61::LR 0.0607692307692 --> Loss 0.000861595074336\n",
      "Epoch 18::Minibatch 62::LR 0.0607692307692 --> Loss 0.00311524987221\n",
      "Epoch 18::Minibatch 63::LR 0.0607692307692 --> Loss 0.00210475742817\n",
      "Epoch 18::Minibatch 64::LR 0.0607692307692 --> Loss 0.00089928885301\n",
      "Epoch 18::Minibatch 65::LR 0.0607692307692 --> Loss 0.00233951449394\n",
      "Epoch 18::Minibatch 66::LR 0.0607692307692 --> Loss 0.00281823635101\n",
      "Epoch 18::Minibatch 67::LR 0.0607692307692 --> Loss 0.00276254793008\n",
      "Epoch 18::Minibatch 68::LR 0.0607692307692 --> Loss 0.00196769138177\n",
      "Epoch 18::Minibatch 69::LR 0.0607692307692 --> Loss 0.00396861712138\n",
      "Epoch 18::Minibatch 70::LR 0.0607692307692 --> Loss 0.00344508051872\n",
      "Epoch 18::Minibatch 71::LR 0.0607692307692 --> Loss 0.00232660770416\n",
      "Epoch 18::Minibatch 72::LR 0.0607692307692 --> Loss 0.000538884898027\n",
      "Epoch 18::Minibatch 73::LR 0.0607692307692 --> Loss 0.00390952110291\n",
      "Epoch 18::Minibatch 74::LR 0.0607692307692 --> Loss 0.00414241909981\n",
      "Epoch 18::Minibatch 75::LR 0.0607692307692 --> Loss 0.00241531232993\n",
      "Epoch 18::Minibatch 76::LR 0.0607692307692 --> Loss 0.000584983627001\n",
      "Epoch 18::Minibatch 77::LR 0.0607692307692 --> Loss 0.00386654734612\n",
      "Epoch 18::Minibatch 78::LR 0.0607692307692 --> Loss 0.00385874867439\n",
      "Epoch 18::Minibatch 79::LR 0.0607692307692 --> Loss 0.0019683599472\n",
      "Epoch 18::Minibatch 80::LR 0.0607692307692 --> Loss 0.00323503295581\n",
      "Epoch 18::Minibatch 81::LR 0.0607692307692 --> Loss 0.00279696126779\n",
      "Epoch 18::Minibatch 82::LR 0.0607692307692 --> Loss 0.00200081487497\n",
      "Epoch 18::Minibatch 83::LR 0.0607692307692 --> Loss 0.00458580931028\n",
      "Epoch 18::Minibatch 84::LR 0.0607692307692 --> Loss 0.00199846367041\n",
      "Epoch 18::Minibatch 85::LR 0.0607692307692 --> Loss 0.00275796234608\n",
      "Epoch 18::Minibatch 86::LR 0.0607692307692 --> Loss 0.0022283544143\n",
      "Epoch 18::Minibatch 87::LR 0.0607692307692 --> Loss 0.00246492803097\n",
      "Epoch 18::Minibatch 88::LR 0.0607692307692 --> Loss 0.00179337938627\n",
      "Epoch 18::Minibatch 89::LR 0.0607692307692 --> Loss 0.00232974886894\n",
      "Epoch 18::Minibatch 90::LR 0.0607692307692 --> Loss 0.00112679292758\n",
      "Epoch 18::Minibatch 91::LR 0.0607692307692 --> Loss 0.000901782512665\n",
      "Epoch 18::Minibatch 92::LR 0.0607692307692 --> Loss 0.00270054678122\n",
      "Epoch 18::Minibatch 93::LR 0.0607692307692 --> Loss 0.0017639319102\n",
      "Epoch 18::Minibatch 94::LR 0.0607692307692 --> Loss 0.00177097598712\n",
      "Epoch 18::Minibatch 95::LR 0.0607692307692 --> Loss 0.00181206703186\n",
      "Epoch 18::Minibatch 96::LR 0.0607692307692 --> Loss 0.00576082905134\n",
      "Epoch 18::Minibatch 97::LR 0.0607692307692 --> Loss 0.00316434005896\n",
      "Epoch 18::Minibatch 98::LR 0.0607692307692 --> Loss 0.000987582405408\n",
      "Epoch 18::Minibatch 99::LR 0.0607692307692 --> Loss 0.00131529996792\n",
      "Epoch 18::Minibatch 100::LR 0.0607692307692 --> Loss 0.0051046637694\n",
      "Epoch 18::Minibatch 101::LR 0.0607692307692 --> Loss 0.000930609405041\n",
      "Epoch 18::Minibatch 102::LR 0.0607692307692 --> Loss 0.00386539578438\n",
      "Epoch 18::Minibatch 103::LR 0.0607692307692 --> Loss 0.00401966849963\n",
      "Epoch 18::Minibatch 104::LR 0.0607692307692 --> Loss 0.0027660916249\n",
      "Epoch 18::Minibatch 105::LR 0.0607692307692 --> Loss 0.002711049517\n",
      "Epoch 18::Minibatch 106::LR 0.0607692307692 --> Loss 0.0173924763997\n",
      "Epoch 18::Minibatch 107::LR 0.0607692307692 --> Loss 0.0048852789402\n",
      "Epoch 18::Minibatch 108::LR 0.0607692307692 --> Loss 0.00105725755294\n",
      "Epoch 18::Minibatch 109::LR 0.0607692307692 --> Loss 0.00438917517662\n",
      "Epoch 18::Minibatch 110::LR 0.0607692307692 --> Loss 0.00240077515443\n",
      "Epoch 18::Minibatch 111::LR 0.0607692307692 --> Loss 0.000968214074771\n",
      "Epoch 18::Minibatch 112::LR 0.0607692307692 --> Loss 0.00355889638265\n",
      "Epoch 18::Minibatch 113::LR 0.0607692307692 --> Loss 0.00266437331835\n",
      "Epoch 18::Minibatch 114::LR 0.0607692307692 --> Loss 0.00147159655889\n",
      "Epoch 18::Minibatch 115::LR 0.0607692307692 --> Loss 0.00133176187674\n",
      "Epoch 18::Minibatch 116::LR 0.0607692307692 --> Loss 0.00279617289702\n",
      "Epoch 18::Minibatch 117::LR 0.0607692307692 --> Loss 0.0038249929746\n",
      "Epoch 18::Minibatch 118::LR 0.0607692307692 --> Loss 0.00691004037857\n",
      "Epoch 18::Minibatch 119::LR 0.0607692307692 --> Loss 0.000646277666092\n",
      "Epoch 18::Minibatch 120::LR 0.0607692307692 --> Loss 0.00178693672021\n",
      "Epoch 18::Minibatch 121::LR 0.0607692307692 --> Loss 0.00266689797242\n",
      "Epoch 18::Minibatch 122::LR 0.0607692307692 --> Loss 0.00372675736745\n",
      "Epoch 18::Minibatch 123::LR 0.0607692307692 --> Loss 0.00102491209904\n",
      "Epoch 18::Minibatch 124::LR 0.0607692307692 --> Loss 0.00278063158194\n",
      "Epoch 18::Minibatch 125::LR 0.0607692307692 --> Loss 0.00464016199112\n",
      "Epoch 18::Minibatch 126::LR 0.0607692307692 --> Loss 0.00271806240082\n",
      "Epoch 18::Minibatch 127::LR 0.0607692307692 --> Loss 0.00441604495049\n",
      "Epoch 18::Minibatch 128::LR 0.0607692307692 --> Loss 0.00362982551257\n",
      "Epoch 18::Minibatch 129::LR 0.0607692307692 --> Loss 0.00270955880483\n",
      "Epoch 18::Minibatch 130::LR 0.0607692307692 --> Loss 0.0043733672301\n",
      "Epoch 18::Minibatch 131::LR 0.0607692307692 --> Loss 0.0018009018898\n",
      "Epoch 18::Minibatch 132::LR 0.0607692307692 --> Loss 0.00309212446213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 133::LR 0.0607692307692 --> Loss 0.00294594824314\n",
      "Epoch 18::Minibatch 134::LR 0.0607692307692 --> Loss 0.00237733741601\n",
      "Epoch 18::Minibatch 135::LR 0.0607692307692 --> Loss 0.00157404492299\n",
      "Epoch 18::Minibatch 136::LR 0.0607692307692 --> Loss 0.00271829466025\n",
      "Epoch 18::Minibatch 137::LR 0.0607692307692 --> Loss 0.00368451635043\n",
      "Epoch 18::Minibatch 138::LR 0.0607692307692 --> Loss 0.00131043543418\n",
      "Epoch 18::Minibatch 139::LR 0.0607692307692 --> Loss 0.00191903869311\n",
      "Epoch 18::Minibatch 140::LR 0.0607692307692 --> Loss 0.00246598203977\n",
      "Epoch 18::Minibatch 141::LR 0.0607692307692 --> Loss 0.0029823799928\n",
      "Epoch 18::Minibatch 142::LR 0.0607692307692 --> Loss 0.00289218465487\n",
      "Epoch 18::Minibatch 143::LR 0.0607692307692 --> Loss 0.000605695645014\n",
      "Epoch 18::Minibatch 144::LR 0.0607692307692 --> Loss 0.00324606160323\n",
      "Epoch 18::Minibatch 145::LR 0.0607692307692 --> Loss 0.00432189424833\n",
      "Epoch 18::Minibatch 146::LR 0.0607692307692 --> Loss 0.00258645971616\n",
      "Epoch 18::Minibatch 147::LR 0.0607692307692 --> Loss 0.00182118833065\n",
      "Epoch 18::Minibatch 148::LR 0.0607692307692 --> Loss 0.00101434280475\n",
      "Epoch 18::Minibatch 149::LR 0.0607692307692 --> Loss 0.00284224748611\n",
      "Epoch 18::Minibatch 150::LR 0.0607692307692 --> Loss 0.00272549053033\n",
      "Epoch 18::Minibatch 151::LR 0.0607692307692 --> Loss 0.0042514983813\n",
      "Epoch 18::Minibatch 152::LR 0.0607692307692 --> Loss 0.000922943850358\n",
      "Epoch 18::Minibatch 153::LR 0.0607692307692 --> Loss 0.00181760350863\n",
      "Epoch 18::Minibatch 154::LR 0.0607692307692 --> Loss 0.00205861151218\n",
      "Epoch 18::Minibatch 155::LR 0.0607692307692 --> Loss 0.00449494322141\n",
      "Epoch 18::Minibatch 156::LR 0.0607692307692 --> Loss 0.00240160663923\n",
      "Epoch 18::Minibatch 157::LR 0.0607692307692 --> Loss 0.000699710100889\n",
      "Epoch 18::Minibatch 158::LR 0.0607692307692 --> Loss 0.00306354026\n",
      "Epoch 18::Minibatch 159::LR 0.0607692307692 --> Loss 0.00276016871134\n",
      "Epoch 18::Minibatch 160::LR 0.0607692307692 --> Loss 0.00263909339905\n",
      "Epoch 18::Minibatch 161::LR 0.0607692307692 --> Loss 0.00102316478888\n",
      "Epoch 18::Minibatch 162::LR 0.0607692307692 --> Loss 0.00376272638639\n",
      "Epoch 18::Minibatch 163::LR 0.0607692307692 --> Loss 0.002405346632\n",
      "Epoch 18::Minibatch 164::LR 0.0607692307692 --> Loss 0.00250084936619\n",
      "Epoch 18::Minibatch 165::LR 0.0607692307692 --> Loss 0.000528826067845\n",
      "Epoch 18::Minibatch 166::LR 0.0607692307692 --> Loss 0.00178965429465\n",
      "Epoch 18::Minibatch 167::LR 0.0607692307692 --> Loss 0.00246129572392\n",
      "Epoch 18::Minibatch 168::LR 0.0607692307692 --> Loss 0.00218698839347\n",
      "Epoch 18::Minibatch 169::LR 0.0607692307692 --> Loss 0.00101418296496\n",
      "Epoch 18::Minibatch 170::LR 0.0607692307692 --> Loss 0.000989585320155\n",
      "Epoch 18::Minibatch 171::LR 0.0607692307692 --> Loss 0.00251542588075\n",
      "Epoch 18::Minibatch 172::LR 0.0607692307692 --> Loss 0.00448835055033\n",
      "Epoch 18::Minibatch 173::LR 0.0607692307692 --> Loss 0.00195582389832\n",
      "Epoch 18::Minibatch 174::LR 0.0607692307692 --> Loss 0.00104393770297\n",
      "Epoch 18::Minibatch 175::LR 0.0607692307692 --> Loss 0.0023087789615\n",
      "Epoch 18::Minibatch 176::LR 0.0607692307692 --> Loss 0.00328385988871\n",
      "Epoch 18::Minibatch 177::LR 0.0607692307692 --> Loss 0.00456003308296\n",
      "Epoch 18::Minibatch 178::LR 0.0607692307692 --> Loss 0.00163437356551\n",
      "Epoch 18::Minibatch 179::LR 0.0607692307692 --> Loss 0.00136164764563\n",
      "Epoch 18::Minibatch 180::LR 0.0607692307692 --> Loss 0.00361667752266\n",
      "Epoch 18::Minibatch 181::LR 0.0607692307692 --> Loss 0.00326215624809\n",
      "Epoch 18::Minibatch 182::LR 0.0607692307692 --> Loss 0.000777527789275\n",
      "Epoch 18::Minibatch 183::LR 0.0607692307692 --> Loss 0.00168831348419\n",
      "Epoch 18::Minibatch 184::LR 0.0607692307692 --> Loss 0.00343071341515\n",
      "Epoch 18::Minibatch 185::LR 0.0607692307692 --> Loss 0.00283999005953\n",
      "Epoch 18::Minibatch 186::LR 0.0607692307692 --> Loss 0.000974793235461\n",
      "Epoch 18::Minibatch 187::LR 0.0607692307692 --> Loss 0.00126374950012\n",
      "Epoch 18::Minibatch 188::LR 0.0607692307692 --> Loss 0.00418848395348\n",
      "Epoch 18::Minibatch 189::LR 0.0607692307692 --> Loss 0.00444824020068\n",
      "Epoch 18::Minibatch 190::LR 0.0607692307692 --> Loss 0.00232253273328\n",
      "Epoch 18::Minibatch 191::LR 0.0607692307692 --> Loss 0.000480001668135\n",
      "Epoch 18::Minibatch 192::LR 0.0607692307692 --> Loss 0.00271646022797\n",
      "Epoch 18::Minibatch 193::LR 0.0607692307692 --> Loss 0.00256610711416\n",
      "Epoch 18::Minibatch 194::LR 0.0607692307692 --> Loss 0.00178472161293\n",
      "Epoch 18::Minibatch 195::LR 0.0607692307692 --> Loss 0.000387285773953\n",
      "Epoch 18::Minibatch 196::LR 0.0607692307692 --> Loss 0.0012386059761\n",
      "Epoch 18::Minibatch 197::LR 0.0607692307692 --> Loss 0.00286867380142\n",
      "Epoch 18::Minibatch 198::LR 0.0607692307692 --> Loss 0.00221208135287\n",
      "Epoch 18::Minibatch 199::LR 0.0607692307692 --> Loss 0.000288660153747\n",
      "Epoch 18::Minibatch 200::LR 0.0607692307692 --> Loss 0.00206295808156\n",
      "Epoch 18::Minibatch 201::LR 0.0607692307692 --> Loss 0.00195712844531\n",
      "Epoch 18::Minibatch 202::LR 0.0607692307692 --> Loss 0.00186999082565\n",
      "Epoch 18::Minibatch 203::LR 0.0607692307692 --> Loss 0.0017761127154\n",
      "Epoch 18::Minibatch 204::LR 0.0607692307692 --> Loss 0.00146470447381\n",
      "Epoch 18::Minibatch 205::LR 0.0607692307692 --> Loss 0.00221163809299\n",
      "Epoch 18::Minibatch 206::LR 0.0607692307692 --> Loss 0.00645301302274\n",
      "Epoch 18::Minibatch 207::LR 0.0607692307692 --> Loss 0.00139622042576\n",
      "Epoch 18::Minibatch 208::LR 0.0607692307692 --> Loss 0.00113069872061\n",
      "Epoch 18::Minibatch 209::LR 0.0607692307692 --> Loss 0.00220927993457\n",
      "Epoch 18::Minibatch 210::LR 0.0607692307692 --> Loss 0.00211086054643\n",
      "Epoch 18::Minibatch 211::LR 0.0607692307692 --> Loss 0.00227529704571\n",
      "Epoch 18::Minibatch 212::LR 0.0607692307692 --> Loss 0.0040006117026\n",
      "Epoch 18::Minibatch 213::LR 0.0607692307692 --> Loss 0.00589040080706\n",
      "Epoch 18::Minibatch 214::LR 0.0607692307692 --> Loss 0.00922112305959\n",
      "Epoch 18::Minibatch 215::LR 0.0607692307692 --> Loss 0.00139724473159\n",
      "Epoch 18::Minibatch 216::LR 0.0607692307692 --> Loss 0.00551833430926\n",
      "Epoch 18::Minibatch 217::LR 0.0607692307692 --> Loss 0.00616465568542\n",
      "Epoch 18::Minibatch 218::LR 0.0607692307692 --> Loss 0.00395338058472\n",
      "Epoch 18::Minibatch 219::LR 0.0607692307692 --> Loss 0.00410543958346\n",
      "Epoch 18::Minibatch 220::LR 0.0607692307692 --> Loss 0.00452890237172\n",
      "Epoch 18::Minibatch 221::LR 0.0607692307692 --> Loss 0.00426992138227\n",
      "Epoch 18::Minibatch 222::LR 0.0607692307692 --> Loss 0.00326209505399\n",
      "Epoch 18::Minibatch 223::LR 0.0607692307692 --> Loss 0.00142140130202\n",
      "Epoch 18::Minibatch 224::LR 0.0607692307692 --> Loss 0.00176654497782\n",
      "Epoch 18::Minibatch 225::LR 0.0607692307692 --> Loss 0.00729269345601\n",
      "Epoch 18::Minibatch 226::LR 0.0607692307692 --> Loss 0.00379070162773\n",
      "Epoch 18::Minibatch 227::LR 0.0607692307692 --> Loss 0.00169873714447\n",
      "Epoch 18::Minibatch 228::LR 0.0607692307692 --> Loss 0.000745374461015\n",
      "Epoch 18::Minibatch 229::LR 0.0607692307692 --> Loss 0.00478080630302\n",
      "Epoch 18::Minibatch 230::LR 0.0607692307692 --> Loss 0.00393917679787\n",
      "Epoch 18::Minibatch 231::LR 0.0607692307692 --> Loss 0.00264156699181\n",
      "Epoch 18::Minibatch 232::LR 0.0607692307692 --> Loss 0.0012224556009\n",
      "Epoch 18::Minibatch 233::LR 0.0607692307692 --> Loss 0.00242950300376\n",
      "Epoch 18::Minibatch 234::LR 0.0607692307692 --> Loss 0.00692469040553\n",
      "Epoch 18::Minibatch 235::LR 0.0607692307692 --> Loss 0.0047776556015\n",
      "Epoch 18::Minibatch 236::LR 0.0607692307692 --> Loss 0.00177078207334\n",
      "Epoch 18::Minibatch 237::LR 0.0607692307692 --> Loss 0.000684819767872\n",
      "Epoch 18::Minibatch 238::LR 0.0607692307692 --> Loss 0.00342077255249\n",
      "Epoch 18::Minibatch 239::LR 0.0607692307692 --> Loss 0.00296489775181\n",
      "Epoch 18::Minibatch 240::LR 0.0607692307692 --> Loss 0.00325105905533\n",
      "Epoch 18::Minibatch 241::LR 0.0607692307692 --> Loss 0.0007691954573\n",
      "Epoch 18::Minibatch 242::LR 0.0607692307692 --> Loss 0.00706300656001\n",
      "Epoch 18::Minibatch 243::LR 0.0607692307692 --> Loss 0.00352825284004\n",
      "Epoch 18::Minibatch 244::LR 0.0607692307692 --> Loss 0.00294807950656\n",
      "Epoch 18::Minibatch 245::LR 0.0607692307692 --> Loss 0.000476378450791\n",
      "Epoch 18::Minibatch 246::LR 0.0607692307692 --> Loss 0.00206310292085\n",
      "Epoch 18::Minibatch 247::LR 0.0607692307692 --> Loss 0.0129546364148\n",
      "Epoch 18::Minibatch 248::LR 0.0607692307692 --> Loss 0.00450137257576\n",
      "Epoch 18::Minibatch 249::LR 0.0607692307692 --> Loss 0.00272457897663\n",
      "Epoch 18::Minibatch 250::LR 0.0607692307692 --> Loss 0.00260888397694\n",
      "Epoch 18::Minibatch 251::LR 0.0607692307692 --> Loss 0.00253867805004\n",
      "Epoch 18::Minibatch 252::LR 0.0607692307692 --> Loss 0.00179918328921\n",
      "Epoch 18::Minibatch 253::LR 0.0607692307692 --> Loss 0.00309893409411\n",
      "Epoch 18::Minibatch 254::LR 0.0607692307692 --> Loss 0.00515219171842\n",
      "Epoch 18::Minibatch 255::LR 0.0607692307692 --> Loss 0.00390746712685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 256::LR 0.0607692307692 --> Loss 0.00164361764987\n",
      "Epoch 18::Minibatch 257::LR 0.0607692307692 --> Loss 0.00124045699835\n",
      "Epoch 18::Minibatch 258::LR 0.0607692307692 --> Loss 0.00363965710004\n",
      "Epoch 18::Minibatch 259::LR 0.0607692307692 --> Loss 0.00179392735163\n",
      "Epoch 18::Minibatch 260::LR 0.0607692307692 --> Loss 0.00189910769463\n",
      "Epoch 18::Minibatch 261::LR 0.0607692307692 --> Loss 0.00289481242498\n",
      "Epoch 18::Minibatch 262::LR 0.0607692307692 --> Loss 0.00193667133649\n",
      "Epoch 18::Minibatch 263::LR 0.0607692307692 --> Loss 0.002374082009\n",
      "Epoch 18::Minibatch 264::LR 0.0607692307692 --> Loss 0.00364939133326\n",
      "Epoch 18::Minibatch 265::LR 0.0607692307692 --> Loss 0.0101795991262\n",
      "Epoch 18::Minibatch 266::LR 0.0607692307692 --> Loss 0.00101357291142\n",
      "Epoch 18::Minibatch 267::LR 0.0607692307692 --> Loss 0.00999103864034\n",
      "Epoch 18::Minibatch 268::LR 0.0607692307692 --> Loss 0.00118635644515\n",
      "Epoch 18::Minibatch 269::LR 0.0607692307692 --> Loss 0.00351501782735\n",
      "Epoch 18::Minibatch 270::LR 0.0607692307692 --> Loss 0.00668135722478\n",
      "Epoch 18::Minibatch 271::LR 0.0607692307692 --> Loss 0.00270832598209\n",
      "Epoch 18::Minibatch 272::LR 0.0607692307692 --> Loss 0.00412432670593\n",
      "Epoch 18::Minibatch 273::LR 0.0607692307692 --> Loss 0.00166164765755\n",
      "Epoch 18::Minibatch 274::LR 0.0607692307692 --> Loss 0.00179955899715\n",
      "Epoch 18::Minibatch 275::LR 0.0607692307692 --> Loss 0.00265443861485\n",
      "Epoch 18::Minibatch 276::LR 0.0607692307692 --> Loss 0.00346681833267\n",
      "Epoch 18::Minibatch 277::LR 0.0607692307692 --> Loss 0.000996120174726\n",
      "Epoch 18::Minibatch 278::LR 0.0607692307692 --> Loss 0.00263599137465\n",
      "Epoch 18::Minibatch 279::LR 0.0607692307692 --> Loss 0.00235706110795\n",
      "Epoch 18::Minibatch 280::LR 0.0607692307692 --> Loss 0.0020528425773\n",
      "Epoch 18::Minibatch 281::LR 0.0607692307692 --> Loss 0.00128990501165\n",
      "Epoch 18::Minibatch 282::LR 0.0607692307692 --> Loss 0.00222044805686\n",
      "Epoch 18::Minibatch 283::LR 0.0607692307692 --> Loss 0.00216455380122\n",
      "Epoch 18::Minibatch 284::LR 0.0607692307692 --> Loss 0.00173078993956\n",
      "Epoch 18::Minibatch 285::LR 0.0607692307692 --> Loss 0.0012116792798\n",
      "Epoch 18::Minibatch 286::LR 0.0607692307692 --> Loss 0.00213398456573\n",
      "Epoch 18::Minibatch 287::LR 0.0607692307692 --> Loss 0.00207339187463\n",
      "Epoch 18::Minibatch 288::LR 0.0607692307692 --> Loss 0.00111466358105\n",
      "Epoch 18::Minibatch 289::LR 0.0607692307692 --> Loss 0.00159478237232\n",
      "Epoch 18::Minibatch 290::LR 0.0607692307692 --> Loss 0.00194215257963\n",
      "Epoch 18::Minibatch 291::LR 0.0607692307692 --> Loss 0.00172864735126\n",
      "Epoch 18::Minibatch 292::LR 0.0607692307692 --> Loss 0.000605579962333\n",
      "Epoch 18::Minibatch 293::LR 0.0607692307692 --> Loss 0.00149550159772\n",
      "Epoch 18::Minibatch 294::LR 0.0607692307692 --> Loss 0.00157540520032\n",
      "Epoch 18::Minibatch 295::LR 0.0607692307692 --> Loss 0.00186395267646\n",
      "Epoch 18::Minibatch 296::LR 0.0607692307692 --> Loss 0.00161501894395\n",
      "Epoch 18::Minibatch 297::LR 0.0607692307692 --> Loss 0.00140229175488\n",
      "Epoch 18::Minibatch 298::LR 0.0607692307692 --> Loss 0.00138858318329\n",
      "Epoch 18::Minibatch 299::LR 0.0607692307692 --> Loss 0.000798774808645\n",
      "Epoch 18::Minibatch 300::LR 0.0607692307692 --> Loss 0.00280748784542\n",
      "Epoch 18::Minibatch 301::LR 0.0607692307692 --> Loss 0.00272085189819\n",
      "Epoch 18::Minibatch 302::LR 0.0607692307692 --> Loss 0.00251062989235\n",
      "Epoch 18::Minibatch 303::LR 0.0607692307692 --> Loss 0.000859246651332\n",
      "Epoch 18::Minibatch 304::LR 0.0607692307692 --> Loss 0.00309825003147\n",
      "Epoch 18::Minibatch 305::LR 0.0607692307692 --> Loss 0.0016930359602\n",
      "Epoch 18::Minibatch 306::LR 0.0607692307692 --> Loss 0.000931258996328\n",
      "Epoch 18::Minibatch 307::LR 0.0607692307692 --> Loss 0.00245662967364\n",
      "Epoch 18::Minibatch 308::LR 0.0607692307692 --> Loss 0.0019932415088\n",
      "Epoch 18::Minibatch 309::LR 0.0607692307692 --> Loss 0.00100547730923\n",
      "Epoch 18::Minibatch 310::LR 0.0607692307692 --> Loss 0.00112444450458\n",
      "Epoch 18::Minibatch 311::LR 0.0607692307692 --> Loss 0.00172760784626\n",
      "Epoch 18::Minibatch 312::LR 0.0607692307692 --> Loss 0.00295394023259\n",
      "Epoch 18::Minibatch 313::LR 0.0607692307692 --> Loss 0.00239369571209\n",
      "Epoch 18::Minibatch 314::LR 0.0607692307692 --> Loss 0.00191824793816\n",
      "Epoch 18::Minibatch 315::LR 0.0607692307692 --> Loss 0.00100056091944\n",
      "Epoch 18::Minibatch 316::LR 0.0607692307692 --> Loss 0.00233214358489\n",
      "Epoch 18::Minibatch 317::LR 0.0607692307692 --> Loss 0.00154830535253\n",
      "Epoch 18::Minibatch 318::LR 0.0607692307692 --> Loss 0.0012310235699\n",
      "Epoch 18::Minibatch 319::LR 0.0607692307692 --> Loss 0.00229569137096\n",
      "Epoch 18::Minibatch 320::LR 0.0607692307692 --> Loss 0.00318611443043\n",
      "Epoch 18::Minibatch 321::LR 0.0607692307692 --> Loss 0.000852331419786\n",
      "Epoch 18::Minibatch 322::LR 0.0607692307692 --> Loss 0.0036514767011\n",
      "Epoch 18::Minibatch 323::LR 0.0607692307692 --> Loss 0.00353379885356\n",
      "Epoch 18::Minibatch 324::LR 0.0607692307692 --> Loss 0.002635110418\n",
      "Epoch 18::Minibatch 325::LR 0.0607692307692 --> Loss 0.00240318616231\n",
      "Epoch 18::Minibatch 326::LR 0.0607692307692 --> Loss 0.00551124374072\n",
      "Epoch 18::Minibatch 327::LR 0.0607692307692 --> Loss 0.00225889027119\n",
      "Epoch 18::Minibatch 328::LR 0.0607692307692 --> Loss 0.00325295905272\n",
      "Epoch 18::Minibatch 329::LR 0.0607692307692 --> Loss 0.00122772455215\n",
      "Epoch 18::Minibatch 330::LR 0.0607692307692 --> Loss 0.00160539776087\n",
      "Epoch 18::Minibatch 331::LR 0.0607692307692 --> Loss 0.00254959404469\n",
      "Epoch 18::Minibatch 332::LR 0.0607692307692 --> Loss 0.00250357806683\n",
      "Epoch 18::Minibatch 333::LR 0.0607692307692 --> Loss 0.0014526450634\n",
      "Epoch 18::Minibatch 334::LR 0.0607692307692 --> Loss 0.00439199447632\n",
      "Epoch 18::Minibatch 335::LR 0.0607692307692 --> Loss 0.00188929100831\n",
      "Epoch 18::Minibatch 336::LR 0.0607692307692 --> Loss 0.00216714282831\n",
      "Epoch 18::Minibatch 337::LR 0.0607692307692 --> Loss 0.0034566338857\n",
      "Epoch 18::Minibatch 338::LR 0.0607692307692 --> Loss 0.000524043341478\n",
      "Epoch 18::Minibatch 339::LR 0.0607692307692 --> Loss 0.00331897656123\n",
      "Epoch 18::Minibatch 340::LR 0.0607692307692 --> Loss 0.00408652702967\n",
      "Epoch 18::Minibatch 341::LR 0.0607692307692 --> Loss 0.00480823437373\n",
      "Epoch 18::Minibatch 342::LR 0.0607692307692 --> Loss 0.00312940696875\n",
      "Epoch 18::Minibatch 343::LR 0.0607692307692 --> Loss 0.0016782438755\n",
      "Epoch 18::Minibatch 344::LR 0.0607692307692 --> Loss 0.00313437124093\n",
      "Epoch 18::Minibatch 345::LR 0.0607692307692 --> Loss 0.00426261266073\n",
      "Epoch 18::Minibatch 346::LR 0.0607692307692 --> Loss 0.00564617594083\n",
      "Epoch 18::Minibatch 347::LR 0.0607692307692 --> Loss 0.000863057672977\n",
      "Epoch 18::Minibatch 348::LR 0.0607692307692 --> Loss 0.00338168938955\n",
      "Epoch 18::Minibatch 349::LR 0.0607692307692 --> Loss 0.00350345094999\n",
      "Epoch 18::Minibatch 350::LR 0.0607692307692 --> Loss 0.00177050511042\n",
      "Epoch 18::Minibatch 351::LR 0.0607692307692 --> Loss 0.00353282729785\n",
      "Epoch 18::Minibatch 352::LR 0.0607692307692 --> Loss 0.00489115476608\n",
      "Epoch 18::Minibatch 353::LR 0.0607692307692 --> Loss 0.00354927142461\n",
      "Epoch 18::Minibatch 354::LR 0.0607692307692 --> Loss 0.00294377923012\n",
      "Epoch 18::Minibatch 355::LR 0.0607692307692 --> Loss 0.00616432507833\n",
      "Epoch 18::Minibatch 356::LR 0.0607692307692 --> Loss 0.00313048660755\n",
      "Epoch 18::Minibatch 357::LR 0.0607692307692 --> Loss 0.00115661680698\n",
      "Epoch 18::Minibatch 358::LR 0.0607692307692 --> Loss 0.00212836821874\n",
      "Epoch 18::Minibatch 359::LR 0.0607692307692 --> Loss 0.00272406260173\n",
      "Epoch 18::Minibatch 360::LR 0.0607692307692 --> Loss 0.00242184678713\n",
      "Epoch 18::Minibatch 361::LR 0.0607692307692 --> Loss 0.00240611930688\n",
      "Epoch 18::Minibatch 362::LR 0.0607692307692 --> Loss 0.00238939126333\n",
      "Epoch 18::Minibatch 363::LR 0.0607692307692 --> Loss 0.000660765022039\n",
      "Epoch 18::Minibatch 364::LR 0.0607692307692 --> Loss 0.00200447738171\n",
      "Epoch 18::Minibatch 365::LR 0.0607692307692 --> Loss 0.00208672225475\n",
      "Epoch 18::Minibatch 366::LR 0.0607692307692 --> Loss 0.00223309536775\n",
      "Epoch 18::Minibatch 367::LR 0.0607692307692 --> Loss 0.00107570280631\n",
      "Epoch 18::Minibatch 368::LR 0.0607692307692 --> Loss 0.000984284480413\n",
      "Epoch 18::Minibatch 369::LR 0.0607692307692 --> Loss 0.0028699674209\n",
      "Epoch 18::Minibatch 370::LR 0.0607692307692 --> Loss 0.00226075390975\n",
      "Epoch 18::Minibatch 371::LR 0.0607692307692 --> Loss 0.00187453230222\n",
      "Epoch 18::Minibatch 372::LR 0.0607692307692 --> Loss 0.000435024847587\n",
      "Epoch 18::Minibatch 373::LR 0.0607692307692 --> Loss 0.00177301347256\n",
      "Epoch 18::Minibatch 374::LR 0.0607692307692 --> Loss 0.00219224731127\n",
      "Epoch 18::Minibatch 375::LR 0.0607692307692 --> Loss 0.00184461037318\n",
      "Epoch 18::Minibatch 376::LR 0.0607692307692 --> Loss 0.00123582859834\n",
      "Epoch 18::Minibatch 377::LR 0.0607692307692 --> Loss 0.00194014132023\n",
      "Epoch 18::Minibatch 378::LR 0.0607692307692 --> Loss 0.00212586581707\n",
      "Epoch 18::Minibatch 379::LR 0.0607692307692 --> Loss 0.00236918707689\n",
      "Epoch 18::Minibatch 380::LR 0.0607692307692 --> Loss 0.00158420970043\n",
      "Epoch 18::Minibatch 381::LR 0.0607692307692 --> Loss 0.000982118546963\n",
      "Epoch 18::Minibatch 382::LR 0.0607692307692 --> Loss 0.00201309462388\n",
      "Epoch 18::Minibatch 383::LR 0.0607692307692 --> Loss 0.00195615172386\n",
      "Epoch 18::Minibatch 384::LR 0.0607692307692 --> Loss 0.00105692525705\n",
      "Epoch 18::Minibatch 385::LR 0.0607692307692 --> Loss 0.00103609134754\n",
      "Epoch 18::Minibatch 386::LR 0.0607692307692 --> Loss 0.00218341012796\n",
      "Epoch 18::Minibatch 387::LR 0.0607692307692 --> Loss 0.00234014054139\n",
      "Epoch 18::Minibatch 388::LR 0.0607692307692 --> Loss 0.00115507771571\n",
      "Epoch 18::Minibatch 389::LR 0.0607692307692 --> Loss 0.00179906825225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 390::LR 0.0607692307692 --> Loss 0.00352382977804\n",
      "Epoch 18::Minibatch 391::LR 0.0607692307692 --> Loss 0.00266306956609\n",
      "Epoch 18::Minibatch 392::LR 0.0607692307692 --> Loss 0.00262497425079\n",
      "Epoch 18::Minibatch 393::LR 0.0607692307692 --> Loss 0.00276701768239\n",
      "Epoch 18::Minibatch 394::LR 0.0607692307692 --> Loss 0.00208245615164\n",
      "Epoch 18::Minibatch 395::LR 0.0607692307692 --> Loss 0.00205654184024\n",
      "Epoch 18::Minibatch 396::LR 0.0607692307692 --> Loss 0.00194067637126\n",
      "Epoch 18::Minibatch 397::LR 0.0607692307692 --> Loss 0.0020728156964\n",
      "Epoch 18::Minibatch 398::LR 0.0607692307692 --> Loss 0.00205766618252\n",
      "Epoch 18::Minibatch 399::LR 0.0607692307692 --> Loss 0.00236535390218\n",
      "Epoch 18::Minibatch 400::LR 0.0607692307692 --> Loss 0.00201011260351\n",
      "Epoch 18::Minibatch 401::LR 0.0607692307692 --> Loss 0.0034752146403\n",
      "Epoch 18::Minibatch 402::LR 0.0607692307692 --> Loss 0.00179293870926\n",
      "Epoch 18::Minibatch 403::LR 0.0607692307692 --> Loss 0.00144642909368\n",
      "Epoch 18::Minibatch 404::LR 0.0607692307692 --> Loss 0.00146128833294\n",
      "Epoch 18::Minibatch 405::LR 0.0607692307692 --> Loss 0.00348322669665\n",
      "Epoch 18::Minibatch 406::LR 0.0607692307692 --> Loss 0.00244332571824\n",
      "Epoch 18::Minibatch 407::LR 0.0607692307692 --> Loss 0.00173214276632\n",
      "Epoch 18::Minibatch 408::LR 0.0607692307692 --> Loss 0.000437043756247\n",
      "Epoch 18::Minibatch 409::LR 0.0607692307692 --> Loss 0.00229785839717\n",
      "Epoch 18::Minibatch 410::LR 0.0607692307692 --> Loss 0.00319345970949\n",
      "Epoch 18::Minibatch 411::LR 0.0607692307692 --> Loss 0.00163359175126\n",
      "Epoch 18::Minibatch 412::LR 0.0607692307692 --> Loss 0.000954934457938\n",
      "Epoch 18::Minibatch 413::LR 0.0607692307692 --> Loss 0.00196294208368\n",
      "Epoch 18::Minibatch 414::LR 0.0607692307692 --> Loss 0.00183068593343\n",
      "Epoch 18::Minibatch 415::LR 0.0607692307692 --> Loss 0.00114164908727\n",
      "Epoch 18::Minibatch 416::LR 0.0607692307692 --> Loss 0.000806059340636\n",
      "Epoch 18::Minibatch 417::LR 0.0607692307692 --> Loss 0.0016912740469\n",
      "Epoch 18::Minibatch 418::LR 0.0607692307692 --> Loss 0.00272843798002\n",
      "Epoch 18::Minibatch 419::LR 0.0607692307692 --> Loss 0.00049181068937\n",
      "Epoch 18::Minibatch 420::LR 0.0607692307692 --> Loss 0.000684879322847\n",
      "Epoch 18::Minibatch 421::LR 0.0607692307692 --> Loss 0.00191540360451\n",
      "Epoch 18::Minibatch 422::LR 0.0607692307692 --> Loss 0.00212332844734\n",
      "Epoch 18::Minibatch 423::LR 0.0607692307692 --> Loss 0.000958186884721\n",
      "Epoch 18::Minibatch 424::LR 0.0607692307692 --> Loss 0.00153962473075\n",
      "Epoch 18::Minibatch 425::LR 0.0607692307692 --> Loss 0.00289389808973\n",
      "Epoch 18::Minibatch 426::LR 0.0607692307692 --> Loss 0.00198982079824\n",
      "Epoch 18::Minibatch 427::LR 0.0607692307692 --> Loss 0.000705320189397\n",
      "Epoch 18::Minibatch 428::LR 0.0607692307692 --> Loss 0.00102428853512\n",
      "Epoch 18::Minibatch 429::LR 0.0607692307692 --> Loss 0.00235890865326\n",
      "Epoch 18::Minibatch 430::LR 0.0607692307692 --> Loss 0.00924643754959\n",
      "Epoch 18::Minibatch 431::LR 0.0607692307692 --> Loss 0.00378530780474\n",
      "Epoch 18::Minibatch 432::LR 0.0607692307692 --> Loss 0.00438872377078\n",
      "Epoch 18::Minibatch 433::LR 0.0607692307692 --> Loss 0.00256812632084\n",
      "Epoch 18::Minibatch 434::LR 0.0607692307692 --> Loss 0.00252868215243\n",
      "Epoch 18::Minibatch 435::LR 0.0607692307692 --> Loss 0.00232448180517\n",
      "Epoch 18::Minibatch 436::LR 0.0607692307692 --> Loss 0.00168076018492\n",
      "Epoch 18::Minibatch 437::LR 0.0607692307692 --> Loss 0.0031900348266\n",
      "Epoch 18::Minibatch 438::LR 0.0607692307692 --> Loss 0.00255118846893\n",
      "Epoch 18::Minibatch 439::LR 0.0607692307692 --> Loss 0.0020642276605\n",
      "Epoch 18::Minibatch 440::LR 0.0607692307692 --> Loss 0.00319397111734\n",
      "Epoch 18::Minibatch 441::LR 0.0607692307692 --> Loss 0.00298317611217\n",
      "Epoch 18::Minibatch 442::LR 0.0607692307692 --> Loss 0.00272269010544\n",
      "Epoch 18::Minibatch 443::LR 0.0607692307692 --> Loss 0.00364202221235\n",
      "Epoch 18::Minibatch 444::LR 0.0607692307692 --> Loss 0.00285004814466\n",
      "Epoch 18::Minibatch 445::LR 0.0607692307692 --> Loss 0.000888396302859\n",
      "Epoch 18::Minibatch 446::LR 0.0607692307692 --> Loss 0.00144267618656\n",
      "Epoch 18::Minibatch 447::LR 0.0607692307692 --> Loss 0.00241781095664\n",
      "Epoch 18::Minibatch 448::LR 0.0607692307692 --> Loss 0.00239449560642\n",
      "Epoch 18::Minibatch 449::LR 0.0607692307692 --> Loss 0.00371248801549\n",
      "Epoch 18::Minibatch 450::LR 0.0607692307692 --> Loss 0.00228207826614\n",
      "Epoch 18::Minibatch 451::LR 0.0607692307692 --> Loss 0.00400974472364\n",
      "Epoch 18::Minibatch 452::LR 0.0607692307692 --> Loss 0.00236843744914\n",
      "Epoch 18::Minibatch 453::LR 0.0607692307692 --> Loss 0.000372314229608\n",
      "Epoch 18::Minibatch 454::LR 0.0607692307692 --> Loss 0.00358886003494\n",
      "Epoch 18::Minibatch 455::LR 0.0607692307692 --> Loss 0.00268537541231\n",
      "Epoch 18::Minibatch 456::LR 0.0607692307692 --> Loss 0.00311785161495\n",
      "Epoch 18::Minibatch 457::LR 0.0607692307692 --> Loss 0.0019493218263\n",
      "Epoch 18::Minibatch 458::LR 0.0607692307692 --> Loss 0.000749920954307\n",
      "Epoch 18::Minibatch 459::LR 0.0607692307692 --> Loss 0.00405387401581\n",
      "Epoch 18::Minibatch 460::LR 0.0607692307692 --> Loss 0.00256222387155\n",
      "Epoch 18::Minibatch 461::LR 0.0607692307692 --> Loss 0.00387681166331\n",
      "Epoch 18::Minibatch 462::LR 0.0607692307692 --> Loss 0.000390146821737\n",
      "Epoch 18::Minibatch 463::LR 0.0607692307692 --> Loss 0.00445448319117\n",
      "Epoch 18::Minibatch 464::LR 0.0607692307692 --> Loss 0.0020258462429\n",
      "Epoch 18::Minibatch 465::LR 0.0607692307692 --> Loss 0.00511950055758\n",
      "Epoch 18::Minibatch 466::LR 0.0607692307692 --> Loss 0.00511519471804\n",
      "Epoch 18::Minibatch 467::LR 0.0607692307692 --> Loss 0.00562775214513\n",
      "Epoch 18::Minibatch 468::LR 0.0607692307692 --> Loss 0.00602499405543\n",
      "Epoch 18::Minibatch 469::LR 0.0607692307692 --> Loss 0.00610852996508\n",
      "Epoch 18::Minibatch 470::LR 0.0607692307692 --> Loss 0.00373331824938\n",
      "Epoch 18::Minibatch 471::LR 0.0607692307692 --> Loss 0.00172896941503\n",
      "Epoch 18::Minibatch 472::LR 0.0607692307692 --> Loss 0.0035399889946\n",
      "Epoch 18::Minibatch 473::LR 0.0607692307692 --> Loss 0.00225473801295\n",
      "Epoch 18::Minibatch 474::LR 0.0607692307692 --> Loss 0.000698966731628\n",
      "Epoch 18::Minibatch 475::LR 0.0607692307692 --> Loss 0.00521853804588\n",
      "Epoch 18::Minibatch 476::LR 0.0607692307692 --> Loss 0.00784884373347\n",
      "Epoch 18::Minibatch 477::LR 0.0607692307692 --> Loss 0.00092853774627\n",
      "Epoch 18::Minibatch 478::LR 0.0607692307692 --> Loss 0.00244930207729\n",
      "Epoch 18::Minibatch 479::LR 0.0607692307692 --> Loss 0.00195912619432\n",
      "Epoch 18::Minibatch 480::LR 0.0607692307692 --> Loss 0.0015300227205\n",
      "Epoch 18::Minibatch 481::LR 0.0607692307692 --> Loss 0.00095706452926\n",
      "Epoch 18::Minibatch 482::LR 0.0607692307692 --> Loss 0.00209385037422\n",
      "Epoch 18::Minibatch 483::LR 0.0607692307692 --> Loss 0.0031578407685\n",
      "Epoch 18::Minibatch 484::LR 0.0607692307692 --> Loss 0.00352855443954\n",
      "Epoch 18::Minibatch 485::LR 0.0607692307692 --> Loss 0.000758809645971\n",
      "Epoch 18::Minibatch 486::LR 0.0607692307692 --> Loss 0.00293497820695\n",
      "Epoch 18::Minibatch 487::LR 0.0607692307692 --> Loss 0.00335818330447\n",
      "Epoch 18::Minibatch 488::LR 0.0607692307692 --> Loss 0.00204290568829\n",
      "Epoch 18::Minibatch 489::LR 0.0607692307692 --> Loss 0.00315779586633\n",
      "Epoch 18::Minibatch 490::LR 0.0607692307692 --> Loss 0.00041054546833\n",
      "Epoch 18::Minibatch 491::LR 0.0607692307692 --> Loss 0.00365057229996\n",
      "Epoch 18::Minibatch 492::LR 0.0607692307692 --> Loss 0.00305594484011\n",
      "Epoch 18::Minibatch 493::LR 0.0607692307692 --> Loss 0.00303404211998\n",
      "Epoch 18::Minibatch 494::LR 0.0607692307692 --> Loss 0.000738139698903\n",
      "Epoch 18::Minibatch 495::LR 0.0607692307692 --> Loss 0.00186962803205\n",
      "Epoch 18::Minibatch 496::LR 0.0607692307692 --> Loss 0.00287727177143\n",
      "Epoch 18::Minibatch 497::LR 0.0607692307692 --> Loss 0.000928591092428\n",
      "Epoch 18::Minibatch 498::LR 0.0607692307692 --> Loss 0.000562462111314\n",
      "Epoch 18::Minibatch 499::LR 0.0607692307692 --> Loss 0.0035993540287\n",
      "Epoch 18::Minibatch 500::LR 0.0607692307692 --> Loss 0.00144239892562\n",
      "Epoch 18::Minibatch 501::LR 0.0607692307692 --> Loss 0.00219251930714\n",
      "Epoch 18::Minibatch 502::LR 0.0607692307692 --> Loss 0.0038221180439\n",
      "Epoch 18::Minibatch 503::LR 0.0607692307692 --> Loss 0.00802745421727\n",
      "Epoch 18::Minibatch 504::LR 0.0607692307692 --> Loss 0.00757359822591\n",
      "Epoch 18::Minibatch 505::LR 0.0607692307692 --> Loss 0.00423882007599\n",
      "Epoch 18::Minibatch 506::LR 0.0607692307692 --> Loss 0.00344468275706\n",
      "Epoch 18::Minibatch 507::LR 0.0607692307692 --> Loss 0.00599675814311\n",
      "Epoch 18::Minibatch 508::LR 0.0607692307692 --> Loss 0.00341139435768\n",
      "Epoch 18::Minibatch 509::LR 0.0607692307692 --> Loss 0.00453534722328\n",
      "Epoch 18::Minibatch 510::LR 0.0607692307692 --> Loss 0.00455695788066\n",
      "Epoch 18::Minibatch 511::LR 0.0607692307692 --> Loss 0.00393098314603\n",
      "Epoch 18::Minibatch 512::LR 0.0607692307692 --> Loss 0.00268942395846\n",
      "Epoch 18::Minibatch 513::LR 0.0607692307692 --> Loss 0.000640136003494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 514::LR 0.0607692307692 --> Loss 0.00263614674409\n",
      "Epoch 18::Minibatch 515::LR 0.0607692307692 --> Loss 0.00301017900308\n",
      "Epoch 18::Minibatch 516::LR 0.0607692307692 --> Loss 0.00406434575717\n",
      "Epoch 18::Minibatch 517::LR 0.0607692307692 --> Loss 0.00352069735527\n",
      "Epoch 18::Minibatch 518::LR 0.0607692307692 --> Loss 0.002572808067\n",
      "Epoch 18::Minibatch 519::LR 0.0607692307692 --> Loss 0.00347098708153\n",
      "Epoch 18::Minibatch 520::LR 0.0607692307692 --> Loss 0.00538870930672\n",
      "Epoch 18::Minibatch 521::LR 0.0607692307692 --> Loss 0.00545455535253\n",
      "Epoch 18::Minibatch 522::LR 0.0607692307692 --> Loss 0.00790480613708\n",
      "Epoch 18::Minibatch 523::LR 0.0607692307692 --> Loss 0.00064668238163\n",
      "Epoch 18::Minibatch 524::LR 0.0607692307692 --> Loss 0.00142183442911\n",
      "Epoch 18::Minibatch 525::LR 0.0607692307692 --> Loss 0.00321467538675\n",
      "Epoch 18::Minibatch 526::LR 0.0607692307692 --> Loss 0.00398883660634\n",
      "Epoch 18::Minibatch 527::LR 0.0607692307692 --> Loss 0.00224846939246\n",
      "Epoch 18::Minibatch 528::LR 0.0607692307692 --> Loss 0.00103693564733\n",
      "Epoch 18::Minibatch 529::LR 0.0607692307692 --> Loss 0.0040570628643\n",
      "Epoch 18::Minibatch 530::LR 0.0607692307692 --> Loss 0.00409228006999\n",
      "Epoch 18::Minibatch 531::LR 0.0607692307692 --> Loss 0.00357350071271\n",
      "Epoch 18::Minibatch 532::LR 0.0607692307692 --> Loss 0.00269266049067\n",
      "Epoch 18::Minibatch 533::LR 0.0607692307692 --> Loss 0.00495022614797\n",
      "Epoch 18::Minibatch 534::LR 0.0607692307692 --> Loss 0.00380093137423\n",
      "Epoch 18::Minibatch 535::LR 0.0607692307692 --> Loss 0.00324735244115\n",
      "Epoch 18::Minibatch 536::LR 0.0607692307692 --> Loss 0.00211160163085\n",
      "Epoch 18::Minibatch 537::LR 0.0607692307692 --> Loss 0.000619599322478\n",
      "Epoch 18::Minibatch 538::LR 0.0607692307692 --> Loss 0.00168454209963\n",
      "Epoch 18::Minibatch 539::LR 0.0607692307692 --> Loss 0.00341669480006\n",
      "Epoch 18::Minibatch 540::LR 0.0607692307692 --> Loss 0.00342010776202\n",
      "Epoch 18::Minibatch 541::LR 0.0607692307692 --> Loss 0.00289977192879\n",
      "Epoch 18::Minibatch 542::LR 0.0607692307692 --> Loss 0.00250853677591\n",
      "Epoch 18::Minibatch 543::LR 0.0607692307692 --> Loss 0.0027245036761\n",
      "Epoch 18::Minibatch 544::LR 0.0607692307692 --> Loss 0.00391353050868\n",
      "Epoch 18::Minibatch 545::LR 0.0607692307692 --> Loss 0.00203701138496\n",
      "Epoch 18::Minibatch 546::LR 0.0607692307692 --> Loss 0.000654987643162\n",
      "Epoch 18::Minibatch 547::LR 0.0607692307692 --> Loss 0.00262046456337\n",
      "Epoch 18::Minibatch 548::LR 0.0607692307692 --> Loss 0.00365433851878\n",
      "Epoch 18::Minibatch 549::LR 0.0607692307692 --> Loss 0.00871428410212\n",
      "Epoch 18::Minibatch 550::LR 0.0607692307692 --> Loss 0.00117088526487\n",
      "Epoch 18::Minibatch 551::LR 0.0607692307692 --> Loss 0.00245349566142\n",
      "Epoch 18::Minibatch 552::LR 0.0607692307692 --> Loss 0.00354186813037\n",
      "Epoch 18::Minibatch 553::LR 0.0607692307692 --> Loss 0.00317529380322\n",
      "Epoch 18::Minibatch 554::LR 0.0607692307692 --> Loss 0.00373248855273\n",
      "Epoch 18::Minibatch 555::LR 0.0607692307692 --> Loss 0.000976287424564\n",
      "Epoch 18::Minibatch 556::LR 0.0607692307692 --> Loss 0.00198454797268\n",
      "Epoch 18::Minibatch 557::LR 0.0607692307692 --> Loss 0.0024281257391\n",
      "Epoch 18::Minibatch 558::LR 0.0607692307692 --> Loss 0.00368989070257\n",
      "Epoch 18::Minibatch 559::LR 0.0607692307692 --> Loss 0.00372826139132\n",
      "Epoch 18::Minibatch 560::LR 0.0607692307692 --> Loss 0.00307434161504\n",
      "Epoch 18::Minibatch 561::LR 0.0607692307692 --> Loss 0.00269714792569\n",
      "Epoch 18::Minibatch 562::LR 0.0607692307692 --> Loss 0.00237145662308\n",
      "Epoch 18::Minibatch 563::LR 0.0607692307692 --> Loss 0.00401980956395\n",
      "Epoch 18::Minibatch 564::LR 0.0607692307692 --> Loss 0.00311143040657\n",
      "Epoch 18::Minibatch 565::LR 0.0607692307692 --> Loss 0.003671058019\n",
      "Epoch 18::Minibatch 566::LR 0.0607692307692 --> Loss 0.00227028508981\n",
      "Epoch 18::Minibatch 567::LR 0.0607692307692 --> Loss 0.00256614724795\n",
      "Epoch 18::Minibatch 568::LR 0.0607692307692 --> Loss 0.00180708428224\n",
      "Epoch 18::Minibatch 569::LR 0.0607692307692 --> Loss 0.000564310252666\n",
      "Epoch 18::Minibatch 570::LR 0.0607692307692 --> Loss 0.00169536650181\n",
      "Epoch 18::Minibatch 571::LR 0.0607692307692 --> Loss 0.00220903456211\n",
      "Epoch 18::Minibatch 572::LR 0.0607692307692 --> Loss 0.00235285282135\n",
      "Epoch 18::Minibatch 573::LR 0.0607692307692 --> Loss 0.00150168081125\n",
      "Epoch 18::Minibatch 574::LR 0.0607692307692 --> Loss 0.00104940573374\n",
      "Epoch 18::Minibatch 575::LR 0.0607692307692 --> Loss 0.00177899579207\n",
      "Epoch 18::Minibatch 576::LR 0.0607692307692 --> Loss 0.00210801680883\n",
      "Epoch 18::Minibatch 577::LR 0.0607692307692 --> Loss 0.00165730943282\n",
      "Epoch 18::Minibatch 578::LR 0.0607692307692 --> Loss 0.00128689398368\n",
      "Epoch 18::Minibatch 579::LR 0.0607692307692 --> Loss 0.00120034952958\n",
      "Epoch 18::Minibatch 580::LR 0.0607692307692 --> Loss 0.00194478491942\n",
      "Epoch 18::Minibatch 581::LR 0.0607692307692 --> Loss 0.00171768605709\n",
      "Epoch 18::Minibatch 582::LR 0.0607692307692 --> Loss 0.0041347138087\n",
      "Epoch 18::Minibatch 583::LR 0.0607692307692 --> Loss 0.000943642854691\n",
      "Epoch 18::Minibatch 584::LR 0.0607692307692 --> Loss 0.00130974123875\n",
      "Epoch 18::Minibatch 585::LR 0.0607692307692 --> Loss 0.00433984875679\n",
      "Epoch 18::Minibatch 586::LR 0.0607692307692 --> Loss 0.00396922429403\n",
      "Epoch 18::Minibatch 587::LR 0.0607692307692 --> Loss 0.0011293031772\n",
      "Epoch 18::Minibatch 588::LR 0.0607692307692 --> Loss 0.00140703668197\n",
      "Epoch 18::Minibatch 589::LR 0.0607692307692 --> Loss 0.00276954392592\n",
      "Epoch 18::Minibatch 590::LR 0.0607692307692 --> Loss 0.0019341335694\n",
      "Epoch 18::Minibatch 591::LR 0.0607692307692 --> Loss 0.00300402462482\n",
      "Epoch 18::Minibatch 592::LR 0.0607692307692 --> Loss 0.00117818613847\n",
      "Epoch 18::Minibatch 593::LR 0.0607692307692 --> Loss 0.00259318073591\n",
      "Epoch 18::Minibatch 594::LR 0.0607692307692 --> Loss 0.00273517648379\n",
      "Epoch 18::Minibatch 595::LR 0.0607692307692 --> Loss 0.00305024862289\n",
      "Epoch 18::Minibatch 596::LR 0.0607692307692 --> Loss 0.00193295657635\n",
      "Epoch 18::Minibatch 597::LR 0.0607692307692 --> Loss 0.00119163463513\n",
      "Epoch 18::Minibatch 598::LR 0.0607692307692 --> Loss 0.00299055119356\n",
      "Epoch 18::Minibatch 599::LR 0.0607692307692 --> Loss 0.00185499966145\n",
      "Epoch 18::Minibatch 600::LR 0.0607692307692 --> Loss 0.00221513032913\n",
      "Epoch 18::Minibatch 601::LR 0.0607692307692 --> Loss 0.00388188401858\n",
      "Epoch 18::Minibatch 602::LR 0.0607692307692 --> Loss 0.0021189413468\n",
      "Epoch 18::Minibatch 603::LR 0.0607692307692 --> Loss 0.00264735817909\n",
      "Epoch 18::Minibatch 604::LR 0.0607692307692 --> Loss 0.00165482829014\n",
      "Epoch 18::Minibatch 605::LR 0.0607692307692 --> Loss 0.00237342913946\n",
      "Epoch 18::Minibatch 606::LR 0.0607692307692 --> Loss 0.00192173302174\n",
      "Epoch 18::Minibatch 607::LR 0.0607692307692 --> Loss 0.000843887329102\n",
      "Epoch 18::Minibatch 608::LR 0.0607692307692 --> Loss 0.00158495664597\n",
      "Epoch 18::Minibatch 609::LR 0.0607692307692 --> Loss 0.00239724139373\n",
      "Epoch 18::Minibatch 610::LR 0.0607692307692 --> Loss 0.00404107610385\n",
      "Epoch 18::Minibatch 611::LR 0.0607692307692 --> Loss 0.00264660259088\n",
      "Epoch 18::Minibatch 612::LR 0.0607692307692 --> Loss 0.000485687851906\n",
      "Epoch 18::Minibatch 613::LR 0.0607692307692 --> Loss 0.00131401618322\n",
      "Epoch 18::Minibatch 614::LR 0.0607692307692 --> Loss 0.00245790461699\n",
      "Epoch 18::Minibatch 615::LR 0.0607692307692 --> Loss 0.00168423295021\n",
      "Epoch 18::Minibatch 616::LR 0.0607692307692 --> Loss 0.000927626589934\n",
      "Epoch 18::Minibatch 617::LR 0.0607692307692 --> Loss 0.000503417849541\n",
      "Epoch 18::Minibatch 618::LR 0.0607692307692 --> Loss 0.00277353982131\n",
      "Epoch 18::Minibatch 619::LR 0.0607692307692 --> Loss 0.00192709982395\n",
      "Epoch 18::Minibatch 620::LR 0.0607692307692 --> Loss 0.00172066609065\n",
      "Epoch 18::Minibatch 621::LR 0.0607692307692 --> Loss 0.0008557716012\n",
      "Epoch 18::Minibatch 622::LR 0.0607692307692 --> Loss 0.0008006148537\n",
      "Epoch 18::Minibatch 623::LR 0.0607692307692 --> Loss 0.00222243408362\n",
      "Epoch 18::Minibatch 624::LR 0.0607692307692 --> Loss 0.00181057492892\n",
      "Epoch 18::Minibatch 625::LR 0.0607692307692 --> Loss 0.00292955875397\n",
      "Epoch 18::Minibatch 626::LR 0.0607692307692 --> Loss 0.00433948993683\n",
      "Epoch 18::Minibatch 627::LR 0.0607692307692 --> Loss 0.00131947269042\n",
      "Epoch 18::Minibatch 628::LR 0.0607692307692 --> Loss 0.000900765657425\n",
      "Epoch 18::Minibatch 629::LR 0.0607692307692 --> Loss 0.00336943825086\n",
      "Epoch 18::Minibatch 630::LR 0.0607692307692 --> Loss 0.00328225413958\n",
      "Epoch 18::Minibatch 631::LR 0.0607692307692 --> Loss 0.00625995516777\n",
      "Epoch 18::Minibatch 632::LR 0.0607692307692 --> Loss 0.00079533825318\n",
      "Epoch 18::Minibatch 633::LR 0.0607692307692 --> Loss 0.00165414611499\n",
      "Epoch 18::Minibatch 634::LR 0.0607692307692 --> Loss 0.00324490368366\n",
      "Epoch 18::Minibatch 635::LR 0.0607692307692 --> Loss 0.00533293525378\n",
      "Epoch 18::Minibatch 636::LR 0.0607692307692 --> Loss 0.00506130814552\n",
      "Epoch 18::Minibatch 637::LR 0.0607692307692 --> Loss 0.000781069944302\n",
      "Epoch 18::Minibatch 638::LR 0.0607692307692 --> Loss 0.00151624619961\n",
      "Epoch 18::Minibatch 639::LR 0.0607692307692 --> Loss 0.00329965094725\n",
      "Epoch 18::Minibatch 640::LR 0.0607692307692 --> Loss 0.00495337684949\n",
      "Epoch 18::Minibatch 641::LR 0.0607692307692 --> Loss 0.00312555392583\n",
      "Epoch 18::Minibatch 642::LR 0.0607692307692 --> Loss 0.000547762215137\n",
      "Epoch 18::Minibatch 643::LR 0.0607692307692 --> Loss 0.00234556376934\n",
      "Epoch 18::Minibatch 644::LR 0.0607692307692 --> Loss 0.00397876103719\n",
      "Epoch 18::Minibatch 645::LR 0.0607692307692 --> Loss 0.00423110286395\n",
      "Epoch 18::Minibatch 646::LR 0.0607692307692 --> Loss 0.00151715983947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 647::LR 0.0607692307692 --> Loss 0.000523392707109\n",
      "Epoch 18::Minibatch 648::LR 0.0607692307692 --> Loss 0.00295641362667\n",
      "Epoch 18::Minibatch 649::LR 0.0607692307692 --> Loss 0.00351493676503\n",
      "Epoch 18::Minibatch 650::LR 0.0607692307692 --> Loss 0.00330998440584\n",
      "Epoch 18::Minibatch 651::LR 0.0607692307692 --> Loss 0.00138276855151\n",
      "Epoch 18::Minibatch 652::LR 0.0607692307692 --> Loss 0.000807754695415\n",
      "Epoch 18::Minibatch 653::LR 0.0607692307692 --> Loss 0.00285974641641\n",
      "Epoch 18::Minibatch 654::LR 0.0607692307692 --> Loss 0.0031194426616\n",
      "Epoch 18::Minibatch 655::LR 0.0607692307692 --> Loss 0.00351207057635\n",
      "Epoch 18::Minibatch 656::LR 0.0607692307692 --> Loss 0.00076174835364\n",
      "Epoch 18::Minibatch 657::LR 0.0607692307692 --> Loss 0.00224401414394\n",
      "Epoch 18::Minibatch 658::LR 0.0607692307692 --> Loss 0.00487381656965\n",
      "Epoch 18::Minibatch 659::LR 0.0607692307692 --> Loss 0.00230875154336\n",
      "Epoch 18::Minibatch 660::LR 0.0607692307692 --> Loss 0.00262175242106\n",
      "Epoch 18::Minibatch 661::LR 0.0607692307692 --> Loss 0.00247694810232\n",
      "Epoch 18::Minibatch 662::LR 0.0607692307692 --> Loss 0.00181986153126\n",
      "Epoch 18::Minibatch 663::LR 0.0607692307692 --> Loss 0.00368030071259\n",
      "Epoch 18::Minibatch 664::LR 0.0607692307692 --> Loss 0.00339558124542\n",
      "Epoch 18::Minibatch 665::LR 0.0607692307692 --> Loss 0.000732490966717\n",
      "Epoch 18::Minibatch 666::LR 0.0607692307692 --> Loss 0.00392826954524\n",
      "Epoch 18::Minibatch 667::LR 0.0607692307692 --> Loss 0.0025542396307\n",
      "Epoch 18::Minibatch 668::LR 0.0607692307692 --> Loss 0.00692327578863\n",
      "Epoch 18::Minibatch 669::LR 0.0607692307692 --> Loss 0.00109408080578\n",
      "Epoch 18::Minibatch 670::LR 0.0607692307692 --> Loss 0.00135446727276\n",
      "Epoch 18::Minibatch 671::LR 0.0607692307692 --> Loss 0.00534665266673\n",
      "Epoch 18::Minibatch 672::LR 0.0607692307692 --> Loss 0.00370552976926\n",
      "Epoch 18::Minibatch 673::LR 0.0607692307692 --> Loss 0.00162253816923\n",
      "Epoch 18::Minibatch 674::LR 0.0607692307692 --> Loss 0.000515832006931\n",
      "Epoch 18::Minibatch 675::LR 0.0607692307692 --> Loss 0.00218826293945\n",
      "Epoch 18::Minibatch 676::LR 0.0607692307692 --> Loss 0.0021331791083\n",
      "Epoch 18::Minibatch 677::LR 0.0607692307692 --> Loss 0.002797772487\n",
      "Epoch 18::Minibatch 678::LR 0.0607692307692 --> Loss 0.00192707558473\n",
      "Epoch 18::Minibatch 679::LR 0.0607692307692 --> Loss 0.00349268992742\n",
      "Epoch 18::Minibatch 680::LR 0.0607692307692 --> Loss 0.00214543203513\n",
      "Epoch 18::Minibatch 681::LR 0.0607692307692 --> Loss 0.00243577539921\n",
      "Epoch 18::Minibatch 682::LR 0.0607692307692 --> Loss 0.000761900742849\n",
      "Epoch 18::Minibatch 683::LR 0.0607692307692 --> Loss 0.00237389584382\n",
      "Epoch 18::Minibatch 684::LR 0.0607692307692 --> Loss 0.00235447684924\n",
      "Epoch 18::Minibatch 685::LR 0.0607692307692 --> Loss 0.00290477136771\n",
      "Epoch 18::Minibatch 686::LR 0.0607692307692 --> Loss 0.00155458122492\n",
      "Epoch 18::Minibatch 687::LR 0.0607692307692 --> Loss 0.000852130850156\n",
      "Epoch 18::Minibatch 688::LR 0.0607692307692 --> Loss 0.00276584664981\n",
      "Epoch 18::Minibatch 689::LR 0.0607692307692 --> Loss 0.00252831578255\n",
      "Epoch 18::Minibatch 690::LR 0.0607692307692 --> Loss 0.00191621442636\n",
      "Epoch 18::Minibatch 691::LR 0.0607692307692 --> Loss 0.000660013854504\n",
      "Epoch 18::Minibatch 692::LR 0.0607692307692 --> Loss 0.0024678581953\n",
      "Epoch 18::Minibatch 693::LR 0.0607692307692 --> Loss 0.00258236408234\n",
      "Epoch 18::Minibatch 694::LR 0.0607692307692 --> Loss 0.00302270253499\n",
      "Epoch 18::Minibatch 695::LR 0.0607692307692 --> Loss 0.00174601852894\n",
      "Epoch 18::Minibatch 696::LR 0.0607692307692 --> Loss 0.00204604367415\n",
      "Epoch 18::Minibatch 697::LR 0.0607692307692 --> Loss 0.00140789677699\n",
      "Epoch 18::Minibatch 698::LR 0.0607692307692 --> Loss 0.00163669566313\n",
      "Epoch 18::Minibatch 699::LR 0.0607692307692 --> Loss 0.00383664608002\n",
      "Epoch 18::Minibatch 700::LR 0.0607692307692 --> Loss 0.00267115314802\n",
      "Epoch 18::Minibatch 701::LR 0.0607692307692 --> Loss 0.0019784150521\n",
      "Epoch 18::Minibatch 702::LR 0.0607692307692 --> Loss 0.00166506846746\n",
      "Epoch 18::Minibatch 703::LR 0.0607692307692 --> Loss 0.00431139628092\n",
      "Epoch 18::Minibatch 704::LR 0.0607692307692 --> Loss 0.00180482347806\n",
      "Epoch 18::Minibatch 705::LR 0.0607692307692 --> Loss 0.00286700526873\n",
      "Epoch 18::Minibatch 706::LR 0.0607692307692 --> Loss 0.00224490205447\n",
      "Epoch 18::Minibatch 707::LR 0.0607692307692 --> Loss 0.00118718942006\n",
      "Epoch 18::Minibatch 708::LR 0.0607692307692 --> Loss 0.00173543473085\n",
      "Epoch 18::Minibatch 709::LR 0.0607692307692 --> Loss 0.00168572743734\n",
      "Epoch 18::Minibatch 710::LR 0.0607692307692 --> Loss 0.00252676943938\n",
      "Epoch 18::Minibatch 711::LR 0.0607692307692 --> Loss 0.00193147917589\n",
      "Epoch 18::Minibatch 712::LR 0.0607692307692 --> Loss 0.00133473763863\n",
      "Epoch 18::Minibatch 713::LR 0.0607692307692 --> Loss 0.0017631683747\n",
      "Epoch 18::Minibatch 714::LR 0.0607692307692 --> Loss 0.00276362419128\n",
      "Epoch 18::Minibatch 715::LR 0.0607692307692 --> Loss 0.00294092794259\n",
      "Epoch 18::Minibatch 716::LR 0.0607692307692 --> Loss 0.00162002851566\n",
      "Epoch 18::Minibatch 717::LR 0.0607692307692 --> Loss 0.00162189265092\n",
      "Epoch 18::Minibatch 718::LR 0.0607692307692 --> Loss 0.00125937153896\n",
      "Epoch 18::Minibatch 719::LR 0.0607692307692 --> Loss 0.00167467594147\n",
      "Epoch 18::Minibatch 720::LR 0.0607692307692 --> Loss 0.00256987432639\n",
      "Epoch 18::Minibatch 721::LR 0.0607692307692 --> Loss 0.000620392560959\n",
      "Epoch 18::Minibatch 722::LR 0.0607692307692 --> Loss 0.00477368672689\n",
      "Epoch 18::Minibatch 723::LR 0.0607692307692 --> Loss 0.00490222414335\n",
      "Epoch 18::Minibatch 724::LR 0.0607692307692 --> Loss 0.000967833002408\n",
      "Epoch 18::Minibatch 725::LR 0.0607692307692 --> Loss 0.00216149449348\n",
      "Epoch 18::Minibatch 726::LR 0.0607692307692 --> Loss 0.00449132720629\n",
      "Epoch 18::Minibatch 727::LR 0.0607692307692 --> Loss 0.00322247425715\n",
      "Epoch 18::Minibatch 728::LR 0.0607692307692 --> Loss 0.000646108587583\n",
      "Epoch 18::Minibatch 729::LR 0.0607692307692 --> Loss 0.000744748959939\n",
      "Epoch 18::Minibatch 730::LR 0.0607692307692 --> Loss 0.00280910511812\n",
      "Epoch 18::Minibatch 731::LR 0.0607692307692 --> Loss 0.00250932574272\n",
      "Epoch 18::Minibatch 732::LR 0.0607692307692 --> Loss 0.0022014160951\n",
      "Epoch 18::Minibatch 733::LR 0.0607692307692 --> Loss 0.000673387398322\n",
      "Epoch 18::Minibatch 734::LR 0.0607692307692 --> Loss 0.00172080377738\n",
      "Epoch 18::Minibatch 735::LR 0.0607692307692 --> Loss 0.00237066527208\n",
      "Epoch 18::Minibatch 736::LR 0.0607692307692 --> Loss 0.00346951921781\n",
      "Epoch 18::Minibatch 737::LR 0.0607692307692 --> Loss 0.0030650271972\n",
      "Epoch 18::Minibatch 738::LR 0.0607692307692 --> Loss 0.00156662692626\n",
      "Epoch 18::Minibatch 739::LR 0.0607692307692 --> Loss 0.0024476848046\n",
      "Epoch 18::Minibatch 740::LR 0.0607692307692 --> Loss 0.00383658925692\n",
      "Epoch 18::Minibatch 741::LR 0.0607692307692 --> Loss 0.0026673712333\n",
      "Epoch 18::Minibatch 742::LR 0.0607692307692 --> Loss 0.00211243669192\n",
      "Epoch 18::Minibatch 743::LR 0.0607692307692 --> Loss 0.00140351215998\n",
      "Epoch 18::Minibatch 744::LR 0.0607692307692 --> Loss 0.00180567880472\n",
      "Epoch 18::Minibatch 745::LR 0.0607692307692 --> Loss 0.0028343774875\n",
      "Epoch 18::Minibatch 746::LR 0.0607692307692 --> Loss 0.00296636243661\n",
      "Epoch 18::Minibatch 747::LR 0.0607692307692 --> Loss 0.00179028650125\n",
      "Epoch 18::Minibatch 748::LR 0.0607692307692 --> Loss 0.000628079622984\n",
      "Epoch 18::Minibatch 749::LR 0.0607692307692 --> Loss 0.00165309170882\n",
      "Epoch 18::Minibatch 750::LR 0.0607692307692 --> Loss 0.00246087829272\n",
      "Epoch 18::Minibatch 751::LR 0.0607692307692 --> Loss 0.00276514708996\n",
      "Epoch 18::Minibatch 752::LR 0.0607692307692 --> Loss 0.00121452411016\n",
      "Epoch 18::Minibatch 753::LR 0.0607692307692 --> Loss 0.00222324252129\n",
      "Epoch 18::Minibatch 754::LR 0.0607692307692 --> Loss 0.00240186015765\n",
      "Epoch 18::Minibatch 755::LR 0.0607692307692 --> Loss 0.00266558965047\n",
      "Epoch 18::Minibatch 756::LR 0.0607692307692 --> Loss 0.0013724331061\n",
      "Epoch 18::Minibatch 757::LR 0.0607692307692 --> Loss 0.00075861637791\n",
      "Epoch 18::Minibatch 758::LR 0.0607692307692 --> Loss 0.00160576959451\n",
      "Epoch 18::Minibatch 759::LR 0.0607692307692 --> Loss 0.00372060775757\n",
      "Epoch 18::Minibatch 760::LR 0.0607692307692 --> Loss 0.00294388115406\n",
      "Epoch 18::Minibatch 761::LR 0.0607692307692 --> Loss 0.0062107026577\n",
      "Epoch 18::Minibatch 762::LR 0.0607692307692 --> Loss 0.00374032219251\n",
      "Epoch 18::Minibatch 763::LR 0.0607692307692 --> Loss 0.0035392677784\n",
      "Epoch 18::Minibatch 764::LR 0.0607692307692 --> Loss 0.00317444086075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 765::LR 0.0607692307692 --> Loss 0.00130470434825\n",
      "Epoch 18::Minibatch 766::LR 0.0607692307692 --> Loss 0.00228051026662\n",
      "Epoch 18::Minibatch 767::LR 0.0607692307692 --> Loss 0.00496753414472\n",
      "Epoch 18::Minibatch 768::LR 0.0607692307692 --> Loss 0.0036302336057\n",
      "Epoch 18::Minibatch 769::LR 0.0607692307692 --> Loss 0.00188583473365\n",
      "Epoch 18::Minibatch 770::LR 0.0607692307692 --> Loss 0.00146341701349\n",
      "Epoch 18::Minibatch 771::LR 0.0607692307692 --> Loss 0.00365443030993\n",
      "Epoch 18::Minibatch 772::LR 0.0607692307692 --> Loss 0.00342967907588\n",
      "Epoch 18::Minibatch 773::LR 0.0607692307692 --> Loss 0.00313745319843\n",
      "Epoch 18::Minibatch 774::LR 0.0607692307692 --> Loss 0.00179202854633\n",
      "Epoch 18::Minibatch 775::LR 0.0607692307692 --> Loss 0.00374050656954\n",
      "Epoch 18::Minibatch 776::LR 0.0607692307692 --> Loss 0.00358504851659\n",
      "Epoch 18::Minibatch 777::LR 0.0607692307692 --> Loss 0.00726583401362\n",
      "Epoch 18::Minibatch 778::LR 0.0607692307692 --> Loss 0.00915428241094\n",
      "Epoch 18::Minibatch 779::LR 0.0607692307692 --> Loss 0.00232693632444\n",
      "Epoch 18::Minibatch 780::LR 0.0607692307692 --> Loss 0.00159361730019\n",
      "Epoch 18::Minibatch 781::LR 0.0607692307692 --> Loss 0.00345360517502\n",
      "Epoch 18::Minibatch 782::LR 0.0607692307692 --> Loss 0.00394442717234\n",
      "Epoch 18::Minibatch 783::LR 0.0607692307692 --> Loss 0.00229791164398\n",
      "Epoch 18::Minibatch 784::LR 0.0607692307692 --> Loss 0.000713235338529\n",
      "Epoch 18::Minibatch 785::LR 0.0607692307692 --> Loss 0.00339018583298\n",
      "Epoch 18::Minibatch 786::LR 0.0607692307692 --> Loss 0.00344613393148\n",
      "Epoch 18::Minibatch 787::LR 0.0607692307692 --> Loss 0.00268145442009\n",
      "Epoch 18::Minibatch 788::LR 0.0607692307692 --> Loss 0.00238440195719\n",
      "Epoch 18::Minibatch 789::LR 0.0607692307692 --> Loss 0.000737516035636\n",
      "Epoch 18::Minibatch 790::LR 0.0607692307692 --> Loss 0.00315923849742\n",
      "Epoch 18::Minibatch 791::LR 0.0607692307692 --> Loss 0.00352750301361\n",
      "Epoch 18::Minibatch 792::LR 0.0607692307692 --> Loss 0.00311871111393\n",
      "Epoch 18::Minibatch 793::LR 0.0607692307692 --> Loss 0.0017594854037\n",
      "Epoch 18::Minibatch 794::LR 0.0607692307692 --> Loss 0.0010181226333\n",
      "Epoch 18::Minibatch 795::LR 0.0607692307692 --> Loss 0.00295145352681\n",
      "Epoch 18::Minibatch 796::LR 0.0607692307692 --> Loss 0.00550562620163\n",
      "Epoch 18::Minibatch 797::LR 0.0607692307692 --> Loss 0.00700525124868\n",
      "Epoch 18::Minibatch 798::LR 0.0607692307692 --> Loss 0.00325980861982\n",
      "Epoch 18::Minibatch 799::LR 0.0607692307692 --> Loss 0.00234026312828\n",
      "Epoch 18::Minibatch 800::LR 0.0607692307692 --> Loss 0.0020191325744\n",
      "Epoch 18::Minibatch 801::LR 0.0607692307692 --> Loss 0.00413319508235\n",
      "Epoch 18::Minibatch 802::LR 0.0607692307692 --> Loss 0.00129076947769\n",
      "Epoch 18::Minibatch 803::LR 0.0607692307692 --> Loss 0.00286862015724\n",
      "Epoch 18::Minibatch 804::LR 0.0607692307692 --> Loss 0.00215591132641\n",
      "Epoch 18::Minibatch 805::LR 0.0607692307692 --> Loss 0.00225438654423\n",
      "Epoch 18::Minibatch 806::LR 0.0607692307692 --> Loss 0.00334834694862\n",
      "Epoch 18::Minibatch 807::LR 0.0607692307692 --> Loss 0.00303163766861\n",
      "Epoch 18::Minibatch 808::LR 0.0607692307692 --> Loss 0.002678399086\n",
      "Epoch 18::Minibatch 809::LR 0.0607692307692 --> Loss 0.00361961404483\n",
      "Epoch 18::Minibatch 810::LR 0.0607692307692 --> Loss 0.00490513761838\n",
      "Epoch 18::Minibatch 811::LR 0.0607692307692 --> Loss 0.00464149355888\n",
      "Epoch 18::Minibatch 812::LR 0.0607692307692 --> Loss 0.00424366354942\n",
      "Epoch 18::Minibatch 813::LR 0.0607692307692 --> Loss 0.00370837410291\n",
      "Epoch 18::Minibatch 814::LR 0.0607692307692 --> Loss 0.00170960088571\n",
      "Epoch 18::Minibatch 815::LR 0.0607692307692 --> Loss 0.00374205112457\n",
      "Epoch 18::Minibatch 816::LR 0.0607692307692 --> Loss 0.0041234155496\n",
      "Epoch 18::Minibatch 817::LR 0.0607692307692 --> Loss 0.00550374865532\n",
      "Epoch 18::Minibatch 818::LR 0.0607692307692 --> Loss 0.00126397142808\n",
      "Epoch 18::Minibatch 819::LR 0.0607692307692 --> Loss 0.000703529417515\n",
      "Epoch 18::Minibatch 820::LR 0.0607692307692 --> Loss 0.00529961943626\n",
      "Epoch 18::Minibatch 821::LR 0.0607692307692 --> Loss 0.00313217242559\n",
      "Epoch 18::Minibatch 822::LR 0.0607692307692 --> Loss 0.00370538592339\n",
      "Epoch 18::Minibatch 823::LR 0.0607692307692 --> Loss 0.00129292031129\n",
      "Epoch 18::Minibatch 824::LR 0.0607692307692 --> Loss 0.00137859463692\n",
      "Epoch 18::Minibatch 825::LR 0.0607692307692 --> Loss 0.00367050886154\n",
      "Epoch 18::Minibatch 826::LR 0.0607692307692 --> Loss 0.00397280693054\n",
      "Epoch 18::Minibatch 827::LR 0.0607692307692 --> Loss 0.00208943049113\n",
      "Epoch 18::Minibatch 828::LR 0.0607692307692 --> Loss 0.000527914216121\n",
      "Epoch 18::Minibatch 829::LR 0.0607692307692 --> Loss 0.00235599279404\n",
      "Epoch 18::Minibatch 830::LR 0.0607692307692 --> Loss 0.00430864651998\n",
      "Epoch 18::Minibatch 831::LR 0.0607692307692 --> Loss 0.002533223629\n",
      "Epoch 18::Minibatch 832::LR 0.0607692307692 --> Loss 0.00221858282884\n",
      "Epoch 18::Minibatch 833::LR 0.0607692307692 --> Loss 0.00183973888556\n",
      "Epoch 18::Minibatch 834::LR 0.0607692307692 --> Loss 0.000774411509434\n",
      "Epoch 18::Minibatch 835::LR 0.0607692307692 --> Loss 0.00378591497739\n",
      "Epoch 18::Minibatch 836::LR 0.0607692307692 --> Loss 0.00368502577146\n",
      "Epoch 18::Minibatch 837::LR 0.0607692307692 --> Loss 0.00219196677208\n",
      "Epoch 18::Minibatch 838::LR 0.0607692307692 --> Loss 0.000630220472813\n",
      "Epoch 18::Minibatch 839::LR 0.0607692307692 --> Loss 0.00245682915052\n",
      "Epoch 18::Minibatch 840::LR 0.0607692307692 --> Loss 0.0028882586956\n",
      "Epoch 18::Minibatch 841::LR 0.0607692307692 --> Loss 0.00281882345676\n",
      "Epoch 18::Minibatch 842::LR 0.0607692307692 --> Loss 0.00207817951838\n",
      "Epoch 18::Minibatch 843::LR 0.0607692307692 --> Loss 0.00100228528182\n",
      "Epoch 18::Minibatch 844::LR 0.0607692307692 --> Loss 0.00148847083251\n",
      "Epoch 18::Minibatch 845::LR 0.0607692307692 --> Loss 0.00427948594093\n",
      "Epoch 18::Minibatch 846::LR 0.0607692307692 --> Loss 0.0016732275486\n",
      "Epoch 18::Minibatch 847::LR 0.0607692307692 --> Loss 0.00228348612785\n",
      "Epoch 18::Minibatch 848::LR 0.0607692307692 --> Loss 0.00101579745611\n",
      "Epoch 18::Minibatch 849::LR 0.0607692307692 --> Loss 0.00182701130708\n",
      "Epoch 18::Minibatch 850::LR 0.0607692307692 --> Loss 0.00317135930061\n",
      "Epoch 18::Minibatch 851::LR 0.0607692307692 --> Loss 0.00264401992162\n",
      "Epoch 18::Minibatch 852::LR 0.0607692307692 --> Loss 0.00107881595691\n",
      "Epoch 18::Minibatch 853::LR 0.0607692307692 --> Loss 0.00130432963371\n",
      "Epoch 18::Minibatch 854::LR 0.0607692307692 --> Loss 0.00256610353788\n",
      "Epoch 18::Minibatch 855::LR 0.0607692307692 --> Loss 0.00215732177099\n",
      "Epoch 18::Minibatch 856::LR 0.0607692307692 --> Loss 0.00178857584794\n",
      "Epoch 18::Minibatch 857::LR 0.0607692307692 --> Loss 0.00121084491412\n",
      "Epoch 18::Minibatch 858::LR 0.0607692307692 --> Loss 0.000593965599934\n",
      "Epoch 18::Minibatch 859::LR 0.0607692307692 --> Loss 0.00191317300002\n",
      "Epoch 18::Minibatch 860::LR 0.0607692307692 --> Loss 0.00125139832497\n",
      "Epoch 18::Minibatch 861::LR 0.0607692307692 --> Loss 0.000935338437557\n",
      "Epoch 18::Minibatch 862::LR 0.0607692307692 --> Loss 0.00364173968633\n",
      "Epoch 18::Minibatch 863::LR 0.0607692307692 --> Loss 0.0034043443203\n",
      "Epoch 18::Minibatch 864::LR 0.0607692307692 --> Loss 0.00283284246922\n",
      "Epoch 18::Minibatch 865::LR 0.0607692307692 --> Loss 0.000437283317248\n",
      "Epoch 18::Minibatch 866::LR 0.0607692307692 --> Loss 0.00213128626347\n",
      "Epoch 18::Minibatch 867::LR 0.0607692307692 --> Loss 0.00295178075631\n",
      "Epoch 18::Minibatch 868::LR 0.0607692307692 --> Loss 0.00243053813775\n",
      "Epoch 18::Minibatch 869::LR 0.0607692307692 --> Loss 0.00210720817248\n",
      "Epoch 18::Minibatch 870::LR 0.0607692307692 --> Loss 0.00349509358406\n",
      "Epoch 18::Minibatch 871::LR 0.0607692307692 --> Loss 0.00153168867032\n",
      "Epoch 18::Minibatch 872::LR 0.0607692307692 --> Loss 0.00224826236566\n",
      "Epoch 18::Minibatch 873::LR 0.0607692307692 --> Loss 0.00246731221676\n",
      "Epoch 18::Minibatch 874::LR 0.0607692307692 --> Loss 0.00604732394218\n",
      "Epoch 18::Minibatch 875::LR 0.0607692307692 --> Loss 0.000526226709286\n",
      "Epoch 18::Minibatch 876::LR 0.0607692307692 --> Loss 0.00312508841356\n",
      "Epoch 18::Minibatch 877::LR 0.0607692307692 --> Loss 0.00579138318698\n",
      "Epoch 18::Minibatch 878::LR 0.0607692307692 --> Loss 0.00319402893384\n",
      "Epoch 18::Minibatch 879::LR 0.0607692307692 --> Loss 0.00399438818296\n",
      "Epoch 18::Minibatch 880::LR 0.0607692307692 --> Loss 0.00481216629346\n",
      "Epoch 18::Minibatch 881::LR 0.0607692307692 --> Loss 0.00427548805873\n",
      "Epoch 18::Minibatch 882::LR 0.0607692307692 --> Loss 0.00196264823278\n",
      "Epoch 18::Minibatch 883::LR 0.0607692307692 --> Loss 0.00343348582586\n",
      "Epoch 18::Minibatch 884::LR 0.0607692307692 --> Loss 0.00271024485429\n",
      "Epoch 18::Minibatch 885::LR 0.0607692307692 --> Loss 0.00253582576911\n",
      "Epoch 18::Minibatch 886::LR 0.0607692307692 --> Loss 0.000498990118504\n",
      "Epoch 18::Minibatch 887::LR 0.0607692307692 --> Loss 0.00528076847394\n",
      "Epoch 18::Minibatch 888::LR 0.0607692307692 --> Loss 0.00259437123934\n",
      "Epoch 18::Minibatch 889::LR 0.0607692307692 --> Loss 0.00280387977759\n",
      "Epoch 18::Minibatch 890::LR 0.0607692307692 --> Loss 0.00414580901464\n",
      "Epoch 18::Minibatch 891::LR 0.0607692307692 --> Loss 0.00184747556845\n",
      "Epoch 18::Minibatch 892::LR 0.0607692307692 --> Loss 0.000851622323195\n",
      "Epoch 18::Minibatch 893::LR 0.0607692307692 --> Loss 0.00241788466771\n",
      "Epoch 18::Minibatch 894::LR 0.0607692307692 --> Loss 0.00213403324286\n",
      "Epoch 18::Minibatch 895::LR 0.0607692307692 --> Loss 0.00238108555476\n",
      "Epoch 18::Minibatch 896::LR 0.0607692307692 --> Loss 0.00126486778259\n",
      "Epoch 18::Minibatch 897::LR 0.0607692307692 --> Loss 0.000707426865896\n",
      "Epoch 18::Minibatch 898::LR 0.0607692307692 --> Loss 0.00212129533291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 899::LR 0.0607692307692 --> Loss 0.0024666784207\n",
      "Epoch 18::Minibatch 900::LR 0.0607692307692 --> Loss 0.00320860445499\n",
      "Epoch 18::Minibatch 901::LR 0.0607692307692 --> Loss 0.00059126863877\n",
      "Epoch 18::Minibatch 902::LR 0.0607692307692 --> Loss 0.00141138702631\n",
      "Epoch 18::Minibatch 903::LR 0.0607692307692 --> Loss 0.0025632806619\n",
      "Epoch 18::Minibatch 904::LR 0.0607692307692 --> Loss 0.00191668947538\n",
      "Epoch 18::Minibatch 905::LR 0.0607692307692 --> Loss 0.0014265887936\n",
      "Epoch 18::Minibatch 906::LR 0.0607692307692 --> Loss 0.00107031524181\n",
      "Epoch 18::Minibatch 907::LR 0.0607692307692 --> Loss 0.00158239920934\n",
      "Epoch 18::Minibatch 908::LR 0.0607692307692 --> Loss 0.00217671414216\n",
      "Epoch 18::Minibatch 909::LR 0.0607692307692 --> Loss 0.00200133939584\n",
      "Epoch 18::Minibatch 910::LR 0.0607692307692 --> Loss 0.000831444263458\n",
      "Epoch 18::Minibatch 911::LR 0.0607692307692 --> Loss 0.0012346620361\n",
      "Epoch 18::Minibatch 912::LR 0.0607692307692 --> Loss 0.00199742933114\n",
      "Epoch 18::Minibatch 913::LR 0.0607692307692 --> Loss 0.00216931919257\n",
      "Epoch 18::Minibatch 914::LR 0.0607692307692 --> Loss 0.00117755353451\n",
      "Epoch 18::Minibatch 915::LR 0.0607692307692 --> Loss 0.000492905080318\n",
      "Epoch 18::Minibatch 916::LR 0.0607692307692 --> Loss 0.00225540379683\n",
      "Epoch 18::Minibatch 917::LR 0.0607692307692 --> Loss 0.00372598767281\n",
      "Epoch 18::Minibatch 918::LR 0.0607692307692 --> Loss 0.00562518437703\n",
      "Epoch 18::Minibatch 919::LR 0.0607692307692 --> Loss 0.000570058077574\n",
      "Epoch 18::Minibatch 920::LR 0.0607692307692 --> Loss 0.0118110704422\n",
      "Epoch 18::Minibatch 921::LR 0.0607692307692 --> Loss 0.00281491796176\n",
      "Epoch 18::Minibatch 922::LR 0.0607692307692 --> Loss 0.00296406328678\n",
      "Epoch 18::Minibatch 923::LR 0.0607692307692 --> Loss 0.00144725441933\n",
      "Epoch 18::Minibatch 924::LR 0.0607692307692 --> Loss 0.00343371868134\n",
      "Epoch 18::Minibatch 925::LR 0.0607692307692 --> Loss 0.0023502488931\n",
      "Epoch 18::Minibatch 926::LR 0.0607692307692 --> Loss 0.00522457679113\n",
      "Epoch 18::Minibatch 927::LR 0.0607692307692 --> Loss 0.00733057339986\n",
      "Epoch 18::Minibatch 928::LR 0.0607692307692 --> Loss 0.00636127789815\n",
      "Epoch 18::Minibatch 929::LR 0.0607692307692 --> Loss 0.00655559341113\n",
      "Epoch 18::Minibatch 930::LR 0.0607692307692 --> Loss 0.00959421555201\n",
      "Epoch 18::Minibatch 931::LR 0.0607692307692 --> Loss 0.00344550053279\n",
      "Epoch 18::Minibatch 932::LR 0.0607692307692 --> Loss 0.00679728269577\n",
      "Epoch 18::Minibatch 933::LR 0.0607692307692 --> Loss 0.00336394906044\n",
      "Epoch 18::Minibatch 934::LR 0.0607692307692 --> Loss 0.00442697246869\n",
      "Epoch 18::Minibatch 935::LR 0.0607692307692 --> Loss 0.00623714327812\n",
      "Epoch 18::Minibatch 936::LR 0.0607692307692 --> Loss 0.00145730515321\n",
      "Epoch 18::Minibatch 937::LR 0.0607692307692 --> Loss 0.00324195623398\n",
      "Epoch 18::Minibatch 938::LR 0.0607692307692 --> Loss 0.00293282012145\n",
      "Epoch 18::Minibatch 939::LR 0.0607692307692 --> Loss 0.00301404396693\n",
      "Epoch 18::Minibatch 940::LR 0.0607692307692 --> Loss 0.0010169027249\n",
      "Epoch 18::Minibatch 941::LR 0.0607692307692 --> Loss 0.000834104518096\n",
      "Epoch 18::Minibatch 942::LR 0.0607692307692 --> Loss 0.00244797448317\n",
      "Epoch 18::Minibatch 943::LR 0.0607692307692 --> Loss 0.00284282366435\n",
      "Epoch 18::Minibatch 944::LR 0.0607692307692 --> Loss 0.00205600301425\n",
      "Epoch 18::Minibatch 945::LR 0.0607692307692 --> Loss 0.00119115223487\n",
      "Epoch 18::Minibatch 946::LR 0.0607692307692 --> Loss 0.00304152230422\n",
      "Epoch 18::Minibatch 947::LR 0.0607692307692 --> Loss 0.00272465527058\n",
      "Epoch 18::Minibatch 948::LR 0.0607692307692 --> Loss 0.00506945689519\n",
      "Epoch 18::Minibatch 949::LR 0.0607692307692 --> Loss 0.00185869057973\n",
      "Epoch 18::Minibatch 950::LR 0.0607692307692 --> Loss 0.000734444955985\n",
      "Epoch 18::Minibatch 951::LR 0.0607692307692 --> Loss 0.00338911453883\n",
      "Epoch 18::Minibatch 952::LR 0.0607692307692 --> Loss 0.00241627017657\n",
      "Epoch 18::Minibatch 953::LR 0.0607692307692 --> Loss 0.00138520509005\n",
      "Epoch 18::Minibatch 954::LR 0.0607692307692 --> Loss 0.000960242152214\n",
      "Epoch 18::Minibatch 955::LR 0.0607692307692 --> Loss 0.00252736787001\n",
      "Epoch 18::Minibatch 956::LR 0.0607692307692 --> Loss 0.00371334592501\n",
      "Epoch 18::Minibatch 957::LR 0.0607692307692 --> Loss 0.0018776712815\n",
      "Epoch 18::Minibatch 958::LR 0.0607692307692 --> Loss 0.00229763746262\n",
      "Epoch 18::Minibatch 959::LR 0.0607692307692 --> Loss 0.00283494412899\n",
      "Epoch 18::Minibatch 960::LR 0.0607692307692 --> Loss 0.00625995198886\n",
      "Epoch 18::Minibatch 961::LR 0.0607692307692 --> Loss 0.0032991874218\n",
      "Epoch 18::Minibatch 962::LR 0.0607692307692 --> Loss 0.00282336731752\n",
      "Epoch 18::Minibatch 963::LR 0.0607692307692 --> Loss 0.00103283772866\n",
      "Epoch 18::Minibatch 964::LR 0.0607692307692 --> Loss 0.00239081025124\n",
      "Epoch 18::Minibatch 965::LR 0.0607692307692 --> Loss 0.00725570122401\n",
      "Epoch 18::Minibatch 966::LR 0.0607692307692 --> Loss 0.00511308908463\n",
      "Epoch 18::Minibatch 967::LR 0.0607692307692 --> Loss 0.00152252535025\n",
      "Epoch 18::Minibatch 968::LR 0.0607692307692 --> Loss 0.00135526359081\n",
      "Epoch 18::Minibatch 969::LR 0.0607692307692 --> Loss 0.0062183201313\n",
      "Epoch 18::Minibatch 970::LR 0.0607692307692 --> Loss 0.00560040195783\n",
      "Epoch 18::Minibatch 971::LR 0.0607692307692 --> Loss 0.0034582610925\n",
      "Epoch 18::Minibatch 972::LR 0.0607692307692 --> Loss 0.0101011951764\n",
      "Epoch 18::Minibatch 973::LR 0.0607692307692 --> Loss 0.00893756786982\n",
      "Epoch 18::Minibatch 974::LR 0.0607692307692 --> Loss 0.00710753917694\n",
      "Epoch 18::Minibatch 975::LR 0.0607692307692 --> Loss 0.00457562685013\n",
      "Epoch 18::Minibatch 976::LR 0.0607692307692 --> Loss 0.00408819556236\n",
      "Epoch 18::Minibatch 977::LR 0.0607692307692 --> Loss 0.00406795501709\n",
      "Epoch 18::Minibatch 978::LR 0.0607692307692 --> Loss 0.00402021209399\n",
      "Epoch 18::Minibatch 979::LR 0.0607692307692 --> Loss 0.00394909302394\n",
      "Epoch 18::Minibatch 980::LR 0.0607692307692 --> Loss 0.00396897832553\n",
      "Epoch 18::Minibatch 981::LR 0.0607692307692 --> Loss 0.00515680789948\n",
      "Epoch 18::Minibatch 982::LR 0.0607692307692 --> Loss 0.0064026137193\n",
      "Epoch 18::Minibatch 983::LR 0.0607692307692 --> Loss 0.00295741717021\n",
      "Epoch 18::Minibatch 984::LR 0.0607692307692 --> Loss 0.00246694823106\n",
      "Epoch 18::Minibatch 985::LR 0.0607692307692 --> Loss 0.00425849755605\n",
      "Epoch 18::Minibatch 986::LR 0.0607692307692 --> Loss 0.00388840874036\n",
      "Epoch 18::Minibatch 987::LR 0.0607692307692 --> Loss 0.00417150576909\n",
      "Epoch 18::Minibatch 988::LR 0.0607692307692 --> Loss 0.00324224134286\n",
      "Epoch 18::Minibatch 989::LR 0.0607692307692 --> Loss 0.00336882948875\n",
      "Epoch 18::Minibatch 990::LR 0.0607692307692 --> Loss 0.00308632651965\n",
      "Epoch 18::Minibatch 991::LR 0.0607692307692 --> Loss 0.00162132382393\n",
      "Epoch 18::Minibatch 992::LR 0.0607692307692 --> Loss 0.00182968735695\n",
      "Epoch 18::Minibatch 993::LR 0.0607692307692 --> Loss 0.0033019254605\n",
      "Epoch 18::Minibatch 994::LR 0.0607692307692 --> Loss 0.00202876051267\n",
      "Epoch 18::Minibatch 995::LR 0.0607692307692 --> Loss 0.000835679769516\n",
      "Epoch 18::Minibatch 996::LR 0.0607692307692 --> Loss 0.00298027733962\n",
      "Epoch 18::Minibatch 997::LR 0.0607692307692 --> Loss 0.00210632324219\n",
      "Epoch 18::Minibatch 998::LR 0.0607692307692 --> Loss 0.00234966595968\n",
      "Epoch 18::Minibatch 999::LR 0.0607692307692 --> Loss 0.00193956653277\n",
      "Epoch 18::Minibatch 1000::LR 0.0607692307692 --> Loss 0.00230824967225\n",
      "Epoch 18::Minibatch 1001::LR 0.0607692307692 --> Loss 0.00183640837669\n",
      "Epoch 18::Minibatch 1002::LR 0.0607692307692 --> Loss 0.0021780371666\n",
      "Epoch 18::Minibatch 1003::LR 0.0607692307692 --> Loss 0.00327501634757\n",
      "Epoch 18::Minibatch 1004::LR 0.0607692307692 --> Loss 0.00100626091162\n",
      "Epoch 18::Minibatch 1005::LR 0.0607692307692 --> Loss 0.00341295043627\n",
      "Epoch 18::Minibatch 1006::LR 0.0607692307692 --> Loss 0.00197359939416\n",
      "Epoch 18::Minibatch 1007::LR 0.0607692307692 --> Loss 0.00243937373161\n",
      "Epoch 18::Minibatch 1008::LR 0.0607692307692 --> Loss 0.000915190378825\n",
      "Epoch 18::Minibatch 1009::LR 0.0607692307692 --> Loss 0.00147939920425\n",
      "Epoch 18::Minibatch 1010::LR 0.0607692307692 --> Loss 0.00135882844528\n",
      "Epoch 18::Minibatch 1011::LR 0.0607692307692 --> Loss 0.0027259272337\n",
      "Epoch 18::Minibatch 1012::LR 0.0607692307692 --> Loss 0.00157262901465\n",
      "Epoch 18::Minibatch 1013::LR 0.0607692307692 --> Loss 0.00416929165522\n",
      "Epoch 18::Minibatch 1014::LR 0.0607692307692 --> Loss 0.00390834490458\n",
      "Epoch 18::Minibatch 1015::LR 0.0607692307692 --> Loss 0.00161295880874\n",
      "Epoch 18::Minibatch 1016::LR 0.0607692307692 --> Loss 0.00487041076024\n",
      "Epoch 18::Minibatch 1017::LR 0.0607692307692 --> Loss 0.00353272120158\n",
      "Epoch 18::Minibatch 1018::LR 0.0607692307692 --> Loss 0.00290675580502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18::Minibatch 1019::LR 0.0607692307692 --> Loss 0.00200264334679\n",
      "Epoch 18::Minibatch 1020::LR 0.0607692307692 --> Loss 0.00203875025113\n",
      "Epoch 18::Minibatch 1021::LR 0.0607692307692 --> Loss 0.00208399732908\n",
      "Epoch 18::Minibatch 1022::LR 0.0607692307692 --> Loss 0.00159879724185\n",
      "Epoch 18::Minibatch 1023::LR 0.0607692307692 --> Loss 0.00122460136811\n",
      "Epoch 18::Minibatch 1024::LR 0.0607692307692 --> Loss 0.00118052850167\n",
      "Epoch 18::Minibatch 1025::LR 0.0607692307692 --> Loss 0.00143790741762\n",
      "Epoch 18::Minibatch 1026::LR 0.0607692307692 --> Loss 0.000818250626326\n",
      "Epoch 18::Minibatch 1027::LR 0.0607692307692 --> Loss 0.00103878309329\n",
      "Epoch 18::Minibatch 1028::LR 0.0607692307692 --> Loss 0.000796789973974\n",
      "Epoch 18::Minibatch 1029::LR 0.0607692307692 --> Loss 0.000779393812021\n",
      "Epoch 18::Minibatch 1030::LR 0.0607692307692 --> Loss 0.000963121453921\n",
      "Epoch 18::Minibatch 1031::LR 0.0607692307692 --> Loss 0.000758407662312\n",
      "Epoch 18::Minibatch 1032::LR 0.0607692307692 --> Loss 0.000792953073978\n",
      "Epoch 18::Minibatch 1033::LR 0.0607692307692 --> Loss 0.000669193118811\n",
      "Epoch 18::Minibatch 1034::LR 0.0607692307692 --> Loss 0.00065285474062\n",
      "Epoch 18::Minibatch 1035::LR 0.0607692307692 --> Loss 0.00045191248258\n",
      "Epoch 18::Minibatch 1036::LR 0.0607692307692 --> Loss 0.000363345046838\n",
      "Epoch 18::Minibatch 1037::LR 0.0607692307692 --> Loss 0.000587301452955\n",
      "Epoch 18::Minibatch 1038::LR 0.0607692307692 --> Loss 0.00127673794826\n",
      "Epoch 18::Minibatch 1039::LR 0.0607692307692 --> Loss 0.000997976561387\n",
      "Epoch 18::Minibatch 1040::LR 0.0607692307692 --> Loss 0.000408596619964\n",
      "Epoch 18::Minibatch 1041::LR 0.0607692307692 --> Loss 0.000577591160933\n",
      "Epoch 19::Minibatch 1::LR 0.0584615384615 --> Loss 0.00920498450597\n",
      "Epoch 19::Minibatch 2::LR 0.0584615384615 --> Loss 0.00556597908338\n",
      "Epoch 19::Minibatch 3::LR 0.0584615384615 --> Loss 0.00370999336243\n",
      "Epoch 19::Minibatch 4::LR 0.0584615384615 --> Loss 0.00418550769488\n",
      "Epoch 19::Minibatch 5::LR 0.0584615384615 --> Loss 0.00466836333275\n",
      "Epoch 19::Minibatch 6::LR 0.0584615384615 --> Loss 0.00233636935552\n",
      "Epoch 19::Minibatch 7::LR 0.0584615384615 --> Loss 0.00756757100423\n",
      "Epoch 19::Minibatch 8::LR 0.0584615384615 --> Loss 0.00721797068914\n",
      "Epoch 19::Minibatch 9::LR 0.0584615384615 --> Loss 0.00529738585154\n",
      "Epoch 19::Minibatch 10::LR 0.0584615384615 --> Loss 0.00268901805083\n",
      "Epoch 19::Minibatch 11::LR 0.0584615384615 --> Loss 0.00235493381818\n",
      "Epoch 19::Minibatch 12::LR 0.0584615384615 --> Loss 0.00344657739003\n",
      "Epoch 19::Minibatch 13::LR 0.0584615384615 --> Loss 0.00520625710487\n",
      "Epoch 19::Minibatch 14::LR 0.0584615384615 --> Loss 0.0052185912927\n",
      "Epoch 19::Minibatch 15::LR 0.0584615384615 --> Loss 0.00437830924988\n",
      "Epoch 19::Minibatch 16::LR 0.0584615384615 --> Loss 0.000834082663059\n",
      "Epoch 19::Minibatch 17::LR 0.0584615384615 --> Loss 0.00304724911849\n",
      "Epoch 19::Minibatch 18::LR 0.0584615384615 --> Loss 0.00253933489323\n",
      "Epoch 19::Minibatch 19::LR 0.0584615384615 --> Loss 0.00133273770412\n",
      "Epoch 19::Minibatch 20::LR 0.0584615384615 --> Loss 0.00180395722389\n",
      "Epoch 19::Minibatch 21::LR 0.0584615384615 --> Loss 0.00328741431236\n",
      "Epoch 19::Minibatch 22::LR 0.0584615384615 --> Loss 0.00227567851543\n",
      "Epoch 19::Minibatch 23::LR 0.0584615384615 --> Loss 0.000783776740233\n",
      "Epoch 19::Minibatch 24::LR 0.0584615384615 --> Loss 0.00038255614539\n",
      "Epoch 19::Minibatch 25::LR 0.0584615384615 --> Loss 0.00112774292628\n",
      "Epoch 19::Minibatch 26::LR 0.0584615384615 --> Loss 0.0013371176521\n",
      "Epoch 19::Minibatch 27::LR 0.0584615384615 --> Loss 0.00093153834343\n",
      "Epoch 19::Minibatch 28::LR 0.0584615384615 --> Loss 0.000393852318327\n",
      "Epoch 19::Minibatch 29::LR 0.0584615384615 --> Loss 0.000395756090681\n",
      "Epoch 19::Minibatch 30::LR 0.0584615384615 --> Loss 0.000870795051257\n",
      "Epoch 19::Minibatch 31::LR 0.0584615384615 --> Loss 0.00135820786158\n",
      "Epoch 19::Minibatch 32::LR 0.0584615384615 --> Loss 0.00126686275005\n",
      "Epoch 19::Minibatch 33::LR 0.0584615384615 --> Loss 0.000776451081038\n",
      "Epoch 19::Minibatch 34::LR 0.0584615384615 --> Loss 0.00222813924154\n",
      "Epoch 19::Minibatch 35::LR 0.0584615384615 --> Loss 0.00392105817795\n",
      "Epoch 19::Minibatch 36::LR 0.0584615384615 --> Loss 0.00226970970631\n",
      "Epoch 19::Minibatch 37::LR 0.0584615384615 --> Loss 0.000644038269917\n",
      "Epoch 19::Minibatch 38::LR 0.0584615384615 --> Loss 0.000737223873536\n",
      "Epoch 19::Minibatch 39::LR 0.0584615384615 --> Loss 0.00236415346464\n",
      "Epoch 19::Minibatch 40::LR 0.0584615384615 --> Loss 0.0034038289388\n",
      "Epoch 19::Minibatch 41::LR 0.0584615384615 --> Loss 0.00277366002401\n",
      "Epoch 19::Minibatch 42::LR 0.0584615384615 --> Loss 0.00582695484161\n",
      "Epoch 19::Minibatch 43::LR 0.0584615384615 --> Loss 0.00187311689059\n",
      "Epoch 19::Minibatch 44::LR 0.0584615384615 --> Loss 0.00311593830585\n",
      "Epoch 19::Minibatch 45::LR 0.0584615384615 --> Loss 0.00245728174845\n",
      "Epoch 19::Minibatch 46::LR 0.0584615384615 --> Loss 0.00336804946264\n",
      "Epoch 19::Minibatch 47::LR 0.0584615384615 --> Loss 0.0042631149292\n",
      "Epoch 19::Minibatch 48::LR 0.0584615384615 --> Loss 0.0057684759299\n",
      "Epoch 19::Minibatch 49::LR 0.0584615384615 --> Loss 0.00611125985781\n",
      "Epoch 19::Minibatch 50::LR 0.0584615384615 --> Loss 0.00609842975934\n",
      "Epoch 19::Minibatch 51::LR 0.0584615384615 --> Loss 0.0065422085921\n",
      "Epoch 19::Minibatch 52::LR 0.0584615384615 --> Loss 0.0034565103054\n",
      "Epoch 19::Minibatch 53::LR 0.0584615384615 --> Loss 0.00342123627663\n",
      "Epoch 19::Minibatch 54::LR 0.0584615384615 --> Loss 0.00402704318364\n",
      "Epoch 19::Minibatch 55::LR 0.0584615384615 --> Loss 0.000985640287399\n",
      "Epoch 19::Minibatch 56::LR 0.0584615384615 --> Loss 0.00269550005595\n",
      "Epoch 19::Minibatch 57::LR 0.0584615384615 --> Loss 0.00544165929159\n",
      "Epoch 19::Minibatch 58::LR 0.0584615384615 --> Loss 0.00332389255365\n",
      "Epoch 19::Minibatch 59::LR 0.0584615384615 --> Loss 0.00246181309223\n",
      "Epoch 19::Minibatch 60::LR 0.0584615384615 --> Loss 0.00237840811412\n",
      "Epoch 19::Minibatch 61::LR 0.0584615384615 --> Loss 0.000845329761505\n",
      "Epoch 19::Minibatch 62::LR 0.0584615384615 --> Loss 0.0030562778314\n",
      "Epoch 19::Minibatch 63::LR 0.0584615384615 --> Loss 0.00208486020565\n",
      "Epoch 19::Minibatch 64::LR 0.0584615384615 --> Loss 0.000891009469827\n",
      "Epoch 19::Minibatch 65::LR 0.0584615384615 --> Loss 0.00232512573401\n",
      "Epoch 19::Minibatch 66::LR 0.0584615384615 --> Loss 0.00280180434386\n",
      "Epoch 19::Minibatch 67::LR 0.0584615384615 --> Loss 0.00273778378963\n",
      "Epoch 19::Minibatch 68::LR 0.0584615384615 --> Loss 0.00196110804876\n",
      "Epoch 19::Minibatch 69::LR 0.0584615384615 --> Loss 0.00393752018611\n",
      "Epoch 19::Minibatch 70::LR 0.0584615384615 --> Loss 0.00340279777845\n",
      "Epoch 19::Minibatch 71::LR 0.0584615384615 --> Loss 0.00231983641783\n",
      "Epoch 19::Minibatch 72::LR 0.0584615384615 --> Loss 0.000544009407361\n",
      "Epoch 19::Minibatch 73::LR 0.0584615384615 --> Loss 0.00390643080076\n",
      "Epoch 19::Minibatch 74::LR 0.0584615384615 --> Loss 0.00413734396299\n",
      "Epoch 19::Minibatch 75::LR 0.0584615384615 --> Loss 0.00239171485106\n",
      "Epoch 19::Minibatch 76::LR 0.0584615384615 --> Loss 0.00057236234347\n",
      "Epoch 19::Minibatch 77::LR 0.0584615384615 --> Loss 0.00380170901616\n",
      "Epoch 19::Minibatch 78::LR 0.0584615384615 --> Loss 0.00385606169701\n",
      "Epoch 19::Minibatch 79::LR 0.0584615384615 --> Loss 0.00193817615509\n",
      "Epoch 19::Minibatch 80::LR 0.0584615384615 --> Loss 0.00320132037004\n",
      "Epoch 19::Minibatch 81::LR 0.0584615384615 --> Loss 0.00277063588301\n",
      "Epoch 19::Minibatch 82::LR 0.0584615384615 --> Loss 0.00199137528737\n",
      "Epoch 19::Minibatch 83::LR 0.0584615384615 --> Loss 0.00452830235163\n",
      "Epoch 19::Minibatch 84::LR 0.0584615384615 --> Loss 0.00198683043321\n",
      "Epoch 19::Minibatch 85::LR 0.0584615384615 --> Loss 0.0027433826526\n",
      "Epoch 19::Minibatch 86::LR 0.0584615384615 --> Loss 0.00221223930518\n",
      "Epoch 19::Minibatch 87::LR 0.0584615384615 --> Loss 0.00244518776735\n",
      "Epoch 19::Minibatch 88::LR 0.0584615384615 --> Loss 0.00178243676821\n",
      "Epoch 19::Minibatch 89::LR 0.0584615384615 --> Loss 0.002318683664\n",
      "Epoch 19::Minibatch 90::LR 0.0584615384615 --> Loss 0.00111019998789\n",
      "Epoch 19::Minibatch 91::LR 0.0584615384615 --> Loss 0.000891343255838\n",
      "Epoch 19::Minibatch 92::LR 0.0584615384615 --> Loss 0.00269142349561\n",
      "Epoch 19::Minibatch 93::LR 0.0584615384615 --> Loss 0.00176015337308\n",
      "Epoch 19::Minibatch 94::LR 0.0584615384615 --> Loss 0.00176166534424\n",
      "Epoch 19::Minibatch 95::LR 0.0584615384615 --> Loss 0.00182201425234\n",
      "Epoch 19::Minibatch 96::LR 0.0584615384615 --> Loss 0.00568406581879\n",
      "Epoch 19::Minibatch 97::LR 0.0584615384615 --> Loss 0.00314908325672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 98::LR 0.0584615384615 --> Loss 0.000994805296262\n",
      "Epoch 19::Minibatch 99::LR 0.0584615384615 --> Loss 0.00131997664769\n",
      "Epoch 19::Minibatch 100::LR 0.0584615384615 --> Loss 0.00504117647807\n",
      "Epoch 19::Minibatch 101::LR 0.0584615384615 --> Loss 0.000927382310232\n",
      "Epoch 19::Minibatch 102::LR 0.0584615384615 --> Loss 0.0038846496741\n",
      "Epoch 19::Minibatch 103::LR 0.0584615384615 --> Loss 0.00401561975479\n",
      "Epoch 19::Minibatch 104::LR 0.0584615384615 --> Loss 0.00276044646899\n",
      "Epoch 19::Minibatch 105::LR 0.0584615384615 --> Loss 0.00262050549189\n",
      "Epoch 19::Minibatch 106::LR 0.0584615384615 --> Loss 0.0174452161789\n",
      "Epoch 19::Minibatch 107::LR 0.0584615384615 --> Loss 0.00487639983495\n",
      "Epoch 19::Minibatch 108::LR 0.0584615384615 --> Loss 0.00104642530282\n",
      "Epoch 19::Minibatch 109::LR 0.0584615384615 --> Loss 0.00436364650726\n",
      "Epoch 19::Minibatch 110::LR 0.0584615384615 --> Loss 0.00237849354744\n",
      "Epoch 19::Minibatch 111::LR 0.0584615384615 --> Loss 0.000947623252869\n",
      "Epoch 19::Minibatch 112::LR 0.0584615384615 --> Loss 0.00353087862333\n",
      "Epoch 19::Minibatch 113::LR 0.0584615384615 --> Loss 0.00263839145501\n",
      "Epoch 19::Minibatch 114::LR 0.0584615384615 --> Loss 0.00146271477143\n",
      "Epoch 19::Minibatch 115::LR 0.0584615384615 --> Loss 0.00131621311108\n",
      "Epoch 19::Minibatch 116::LR 0.0584615384615 --> Loss 0.00277125000954\n",
      "Epoch 19::Minibatch 117::LR 0.0584615384615 --> Loss 0.00384190400441\n",
      "Epoch 19::Minibatch 118::LR 0.0584615384615 --> Loss 0.00689207235972\n",
      "Epoch 19::Minibatch 119::LR 0.0584615384615 --> Loss 0.000635699729125\n",
      "Epoch 19::Minibatch 120::LR 0.0584615384615 --> Loss 0.00177041590214\n",
      "Epoch 19::Minibatch 121::LR 0.0584615384615 --> Loss 0.00263931910197\n",
      "Epoch 19::Minibatch 122::LR 0.0584615384615 --> Loss 0.0037260556221\n",
      "Epoch 19::Minibatch 123::LR 0.0584615384615 --> Loss 0.000993091166019\n",
      "Epoch 19::Minibatch 124::LR 0.0584615384615 --> Loss 0.00276425222556\n",
      "Epoch 19::Minibatch 125::LR 0.0584615384615 --> Loss 0.00461941917737\n",
      "Epoch 19::Minibatch 126::LR 0.0584615384615 --> Loss 0.00270055850347\n",
      "Epoch 19::Minibatch 127::LR 0.0584615384615 --> Loss 0.00445796052615\n",
      "Epoch 19::Minibatch 128::LR 0.0584615384615 --> Loss 0.00361739317576\n",
      "Epoch 19::Minibatch 129::LR 0.0584615384615 --> Loss 0.00268710414569\n",
      "Epoch 19::Minibatch 130::LR 0.0584615384615 --> Loss 0.00436224341393\n",
      "Epoch 19::Minibatch 131::LR 0.0584615384615 --> Loss 0.00179301222165\n",
      "Epoch 19::Minibatch 132::LR 0.0584615384615 --> Loss 0.00306825141112\n",
      "Epoch 19::Minibatch 133::LR 0.0584615384615 --> Loss 0.0029168532292\n",
      "Epoch 19::Minibatch 134::LR 0.0584615384615 --> Loss 0.0023495388031\n",
      "Epoch 19::Minibatch 135::LR 0.0584615384615 --> Loss 0.00155153354009\n",
      "Epoch 19::Minibatch 136::LR 0.0584615384615 --> Loss 0.00269243518511\n",
      "Epoch 19::Minibatch 137::LR 0.0584615384615 --> Loss 0.00366163015366\n",
      "Epoch 19::Minibatch 138::LR 0.0584615384615 --> Loss 0.00130431741476\n",
      "Epoch 19::Minibatch 139::LR 0.0584615384615 --> Loss 0.00191763718923\n",
      "Epoch 19::Minibatch 140::LR 0.0584615384615 --> Loss 0.00246468325456\n",
      "Epoch 19::Minibatch 141::LR 0.0584615384615 --> Loss 0.00297577997049\n",
      "Epoch 19::Minibatch 142::LR 0.0584615384615 --> Loss 0.00286619246006\n",
      "Epoch 19::Minibatch 143::LR 0.0584615384615 --> Loss 0.000603604614735\n",
      "Epoch 19::Minibatch 144::LR 0.0584615384615 --> Loss 0.00325113097827\n",
      "Epoch 19::Minibatch 145::LR 0.0584615384615 --> Loss 0.00430413722992\n",
      "Epoch 19::Minibatch 146::LR 0.0584615384615 --> Loss 0.00258047501246\n",
      "Epoch 19::Minibatch 147::LR 0.0584615384615 --> Loss 0.00181921919187\n",
      "Epoch 19::Minibatch 148::LR 0.0584615384615 --> Loss 0.00101231137911\n",
      "Epoch 19::Minibatch 149::LR 0.0584615384615 --> Loss 0.0028428397576\n",
      "Epoch 19::Minibatch 150::LR 0.0584615384615 --> Loss 0.00272373219331\n",
      "Epoch 19::Minibatch 151::LR 0.0584615384615 --> Loss 0.00425367752711\n",
      "Epoch 19::Minibatch 152::LR 0.0584615384615 --> Loss 0.000922801494598\n",
      "Epoch 19::Minibatch 153::LR 0.0584615384615 --> Loss 0.00180974404017\n",
      "Epoch 19::Minibatch 154::LR 0.0584615384615 --> Loss 0.00205798049768\n",
      "Epoch 19::Minibatch 155::LR 0.0584615384615 --> Loss 0.00443120161692\n",
      "Epoch 19::Minibatch 156::LR 0.0584615384615 --> Loss 0.00240063587825\n",
      "Epoch 19::Minibatch 157::LR 0.0584615384615 --> Loss 0.000701124767462\n",
      "Epoch 19::Minibatch 158::LR 0.0584615384615 --> Loss 0.00308407167594\n",
      "Epoch 19::Minibatch 159::LR 0.0584615384615 --> Loss 0.00275848944982\n",
      "Epoch 19::Minibatch 160::LR 0.0584615384615 --> Loss 0.00263808389505\n",
      "Epoch 19::Minibatch 161::LR 0.0584615384615 --> Loss 0.00102226545413\n",
      "Epoch 19::Minibatch 162::LR 0.0584615384615 --> Loss 0.0037789885203\n",
      "Epoch 19::Minibatch 163::LR 0.0584615384615 --> Loss 0.00240452110767\n",
      "Epoch 19::Minibatch 164::LR 0.0584615384615 --> Loss 0.00250304162502\n",
      "Epoch 19::Minibatch 165::LR 0.0584615384615 --> Loss 0.000528365671635\n",
      "Epoch 19::Minibatch 166::LR 0.0584615384615 --> Loss 0.00178619166215\n",
      "Epoch 19::Minibatch 167::LR 0.0584615384615 --> Loss 0.00246427595615\n",
      "Epoch 19::Minibatch 168::LR 0.0584615384615 --> Loss 0.00218561609586\n",
      "Epoch 19::Minibatch 169::LR 0.0584615384615 --> Loss 0.00101466327906\n",
      "Epoch 19::Minibatch 170::LR 0.0584615384615 --> Loss 0.000988722940286\n",
      "Epoch 19::Minibatch 171::LR 0.0584615384615 --> Loss 0.0025113872687\n",
      "Epoch 19::Minibatch 172::LR 0.0584615384615 --> Loss 0.00445725083351\n",
      "Epoch 19::Minibatch 173::LR 0.0584615384615 --> Loss 0.00195525030295\n",
      "Epoch 19::Minibatch 174::LR 0.0584615384615 --> Loss 0.0010398598512\n",
      "Epoch 19::Minibatch 175::LR 0.0584615384615 --> Loss 0.00231251597404\n",
      "Epoch 19::Minibatch 176::LR 0.0584615384615 --> Loss 0.00325041890144\n",
      "Epoch 19::Minibatch 177::LR 0.0584615384615 --> Loss 0.00457094828288\n",
      "Epoch 19::Minibatch 178::LR 0.0584615384615 --> Loss 0.00162264227867\n",
      "Epoch 19::Minibatch 179::LR 0.0584615384615 --> Loss 0.00133093635241\n",
      "Epoch 19::Minibatch 180::LR 0.0584615384615 --> Loss 0.00355578263601\n",
      "Epoch 19::Minibatch 181::LR 0.0584615384615 --> Loss 0.00324906170368\n",
      "Epoch 19::Minibatch 182::LR 0.0584615384615 --> Loss 0.000771096696456\n",
      "Epoch 19::Minibatch 183::LR 0.0584615384615 --> Loss 0.00167541702588\n",
      "Epoch 19::Minibatch 184::LR 0.0584615384615 --> Loss 0.0034377793471\n",
      "Epoch 19::Minibatch 185::LR 0.0584615384615 --> Loss 0.00281173110008\n",
      "Epoch 19::Minibatch 186::LR 0.0584615384615 --> Loss 0.000974309742451\n",
      "Epoch 19::Minibatch 187::LR 0.0584615384615 --> Loss 0.00126317550739\n",
      "Epoch 19::Minibatch 188::LR 0.0584615384615 --> Loss 0.00417517582575\n",
      "Epoch 19::Minibatch 189::LR 0.0584615384615 --> Loss 0.0044174182415\n",
      "Epoch 19::Minibatch 190::LR 0.0584615384615 --> Loss 0.00232421259085\n",
      "Epoch 19::Minibatch 191::LR 0.0584615384615 --> Loss 0.000476326843103\n",
      "Epoch 19::Minibatch 192::LR 0.0584615384615 --> Loss 0.0027213982741\n",
      "Epoch 19::Minibatch 193::LR 0.0584615384615 --> Loss 0.00257384618123\n",
      "Epoch 19::Minibatch 194::LR 0.0584615384615 --> Loss 0.0017828587691\n",
      "Epoch 19::Minibatch 195::LR 0.0584615384615 --> Loss 0.0003830456237\n",
      "Epoch 19::Minibatch 196::LR 0.0584615384615 --> Loss 0.00123855958382\n",
      "Epoch 19::Minibatch 197::LR 0.0584615384615 --> Loss 0.00287049452464\n",
      "Epoch 19::Minibatch 198::LR 0.0584615384615 --> Loss 0.00221258342266\n",
      "Epoch 19::Minibatch 199::LR 0.0584615384615 --> Loss 0.000285774221023\n",
      "Epoch 19::Minibatch 200::LR 0.0584615384615 --> Loss 0.00206095159054\n",
      "Epoch 19::Minibatch 201::LR 0.0584615384615 --> Loss 0.0019529914856\n",
      "Epoch 19::Minibatch 202::LR 0.0584615384615 --> Loss 0.00186682323615\n",
      "Epoch 19::Minibatch 203::LR 0.0584615384615 --> Loss 0.00176492114862\n",
      "Epoch 19::Minibatch 204::LR 0.0584615384615 --> Loss 0.00145521571239\n",
      "Epoch 19::Minibatch 205::LR 0.0584615384615 --> Loss 0.00220920205116\n",
      "Epoch 19::Minibatch 206::LR 0.0584615384615 --> Loss 0.00638101061185\n",
      "Epoch 19::Minibatch 207::LR 0.0584615384615 --> Loss 0.00139484385649\n",
      "Epoch 19::Minibatch 208::LR 0.0584615384615 --> Loss 0.00112652291854\n",
      "Epoch 19::Minibatch 209::LR 0.0584615384615 --> Loss 0.00222638467948\n",
      "Epoch 19::Minibatch 210::LR 0.0584615384615 --> Loss 0.00212576886018\n",
      "Epoch 19::Minibatch 211::LR 0.0584615384615 --> Loss 0.0022996789217\n",
      "Epoch 19::Minibatch 212::LR 0.0584615384615 --> Loss 0.00397641181946\n",
      "Epoch 19::Minibatch 213::LR 0.0584615384615 --> Loss 0.00585165858269\n",
      "Epoch 19::Minibatch 214::LR 0.0584615384615 --> Loss 0.0089878487587\n",
      "Epoch 19::Minibatch 215::LR 0.0584615384615 --> Loss 0.00138712922732\n",
      "Epoch 19::Minibatch 216::LR 0.0584615384615 --> Loss 0.00549414952596\n",
      "Epoch 19::Minibatch 217::LR 0.0584615384615 --> Loss 0.00614792108536\n",
      "Epoch 19::Minibatch 218::LR 0.0584615384615 --> Loss 0.00395235260328\n",
      "Epoch 19::Minibatch 219::LR 0.0584615384615 --> Loss 0.00414072831472\n",
      "Epoch 19::Minibatch 220::LR 0.0584615384615 --> Loss 0.00450460116069\n",
      "Epoch 19::Minibatch 221::LR 0.0584615384615 --> Loss 0.00426052888234\n",
      "Epoch 19::Minibatch 222::LR 0.0584615384615 --> Loss 0.00325252731641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 223::LR 0.0584615384615 --> Loss 0.00141658862432\n",
      "Epoch 19::Minibatch 224::LR 0.0584615384615 --> Loss 0.00174784819285\n",
      "Epoch 19::Minibatch 225::LR 0.0584615384615 --> Loss 0.00732390960058\n",
      "Epoch 19::Minibatch 226::LR 0.0584615384615 --> Loss 0.00378181656202\n",
      "Epoch 19::Minibatch 227::LR 0.0584615384615 --> Loss 0.00169426182906\n",
      "Epoch 19::Minibatch 228::LR 0.0584615384615 --> Loss 0.000736715942621\n",
      "Epoch 19::Minibatch 229::LR 0.0584615384615 --> Loss 0.00479254206022\n",
      "Epoch 19::Minibatch 230::LR 0.0584615384615 --> Loss 0.00392247756322\n",
      "Epoch 19::Minibatch 231::LR 0.0584615384615 --> Loss 0.00264676729838\n",
      "Epoch 19::Minibatch 232::LR 0.0584615384615 --> Loss 0.00121461351713\n",
      "Epoch 19::Minibatch 233::LR 0.0584615384615 --> Loss 0.00242810249329\n",
      "Epoch 19::Minibatch 234::LR 0.0584615384615 --> Loss 0.00694200913111\n",
      "Epoch 19::Minibatch 235::LR 0.0584615384615 --> Loss 0.00472101012866\n",
      "Epoch 19::Minibatch 236::LR 0.0584615384615 --> Loss 0.00176046391328\n",
      "Epoch 19::Minibatch 237::LR 0.0584615384615 --> Loss 0.000678268820047\n",
      "Epoch 19::Minibatch 238::LR 0.0584615384615 --> Loss 0.00341857790947\n",
      "Epoch 19::Minibatch 239::LR 0.0584615384615 --> Loss 0.00296265482903\n",
      "Epoch 19::Minibatch 240::LR 0.0584615384615 --> Loss 0.00324634969234\n",
      "Epoch 19::Minibatch 241::LR 0.0584615384615 --> Loss 0.000765572885672\n",
      "Epoch 19::Minibatch 242::LR 0.0584615384615 --> Loss 0.00703569332759\n",
      "Epoch 19::Minibatch 243::LR 0.0584615384615 --> Loss 0.00349833250046\n",
      "Epoch 19::Minibatch 244::LR 0.0584615384615 --> Loss 0.00292750636737\n",
      "Epoch 19::Minibatch 245::LR 0.0584615384615 --> Loss 0.000473421216011\n",
      "Epoch 19::Minibatch 246::LR 0.0584615384615 --> Loss 0.00205519477526\n",
      "Epoch 19::Minibatch 247::LR 0.0584615384615 --> Loss 0.0127871958415\n",
      "Epoch 19::Minibatch 248::LR 0.0584615384615 --> Loss 0.0044861527284\n",
      "Epoch 19::Minibatch 249::LR 0.0584615384615 --> Loss 0.00269372443358\n",
      "Epoch 19::Minibatch 250::LR 0.0584615384615 --> Loss 0.00257827957471\n",
      "Epoch 19::Minibatch 251::LR 0.0584615384615 --> Loss 0.00251361370087\n",
      "Epoch 19::Minibatch 252::LR 0.0584615384615 --> Loss 0.00177791158358\n",
      "Epoch 19::Minibatch 253::LR 0.0584615384615 --> Loss 0.00307341575623\n",
      "Epoch 19::Minibatch 254::LR 0.0584615384615 --> Loss 0.00513485948245\n",
      "Epoch 19::Minibatch 255::LR 0.0584615384615 --> Loss 0.00385980367661\n",
      "Epoch 19::Minibatch 256::LR 0.0584615384615 --> Loss 0.00162444988887\n",
      "Epoch 19::Minibatch 257::LR 0.0584615384615 --> Loss 0.00122677097718\n",
      "Epoch 19::Minibatch 258::LR 0.0584615384615 --> Loss 0.00363996783892\n",
      "Epoch 19::Minibatch 259::LR 0.0584615384615 --> Loss 0.00177795330683\n",
      "Epoch 19::Minibatch 260::LR 0.0584615384615 --> Loss 0.00188848237197\n",
      "Epoch 19::Minibatch 261::LR 0.0584615384615 --> Loss 0.00284860452016\n",
      "Epoch 19::Minibatch 262::LR 0.0584615384615 --> Loss 0.00192287127177\n",
      "Epoch 19::Minibatch 263::LR 0.0584615384615 --> Loss 0.00236896375815\n",
      "Epoch 19::Minibatch 264::LR 0.0584615384615 --> Loss 0.00363992492358\n",
      "Epoch 19::Minibatch 265::LR 0.0584615384615 --> Loss 0.010214223067\n",
      "Epoch 19::Minibatch 266::LR 0.0584615384615 --> Loss 0.00100166579088\n",
      "Epoch 19::Minibatch 267::LR 0.0584615384615 --> Loss 0.00993129014969\n",
      "Epoch 19::Minibatch 268::LR 0.0584615384615 --> Loss 0.00117136041323\n",
      "Epoch 19::Minibatch 269::LR 0.0584615384615 --> Loss 0.0035420413812\n",
      "Epoch 19::Minibatch 270::LR 0.0584615384615 --> Loss 0.00671373526255\n",
      "Epoch 19::Minibatch 271::LR 0.0584615384615 --> Loss 0.00268135070801\n",
      "Epoch 19::Minibatch 272::LR 0.0584615384615 --> Loss 0.00416527589162\n",
      "Epoch 19::Minibatch 273::LR 0.0584615384615 --> Loss 0.00163662681977\n",
      "Epoch 19::Minibatch 274::LR 0.0584615384615 --> Loss 0.00179419636726\n",
      "Epoch 19::Minibatch 275::LR 0.0584615384615 --> Loss 0.00263632416725\n",
      "Epoch 19::Minibatch 276::LR 0.0584615384615 --> Loss 0.00345616221428\n",
      "Epoch 19::Minibatch 277::LR 0.0584615384615 --> Loss 0.000985887447993\n",
      "Epoch 19::Minibatch 278::LR 0.0584615384615 --> Loss 0.00262564400832\n",
      "Epoch 19::Minibatch 279::LR 0.0584615384615 --> Loss 0.00233194708824\n",
      "Epoch 19::Minibatch 280::LR 0.0584615384615 --> Loss 0.00203160822392\n",
      "Epoch 19::Minibatch 281::LR 0.0584615384615 --> Loss 0.00127907087406\n",
      "Epoch 19::Minibatch 282::LR 0.0584615384615 --> Loss 0.00220489382744\n",
      "Epoch 19::Minibatch 283::LR 0.0584615384615 --> Loss 0.00214880426725\n",
      "Epoch 19::Minibatch 284::LR 0.0584615384615 --> Loss 0.0017180510362\n",
      "Epoch 19::Minibatch 285::LR 0.0584615384615 --> Loss 0.00120699981848\n",
      "Epoch 19::Minibatch 286::LR 0.0584615384615 --> Loss 0.00212351659934\n",
      "Epoch 19::Minibatch 287::LR 0.0584615384615 --> Loss 0.00206324557463\n",
      "Epoch 19::Minibatch 288::LR 0.0584615384615 --> Loss 0.00111153105895\n",
      "Epoch 19::Minibatch 289::LR 0.0584615384615 --> Loss 0.00159670511882\n",
      "Epoch 19::Minibatch 290::LR 0.0584615384615 --> Loss 0.00193738619486\n",
      "Epoch 19::Minibatch 291::LR 0.0584615384615 --> Loss 0.00172392090162\n",
      "Epoch 19::Minibatch 292::LR 0.0584615384615 --> Loss 0.000605070094268\n",
      "Epoch 19::Minibatch 293::LR 0.0584615384615 --> Loss 0.00149544109901\n",
      "Epoch 19::Minibatch 294::LR 0.0584615384615 --> Loss 0.00157785018285\n",
      "Epoch 19::Minibatch 295::LR 0.0584615384615 --> Loss 0.00186633567015\n",
      "Epoch 19::Minibatch 296::LR 0.0584615384615 --> Loss 0.00161672164996\n",
      "Epoch 19::Minibatch 297::LR 0.0584615384615 --> Loss 0.00140368094047\n",
      "Epoch 19::Minibatch 298::LR 0.0584615384615 --> Loss 0.00139013608297\n",
      "Epoch 19::Minibatch 299::LR 0.0584615384615 --> Loss 0.000799452960491\n",
      "Epoch 19::Minibatch 300::LR 0.0584615384615 --> Loss 0.00279635866483\n",
      "Epoch 19::Minibatch 301::LR 0.0584615384615 --> Loss 0.00271244903406\n",
      "Epoch 19::Minibatch 302::LR 0.0584615384615 --> Loss 0.00249440530936\n",
      "Epoch 19::Minibatch 303::LR 0.0584615384615 --> Loss 0.000858483016491\n",
      "Epoch 19::Minibatch 304::LR 0.0584615384615 --> Loss 0.00308753053347\n",
      "Epoch 19::Minibatch 305::LR 0.0584615384615 --> Loss 0.00169328729312\n",
      "Epoch 19::Minibatch 306::LR 0.0584615384615 --> Loss 0.000932831962903\n",
      "Epoch 19::Minibatch 307::LR 0.0584615384615 --> Loss 0.00245547334353\n",
      "Epoch 19::Minibatch 308::LR 0.0584615384615 --> Loss 0.00199587146441\n",
      "Epoch 19::Minibatch 309::LR 0.0584615384615 --> Loss 0.00100808084011\n",
      "Epoch 19::Minibatch 310::LR 0.0584615384615 --> Loss 0.00113079756498\n",
      "Epoch 19::Minibatch 311::LR 0.0584615384615 --> Loss 0.00173419793447\n",
      "Epoch 19::Minibatch 312::LR 0.0584615384615 --> Loss 0.00294113238653\n",
      "Epoch 19::Minibatch 313::LR 0.0584615384615 --> Loss 0.00239221235116\n",
      "Epoch 19::Minibatch 314::LR 0.0584615384615 --> Loss 0.00191799024741\n",
      "Epoch 19::Minibatch 315::LR 0.0584615384615 --> Loss 0.00100563724836\n",
      "Epoch 19::Minibatch 316::LR 0.0584615384615 --> Loss 0.00233153184255\n",
      "Epoch 19::Minibatch 317::LR 0.0584615384615 --> Loss 0.00155021160841\n",
      "Epoch 19::Minibatch 318::LR 0.0584615384615 --> Loss 0.00123960624139\n",
      "Epoch 19::Minibatch 319::LR 0.0584615384615 --> Loss 0.0022968318065\n",
      "Epoch 19::Minibatch 320::LR 0.0584615384615 --> Loss 0.00317356050014\n",
      "Epoch 19::Minibatch 321::LR 0.0584615384615 --> Loss 0.000848441720009\n",
      "Epoch 19::Minibatch 322::LR 0.0584615384615 --> Loss 0.00363785664241\n",
      "Epoch 19::Minibatch 323::LR 0.0584615384615 --> Loss 0.00352122267087\n",
      "Epoch 19::Minibatch 324::LR 0.0584615384615 --> Loss 0.00263845880826\n",
      "Epoch 19::Minibatch 325::LR 0.0584615384615 --> Loss 0.00239856998126\n",
      "Epoch 19::Minibatch 326::LR 0.0584615384615 --> Loss 0.00549732247988\n",
      "Epoch 19::Minibatch 327::LR 0.0584615384615 --> Loss 0.00225938459237\n",
      "Epoch 19::Minibatch 328::LR 0.0584615384615 --> Loss 0.00322843770186\n",
      "Epoch 19::Minibatch 329::LR 0.0584615384615 --> Loss 0.0012208366394\n",
      "Epoch 19::Minibatch 330::LR 0.0584615384615 --> Loss 0.00160270591577\n",
      "Epoch 19::Minibatch 331::LR 0.0584615384615 --> Loss 0.00254590034485\n",
      "Epoch 19::Minibatch 332::LR 0.0584615384615 --> Loss 0.0025004607439\n",
      "Epoch 19::Minibatch 333::LR 0.0584615384615 --> Loss 0.00145103385051\n",
      "Epoch 19::Minibatch 334::LR 0.0584615384615 --> Loss 0.00440519491831\n",
      "Epoch 19::Minibatch 335::LR 0.0584615384615 --> Loss 0.00188647290071\n",
      "Epoch 19::Minibatch 336::LR 0.0584615384615 --> Loss 0.00217715382576\n",
      "Epoch 19::Minibatch 337::LR 0.0584615384615 --> Loss 0.00348297595978\n",
      "Epoch 19::Minibatch 338::LR 0.0584615384615 --> Loss 0.000526585976283\n",
      "Epoch 19::Minibatch 339::LR 0.0584615384615 --> Loss 0.00331584870815\n",
      "Epoch 19::Minibatch 340::LR 0.0584615384615 --> Loss 0.004042643706\n",
      "Epoch 19::Minibatch 341::LR 0.0584615384615 --> Loss 0.00476598540942\n",
      "Epoch 19::Minibatch 342::LR 0.0584615384615 --> Loss 0.00311903158824\n",
      "Epoch 19::Minibatch 343::LR 0.0584615384615 --> Loss 0.00167293449243\n",
      "Epoch 19::Minibatch 344::LR 0.0584615384615 --> Loss 0.0031390941143\n",
      "Epoch 19::Minibatch 345::LR 0.0584615384615 --> Loss 0.00424657225609\n",
      "Epoch 19::Minibatch 346::LR 0.0584615384615 --> Loss 0.00563055634499\n",
      "Epoch 19::Minibatch 347::LR 0.0584615384615 --> Loss 0.000844867229462\n",
      "Epoch 19::Minibatch 348::LR 0.0584615384615 --> Loss 0.00334239562352\n",
      "Epoch 19::Minibatch 349::LR 0.0584615384615 --> Loss 0.00348203023275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 350::LR 0.0584615384615 --> Loss 0.0017415757974\n",
      "Epoch 19::Minibatch 351::LR 0.0584615384615 --> Loss 0.00350242733955\n",
      "Epoch 19::Minibatch 352::LR 0.0584615384615 --> Loss 0.00490529696147\n",
      "Epoch 19::Minibatch 353::LR 0.0584615384615 --> Loss 0.00354712049166\n",
      "Epoch 19::Minibatch 354::LR 0.0584615384615 --> Loss 0.00295332948367\n",
      "Epoch 19::Minibatch 355::LR 0.0584615384615 --> Loss 0.00616669098536\n",
      "Epoch 19::Minibatch 356::LR 0.0584615384615 --> Loss 0.00312845806281\n",
      "Epoch 19::Minibatch 357::LR 0.0584615384615 --> Loss 0.00113927135865\n",
      "Epoch 19::Minibatch 358::LR 0.0584615384615 --> Loss 0.00211287856102\n",
      "Epoch 19::Minibatch 359::LR 0.0584615384615 --> Loss 0.00271985272566\n",
      "Epoch 19::Minibatch 360::LR 0.0584615384615 --> Loss 0.00241111516953\n",
      "Epoch 19::Minibatch 361::LR 0.0584615384615 --> Loss 0.00239927093188\n",
      "Epoch 19::Minibatch 362::LR 0.0584615384615 --> Loss 0.00237446288268\n",
      "Epoch 19::Minibatch 363::LR 0.0584615384615 --> Loss 0.000657792240381\n",
      "Epoch 19::Minibatch 364::LR 0.0584615384615 --> Loss 0.00200170973937\n",
      "Epoch 19::Minibatch 365::LR 0.0584615384615 --> Loss 0.00208221654097\n",
      "Epoch 19::Minibatch 366::LR 0.0584615384615 --> Loss 0.00222207744916\n",
      "Epoch 19::Minibatch 367::LR 0.0584615384615 --> Loss 0.00106840749582\n",
      "Epoch 19::Minibatch 368::LR 0.0584615384615 --> Loss 0.000983590086301\n",
      "Epoch 19::Minibatch 369::LR 0.0584615384615 --> Loss 0.00286292970181\n",
      "Epoch 19::Minibatch 370::LR 0.0584615384615 --> Loss 0.002257767121\n",
      "Epoch 19::Minibatch 371::LR 0.0584615384615 --> Loss 0.00187097887198\n",
      "Epoch 19::Minibatch 372::LR 0.0584615384615 --> Loss 0.000434177617232\n",
      "Epoch 19::Minibatch 373::LR 0.0584615384615 --> Loss 0.00177599489689\n",
      "Epoch 19::Minibatch 374::LR 0.0584615384615 --> Loss 0.00219771186511\n",
      "Epoch 19::Minibatch 375::LR 0.0584615384615 --> Loss 0.00184565881888\n",
      "Epoch 19::Minibatch 376::LR 0.0584615384615 --> Loss 0.00123378684123\n",
      "Epoch 19::Minibatch 377::LR 0.0584615384615 --> Loss 0.00193764448166\n",
      "Epoch 19::Minibatch 378::LR 0.0584615384615 --> Loss 0.00212541540464\n",
      "Epoch 19::Minibatch 379::LR 0.0584615384615 --> Loss 0.00236751655738\n",
      "Epoch 19::Minibatch 380::LR 0.0584615384615 --> Loss 0.00158224980036\n",
      "Epoch 19::Minibatch 381::LR 0.0584615384615 --> Loss 0.000982785622279\n",
      "Epoch 19::Minibatch 382::LR 0.0584615384615 --> Loss 0.00201415300369\n",
      "Epoch 19::Minibatch 383::LR 0.0584615384615 --> Loss 0.00195815006892\n",
      "Epoch 19::Minibatch 384::LR 0.0584615384615 --> Loss 0.0010578083992\n",
      "Epoch 19::Minibatch 385::LR 0.0584615384615 --> Loss 0.00103718678157\n",
      "Epoch 19::Minibatch 386::LR 0.0584615384615 --> Loss 0.00218659102917\n",
      "Epoch 19::Minibatch 387::LR 0.0584615384615 --> Loss 0.00234371920427\n",
      "Epoch 19::Minibatch 388::LR 0.0584615384615 --> Loss 0.00115854541461\n",
      "Epoch 19::Minibatch 389::LR 0.0584615384615 --> Loss 0.00179744700591\n",
      "Epoch 19::Minibatch 390::LR 0.0584615384615 --> Loss 0.00350251396497\n",
      "Epoch 19::Minibatch 391::LR 0.0584615384615 --> Loss 0.00265475451946\n",
      "Epoch 19::Minibatch 392::LR 0.0584615384615 --> Loss 0.00261565347513\n",
      "Epoch 19::Minibatch 393::LR 0.0584615384615 --> Loss 0.00276387155056\n",
      "Epoch 19::Minibatch 394::LR 0.0584615384615 --> Loss 0.00208253423373\n",
      "Epoch 19::Minibatch 395::LR 0.0584615384615 --> Loss 0.00205654342969\n",
      "Epoch 19::Minibatch 396::LR 0.0584615384615 --> Loss 0.00193725645542\n",
      "Epoch 19::Minibatch 397::LR 0.0584615384615 --> Loss 0.00207191129526\n",
      "Epoch 19::Minibatch 398::LR 0.0584615384615 --> Loss 0.00205689748128\n",
      "Epoch 19::Minibatch 399::LR 0.0584615384615 --> Loss 0.00236498455207\n",
      "Epoch 19::Minibatch 400::LR 0.0584615384615 --> Loss 0.00200835843881\n",
      "Epoch 19::Minibatch 401::LR 0.0584615384615 --> Loss 0.00345912416776\n",
      "Epoch 19::Minibatch 402::LR 0.0584615384615 --> Loss 0.00177684485912\n",
      "Epoch 19::Minibatch 403::LR 0.0584615384615 --> Loss 0.00144404908021\n",
      "Epoch 19::Minibatch 404::LR 0.0584615384615 --> Loss 0.00144788871209\n",
      "Epoch 19::Minibatch 405::LR 0.0584615384615 --> Loss 0.00346743901571\n",
      "Epoch 19::Minibatch 406::LR 0.0584615384615 --> Loss 0.0024266064167\n",
      "Epoch 19::Minibatch 407::LR 0.0584615384615 --> Loss 0.00172307809194\n",
      "Epoch 19::Minibatch 408::LR 0.0584615384615 --> Loss 0.000434499830008\n",
      "Epoch 19::Minibatch 409::LR 0.0584615384615 --> Loss 0.00230087041855\n",
      "Epoch 19::Minibatch 410::LR 0.0584615384615 --> Loss 0.00318304538727\n",
      "Epoch 19::Minibatch 411::LR 0.0584615384615 --> Loss 0.00163203825553\n",
      "Epoch 19::Minibatch 412::LR 0.0584615384615 --> Loss 0.000950530171394\n",
      "Epoch 19::Minibatch 413::LR 0.0584615384615 --> Loss 0.00195965627829\n",
      "Epoch 19::Minibatch 414::LR 0.0584615384615 --> Loss 0.00183042168617\n",
      "Epoch 19::Minibatch 415::LR 0.0584615384615 --> Loss 0.00113866647085\n",
      "Epoch 19::Minibatch 416::LR 0.0584615384615 --> Loss 0.000801689525445\n",
      "Epoch 19::Minibatch 417::LR 0.0584615384615 --> Loss 0.00168653527896\n",
      "Epoch 19::Minibatch 418::LR 0.0584615384615 --> Loss 0.00271101534367\n",
      "Epoch 19::Minibatch 419::LR 0.0584615384615 --> Loss 0.000490851054589\n",
      "Epoch 19::Minibatch 420::LR 0.0584615384615 --> Loss 0.000686622411013\n",
      "Epoch 19::Minibatch 421::LR 0.0584615384615 --> Loss 0.00191286146641\n",
      "Epoch 19::Minibatch 422::LR 0.0584615384615 --> Loss 0.00211656590303\n",
      "Epoch 19::Minibatch 423::LR 0.0584615384615 --> Loss 0.000958277285099\n",
      "Epoch 19::Minibatch 424::LR 0.0584615384615 --> Loss 0.00153565337261\n",
      "Epoch 19::Minibatch 425::LR 0.0584615384615 --> Loss 0.00289295355479\n",
      "Epoch 19::Minibatch 426::LR 0.0584615384615 --> Loss 0.00198743740718\n",
      "Epoch 19::Minibatch 427::LR 0.0584615384615 --> Loss 0.00070456251502\n",
      "Epoch 19::Minibatch 428::LR 0.0584615384615 --> Loss 0.00101220001777\n",
      "Epoch 19::Minibatch 429::LR 0.0584615384615 --> Loss 0.0023494742314\n",
      "Epoch 19::Minibatch 430::LR 0.0584615384615 --> Loss 0.00917001485825\n",
      "Epoch 19::Minibatch 431::LR 0.0584615384615 --> Loss 0.00378180424372\n",
      "Epoch 19::Minibatch 432::LR 0.0584615384615 --> Loss 0.00436184167862\n",
      "Epoch 19::Minibatch 433::LR 0.0584615384615 --> Loss 0.00256118893623\n",
      "Epoch 19::Minibatch 434::LR 0.0584615384615 --> Loss 0.00251922527949\n",
      "Epoch 19::Minibatch 435::LR 0.0584615384615 --> Loss 0.00231482803822\n",
      "Epoch 19::Minibatch 436::LR 0.0584615384615 --> Loss 0.00167012830575\n",
      "Epoch 19::Minibatch 437::LR 0.0584615384615 --> Loss 0.00314244925976\n",
      "Epoch 19::Minibatch 438::LR 0.0584615384615 --> Loss 0.00251431246599\n",
      "Epoch 19::Minibatch 439::LR 0.0584615384615 --> Loss 0.00203975160917\n",
      "Epoch 19::Minibatch 440::LR 0.0584615384615 --> Loss 0.00316269099712\n",
      "Epoch 19::Minibatch 441::LR 0.0584615384615 --> Loss 0.00295775969823\n",
      "Epoch 19::Minibatch 442::LR 0.0584615384615 --> Loss 0.00268960992495\n",
      "Epoch 19::Minibatch 443::LR 0.0584615384615 --> Loss 0.00362491647402\n",
      "Epoch 19::Minibatch 444::LR 0.0584615384615 --> Loss 0.00282478511333\n",
      "Epoch 19::Minibatch 445::LR 0.0584615384615 --> Loss 0.000881799360116\n",
      "Epoch 19::Minibatch 446::LR 0.0584615384615 --> Loss 0.00142927477757\n",
      "Epoch 19::Minibatch 447::LR 0.0584615384615 --> Loss 0.00239868462086\n",
      "Epoch 19::Minibatch 448::LR 0.0584615384615 --> Loss 0.00237778464953\n",
      "Epoch 19::Minibatch 449::LR 0.0584615384615 --> Loss 0.00369474768639\n",
      "Epoch 19::Minibatch 450::LR 0.0584615384615 --> Loss 0.00226046423117\n",
      "Epoch 19::Minibatch 451::LR 0.0584615384615 --> Loss 0.00398429791133\n",
      "Epoch 19::Minibatch 452::LR 0.0584615384615 --> Loss 0.00235768338044\n",
      "Epoch 19::Minibatch 453::LR 0.0584615384615 --> Loss 0.000369013001521\n",
      "Epoch 19::Minibatch 454::LR 0.0584615384615 --> Loss 0.00358517169952\n",
      "Epoch 19::Minibatch 455::LR 0.0584615384615 --> Loss 0.00267347554366\n",
      "Epoch 19::Minibatch 456::LR 0.0584615384615 --> Loss 0.00310401856899\n",
      "Epoch 19::Minibatch 457::LR 0.0584615384615 --> Loss 0.0019368861119\n",
      "Epoch 19::Minibatch 458::LR 0.0584615384615 --> Loss 0.000742681821187\n",
      "Epoch 19::Minibatch 459::LR 0.0584615384615 --> Loss 0.00405282219251\n",
      "Epoch 19::Minibatch 460::LR 0.0584615384615 --> Loss 0.00254309912523\n",
      "Epoch 19::Minibatch 461::LR 0.0584615384615 --> Loss 0.00385474522909\n",
      "Epoch 19::Minibatch 462::LR 0.0584615384615 --> Loss 0.000387089004119\n",
      "Epoch 19::Minibatch 463::LR 0.0584615384615 --> Loss 0.00447748382886\n",
      "Epoch 19::Minibatch 464::LR 0.0584615384615 --> Loss 0.00201499183973\n",
      "Epoch 19::Minibatch 465::LR 0.0584615384615 --> Loss 0.00506933172544\n",
      "Epoch 19::Minibatch 466::LR 0.0584615384615 --> Loss 0.0050706466039\n",
      "Epoch 19::Minibatch 467::LR 0.0584615384615 --> Loss 0.00556886633237\n",
      "Epoch 19::Minibatch 468::LR 0.0584615384615 --> Loss 0.00598705371221\n",
      "Epoch 19::Minibatch 469::LR 0.0584615384615 --> Loss 0.00656233668327\n",
      "Epoch 19::Minibatch 470::LR 0.0584615384615 --> Loss 0.00370045741399\n",
      "Epoch 19::Minibatch 471::LR 0.0584615384615 --> Loss 0.00170705397924\n",
      "Epoch 19::Minibatch 472::LR 0.0584615384615 --> Loss 0.00353796919187\n",
      "Epoch 19::Minibatch 473::LR 0.0584615384615 --> Loss 0.00226008812586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 474::LR 0.0584615384615 --> Loss 0.000694943318764\n",
      "Epoch 19::Minibatch 475::LR 0.0584615384615 --> Loss 0.00479148626328\n",
      "Epoch 19::Minibatch 476::LR 0.0584615384615 --> Loss 0.00765122095744\n",
      "Epoch 19::Minibatch 477::LR 0.0584615384615 --> Loss 0.0009241827329\n",
      "Epoch 19::Minibatch 478::LR 0.0584615384615 --> Loss 0.0024555037419\n",
      "Epoch 19::Minibatch 479::LR 0.0584615384615 --> Loss 0.00195484618346\n",
      "Epoch 19::Minibatch 480::LR 0.0584615384615 --> Loss 0.00152454624573\n",
      "Epoch 19::Minibatch 481::LR 0.0584615384615 --> Loss 0.000955740213394\n",
      "Epoch 19::Minibatch 482::LR 0.0584615384615 --> Loss 0.0020859871308\n",
      "Epoch 19::Minibatch 483::LR 0.0584615384615 --> Loss 0.0031394247214\n",
      "Epoch 19::Minibatch 484::LR 0.0584615384615 --> Loss 0.00350982387861\n",
      "Epoch 19::Minibatch 485::LR 0.0584615384615 --> Loss 0.000755497912566\n",
      "Epoch 19::Minibatch 486::LR 0.0584615384615 --> Loss 0.00291674017906\n",
      "Epoch 19::Minibatch 487::LR 0.0584615384615 --> Loss 0.00334707538287\n",
      "Epoch 19::Minibatch 488::LR 0.0584615384615 --> Loss 0.00203784406185\n",
      "Epoch 19::Minibatch 489::LR 0.0584615384615 --> Loss 0.00317957063516\n",
      "Epoch 19::Minibatch 490::LR 0.0584615384615 --> Loss 0.000409922947486\n",
      "Epoch 19::Minibatch 491::LR 0.0584615384615 --> Loss 0.00360326250394\n",
      "Epoch 19::Minibatch 492::LR 0.0584615384615 --> Loss 0.00305393874645\n",
      "Epoch 19::Minibatch 493::LR 0.0584615384615 --> Loss 0.00302592774232\n",
      "Epoch 19::Minibatch 494::LR 0.0584615384615 --> Loss 0.000736521979173\n",
      "Epoch 19::Minibatch 495::LR 0.0584615384615 --> Loss 0.00187342305978\n",
      "Epoch 19::Minibatch 496::LR 0.0584615384615 --> Loss 0.00285793185234\n",
      "Epoch 19::Minibatch 497::LR 0.0584615384615 --> Loss 0.000923422177633\n",
      "Epoch 19::Minibatch 498::LR 0.0584615384615 --> Loss 0.000559192399184\n",
      "Epoch 19::Minibatch 499::LR 0.0584615384615 --> Loss 0.00357982158661\n",
      "Epoch 19::Minibatch 500::LR 0.0584615384615 --> Loss 0.00143973102172\n",
      "Epoch 19::Minibatch 501::LR 0.0584615384615 --> Loss 0.00218187888463\n",
      "Epoch 19::Minibatch 502::LR 0.0584615384615 --> Loss 0.00380901813507\n",
      "Epoch 19::Minibatch 503::LR 0.0584615384615 --> Loss 0.00787814855576\n",
      "Epoch 19::Minibatch 504::LR 0.0584615384615 --> Loss 0.00748396873474\n",
      "Epoch 19::Minibatch 505::LR 0.0584615384615 --> Loss 0.00421923240026\n",
      "Epoch 19::Minibatch 506::LR 0.0584615384615 --> Loss 0.00342574795087\n",
      "Epoch 19::Minibatch 507::LR 0.0584615384615 --> Loss 0.00597656647364\n",
      "Epoch 19::Minibatch 508::LR 0.0584615384615 --> Loss 0.00340807199478\n",
      "Epoch 19::Minibatch 509::LR 0.0584615384615 --> Loss 0.00450592358907\n",
      "Epoch 19::Minibatch 510::LR 0.0584615384615 --> Loss 0.0045360604922\n",
      "Epoch 19::Minibatch 511::LR 0.0584615384615 --> Loss 0.00393177668254\n",
      "Epoch 19::Minibatch 512::LR 0.0584615384615 --> Loss 0.00268749038378\n",
      "Epoch 19::Minibatch 513::LR 0.0584615384615 --> Loss 0.000634636431932\n",
      "Epoch 19::Minibatch 514::LR 0.0584615384615 --> Loss 0.00266444245974\n",
      "Epoch 19::Minibatch 515::LR 0.0584615384615 --> Loss 0.00300531109174\n",
      "Epoch 19::Minibatch 516::LR 0.0584615384615 --> Loss 0.00404554804166\n",
      "Epoch 19::Minibatch 517::LR 0.0584615384615 --> Loss 0.00352669119835\n",
      "Epoch 19::Minibatch 518::LR 0.0584615384615 --> Loss 0.00257926623027\n",
      "Epoch 19::Minibatch 519::LR 0.0584615384615 --> Loss 0.0034732679526\n",
      "Epoch 19::Minibatch 520::LR 0.0584615384615 --> Loss 0.00537893374761\n",
      "Epoch 19::Minibatch 521::LR 0.0584615384615 --> Loss 0.00546264648438\n",
      "Epoch 19::Minibatch 522::LR 0.0584615384615 --> Loss 0.00786797364553\n",
      "Epoch 19::Minibatch 523::LR 0.0584615384615 --> Loss 0.000642246007919\n",
      "Epoch 19::Minibatch 524::LR 0.0584615384615 --> Loss 0.00141648302476\n",
      "Epoch 19::Minibatch 525::LR 0.0584615384615 --> Loss 0.00319966892401\n",
      "Epoch 19::Minibatch 526::LR 0.0584615384615 --> Loss 0.00395947297414\n",
      "Epoch 19::Minibatch 527::LR 0.0584615384615 --> Loss 0.00222848296165\n",
      "Epoch 19::Minibatch 528::LR 0.0584615384615 --> Loss 0.00102339009444\n",
      "Epoch 19::Minibatch 529::LR 0.0584615384615 --> Loss 0.00405762632688\n",
      "Epoch 19::Minibatch 530::LR 0.0584615384615 --> Loss 0.0041087547938\n",
      "Epoch 19::Minibatch 531::LR 0.0584615384615 --> Loss 0.00362931370735\n",
      "Epoch 19::Minibatch 532::LR 0.0584615384615 --> Loss 0.00269597073396\n",
      "Epoch 19::Minibatch 533::LR 0.0584615384615 --> Loss 0.00500140110652\n",
      "Epoch 19::Minibatch 534::LR 0.0584615384615 --> Loss 0.00379600644112\n",
      "Epoch 19::Minibatch 535::LR 0.0584615384615 --> Loss 0.00326761066914\n",
      "Epoch 19::Minibatch 536::LR 0.0584615384615 --> Loss 0.00210692405701\n",
      "Epoch 19::Minibatch 537::LR 0.0584615384615 --> Loss 0.000615257869164\n",
      "Epoch 19::Minibatch 538::LR 0.0584615384615 --> Loss 0.00167636454105\n",
      "Epoch 19::Minibatch 539::LR 0.0584615384615 --> Loss 0.00340519110362\n",
      "Epoch 19::Minibatch 540::LR 0.0584615384615 --> Loss 0.00341409603755\n",
      "Epoch 19::Minibatch 541::LR 0.0584615384615 --> Loss 0.0028920686245\n",
      "Epoch 19::Minibatch 542::LR 0.0584615384615 --> Loss 0.00250811874866\n",
      "Epoch 19::Minibatch 543::LR 0.0584615384615 --> Loss 0.00270690560341\n",
      "Epoch 19::Minibatch 544::LR 0.0584615384615 --> Loss 0.00391638120015\n",
      "Epoch 19::Minibatch 545::LR 0.0584615384615 --> Loss 0.00202912429969\n",
      "Epoch 19::Minibatch 546::LR 0.0584615384615 --> Loss 0.00065222799778\n",
      "Epoch 19::Minibatch 547::LR 0.0584615384615 --> Loss 0.00261494338512\n",
      "Epoch 19::Minibatch 548::LR 0.0584615384615 --> Loss 0.00363127628962\n",
      "Epoch 19::Minibatch 549::LR 0.0584615384615 --> Loss 0.00873813788096\n",
      "Epoch 19::Minibatch 550::LR 0.0584615384615 --> Loss 0.00116884976625\n",
      "Epoch 19::Minibatch 551::LR 0.0584615384615 --> Loss 0.00245051383972\n",
      "Epoch 19::Minibatch 552::LR 0.0584615384615 --> Loss 0.00352710445722\n",
      "Epoch 19::Minibatch 553::LR 0.0584615384615 --> Loss 0.00315569937229\n",
      "Epoch 19::Minibatch 554::LR 0.0584615384615 --> Loss 0.00372046748797\n",
      "Epoch 19::Minibatch 555::LR 0.0584615384615 --> Loss 0.000970864196618\n",
      "Epoch 19::Minibatch 556::LR 0.0584615384615 --> Loss 0.00197457134724\n",
      "Epoch 19::Minibatch 557::LR 0.0584615384615 --> Loss 0.00243676284949\n",
      "Epoch 19::Minibatch 558::LR 0.0584615384615 --> Loss 0.00372464021047\n",
      "Epoch 19::Minibatch 559::LR 0.0584615384615 --> Loss 0.00372135718664\n",
      "Epoch 19::Minibatch 560::LR 0.0584615384615 --> Loss 0.00309711535772\n",
      "Epoch 19::Minibatch 561::LR 0.0584615384615 --> Loss 0.00268817404906\n",
      "Epoch 19::Minibatch 562::LR 0.0584615384615 --> Loss 0.00236889501413\n",
      "Epoch 19::Minibatch 563::LR 0.0584615384615 --> Loss 0.00402230620384\n",
      "Epoch 19::Minibatch 564::LR 0.0584615384615 --> Loss 0.00310613910357\n",
      "Epoch 19::Minibatch 565::LR 0.0584615384615 --> Loss 0.00365575432777\n",
      "Epoch 19::Minibatch 566::LR 0.0584615384615 --> Loss 0.0022579284509\n",
      "Epoch 19::Minibatch 567::LR 0.0584615384615 --> Loss 0.00255881230036\n",
      "Epoch 19::Minibatch 568::LR 0.0584615384615 --> Loss 0.00179812749227\n",
      "Epoch 19::Minibatch 569::LR 0.0584615384615 --> Loss 0.000562497079372\n",
      "Epoch 19::Minibatch 570::LR 0.0584615384615 --> Loss 0.00168467183908\n",
      "Epoch 19::Minibatch 571::LR 0.0584615384615 --> Loss 0.00219221909841\n",
      "Epoch 19::Minibatch 572::LR 0.0584615384615 --> Loss 0.00233758827051\n",
      "Epoch 19::Minibatch 573::LR 0.0584615384615 --> Loss 0.00149192482233\n",
      "Epoch 19::Minibatch 574::LR 0.0584615384615 --> Loss 0.00104704916477\n",
      "Epoch 19::Minibatch 575::LR 0.0584615384615 --> Loss 0.00176953196526\n",
      "Epoch 19::Minibatch 576::LR 0.0584615384615 --> Loss 0.00209912776947\n",
      "Epoch 19::Minibatch 577::LR 0.0584615384615 --> Loss 0.00164938718081\n",
      "Epoch 19::Minibatch 578::LR 0.0584615384615 --> Loss 0.00128131687641\n",
      "Epoch 19::Minibatch 579::LR 0.0584615384615 --> Loss 0.00119662344456\n",
      "Epoch 19::Minibatch 580::LR 0.0584615384615 --> Loss 0.00193689624468\n",
      "Epoch 19::Minibatch 581::LR 0.0584615384615 --> Loss 0.00171397725741\n",
      "Epoch 19::Minibatch 582::LR 0.0584615384615 --> Loss 0.00413507978121\n",
      "Epoch 19::Minibatch 583::LR 0.0584615384615 --> Loss 0.000942555467288\n",
      "Epoch 19::Minibatch 584::LR 0.0584615384615 --> Loss 0.00130708773931\n",
      "Epoch 19::Minibatch 585::LR 0.0584615384615 --> Loss 0.00428928772608\n",
      "Epoch 19::Minibatch 586::LR 0.0584615384615 --> Loss 0.0039435728391\n",
      "Epoch 19::Minibatch 587::LR 0.0584615384615 --> Loss 0.0011255333821\n",
      "Epoch 19::Minibatch 588::LR 0.0584615384615 --> Loss 0.00140188564857\n",
      "Epoch 19::Minibatch 589::LR 0.0584615384615 --> Loss 0.00276578426361\n",
      "Epoch 19::Minibatch 590::LR 0.0584615384615 --> Loss 0.00192076643308\n",
      "Epoch 19::Minibatch 591::LR 0.0584615384615 --> Loss 0.00297523677349\n",
      "Epoch 19::Minibatch 592::LR 0.0584615384615 --> Loss 0.00117520610491\n",
      "Epoch 19::Minibatch 593::LR 0.0584615384615 --> Loss 0.00258094569047\n",
      "Epoch 19::Minibatch 594::LR 0.0584615384615 --> Loss 0.0027204712232\n",
      "Epoch 19::Minibatch 595::LR 0.0584615384615 --> Loss 0.00304911474387\n",
      "Epoch 19::Minibatch 596::LR 0.0584615384615 --> Loss 0.00192441642284\n",
      "Epoch 19::Minibatch 597::LR 0.0584615384615 --> Loss 0.00118951439857\n",
      "Epoch 19::Minibatch 598::LR 0.0584615384615 --> Loss 0.00297056317329\n",
      "Epoch 19::Minibatch 599::LR 0.0584615384615 --> Loss 0.00185009837151\n",
      "Epoch 19::Minibatch 600::LR 0.0584615384615 --> Loss 0.00220685064793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 601::LR 0.0584615384615 --> Loss 0.00386785904566\n",
      "Epoch 19::Minibatch 602::LR 0.0584615384615 --> Loss 0.00211436053117\n",
      "Epoch 19::Minibatch 603::LR 0.0584615384615 --> Loss 0.00264440059662\n",
      "Epoch 19::Minibatch 604::LR 0.0584615384615 --> Loss 0.00165325929721\n",
      "Epoch 19::Minibatch 605::LR 0.0584615384615 --> Loss 0.00236204087734\n",
      "Epoch 19::Minibatch 606::LR 0.0584615384615 --> Loss 0.00191515247027\n",
      "Epoch 19::Minibatch 607::LR 0.0584615384615 --> Loss 0.000842161774635\n",
      "Epoch 19::Minibatch 608::LR 0.0584615384615 --> Loss 0.00158144384623\n",
      "Epoch 19::Minibatch 609::LR 0.0584615384615 --> Loss 0.0023989790678\n",
      "Epoch 19::Minibatch 610::LR 0.0584615384615 --> Loss 0.00403846542041\n",
      "Epoch 19::Minibatch 611::LR 0.0584615384615 --> Loss 0.00264225522677\n",
      "Epoch 19::Minibatch 612::LR 0.0584615384615 --> Loss 0.000483521074057\n",
      "Epoch 19::Minibatch 613::LR 0.0584615384615 --> Loss 0.00131211360296\n",
      "Epoch 19::Minibatch 614::LR 0.0584615384615 --> Loss 0.00245086769263\n",
      "Epoch 19::Minibatch 615::LR 0.0584615384615 --> Loss 0.00168151656787\n",
      "Epoch 19::Minibatch 616::LR 0.0584615384615 --> Loss 0.000925798813502\n",
      "Epoch 19::Minibatch 617::LR 0.0584615384615 --> Loss 0.000501547108094\n",
      "Epoch 19::Minibatch 618::LR 0.0584615384615 --> Loss 0.00277941604455\n",
      "Epoch 19::Minibatch 619::LR 0.0584615384615 --> Loss 0.00192767103513\n",
      "Epoch 19::Minibatch 620::LR 0.0584615384615 --> Loss 0.00171470403671\n",
      "Epoch 19::Minibatch 621::LR 0.0584615384615 --> Loss 0.000852420628071\n",
      "Epoch 19::Minibatch 622::LR 0.0584615384615 --> Loss 0.000797022034725\n",
      "Epoch 19::Minibatch 623::LR 0.0584615384615 --> Loss 0.00222250878811\n",
      "Epoch 19::Minibatch 624::LR 0.0584615384615 --> Loss 0.00180282115936\n",
      "Epoch 19::Minibatch 625::LR 0.0584615384615 --> Loss 0.00290001988411\n",
      "Epoch 19::Minibatch 626::LR 0.0584615384615 --> Loss 0.00427227854729\n",
      "Epoch 19::Minibatch 627::LR 0.0584615384615 --> Loss 0.0013129979372\n",
      "Epoch 19::Minibatch 628::LR 0.0584615384615 --> Loss 0.000897620121638\n",
      "Epoch 19::Minibatch 629::LR 0.0584615384615 --> Loss 0.00334458390872\n",
      "Epoch 19::Minibatch 630::LR 0.0584615384615 --> Loss 0.00326206703981\n",
      "Epoch 19::Minibatch 631::LR 0.0584615384615 --> Loss 0.00615242878596\n",
      "Epoch 19::Minibatch 632::LR 0.0584615384615 --> Loss 0.000793817341328\n",
      "Epoch 19::Minibatch 633::LR 0.0584615384615 --> Loss 0.00165070792039\n",
      "Epoch 19::Minibatch 634::LR 0.0584615384615 --> Loss 0.00323928018411\n",
      "Epoch 19::Minibatch 635::LR 0.0584615384615 --> Loss 0.00537265658379\n",
      "Epoch 19::Minibatch 636::LR 0.0584615384615 --> Loss 0.00500998139381\n",
      "Epoch 19::Minibatch 637::LR 0.0584615384615 --> Loss 0.000772608568271\n",
      "Epoch 19::Minibatch 638::LR 0.0584615384615 --> Loss 0.00151076614857\n",
      "Epoch 19::Minibatch 639::LR 0.0584615384615 --> Loss 0.00329040070375\n",
      "Epoch 19::Minibatch 640::LR 0.0584615384615 --> Loss 0.00493296941121\n",
      "Epoch 19::Minibatch 641::LR 0.0584615384615 --> Loss 0.0031228685379\n",
      "Epoch 19::Minibatch 642::LR 0.0584615384615 --> Loss 0.000544838160276\n",
      "Epoch 19::Minibatch 643::LR 0.0584615384615 --> Loss 0.00234061221282\n",
      "Epoch 19::Minibatch 644::LR 0.0584615384615 --> Loss 0.00396762013435\n",
      "Epoch 19::Minibatch 645::LR 0.0584615384615 --> Loss 0.00424025456111\n",
      "Epoch 19::Minibatch 646::LR 0.0584615384615 --> Loss 0.00151281148195\n",
      "Epoch 19::Minibatch 647::LR 0.0584615384615 --> Loss 0.000516432523727\n",
      "Epoch 19::Minibatch 648::LR 0.0584615384615 --> Loss 0.0029410191377\n",
      "Epoch 19::Minibatch 649::LR 0.0584615384615 --> Loss 0.00349353869756\n",
      "Epoch 19::Minibatch 650::LR 0.0584615384615 --> Loss 0.00329916914304\n",
      "Epoch 19::Minibatch 651::LR 0.0584615384615 --> Loss 0.00137677212556\n",
      "Epoch 19::Minibatch 652::LR 0.0584615384615 --> Loss 0.000803008327881\n",
      "Epoch 19::Minibatch 653::LR 0.0584615384615 --> Loss 0.0028548036019\n",
      "Epoch 19::Minibatch 654::LR 0.0584615384615 --> Loss 0.00311909834544\n",
      "Epoch 19::Minibatch 655::LR 0.0584615384615 --> Loss 0.00351679086685\n",
      "Epoch 19::Minibatch 656::LR 0.0584615384615 --> Loss 0.000759918292363\n",
      "Epoch 19::Minibatch 657::LR 0.0584615384615 --> Loss 0.00224671959877\n",
      "Epoch 19::Minibatch 658::LR 0.0584615384615 --> Loss 0.00484177748362\n",
      "Epoch 19::Minibatch 659::LR 0.0584615384615 --> Loss 0.00230175793171\n",
      "Epoch 19::Minibatch 660::LR 0.0584615384615 --> Loss 0.00260660529137\n",
      "Epoch 19::Minibatch 661::LR 0.0584615384615 --> Loss 0.00246226211389\n",
      "Epoch 19::Minibatch 662::LR 0.0584615384615 --> Loss 0.00181368609269\n",
      "Epoch 19::Minibatch 663::LR 0.0584615384615 --> Loss 0.00368082841237\n",
      "Epoch 19::Minibatch 664::LR 0.0584615384615 --> Loss 0.00338622053464\n",
      "Epoch 19::Minibatch 665::LR 0.0584615384615 --> Loss 0.0007267477115\n",
      "Epoch 19::Minibatch 666::LR 0.0584615384615 --> Loss 0.00392355720202\n",
      "Epoch 19::Minibatch 667::LR 0.0584615384615 --> Loss 0.00255221406619\n",
      "Epoch 19::Minibatch 668::LR 0.0584615384615 --> Loss 0.00686941305796\n",
      "Epoch 19::Minibatch 669::LR 0.0584615384615 --> Loss 0.00109292497238\n",
      "Epoch 19::Minibatch 670::LR 0.0584615384615 --> Loss 0.00135081509749\n",
      "Epoch 19::Minibatch 671::LR 0.0584615384615 --> Loss 0.00532302419345\n",
      "Epoch 19::Minibatch 672::LR 0.0584615384615 --> Loss 0.00367866714795\n",
      "Epoch 19::Minibatch 673::LR 0.0584615384615 --> Loss 0.00162098427614\n",
      "Epoch 19::Minibatch 674::LR 0.0584615384615 --> Loss 0.000514251589775\n",
      "Epoch 19::Minibatch 675::LR 0.0584615384615 --> Loss 0.00218727389971\n",
      "Epoch 19::Minibatch 676::LR 0.0584615384615 --> Loss 0.00213043053945\n",
      "Epoch 19::Minibatch 677::LR 0.0584615384615 --> Loss 0.00278816878796\n",
      "Epoch 19::Minibatch 678::LR 0.0584615384615 --> Loss 0.00192092180252\n",
      "Epoch 19::Minibatch 679::LR 0.0584615384615 --> Loss 0.00347399950027\n",
      "Epoch 19::Minibatch 680::LR 0.0584615384615 --> Loss 0.00214358846347\n",
      "Epoch 19::Minibatch 681::LR 0.0584615384615 --> Loss 0.00243282417456\n",
      "Epoch 19::Minibatch 682::LR 0.0584615384615 --> Loss 0.000761300524076\n",
      "Epoch 19::Minibatch 683::LR 0.0584615384615 --> Loss 0.00236771404743\n",
      "Epoch 19::Minibatch 684::LR 0.0584615384615 --> Loss 0.00235047797362\n",
      "Epoch 19::Minibatch 685::LR 0.0584615384615 --> Loss 0.00289627850056\n",
      "Epoch 19::Minibatch 686::LR 0.0584615384615 --> Loss 0.00155664712191\n",
      "Epoch 19::Minibatch 687::LR 0.0584615384615 --> Loss 0.000853154857953\n",
      "Epoch 19::Minibatch 688::LR 0.0584615384615 --> Loss 0.00276654799779\n",
      "Epoch 19::Minibatch 689::LR 0.0584615384615 --> Loss 0.00252373476823\n",
      "Epoch 19::Minibatch 690::LR 0.0584615384615 --> Loss 0.00191210389137\n",
      "Epoch 19::Minibatch 691::LR 0.0584615384615 --> Loss 0.000659225136042\n",
      "Epoch 19::Minibatch 692::LR 0.0584615384615 --> Loss 0.00246294220289\n",
      "Epoch 19::Minibatch 693::LR 0.0584615384615 --> Loss 0.00258323947589\n",
      "Epoch 19::Minibatch 694::LR 0.0584615384615 --> Loss 0.00302053074042\n",
      "Epoch 19::Minibatch 695::LR 0.0584615384615 --> Loss 0.00175105710824\n",
      "Epoch 19::Minibatch 696::LR 0.0584615384615 --> Loss 0.00204581757387\n",
      "Epoch 19::Minibatch 697::LR 0.0584615384615 --> Loss 0.00140563547611\n",
      "Epoch 19::Minibatch 698::LR 0.0584615384615 --> Loss 0.00163704027732\n",
      "Epoch 19::Minibatch 699::LR 0.0584615384615 --> Loss 0.00382847348849\n",
      "Epoch 19::Minibatch 700::LR 0.0584615384615 --> Loss 0.00266424357891\n",
      "Epoch 19::Minibatch 701::LR 0.0584615384615 --> Loss 0.0019720296065\n",
      "Epoch 19::Minibatch 702::LR 0.0584615384615 --> Loss 0.00166485011578\n",
      "Epoch 19::Minibatch 703::LR 0.0584615384615 --> Loss 0.00431595047315\n",
      "Epoch 19::Minibatch 704::LR 0.0584615384615 --> Loss 0.00180582741896\n",
      "Epoch 19::Minibatch 705::LR 0.0584615384615 --> Loss 0.00286485393842\n",
      "Epoch 19::Minibatch 706::LR 0.0584615384615 --> Loss 0.00224085172017\n",
      "Epoch 19::Minibatch 707::LR 0.0584615384615 --> Loss 0.0011828349034\n",
      "Epoch 19::Minibatch 708::LR 0.0584615384615 --> Loss 0.00173451125622\n",
      "Epoch 19::Minibatch 709::LR 0.0584615384615 --> Loss 0.00168463766575\n",
      "Epoch 19::Minibatch 710::LR 0.0584615384615 --> Loss 0.00253171960513\n",
      "Epoch 19::Minibatch 711::LR 0.0584615384615 --> Loss 0.00193287452062\n",
      "Epoch 19::Minibatch 712::LR 0.0584615384615 --> Loss 0.0013362027208\n",
      "Epoch 19::Minibatch 713::LR 0.0584615384615 --> Loss 0.00176657001177\n",
      "Epoch 19::Minibatch 714::LR 0.0584615384615 --> Loss 0.00277134935061\n",
      "Epoch 19::Minibatch 715::LR 0.0584615384615 --> Loss 0.0029381720225\n",
      "Epoch 19::Minibatch 716::LR 0.0584615384615 --> Loss 0.00162296354771\n",
      "Epoch 19::Minibatch 717::LR 0.0584615384615 --> Loss 0.00162566204866\n",
      "Epoch 19::Minibatch 718::LR 0.0584615384615 --> Loss 0.00126129448414\n",
      "Epoch 19::Minibatch 719::LR 0.0584615384615 --> Loss 0.00167733808359\n",
      "Epoch 19::Minibatch 720::LR 0.0584615384615 --> Loss 0.00257862488429\n",
      "Epoch 19::Minibatch 721::LR 0.0584615384615 --> Loss 0.00061803534627\n",
      "Epoch 19::Minibatch 722::LR 0.0584615384615 --> Loss 0.00475845456123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 723::LR 0.0584615384615 --> Loss 0.00489806771278\n",
      "Epoch 19::Minibatch 724::LR 0.0584615384615 --> Loss 0.000967618028323\n",
      "Epoch 19::Minibatch 725::LR 0.0584615384615 --> Loss 0.00216497302055\n",
      "Epoch 19::Minibatch 726::LR 0.0584615384615 --> Loss 0.00442591468493\n",
      "Epoch 19::Minibatch 727::LR 0.0584615384615 --> Loss 0.00322177847226\n",
      "Epoch 19::Minibatch 728::LR 0.0584615384615 --> Loss 0.000645259867112\n",
      "Epoch 19::Minibatch 729::LR 0.0584615384615 --> Loss 0.000742005010446\n",
      "Epoch 19::Minibatch 730::LR 0.0584615384615 --> Loss 0.00282222191493\n",
      "Epoch 19::Minibatch 731::LR 0.0584615384615 --> Loss 0.00251752932866\n",
      "Epoch 19::Minibatch 732::LR 0.0584615384615 --> Loss 0.00218800365925\n",
      "Epoch 19::Minibatch 733::LR 0.0584615384615 --> Loss 0.000661039004723\n",
      "Epoch 19::Minibatch 734::LR 0.0584615384615 --> Loss 0.00172525048256\n",
      "Epoch 19::Minibatch 735::LR 0.0584615384615 --> Loss 0.00237446328004\n",
      "Epoch 19::Minibatch 736::LR 0.0584615384615 --> Loss 0.00347092866898\n",
      "Epoch 19::Minibatch 737::LR 0.0584615384615 --> Loss 0.00305561204751\n",
      "Epoch 19::Minibatch 738::LR 0.0584615384615 --> Loss 0.00155224194129\n",
      "Epoch 19::Minibatch 739::LR 0.0584615384615 --> Loss 0.00246134579182\n",
      "Epoch 19::Minibatch 740::LR 0.0584615384615 --> Loss 0.00383919239044\n",
      "Epoch 19::Minibatch 741::LR 0.0584615384615 --> Loss 0.00265598595142\n",
      "Epoch 19::Minibatch 742::LR 0.0584615384615 --> Loss 0.00210958242416\n",
      "Epoch 19::Minibatch 743::LR 0.0584615384615 --> Loss 0.0014113604029\n",
      "Epoch 19::Minibatch 744::LR 0.0584615384615 --> Loss 0.00180856585503\n",
      "Epoch 19::Minibatch 745::LR 0.0584615384615 --> Loss 0.00283091624578\n",
      "Epoch 19::Minibatch 746::LR 0.0584615384615 --> Loss 0.00296194593112\n",
      "Epoch 19::Minibatch 747::LR 0.0584615384615 --> Loss 0.00178924580415\n",
      "Epoch 19::Minibatch 748::LR 0.0584615384615 --> Loss 0.000625137885412\n",
      "Epoch 19::Minibatch 749::LR 0.0584615384615 --> Loss 0.00165237029394\n",
      "Epoch 19::Minibatch 750::LR 0.0584615384615 --> Loss 0.00245957454046\n",
      "Epoch 19::Minibatch 751::LR 0.0584615384615 --> Loss 0.00277477522691\n",
      "Epoch 19::Minibatch 752::LR 0.0584615384615 --> Loss 0.00122865557671\n",
      "Epoch 19::Minibatch 753::LR 0.0584615384615 --> Loss 0.00221996446451\n",
      "Epoch 19::Minibatch 754::LR 0.0584615384615 --> Loss 0.00240255832672\n",
      "Epoch 19::Minibatch 755::LR 0.0584615384615 --> Loss 0.00266720791658\n",
      "Epoch 19::Minibatch 756::LR 0.0584615384615 --> Loss 0.00136756628752\n",
      "Epoch 19::Minibatch 757::LR 0.0584615384615 --> Loss 0.000743654320637\n",
      "Epoch 19::Minibatch 758::LR 0.0584615384615 --> Loss 0.00160229414701\n",
      "Epoch 19::Minibatch 759::LR 0.0584615384615 --> Loss 0.00369398236275\n",
      "Epoch 19::Minibatch 760::LR 0.0584615384615 --> Loss 0.00296345233917\n",
      "Epoch 19::Minibatch 761::LR 0.0584615384615 --> Loss 0.00617135882378\n",
      "Epoch 19::Minibatch 762::LR 0.0584615384615 --> Loss 0.00372555732727\n",
      "Epoch 19::Minibatch 763::LR 0.0584615384615 --> Loss 0.00352722326914\n",
      "Epoch 19::Minibatch 764::LR 0.0584615384615 --> Loss 0.00314584255219\n",
      "Epoch 19::Minibatch 765::LR 0.0584615384615 --> Loss 0.00129857758681\n",
      "Epoch 19::Minibatch 766::LR 0.0584615384615 --> Loss 0.00227901995182\n",
      "Epoch 19::Minibatch 767::LR 0.0584615384615 --> Loss 0.00495301604271\n",
      "Epoch 19::Minibatch 768::LR 0.0584615384615 --> Loss 0.00363452275594\n",
      "Epoch 19::Minibatch 769::LR 0.0584615384615 --> Loss 0.00187788327535\n",
      "Epoch 19::Minibatch 770::LR 0.0584615384615 --> Loss 0.00148034294446\n",
      "Epoch 19::Minibatch 771::LR 0.0584615384615 --> Loss 0.00363605737686\n",
      "Epoch 19::Minibatch 772::LR 0.0584615384615 --> Loss 0.00343951781591\n",
      "Epoch 19::Minibatch 773::LR 0.0584615384615 --> Loss 0.00313746551673\n",
      "Epoch 19::Minibatch 774::LR 0.0584615384615 --> Loss 0.00180298268795\n",
      "Epoch 19::Minibatch 775::LR 0.0584615384615 --> Loss 0.00370183587074\n",
      "Epoch 19::Minibatch 776::LR 0.0584615384615 --> Loss 0.00359631896019\n",
      "Epoch 19::Minibatch 777::LR 0.0584615384615 --> Loss 0.00717736323675\n",
      "Epoch 19::Minibatch 778::LR 0.0584615384615 --> Loss 0.00899302959442\n",
      "Epoch 19::Minibatch 779::LR 0.0584615384615 --> Loss 0.00234056214492\n",
      "Epoch 19::Minibatch 780::LR 0.0584615384615 --> Loss 0.00158412277699\n",
      "Epoch 19::Minibatch 781::LR 0.0584615384615 --> Loss 0.00344271063805\n",
      "Epoch 19::Minibatch 782::LR 0.0584615384615 --> Loss 0.00392268419266\n",
      "Epoch 19::Minibatch 783::LR 0.0584615384615 --> Loss 0.00229628503323\n",
      "Epoch 19::Minibatch 784::LR 0.0584615384615 --> Loss 0.00071395650506\n",
      "Epoch 19::Minibatch 785::LR 0.0584615384615 --> Loss 0.00335555990537\n",
      "Epoch 19::Minibatch 786::LR 0.0584615384615 --> Loss 0.00343349178632\n",
      "Epoch 19::Minibatch 787::LR 0.0584615384615 --> Loss 0.00266661902269\n",
      "Epoch 19::Minibatch 788::LR 0.0584615384615 --> Loss 0.00237611651421\n",
      "Epoch 19::Minibatch 789::LR 0.0584615384615 --> Loss 0.00073439086477\n",
      "Epoch 19::Minibatch 790::LR 0.0584615384615 --> Loss 0.00314977765083\n",
      "Epoch 19::Minibatch 791::LR 0.0584615384615 --> Loss 0.00349518140157\n",
      "Epoch 19::Minibatch 792::LR 0.0584615384615 --> Loss 0.00309264659882\n",
      "Epoch 19::Minibatch 793::LR 0.0584615384615 --> Loss 0.00174342830976\n",
      "Epoch 19::Minibatch 794::LR 0.0584615384615 --> Loss 0.00101251562436\n",
      "Epoch 19::Minibatch 795::LR 0.0584615384615 --> Loss 0.00291820923487\n",
      "Epoch 19::Minibatch 796::LR 0.0584615384615 --> Loss 0.00545435945193\n",
      "Epoch 19::Minibatch 797::LR 0.0584615384615 --> Loss 0.0069305785497\n",
      "Epoch 19::Minibatch 798::LR 0.0584615384615 --> Loss 0.00323402722677\n",
      "Epoch 19::Minibatch 799::LR 0.0584615384615 --> Loss 0.00232603907585\n",
      "Epoch 19::Minibatch 800::LR 0.0584615384615 --> Loss 0.00201413710912\n",
      "Epoch 19::Minibatch 801::LR 0.0584615384615 --> Loss 0.00412796656291\n",
      "Epoch 19::Minibatch 802::LR 0.0584615384615 --> Loss 0.00128378609816\n",
      "Epoch 19::Minibatch 803::LR 0.0584615384615 --> Loss 0.0028768269221\n",
      "Epoch 19::Minibatch 804::LR 0.0584615384615 --> Loss 0.00214944104354\n",
      "Epoch 19::Minibatch 805::LR 0.0584615384615 --> Loss 0.00224664270878\n",
      "Epoch 19::Minibatch 806::LR 0.0584615384615 --> Loss 0.00335669835409\n",
      "Epoch 19::Minibatch 807::LR 0.0584615384615 --> Loss 0.00303588449955\n",
      "Epoch 19::Minibatch 808::LR 0.0584615384615 --> Loss 0.00267976224422\n",
      "Epoch 19::Minibatch 809::LR 0.0584615384615 --> Loss 0.00356095671654\n",
      "Epoch 19::Minibatch 810::LR 0.0584615384615 --> Loss 0.00484736482302\n",
      "Epoch 19::Minibatch 811::LR 0.0584615384615 --> Loss 0.00458948254585\n",
      "Epoch 19::Minibatch 812::LR 0.0584615384615 --> Loss 0.00419907569885\n",
      "Epoch 19::Minibatch 813::LR 0.0584615384615 --> Loss 0.00367041826248\n",
      "Epoch 19::Minibatch 814::LR 0.0584615384615 --> Loss 0.00168792148431\n",
      "Epoch 19::Minibatch 815::LR 0.0584615384615 --> Loss 0.00371793190638\n",
      "Epoch 19::Minibatch 816::LR 0.0584615384615 --> Loss 0.00410562396049\n",
      "Epoch 19::Minibatch 817::LR 0.0584615384615 --> Loss 0.00548237681389\n",
      "Epoch 19::Minibatch 818::LR 0.0584615384615 --> Loss 0.00125897447268\n",
      "Epoch 19::Minibatch 819::LR 0.0584615384615 --> Loss 0.00070436924696\n",
      "Epoch 19::Minibatch 820::LR 0.0584615384615 --> Loss 0.00528224507968\n",
      "Epoch 19::Minibatch 821::LR 0.0584615384615 --> Loss 0.0031222085158\n",
      "Epoch 19::Minibatch 822::LR 0.0584615384615 --> Loss 0.00369572003682\n",
      "Epoch 19::Minibatch 823::LR 0.0584615384615 --> Loss 0.0012884058555\n",
      "Epoch 19::Minibatch 824::LR 0.0584615384615 --> Loss 0.00137474199136\n",
      "Epoch 19::Minibatch 825::LR 0.0584615384615 --> Loss 0.00366421262423\n",
      "Epoch 19::Minibatch 826::LR 0.0584615384615 --> Loss 0.0039933848381\n",
      "Epoch 19::Minibatch 827::LR 0.0584615384615 --> Loss 0.00208398302396\n",
      "Epoch 19::Minibatch 828::LR 0.0584615384615 --> Loss 0.000521883418163\n",
      "Epoch 19::Minibatch 829::LR 0.0584615384615 --> Loss 0.0023467284441\n",
      "Epoch 19::Minibatch 830::LR 0.0584615384615 --> Loss 0.00428864876429\n",
      "Epoch 19::Minibatch 831::LR 0.0584615384615 --> Loss 0.00252835094929\n",
      "Epoch 19::Minibatch 832::LR 0.0584615384615 --> Loss 0.00221396803856\n",
      "Epoch 19::Minibatch 833::LR 0.0584615384615 --> Loss 0.00183815697829\n",
      "Epoch 19::Minibatch 834::LR 0.0584615384615 --> Loss 0.000774137824774\n",
      "Epoch 19::Minibatch 835::LR 0.0584615384615 --> Loss 0.00377887646357\n",
      "Epoch 19::Minibatch 836::LR 0.0584615384615 --> Loss 0.00367287993431\n",
      "Epoch 19::Minibatch 837::LR 0.0584615384615 --> Loss 0.0021900331974\n",
      "Epoch 19::Minibatch 838::LR 0.0584615384615 --> Loss 0.000630326320728\n",
      "Epoch 19::Minibatch 839::LR 0.0584615384615 --> Loss 0.0024520055453\n",
      "Epoch 19::Minibatch 840::LR 0.0584615384615 --> Loss 0.00288224637508\n",
      "Epoch 19::Minibatch 841::LR 0.0584615384615 --> Loss 0.00280718048414\n",
      "Epoch 19::Minibatch 842::LR 0.0584615384615 --> Loss 0.00207372188568\n",
      "Epoch 19::Minibatch 843::LR 0.0584615384615 --> Loss 0.000999608933926\n",
      "Epoch 19::Minibatch 844::LR 0.0584615384615 --> Loss 0.00148497958978\n",
      "Epoch 19::Minibatch 845::LR 0.0584615384615 --> Loss 0.00426372687022\n",
      "Epoch 19::Minibatch 846::LR 0.0584615384615 --> Loss 0.00167204638322\n",
      "Epoch 19::Minibatch 847::LR 0.0584615384615 --> Loss 0.00228028635184\n",
      "Epoch 19::Minibatch 848::LR 0.0584615384615 --> Loss 0.00102022389571\n",
      "Epoch 19::Minibatch 849::LR 0.0584615384615 --> Loss 0.00182163039843\n",
      "Epoch 19::Minibatch 850::LR 0.0584615384615 --> Loss 0.00316567619642\n",
      "Epoch 19::Minibatch 851::LR 0.0584615384615 --> Loss 0.00262829264005\n",
      "Epoch 19::Minibatch 852::LR 0.0584615384615 --> Loss 0.00108056773742\n",
      "Epoch 19::Minibatch 853::LR 0.0584615384615 --> Loss 0.00130325784286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 854::LR 0.0584615384615 --> Loss 0.00256401439508\n",
      "Epoch 19::Minibatch 855::LR 0.0584615384615 --> Loss 0.00215782344341\n",
      "Epoch 19::Minibatch 856::LR 0.0584615384615 --> Loss 0.00179192960262\n",
      "Epoch 19::Minibatch 857::LR 0.0584615384615 --> Loss 0.00121142576138\n",
      "Epoch 19::Minibatch 858::LR 0.0584615384615 --> Loss 0.000593076497316\n",
      "Epoch 19::Minibatch 859::LR 0.0584615384615 --> Loss 0.00191606879234\n",
      "Epoch 19::Minibatch 860::LR 0.0584615384615 --> Loss 0.00125452836355\n",
      "Epoch 19::Minibatch 861::LR 0.0584615384615 --> Loss 0.000935217042764\n",
      "Epoch 19::Minibatch 862::LR 0.0584615384615 --> Loss 0.00364608605703\n",
      "Epoch 19::Minibatch 863::LR 0.0584615384615 --> Loss 0.00340130964915\n",
      "Epoch 19::Minibatch 864::LR 0.0584615384615 --> Loss 0.00281258404255\n",
      "Epoch 19::Minibatch 865::LR 0.0584615384615 --> Loss 0.000440882444382\n",
      "Epoch 19::Minibatch 866::LR 0.0584615384615 --> Loss 0.00212842563788\n",
      "Epoch 19::Minibatch 867::LR 0.0584615384615 --> Loss 0.0029458963871\n",
      "Epoch 19::Minibatch 868::LR 0.0584615384615 --> Loss 0.00242489159107\n",
      "Epoch 19::Minibatch 869::LR 0.0584615384615 --> Loss 0.00211227973302\n",
      "Epoch 19::Minibatch 870::LR 0.0584615384615 --> Loss 0.00348970015844\n",
      "Epoch 19::Minibatch 871::LR 0.0584615384615 --> Loss 0.00153676529725\n",
      "Epoch 19::Minibatch 872::LR 0.0584615384615 --> Loss 0.00224059780439\n",
      "Epoch 19::Minibatch 873::LR 0.0584615384615 --> Loss 0.00246608873208\n",
      "Epoch 19::Minibatch 874::LR 0.0584615384615 --> Loss 0.00599085887273\n",
      "Epoch 19::Minibatch 875::LR 0.0584615384615 --> Loss 0.000530544469754\n",
      "Epoch 19::Minibatch 876::LR 0.0584615384615 --> Loss 0.00308981895447\n",
      "Epoch 19::Minibatch 877::LR 0.0584615384615 --> Loss 0.0056371319294\n",
      "Epoch 19::Minibatch 878::LR 0.0584615384615 --> Loss 0.00317896624406\n",
      "Epoch 19::Minibatch 879::LR 0.0584615384615 --> Loss 0.00398690342903\n",
      "Epoch 19::Minibatch 880::LR 0.0584615384615 --> Loss 0.00481047074\n",
      "Epoch 19::Minibatch 881::LR 0.0584615384615 --> Loss 0.00427272955577\n",
      "Epoch 19::Minibatch 882::LR 0.0584615384615 --> Loss 0.00195885340373\n",
      "Epoch 19::Minibatch 883::LR 0.0584615384615 --> Loss 0.00344354510307\n",
      "Epoch 19::Minibatch 884::LR 0.0584615384615 --> Loss 0.00271895706654\n",
      "Epoch 19::Minibatch 885::LR 0.0584615384615 --> Loss 0.00254160046577\n",
      "Epoch 19::Minibatch 886::LR 0.0584615384615 --> Loss 0.000488161146641\n",
      "Epoch 19::Minibatch 887::LR 0.0584615384615 --> Loss 0.00527628660202\n",
      "Epoch 19::Minibatch 888::LR 0.0584615384615 --> Loss 0.00259168982506\n",
      "Epoch 19::Minibatch 889::LR 0.0584615384615 --> Loss 0.00276793062687\n",
      "Epoch 19::Minibatch 890::LR 0.0584615384615 --> Loss 0.00408720771472\n",
      "Epoch 19::Minibatch 891::LR 0.0584615384615 --> Loss 0.00183012624582\n",
      "Epoch 19::Minibatch 892::LR 0.0584615384615 --> Loss 0.000846018294493\n",
      "Epoch 19::Minibatch 893::LR 0.0584615384615 --> Loss 0.00240703980128\n",
      "Epoch 19::Minibatch 894::LR 0.0584615384615 --> Loss 0.00212782561779\n",
      "Epoch 19::Minibatch 895::LR 0.0584615384615 --> Loss 0.00237832963467\n",
      "Epoch 19::Minibatch 896::LR 0.0584615384615 --> Loss 0.00125664790471\n",
      "Epoch 19::Minibatch 897::LR 0.0584615384615 --> Loss 0.000703382045031\n",
      "Epoch 19::Minibatch 898::LR 0.0584615384615 --> Loss 0.00211011807124\n",
      "Epoch 19::Minibatch 899::LR 0.0584615384615 --> Loss 0.00247348149618\n",
      "Epoch 19::Minibatch 900::LR 0.0584615384615 --> Loss 0.00319738765558\n",
      "Epoch 19::Minibatch 901::LR 0.0584615384615 --> Loss 0.000590104162693\n",
      "Epoch 19::Minibatch 902::LR 0.0584615384615 --> Loss 0.00141301850478\n",
      "Epoch 19::Minibatch 903::LR 0.0584615384615 --> Loss 0.00255424936612\n",
      "Epoch 19::Minibatch 904::LR 0.0584615384615 --> Loss 0.00190164287885\n",
      "Epoch 19::Minibatch 905::LR 0.0584615384615 --> Loss 0.00142980307341\n",
      "Epoch 19::Minibatch 906::LR 0.0584615384615 --> Loss 0.00106940746307\n",
      "Epoch 19::Minibatch 907::LR 0.0584615384615 --> Loss 0.00158063530922\n",
      "Epoch 19::Minibatch 908::LR 0.0584615384615 --> Loss 0.00216147840023\n",
      "Epoch 19::Minibatch 909::LR 0.0584615384615 --> Loss 0.00198617776235\n",
      "Epoch 19::Minibatch 910::LR 0.0584615384615 --> Loss 0.000833528935909\n",
      "Epoch 19::Minibatch 911::LR 0.0584615384615 --> Loss 0.00123826195796\n",
      "Epoch 19::Minibatch 912::LR 0.0584615384615 --> Loss 0.00199484109879\n",
      "Epoch 19::Minibatch 913::LR 0.0584615384615 --> Loss 0.00217274208864\n",
      "Epoch 19::Minibatch 914::LR 0.0584615384615 --> Loss 0.00117567886909\n",
      "Epoch 19::Minibatch 915::LR 0.0584615384615 --> Loss 0.00049441576004\n",
      "Epoch 19::Minibatch 916::LR 0.0584615384615 --> Loss 0.00222865104675\n",
      "Epoch 19::Minibatch 917::LR 0.0584615384615 --> Loss 0.00366864641507\n",
      "Epoch 19::Minibatch 918::LR 0.0584615384615 --> Loss 0.00563678026199\n",
      "Epoch 19::Minibatch 919::LR 0.0584615384615 --> Loss 0.000562564283609\n",
      "Epoch 19::Minibatch 920::LR 0.0584615384615 --> Loss 0.0119015010198\n",
      "Epoch 19::Minibatch 921::LR 0.0584615384615 --> Loss 0.00280699491501\n",
      "Epoch 19::Minibatch 922::LR 0.0584615384615 --> Loss 0.00295641879241\n",
      "Epoch 19::Minibatch 923::LR 0.0584615384615 --> Loss 0.00142759501934\n",
      "Epoch 19::Minibatch 924::LR 0.0584615384615 --> Loss 0.00341478824615\n",
      "Epoch 19::Minibatch 925::LR 0.0584615384615 --> Loss 0.00232093413671\n",
      "Epoch 19::Minibatch 926::LR 0.0584615384615 --> Loss 0.00519025325775\n",
      "Epoch 19::Minibatch 927::LR 0.0584615384615 --> Loss 0.00716864109039\n",
      "Epoch 19::Minibatch 928::LR 0.0584615384615 --> Loss 0.00632100542386\n",
      "Epoch 19::Minibatch 929::LR 0.0584615384615 --> Loss 0.00643854339918\n",
      "Epoch 19::Minibatch 930::LR 0.0584615384615 --> Loss 0.00933330376943\n",
      "Epoch 19::Minibatch 931::LR 0.0584615384615 --> Loss 0.00339414834976\n",
      "Epoch 19::Minibatch 932::LR 0.0584615384615 --> Loss 0.00662276029587\n",
      "Epoch 19::Minibatch 933::LR 0.0584615384615 --> Loss 0.00325464248657\n",
      "Epoch 19::Minibatch 934::LR 0.0584615384615 --> Loss 0.00428472240766\n",
      "Epoch 19::Minibatch 935::LR 0.0584615384615 --> Loss 0.00606471896172\n",
      "Epoch 19::Minibatch 936::LR 0.0584615384615 --> Loss 0.0013928164045\n",
      "Epoch 19::Minibatch 937::LR 0.0584615384615 --> Loss 0.00314898729324\n",
      "Epoch 19::Minibatch 938::LR 0.0584615384615 --> Loss 0.0028284885486\n",
      "Epoch 19::Minibatch 939::LR 0.0584615384615 --> Loss 0.00291494588057\n",
      "Epoch 19::Minibatch 940::LR 0.0584615384615 --> Loss 0.00100936214129\n",
      "Epoch 19::Minibatch 941::LR 0.0584615384615 --> Loss 0.000828827073177\n",
      "Epoch 19::Minibatch 942::LR 0.0584615384615 --> Loss 0.00245383699735\n",
      "Epoch 19::Minibatch 943::LR 0.0584615384615 --> Loss 0.00278115590413\n",
      "Epoch 19::Minibatch 944::LR 0.0584615384615 --> Loss 0.00200444400311\n",
      "Epoch 19::Minibatch 945::LR 0.0584615384615 --> Loss 0.0011579511563\n",
      "Epoch 19::Minibatch 946::LR 0.0584615384615 --> Loss 0.00296545823415\n",
      "Epoch 19::Minibatch 947::LR 0.0584615384615 --> Loss 0.0026565182209\n",
      "Epoch 19::Minibatch 948::LR 0.0584615384615 --> Loss 0.00496212601662\n",
      "Epoch 19::Minibatch 949::LR 0.0584615384615 --> Loss 0.00184868514538\n",
      "Epoch 19::Minibatch 950::LR 0.0584615384615 --> Loss 0.000733067244291\n",
      "Epoch 19::Minibatch 951::LR 0.0584615384615 --> Loss 0.00339623689651\n",
      "Epoch 19::Minibatch 952::LR 0.0584615384615 --> Loss 0.00241285085678\n",
      "Epoch 19::Minibatch 953::LR 0.0584615384615 --> Loss 0.0013918564717\n",
      "Epoch 19::Minibatch 954::LR 0.0584615384615 --> Loss 0.000960181951523\n",
      "Epoch 19::Minibatch 955::LR 0.0584615384615 --> Loss 0.00253666698933\n",
      "Epoch 19::Minibatch 956::LR 0.0584615384615 --> Loss 0.00363218188286\n",
      "Epoch 19::Minibatch 957::LR 0.0584615384615 --> Loss 0.00187121828397\n",
      "Epoch 19::Minibatch 958::LR 0.0584615384615 --> Loss 0.00226517438889\n",
      "Epoch 19::Minibatch 959::LR 0.0584615384615 --> Loss 0.00278422256311\n",
      "Epoch 19::Minibatch 960::LR 0.0584615384615 --> Loss 0.00616424441338\n",
      "Epoch 19::Minibatch 961::LR 0.0584615384615 --> Loss 0.00326048394044\n",
      "Epoch 19::Minibatch 962::LR 0.0584615384615 --> Loss 0.00278427282969\n",
      "Epoch 19::Minibatch 963::LR 0.0584615384615 --> Loss 0.00103047211965\n",
      "Epoch 19::Minibatch 964::LR 0.0584615384615 --> Loss 0.00237244288127\n",
      "Epoch 19::Minibatch 965::LR 0.0584615384615 --> Loss 0.00721886873245\n",
      "Epoch 19::Minibatch 966::LR 0.0584615384615 --> Loss 0.00512125690778\n",
      "Epoch 19::Minibatch 967::LR 0.0584615384615 --> Loss 0.00148854762316\n",
      "Epoch 19::Minibatch 968::LR 0.0584615384615 --> Loss 0.0013257475694\n",
      "Epoch 19::Minibatch 969::LR 0.0584615384615 --> Loss 0.00607900301615\n",
      "Epoch 19::Minibatch 970::LR 0.0584615384615 --> Loss 0.00553374489148\n",
      "Epoch 19::Minibatch 971::LR 0.0584615384615 --> Loss 0.00347975651423\n",
      "Epoch 19::Minibatch 972::LR 0.0584615384615 --> Loss 0.0096916103363\n",
      "Epoch 19::Minibatch 973::LR 0.0584615384615 --> Loss 0.00901490211487\n",
      "Epoch 19::Minibatch 974::LR 0.0584615384615 --> Loss 0.00824356794357\n",
      "Epoch 19::Minibatch 975::LR 0.0584615384615 --> Loss 0.00462882518768\n",
      "Epoch 19::Minibatch 976::LR 0.0584615384615 --> Loss 0.00417725324631\n",
      "Epoch 19::Minibatch 977::LR 0.0584615384615 --> Loss 0.0041730650266\n",
      "Epoch 19::Minibatch 978::LR 0.0584615384615 --> Loss 0.00417884588242\n",
      "Epoch 19::Minibatch 979::LR 0.0584615384615 --> Loss 0.00412383437157\n",
      "Epoch 19::Minibatch 980::LR 0.0584615384615 --> Loss 0.00407192031542\n",
      "Epoch 19::Minibatch 981::LR 0.0584615384615 --> Loss 0.00533508102099\n",
      "Epoch 19::Minibatch 982::LR 0.0584615384615 --> Loss 0.0065801858902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19::Minibatch 983::LR 0.0584615384615 --> Loss 0.00309078176816\n",
      "Epoch 19::Minibatch 984::LR 0.0584615384615 --> Loss 0.00267937620481\n",
      "Epoch 19::Minibatch 985::LR 0.0584615384615 --> Loss 0.00446452140808\n",
      "Epoch 19::Minibatch 986::LR 0.0584615384615 --> Loss 0.00412820299466\n",
      "Epoch 19::Minibatch 987::LR 0.0584615384615 --> Loss 0.00441289305687\n",
      "Epoch 19::Minibatch 988::LR 0.0584615384615 --> Loss 0.00350595196088\n",
      "Epoch 19::Minibatch 989::LR 0.0584615384615 --> Loss 0.00362031380335\n",
      "Epoch 19::Minibatch 990::LR 0.0584615384615 --> Loss 0.0032525942723\n",
      "Epoch 19::Minibatch 991::LR 0.0584615384615 --> Loss 0.00187662382921\n",
      "Epoch 19::Minibatch 992::LR 0.0584615384615 --> Loss 0.00203180015087\n",
      "Epoch 19::Minibatch 993::LR 0.0584615384615 --> Loss 0.00357643405596\n",
      "Epoch 19::Minibatch 994::LR 0.0584615384615 --> Loss 0.00223646362623\n",
      "Epoch 19::Minibatch 995::LR 0.0584615384615 --> Loss 0.00093808790048\n",
      "Epoch 19::Minibatch 996::LR 0.0584615384615 --> Loss 0.00313800215721\n",
      "Epoch 19::Minibatch 997::LR 0.0584615384615 --> Loss 0.00237144589424\n",
      "Epoch 19::Minibatch 998::LR 0.0584615384615 --> Loss 0.00263219952583\n",
      "Epoch 19::Minibatch 999::LR 0.0584615384615 --> Loss 0.00216837803523\n",
      "Epoch 19::Minibatch 1000::LR 0.0584615384615 --> Loss 0.00255817035834\n",
      "Epoch 19::Minibatch 1001::LR 0.0584615384615 --> Loss 0.00208845297496\n",
      "Epoch 19::Minibatch 1002::LR 0.0584615384615 --> Loss 0.00234238465627\n",
      "Epoch 19::Minibatch 1003::LR 0.0584615384615 --> Loss 0.00339610695839\n",
      "Epoch 19::Minibatch 1004::LR 0.0584615384615 --> Loss 0.00112484822671\n",
      "Epoch 19::Minibatch 1005::LR 0.0584615384615 --> Loss 0.00349625865618\n",
      "Epoch 19::Minibatch 1006::LR 0.0584615384615 --> Loss 0.00206768413385\n",
      "Epoch 19::Minibatch 1007::LR 0.0584615384615 --> Loss 0.00246964693069\n",
      "Epoch 19::Minibatch 1008::LR 0.0584615384615 --> Loss 0.00101797878742\n",
      "Epoch 19::Minibatch 1009::LR 0.0584615384615 --> Loss 0.00149534285069\n",
      "Epoch 19::Minibatch 1010::LR 0.0584615384615 --> Loss 0.00131405641635\n",
      "Epoch 19::Minibatch 1011::LR 0.0584615384615 --> Loss 0.00229845921199\n",
      "Epoch 19::Minibatch 1012::LR 0.0584615384615 --> Loss 0.00162980675697\n",
      "Epoch 19::Minibatch 1013::LR 0.0584615384615 --> Loss 0.00422025521596\n",
      "Epoch 19::Minibatch 1014::LR 0.0584615384615 --> Loss 0.0039926302433\n",
      "Epoch 19::Minibatch 1015::LR 0.0584615384615 --> Loss 0.00171232620875\n",
      "Epoch 19::Minibatch 1016::LR 0.0584615384615 --> Loss 0.0049204480648\n",
      "Epoch 19::Minibatch 1017::LR 0.0584615384615 --> Loss 0.00269588271777\n",
      "Epoch 19::Minibatch 1018::LR 0.0584615384615 --> Loss 0.0028781781594\n",
      "Epoch 19::Minibatch 1019::LR 0.0584615384615 --> Loss 0.00193132340908\n",
      "Epoch 19::Minibatch 1020::LR 0.0584615384615 --> Loss 0.00195517917474\n",
      "Epoch 19::Minibatch 1021::LR 0.0584615384615 --> Loss 0.00198844512304\n",
      "Epoch 19::Minibatch 1022::LR 0.0584615384615 --> Loss 0.00149675786495\n",
      "Epoch 19::Minibatch 1023::LR 0.0584615384615 --> Loss 0.00114770849546\n",
      "Epoch 19::Minibatch 1024::LR 0.0584615384615 --> Loss 0.00112764120102\n",
      "Epoch 19::Minibatch 1025::LR 0.0584615384615 --> Loss 0.00140660901864\n",
      "Epoch 19::Minibatch 1026::LR 0.0584615384615 --> Loss 0.000801150649786\n",
      "Epoch 19::Minibatch 1027::LR 0.0584615384615 --> Loss 0.00102700928847\n",
      "Epoch 19::Minibatch 1028::LR 0.0584615384615 --> Loss 0.000787236044804\n",
      "Epoch 19::Minibatch 1029::LR 0.0584615384615 --> Loss 0.00077327499787\n",
      "Epoch 19::Minibatch 1030::LR 0.0584615384615 --> Loss 0.000953421791395\n",
      "Epoch 19::Minibatch 1031::LR 0.0584615384615 --> Loss 0.000741976598899\n",
      "Epoch 19::Minibatch 1032::LR 0.0584615384615 --> Loss 0.000780377984047\n",
      "Epoch 19::Minibatch 1033::LR 0.0584615384615 --> Loss 0.000664042681456\n",
      "Epoch 19::Minibatch 1034::LR 0.0584615384615 --> Loss 0.000640288045009\n",
      "Epoch 19::Minibatch 1035::LR 0.0584615384615 --> Loss 0.000445180535316\n",
      "Epoch 19::Minibatch 1036::LR 0.0584615384615 --> Loss 0.000355870525042\n",
      "Epoch 19::Minibatch 1037::LR 0.0584615384615 --> Loss 0.000581249644359\n",
      "Epoch 19::Minibatch 1038::LR 0.0584615384615 --> Loss 0.00126152346532\n",
      "Epoch 19::Minibatch 1039::LR 0.0584615384615 --> Loss 0.000964830815792\n",
      "Epoch 19::Minibatch 1040::LR 0.0584615384615 --> Loss 0.00040008969605\n",
      "Epoch 19::Minibatch 1041::LR 0.0584615384615 --> Loss 0.000568410058816\n",
      "Epoch 20::Minibatch 1::LR 0.0561538461538 --> Loss 0.00904821713765\n",
      "Epoch 20::Minibatch 2::LR 0.0561538461538 --> Loss 0.00584187308947\n",
      "Epoch 20::Minibatch 3::LR 0.0561538461538 --> Loss 0.00378283301989\n",
      "Epoch 20::Minibatch 4::LR 0.0561538461538 --> Loss 0.00426887075106\n",
      "Epoch 20::Minibatch 5::LR 0.0561538461538 --> Loss 0.00467287540436\n",
      "Epoch 20::Minibatch 6::LR 0.0561538461538 --> Loss 0.00233797609806\n",
      "Epoch 20::Minibatch 7::LR 0.0561538461538 --> Loss 0.0076895459493\n",
      "Epoch 20::Minibatch 8::LR 0.0561538461538 --> Loss 0.00733854532242\n",
      "Epoch 20::Minibatch 9::LR 0.0561538461538 --> Loss 0.00544256766637\n",
      "Epoch 20::Minibatch 10::LR 0.0561538461538 --> Loss 0.00271338800589\n",
      "Epoch 20::Minibatch 11::LR 0.0561538461538 --> Loss 0.00240553041299\n",
      "Epoch 20::Minibatch 12::LR 0.0561538461538 --> Loss 0.00352874318759\n",
      "Epoch 20::Minibatch 13::LR 0.0561538461538 --> Loss 0.00537051598231\n",
      "Epoch 20::Minibatch 14::LR 0.0561538461538 --> Loss 0.00529487729073\n",
      "Epoch 20::Minibatch 15::LR 0.0561538461538 --> Loss 0.00445171753565\n",
      "Epoch 20::Minibatch 16::LR 0.0561538461538 --> Loss 0.000845942298571\n",
      "Epoch 20::Minibatch 17::LR 0.0561538461538 --> Loss 0.00315685530504\n",
      "Epoch 20::Minibatch 18::LR 0.0561538461538 --> Loss 0.00255380054315\n",
      "Epoch 20::Minibatch 19::LR 0.0561538461538 --> Loss 0.00135175466537\n",
      "Epoch 20::Minibatch 20::LR 0.0561538461538 --> Loss 0.00184972484907\n",
      "Epoch 20::Minibatch 21::LR 0.0561538461538 --> Loss 0.00329096059004\n",
      "Epoch 20::Minibatch 22::LR 0.0561538461538 --> Loss 0.00227068543434\n",
      "Epoch 20::Minibatch 23::LR 0.0561538461538 --> Loss 0.000807731002569\n",
      "Epoch 20::Minibatch 24::LR 0.0561538461538 --> Loss 0.000394026016196\n",
      "Epoch 20::Minibatch 25::LR 0.0561538461538 --> Loss 0.0011555325985\n",
      "Epoch 20::Minibatch 26::LR 0.0561538461538 --> Loss 0.00135502457619\n",
      "Epoch 20::Minibatch 27::LR 0.0561538461538 --> Loss 0.00095636198918\n",
      "Epoch 20::Minibatch 28::LR 0.0561538461538 --> Loss 0.000404129326344\n",
      "Epoch 20::Minibatch 29::LR 0.0561538461538 --> Loss 0.000413654968143\n",
      "Epoch 20::Minibatch 30::LR 0.0561538461538 --> Loss 0.000890944500764\n",
      "Epoch 20::Minibatch 31::LR 0.0561538461538 --> Loss 0.00137707610925\n",
      "Epoch 20::Minibatch 32::LR 0.0561538461538 --> Loss 0.00128391762575\n",
      "Epoch 20::Minibatch 33::LR 0.0561538461538 --> Loss 0.000777126749357\n",
      "Epoch 20::Minibatch 34::LR 0.0561538461538 --> Loss 0.00228337585926\n",
      "Epoch 20::Minibatch 35::LR 0.0561538461538 --> Loss 0.00371951738993\n",
      "Epoch 20::Minibatch 36::LR 0.0561538461538 --> Loss 0.00222511152426\n",
      "Epoch 20::Minibatch 37::LR 0.0561538461538 --> Loss 0.000637508829435\n",
      "Epoch 20::Minibatch 38::LR 0.0561538461538 --> Loss 0.000723593384027\n",
      "Epoch 20::Minibatch 39::LR 0.0561538461538 --> Loss 0.00233718693256\n",
      "Epoch 20::Minibatch 40::LR 0.0561538461538 --> Loss 0.0033452864488\n",
      "Epoch 20::Minibatch 41::LR 0.0561538461538 --> Loss 0.00272617777189\n",
      "Epoch 20::Minibatch 42::LR 0.0561538461538 --> Loss 0.00572474241257\n",
      "Epoch 20::Minibatch 43::LR 0.0561538461538 --> Loss 0.00187704364459\n",
      "Epoch 20::Minibatch 44::LR 0.0561538461538 --> Loss 0.00310461799304\n",
      "Epoch 20::Minibatch 45::LR 0.0561538461538 --> Loss 0.00244084457556\n",
      "Epoch 20::Minibatch 46::LR 0.0561538461538 --> Loss 0.00333153227965\n",
      "Epoch 20::Minibatch 47::LR 0.0561538461538 --> Loss 0.00417005379995\n",
      "Epoch 20::Minibatch 48::LR 0.0561538461538 --> Loss 0.00569751262665\n",
      "Epoch 20::Minibatch 49::LR 0.0561538461538 --> Loss 0.00607504049937\n",
      "Epoch 20::Minibatch 50::LR 0.0561538461538 --> Loss 0.00610013723373\n",
      "Epoch 20::Minibatch 51::LR 0.0561538461538 --> Loss 0.00630747993787\n",
      "Epoch 20::Minibatch 52::LR 0.0561538461538 --> Loss 0.00345527966817\n",
      "Epoch 20::Minibatch 53::LR 0.0561538461538 --> Loss 0.00339659651121\n",
      "Epoch 20::Minibatch 54::LR 0.0561538461538 --> Loss 0.00401264627775\n",
      "Epoch 20::Minibatch 55::LR 0.0561538461538 --> Loss 0.00098314166069\n",
      "Epoch 20::Minibatch 56::LR 0.0561538461538 --> Loss 0.00268749117851\n",
      "Epoch 20::Minibatch 57::LR 0.0561538461538 --> Loss 0.00534577965736\n",
      "Epoch 20::Minibatch 58::LR 0.0561538461538 --> Loss 0.00330860038598\n",
      "Epoch 20::Minibatch 59::LR 0.0561538461538 --> Loss 0.00244971990585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 60::LR 0.0561538461538 --> Loss 0.00238256255786\n",
      "Epoch 20::Minibatch 61::LR 0.0561538461538 --> Loss 0.000832126984994\n",
      "Epoch 20::Minibatch 62::LR 0.0561538461538 --> Loss 0.00300303498904\n",
      "Epoch 20::Minibatch 63::LR 0.0561538461538 --> Loss 0.00206860582034\n",
      "Epoch 20::Minibatch 64::LR 0.0561538461538 --> Loss 0.000880809525649\n",
      "Epoch 20::Minibatch 65::LR 0.0561538461538 --> Loss 0.00230238099893\n",
      "Epoch 20::Minibatch 66::LR 0.0561538461538 --> Loss 0.00277876814206\n",
      "Epoch 20::Minibatch 67::LR 0.0561538461538 --> Loss 0.00272205551465\n",
      "Epoch 20::Minibatch 68::LR 0.0561538461538 --> Loss 0.00194140732288\n",
      "Epoch 20::Minibatch 69::LR 0.0561538461538 --> Loss 0.00391022483508\n",
      "Epoch 20::Minibatch 70::LR 0.0561538461538 --> Loss 0.00341110865275\n",
      "Epoch 20::Minibatch 71::LR 0.0561538461538 --> Loss 0.00230901539326\n",
      "Epoch 20::Minibatch 72::LR 0.0561538461538 --> Loss 0.000537110865116\n",
      "Epoch 20::Minibatch 73::LR 0.0561538461538 --> Loss 0.00387852509816\n",
      "Epoch 20::Minibatch 74::LR 0.0561538461538 --> Loss 0.00411524097125\n",
      "Epoch 20::Minibatch 75::LR 0.0561538461538 --> Loss 0.00235851109028\n",
      "Epoch 20::Minibatch 76::LR 0.0561538461538 --> Loss 0.000568413436413\n",
      "Epoch 20::Minibatch 77::LR 0.0561538461538 --> Loss 0.00375118136406\n",
      "Epoch 20::Minibatch 78::LR 0.0561538461538 --> Loss 0.00384902914365\n",
      "Epoch 20::Minibatch 79::LR 0.0561538461538 --> Loss 0.00192105750243\n",
      "Epoch 20::Minibatch 80::LR 0.0561538461538 --> Loss 0.00316449443499\n",
      "Epoch 20::Minibatch 81::LR 0.0561538461538 --> Loss 0.00274263819059\n",
      "Epoch 20::Minibatch 82::LR 0.0561538461538 --> Loss 0.00197519520919\n",
      "Epoch 20::Minibatch 83::LR 0.0561538461538 --> Loss 0.00445797721545\n",
      "Epoch 20::Minibatch 84::LR 0.0561538461538 --> Loss 0.00197117010752\n",
      "Epoch 20::Minibatch 85::LR 0.0561538461538 --> Loss 0.00272336085637\n",
      "Epoch 20::Minibatch 86::LR 0.0561538461538 --> Loss 0.00219911615054\n",
      "Epoch 20::Minibatch 87::LR 0.0561538461538 --> Loss 0.00241766075293\n",
      "Epoch 20::Minibatch 88::LR 0.0561538461538 --> Loss 0.00176548043887\n",
      "Epoch 20::Minibatch 89::LR 0.0561538461538 --> Loss 0.00230305453142\n",
      "Epoch 20::Minibatch 90::LR 0.0561538461538 --> Loss 0.0011003224055\n",
      "Epoch 20::Minibatch 91::LR 0.0561538461538 --> Loss 0.000884690185388\n",
      "Epoch 20::Minibatch 92::LR 0.0561538461538 --> Loss 0.0026750767231\n",
      "Epoch 20::Minibatch 93::LR 0.0561538461538 --> Loss 0.00174794316292\n",
      "Epoch 20::Minibatch 94::LR 0.0561538461538 --> Loss 0.00176054596901\n",
      "Epoch 20::Minibatch 95::LR 0.0561538461538 --> Loss 0.00182425141335\n",
      "Epoch 20::Minibatch 96::LR 0.0561538461538 --> Loss 0.00559931437174\n",
      "Epoch 20::Minibatch 97::LR 0.0561538461538 --> Loss 0.00313249051571\n",
      "Epoch 20::Minibatch 98::LR 0.0561538461538 --> Loss 0.000998604695002\n",
      "Epoch 20::Minibatch 99::LR 0.0561538461538 --> Loss 0.00132413655519\n",
      "Epoch 20::Minibatch 100::LR 0.0561538461538 --> Loss 0.00496166825294\n",
      "Epoch 20::Minibatch 101::LR 0.0561538461538 --> Loss 0.000921185413996\n",
      "Epoch 20::Minibatch 102::LR 0.0561538461538 --> Loss 0.00387461543083\n",
      "Epoch 20::Minibatch 103::LR 0.0561538461538 --> Loss 0.00400418361028\n",
      "Epoch 20::Minibatch 104::LR 0.0561538461538 --> Loss 0.0027446715037\n",
      "Epoch 20::Minibatch 105::LR 0.0561538461538 --> Loss 0.00259615679582\n",
      "Epoch 20::Minibatch 106::LR 0.0561538461538 --> Loss 0.0169082514445\n",
      "Epoch 20::Minibatch 107::LR 0.0561538461538 --> Loss 0.00486554781596\n",
      "Epoch 20::Minibatch 108::LR 0.0561538461538 --> Loss 0.0010276996096\n",
      "Epoch 20::Minibatch 109::LR 0.0561538461538 --> Loss 0.00435301462809\n",
      "Epoch 20::Minibatch 110::LR 0.0561538461538 --> Loss 0.00235676427682\n",
      "Epoch 20::Minibatch 111::LR 0.0561538461538 --> Loss 0.000934776763121\n",
      "Epoch 20::Minibatch 112::LR 0.0561538461538 --> Loss 0.00350185195605\n",
      "Epoch 20::Minibatch 113::LR 0.0561538461538 --> Loss 0.00260721325874\n",
      "Epoch 20::Minibatch 114::LR 0.0561538461538 --> Loss 0.0014421637853\n",
      "Epoch 20::Minibatch 115::LR 0.0561538461538 --> Loss 0.00129368851582\n",
      "Epoch 20::Minibatch 116::LR 0.0561538461538 --> Loss 0.00275441090266\n",
      "Epoch 20::Minibatch 117::LR 0.0561538461538 --> Loss 0.00384679635366\n",
      "Epoch 20::Minibatch 118::LR 0.0561538461538 --> Loss 0.00685557365417\n",
      "Epoch 20::Minibatch 119::LR 0.0561538461538 --> Loss 0.000616800536712\n",
      "Epoch 20::Minibatch 120::LR 0.0561538461538 --> Loss 0.00174327154954\n",
      "Epoch 20::Minibatch 121::LR 0.0561538461538 --> Loss 0.00260316948096\n",
      "Epoch 20::Minibatch 122::LR 0.0561538461538 --> Loss 0.00372535824776\n",
      "Epoch 20::Minibatch 123::LR 0.0561538461538 --> Loss 0.000960812270641\n",
      "Epoch 20::Minibatch 124::LR 0.0561538461538 --> Loss 0.00273609141509\n",
      "Epoch 20::Minibatch 125::LR 0.0561538461538 --> Loss 0.00459290663401\n",
      "Epoch 20::Minibatch 126::LR 0.0561538461538 --> Loss 0.002672372063\n",
      "Epoch 20::Minibatch 127::LR 0.0561538461538 --> Loss 0.00444104274114\n",
      "Epoch 20::Minibatch 128::LR 0.0561538461538 --> Loss 0.00360727548599\n",
      "Epoch 20::Minibatch 129::LR 0.0561538461538 --> Loss 0.00265757997831\n",
      "Epoch 20::Minibatch 130::LR 0.0561538461538 --> Loss 0.00436119914055\n",
      "Epoch 20::Minibatch 131::LR 0.0561538461538 --> Loss 0.00178120752176\n",
      "Epoch 20::Minibatch 132::LR 0.0561538461538 --> Loss 0.00304504235586\n",
      "Epoch 20::Minibatch 133::LR 0.0561538461538 --> Loss 0.00290026207765\n",
      "Epoch 20::Minibatch 134::LR 0.0561538461538 --> Loss 0.00232871850332\n",
      "Epoch 20::Minibatch 135::LR 0.0561538461538 --> Loss 0.0015246134003\n",
      "Epoch 20::Minibatch 136::LR 0.0561538461538 --> Loss 0.00267179906368\n",
      "Epoch 20::Minibatch 137::LR 0.0561538461538 --> Loss 0.00364271680514\n",
      "Epoch 20::Minibatch 138::LR 0.0561538461538 --> Loss 0.00129317651192\n",
      "Epoch 20::Minibatch 139::LR 0.0561538461538 --> Loss 0.00191325207551\n",
      "Epoch 20::Minibatch 140::LR 0.0561538461538 --> Loss 0.00245555977027\n",
      "Epoch 20::Minibatch 141::LR 0.0561538461538 --> Loss 0.00296964426835\n",
      "Epoch 20::Minibatch 142::LR 0.0561538461538 --> Loss 0.0028433684508\n",
      "Epoch 20::Minibatch 143::LR 0.0561538461538 --> Loss 0.000594466527303\n",
      "Epoch 20::Minibatch 144::LR 0.0561538461538 --> Loss 0.00325672109922\n",
      "Epoch 20::Minibatch 145::LR 0.0561538461538 --> Loss 0.00428897619247\n",
      "Epoch 20::Minibatch 146::LR 0.0561538461538 --> Loss 0.00256781895955\n",
      "Epoch 20::Minibatch 147::LR 0.0561538461538 --> Loss 0.00181298951308\n",
      "Epoch 20::Minibatch 148::LR 0.0561538461538 --> Loss 0.00100701630116\n",
      "Epoch 20::Minibatch 149::LR 0.0561538461538 --> Loss 0.00283864537875\n",
      "Epoch 20::Minibatch 150::LR 0.0561538461538 --> Loss 0.0027109926939\n",
      "Epoch 20::Minibatch 151::LR 0.0561538461538 --> Loss 0.00424954295158\n",
      "Epoch 20::Minibatch 152::LR 0.0561538461538 --> Loss 0.000918300350507\n",
      "Epoch 20::Minibatch 153::LR 0.0561538461538 --> Loss 0.00178936521212\n",
      "Epoch 20::Minibatch 154::LR 0.0561538461538 --> Loss 0.00204933861891\n",
      "Epoch 20::Minibatch 155::LR 0.0561538461538 --> Loss 0.00442348957062\n",
      "Epoch 20::Minibatch 156::LR 0.0561538461538 --> Loss 0.00239046573639\n",
      "Epoch 20::Minibatch 157::LR 0.0561538461538 --> Loss 0.000697516401609\n",
      "Epoch 20::Minibatch 158::LR 0.0561538461538 --> Loss 0.00307158331076\n",
      "Epoch 20::Minibatch 159::LR 0.0561538461538 --> Loss 0.00275104085604\n",
      "Epoch 20::Minibatch 160::LR 0.0561538461538 --> Loss 0.00263323366642\n",
      "Epoch 20::Minibatch 161::LR 0.0561538461538 --> Loss 0.00101871003707\n",
      "Epoch 20::Minibatch 162::LR 0.0561538461538 --> Loss 0.00378591299057\n",
      "Epoch 20::Minibatch 163::LR 0.0561538461538 --> Loss 0.00239872674147\n",
      "Epoch 20::Minibatch 164::LR 0.0561538461538 --> Loss 0.00250003814697\n",
      "Epoch 20::Minibatch 165::LR 0.0561538461538 --> Loss 0.00052350372076\n",
      "Epoch 20::Minibatch 166::LR 0.0561538461538 --> Loss 0.00177579025428\n",
      "Epoch 20::Minibatch 167::LR 0.0561538461538 --> Loss 0.0024586268266\n",
      "Epoch 20::Minibatch 168::LR 0.0561538461538 --> Loss 0.00217757324378\n",
      "Epoch 20::Minibatch 169::LR 0.0561538461538 --> Loss 0.00101001193126\n",
      "Epoch 20::Minibatch 170::LR 0.0561538461538 --> Loss 0.00098483423392\n",
      "Epoch 20::Minibatch 171::LR 0.0561538461538 --> Loss 0.00250776867072\n",
      "Epoch 20::Minibatch 172::LR 0.0561538461538 --> Loss 0.00442358295123\n",
      "Epoch 20::Minibatch 173::LR 0.0561538461538 --> Loss 0.00195268412431\n",
      "Epoch 20::Minibatch 174::LR 0.0561538461538 --> Loss 0.00103104293346\n",
      "Epoch 20::Minibatch 175::LR 0.0561538461538 --> Loss 0.00231086631616\n",
      "Epoch 20::Minibatch 176::LR 0.0561538461538 --> Loss 0.00326113820076\n",
      "Epoch 20::Minibatch 177::LR 0.0561538461538 --> Loss 0.004517335097\n",
      "Epoch 20::Minibatch 178::LR 0.0561538461538 --> Loss 0.00161765376727\n",
      "Epoch 20::Minibatch 179::LR 0.0561538461538 --> Loss 0.00134525467952\n",
      "Epoch 20::Minibatch 180::LR 0.0561538461538 --> Loss 0.00359216968218\n",
      "Epoch 20::Minibatch 181::LR 0.0561538461538 --> Loss 0.0032302125295\n",
      "Epoch 20::Minibatch 182::LR 0.0561538461538 --> Loss 0.000767017304897\n",
      "Epoch 20::Minibatch 183::LR 0.0561538461538 --> Loss 0.00167251487573\n",
      "Epoch 20::Minibatch 184::LR 0.0561538461538 --> Loss 0.00343065182368\n",
      "Epoch 20::Minibatch 185::LR 0.0561538461538 --> Loss 0.00282588084539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 186::LR 0.0561538461538 --> Loss 0.000968515078227\n",
      "Epoch 20::Minibatch 187::LR 0.0561538461538 --> Loss 0.00126843462388\n",
      "Epoch 20::Minibatch 188::LR 0.0561538461538 --> Loss 0.00418312748273\n",
      "Epoch 20::Minibatch 189::LR 0.0561538461538 --> Loss 0.00440270026525\n",
      "Epoch 20::Minibatch 190::LR 0.0561538461538 --> Loss 0.00232325494289\n",
      "Epoch 20::Minibatch 191::LR 0.0561538461538 --> Loss 0.00047497322162\n",
      "Epoch 20::Minibatch 192::LR 0.0561538461538 --> Loss 0.00272491037846\n",
      "Epoch 20::Minibatch 193::LR 0.0561538461538 --> Loss 0.00258470972379\n",
      "Epoch 20::Minibatch 194::LR 0.0561538461538 --> Loss 0.00177736957868\n",
      "Epoch 20::Minibatch 195::LR 0.0561538461538 --> Loss 0.000385624567668\n",
      "Epoch 20::Minibatch 196::LR 0.0561538461538 --> Loss 0.00125162790219\n",
      "Epoch 20::Minibatch 197::LR 0.0561538461538 --> Loss 0.00288367331028\n",
      "Epoch 20::Minibatch 198::LR 0.0561538461538 --> Loss 0.0022224676609\n",
      "Epoch 20::Minibatch 199::LR 0.0561538461538 --> Loss 0.000288746257623\n",
      "Epoch 20::Minibatch 200::LR 0.0561538461538 --> Loss 0.00205633640289\n",
      "Epoch 20::Minibatch 201::LR 0.0561538461538 --> Loss 0.00195168236891\n",
      "Epoch 20::Minibatch 202::LR 0.0561538461538 --> Loss 0.00186000784238\n",
      "Epoch 20::Minibatch 203::LR 0.0561538461538 --> Loss 0.001767329971\n",
      "Epoch 20::Minibatch 204::LR 0.0561538461538 --> Loss 0.00145097583532\n",
      "Epoch 20::Minibatch 205::LR 0.0561538461538 --> Loss 0.00220582286517\n",
      "Epoch 20::Minibatch 206::LR 0.0561538461538 --> Loss 0.00630806485812\n",
      "Epoch 20::Minibatch 207::LR 0.0561538461538 --> Loss 0.00139565040668\n",
      "Epoch 20::Minibatch 208::LR 0.0561538461538 --> Loss 0.00112371037404\n",
      "Epoch 20::Minibatch 209::LR 0.0561538461538 --> Loss 0.00224255164464\n",
      "Epoch 20::Minibatch 210::LR 0.0561538461538 --> Loss 0.00214333454768\n",
      "Epoch 20::Minibatch 211::LR 0.0561538461538 --> Loss 0.00232746700446\n",
      "Epoch 20::Minibatch 212::LR 0.0561538461538 --> Loss 0.0039555422465\n",
      "Epoch 20::Minibatch 213::LR 0.0561538461538 --> Loss 0.00580748399099\n",
      "Epoch 20::Minibatch 214::LR 0.0561538461538 --> Loss 0.00889997243881\n",
      "Epoch 20::Minibatch 215::LR 0.0561538461538 --> Loss 0.00138597389062\n",
      "Epoch 20::Minibatch 216::LR 0.0561538461538 --> Loss 0.00548686345418\n",
      "Epoch 20::Minibatch 217::LR 0.0561538461538 --> Loss 0.00613889376322\n",
      "Epoch 20::Minibatch 218::LR 0.0561538461538 --> Loss 0.00393515626589\n",
      "Epoch 20::Minibatch 219::LR 0.0561538461538 --> Loss 0.00416151563327\n",
      "Epoch 20::Minibatch 220::LR 0.0561538461538 --> Loss 0.00449975689252\n",
      "Epoch 20::Minibatch 221::LR 0.0561538461538 --> Loss 0.00425951798757\n",
      "Epoch 20::Minibatch 222::LR 0.0561538461538 --> Loss 0.00324256996314\n",
      "Epoch 20::Minibatch 223::LR 0.0561538461538 --> Loss 0.00141289512316\n",
      "Epoch 20::Minibatch 224::LR 0.0561538461538 --> Loss 0.00173474748929\n",
      "Epoch 20::Minibatch 225::LR 0.0561538461538 --> Loss 0.00735509077708\n",
      "Epoch 20::Minibatch 226::LR 0.0561538461538 --> Loss 0.00377518773079\n",
      "Epoch 20::Minibatch 227::LR 0.0561538461538 --> Loss 0.00169272124767\n",
      "Epoch 20::Minibatch 228::LR 0.0561538461538 --> Loss 0.000728164613247\n",
      "Epoch 20::Minibatch 229::LR 0.0561538461538 --> Loss 0.00476403991381\n",
      "Epoch 20::Minibatch 230::LR 0.0561538461538 --> Loss 0.00390510439873\n",
      "Epoch 20::Minibatch 231::LR 0.0561538461538 --> Loss 0.00264252364635\n",
      "Epoch 20::Minibatch 232::LR 0.0561538461538 --> Loss 0.00120998948812\n",
      "Epoch 20::Minibatch 233::LR 0.0561538461538 --> Loss 0.00243167519569\n",
      "Epoch 20::Minibatch 234::LR 0.0561538461538 --> Loss 0.00698630889257\n",
      "Epoch 20::Minibatch 235::LR 0.0561538461538 --> Loss 0.00470150272051\n",
      "Epoch 20::Minibatch 236::LR 0.0561538461538 --> Loss 0.00175392568111\n",
      "Epoch 20::Minibatch 237::LR 0.0561538461538 --> Loss 0.000669249842564\n",
      "Epoch 20::Minibatch 238::LR 0.0561538461538 --> Loss 0.00341594060262\n",
      "Epoch 20::Minibatch 239::LR 0.0561538461538 --> Loss 0.00296201944351\n",
      "Epoch 20::Minibatch 240::LR 0.0561538461538 --> Loss 0.00324610352516\n",
      "Epoch 20::Minibatch 241::LR 0.0561538461538 --> Loss 0.000761366039515\n",
      "Epoch 20::Minibatch 242::LR 0.0561538461538 --> Loss 0.00700370709101\n",
      "Epoch 20::Minibatch 243::LR 0.0561538461538 --> Loss 0.00348900477091\n",
      "Epoch 20::Minibatch 244::LR 0.0561538461538 --> Loss 0.00291689376036\n",
      "Epoch 20::Minibatch 245::LR 0.0561538461538 --> Loss 0.000468290150166\n",
      "Epoch 20::Minibatch 246::LR 0.0561538461538 --> Loss 0.00204106370608\n",
      "Epoch 20::Minibatch 247::LR 0.0561538461538 --> Loss 0.0126167734464\n",
      "Epoch 20::Minibatch 248::LR 0.0561538461538 --> Loss 0.00446687976519\n",
      "Epoch 20::Minibatch 249::LR 0.0561538461538 --> Loss 0.00266634821892\n",
      "Epoch 20::Minibatch 250::LR 0.0561538461538 --> Loss 0.00255432009697\n",
      "Epoch 20::Minibatch 251::LR 0.0561538461538 --> Loss 0.00249848783016\n",
      "Epoch 20::Minibatch 252::LR 0.0561538461538 --> Loss 0.00176523605982\n",
      "Epoch 20::Minibatch 253::LR 0.0561538461538 --> Loss 0.00305455883344\n",
      "Epoch 20::Minibatch 254::LR 0.0561538461538 --> Loss 0.005093892018\n",
      "Epoch 20::Minibatch 255::LR 0.0561538461538 --> Loss 0.00388335307439\n",
      "Epoch 20::Minibatch 256::LR 0.0561538461538 --> Loss 0.00160398870707\n",
      "Epoch 20::Minibatch 257::LR 0.0561538461538 --> Loss 0.0012185878555\n",
      "Epoch 20::Minibatch 258::LR 0.0561538461538 --> Loss 0.0036351788044\n",
      "Epoch 20::Minibatch 259::LR 0.0561538461538 --> Loss 0.00176244298617\n",
      "Epoch 20::Minibatch 260::LR 0.0561538461538 --> Loss 0.00188736041387\n",
      "Epoch 20::Minibatch 261::LR 0.0561538461538 --> Loss 0.00285591741403\n",
      "Epoch 20::Minibatch 262::LR 0.0561538461538 --> Loss 0.00191544453303\n",
      "Epoch 20::Minibatch 263::LR 0.0561538461538 --> Loss 0.0023602159818\n",
      "Epoch 20::Minibatch 264::LR 0.0561538461538 --> Loss 0.00363388061523\n",
      "Epoch 20::Minibatch 265::LR 0.0561538461538 --> Loss 0.0101241485278\n",
      "Epoch 20::Minibatch 266::LR 0.0561538461538 --> Loss 0.000996011694272\n",
      "Epoch 20::Minibatch 267::LR 0.0561538461538 --> Loss 0.00986800273259\n",
      "Epoch 20::Minibatch 268::LR 0.0561538461538 --> Loss 0.0011644718051\n",
      "Epoch 20::Minibatch 269::LR 0.0561538461538 --> Loss 0.00349762121836\n",
      "Epoch 20::Minibatch 270::LR 0.0561538461538 --> Loss 0.00675177494685\n",
      "Epoch 20::Minibatch 271::LR 0.0561538461538 --> Loss 0.00266806880633\n",
      "Epoch 20::Minibatch 272::LR 0.0561538461538 --> Loss 0.00415416399638\n",
      "Epoch 20::Minibatch 273::LR 0.0561538461538 --> Loss 0.00162437826395\n",
      "Epoch 20::Minibatch 274::LR 0.0561538461538 --> Loss 0.00179437279701\n",
      "Epoch 20::Minibatch 275::LR 0.0561538461538 --> Loss 0.00262711485227\n",
      "Epoch 20::Minibatch 276::LR 0.0561538461538 --> Loss 0.00345363060633\n",
      "Epoch 20::Minibatch 277::LR 0.0561538461538 --> Loss 0.000978709260623\n",
      "Epoch 20::Minibatch 278::LR 0.0561538461538 --> Loss 0.00262439409892\n",
      "Epoch 20::Minibatch 279::LR 0.0561538461538 --> Loss 0.00231224576632\n",
      "Epoch 20::Minibatch 280::LR 0.0561538461538 --> Loss 0.00201836049557\n",
      "Epoch 20::Minibatch 281::LR 0.0561538461538 --> Loss 0.00126993745565\n",
      "Epoch 20::Minibatch 282::LR 0.0561538461538 --> Loss 0.00219886243343\n",
      "Epoch 20::Minibatch 283::LR 0.0561538461538 --> Loss 0.00213675022125\n",
      "Epoch 20::Minibatch 284::LR 0.0561538461538 --> Loss 0.00171311736107\n",
      "Epoch 20::Minibatch 285::LR 0.0561538461538 --> Loss 0.00120303014914\n",
      "Epoch 20::Minibatch 286::LR 0.0561538461538 --> Loss 0.00211691180865\n",
      "Epoch 20::Minibatch 287::LR 0.0561538461538 --> Loss 0.00206245640914\n",
      "Epoch 20::Minibatch 288::LR 0.0561538461538 --> Loss 0.00111089150111\n",
      "Epoch 20::Minibatch 289::LR 0.0561538461538 --> Loss 0.00159826705853\n",
      "Epoch 20::Minibatch 290::LR 0.0561538461538 --> Loss 0.00193491657575\n",
      "Epoch 20::Minibatch 291::LR 0.0561538461538 --> Loss 0.00172368705273\n",
      "Epoch 20::Minibatch 292::LR 0.0561538461538 --> Loss 0.000604073901971\n",
      "Epoch 20::Minibatch 293::LR 0.0561538461538 --> Loss 0.00150045216084\n",
      "Epoch 20::Minibatch 294::LR 0.0561538461538 --> Loss 0.00158194422722\n",
      "Epoch 20::Minibatch 295::LR 0.0561538461538 --> Loss 0.00187087158362\n",
      "Epoch 20::Minibatch 296::LR 0.0561538461538 --> Loss 0.00162253320217\n",
      "Epoch 20::Minibatch 297::LR 0.0561538461538 --> Loss 0.00140823016564\n",
      "Epoch 20::Minibatch 298::LR 0.0561538461538 --> Loss 0.00139737437169\n",
      "Epoch 20::Minibatch 299::LR 0.0561538461538 --> Loss 0.000801303635041\n",
      "Epoch 20::Minibatch 300::LR 0.0561538461538 --> Loss 0.00278935154279\n",
      "Epoch 20::Minibatch 301::LR 0.0561538461538 --> Loss 0.00270218392213\n",
      "Epoch 20::Minibatch 302::LR 0.0561538461538 --> Loss 0.00248832523823\n",
      "Epoch 20::Minibatch 303::LR 0.0561538461538 --> Loss 0.000855302413305\n",
      "Epoch 20::Minibatch 304::LR 0.0561538461538 --> Loss 0.00307581404845\n",
      "Epoch 20::Minibatch 305::LR 0.0561538461538 --> Loss 0.00169573525588\n",
      "Epoch 20::Minibatch 306::LR 0.0561538461538 --> Loss 0.000932772954305\n",
      "Epoch 20::Minibatch 307::LR 0.0561538461538 --> Loss 0.0024485941728\n",
      "Epoch 20::Minibatch 308::LR 0.0561538461538 --> Loss 0.00199972788493\n",
      "Epoch 20::Minibatch 309::LR 0.0561538461538 --> Loss 0.00101175258557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 310::LR 0.0561538461538 --> Loss 0.00113700807095\n",
      "Epoch 20::Minibatch 311::LR 0.0561538461538 --> Loss 0.00174063483874\n",
      "Epoch 20::Minibatch 312::LR 0.0561538461538 --> Loss 0.00293394505978\n",
      "Epoch 20::Minibatch 313::LR 0.0561538461538 --> Loss 0.00238625744979\n",
      "Epoch 20::Minibatch 314::LR 0.0561538461538 --> Loss 0.00191894928614\n",
      "Epoch 20::Minibatch 315::LR 0.0561538461538 --> Loss 0.00100773135821\n",
      "Epoch 20::Minibatch 316::LR 0.0561538461538 --> Loss 0.00233317156633\n",
      "Epoch 20::Minibatch 317::LR 0.0561538461538 --> Loss 0.00154967745145\n",
      "Epoch 20::Minibatch 318::LR 0.0561538461538 --> Loss 0.00124394913514\n",
      "Epoch 20::Minibatch 319::LR 0.0561538461538 --> Loss 0.00229743778706\n",
      "Epoch 20::Minibatch 320::LR 0.0561538461538 --> Loss 0.00316158791383\n",
      "Epoch 20::Minibatch 321::LR 0.0561538461538 --> Loss 0.000847576161226\n",
      "Epoch 20::Minibatch 322::LR 0.0561538461538 --> Loss 0.00362589081128\n",
      "Epoch 20::Minibatch 323::LR 0.0561538461538 --> Loss 0.00351253549258\n",
      "Epoch 20::Minibatch 324::LR 0.0561538461538 --> Loss 0.00263597448667\n",
      "Epoch 20::Minibatch 325::LR 0.0561538461538 --> Loss 0.00239656190077\n",
      "Epoch 20::Minibatch 326::LR 0.0561538461538 --> Loss 0.00548657735189\n",
      "Epoch 20::Minibatch 327::LR 0.0561538461538 --> Loss 0.00225365241369\n",
      "Epoch 20::Minibatch 328::LR 0.0561538461538 --> Loss 0.00320182462533\n",
      "Epoch 20::Minibatch 329::LR 0.0561538461538 --> Loss 0.00122045487165\n",
      "Epoch 20::Minibatch 330::LR 0.0561538461538 --> Loss 0.00159964203835\n",
      "Epoch 20::Minibatch 331::LR 0.0561538461538 --> Loss 0.0025437627236\n",
      "Epoch 20::Minibatch 332::LR 0.0561538461538 --> Loss 0.00249484638373\n",
      "Epoch 20::Minibatch 333::LR 0.0561538461538 --> Loss 0.00145226319631\n",
      "Epoch 20::Minibatch 334::LR 0.0561538461538 --> Loss 0.00440328200658\n",
      "Epoch 20::Minibatch 335::LR 0.0561538461538 --> Loss 0.0018883339564\n",
      "Epoch 20::Minibatch 336::LR 0.0561538461538 --> Loss 0.00218466242154\n",
      "Epoch 20::Minibatch 337::LR 0.0561538461538 --> Loss 0.00349780996641\n",
      "Epoch 20::Minibatch 338::LR 0.0561538461538 --> Loss 0.000527483026187\n",
      "Epoch 20::Minibatch 339::LR 0.0561538461538 --> Loss 0.00331347644329\n",
      "Epoch 20::Minibatch 340::LR 0.0561538461538 --> Loss 0.00399980545044\n",
      "Epoch 20::Minibatch 341::LR 0.0561538461538 --> Loss 0.00472113172213\n",
      "Epoch 20::Minibatch 342::LR 0.0561538461538 --> Loss 0.00310807724794\n",
      "Epoch 20::Minibatch 343::LR 0.0561538461538 --> Loss 0.00166685620944\n",
      "Epoch 20::Minibatch 344::LR 0.0561538461538 --> Loss 0.0031417397658\n",
      "Epoch 20::Minibatch 345::LR 0.0561538461538 --> Loss 0.00423253377279\n",
      "Epoch 20::Minibatch 346::LR 0.0561538461538 --> Loss 0.00561041792234\n",
      "Epoch 20::Minibatch 347::LR 0.0561538461538 --> Loss 0.000852943360806\n",
      "Epoch 20::Minibatch 348::LR 0.0561538461538 --> Loss 0.00332052767277\n",
      "Epoch 20::Minibatch 349::LR 0.0561538461538 --> Loss 0.00348768353462\n",
      "Epoch 20::Minibatch 350::LR 0.0561538461538 --> Loss 0.00174645046393\n",
      "Epoch 20::Minibatch 351::LR 0.0561538461538 --> Loss 0.00351646502813\n",
      "Epoch 20::Minibatch 352::LR 0.0561538461538 --> Loss 0.00490334947904\n",
      "Epoch 20::Minibatch 353::LR 0.0561538461538 --> Loss 0.00354387958845\n",
      "Epoch 20::Minibatch 354::LR 0.0561538461538 --> Loss 0.0029402355353\n",
      "Epoch 20::Minibatch 355::LR 0.0561538461538 --> Loss 0.00616300622622\n",
      "Epoch 20::Minibatch 356::LR 0.0561538461538 --> Loss 0.00312869330247\n",
      "Epoch 20::Minibatch 357::LR 0.0561538461538 --> Loss 0.00115235636632\n",
      "Epoch 20::Minibatch 358::LR 0.0561538461538 --> Loss 0.00209570646286\n",
      "Epoch 20::Minibatch 359::LR 0.0561538461538 --> Loss 0.00271363218625\n",
      "Epoch 20::Minibatch 360::LR 0.0561538461538 --> Loss 0.00240302443504\n",
      "Epoch 20::Minibatch 361::LR 0.0561538461538 --> Loss 0.00238385438919\n",
      "Epoch 20::Minibatch 362::LR 0.0561538461538 --> Loss 0.00236513614655\n",
      "Epoch 20::Minibatch 363::LR 0.0561538461538 --> Loss 0.000654085278511\n",
      "Epoch 20::Minibatch 364::LR 0.0561538461538 --> Loss 0.0019968911012\n",
      "Epoch 20::Minibatch 365::LR 0.0561538461538 --> Loss 0.00207240362962\n",
      "Epoch 20::Minibatch 366::LR 0.0561538461538 --> Loss 0.00221347749233\n",
      "Epoch 20::Minibatch 367::LR 0.0561538461538 --> Loss 0.00106132239103\n",
      "Epoch 20::Minibatch 368::LR 0.0561538461538 --> Loss 0.000980048278968\n",
      "Epoch 20::Minibatch 369::LR 0.0561538461538 --> Loss 0.00285551428795\n",
      "Epoch 20::Minibatch 370::LR 0.0561538461538 --> Loss 0.00225280960401\n",
      "Epoch 20::Minibatch 371::LR 0.0561538461538 --> Loss 0.0018714928627\n",
      "Epoch 20::Minibatch 372::LR 0.0561538461538 --> Loss 0.000432187467813\n",
      "Epoch 20::Minibatch 373::LR 0.0561538461538 --> Loss 0.00177690386772\n",
      "Epoch 20::Minibatch 374::LR 0.0561538461538 --> Loss 0.002201414903\n",
      "Epoch 20::Minibatch 375::LR 0.0561538461538 --> Loss 0.00184870481491\n",
      "Epoch 20::Minibatch 376::LR 0.0561538461538 --> Loss 0.0012324009339\n",
      "Epoch 20::Minibatch 377::LR 0.0561538461538 --> Loss 0.00193407197793\n",
      "Epoch 20::Minibatch 378::LR 0.0561538461538 --> Loss 0.00212088485559\n",
      "Epoch 20::Minibatch 379::LR 0.0561538461538 --> Loss 0.00236075997353\n",
      "Epoch 20::Minibatch 380::LR 0.0561538461538 --> Loss 0.0015801636378\n",
      "Epoch 20::Minibatch 381::LR 0.0561538461538 --> Loss 0.00098205824693\n",
      "Epoch 20::Minibatch 382::LR 0.0561538461538 --> Loss 0.00201430737972\n",
      "Epoch 20::Minibatch 383::LR 0.0561538461538 --> Loss 0.00195934712887\n",
      "Epoch 20::Minibatch 384::LR 0.0561538461538 --> Loss 0.00106303860744\n",
      "Epoch 20::Minibatch 385::LR 0.0561538461538 --> Loss 0.00103733519713\n",
      "Epoch 20::Minibatch 386::LR 0.0561538461538 --> Loss 0.00218791087468\n",
      "Epoch 20::Minibatch 387::LR 0.0561538461538 --> Loss 0.00234284778436\n",
      "Epoch 20::Minibatch 388::LR 0.0561538461538 --> Loss 0.00116170654694\n",
      "Epoch 20::Minibatch 389::LR 0.0561538461538 --> Loss 0.00179372092088\n",
      "Epoch 20::Minibatch 390::LR 0.0561538461538 --> Loss 0.00348039070765\n",
      "Epoch 20::Minibatch 391::LR 0.0561538461538 --> Loss 0.00264327744643\n",
      "Epoch 20::Minibatch 392::LR 0.0561538461538 --> Loss 0.00260876397292\n",
      "Epoch 20::Minibatch 393::LR 0.0561538461538 --> Loss 0.00275966982047\n",
      "Epoch 20::Minibatch 394::LR 0.0561538461538 --> Loss 0.00207683046659\n",
      "Epoch 20::Minibatch 395::LR 0.0561538461538 --> Loss 0.00205605208874\n",
      "Epoch 20::Minibatch 396::LR 0.0561538461538 --> Loss 0.00193508863449\n",
      "Epoch 20::Minibatch 397::LR 0.0561538461538 --> Loss 0.00206941147645\n",
      "Epoch 20::Minibatch 398::LR 0.0561538461538 --> Loss 0.00205475429694\n",
      "Epoch 20::Minibatch 399::LR 0.0561538461538 --> Loss 0.00236390093962\n",
      "Epoch 20::Minibatch 400::LR 0.0561538461538 --> Loss 0.00200614770253\n",
      "Epoch 20::Minibatch 401::LR 0.0561538461538 --> Loss 0.00345979173978\n",
      "Epoch 20::Minibatch 402::LR 0.0561538461538 --> Loss 0.00177637020747\n",
      "Epoch 20::Minibatch 403::LR 0.0561538461538 --> Loss 0.0014396867156\n",
      "Epoch 20::Minibatch 404::LR 0.0561538461538 --> Loss 0.00143498520056\n",
      "Epoch 20::Minibatch 405::LR 0.0561538461538 --> Loss 0.00345028241475\n",
      "Epoch 20::Minibatch 406::LR 0.0561538461538 --> Loss 0.00242495973905\n",
      "Epoch 20::Minibatch 407::LR 0.0561538461538 --> Loss 0.00172427097956\n",
      "Epoch 20::Minibatch 408::LR 0.0561538461538 --> Loss 0.000433380256097\n",
      "Epoch 20::Minibatch 409::LR 0.0561538461538 --> Loss 0.0022733014822\n",
      "Epoch 20::Minibatch 410::LR 0.0561538461538 --> Loss 0.00317608237267\n",
      "Epoch 20::Minibatch 411::LR 0.0561538461538 --> Loss 0.00163309534391\n",
      "Epoch 20::Minibatch 412::LR 0.0561538461538 --> Loss 0.000949841141701\n",
      "Epoch 20::Minibatch 413::LR 0.0561538461538 --> Loss 0.00195842087269\n",
      "Epoch 20::Minibatch 414::LR 0.0561538461538 --> Loss 0.00183457354705\n",
      "Epoch 20::Minibatch 415::LR 0.0561538461538 --> Loss 0.00114286045233\n",
      "Epoch 20::Minibatch 416::LR 0.0561538461538 --> Loss 0.000800197720528\n",
      "Epoch 20::Minibatch 417::LR 0.0561538461538 --> Loss 0.00168542901675\n",
      "Epoch 20::Minibatch 418::LR 0.0561538461538 --> Loss 0.00269290089607\n",
      "Epoch 20::Minibatch 419::LR 0.0561538461538 --> Loss 0.000488416900237\n",
      "Epoch 20::Minibatch 420::LR 0.0561538461538 --> Loss 0.000681779930989\n",
      "Epoch 20::Minibatch 421::LR 0.0561538461538 --> Loss 0.00190516332785\n",
      "Epoch 20::Minibatch 422::LR 0.0561538461538 --> Loss 0.00210721890132\n",
      "Epoch 20::Minibatch 423::LR 0.0561538461538 --> Loss 0.000958512425423\n",
      "Epoch 20::Minibatch 424::LR 0.0561538461538 --> Loss 0.00153076469898\n",
      "Epoch 20::Minibatch 425::LR 0.0561538461538 --> Loss 0.00289026021957\n",
      "Epoch 20::Minibatch 426::LR 0.0561538461538 --> Loss 0.00198505818844\n",
      "Epoch 20::Minibatch 427::LR 0.0561538461538 --> Loss 0.000706256081661\n",
      "Epoch 20::Minibatch 428::LR 0.0561538461538 --> Loss 0.00100762079159\n",
      "Epoch 20::Minibatch 429::LR 0.0561538461538 --> Loss 0.00233366171519\n",
      "Epoch 20::Minibatch 430::LR 0.0561538461538 --> Loss 0.00908973852793\n",
      "Epoch 20::Minibatch 431::LR 0.0561538461538 --> Loss 0.00377690235774\n",
      "Epoch 20::Minibatch 432::LR 0.0561538461538 --> Loss 0.00433494488398\n",
      "Epoch 20::Minibatch 433::LR 0.0561538461538 --> Loss 0.00255904614925\n",
      "Epoch 20::Minibatch 434::LR 0.0561538461538 --> Loss 0.00251482168833\n",
      "Epoch 20::Minibatch 435::LR 0.0561538461538 --> Loss 0.00230581601461\n",
      "Epoch 20::Minibatch 436::LR 0.0561538461538 --> Loss 0.00166025300821\n",
      "Epoch 20::Minibatch 437::LR 0.0561538461538 --> Loss 0.00311620553335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 438::LR 0.0561538461538 --> Loss 0.00249707023303\n",
      "Epoch 20::Minibatch 439::LR 0.0561538461538 --> Loss 0.00203159411748\n",
      "Epoch 20::Minibatch 440::LR 0.0561538461538 --> Loss 0.00315053125223\n",
      "Epoch 20::Minibatch 441::LR 0.0561538461538 --> Loss 0.00294072508812\n",
      "Epoch 20::Minibatch 442::LR 0.0561538461538 --> Loss 0.00267605880896\n",
      "Epoch 20::Minibatch 443::LR 0.0561538461538 --> Loss 0.00360310951869\n",
      "Epoch 20::Minibatch 444::LR 0.0561538461538 --> Loss 0.00281374732653\n",
      "Epoch 20::Minibatch 445::LR 0.0561538461538 --> Loss 0.000879167119662\n",
      "Epoch 20::Minibatch 446::LR 0.0561538461538 --> Loss 0.00142516215642\n",
      "Epoch 20::Minibatch 447::LR 0.0561538461538 --> Loss 0.00239269196987\n",
      "Epoch 20::Minibatch 448::LR 0.0561538461538 --> Loss 0.00237417856852\n",
      "Epoch 20::Minibatch 449::LR 0.0561538461538 --> Loss 0.00368424971898\n",
      "Epoch 20::Minibatch 450::LR 0.0561538461538 --> Loss 0.00224946995576\n",
      "Epoch 20::Minibatch 451::LR 0.0561538461538 --> Loss 0.00397344311078\n",
      "Epoch 20::Minibatch 452::LR 0.0561538461538 --> Loss 0.00235255261262\n",
      "Epoch 20::Minibatch 453::LR 0.0561538461538 --> Loss 0.000366064707438\n",
      "Epoch 20::Minibatch 454::LR 0.0561538461538 --> Loss 0.003567618529\n",
      "Epoch 20::Minibatch 455::LR 0.0561538461538 --> Loss 0.00266718685627\n",
      "Epoch 20::Minibatch 456::LR 0.0561538461538 --> Loss 0.00309843957424\n",
      "Epoch 20::Minibatch 457::LR 0.0561538461538 --> Loss 0.00193179647128\n",
      "Epoch 20::Minibatch 458::LR 0.0561538461538 --> Loss 0.000740015258392\n",
      "Epoch 20::Minibatch 459::LR 0.0561538461538 --> Loss 0.00401564796766\n",
      "Epoch 20::Minibatch 460::LR 0.0561538461538 --> Loss 0.00253294130166\n",
      "Epoch 20::Minibatch 461::LR 0.0561538461538 --> Loss 0.0038415535291\n",
      "Epoch 20::Minibatch 462::LR 0.0561538461538 --> Loss 0.000384581983089\n",
      "Epoch 20::Minibatch 463::LR 0.0561538461538 --> Loss 0.00440810084343\n",
      "Epoch 20::Minibatch 464::LR 0.0561538461538 --> Loss 0.00200916171074\n",
      "Epoch 20::Minibatch 465::LR 0.0561538461538 --> Loss 0.00502305467923\n",
      "Epoch 20::Minibatch 466::LR 0.0561538461538 --> Loss 0.00509094794591\n",
      "Epoch 20::Minibatch 467::LR 0.0561538461538 --> Loss 0.00551902095477\n",
      "Epoch 20::Minibatch 468::LR 0.0561538461538 --> Loss 0.00595862348874\n",
      "Epoch 20::Minibatch 469::LR 0.0561538461538 --> Loss 0.00609610716502\n",
      "Epoch 20::Minibatch 470::LR 0.0561538461538 --> Loss 0.00369789123535\n",
      "Epoch 20::Minibatch 471::LR 0.0561538461538 --> Loss 0.00171341896057\n",
      "Epoch 20::Minibatch 472::LR 0.0561538461538 --> Loss 0.00354318261147\n",
      "Epoch 20::Minibatch 473::LR 0.0561538461538 --> Loss 0.00226478656133\n",
      "Epoch 20::Minibatch 474::LR 0.0561538461538 --> Loss 0.000695905834436\n",
      "Epoch 20::Minibatch 475::LR 0.0561538461538 --> Loss 0.00512489080429\n",
      "Epoch 20::Minibatch 476::LR 0.0561538461538 --> Loss 0.0078231159846\n",
      "Epoch 20::Minibatch 477::LR 0.0561538461538 --> Loss 0.000924052000046\n",
      "Epoch 20::Minibatch 478::LR 0.0561538461538 --> Loss 0.00244145671527\n",
      "Epoch 20::Minibatch 479::LR 0.0561538461538 --> Loss 0.00196007370949\n",
      "Epoch 20::Minibatch 480::LR 0.0561538461538 --> Loss 0.00152732004722\n",
      "Epoch 20::Minibatch 481::LR 0.0561538461538 --> Loss 0.000956258277098\n",
      "Epoch 20::Minibatch 482::LR 0.0561538461538 --> Loss 0.0020885916551\n",
      "Epoch 20::Minibatch 483::LR 0.0561538461538 --> Loss 0.00312964479129\n",
      "Epoch 20::Minibatch 484::LR 0.0561538461538 --> Loss 0.00350494742393\n",
      "Epoch 20::Minibatch 485::LR 0.0561538461538 --> Loss 0.000758721133073\n",
      "Epoch 20::Minibatch 486::LR 0.0561538461538 --> Loss 0.00290315588315\n",
      "Epoch 20::Minibatch 487::LR 0.0561538461538 --> Loss 0.00334296822548\n",
      "Epoch 20::Minibatch 488::LR 0.0561538461538 --> Loss 0.00203868548075\n",
      "Epoch 20::Minibatch 489::LR 0.0561538461538 --> Loss 0.00314600467682\n",
      "Epoch 20::Minibatch 490::LR 0.0561538461538 --> Loss 0.000409521510204\n",
      "Epoch 20::Minibatch 491::LR 0.0561538461538 --> Loss 0.00356249094009\n",
      "Epoch 20::Minibatch 492::LR 0.0561538461538 --> Loss 0.00305782318115\n",
      "Epoch 20::Minibatch 493::LR 0.0561538461538 --> Loss 0.00303368488948\n",
      "Epoch 20::Minibatch 494::LR 0.0561538461538 --> Loss 0.000736521532138\n",
      "Epoch 20::Minibatch 495::LR 0.0561538461538 --> Loss 0.00186198512713\n",
      "Epoch 20::Minibatch 496::LR 0.0561538461538 --> Loss 0.00285443286101\n",
      "Epoch 20::Minibatch 497::LR 0.0561538461538 --> Loss 0.000924422840277\n",
      "Epoch 20::Minibatch 498::LR 0.0561538461538 --> Loss 0.000558400452137\n",
      "Epoch 20::Minibatch 499::LR 0.0561538461538 --> Loss 0.00355742454529\n",
      "Epoch 20::Minibatch 500::LR 0.0561538461538 --> Loss 0.0014389359951\n",
      "Epoch 20::Minibatch 501::LR 0.0561538461538 --> Loss 0.00216597358386\n",
      "Epoch 20::Minibatch 502::LR 0.0561538461538 --> Loss 0.00380172093709\n",
      "Epoch 20::Minibatch 503::LR 0.0561538461538 --> Loss 0.00774782816569\n",
      "Epoch 20::Minibatch 504::LR 0.0561538461538 --> Loss 0.00740385532379\n",
      "Epoch 20::Minibatch 505::LR 0.0561538461538 --> Loss 0.00418973088264\n",
      "Epoch 20::Minibatch 506::LR 0.0561538461538 --> Loss 0.00341953794161\n",
      "Epoch 20::Minibatch 507::LR 0.0561538461538 --> Loss 0.00596126437187\n",
      "Epoch 20::Minibatch 508::LR 0.0561538461538 --> Loss 0.00340825517972\n",
      "Epoch 20::Minibatch 509::LR 0.0561538461538 --> Loss 0.00448250214259\n",
      "Epoch 20::Minibatch 510::LR 0.0561538461538 --> Loss 0.00452503005664\n",
      "Epoch 20::Minibatch 511::LR 0.0561538461538 --> Loss 0.00393873055776\n",
      "Epoch 20::Minibatch 512::LR 0.0561538461538 --> Loss 0.00268684188525\n",
      "Epoch 20::Minibatch 513::LR 0.0561538461538 --> Loss 0.000630500515302\n",
      "Epoch 20::Minibatch 514::LR 0.0561538461538 --> Loss 0.00263986885548\n",
      "Epoch 20::Minibatch 515::LR 0.0561538461538 --> Loss 0.00300604085128\n",
      "Epoch 20::Minibatch 516::LR 0.0561538461538 --> Loss 0.00403472065926\n",
      "Epoch 20::Minibatch 517::LR 0.0561538461538 --> Loss 0.00353638410568\n",
      "Epoch 20::Minibatch 518::LR 0.0561538461538 --> Loss 0.00257478336493\n",
      "Epoch 20::Minibatch 519::LR 0.0561538461538 --> Loss 0.00348192890485\n",
      "Epoch 20::Minibatch 520::LR 0.0561538461538 --> Loss 0.00539742310842\n",
      "Epoch 20::Minibatch 521::LR 0.0561538461538 --> Loss 0.00547605435054\n",
      "Epoch 20::Minibatch 522::LR 0.0561538461538 --> Loss 0.00779043038686\n",
      "Epoch 20::Minibatch 523::LR 0.0561538461538 --> Loss 0.000640027821064\n",
      "Epoch 20::Minibatch 524::LR 0.0561538461538 --> Loss 0.00141603042682\n",
      "Epoch 20::Minibatch 525::LR 0.0561538461538 --> Loss 0.00319016238054\n",
      "Epoch 20::Minibatch 526::LR 0.0561538461538 --> Loss 0.00393811146418\n",
      "Epoch 20::Minibatch 527::LR 0.0561538461538 --> Loss 0.0022228650252\n",
      "Epoch 20::Minibatch 528::LR 0.0561538461538 --> Loss 0.00101326833169\n",
      "Epoch 20::Minibatch 529::LR 0.0561538461538 --> Loss 0.00401495138804\n",
      "Epoch 20::Minibatch 530::LR 0.0561538461538 --> Loss 0.00403473416964\n",
      "Epoch 20::Minibatch 531::LR 0.0561538461538 --> Loss 0.00353248635928\n",
      "Epoch 20::Minibatch 532::LR 0.0561538461538 --> Loss 0.00267479976018\n",
      "Epoch 20::Minibatch 533::LR 0.0561538461538 --> Loss 0.00493332743645\n",
      "Epoch 20::Minibatch 534::LR 0.0561538461538 --> Loss 0.00377568324407\n",
      "Epoch 20::Minibatch 535::LR 0.0561538461538 --> Loss 0.00325009743373\n",
      "Epoch 20::Minibatch 536::LR 0.0561538461538 --> Loss 0.00210967600346\n",
      "Epoch 20::Minibatch 537::LR 0.0561538461538 --> Loss 0.000611013273398\n",
      "Epoch 20::Minibatch 538::LR 0.0561538461538 --> Loss 0.00167428950469\n",
      "Epoch 20::Minibatch 539::LR 0.0561538461538 --> Loss 0.00339874943097\n",
      "Epoch 20::Minibatch 540::LR 0.0561538461538 --> Loss 0.00341618577639\n",
      "Epoch 20::Minibatch 541::LR 0.0561538461538 --> Loss 0.00288930217425\n",
      "Epoch 20::Minibatch 542::LR 0.0561538461538 --> Loss 0.00249056657155\n",
      "Epoch 20::Minibatch 543::LR 0.0561538461538 --> Loss 0.00269704540571\n",
      "Epoch 20::Minibatch 544::LR 0.0561538461538 --> Loss 0.0039196908474\n",
      "Epoch 20::Minibatch 545::LR 0.0561538461538 --> Loss 0.00202742278576\n",
      "Epoch 20::Minibatch 546::LR 0.0561538461538 --> Loss 0.000653819938501\n",
      "Epoch 20::Minibatch 547::LR 0.0561538461538 --> Loss 0.0026117515564\n",
      "Epoch 20::Minibatch 548::LR 0.0561538461538 --> Loss 0.0036051940918\n",
      "Epoch 20::Minibatch 549::LR 0.0561538461538 --> Loss 0.00874162356059\n",
      "Epoch 20::Minibatch 550::LR 0.0561538461538 --> Loss 0.00117202202479\n",
      "Epoch 20::Minibatch 551::LR 0.0561538461538 --> Loss 0.00245110551516\n",
      "Epoch 20::Minibatch 552::LR 0.0561538461538 --> Loss 0.00351784785589\n",
      "Epoch 20::Minibatch 553::LR 0.0561538461538 --> Loss 0.003139133056\n",
      "Epoch 20::Minibatch 554::LR 0.0561538461538 --> Loss 0.00371521313985\n",
      "Epoch 20::Minibatch 555::LR 0.0561538461538 --> Loss 0.000969045460224\n",
      "Epoch 20::Minibatch 556::LR 0.0561538461538 --> Loss 0.00197088857492\n",
      "Epoch 20::Minibatch 557::LR 0.0561538461538 --> Loss 0.00241621772448\n",
      "Epoch 20::Minibatch 558::LR 0.0561538461538 --> Loss 0.00367070396741\n",
      "Epoch 20::Minibatch 559::LR 0.0561538461538 --> Loss 0.00371087829272\n",
      "Epoch 20::Minibatch 560::LR 0.0561538461538 --> Loss 0.00306735237439\n",
      "Epoch 20::Minibatch 561::LR 0.0561538461538 --> Loss 0.00267877558867\n",
      "Epoch 20::Minibatch 562::LR 0.0561538461538 --> Loss 0.0023633223772\n",
      "Epoch 20::Minibatch 563::LR 0.0561538461538 --> Loss 0.00401167909304\n",
      "Epoch 20::Minibatch 564::LR 0.0561538461538 --> Loss 0.00309752583504\n",
      "Epoch 20::Minibatch 565::LR 0.0561538461538 --> Loss 0.00365305701892\n",
      "Epoch 20::Minibatch 566::LR 0.0561538461538 --> Loss 0.00225158592065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 567::LR 0.0561538461538 --> Loss 0.00255499859651\n",
      "Epoch 20::Minibatch 568::LR 0.0561538461538 --> Loss 0.00179502507051\n",
      "Epoch 20::Minibatch 569::LR 0.0561538461538 --> Loss 0.000563091089328\n",
      "Epoch 20::Minibatch 570::LR 0.0561538461538 --> Loss 0.00168219546477\n",
      "Epoch 20::Minibatch 571::LR 0.0561538461538 --> Loss 0.00218327542146\n",
      "Epoch 20::Minibatch 572::LR 0.0561538461538 --> Loss 0.00232998490334\n",
      "Epoch 20::Minibatch 573::LR 0.0561538461538 --> Loss 0.00149104317029\n",
      "Epoch 20::Minibatch 574::LR 0.0561538461538 --> Loss 0.00104796111584\n",
      "Epoch 20::Minibatch 575::LR 0.0561538461538 --> Loss 0.00176818132401\n",
      "Epoch 20::Minibatch 576::LR 0.0561538461538 --> Loss 0.00209181110064\n",
      "Epoch 20::Minibatch 577::LR 0.0561538461538 --> Loss 0.00164798527956\n",
      "Epoch 20::Minibatch 578::LR 0.0561538461538 --> Loss 0.00128281652927\n",
      "Epoch 20::Minibatch 579::LR 0.0561538461538 --> Loss 0.00119649598996\n",
      "Epoch 20::Minibatch 580::LR 0.0561538461538 --> Loss 0.00193896154563\n",
      "Epoch 20::Minibatch 581::LR 0.0561538461538 --> Loss 0.00171488483747\n",
      "Epoch 20::Minibatch 582::LR 0.0561538461538 --> Loss 0.00414195338885\n",
      "Epoch 20::Minibatch 583::LR 0.0561538461538 --> Loss 0.000944178501765\n",
      "Epoch 20::Minibatch 584::LR 0.0561538461538 --> Loss 0.00130844950676\n",
      "Epoch 20::Minibatch 585::LR 0.0561538461538 --> Loss 0.00424813906352\n",
      "Epoch 20::Minibatch 586::LR 0.0561538461538 --> Loss 0.00392440319061\n",
      "Epoch 20::Minibatch 587::LR 0.0561538461538 --> Loss 0.00112595617771\n",
      "Epoch 20::Minibatch 588::LR 0.0561538461538 --> Loss 0.00140031546354\n",
      "Epoch 20::Minibatch 589::LR 0.0561538461538 --> Loss 0.00276608169079\n",
      "Epoch 20::Minibatch 590::LR 0.0561538461538 --> Loss 0.00190894683202\n",
      "Epoch 20::Minibatch 591::LR 0.0561538461538 --> Loss 0.00295183897018\n",
      "Epoch 20::Minibatch 592::LR 0.0561538461538 --> Loss 0.00117304285367\n",
      "Epoch 20::Minibatch 593::LR 0.0561538461538 --> Loss 0.00257192293803\n",
      "Epoch 20::Minibatch 594::LR 0.0561538461538 --> Loss 0.00270674169064\n",
      "Epoch 20::Minibatch 595::LR 0.0561538461538 --> Loss 0.00304761350155\n",
      "Epoch 20::Minibatch 596::LR 0.0561538461538 --> Loss 0.00191689372063\n",
      "Epoch 20::Minibatch 597::LR 0.0561538461538 --> Loss 0.00118766913811\n",
      "Epoch 20::Minibatch 598::LR 0.0561538461538 --> Loss 0.00295655985673\n",
      "Epoch 20::Minibatch 599::LR 0.0561538461538 --> Loss 0.00184359689554\n",
      "Epoch 20::Minibatch 600::LR 0.0561538461538 --> Loss 0.00220006068548\n",
      "Epoch 20::Minibatch 601::LR 0.0561538461538 --> Loss 0.00385580619176\n",
      "Epoch 20::Minibatch 602::LR 0.0561538461538 --> Loss 0.00211221039295\n",
      "Epoch 20::Minibatch 603::LR 0.0561538461538 --> Loss 0.00264136135578\n",
      "Epoch 20::Minibatch 604::LR 0.0561538461538 --> Loss 0.00165139983098\n",
      "Epoch 20::Minibatch 605::LR 0.0561538461538 --> Loss 0.00235723475615\n",
      "Epoch 20::Minibatch 606::LR 0.0561538461538 --> Loss 0.00191160440445\n",
      "Epoch 20::Minibatch 607::LR 0.0561538461538 --> Loss 0.000840559999148\n",
      "Epoch 20::Minibatch 608::LR 0.0561538461538 --> Loss 0.00157929013173\n",
      "Epoch 20::Minibatch 609::LR 0.0561538461538 --> Loss 0.00240197916826\n",
      "Epoch 20::Minibatch 610::LR 0.0561538461538 --> Loss 0.00403731107712\n",
      "Epoch 20::Minibatch 611::LR 0.0561538461538 --> Loss 0.00264030834039\n",
      "Epoch 20::Minibatch 612::LR 0.0561538461538 --> Loss 0.000481601754824\n",
      "Epoch 20::Minibatch 613::LR 0.0561538461538 --> Loss 0.00131268401941\n",
      "Epoch 20::Minibatch 614::LR 0.0561538461538 --> Loss 0.00244687219461\n",
      "Epoch 20::Minibatch 615::LR 0.0561538461538 --> Loss 0.00167993446191\n",
      "Epoch 20::Minibatch 616::LR 0.0561538461538 --> Loss 0.000925595561663\n",
      "Epoch 20::Minibatch 617::LR 0.0561538461538 --> Loss 0.00050016378363\n",
      "Epoch 20::Minibatch 618::LR 0.0561538461538 --> Loss 0.00278575917085\n",
      "Epoch 20::Minibatch 619::LR 0.0561538461538 --> Loss 0.00192722678185\n",
      "Epoch 20::Minibatch 620::LR 0.0561538461538 --> Loss 0.00171558320522\n",
      "Epoch 20::Minibatch 621::LR 0.0561538461538 --> Loss 0.000853138168653\n",
      "Epoch 20::Minibatch 622::LR 0.0561538461538 --> Loss 0.00079575141271\n",
      "Epoch 20::Minibatch 623::LR 0.0561538461538 --> Loss 0.00222266991933\n",
      "Epoch 20::Minibatch 624::LR 0.0561538461538 --> Loss 0.00180424233278\n",
      "Epoch 20::Minibatch 625::LR 0.0561538461538 --> Loss 0.00287802596887\n",
      "Epoch 20::Minibatch 626::LR 0.0561538461538 --> Loss 0.00421118736267\n",
      "Epoch 20::Minibatch 627::LR 0.0561538461538 --> Loss 0.00130859861771\n",
      "Epoch 20::Minibatch 628::LR 0.0561538461538 --> Loss 0.00089480082194\n",
      "Epoch 20::Minibatch 629::LR 0.0561538461538 --> Loss 0.00332299828529\n",
      "Epoch 20::Minibatch 630::LR 0.0561538461538 --> Loss 0.0032412391901\n",
      "Epoch 20::Minibatch 631::LR 0.0561538461538 --> Loss 0.00605388482412\n",
      "Epoch 20::Minibatch 632::LR 0.0561538461538 --> Loss 0.000793089369933\n",
      "Epoch 20::Minibatch 633::LR 0.0561538461538 --> Loss 0.00164740681648\n",
      "Epoch 20::Minibatch 634::LR 0.0561538461538 --> Loss 0.00323589503765\n",
      "Epoch 20::Minibatch 635::LR 0.0561538461538 --> Loss 0.00540638566017\n",
      "Epoch 20::Minibatch 636::LR 0.0561538461538 --> Loss 0.00496416211128\n",
      "Epoch 20::Minibatch 637::LR 0.0561538461538 --> Loss 0.000765358358622\n",
      "Epoch 20::Minibatch 638::LR 0.0561538461538 --> Loss 0.00150606652101\n",
      "Epoch 20::Minibatch 639::LR 0.0561538461538 --> Loss 0.00327802121639\n",
      "Epoch 20::Minibatch 640::LR 0.0561538461538 --> Loss 0.00489824930827\n",
      "Epoch 20::Minibatch 641::LR 0.0561538461538 --> Loss 0.00311156948407\n",
      "Epoch 20::Minibatch 642::LR 0.0561538461538 --> Loss 0.000542435497046\n",
      "Epoch 20::Minibatch 643::LR 0.0561538461538 --> Loss 0.00233812669913\n",
      "Epoch 20::Minibatch 644::LR 0.0561538461538 --> Loss 0.00395889401436\n",
      "Epoch 20::Minibatch 645::LR 0.0561538461538 --> Loss 0.0042530866464\n",
      "Epoch 20::Minibatch 646::LR 0.0561538461538 --> Loss 0.00151072949171\n",
      "Epoch 20::Minibatch 647::LR 0.0561538461538 --> Loss 0.000510038932165\n",
      "Epoch 20::Minibatch 648::LR 0.0561538461538 --> Loss 0.00292640686035\n",
      "Epoch 20::Minibatch 649::LR 0.0561538461538 --> Loss 0.00347364068031\n",
      "Epoch 20::Minibatch 650::LR 0.0561538461538 --> Loss 0.00329154392083\n",
      "Epoch 20::Minibatch 651::LR 0.0561538461538 --> Loss 0.00137289812167\n",
      "Epoch 20::Minibatch 652::LR 0.0561538461538 --> Loss 0.000798847526312\n",
      "Epoch 20::Minibatch 653::LR 0.0561538461538 --> Loss 0.00284971276919\n",
      "Epoch 20::Minibatch 654::LR 0.0561538461538 --> Loss 0.00312231818835\n",
      "Epoch 20::Minibatch 655::LR 0.0561538461538 --> Loss 0.00352570970853\n",
      "Epoch 20::Minibatch 656::LR 0.0561538461538 --> Loss 0.000758360425631\n",
      "Epoch 20::Minibatch 657::LR 0.0561538461538 --> Loss 0.00225028157234\n",
      "Epoch 20::Minibatch 658::LR 0.0561538461538 --> Loss 0.00481182893117\n",
      "Epoch 20::Minibatch 659::LR 0.0561538461538 --> Loss 0.00229192793369\n",
      "Epoch 20::Minibatch 660::LR 0.0561538461538 --> Loss 0.00261964917183\n",
      "Epoch 20::Minibatch 661::LR 0.0561538461538 --> Loss 0.00244347492854\n",
      "Epoch 20::Minibatch 662::LR 0.0561538461538 --> Loss 0.00181374529998\n",
      "Epoch 20::Minibatch 663::LR 0.0561538461538 --> Loss 0.00368589083354\n",
      "Epoch 20::Minibatch 664::LR 0.0561538461538 --> Loss 0.00335675239563\n",
      "Epoch 20::Minibatch 665::LR 0.0561538461538 --> Loss 0.000723456442356\n",
      "Epoch 20::Minibatch 666::LR 0.0561538461538 --> Loss 0.00392023523649\n",
      "Epoch 20::Minibatch 667::LR 0.0561538461538 --> Loss 0.00255101442337\n",
      "Epoch 20::Minibatch 668::LR 0.0561538461538 --> Loss 0.00682583649953\n",
      "Epoch 20::Minibatch 669::LR 0.0561538461538 --> Loss 0.00109329263369\n",
      "Epoch 20::Minibatch 670::LR 0.0561538461538 --> Loss 0.00134894539913\n",
      "Epoch 20::Minibatch 671::LR 0.0561538461538 --> Loss 0.00530228575071\n",
      "Epoch 20::Minibatch 672::LR 0.0561538461538 --> Loss 0.0036538652579\n",
      "Epoch 20::Minibatch 673::LR 0.0561538461538 --> Loss 0.00162064701319\n",
      "Epoch 20::Minibatch 674::LR 0.0561538461538 --> Loss 0.000513378282388\n",
      "Epoch 20::Minibatch 675::LR 0.0561538461538 --> Loss 0.00218718111515\n",
      "Epoch 20::Minibatch 676::LR 0.0561538461538 --> Loss 0.00213165044785\n",
      "Epoch 20::Minibatch 677::LR 0.0561538461538 --> Loss 0.00278007427851\n",
      "Epoch 20::Minibatch 678::LR 0.0561538461538 --> Loss 0.00191609283288\n",
      "Epoch 20::Minibatch 679::LR 0.0561538461538 --> Loss 0.00346092661222\n",
      "Epoch 20::Minibatch 680::LR 0.0561538461538 --> Loss 0.00214167674383\n",
      "Epoch 20::Minibatch 681::LR 0.0561538461538 --> Loss 0.00242973883947\n",
      "Epoch 20::Minibatch 682::LR 0.0561538461538 --> Loss 0.000761203765869\n",
      "Epoch 20::Minibatch 683::LR 0.0561538461538 --> Loss 0.00236244956652\n",
      "Epoch 20::Minibatch 684::LR 0.0561538461538 --> Loss 0.00235001305739\n",
      "Epoch 20::Minibatch 685::LR 0.0561538461538 --> Loss 0.00289007902145\n",
      "Epoch 20::Minibatch 686::LR 0.0561538461538 --> Loss 0.00156093100707\n",
      "Epoch 20::Minibatch 687::LR 0.0561538461538 --> Loss 0.000855293869972\n",
      "Epoch 20::Minibatch 688::LR 0.0561538461538 --> Loss 0.00276948730151\n",
      "Epoch 20::Minibatch 689::LR 0.0561538461538 --> Loss 0.00251925130685\n",
      "Epoch 20::Minibatch 690::LR 0.0561538461538 --> Loss 0.00191158692042\n",
      "Epoch 20::Minibatch 691::LR 0.0561538461538 --> Loss 0.000659178197384\n",
      "Epoch 20::Minibatch 692::LR 0.0561538461538 --> Loss 0.00246149758498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 693::LR 0.0561538461538 --> Loss 0.00258587082227\n",
      "Epoch 20::Minibatch 694::LR 0.0561538461538 --> Loss 0.00301906188329\n",
      "Epoch 20::Minibatch 695::LR 0.0561538461538 --> Loss 0.00175391813119\n",
      "Epoch 20::Minibatch 696::LR 0.0561538461538 --> Loss 0.00204592784246\n",
      "Epoch 20::Minibatch 697::LR 0.0561538461538 --> Loss 0.00140620976686\n",
      "Epoch 20::Minibatch 698::LR 0.0561538461538 --> Loss 0.00164101888736\n",
      "Epoch 20::Minibatch 699::LR 0.0561538461538 --> Loss 0.00382057309151\n",
      "Epoch 20::Minibatch 700::LR 0.0561538461538 --> Loss 0.00265752593676\n",
      "Epoch 20::Minibatch 701::LR 0.0561538461538 --> Loss 0.00196394542853\n",
      "Epoch 20::Minibatch 702::LR 0.0561538461538 --> Loss 0.00166475683451\n",
      "Epoch 20::Minibatch 703::LR 0.0561538461538 --> Loss 0.00432094057401\n",
      "Epoch 20::Minibatch 704::LR 0.0561538461538 --> Loss 0.00180487970511\n",
      "Epoch 20::Minibatch 705::LR 0.0561538461538 --> Loss 0.00286651213964\n",
      "Epoch 20::Minibatch 706::LR 0.0561538461538 --> Loss 0.00224064727624\n",
      "Epoch 20::Minibatch 707::LR 0.0561538461538 --> Loss 0.00118552198013\n",
      "Epoch 20::Minibatch 708::LR 0.0561538461538 --> Loss 0.00173416097959\n",
      "Epoch 20::Minibatch 709::LR 0.0561538461538 --> Loss 0.00168223718802\n",
      "Epoch 20::Minibatch 710::LR 0.0561538461538 --> Loss 0.00253655890624\n",
      "Epoch 20::Minibatch 711::LR 0.0561538461538 --> Loss 0.00193724075953\n",
      "Epoch 20::Minibatch 712::LR 0.0561538461538 --> Loss 0.00133803268274\n",
      "Epoch 20::Minibatch 713::LR 0.0561538461538 --> Loss 0.00176862935225\n",
      "Epoch 20::Minibatch 714::LR 0.0561538461538 --> Loss 0.00277833422025\n",
      "Epoch 20::Minibatch 715::LR 0.0561538461538 --> Loss 0.00293729345004\n",
      "Epoch 20::Minibatch 716::LR 0.0561538461538 --> Loss 0.00162581115961\n",
      "Epoch 20::Minibatch 717::LR 0.0561538461538 --> Loss 0.00162830670675\n",
      "Epoch 20::Minibatch 718::LR 0.0561538461538 --> Loss 0.00126075784365\n",
      "Epoch 20::Minibatch 719::LR 0.0561538461538 --> Loss 0.00168162266413\n",
      "Epoch 20::Minibatch 720::LR 0.0561538461538 --> Loss 0.00259120086829\n",
      "Epoch 20::Minibatch 721::LR 0.0561538461538 --> Loss 0.000616597781579\n",
      "Epoch 20::Minibatch 722::LR 0.0561538461538 --> Loss 0.00474457661311\n",
      "Epoch 20::Minibatch 723::LR 0.0561538461538 --> Loss 0.00489228804906\n",
      "Epoch 20::Minibatch 724::LR 0.0561538461538 --> Loss 0.000966749489307\n",
      "Epoch 20::Minibatch 725::LR 0.0561538461538 --> Loss 0.00214371999105\n",
      "Epoch 20::Minibatch 726::LR 0.0561538461538 --> Loss 0.0043616048495\n",
      "Epoch 20::Minibatch 727::LR 0.0561538461538 --> Loss 0.0032196633021\n",
      "Epoch 20::Minibatch 728::LR 0.0561538461538 --> Loss 0.000644675195217\n",
      "Epoch 20::Minibatch 729::LR 0.0561538461538 --> Loss 0.00073965276281\n",
      "Epoch 20::Minibatch 730::LR 0.0561538461538 --> Loss 0.00283647477627\n",
      "Epoch 20::Minibatch 731::LR 0.0561538461538 --> Loss 0.00252712269624\n",
      "Epoch 20::Minibatch 732::LR 0.0561538461538 --> Loss 0.0021781172355\n",
      "Epoch 20::Minibatch 733::LR 0.0561538461538 --> Loss 0.000659403850635\n",
      "Epoch 20::Minibatch 734::LR 0.0561538461538 --> Loss 0.00170747439067\n",
      "Epoch 20::Minibatch 735::LR 0.0561538461538 --> Loss 0.00238145271937\n",
      "Epoch 20::Minibatch 736::LR 0.0561538461538 --> Loss 0.00347135663033\n",
      "Epoch 20::Minibatch 737::LR 0.0561538461538 --> Loss 0.00304704606533\n",
      "Epoch 20::Minibatch 738::LR 0.0561538461538 --> Loss 0.00153939108054\n",
      "Epoch 20::Minibatch 739::LR 0.0561538461538 --> Loss 0.00244066178799\n",
      "Epoch 20::Minibatch 740::LR 0.0561538461538 --> Loss 0.00383064031601\n",
      "Epoch 20::Minibatch 741::LR 0.0561538461538 --> Loss 0.00264326930046\n",
      "Epoch 20::Minibatch 742::LR 0.0561538461538 --> Loss 0.00210907697678\n",
      "Epoch 20::Minibatch 743::LR 0.0561538461538 --> Loss 0.00141956706842\n",
      "Epoch 20::Minibatch 744::LR 0.0561538461538 --> Loss 0.00181229551633\n",
      "Epoch 20::Minibatch 745::LR 0.0561538461538 --> Loss 0.00282392760118\n",
      "Epoch 20::Minibatch 746::LR 0.0561538461538 --> Loss 0.00294872522354\n",
      "Epoch 20::Minibatch 747::LR 0.0561538461538 --> Loss 0.00178676704566\n",
      "Epoch 20::Minibatch 748::LR 0.0561538461538 --> Loss 0.000624631941319\n",
      "Epoch 20::Minibatch 749::LR 0.0561538461538 --> Loss 0.00165424317122\n",
      "Epoch 20::Minibatch 750::LR 0.0561538461538 --> Loss 0.00245330254237\n",
      "Epoch 20::Minibatch 751::LR 0.0561538461538 --> Loss 0.00278578102589\n",
      "Epoch 20::Minibatch 752::LR 0.0561538461538 --> Loss 0.00124365111192\n",
      "Epoch 20::Minibatch 753::LR 0.0561538461538 --> Loss 0.0022155191501\n",
      "Epoch 20::Minibatch 754::LR 0.0561538461538 --> Loss 0.00240391671658\n",
      "Epoch 20::Minibatch 755::LR 0.0561538461538 --> Loss 0.00266499876976\n",
      "Epoch 20::Minibatch 756::LR 0.0561538461538 --> Loss 0.00136271774769\n",
      "Epoch 20::Minibatch 757::LR 0.0561538461538 --> Loss 0.000731050322453\n",
      "Epoch 20::Minibatch 758::LR 0.0561538461538 --> Loss 0.00159869581461\n",
      "Epoch 20::Minibatch 759::LR 0.0561538461538 --> Loss 0.00368154247602\n",
      "Epoch 20::Minibatch 760::LR 0.0561538461538 --> Loss 0.00292112410069\n",
      "Epoch 20::Minibatch 761::LR 0.0561538461538 --> Loss 0.00613644917806\n",
      "Epoch 20::Minibatch 762::LR 0.0561538461538 --> Loss 0.00371948679288\n",
      "Epoch 20::Minibatch 763::LR 0.0561538461538 --> Loss 0.00352421164513\n",
      "Epoch 20::Minibatch 764::LR 0.0561538461538 --> Loss 0.00315515756607\n",
      "Epoch 20::Minibatch 765::LR 0.0561538461538 --> Loss 0.0012956187129\n",
      "Epoch 20::Minibatch 766::LR 0.0561538461538 --> Loss 0.00228387971719\n",
      "Epoch 20::Minibatch 767::LR 0.0561538461538 --> Loss 0.00493957122167\n",
      "Epoch 20::Minibatch 768::LR 0.0561538461538 --> Loss 0.00364185214043\n",
      "Epoch 20::Minibatch 769::LR 0.0561538461538 --> Loss 0.00187833031019\n",
      "Epoch 20::Minibatch 770::LR 0.0561538461538 --> Loss 0.00146863689025\n",
      "Epoch 20::Minibatch 771::LR 0.0561538461538 --> Loss 0.00361470739047\n",
      "Epoch 20::Minibatch 772::LR 0.0561538461538 --> Loss 0.00345437606176\n",
      "Epoch 20::Minibatch 773::LR 0.0561538461538 --> Loss 0.0031424554189\n",
      "Epoch 20::Minibatch 774::LR 0.0561538461538 --> Loss 0.00180520653725\n",
      "Epoch 20::Minibatch 775::LR 0.0561538461538 --> Loss 0.00365844607353\n",
      "Epoch 20::Minibatch 776::LR 0.0561538461538 --> Loss 0.00360259572665\n",
      "Epoch 20::Minibatch 777::LR 0.0561538461538 --> Loss 0.00707557837168\n",
      "Epoch 20::Minibatch 778::LR 0.0561538461538 --> Loss 0.00884787718455\n",
      "Epoch 20::Minibatch 779::LR 0.0561538461538 --> Loss 0.00235881984234\n",
      "Epoch 20::Minibatch 780::LR 0.0561538461538 --> Loss 0.00157776256402\n",
      "Epoch 20::Minibatch 781::LR 0.0561538461538 --> Loss 0.00344582279523\n",
      "Epoch 20::Minibatch 782::LR 0.0561538461538 --> Loss 0.00390352805456\n",
      "Epoch 20::Minibatch 783::LR 0.0561538461538 --> Loss 0.00229074180126\n",
      "Epoch 20::Minibatch 784::LR 0.0561538461538 --> Loss 0.000710145334403\n",
      "Epoch 20::Minibatch 785::LR 0.0561538461538 --> Loss 0.00332317690055\n",
      "Epoch 20::Minibatch 786::LR 0.0561538461538 --> Loss 0.00342494050662\n",
      "Epoch 20::Minibatch 787::LR 0.0561538461538 --> Loss 0.00265349924564\n",
      "Epoch 20::Minibatch 788::LR 0.0561538461538 --> Loss 0.00236836433411\n",
      "Epoch 20::Minibatch 789::LR 0.0561538461538 --> Loss 0.000734275182088\n",
      "Epoch 20::Minibatch 790::LR 0.0561538461538 --> Loss 0.00314463774363\n",
      "Epoch 20::Minibatch 791::LR 0.0561538461538 --> Loss 0.0034814675649\n",
      "Epoch 20::Minibatch 792::LR 0.0561538461538 --> Loss 0.00307397464911\n",
      "Epoch 20::Minibatch 793::LR 0.0561538461538 --> Loss 0.00173317213853\n",
      "Epoch 20::Minibatch 794::LR 0.0561538461538 --> Loss 0.00100804100434\n",
      "Epoch 20::Minibatch 795::LR 0.0561538461538 --> Loss 0.00288792967796\n",
      "Epoch 20::Minibatch 796::LR 0.0561538461538 --> Loss 0.00539020776749\n",
      "Epoch 20::Minibatch 797::LR 0.0561538461538 --> Loss 0.00675911267598\n",
      "Epoch 20::Minibatch 798::LR 0.0561538461538 --> Loss 0.00321260174115\n",
      "Epoch 20::Minibatch 799::LR 0.0561538461538 --> Loss 0.00231893142064\n",
      "Epoch 20::Minibatch 800::LR 0.0561538461538 --> Loss 0.00201472878456\n",
      "Epoch 20::Minibatch 801::LR 0.0561538461538 --> Loss 0.00411092758179\n",
      "Epoch 20::Minibatch 802::LR 0.0561538461538 --> Loss 0.00127464602391\n",
      "Epoch 20::Minibatch 803::LR 0.0561538461538 --> Loss 0.00288286546866\n",
      "Epoch 20::Minibatch 804::LR 0.0561538461538 --> Loss 0.00214033265909\n",
      "Epoch 20::Minibatch 805::LR 0.0561538461538 --> Loss 0.00224001904329\n",
      "Epoch 20::Minibatch 806::LR 0.0561538461538 --> Loss 0.00336310863495\n",
      "Epoch 20::Minibatch 807::LR 0.0561538461538 --> Loss 0.00303734123707\n",
      "Epoch 20::Minibatch 808::LR 0.0561538461538 --> Loss 0.00268281638622\n",
      "Epoch 20::Minibatch 809::LR 0.0561538461538 --> Loss 0.00351790388425\n",
      "Epoch 20::Minibatch 810::LR 0.0561538461538 --> Loss 0.00479764143626\n",
      "Epoch 20::Minibatch 811::LR 0.0561538461538 --> Loss 0.00454563379288\n",
      "Epoch 20::Minibatch 812::LR 0.0561538461538 --> Loss 0.00415837446849\n",
      "Epoch 20::Minibatch 813::LR 0.0561538461538 --> Loss 0.00363099376361\n",
      "Epoch 20::Minibatch 814::LR 0.0561538461538 --> Loss 0.00166532079379\n",
      "Epoch 20::Minibatch 815::LR 0.0561538461538 --> Loss 0.00369674007098\n",
      "Epoch 20::Minibatch 816::LR 0.0561538461538 --> Loss 0.00409783601761\n",
      "Epoch 20::Minibatch 817::LR 0.0561538461538 --> Loss 0.00545903722445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 818::LR 0.0561538461538 --> Loss 0.00126153975725\n",
      "Epoch 20::Minibatch 819::LR 0.0561538461538 --> Loss 0.000705389579137\n",
      "Epoch 20::Minibatch 820::LR 0.0561538461538 --> Loss 0.00526752710342\n",
      "Epoch 20::Minibatch 821::LR 0.0561538461538 --> Loss 0.00311342219512\n",
      "Epoch 20::Minibatch 822::LR 0.0561538461538 --> Loss 0.00369056582451\n",
      "Epoch 20::Minibatch 823::LR 0.0561538461538 --> Loss 0.00128666440646\n",
      "Epoch 20::Minibatch 824::LR 0.0561538461538 --> Loss 0.00137207438548\n",
      "Epoch 20::Minibatch 825::LR 0.0561538461538 --> Loss 0.00366263230642\n",
      "Epoch 20::Minibatch 826::LR 0.0561538461538 --> Loss 0.00401655356089\n",
      "Epoch 20::Minibatch 827::LR 0.0561538461538 --> Loss 0.00207778394222\n",
      "Epoch 20::Minibatch 828::LR 0.0561538461538 --> Loss 0.00051544174552\n",
      "Epoch 20::Minibatch 829::LR 0.0561538461538 --> Loss 0.00233785589536\n",
      "Epoch 20::Minibatch 830::LR 0.0561538461538 --> Loss 0.00426108996073\n",
      "Epoch 20::Minibatch 831::LR 0.0561538461538 --> Loss 0.00251300195853\n",
      "Epoch 20::Minibatch 832::LR 0.0561538461538 --> Loss 0.0022014037768\n",
      "Epoch 20::Minibatch 833::LR 0.0561538461538 --> Loss 0.00183526178201\n",
      "Epoch 20::Minibatch 834::LR 0.0561538461538 --> Loss 0.000774747331937\n",
      "Epoch 20::Minibatch 835::LR 0.0561538461538 --> Loss 0.00377367933591\n",
      "Epoch 20::Minibatch 836::LR 0.0561538461538 --> Loss 0.00366383393606\n",
      "Epoch 20::Minibatch 837::LR 0.0561538461538 --> Loss 0.00219369252523\n",
      "Epoch 20::Minibatch 838::LR 0.0561538461538 --> Loss 0.000630907466014\n",
      "Epoch 20::Minibatch 839::LR 0.0561538461538 --> Loss 0.00244833389918\n",
      "Epoch 20::Minibatch 840::LR 0.0561538461538 --> Loss 0.0028776905934\n",
      "Epoch 20::Minibatch 841::LR 0.0561538461538 --> Loss 0.00280376096567\n",
      "Epoch 20::Minibatch 842::LR 0.0561538461538 --> Loss 0.0020765187343\n",
      "Epoch 20::Minibatch 843::LR 0.0561538461538 --> Loss 0.000997909108798\n",
      "Epoch 20::Minibatch 844::LR 0.0561538461538 --> Loss 0.00148320416609\n",
      "Epoch 20::Minibatch 845::LR 0.0561538461538 --> Loss 0.00423900683721\n",
      "Epoch 20::Minibatch 846::LR 0.0561538461538 --> Loss 0.00166993697484\n",
      "Epoch 20::Minibatch 847::LR 0.0561538461538 --> Loss 0.00228896458944\n",
      "Epoch 20::Minibatch 848::LR 0.0561538461538 --> Loss 0.00102539261182\n",
      "Epoch 20::Minibatch 849::LR 0.0561538461538 --> Loss 0.00181720217069\n",
      "Epoch 20::Minibatch 850::LR 0.0561538461538 --> Loss 0.00316423157851\n",
      "Epoch 20::Minibatch 851::LR 0.0561538461538 --> Loss 0.00262321054935\n",
      "Epoch 20::Minibatch 852::LR 0.0561538461538 --> Loss 0.00108388115962\n",
      "Epoch 20::Minibatch 853::LR 0.0561538461538 --> Loss 0.00130253871282\n",
      "Epoch 20::Minibatch 854::LR 0.0561538461538 --> Loss 0.00256047685941\n",
      "Epoch 20::Minibatch 855::LR 0.0561538461538 --> Loss 0.00214929759502\n",
      "Epoch 20::Minibatch 856::LR 0.0561538461538 --> Loss 0.00178710182508\n",
      "Epoch 20::Minibatch 857::LR 0.0561538461538 --> Loss 0.00120937794447\n",
      "Epoch 20::Minibatch 858::LR 0.0561538461538 --> Loss 0.000593388875326\n",
      "Epoch 20::Minibatch 859::LR 0.0561538461538 --> Loss 0.00191821217537\n",
      "Epoch 20::Minibatch 860::LR 0.0561538461538 --> Loss 0.00125805000464\n",
      "Epoch 20::Minibatch 861::LR 0.0561538461538 --> Loss 0.000935795505842\n",
      "Epoch 20::Minibatch 862::LR 0.0561538461538 --> Loss 0.00364765286446\n",
      "Epoch 20::Minibatch 863::LR 0.0561538461538 --> Loss 0.00339720408122\n",
      "Epoch 20::Minibatch 864::LR 0.0561538461538 --> Loss 0.00279511054357\n",
      "Epoch 20::Minibatch 865::LR 0.0561538461538 --> Loss 0.000443244129419\n",
      "Epoch 20::Minibatch 866::LR 0.0561538461538 --> Loss 0.00212184806665\n",
      "Epoch 20::Minibatch 867::LR 0.0561538461538 --> Loss 0.00293719112873\n",
      "Epoch 20::Minibatch 868::LR 0.0561538461538 --> Loss 0.00241985897223\n",
      "Epoch 20::Minibatch 869::LR 0.0561538461538 --> Loss 0.00210988124212\n",
      "Epoch 20::Minibatch 870::LR 0.0561538461538 --> Loss 0.00346122105916\n",
      "Epoch 20::Minibatch 871::LR 0.0561538461538 --> Loss 0.0015419831872\n",
      "Epoch 20::Minibatch 872::LR 0.0561538461538 --> Loss 0.00223264892896\n",
      "Epoch 20::Minibatch 873::LR 0.0561538461538 --> Loss 0.00246458133062\n",
      "Epoch 20::Minibatch 874::LR 0.0561538461538 --> Loss 0.00593937397003\n",
      "Epoch 20::Minibatch 875::LR 0.0561538461538 --> Loss 0.000534900476535\n",
      "Epoch 20::Minibatch 876::LR 0.0561538461538 --> Loss 0.00305630842845\n",
      "Epoch 20::Minibatch 877::LR 0.0561538461538 --> Loss 0.00553983211517\n",
      "Epoch 20::Minibatch 878::LR 0.0561538461538 --> Loss 0.00316529770692\n",
      "Epoch 20::Minibatch 879::LR 0.0561538461538 --> Loss 0.00398084044456\n",
      "Epoch 20::Minibatch 880::LR 0.0561538461538 --> Loss 0.00481287240982\n",
      "Epoch 20::Minibatch 881::LR 0.0561538461538 --> Loss 0.00426930030187\n",
      "Epoch 20::Minibatch 882::LR 0.0561538461538 --> Loss 0.00195452213287\n",
      "Epoch 20::Minibatch 883::LR 0.0561538461538 --> Loss 0.00345356146495\n",
      "Epoch 20::Minibatch 884::LR 0.0561538461538 --> Loss 0.00271811664104\n",
      "Epoch 20::Minibatch 885::LR 0.0561538461538 --> Loss 0.00254210670789\n",
      "Epoch 20::Minibatch 886::LR 0.0561538461538 --> Loss 0.000479693760475\n",
      "Epoch 20::Minibatch 887::LR 0.0561538461538 --> Loss 0.00527488032977\n",
      "Epoch 20::Minibatch 888::LR 0.0561538461538 --> Loss 0.00257183651129\n",
      "Epoch 20::Minibatch 889::LR 0.0561538461538 --> Loss 0.00274472773075\n",
      "Epoch 20::Minibatch 890::LR 0.0561538461538 --> Loss 0.00404669602712\n",
      "Epoch 20::Minibatch 891::LR 0.0561538461538 --> Loss 0.0018196918567\n",
      "Epoch 20::Minibatch 892::LR 0.0561538461538 --> Loss 0.00083964318037\n",
      "Epoch 20::Minibatch 893::LR 0.0561538461538 --> Loss 0.00239205380281\n",
      "Epoch 20::Minibatch 894::LR 0.0561538461538 --> Loss 0.00210851629575\n",
      "Epoch 20::Minibatch 895::LR 0.0561538461538 --> Loss 0.00236026704311\n",
      "Epoch 20::Minibatch 896::LR 0.0561538461538 --> Loss 0.00125230272611\n",
      "Epoch 20::Minibatch 897::LR 0.0561538461538 --> Loss 0.000699404378732\n",
      "Epoch 20::Minibatch 898::LR 0.0561538461538 --> Loss 0.00209835092227\n",
      "Epoch 20::Minibatch 899::LR 0.0561538461538 --> Loss 0.00246369918187\n",
      "Epoch 20::Minibatch 900::LR 0.0561538461538 --> Loss 0.00318510254224\n",
      "Epoch 20::Minibatch 901::LR 0.0561538461538 --> Loss 0.000588088432948\n",
      "Epoch 20::Minibatch 902::LR 0.0561538461538 --> Loss 0.0014076034228\n",
      "Epoch 20::Minibatch 903::LR 0.0561538461538 --> Loss 0.00254850745201\n",
      "Epoch 20::Minibatch 904::LR 0.0561538461538 --> Loss 0.00188733438651\n",
      "Epoch 20::Minibatch 905::LR 0.0561538461538 --> Loss 0.00142112821341\n",
      "Epoch 20::Minibatch 906::LR 0.0561538461538 --> Loss 0.00106171975533\n",
      "Epoch 20::Minibatch 907::LR 0.0561538461538 --> Loss 0.00157672504584\n",
      "Epoch 20::Minibatch 908::LR 0.0561538461538 --> Loss 0.00215050538381\n",
      "Epoch 20::Minibatch 909::LR 0.0561538461538 --> Loss 0.00198249598344\n",
      "Epoch 20::Minibatch 910::LR 0.0561538461538 --> Loss 0.000831666141748\n",
      "Epoch 20::Minibatch 911::LR 0.0561538461538 --> Loss 0.00123815099398\n",
      "Epoch 20::Minibatch 912::LR 0.0561538461538 --> Loss 0.00199795643489\n",
      "Epoch 20::Minibatch 913::LR 0.0561538461538 --> Loss 0.00217512885729\n",
      "Epoch 20::Minibatch 914::LR 0.0561538461538 --> Loss 0.00117747525374\n",
      "Epoch 20::Minibatch 915::LR 0.0561538461538 --> Loss 0.000495551923911\n",
      "Epoch 20::Minibatch 916::LR 0.0561538461538 --> Loss 0.00221523384253\n",
      "Epoch 20::Minibatch 917::LR 0.0561538461538 --> Loss 0.00366408824921\n",
      "Epoch 20::Minibatch 918::LR 0.0561538461538 --> Loss 0.00560885826747\n",
      "Epoch 20::Minibatch 919::LR 0.0561538461538 --> Loss 0.000556165079276\n",
      "Epoch 20::Minibatch 920::LR 0.0561538461538 --> Loss 0.0120285344124\n",
      "Epoch 20::Minibatch 921::LR 0.0561538461538 --> Loss 0.00282099684079\n",
      "Epoch 20::Minibatch 922::LR 0.0561538461538 --> Loss 0.00295261363188\n",
      "Epoch 20::Minibatch 923::LR 0.0561538461538 --> Loss 0.00140762577454\n",
      "Epoch 20::Minibatch 924::LR 0.0561538461538 --> Loss 0.00339848836263\n",
      "Epoch 20::Minibatch 925::LR 0.0561538461538 --> Loss 0.00230455895265\n",
      "Epoch 20::Minibatch 926::LR 0.0561538461538 --> Loss 0.00515824000041\n",
      "Epoch 20::Minibatch 927::LR 0.0561538461538 --> Loss 0.00701296011607\n",
      "Epoch 20::Minibatch 928::LR 0.0561538461538 --> Loss 0.00629146814346\n",
      "Epoch 20::Minibatch 929::LR 0.0561538461538 --> Loss 0.00633574088415\n",
      "Epoch 20::Minibatch 930::LR 0.0561538461538 --> Loss 0.0091933409373\n",
      "Epoch 20::Minibatch 931::LR 0.0561538461538 --> Loss 0.00335373838743\n",
      "Epoch 20::Minibatch 932::LR 0.0561538461538 --> Loss 0.00646687626839\n",
      "Epoch 20::Minibatch 933::LR 0.0561538461538 --> Loss 0.00316569507122\n",
      "Epoch 20::Minibatch 934::LR 0.0561538461538 --> Loss 0.0041673652331\n",
      "Epoch 20::Minibatch 935::LR 0.0561538461538 --> Loss 0.00592598080635\n",
      "Epoch 20::Minibatch 936::LR 0.0561538461538 --> Loss 0.00134255876144\n",
      "Epoch 20::Minibatch 937::LR 0.0561538461538 --> Loss 0.00307244221369\n",
      "Epoch 20::Minibatch 938::LR 0.0561538461538 --> Loss 0.0027483210961\n",
      "Epoch 20::Minibatch 939::LR 0.0561538461538 --> Loss 0.00284352084001\n",
      "Epoch 20::Minibatch 940::LR 0.0561538461538 --> Loss 0.000996537009875\n",
      "Epoch 20::Minibatch 941::LR 0.0561538461538 --> Loss 0.000819610009591\n",
      "Epoch 20::Minibatch 942::LR 0.0561538461538 --> Loss 0.00244670689106\n",
      "Epoch 20::Minibatch 943::LR 0.0561538461538 --> Loss 0.00273096203804\n",
      "Epoch 20::Minibatch 944::LR 0.0561538461538 --> Loss 0.00197217285633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20::Minibatch 945::LR 0.0561538461538 --> Loss 0.00113682111104\n",
      "Epoch 20::Minibatch 946::LR 0.0561538461538 --> Loss 0.00290771921476\n",
      "Epoch 20::Minibatch 947::LR 0.0561538461538 --> Loss 0.00261132717133\n",
      "Epoch 20::Minibatch 948::LR 0.0561538461538 --> Loss 0.00488115429878\n",
      "Epoch 20::Minibatch 949::LR 0.0561538461538 --> Loss 0.00182618141174\n",
      "Epoch 20::Minibatch 950::LR 0.0561538461538 --> Loss 0.000731033285459\n",
      "Epoch 20::Minibatch 951::LR 0.0561538461538 --> Loss 0.00338263789813\n",
      "Epoch 20::Minibatch 952::LR 0.0561538461538 --> Loss 0.00239139219125\n",
      "Epoch 20::Minibatch 953::LR 0.0561538461538 --> Loss 0.00138701150815\n",
      "Epoch 20::Minibatch 954::LR 0.0561538461538 --> Loss 0.000958136618137\n",
      "Epoch 20::Minibatch 955::LR 0.0561538461538 --> Loss 0.00252352416515\n",
      "Epoch 20::Minibatch 956::LR 0.0561538461538 --> Loss 0.00357358574867\n",
      "Epoch 20::Minibatch 957::LR 0.0561538461538 --> Loss 0.00185457468033\n",
      "Epoch 20::Minibatch 958::LR 0.0561538461538 --> Loss 0.00224678834279\n",
      "Epoch 20::Minibatch 959::LR 0.0561538461538 --> Loss 0.00275561213493\n",
      "Epoch 20::Minibatch 960::LR 0.0561538461538 --> Loss 0.00608510335286\n",
      "Epoch 20::Minibatch 961::LR 0.0561538461538 --> Loss 0.0032355984052\n",
      "Epoch 20::Minibatch 962::LR 0.0561538461538 --> Loss 0.00275044322014\n",
      "Epoch 20::Minibatch 963::LR 0.0561538461538 --> Loss 0.0010325161616\n",
      "Epoch 20::Minibatch 964::LR 0.0561538461538 --> Loss 0.00236441850662\n",
      "Epoch 20::Minibatch 965::LR 0.0561538461538 --> Loss 0.00715766986211\n",
      "Epoch 20::Minibatch 966::LR 0.0561538461538 --> Loss 0.00510388930639\n",
      "Epoch 20::Minibatch 967::LR 0.0561538461538 --> Loss 0.00146315266689\n",
      "Epoch 20::Minibatch 968::LR 0.0561538461538 --> Loss 0.00129658073187\n",
      "Epoch 20::Minibatch 969::LR 0.0561538461538 --> Loss 0.00595379630725\n",
      "Epoch 20::Minibatch 970::LR 0.0561538461538 --> Loss 0.00545893232028\n",
      "Epoch 20::Minibatch 971::LR 0.0561538461538 --> Loss 0.00344156225522\n",
      "Epoch 20::Minibatch 972::LR 0.0561538461538 --> Loss 0.00992778539658\n",
      "Epoch 20::Minibatch 973::LR 0.0561538461538 --> Loss 0.00896647930145\n",
      "Epoch 20::Minibatch 974::LR 0.0561538461538 --> Loss 0.00740654786428\n",
      "Epoch 20::Minibatch 975::LR 0.0561538461538 --> Loss 0.00451770464579\n",
      "Epoch 20::Minibatch 976::LR 0.0561538461538 --> Loss 0.00402438441912\n",
      "Epoch 20::Minibatch 977::LR 0.0561538461538 --> Loss 0.0039814388752\n",
      "Epoch 20::Minibatch 978::LR 0.0561538461538 --> Loss 0.00394384702047\n",
      "Epoch 20::Minibatch 979::LR 0.0561538461538 --> Loss 0.00385270913442\n",
      "Epoch 20::Minibatch 980::LR 0.0561538461538 --> Loss 0.0039177330335\n",
      "Epoch 20::Minibatch 981::LR 0.0561538461538 --> Loss 0.00508066852887\n",
      "Epoch 20::Minibatch 982::LR 0.0561538461538 --> Loss 0.00616939306259\n",
      "Epoch 20::Minibatch 983::LR 0.0561538461538 --> Loss 0.00291703402996\n",
      "Epoch 20::Minibatch 984::LR 0.0561538461538 --> Loss 0.00237153907617\n",
      "Epoch 20::Minibatch 985::LR 0.0561538461538 --> Loss 0.00416073322296\n",
      "Epoch 20::Minibatch 986::LR 0.0561538461538 --> Loss 0.00380681872368\n",
      "Epoch 20::Minibatch 987::LR 0.0561538461538 --> Loss 0.00408577839533\n",
      "Epoch 20::Minibatch 988::LR 0.0561538461538 --> Loss 0.00320058782895\n",
      "Epoch 20::Minibatch 989::LR 0.0561538461538 --> Loss 0.00335305015246\n",
      "Epoch 20::Minibatch 990::LR 0.0561538461538 --> Loss 0.00306409815947\n",
      "Epoch 20::Minibatch 991::LR 0.0561538461538 --> Loss 0.00161787609259\n",
      "Epoch 20::Minibatch 992::LR 0.0561538461538 --> Loss 0.00181462109089\n",
      "Epoch 20::Minibatch 993::LR 0.0561538461538 --> Loss 0.00329487522443\n",
      "Epoch 20::Minibatch 994::LR 0.0561538461538 --> Loss 0.00205289065838\n",
      "Epoch 20::Minibatch 995::LR 0.0561538461538 --> Loss 0.000841633280118\n",
      "Epoch 20::Minibatch 996::LR 0.0561538461538 --> Loss 0.00294611295064\n",
      "Epoch 20::Minibatch 997::LR 0.0561538461538 --> Loss 0.0021451040109\n",
      "Epoch 20::Minibatch 998::LR 0.0561538461538 --> Loss 0.0024093858401\n",
      "Epoch 20::Minibatch 999::LR 0.0561538461538 --> Loss 0.0020019731919\n",
      "Epoch 20::Minibatch 1000::LR 0.0561538461538 --> Loss 0.00237589677175\n",
      "Epoch 20::Minibatch 1001::LR 0.0561538461538 --> Loss 0.00189227084319\n",
      "Epoch 20::Minibatch 1002::LR 0.0561538461538 --> Loss 0.00206460614999\n",
      "Epoch 20::Minibatch 1003::LR 0.0561538461538 --> Loss 0.00317320247491\n",
      "Epoch 20::Minibatch 1004::LR 0.0561538461538 --> Loss 0.00102559268475\n",
      "Epoch 20::Minibatch 1005::LR 0.0561538461538 --> Loss 0.0032445559899\n",
      "Epoch 20::Minibatch 1006::LR 0.0561538461538 --> Loss 0.00183434387048\n",
      "Epoch 20::Minibatch 1007::LR 0.0561538461538 --> Loss 0.0022952546676\n",
      "Epoch 20::Minibatch 1008::LR 0.0561538461538 --> Loss 0.00092164148887\n",
      "Epoch 20::Minibatch 1009::LR 0.0561538461538 --> Loss 0.00140153636535\n",
      "Epoch 20::Minibatch 1010::LR 0.0561538461538 --> Loss 0.00127837707599\n",
      "Epoch 20::Minibatch 1011::LR 0.0561538461538 --> Loss 0.00247669378916\n",
      "Epoch 20::Minibatch 1012::LR 0.0561538461538 --> Loss 0.00150087644656\n",
      "Epoch 20::Minibatch 1013::LR 0.0561538461538 --> Loss 0.0040581715107\n",
      "Epoch 20::Minibatch 1014::LR 0.0561538461538 --> Loss 0.00381565888723\n",
      "Epoch 20::Minibatch 1015::LR 0.0561538461538 --> Loss 0.00160062193871\n",
      "Epoch 20::Minibatch 1016::LR 0.0561538461538 --> Loss 0.00480693896612\n",
      "Epoch 20::Minibatch 1017::LR 0.0561538461538 --> Loss 0.00336762666702\n",
      "Epoch 20::Minibatch 1018::LR 0.0561538461538 --> Loss 0.00282915532589\n",
      "Epoch 20::Minibatch 1019::LR 0.0561538461538 --> Loss 0.00191486557325\n",
      "Epoch 20::Minibatch 1020::LR 0.0561538461538 --> Loss 0.00196122189363\n",
      "Epoch 20::Minibatch 1021::LR 0.0561538461538 --> Loss 0.0020189789931\n",
      "Epoch 20::Minibatch 1022::LR 0.0561538461538 --> Loss 0.0015370875597\n",
      "Epoch 20::Minibatch 1023::LR 0.0561538461538 --> Loss 0.00117079575857\n",
      "Epoch 20::Minibatch 1024::LR 0.0561538461538 --> Loss 0.00113698969285\n",
      "Epoch 20::Minibatch 1025::LR 0.0561538461538 --> Loss 0.00141715437174\n",
      "Epoch 20::Minibatch 1026::LR 0.0561538461538 --> Loss 0.000793952743212\n",
      "Epoch 20::Minibatch 1027::LR 0.0561538461538 --> Loss 0.00102391958237\n",
      "Epoch 20::Minibatch 1028::LR 0.0561538461538 --> Loss 0.000784995307525\n",
      "Epoch 20::Minibatch 1029::LR 0.0561538461538 --> Loss 0.000770418147246\n",
      "Epoch 20::Minibatch 1030::LR 0.0561538461538 --> Loss 0.000951061745485\n",
      "Epoch 20::Minibatch 1031::LR 0.0561538461538 --> Loss 0.000744460324446\n",
      "Epoch 20::Minibatch 1032::LR 0.0561538461538 --> Loss 0.000786351511876\n",
      "Epoch 20::Minibatch 1033::LR 0.0561538461538 --> Loss 0.000665753185749\n",
      "Epoch 20::Minibatch 1034::LR 0.0561538461538 --> Loss 0.000644762913386\n",
      "Epoch 20::Minibatch 1035::LR 0.0561538461538 --> Loss 0.000442012945811\n",
      "Epoch 20::Minibatch 1036::LR 0.0561538461538 --> Loss 0.000355108181636\n",
      "Epoch 20::Minibatch 1037::LR 0.0561538461538 --> Loss 0.000586435447137\n",
      "Epoch 20::Minibatch 1038::LR 0.0561538461538 --> Loss 0.00125327289104\n",
      "Epoch 20::Minibatch 1039::LR 0.0561538461538 --> Loss 0.000969889263312\n",
      "Epoch 20::Minibatch 1040::LR 0.0561538461538 --> Loss 0.000394176120559\n",
      "Epoch 20::Minibatch 1041::LR 0.0561538461538 --> Loss 0.000562378317118\n",
      "Epoch 21::Minibatch 1::LR 0.0538461538462 --> Loss 0.00891972223918\n",
      "Epoch 21::Minibatch 2::LR 0.0538461538462 --> Loss 0.00540180921555\n",
      "Epoch 21::Minibatch 3::LR 0.0538461538462 --> Loss 0.00361149390539\n",
      "Epoch 21::Minibatch 4::LR 0.0538461538462 --> Loss 0.00412497083346\n",
      "Epoch 21::Minibatch 5::LR 0.0538461538462 --> Loss 0.00462660908699\n",
      "Epoch 21::Minibatch 6::LR 0.0538461538462 --> Loss 0.0022950108846\n",
      "Epoch 21::Minibatch 7::LR 0.0538461538462 --> Loss 0.007527059714\n",
      "Epoch 21::Minibatch 8::LR 0.0538461538462 --> Loss 0.00712612549464\n",
      "Epoch 21::Minibatch 9::LR 0.0538461538462 --> Loss 0.00528798341751\n",
      "Epoch 21::Minibatch 10::LR 0.0538461538462 --> Loss 0.00263755440712\n",
      "Epoch 21::Minibatch 11::LR 0.0538461538462 --> Loss 0.00234616716703\n",
      "Epoch 21::Minibatch 12::LR 0.0538461538462 --> Loss 0.00343537449837\n",
      "Epoch 21::Minibatch 13::LR 0.0538461538462 --> Loss 0.00522240360578\n",
      "Epoch 21::Minibatch 14::LR 0.0538461538462 --> Loss 0.00523958086967\n",
      "Epoch 21::Minibatch 15::LR 0.0538461538462 --> Loss 0.0044306063652\n",
      "Epoch 21::Minibatch 16::LR 0.0538461538462 --> Loss 0.000814393709103\n",
      "Epoch 21::Minibatch 17::LR 0.0538461538462 --> Loss 0.00307804803054\n",
      "Epoch 21::Minibatch 18::LR 0.0538461538462 --> Loss 0.00255139966806\n",
      "Epoch 21::Minibatch 19::LR 0.0538461538462 --> Loss 0.00137485057116\n",
      "Epoch 21::Minibatch 20::LR 0.0538461538462 --> Loss 0.00185690601667\n",
      "Epoch 21::Minibatch 21::LR 0.0538461538462 --> Loss 0.0032937369744\n",
      "Epoch 21::Minibatch 22::LR 0.0538461538462 --> Loss 0.00226059913635\n",
      "Epoch 21::Minibatch 23::LR 0.0538461538462 --> Loss 0.00079809114337\n",
      "Epoch 21::Minibatch 24::LR 0.0538461538462 --> Loss 0.000397204806407\n",
      "Epoch 21::Minibatch 25::LR 0.0538461538462 --> Loss 0.00115405490001\n",
      "Epoch 21::Minibatch 26::LR 0.0538461538462 --> Loss 0.00136114994685\n",
      "Epoch 21::Minibatch 27::LR 0.0538461538462 --> Loss 0.000955336491267\n",
      "Epoch 21::Minibatch 28::LR 0.0538461538462 --> Loss 0.000407426009576\n",
      "Epoch 21::Minibatch 29::LR 0.0538461538462 --> Loss 0.000422033419212\n",
      "Epoch 21::Minibatch 30::LR 0.0538461538462 --> Loss 0.000895985265573\n",
      "Epoch 21::Minibatch 31::LR 0.0538461538462 --> Loss 0.00138495743275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 32::LR 0.0538461538462 --> Loss 0.00127916465203\n",
      "Epoch 21::Minibatch 33::LR 0.0538461538462 --> Loss 0.000777896791697\n",
      "Epoch 21::Minibatch 34::LR 0.0538461538462 --> Loss 0.00218384663264\n",
      "Epoch 21::Minibatch 35::LR 0.0538461538462 --> Loss 0.00378544767698\n",
      "Epoch 21::Minibatch 36::LR 0.0538461538462 --> Loss 0.00227700193723\n",
      "Epoch 21::Minibatch 37::LR 0.0538461538462 --> Loss 0.000652233113845\n",
      "Epoch 21::Minibatch 38::LR 0.0538461538462 --> Loss 0.00072860494256\n",
      "Epoch 21::Minibatch 39::LR 0.0538461538462 --> Loss 0.00233429769675\n",
      "Epoch 21::Minibatch 40::LR 0.0538461538462 --> Loss 0.00330900390943\n",
      "Epoch 21::Minibatch 41::LR 0.0538461538462 --> Loss 0.00269394477208\n",
      "Epoch 21::Minibatch 42::LR 0.0538461538462 --> Loss 0.00565515875816\n",
      "Epoch 21::Minibatch 43::LR 0.0538461538462 --> Loss 0.00188639640808\n",
      "Epoch 21::Minibatch 44::LR 0.0538461538462 --> Loss 0.00311702092489\n",
      "Epoch 21::Minibatch 45::LR 0.0538461538462 --> Loss 0.00242961068948\n",
      "Epoch 21::Minibatch 46::LR 0.0538461538462 --> Loss 0.00330674250921\n",
      "Epoch 21::Minibatch 47::LR 0.0538461538462 --> Loss 0.00409632444382\n",
      "Epoch 21::Minibatch 48::LR 0.0538461538462 --> Loss 0.00562151352564\n",
      "Epoch 21::Minibatch 49::LR 0.0538461538462 --> Loss 0.00603048801422\n",
      "Epoch 21::Minibatch 50::LR 0.0538461538462 --> Loss 0.00609801411629\n",
      "Epoch 21::Minibatch 51::LR 0.0538461538462 --> Loss 0.00607054193815\n",
      "Epoch 21::Minibatch 52::LR 0.0538461538462 --> Loss 0.00344979008039\n",
      "Epoch 21::Minibatch 53::LR 0.0538461538462 --> Loss 0.00340344508489\n",
      "Epoch 21::Minibatch 54::LR 0.0538461538462 --> Loss 0.00402167161306\n",
      "Epoch 21::Minibatch 55::LR 0.0538461538462 --> Loss 0.000985385378202\n",
      "Epoch 21::Minibatch 56::LR 0.0538461538462 --> Loss 0.00269149363041\n",
      "Epoch 21::Minibatch 57::LR 0.0538461538462 --> Loss 0.00526892940203\n",
      "Epoch 21::Minibatch 58::LR 0.0538461538462 --> Loss 0.00329833328724\n",
      "Epoch 21::Minibatch 59::LR 0.0538461538462 --> Loss 0.00243811527888\n",
      "Epoch 21::Minibatch 60::LR 0.0538461538462 --> Loss 0.00238347311815\n",
      "Epoch 21::Minibatch 61::LR 0.0538461538462 --> Loss 0.000818133751551\n",
      "Epoch 21::Minibatch 62::LR 0.0538461538462 --> Loss 0.00294830342134\n",
      "Epoch 21::Minibatch 63::LR 0.0538461538462 --> Loss 0.00205315550168\n",
      "Epoch 21::Minibatch 64::LR 0.0538461538462 --> Loss 0.00087432205677\n",
      "Epoch 21::Minibatch 65::LR 0.0538461538462 --> Loss 0.00228939056396\n",
      "Epoch 21::Minibatch 66::LR 0.0538461538462 --> Loss 0.00276571631432\n",
      "Epoch 21::Minibatch 67::LR 0.0538461538462 --> Loss 0.00269830604394\n",
      "Epoch 21::Minibatch 68::LR 0.0538461538462 --> Loss 0.00193482180436\n",
      "Epoch 21::Minibatch 69::LR 0.0538461538462 --> Loss 0.00387907505035\n",
      "Epoch 21::Minibatch 70::LR 0.0538461538462 --> Loss 0.00336767276128\n",
      "Epoch 21::Minibatch 71::LR 0.0538461538462 --> Loss 0.00230299393336\n",
      "Epoch 21::Minibatch 72::LR 0.0538461538462 --> Loss 0.000543211450179\n",
      "Epoch 21::Minibatch 73::LR 0.0538461538462 --> Loss 0.00386734724045\n",
      "Epoch 21::Minibatch 74::LR 0.0538461538462 --> Loss 0.00411066333453\n",
      "Epoch 21::Minibatch 75::LR 0.0538461538462 --> Loss 0.00233605742455\n",
      "Epoch 21::Minibatch 76::LR 0.0538461538462 --> Loss 0.00055820475022\n",
      "Epoch 21::Minibatch 77::LR 0.0538461538462 --> Loss 0.00369518319766\n",
      "Epoch 21::Minibatch 78::LR 0.0538461538462 --> Loss 0.0038497487704\n",
      "Epoch 21::Minibatch 79::LR 0.0538461538462 --> Loss 0.00189381758372\n",
      "Epoch 21::Minibatch 80::LR 0.0538461538462 --> Loss 0.00313305755456\n",
      "Epoch 21::Minibatch 81::LR 0.0538461538462 --> Loss 0.0027188851436\n",
      "Epoch 21::Minibatch 82::LR 0.0538461538462 --> Loss 0.0019659280777\n",
      "Epoch 21::Minibatch 83::LR 0.0538461538462 --> Loss 0.00440471212069\n",
      "Epoch 21::Minibatch 84::LR 0.0538461538462 --> Loss 0.0019612044096\n",
      "Epoch 21::Minibatch 85::LR 0.0538461538462 --> Loss 0.00270645697912\n",
      "Epoch 21::Minibatch 86::LR 0.0538461538462 --> Loss 0.00218511164188\n",
      "Epoch 21::Minibatch 87::LR 0.0538461538462 --> Loss 0.00239941457907\n",
      "Epoch 21::Minibatch 88::LR 0.0538461538462 --> Loss 0.0017567127943\n",
      "Epoch 21::Minibatch 89::LR 0.0538461538462 --> Loss 0.00229275683562\n",
      "Epoch 21::Minibatch 90::LR 0.0538461538462 --> Loss 0.00108789632718\n",
      "Epoch 21::Minibatch 91::LR 0.0538461538462 --> Loss 0.00087847640117\n",
      "Epoch 21::Minibatch 92::LR 0.0538461538462 --> Loss 0.00266578396161\n",
      "Epoch 21::Minibatch 93::LR 0.0538461538462 --> Loss 0.00174529194832\n",
      "Epoch 21::Minibatch 94::LR 0.0538461538462 --> Loss 0.00175299028556\n",
      "Epoch 21::Minibatch 95::LR 0.0538461538462 --> Loss 0.00183440963427\n",
      "Epoch 21::Minibatch 96::LR 0.0538461538462 --> Loss 0.00552550037702\n",
      "Epoch 21::Minibatch 97::LR 0.0538461538462 --> Loss 0.00311920682589\n",
      "Epoch 21::Minibatch 98::LR 0.0538461538462 --> Loss 0.00100650151571\n",
      "Epoch 21::Minibatch 99::LR 0.0538461538462 --> Loss 0.00133035391569\n",
      "Epoch 21::Minibatch 100::LR 0.0538461538462 --> Loss 0.00489953239759\n",
      "Epoch 21::Minibatch 101::LR 0.0538461538462 --> Loss 0.000918712218602\n",
      "Epoch 21::Minibatch 102::LR 0.0538461538462 --> Loss 0.00388789534569\n",
      "Epoch 21::Minibatch 103::LR 0.0538461538462 --> Loss 0.00399955272675\n",
      "Epoch 21::Minibatch 104::LR 0.0538461538462 --> Loss 0.00273979524771\n",
      "Epoch 21::Minibatch 105::LR 0.0538461538462 --> Loss 0.00251476248105\n",
      "Epoch 21::Minibatch 106::LR 0.0538461538462 --> Loss 0.0168591483434\n",
      "Epoch 21::Minibatch 107::LR 0.0538461538462 --> Loss 0.00485609610875\n",
      "Epoch 21::Minibatch 108::LR 0.0538461538462 --> Loss 0.00101921051741\n",
      "Epoch 21::Minibatch 109::LR 0.0538461538462 --> Loss 0.00433468341827\n",
      "Epoch 21::Minibatch 110::LR 0.0538461538462 --> Loss 0.0023373478651\n",
      "Epoch 21::Minibatch 111::LR 0.0538461538462 --> Loss 0.000916560788949\n",
      "Epoch 21::Minibatch 112::LR 0.0538461538462 --> Loss 0.0034756676356\n",
      "Epoch 21::Minibatch 113::LR 0.0538461538462 --> Loss 0.00258427123229\n",
      "Epoch 21::Minibatch 114::LR 0.0538461538462 --> Loss 0.0014323609074\n",
      "Epoch 21::Minibatch 115::LR 0.0538461538462 --> Loss 0.00127921700478\n",
      "Epoch 21::Minibatch 116::LR 0.0538461538462 --> Loss 0.00273071448008\n",
      "Epoch 21::Minibatch 117::LR 0.0538461538462 --> Loss 0.00386541088422\n",
      "Epoch 21::Minibatch 118::LR 0.0538461538462 --> Loss 0.00683531522751\n",
      "Epoch 21::Minibatch 119::LR 0.0538461538462 --> Loss 0.000606652249893\n",
      "Epoch 21::Minibatch 120::LR 0.0538461538462 --> Loss 0.00172816216946\n",
      "Epoch 21::Minibatch 121::LR 0.0538461538462 --> Loss 0.00257832189401\n",
      "Epoch 21::Minibatch 122::LR 0.0538461538462 --> Loss 0.00372740149498\n",
      "Epoch 21::Minibatch 123::LR 0.0538461538462 --> Loss 0.000930740833282\n",
      "Epoch 21::Minibatch 124::LR 0.0538461538462 --> Loss 0.00272009670734\n",
      "Epoch 21::Minibatch 125::LR 0.0538461538462 --> Loss 0.00457431038221\n",
      "Epoch 21::Minibatch 126::LR 0.0538461538462 --> Loss 0.00265579064687\n",
      "Epoch 21::Minibatch 127::LR 0.0538461538462 --> Loss 0.0044757437706\n",
      "Epoch 21::Minibatch 128::LR 0.0538461538462 --> Loss 0.00359631896019\n",
      "Epoch 21::Minibatch 129::LR 0.0538461538462 --> Loss 0.00263607998689\n",
      "Epoch 21::Minibatch 130::LR 0.0538461538462 --> Loss 0.00435110211372\n",
      "Epoch 21::Minibatch 131::LR 0.0538461538462 --> Loss 0.00177458743254\n",
      "Epoch 21::Minibatch 132::LR 0.0538461538462 --> Loss 0.00302284340064\n",
      "Epoch 21::Minibatch 133::LR 0.0538461538462 --> Loss 0.0028739609321\n",
      "Epoch 21::Minibatch 134::LR 0.0538461538462 --> Loss 0.00230266491572\n",
      "Epoch 21::Minibatch 135::LR 0.0538461538462 --> Loss 0.00150277495384\n",
      "Epoch 21::Minibatch 136::LR 0.0538461538462 --> Loss 0.00264715969563\n",
      "Epoch 21::Minibatch 137::LR 0.0538461538462 --> Loss 0.00361901799838\n",
      "Epoch 21::Minibatch 138::LR 0.0538461538462 --> Loss 0.00128741562366\n",
      "Epoch 21::Minibatch 139::LR 0.0538461538462 --> Loss 0.00191155493259\n",
      "Epoch 21::Minibatch 140::LR 0.0538461538462 --> Loss 0.00245362838109\n",
      "Epoch 21::Minibatch 141::LR 0.0538461538462 --> Loss 0.00296261449655\n",
      "Epoch 21::Minibatch 142::LR 0.0538461538462 --> Loss 0.00282099922498\n",
      "Epoch 21::Minibatch 143::LR 0.0538461538462 --> Loss 0.000592192858458\n",
      "Epoch 21::Minibatch 144::LR 0.0538461538462 --> Loss 0.00326381504536\n",
      "Epoch 21::Minibatch 145::LR 0.0538461538462 --> Loss 0.00427293340365\n",
      "Epoch 21::Minibatch 146::LR 0.0538461538462 --> Loss 0.00256268719832\n",
      "Epoch 21::Minibatch 147::LR 0.0538461538462 --> Loss 0.00181157390277\n",
      "Epoch 21::Minibatch 148::LR 0.0538461538462 --> Loss 0.0010051732262\n",
      "Epoch 21::Minibatch 149::LR 0.0538461538462 --> Loss 0.00284032245477\n",
      "Epoch 21::Minibatch 150::LR 0.0538461538462 --> Loss 0.00270993590355\n",
      "Epoch 21::Minibatch 151::LR 0.0538461538462 --> Loss 0.00425282478333\n",
      "Epoch 21::Minibatch 152::LR 0.0538461538462 --> Loss 0.000918392936389\n",
      "Epoch 21::Minibatch 153::LR 0.0538461538462 --> Loss 0.00178111632665\n",
      "Epoch 21::Minibatch 154::LR 0.0538461538462 --> Loss 0.00204908708731\n",
      "Epoch 21::Minibatch 155::LR 0.0538461538462 --> Loss 0.00435797890027\n",
      "Epoch 21::Minibatch 156::LR 0.0538461538462 --> Loss 0.00239059388638\n",
      "Epoch 21::Minibatch 157::LR 0.0538461538462 --> Loss 0.000698667019606\n",
      "Epoch 21::Minibatch 158::LR 0.0538461538462 --> Loss 0.00308724741141\n",
      "Epoch 21::Minibatch 159::LR 0.0538461538462 --> Loss 0.00275007327398\n",
      "Epoch 21::Minibatch 160::LR 0.0538461538462 --> Loss 0.00263349334399\n",
      "Epoch 21::Minibatch 161::LR 0.0538461538462 --> Loss 0.00101824730635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 162::LR 0.0538461538462 --> Loss 0.00380132436752\n",
      "Epoch 21::Minibatch 163::LR 0.0538461538462 --> Loss 0.0023987309138\n",
      "Epoch 21::Minibatch 164::LR 0.0538461538462 --> Loss 0.00250285863876\n",
      "Epoch 21::Minibatch 165::LR 0.0538461538462 --> Loss 0.000523301810026\n",
      "Epoch 21::Minibatch 166::LR 0.0538461538462 --> Loss 0.00177248477936\n",
      "Epoch 21::Minibatch 167::LR 0.0538461538462 --> Loss 0.00246235132217\n",
      "Epoch 21::Minibatch 168::LR 0.0538461538462 --> Loss 0.00217652738094\n",
      "Epoch 21::Minibatch 169::LR 0.0538461538462 --> Loss 0.00101080814997\n",
      "Epoch 21::Minibatch 170::LR 0.0538461538462 --> Loss 0.000983944733938\n",
      "Epoch 21::Minibatch 171::LR 0.0538461538462 --> Loss 0.0025049507618\n",
      "Epoch 21::Minibatch 172::LR 0.0538461538462 --> Loss 0.00439691940943\n",
      "Epoch 21::Minibatch 173::LR 0.0538461538462 --> Loss 0.00195327877998\n",
      "Epoch 21::Minibatch 174::LR 0.0538461538462 --> Loss 0.00102681269248\n",
      "Epoch 21::Minibatch 175::LR 0.0538461538462 --> Loss 0.00231505095959\n",
      "Epoch 21::Minibatch 176::LR 0.0538461538462 --> Loss 0.00323054015636\n",
      "Epoch 21::Minibatch 177::LR 0.0538461538462 --> Loss 0.00451024691264\n",
      "Epoch 21::Minibatch 178::LR 0.0538461538462 --> Loss 0.0016056278348\n",
      "Epoch 21::Minibatch 179::LR 0.0538461538462 --> Loss 0.00131490141153\n",
      "Epoch 21::Minibatch 180::LR 0.0538461538462 --> Loss 0.00353295445442\n",
      "Epoch 21::Minibatch 181::LR 0.0538461538462 --> Loss 0.00321512202422\n",
      "Epoch 21::Minibatch 182::LR 0.0538461538462 --> Loss 0.00076052342852\n",
      "Epoch 21::Minibatch 183::LR 0.0538461538462 --> Loss 0.00165985504786\n",
      "Epoch 21::Minibatch 184::LR 0.0538461538462 --> Loss 0.00343552470207\n",
      "Epoch 21::Minibatch 185::LR 0.0538461538462 --> Loss 0.00279599765937\n",
      "Epoch 21::Minibatch 186::LR 0.0538461538462 --> Loss 0.000967813034852\n",
      "Epoch 21::Minibatch 187::LR 0.0538461538462 --> Loss 0.00126801451047\n",
      "Epoch 21::Minibatch 188::LR 0.0538461538462 --> Loss 0.00416615009308\n",
      "Epoch 21::Minibatch 189::LR 0.0538461538462 --> Loss 0.00437132676442\n",
      "Epoch 21::Minibatch 190::LR 0.0538461538462 --> Loss 0.00232479254405\n",
      "Epoch 21::Minibatch 191::LR 0.0538461538462 --> Loss 0.000471608589093\n",
      "Epoch 21::Minibatch 192::LR 0.0538461538462 --> Loss 0.00272897024949\n",
      "Epoch 21::Minibatch 193::LR 0.0538461538462 --> Loss 0.00259168366591\n",
      "Epoch 21::Minibatch 194::LR 0.0538461538462 --> Loss 0.00177594403426\n",
      "Epoch 21::Minibatch 195::LR 0.0538461538462 --> Loss 0.000381719345848\n",
      "Epoch 21::Minibatch 196::LR 0.0538461538462 --> Loss 0.00125206440687\n",
      "Epoch 21::Minibatch 197::LR 0.0538461538462 --> Loss 0.00288504978021\n",
      "Epoch 21::Minibatch 198::LR 0.0538461538462 --> Loss 0.00222479561965\n",
      "Epoch 21::Minibatch 199::LR 0.0538461538462 --> Loss 0.000286219765743\n",
      "Epoch 21::Minibatch 200::LR 0.0538461538462 --> Loss 0.00205482641856\n",
      "Epoch 21::Minibatch 201::LR 0.0538461538462 --> Loss 0.0019485449791\n",
      "Epoch 21::Minibatch 202::LR 0.0538461538462 --> Loss 0.00185745477676\n",
      "Epoch 21::Minibatch 203::LR 0.0538461538462 --> Loss 0.0017580695947\n",
      "Epoch 21::Minibatch 204::LR 0.0538461538462 --> Loss 0.00144366224607\n",
      "Epoch 21::Minibatch 205::LR 0.0538461538462 --> Loss 0.00220464328925\n",
      "Epoch 21::Minibatch 206::LR 0.0538461538462 --> Loss 0.00624156514804\n",
      "Epoch 21::Minibatch 207::LR 0.0538461538462 --> Loss 0.0013948054115\n",
      "Epoch 21::Minibatch 208::LR 0.0538461538462 --> Loss 0.0011204157273\n",
      "Epoch 21::Minibatch 209::LR 0.0538461538462 --> Loss 0.0022603537639\n",
      "Epoch 21::Minibatch 210::LR 0.0538461538462 --> Loss 0.00215823491414\n",
      "Epoch 21::Minibatch 211::LR 0.0538461538462 --> Loss 0.00235335012277\n",
      "Epoch 21::Minibatch 212::LR 0.0538461538462 --> Loss 0.0039363582929\n",
      "Epoch 21::Minibatch 213::LR 0.0538461538462 --> Loss 0.00577032605807\n",
      "Epoch 21::Minibatch 214::LR 0.0538461538462 --> Loss 0.00869352261225\n",
      "Epoch 21::Minibatch 215::LR 0.0538461538462 --> Loss 0.00137786448002\n",
      "Epoch 21::Minibatch 216::LR 0.0538461538462 --> Loss 0.00546133478483\n",
      "Epoch 21::Minibatch 217::LR 0.0538461538462 --> Loss 0.00611583511035\n",
      "Epoch 21::Minibatch 218::LR 0.0538461538462 --> Loss 0.00393657128016\n",
      "Epoch 21::Minibatch 219::LR 0.0538461538462 --> Loss 0.00418975075086\n",
      "Epoch 21::Minibatch 220::LR 0.0538461538462 --> Loss 0.00447703719139\n",
      "Epoch 21::Minibatch 221::LR 0.0538461538462 --> Loss 0.00425074974696\n",
      "Epoch 21::Minibatch 222::LR 0.0538461538462 --> Loss 0.00323360482852\n",
      "Epoch 21::Minibatch 223::LR 0.0538461538462 --> Loss 0.00140956054131\n",
      "Epoch 21::Minibatch 224::LR 0.0538461538462 --> Loss 0.00171869913737\n",
      "Epoch 21::Minibatch 225::LR 0.0538461538462 --> Loss 0.00738778352737\n",
      "Epoch 21::Minibatch 226::LR 0.0538461538462 --> Loss 0.00376599947611\n",
      "Epoch 21::Minibatch 227::LR 0.0538461538462 --> Loss 0.00168964803219\n",
      "Epoch 21::Minibatch 228::LR 0.0538461538462 --> Loss 0.000721178452174\n",
      "Epoch 21::Minibatch 229::LR 0.0538461538462 --> Loss 0.00476744691531\n",
      "Epoch 21::Minibatch 230::LR 0.0538461538462 --> Loss 0.0038888045152\n",
      "Epoch 21::Minibatch 231::LR 0.0538461538462 --> Loss 0.00264876504739\n",
      "Epoch 21::Minibatch 232::LR 0.0538461538462 --> Loss 0.00120393584172\n",
      "Epoch 21::Minibatch 233::LR 0.0538461538462 --> Loss 0.00243148783843\n",
      "Epoch 21::Minibatch 234::LR 0.0538461538462 --> Loss 0.00701250553131\n",
      "Epoch 21::Minibatch 235::LR 0.0538461538462 --> Loss 0.004671296676\n",
      "Epoch 21::Minibatch 236::LR 0.0538461538462 --> Loss 0.00174529413382\n",
      "Epoch 21::Minibatch 237::LR 0.0538461538462 --> Loss 0.000663639803727\n",
      "Epoch 21::Minibatch 238::LR 0.0538461538462 --> Loss 0.0034150604407\n",
      "Epoch 21::Minibatch 239::LR 0.0538461538462 --> Loss 0.00296072880427\n",
      "Epoch 21::Minibatch 240::LR 0.0538461538462 --> Loss 0.00324312984943\n",
      "Epoch 21::Minibatch 241::LR 0.0538461538462 --> Loss 0.000758863588174\n",
      "Epoch 21::Minibatch 242::LR 0.0538461538462 --> Loss 0.00697793563207\n",
      "Epoch 21::Minibatch 243::LR 0.0538461538462 --> Loss 0.00345952510834\n",
      "Epoch 21::Minibatch 244::LR 0.0538461538462 --> Loss 0.00289737939835\n",
      "Epoch 21::Minibatch 245::LR 0.0538461538462 --> Loss 0.0004662827154\n",
      "Epoch 21::Minibatch 246::LR 0.0538461538462 --> Loss 0.00203336397807\n",
      "Epoch 21::Minibatch 247::LR 0.0538461538462 --> Loss 0.0124517337481\n",
      "Epoch 21::Minibatch 248::LR 0.0538461538462 --> Loss 0.00445590138435\n",
      "Epoch 21::Minibatch 249::LR 0.0538461538462 --> Loss 0.00263932943344\n",
      "Epoch 21::Minibatch 250::LR 0.0538461538462 --> Loss 0.00252832174301\n",
      "Epoch 21::Minibatch 251::LR 0.0538461538462 --> Loss 0.00247650365035\n",
      "Epoch 21::Minibatch 252::LR 0.0538461538462 --> Loss 0.00174663861593\n",
      "Epoch 21::Minibatch 253::LR 0.0538461538462 --> Loss 0.00303046325843\n",
      "Epoch 21::Minibatch 254::LR 0.0538461538462 --> Loss 0.00507910609245\n",
      "Epoch 21::Minibatch 255::LR 0.0538461538462 --> Loss 0.0038397594293\n",
      "Epoch 21::Minibatch 256::LR 0.0538461538462 --> Loss 0.00158669004838\n",
      "Epoch 21::Minibatch 257::LR 0.0538461538462 --> Loss 0.00120707223813\n",
      "Epoch 21::Minibatch 258::LR 0.0538461538462 --> Loss 0.00363676826159\n",
      "Epoch 21::Minibatch 259::LR 0.0538461538462 --> Loss 0.00174810290337\n",
      "Epoch 21::Minibatch 260::LR 0.0538461538462 --> Loss 0.00187769432863\n",
      "Epoch 21::Minibatch 261::LR 0.0538461538462 --> Loss 0.00281012455622\n",
      "Epoch 21::Minibatch 262::LR 0.0538461538462 --> Loss 0.00190301795801\n",
      "Epoch 21::Minibatch 263::LR 0.0538461538462 --> Loss 0.00235600749652\n",
      "Epoch 21::Minibatch 264::LR 0.0538461538462 --> Loss 0.00362529754639\n",
      "Epoch 21::Minibatch 265::LR 0.0538461538462 --> Loss 0.0101376835505\n",
      "Epoch 21::Minibatch 266::LR 0.0538461538462 --> Loss 0.000984791417917\n",
      "Epoch 21::Minibatch 267::LR 0.0538461538462 --> Loss 0.00980553468068\n",
      "Epoch 21::Minibatch 268::LR 0.0538461538462 --> Loss 0.001150679787\n",
      "Epoch 21::Minibatch 269::LR 0.0538461538462 --> Loss 0.00352601687113\n",
      "Epoch 21::Minibatch 270::LR 0.0538461538462 --> Loss 0.00678627173106\n",
      "Epoch 21::Minibatch 271::LR 0.0538461538462 --> Loss 0.00264255682627\n",
      "Epoch 21::Minibatch 272::LR 0.0538461538462 --> Loss 0.00419714689255\n",
      "Epoch 21::Minibatch 273::LR 0.0538461538462 --> Loss 0.00160004595915\n",
      "Epoch 21::Minibatch 274::LR 0.0538461538462 --> Loss 0.00178993662198\n",
      "Epoch 21::Minibatch 275::LR 0.0538461538462 --> Loss 0.00260997871558\n",
      "Epoch 21::Minibatch 276::LR 0.0538461538462 --> Loss 0.00344339251518\n",
      "Epoch 21::Minibatch 277::LR 0.0538461538462 --> Loss 0.000968852440516\n",
      "Epoch 21::Minibatch 278::LR 0.0538461538462 --> Loss 0.00261437972387\n",
      "Epoch 21::Minibatch 279::LR 0.0538461538462 --> Loss 0.00228695829709\n",
      "Epoch 21::Minibatch 280::LR 0.0538461538462 --> Loss 0.00199703852336\n",
      "Epoch 21::Minibatch 281::LR 0.0538461538462 --> Loss 0.00125916282336\n",
      "Epoch 21::Minibatch 282::LR 0.0538461538462 --> Loss 0.00218287408352\n",
      "Epoch 21::Minibatch 283::LR 0.0538461538462 --> Loss 0.00212032675743\n",
      "Epoch 21::Minibatch 284::LR 0.0538461538462 --> Loss 0.00170029699802\n",
      "Epoch 21::Minibatch 285::LR 0.0538461538462 --> Loss 0.00119811405738\n",
      "Epoch 21::Minibatch 286::LR 0.0538461538462 --> Loss 0.00210559924444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 287::LR 0.0538461538462 --> Loss 0.00205169399579\n",
      "Epoch 21::Minibatch 288::LR 0.0538461538462 --> Loss 0.00110743274291\n",
      "Epoch 21::Minibatch 289::LR 0.0538461538462 --> Loss 0.00159881452719\n",
      "Epoch 21::Minibatch 290::LR 0.0538461538462 --> Loss 0.00192943811417\n",
      "Epoch 21::Minibatch 291::LR 0.0538461538462 --> Loss 0.00171877841155\n",
      "Epoch 21::Minibatch 292::LR 0.0538461538462 --> Loss 0.000603492110968\n",
      "Epoch 21::Minibatch 293::LR 0.0538461538462 --> Loss 0.00149986515443\n",
      "Epoch 21::Minibatch 294::LR 0.0538461538462 --> Loss 0.00158452610175\n",
      "Epoch 21::Minibatch 295::LR 0.0538461538462 --> Loss 0.00187262137731\n",
      "Epoch 21::Minibatch 296::LR 0.0538461538462 --> Loss 0.0016236598293\n",
      "Epoch 21::Minibatch 297::LR 0.0538461538462 --> Loss 0.00140957812468\n",
      "Epoch 21::Minibatch 298::LR 0.0538461538462 --> Loss 0.00139899283648\n",
      "Epoch 21::Minibatch 299::LR 0.0538461538462 --> Loss 0.000802436570326\n",
      "Epoch 21::Minibatch 300::LR 0.0538461538462 --> Loss 0.00277992228667\n",
      "Epoch 21::Minibatch 301::LR 0.0538461538462 --> Loss 0.00269454320272\n",
      "Epoch 21::Minibatch 302::LR 0.0538461538462 --> Loss 0.00247420052687\n",
      "Epoch 21::Minibatch 303::LR 0.0538461538462 --> Loss 0.000855359733105\n",
      "Epoch 21::Minibatch 304::LR 0.0538461538462 --> Loss 0.00306613047918\n",
      "Epoch 21::Minibatch 305::LR 0.0538461538462 --> Loss 0.00169709205627\n",
      "Epoch 21::Minibatch 306::LR 0.0538461538462 --> Loss 0.000934981107712\n",
      "Epoch 21::Minibatch 307::LR 0.0538461538462 --> Loss 0.00244748433431\n",
      "Epoch 21::Minibatch 308::LR 0.0538461538462 --> Loss 0.00200279533863\n",
      "Epoch 21::Minibatch 309::LR 0.0538461538462 --> Loss 0.00101488431295\n",
      "Epoch 21::Minibatch 310::LR 0.0538461538462 --> Loss 0.0011433827877\n",
      "Epoch 21::Minibatch 311::LR 0.0538461538462 --> Loss 0.00174747109413\n",
      "Epoch 21::Minibatch 312::LR 0.0538461538462 --> Loss 0.00292291045189\n",
      "Epoch 21::Minibatch 313::LR 0.0538461538462 --> Loss 0.00238460659981\n",
      "Epoch 21::Minibatch 314::LR 0.0538461538462 --> Loss 0.00191924432913\n",
      "Epoch 21::Minibatch 315::LR 0.0538461538462 --> Loss 0.00101331710815\n",
      "Epoch 21::Minibatch 316::LR 0.0538461538462 --> Loss 0.00233359634876\n",
      "Epoch 21::Minibatch 317::LR 0.0538461538462 --> Loss 0.00155223409335\n",
      "Epoch 21::Minibatch 318::LR 0.0538461538462 --> Loss 0.00125233620405\n",
      "Epoch 21::Minibatch 319::LR 0.0538461538462 --> Loss 0.0022988563776\n",
      "Epoch 21::Minibatch 320::LR 0.0538461538462 --> Loss 0.00314965943495\n",
      "Epoch 21::Minibatch 321::LR 0.0538461538462 --> Loss 0.000844669938087\n",
      "Epoch 21::Minibatch 322::LR 0.0538461538462 --> Loss 0.00361179669698\n",
      "Epoch 21::Minibatch 323::LR 0.0538461538462 --> Loss 0.00350129961967\n",
      "Epoch 21::Minibatch 324::LR 0.0538461538462 --> Loss 0.00263998925686\n",
      "Epoch 21::Minibatch 325::LR 0.0538461538462 --> Loss 0.00239239275455\n",
      "Epoch 21::Minibatch 326::LR 0.0538461538462 --> Loss 0.00547166784604\n",
      "Epoch 21::Minibatch 327::LR 0.0538461538462 --> Loss 0.00225446343422\n",
      "Epoch 21::Minibatch 328::LR 0.0538461538462 --> Loss 0.00317994296551\n",
      "Epoch 21::Minibatch 329::LR 0.0538461538462 --> Loss 0.00121439228455\n",
      "Epoch 21::Minibatch 330::LR 0.0538461538462 --> Loss 0.00159806509813\n",
      "Epoch 21::Minibatch 331::LR 0.0538461538462 --> Loss 0.00254137376944\n",
      "Epoch 21::Minibatch 332::LR 0.0538461538462 --> Loss 0.00249276777109\n",
      "Epoch 21::Minibatch 333::LR 0.0538461538462 --> Loss 0.00145158280929\n",
      "Epoch 21::Minibatch 334::LR 0.0538461538462 --> Loss 0.00441309650739\n",
      "Epoch 21::Minibatch 335::LR 0.0538461538462 --> Loss 0.0018866811196\n",
      "Epoch 21::Minibatch 336::LR 0.0538461538462 --> Loss 0.00219240128994\n",
      "Epoch 21::Minibatch 337::LR 0.0538461538462 --> Loss 0.00352120161057\n",
      "Epoch 21::Minibatch 338::LR 0.0538461538462 --> Loss 0.000530752042929\n",
      "Epoch 21::Minibatch 339::LR 0.0538461538462 --> Loss 0.0033093392849\n",
      "Epoch 21::Minibatch 340::LR 0.0538461538462 --> Loss 0.0039627122879\n",
      "Epoch 21::Minibatch 341::LR 0.0538461538462 --> Loss 0.0046813595295\n",
      "Epoch 21::Minibatch 342::LR 0.0538461538462 --> Loss 0.00310211618741\n",
      "Epoch 21::Minibatch 343::LR 0.0538461538462 --> Loss 0.00166311273972\n",
      "Epoch 21::Minibatch 344::LR 0.0538461538462 --> Loss 0.0031455775102\n",
      "Epoch 21::Minibatch 345::LR 0.0538461538462 --> Loss 0.00421858708064\n",
      "Epoch 21::Minibatch 346::LR 0.0538461538462 --> Loss 0.00559388279915\n",
      "Epoch 21::Minibatch 347::LR 0.0538461538462 --> Loss 0.000835832357407\n",
      "Epoch 21::Minibatch 348::LR 0.0538461538462 --> Loss 0.00328292985757\n",
      "Epoch 21::Minibatch 349::LR 0.0538461538462 --> Loss 0.00346656282743\n",
      "Epoch 21::Minibatch 350::LR 0.0538461538462 --> Loss 0.00171851317088\n",
      "Epoch 21::Minibatch 351::LR 0.0538461538462 --> Loss 0.00348612149556\n",
      "Epoch 21::Minibatch 352::LR 0.0538461538462 --> Loss 0.00491584936778\n",
      "Epoch 21::Minibatch 353::LR 0.0538461538462 --> Loss 0.00354174455007\n",
      "Epoch 21::Minibatch 354::LR 0.0538461538462 --> Loss 0.00295003175735\n",
      "Epoch 21::Minibatch 355::LR 0.0538461538462 --> Loss 0.00616790771484\n",
      "Epoch 21::Minibatch 356::LR 0.0538461538462 --> Loss 0.00312743564447\n",
      "Epoch 21::Minibatch 357::LR 0.0538461538462 --> Loss 0.0011359077692\n",
      "Epoch 21::Minibatch 358::LR 0.0538461538462 --> Loss 0.00208214223385\n",
      "Epoch 21::Minibatch 359::LR 0.0538461538462 --> Loss 0.0027101435264\n",
      "Epoch 21::Minibatch 360::LR 0.0538461538462 --> Loss 0.00239275415738\n",
      "Epoch 21::Minibatch 361::LR 0.0538461538462 --> Loss 0.00237725615501\n",
      "Epoch 21::Minibatch 362::LR 0.0538461538462 --> Loss 0.00235198418299\n",
      "Epoch 21::Minibatch 363::LR 0.0538461538462 --> Loss 0.000652291228374\n",
      "Epoch 21::Minibatch 364::LR 0.0538461538462 --> Loss 0.00199492434661\n",
      "Epoch 21::Minibatch 365::LR 0.0538461538462 --> Loss 0.00206860701243\n",
      "Epoch 21::Minibatch 366::LR 0.0538461538462 --> Loss 0.00220389624437\n",
      "Epoch 21::Minibatch 367::LR 0.0538461538462 --> Loss 0.00105518907309\n",
      "Epoch 21::Minibatch 368::LR 0.0538461538462 --> Loss 0.000980151991049\n",
      "Epoch 21::Minibatch 369::LR 0.0538461538462 --> Loss 0.00284900327524\n",
      "Epoch 21::Minibatch 370::LR 0.0538461538462 --> Loss 0.00225037356218\n",
      "Epoch 21::Minibatch 371::LR 0.0538461538462 --> Loss 0.00186842978001\n",
      "Epoch 21::Minibatch 372::LR 0.0538461538462 --> Loss 0.000432063738505\n",
      "Epoch 21::Minibatch 373::LR 0.0538461538462 --> Loss 0.00178031623363\n",
      "Epoch 21::Minibatch 374::LR 0.0538461538462 --> Loss 0.00220724185308\n",
      "Epoch 21::Minibatch 375::LR 0.0538461538462 --> Loss 0.00185069481532\n",
      "Epoch 21::Minibatch 376::LR 0.0538461538462 --> Loss 0.0012309490641\n",
      "Epoch 21::Minibatch 377::LR 0.0538461538462 --> Loss 0.00193223933379\n",
      "Epoch 21::Minibatch 378::LR 0.0538461538462 --> Loss 0.00212050000827\n",
      "Epoch 21::Minibatch 379::LR 0.0538461538462 --> Loss 0.00236005922159\n",
      "Epoch 21::Minibatch 380::LR 0.0538461538462 --> Loss 0.00157979309559\n",
      "Epoch 21::Minibatch 381::LR 0.0538461538462 --> Loss 0.000983340640863\n",
      "Epoch 21::Minibatch 382::LR 0.0538461538462 --> Loss 0.00201590200265\n",
      "Epoch 21::Minibatch 383::LR 0.0538461538462 --> Loss 0.00196205496788\n",
      "Epoch 21::Minibatch 384::LR 0.0538461538462 --> Loss 0.00106508394082\n",
      "Epoch 21::Minibatch 385::LR 0.0538461538462 --> Loss 0.00103898247083\n",
      "Epoch 21::Minibatch 386::LR 0.0538461538462 --> Loss 0.00219187597434\n",
      "Epoch 21::Minibatch 387::LR 0.0538461538462 --> Loss 0.00234659353892\n",
      "Epoch 21::Minibatch 388::LR 0.0538461538462 --> Loss 0.00116581330697\n",
      "Epoch 21::Minibatch 389::LR 0.0538461538462 --> Loss 0.00179274419943\n",
      "Epoch 21::Minibatch 390::LR 0.0538461538462 --> Loss 0.00346053997676\n",
      "Epoch 21::Minibatch 391::LR 0.0538461538462 --> Loss 0.00263483424981\n",
      "Epoch 21::Minibatch 392::LR 0.0538461538462 --> Loss 0.00260116616885\n",
      "Epoch 21::Minibatch 393::LR 0.0538461538462 --> Loss 0.00275684535503\n",
      "Epoch 21::Minibatch 394::LR 0.0538461538462 --> Loss 0.00207042555014\n",
      "Epoch 21::Minibatch 395::LR 0.0538461538462 --> Loss 0.00205648283164\n",
      "Epoch 21::Minibatch 396::LR 0.0538461538462 --> Loss 0.00193302591642\n",
      "Epoch 21::Minibatch 397::LR 0.0538461538462 --> Loss 0.00206873953342\n",
      "Epoch 21::Minibatch 398::LR 0.0538461538462 --> Loss 0.00205446461836\n",
      "Epoch 21::Minibatch 399::LR 0.0538461538462 --> Loss 0.00236398319403\n",
      "Epoch 21::Minibatch 400::LR 0.0538461538462 --> Loss 0.00200499018033\n",
      "Epoch 21::Minibatch 401::LR 0.0538461538462 --> Loss 0.00344528198242\n",
      "Epoch 21::Minibatch 402::LR 0.0538461538462 --> Loss 0.00176004290581\n",
      "Epoch 21::Minibatch 403::LR 0.0538461538462 --> Loss 0.00143656353156\n",
      "Epoch 21::Minibatch 404::LR 0.0538461538462 --> Loss 0.00142328639825\n",
      "Epoch 21::Minibatch 405::LR 0.0538461538462 --> Loss 0.00343667467435\n",
      "Epoch 21::Minibatch 406::LR 0.0538461538462 --> Loss 0.00240869820118\n",
      "Epoch 21::Minibatch 407::LR 0.0538461538462 --> Loss 0.00171637177467\n",
      "Epoch 21::Minibatch 408::LR 0.0538461538462 --> Loss 0.00043209100763\n",
      "Epoch 21::Minibatch 409::LR 0.0538461538462 --> Loss 0.00227901955446\n",
      "Epoch 21::Minibatch 410::LR 0.0538461538462 --> Loss 0.00316757758458\n",
      "Epoch 21::Minibatch 411::LR 0.0538461538462 --> Loss 0.00163242250681\n",
      "Epoch 21::Minibatch 412::LR 0.0538461538462 --> Loss 0.000946101943652\n",
      "Epoch 21::Minibatch 413::LR 0.0538461538462 --> Loss 0.00195632835229\n",
      "Epoch 21::Minibatch 414::LR 0.0538461538462 --> Loss 0.00183464209239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 415::LR 0.0538461538462 --> Loss 0.00114059497913\n",
      "Epoch 21::Minibatch 416::LR 0.0538461538462 --> Loss 0.000796786000331\n",
      "Epoch 21::Minibatch 417::LR 0.0538461538462 --> Loss 0.00168127536774\n",
      "Epoch 21::Minibatch 418::LR 0.0538461538462 --> Loss 0.00267884671688\n",
      "Epoch 21::Minibatch 419::LR 0.0538461538462 --> Loss 0.000488311499357\n",
      "Epoch 21::Minibatch 420::LR 0.0538461538462 --> Loss 0.000684057126443\n",
      "Epoch 21::Minibatch 421::LR 0.0538461538462 --> Loss 0.00190207143625\n",
      "Epoch 21::Minibatch 422::LR 0.0538461538462 --> Loss 0.00210098246733\n",
      "Epoch 21::Minibatch 423::LR 0.0538461538462 --> Loss 0.000959318578243\n",
      "Epoch 21::Minibatch 424::LR 0.0538461538462 --> Loss 0.0015279062589\n",
      "Epoch 21::Minibatch 425::LR 0.0538461538462 --> Loss 0.00288892487685\n",
      "Epoch 21::Minibatch 426::LR 0.0538461538462 --> Loss 0.00198348780473\n",
      "Epoch 21::Minibatch 427::LR 0.0538461538462 --> Loss 0.000706488241752\n",
      "Epoch 21::Minibatch 428::LR 0.0538461538462 --> Loss 0.000997550388177\n",
      "Epoch 21::Minibatch 429::LR 0.0538461538462 --> Loss 0.00232504804929\n",
      "Epoch 21::Minibatch 430::LR 0.0538461538462 --> Loss 0.00900610287984\n",
      "Epoch 21::Minibatch 431::LR 0.0538461538462 --> Loss 0.0037695980072\n",
      "Epoch 21::Minibatch 432::LR 0.0538461538462 --> Loss 0.00430795749029\n",
      "Epoch 21::Minibatch 433::LR 0.0538461538462 --> Loss 0.00255252897739\n",
      "Epoch 21::Minibatch 434::LR 0.0538461538462 --> Loss 0.0025059936444\n",
      "Epoch 21::Minibatch 435::LR 0.0538461538462 --> Loss 0.00229768276215\n",
      "Epoch 21::Minibatch 436::LR 0.0538461538462 --> Loss 0.00165154457092\n",
      "Epoch 21::Minibatch 437::LR 0.0538461538462 --> Loss 0.00307634949684\n",
      "Epoch 21::Minibatch 438::LR 0.0538461538462 --> Loss 0.00246674696604\n",
      "Epoch 21::Minibatch 439::LR 0.0538461538462 --> Loss 0.0020131534338\n",
      "Epoch 21::Minibatch 440::LR 0.0538461538462 --> Loss 0.00312520841757\n",
      "Epoch 21::Minibatch 441::LR 0.0538461538462 --> Loss 0.00291976571083\n",
      "Epoch 21::Minibatch 442::LR 0.0538461538462 --> Loss 0.00264903505643\n",
      "Epoch 21::Minibatch 443::LR 0.0538461538462 --> Loss 0.00358725190163\n",
      "Epoch 21::Minibatch 444::LR 0.0538461538462 --> Loss 0.00279285569986\n",
      "Epoch 21::Minibatch 445::LR 0.0538461538462 --> Loss 0.000874040722847\n",
      "Epoch 21::Minibatch 446::LR 0.0538461538462 --> Loss 0.00141486406326\n",
      "Epoch 21::Minibatch 447::LR 0.0538461538462 --> Loss 0.00237712045511\n",
      "Epoch 21::Minibatch 448::LR 0.0538461538462 --> Loss 0.00236128826936\n",
      "Epoch 21::Minibatch 449::LR 0.0538461538462 --> Loss 0.00367045084635\n",
      "Epoch 21::Minibatch 450::LR 0.0538461538462 --> Loss 0.002231746912\n",
      "Epoch 21::Minibatch 451::LR 0.0538461538462 --> Loss 0.00395248015722\n",
      "Epoch 21::Minibatch 452::LR 0.0538461538462 --> Loss 0.00234362939994\n",
      "Epoch 21::Minibatch 453::LR 0.0538461538462 --> Loss 0.000363583887617\n",
      "Epoch 21::Minibatch 454::LR 0.0538461538462 --> Loss 0.00355937123299\n",
      "Epoch 21::Minibatch 455::LR 0.0538461538462 --> Loss 0.00265670259794\n",
      "Epoch 21::Minibatch 456::LR 0.0538461538462 --> Loss 0.00308776199818\n",
      "Epoch 21::Minibatch 457::LR 0.0538461538462 --> Loss 0.00192178169886\n",
      "Epoch 21::Minibatch 458::LR 0.0538461538462 --> Loss 0.000734823296467\n",
      "Epoch 21::Minibatch 459::LR 0.0538461538462 --> Loss 0.00400815606117\n",
      "Epoch 21::Minibatch 460::LR 0.0538461538462 --> Loss 0.00251620908578\n",
      "Epoch 21::Minibatch 461::LR 0.0538461538462 --> Loss 0.00382197101911\n",
      "Epoch 21::Minibatch 462::LR 0.0538461538462 --> Loss 0.000382193525632\n",
      "Epoch 21::Minibatch 463::LR 0.0538461538462 --> Loss 0.00441314776738\n",
      "Epoch 21::Minibatch 464::LR 0.0538461538462 --> Loss 0.00199993828932\n",
      "Epoch 21::Minibatch 465::LR 0.0538461538462 --> Loss 0.00497387091319\n",
      "Epoch 21::Minibatch 466::LR 0.0538461538462 --> Loss 0.00505333145459\n",
      "Epoch 21::Minibatch 467::LR 0.0538461538462 --> Loss 0.00546620090803\n",
      "Epoch 21::Minibatch 468::LR 0.0538461538462 --> Loss 0.0059238799413\n",
      "Epoch 21::Minibatch 469::LR 0.0538461538462 --> Loss 0.00642313679059\n",
      "Epoch 21::Minibatch 470::LR 0.0538461538462 --> Loss 0.00367028713226\n",
      "Epoch 21::Minibatch 471::LR 0.0538461538462 --> Loss 0.00169584194819\n",
      "Epoch 21::Minibatch 472::LR 0.0538461538462 --> Loss 0.00354151288668\n",
      "Epoch 21::Minibatch 473::LR 0.0538461538462 --> Loss 0.0022695428133\n",
      "Epoch 21::Minibatch 474::LR 0.0538461538462 --> Loss 0.000693105955919\n",
      "Epoch 21::Minibatch 475::LR 0.0538461538462 --> Loss 0.00481094757716\n",
      "Epoch 21::Minibatch 476::LR 0.0538461538462 --> Loss 0.0076469484965\n",
      "Epoch 21::Minibatch 477::LR 0.0538461538462 --> Loss 0.000920971632004\n",
      "Epoch 21::Minibatch 478::LR 0.0538461538462 --> Loss 0.00244392196337\n",
      "Epoch 21::Minibatch 479::LR 0.0538461538462 --> Loss 0.00195682525635\n",
      "Epoch 21::Minibatch 480::LR 0.0538461538462 --> Loss 0.00152302275101\n",
      "Epoch 21::Minibatch 481::LR 0.0538461538462 --> Loss 0.000955497225126\n",
      "Epoch 21::Minibatch 482::LR 0.0538461538462 --> Loss 0.00208254933357\n",
      "Epoch 21::Minibatch 483::LR 0.0538461538462 --> Loss 0.00311399797599\n",
      "Epoch 21::Minibatch 484::LR 0.0538461538462 --> Loss 0.00348936676979\n",
      "Epoch 21::Minibatch 485::LR 0.0538461538462 --> Loss 0.000756089389324\n",
      "Epoch 21::Minibatch 486::LR 0.0538461538462 --> Loss 0.00288784344991\n",
      "Epoch 21::Minibatch 487::LR 0.0538461538462 --> Loss 0.00333462317785\n",
      "Epoch 21::Minibatch 488::LR 0.0538461538462 --> Loss 0.00203436513742\n",
      "Epoch 21::Minibatch 489::LR 0.0538461538462 --> Loss 0.00315622786681\n",
      "Epoch 21::Minibatch 490::LR 0.0538461538462 --> Loss 0.000409382383029\n",
      "Epoch 21::Minibatch 491::LR 0.0538461538462 --> Loss 0.00352147658666\n",
      "Epoch 21::Minibatch 492::LR 0.0538461538462 --> Loss 0.00305672268073\n",
      "Epoch 21::Minibatch 493::LR 0.0538461538462 --> Loss 0.00302678922812\n",
      "Epoch 21::Minibatch 494::LR 0.0538461538462 --> Loss 0.000735532691081\n",
      "Epoch 21::Minibatch 495::LR 0.0538461538462 --> Loss 0.00186360736688\n",
      "Epoch 21::Minibatch 496::LR 0.0538461538462 --> Loss 0.00284004727999\n",
      "Epoch 21::Minibatch 497::LR 0.0538461538462 --> Loss 0.000920308927695\n",
      "Epoch 21::Minibatch 498::LR 0.0538461538462 --> Loss 0.00055609335502\n",
      "Epoch 21::Minibatch 499::LR 0.0538461538462 --> Loss 0.00354075908661\n",
      "Epoch 21::Minibatch 500::LR 0.0538461538462 --> Loss 0.00143623024225\n",
      "Epoch 21::Minibatch 501::LR 0.0538461538462 --> Loss 0.00215611259143\n",
      "Epoch 21::Minibatch 502::LR 0.0538461538462 --> Loss 0.00379147529602\n",
      "Epoch 21::Minibatch 503::LR 0.0538461538462 --> Loss 0.00762156248093\n",
      "Epoch 21::Minibatch 504::LR 0.0538461538462 --> Loss 0.00732697089513\n",
      "Epoch 21::Minibatch 505::LR 0.0538461538462 --> Loss 0.00416932026545\n",
      "Epoch 21::Minibatch 506::LR 0.0538461538462 --> Loss 0.00340355674426\n",
      "Epoch 21::Minibatch 507::LR 0.0538461538462 --> Loss 0.00594110091527\n",
      "Epoch 21::Minibatch 508::LR 0.0538461538462 --> Loss 0.00340483824412\n",
      "Epoch 21::Minibatch 509::LR 0.0538461538462 --> Loss 0.00445468664169\n",
      "Epoch 21::Minibatch 510::LR 0.0538461538462 --> Loss 0.0045058409373\n",
      "Epoch 21::Minibatch 511::LR 0.0538461538462 --> Loss 0.00394018729528\n",
      "Epoch 21::Minibatch 512::LR 0.0538461538462 --> Loss 0.00268487632275\n",
      "Epoch 21::Minibatch 513::LR 0.0538461538462 --> Loss 0.000625225504239\n",
      "Epoch 21::Minibatch 514::LR 0.0538461538462 --> Loss 0.00265491743882\n",
      "Epoch 21::Minibatch 515::LR 0.0538461538462 --> Loss 0.00300225178401\n",
      "Epoch 21::Minibatch 516::LR 0.0538461538462 --> Loss 0.00401733120282\n",
      "Epoch 21::Minibatch 517::LR 0.0538461538462 --> Loss 0.0035421359539\n",
      "Epoch 21::Minibatch 518::LR 0.0538461538462 --> Loss 0.00257905503114\n",
      "Epoch 21::Minibatch 519::LR 0.0538461538462 --> Loss 0.00348324894905\n",
      "Epoch 21::Minibatch 520::LR 0.0538461538462 --> Loss 0.00540439486504\n",
      "Epoch 21::Minibatch 521::LR 0.0538461538462 --> Loss 0.0055107263724\n",
      "Epoch 21::Minibatch 522::LR 0.0538461538462 --> Loss 0.00775150299072\n",
      "Epoch 21::Minibatch 523::LR 0.0538461538462 --> Loss 0.000636565784613\n",
      "Epoch 21::Minibatch 524::LR 0.0538461538462 --> Loss 0.00141182442506\n",
      "Epoch 21::Minibatch 525::LR 0.0538461538462 --> Loss 0.00317546327909\n",
      "Epoch 21::Minibatch 526::LR 0.0538461538462 --> Loss 0.00391136328379\n",
      "Epoch 21::Minibatch 527::LR 0.0538461538462 --> Loss 0.0022040673097\n",
      "Epoch 21::Minibatch 528::LR 0.0538461538462 --> Loss 0.00100109408299\n",
      "Epoch 21::Minibatch 529::LR 0.0538461538462 --> Loss 0.00401450951894\n",
      "Epoch 21::Minibatch 530::LR 0.0538461538462 --> Loss 0.00405531525612\n",
      "Epoch 21::Minibatch 531::LR 0.0538461538462 --> Loss 0.00359005014102\n",
      "Epoch 21::Minibatch 532::LR 0.0538461538462 --> Loss 0.0026794586579\n",
      "Epoch 21::Minibatch 533::LR 0.0538461538462 --> Loss 0.00498680750529\n",
      "Epoch 21::Minibatch 534::LR 0.0538461538462 --> Loss 0.00377454837163\n",
      "Epoch 21::Minibatch 535::LR 0.0538461538462 --> Loss 0.00327424565951\n",
      "Epoch 21::Minibatch 536::LR 0.0538461538462 --> Loss 0.00210604310036\n",
      "Epoch 21::Minibatch 537::LR 0.0538461538462 --> Loss 0.000607425669829\n",
      "Epoch 21::Minibatch 538::LR 0.0538461538462 --> Loss 0.0016678104798\n",
      "Epoch 21::Minibatch 539::LR 0.0538461538462 --> Loss 0.00338839650154\n",
      "Epoch 21::Minibatch 540::LR 0.0538461538462 --> Loss 0.00341127077738\n",
      "Epoch 21::Minibatch 541::LR 0.0538461538462 --> Loss 0.00288349072138\n",
      "Epoch 21::Minibatch 542::LR 0.0538461538462 --> Loss 0.00249390661716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 543::LR 0.0538461538462 --> Loss 0.0026818972826\n",
      "Epoch 21::Minibatch 544::LR 0.0538461538462 --> Loss 0.00392493208249\n",
      "Epoch 21::Minibatch 545::LR 0.0538461538462 --> Loss 0.00202051103115\n",
      "Epoch 21::Minibatch 546::LR 0.0538461538462 --> Loss 0.000652199635903\n",
      "Epoch 21::Minibatch 547::LR 0.0538461538462 --> Loss 0.0026073483626\n",
      "Epoch 21::Minibatch 548::LR 0.0538461538462 --> Loss 0.00358287096024\n",
      "Epoch 21::Minibatch 549::LR 0.0538461538462 --> Loss 0.00873746315638\n",
      "Epoch 21::Minibatch 550::LR 0.0538461538462 --> Loss 0.00117085248232\n",
      "Epoch 21::Minibatch 551::LR 0.0538461538462 --> Loss 0.00244961043199\n",
      "Epoch 21::Minibatch 552::LR 0.0538461538462 --> Loss 0.00350467006365\n",
      "Epoch 21::Minibatch 553::LR 0.0538461538462 --> Loss 0.00312074859937\n",
      "Epoch 21::Minibatch 554::LR 0.0538461538462 --> Loss 0.00370496749878\n",
      "Epoch 21::Minibatch 555::LR 0.0538461538462 --> Loss 0.000964603821437\n",
      "Epoch 21::Minibatch 556::LR 0.0538461538462 --> Loss 0.0019628717502\n",
      "Epoch 21::Minibatch 557::LR 0.0538461538462 --> Loss 0.00242762664954\n",
      "Epoch 21::Minibatch 558::LR 0.0538461538462 --> Loss 0.00368986646334\n",
      "Epoch 21::Minibatch 559::LR 0.0538461538462 --> Loss 0.00370485981305\n",
      "Epoch 21::Minibatch 560::LR 0.0538461538462 --> Loss 0.00308175007502\n",
      "Epoch 21::Minibatch 561::LR 0.0538461538462 --> Loss 0.00267190476259\n",
      "Epoch 21::Minibatch 562::LR 0.0538461538462 --> Loss 0.00236213525136\n",
      "Epoch 21::Minibatch 563::LR 0.0538461538462 --> Loss 0.00400799592336\n",
      "Epoch 21::Minibatch 564::LR 0.0538461538462 --> Loss 0.00309198300044\n",
      "Epoch 21::Minibatch 565::LR 0.0538461538462 --> Loss 0.0036399769783\n",
      "Epoch 21::Minibatch 566::LR 0.0538461538462 --> Loss 0.00224148035049\n",
      "Epoch 21::Minibatch 567::LR 0.0538461538462 --> Loss 0.00254933536053\n",
      "Epoch 21::Minibatch 568::LR 0.0538461538462 --> Loss 0.0017872484525\n",
      "Epoch 21::Minibatch 569::LR 0.0538461538462 --> Loss 0.000561884095271\n",
      "Epoch 21::Minibatch 570::LR 0.0538461538462 --> Loss 0.00167320430279\n",
      "Epoch 21::Minibatch 571::LR 0.0538461538462 --> Loss 0.00216820617517\n",
      "Epoch 21::Minibatch 572::LR 0.0538461538462 --> Loss 0.00231584489346\n",
      "Epoch 21::Minibatch 573::LR 0.0538461538462 --> Loss 0.00148251165946\n",
      "Epoch 21::Minibatch 574::LR 0.0538461538462 --> Loss 0.00104634225368\n",
      "Epoch 21::Minibatch 575::LR 0.0538461538462 --> Loss 0.00176003277302\n",
      "Epoch 21::Minibatch 576::LR 0.0538461538462 --> Loss 0.00208415269852\n",
      "Epoch 21::Minibatch 577::LR 0.0538461538462 --> Loss 0.00164131035407\n",
      "Epoch 21::Minibatch 578::LR 0.0538461538462 --> Loss 0.0012781020999\n",
      "Epoch 21::Minibatch 579::LR 0.0538461538462 --> Loss 0.00119362781445\n",
      "Epoch 21::Minibatch 580::LR 0.0538461538462 --> Loss 0.00193279882272\n",
      "Epoch 21::Minibatch 581::LR 0.0538461538462 --> Loss 0.00171220997969\n",
      "Epoch 21::Minibatch 582::LR 0.0538461538462 --> Loss 0.00414309263229\n",
      "Epoch 21::Minibatch 583::LR 0.0538461538462 --> Loss 0.000943909188112\n",
      "Epoch 21::Minibatch 584::LR 0.0538461538462 --> Loss 0.00130692462126\n",
      "Epoch 21::Minibatch 585::LR 0.0538461538462 --> Loss 0.00420587142309\n",
      "Epoch 21::Minibatch 586::LR 0.0538461538462 --> Loss 0.00390166521072\n",
      "Epoch 21::Minibatch 587::LR 0.0538461538462 --> Loss 0.00112280537685\n",
      "Epoch 21::Minibatch 588::LR 0.0538461538462 --> Loss 0.00139614591996\n",
      "Epoch 21::Minibatch 589::LR 0.0538461538462 --> Loss 0.00276288866997\n",
      "Epoch 21::Minibatch 590::LR 0.0538461538462 --> Loss 0.00189708312352\n",
      "Epoch 21::Minibatch 591::LR 0.0538461538462 --> Loss 0.00292484839757\n",
      "Epoch 21::Minibatch 592::LR 0.0538461538462 --> Loss 0.00117049753666\n",
      "Epoch 21::Minibatch 593::LR 0.0538461538462 --> Loss 0.00256034195423\n",
      "Epoch 21::Minibatch 594::LR 0.0538461538462 --> Loss 0.00269286851088\n",
      "Epoch 21::Minibatch 595::LR 0.0538461538462 --> Loss 0.00304704248905\n",
      "Epoch 21::Minibatch 596::LR 0.0538461538462 --> Loss 0.00190893133481\n",
      "Epoch 21::Minibatch 597::LR 0.0538461538462 --> Loss 0.00118583202362\n",
      "Epoch 21::Minibatch 598::LR 0.0538461538462 --> Loss 0.00293921252092\n",
      "Epoch 21::Minibatch 599::LR 0.0538461538462 --> Loss 0.00183883190155\n",
      "Epoch 21::Minibatch 600::LR 0.0538461538462 --> Loss 0.0021923528115\n",
      "Epoch 21::Minibatch 601::LR 0.0538461538462 --> Loss 0.00384212136269\n",
      "Epoch 21::Minibatch 602::LR 0.0538461538462 --> Loss 0.00210828542709\n",
      "Epoch 21::Minibatch 603::LR 0.0538461538462 --> Loss 0.00263819992542\n",
      "Epoch 21::Minibatch 604::LR 0.0538461538462 --> Loss 0.0016499620676\n",
      "Epoch 21::Minibatch 605::LR 0.0538461538462 --> Loss 0.00234641273816\n",
      "Epoch 21::Minibatch 606::LR 0.0538461538462 --> Loss 0.0019051104784\n",
      "Epoch 21::Minibatch 607::LR 0.0538461538462 --> Loss 0.0008390690883\n",
      "Epoch 21::Minibatch 608::LR 0.0538461538462 --> Loss 0.00157638231913\n",
      "Epoch 21::Minibatch 609::LR 0.0538461538462 --> Loss 0.00240364531676\n",
      "Epoch 21::Minibatch 610::LR 0.0538461538462 --> Loss 0.00403489669164\n",
      "Epoch 21::Minibatch 611::LR 0.0538461538462 --> Loss 0.00263788839181\n",
      "Epoch 21::Minibatch 612::LR 0.0538461538462 --> Loss 0.000480047265689\n",
      "Epoch 21::Minibatch 613::LR 0.0538461538462 --> Loss 0.00131116449833\n",
      "Epoch 21::Minibatch 614::LR 0.0538461538462 --> Loss 0.00244064807892\n",
      "Epoch 21::Minibatch 615::LR 0.0538461538462 --> Loss 0.00167702496052\n",
      "Epoch 21::Minibatch 616::LR 0.0538461538462 --> Loss 0.000924089550972\n",
      "Epoch 21::Minibatch 617::LR 0.0538461538462 --> Loss 0.000498865842819\n",
      "Epoch 21::Minibatch 618::LR 0.0538461538462 --> Loss 0.00279193441073\n",
      "Epoch 21::Minibatch 619::LR 0.0538461538462 --> Loss 0.0019275957346\n",
      "Epoch 21::Minibatch 620::LR 0.0538461538462 --> Loss 0.00171062350273\n",
      "Epoch 21::Minibatch 621::LR 0.0538461538462 --> Loss 0.000850578447183\n",
      "Epoch 21::Minibatch 622::LR 0.0538461538462 --> Loss 0.000793021818002\n",
      "Epoch 21::Minibatch 623::LR 0.0538461538462 --> Loss 0.00222259104252\n",
      "Epoch 21::Minibatch 624::LR 0.0538461538462 --> Loss 0.00179620484511\n",
      "Epoch 21::Minibatch 625::LR 0.0538461538462 --> Loss 0.00285090287526\n",
      "Epoch 21::Minibatch 626::LR 0.0538461538462 --> Loss 0.00414801955223\n",
      "Epoch 21::Minibatch 627::LR 0.0538461538462 --> Loss 0.0013029568394\n",
      "Epoch 21::Minibatch 628::LR 0.0538461538462 --> Loss 0.000892327725887\n",
      "Epoch 21::Minibatch 629::LR 0.0538461538462 --> Loss 0.00329914331436\n",
      "Epoch 21::Minibatch 630::LR 0.0538461538462 --> Loss 0.0032194964091\n",
      "Epoch 21::Minibatch 631::LR 0.0538461538462 --> Loss 0.00595705509186\n",
      "Epoch 21::Minibatch 632::LR 0.0538461538462 --> Loss 0.000792142947515\n",
      "Epoch 21::Minibatch 633::LR 0.0538461538462 --> Loss 0.00164460271597\n",
      "Epoch 21::Minibatch 634::LR 0.0538461538462 --> Loss 0.0032305264473\n",
      "Epoch 21::Minibatch 635::LR 0.0538461538462 --> Loss 0.00543262561162\n",
      "Epoch 21::Minibatch 636::LR 0.0538461538462 --> Loss 0.00491897503535\n",
      "Epoch 21::Minibatch 637::LR 0.0538461538462 --> Loss 0.000758369167646\n",
      "Epoch 21::Minibatch 638::LR 0.0538461538462 --> Loss 0.00150186737378\n",
      "Epoch 21::Minibatch 639::LR 0.0538461538462 --> Loss 0.00326893150806\n",
      "Epoch 21::Minibatch 640::LR 0.0538461538462 --> Loss 0.00487337986628\n",
      "Epoch 21::Minibatch 641::LR 0.0538461538462 --> Loss 0.00310718476772\n",
      "Epoch 21::Minibatch 642::LR 0.0538461538462 --> Loss 0.000540290673574\n",
      "Epoch 21::Minibatch 643::LR 0.0538461538462 --> Loss 0.00233399172624\n",
      "Epoch 21::Minibatch 644::LR 0.0538461538462 --> Loss 0.0039474594593\n",
      "Epoch 21::Minibatch 645::LR 0.0538461538462 --> Loss 0.00426511009534\n",
      "Epoch 21::Minibatch 646::LR 0.0538461538462 --> Loss 0.00150732596715\n",
      "Epoch 21::Minibatch 647::LR 0.0538461538462 --> Loss 0.000504183620214\n",
      "Epoch 21::Minibatch 648::LR 0.0538461538462 --> Loss 0.00291126807531\n",
      "Epoch 21::Minibatch 649::LR 0.0538461538462 --> Loss 0.00345155119896\n",
      "Epoch 21::Minibatch 650::LR 0.0538461538462 --> Loss 0.00328054567178\n",
      "Epoch 21::Minibatch 651::LR 0.0538461538462 --> Loss 0.00136759251356\n",
      "Epoch 21::Minibatch 652::LR 0.0538461538462 --> Loss 0.000795208017031\n",
      "Epoch 21::Minibatch 653::LR 0.0538461538462 --> Loss 0.00284489134947\n",
      "Epoch 21::Minibatch 654::LR 0.0538461538462 --> Loss 0.00312205374241\n",
      "Epoch 21::Minibatch 655::LR 0.0538461538462 --> Loss 0.00353173732758\n",
      "Epoch 21::Minibatch 656::LR 0.0538461538462 --> Loss 0.000757110416889\n",
      "Epoch 21::Minibatch 657::LR 0.0538461538462 --> Loss 0.0022525592645\n",
      "Epoch 21::Minibatch 658::LR 0.0538461538462 --> Loss 0.00478130698204\n",
      "Epoch 21::Minibatch 659::LR 0.0538461538462 --> Loss 0.00228610694408\n",
      "Epoch 21::Minibatch 660::LR 0.0538461538462 --> Loss 0.00261006474495\n",
      "Epoch 21::Minibatch 661::LR 0.0538461538462 --> Loss 0.00242853601774\n",
      "Epoch 21::Minibatch 662::LR 0.0538461538462 --> Loss 0.00180880169074\n",
      "Epoch 21::Minibatch 663::LR 0.0538461538462 --> Loss 0.00368653098742\n",
      "Epoch 21::Minibatch 664::LR 0.0538461538462 --> Loss 0.00334568182627\n",
      "Epoch 21::Minibatch 665::LR 0.0538461538462 --> Loss 0.00071867843469\n",
      "Epoch 21::Minibatch 666::LR 0.0538461538462 --> Loss 0.00391662398974\n",
      "Epoch 21::Minibatch 667::LR 0.0538461538462 --> Loss 0.00254895190398\n",
      "Epoch 21::Minibatch 668::LR 0.0538461538462 --> Loss 0.00677585045497\n",
      "Epoch 21::Minibatch 669::LR 0.0538461538462 --> Loss 0.00109216928482\n",
      "Epoch 21::Minibatch 670::LR 0.0538461538462 --> Loss 0.00134580433369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 671::LR 0.0538461538462 --> Loss 0.00527927478155\n",
      "Epoch 21::Minibatch 672::LR 0.0538461538462 --> Loss 0.00362827380498\n",
      "Epoch 21::Minibatch 673::LR 0.0538461538462 --> Loss 0.00161917289098\n",
      "Epoch 21::Minibatch 674::LR 0.0538461538462 --> Loss 0.000512293080489\n",
      "Epoch 21::Minibatch 675::LR 0.0538461538462 --> Loss 0.00218678553899\n",
      "Epoch 21::Minibatch 676::LR 0.0538461538462 --> Loss 0.00213200211525\n",
      "Epoch 21::Minibatch 677::LR 0.0538461538462 --> Loss 0.00277150094509\n",
      "Epoch 21::Minibatch 678::LR 0.0538461538462 --> Loss 0.00191043833892\n",
      "Epoch 21::Minibatch 679::LR 0.0538461538462 --> Loss 0.00344388524691\n",
      "Epoch 21::Minibatch 680::LR 0.0538461538462 --> Loss 0.00213964323203\n",
      "Epoch 21::Minibatch 681::LR 0.0538461538462 --> Loss 0.00242697636286\n",
      "Epoch 21::Minibatch 682::LR 0.0538461538462 --> Loss 0.000760961870352\n",
      "Epoch 21::Minibatch 683::LR 0.0538461538462 --> Loss 0.00235743363698\n",
      "Epoch 21::Minibatch 684::LR 0.0538461538462 --> Loss 0.00234675506751\n",
      "Epoch 21::Minibatch 685::LR 0.0538461538462 --> Loss 0.00288187861443\n",
      "Epoch 21::Minibatch 686::LR 0.0538461538462 --> Loss 0.00156291653713\n",
      "Epoch 21::Minibatch 687::LR 0.0538461538462 --> Loss 0.000856792628765\n",
      "Epoch 21::Minibatch 688::LR 0.0538461538462 --> Loss 0.00277060389519\n",
      "Epoch 21::Minibatch 689::LR 0.0538461538462 --> Loss 0.00251449922721\n",
      "Epoch 21::Minibatch 690::LR 0.0538461538462 --> Loss 0.00190770486991\n",
      "Epoch 21::Minibatch 691::LR 0.0538461538462 --> Loss 0.000658591985703\n",
      "Epoch 21::Minibatch 692::LR 0.0538461538462 --> Loss 0.00245750923951\n",
      "Epoch 21::Minibatch 693::LR 0.0538461538462 --> Loss 0.0025869333744\n",
      "Epoch 21::Minibatch 694::LR 0.0538461538462 --> Loss 0.00301713744799\n",
      "Epoch 21::Minibatch 695::LR 0.0538461538462 --> Loss 0.00175876994928\n",
      "Epoch 21::Minibatch 696::LR 0.0538461538462 --> Loss 0.00204534828663\n",
      "Epoch 21::Minibatch 697::LR 0.0538461538462 --> Loss 0.00140470494827\n",
      "Epoch 21::Minibatch 698::LR 0.0538461538462 --> Loss 0.0016421615084\n",
      "Epoch 21::Minibatch 699::LR 0.0538461538462 --> Loss 0.00381217638652\n",
      "Epoch 21::Minibatch 700::LR 0.0538461538462 --> Loss 0.00265061636766\n",
      "Epoch 21::Minibatch 701::LR 0.0538461538462 --> Loss 0.00195729792118\n",
      "Epoch 21::Minibatch 702::LR 0.0538461538462 --> Loss 0.00166470468044\n",
      "Epoch 21::Minibatch 703::LR 0.0538461538462 --> Loss 0.00432429631551\n",
      "Epoch 21::Minibatch 704::LR 0.0538461538462 --> Loss 0.00180548191071\n",
      "Epoch 21::Minibatch 705::LR 0.0538461538462 --> Loss 0.00286396682262\n",
      "Epoch 21::Minibatch 706::LR 0.0538461538462 --> Loss 0.00223620295525\n",
      "Epoch 21::Minibatch 707::LR 0.0538461538462 --> Loss 0.00118182162444\n",
      "Epoch 21::Minibatch 708::LR 0.0538461538462 --> Loss 0.00173372725646\n",
      "Epoch 21::Minibatch 709::LR 0.0538461538462 --> Loss 0.00168127318223\n",
      "Epoch 21::Minibatch 710::LR 0.0538461538462 --> Loss 0.00254110534986\n",
      "Epoch 21::Minibatch 711::LR 0.0538461538462 --> Loss 0.00193905154864\n",
      "Epoch 21::Minibatch 712::LR 0.0538461538462 --> Loss 0.00133965780338\n",
      "Epoch 21::Minibatch 713::LR 0.0538461538462 --> Loss 0.0017714703083\n",
      "Epoch 21::Minibatch 714::LR 0.0538461538462 --> Loss 0.00278580228488\n",
      "Epoch 21::Minibatch 715::LR 0.0538461538462 --> Loss 0.00293524742126\n",
      "Epoch 21::Minibatch 716::LR 0.0538461538462 --> Loss 0.0016289182504\n",
      "Epoch 21::Minibatch 717::LR 0.0538461538462 --> Loss 0.00163219471773\n",
      "Epoch 21::Minibatch 718::LR 0.0538461538462 --> Loss 0.00126275589069\n",
      "Epoch 21::Minibatch 719::LR 0.0538461538462 --> Loss 0.00168453892072\n",
      "Epoch 21::Minibatch 720::LR 0.0538461538462 --> Loss 0.00260208785534\n",
      "Epoch 21::Minibatch 721::LR 0.0538461538462 --> Loss 0.000614613989989\n",
      "Epoch 21::Minibatch 722::LR 0.0538461538462 --> Loss 0.00473032514254\n",
      "Epoch 21::Minibatch 723::LR 0.0538461538462 --> Loss 0.00488787213961\n",
      "Epoch 21::Minibatch 724::LR 0.0538461538462 --> Loss 0.000966663459937\n",
      "Epoch 21::Minibatch 725::LR 0.0538461538462 --> Loss 0.00214344362418\n",
      "Epoch 21::Minibatch 726::LR 0.0538461538462 --> Loss 0.00429736971855\n",
      "Epoch 21::Minibatch 727::LR 0.0538461538462 --> Loss 0.00321426868439\n",
      "Epoch 21::Minibatch 728::LR 0.0538461538462 --> Loss 0.000644016762575\n",
      "Epoch 21::Minibatch 729::LR 0.0538461538462 --> Loss 0.000737000604471\n",
      "Epoch 21::Minibatch 730::LR 0.0538461538462 --> Loss 0.00284850358963\n",
      "Epoch 21::Minibatch 731::LR 0.0538461538462 --> Loss 0.00253541707993\n",
      "Epoch 21::Minibatch 732::LR 0.0538461538462 --> Loss 0.00216409643491\n",
      "Epoch 21::Minibatch 733::LR 0.0538461538462 --> Loss 0.000647986183564\n",
      "Epoch 21::Minibatch 734::LR 0.0538461538462 --> Loss 0.00170795241992\n",
      "Epoch 21::Minibatch 735::LR 0.0538461538462 --> Loss 0.00238660931587\n",
      "Epoch 21::Minibatch 736::LR 0.0538461538462 --> Loss 0.00347230990728\n",
      "Epoch 21::Minibatch 737::LR 0.0538461538462 --> Loss 0.00303729255994\n",
      "Epoch 21::Minibatch 738::LR 0.0538461538462 --> Loss 0.00152628193299\n",
      "Epoch 21::Minibatch 739::LR 0.0538461538462 --> Loss 0.00244834840298\n",
      "Epoch 21::Minibatch 740::LR 0.0538461538462 --> Loss 0.00382697025935\n",
      "Epoch 21::Minibatch 741::LR 0.0538461538462 --> Loss 0.00263218720754\n",
      "Epoch 21::Minibatch 742::LR 0.0538461538462 --> Loss 0.00210599581401\n",
      "Epoch 21::Minibatch 743::LR 0.0538461538462 --> Loss 0.00142771164576\n",
      "Epoch 21::Minibatch 744::LR 0.0538461538462 --> Loss 0.00181622644265\n",
      "Epoch 21::Minibatch 745::LR 0.0538461538462 --> Loss 0.00282006104787\n",
      "Epoch 21::Minibatch 746::LR 0.0538461538462 --> Loss 0.00294258753459\n",
      "Epoch 21::Minibatch 747::LR 0.0538461538462 --> Loss 0.00178495546182\n",
      "Epoch 21::Minibatch 748::LR 0.0538461538462 --> Loss 0.000622744907935\n",
      "Epoch 21::Minibatch 749::LR 0.0538461538462 --> Loss 0.00165449857712\n",
      "Epoch 21::Minibatch 750::LR 0.0538461538462 --> Loss 0.00245163222154\n",
      "Epoch 21::Minibatch 751::LR 0.0538461538462 --> Loss 0.00279568235079\n",
      "Epoch 21::Minibatch 752::LR 0.0538461538462 --> Loss 0.00125866969426\n",
      "Epoch 21::Minibatch 753::LR 0.0538461538462 --> Loss 0.00221250633399\n",
      "Epoch 21::Minibatch 754::LR 0.0538461538462 --> Loss 0.00240431129932\n",
      "Epoch 21::Minibatch 755::LR 0.0538461538462 --> Loss 0.00266653438409\n",
      "Epoch 21::Minibatch 756::LR 0.0538461538462 --> Loss 0.00135664661725\n",
      "Epoch 21::Minibatch 757::LR 0.0538461538462 --> Loss 0.000716324796279\n",
      "Epoch 21::Minibatch 758::LR 0.0538461538462 --> Loss 0.00159457147121\n",
      "Epoch 21::Minibatch 759::LR 0.0538461538462 --> Loss 0.00365469098091\n",
      "Epoch 21::Minibatch 760::LR 0.0538461538462 --> Loss 0.00293285985788\n",
      "Epoch 21::Minibatch 761::LR 0.0538461538462 --> Loss 0.0060948463281\n",
      "Epoch 21::Minibatch 762::LR 0.0538461538462 --> Loss 0.00370324174563\n",
      "Epoch 21::Minibatch 763::LR 0.0538461538462 --> Loss 0.00351320107778\n",
      "Epoch 21::Minibatch 764::LR 0.0538461538462 --> Loss 0.00312698284785\n",
      "Epoch 21::Minibatch 765::LR 0.0538461538462 --> Loss 0.00129009743532\n",
      "Epoch 21::Minibatch 766::LR 0.0538461538462 --> Loss 0.00228394627571\n",
      "Epoch 21::Minibatch 767::LR 0.0538461538462 --> Loss 0.00492597103119\n",
      "Epoch 21::Minibatch 768::LR 0.0538461538462 --> Loss 0.00364493648211\n",
      "Epoch 21::Minibatch 769::LR 0.0538461538462 --> Loss 0.00187108516693\n",
      "Epoch 21::Minibatch 770::LR 0.0538461538462 --> Loss 0.00148037731647\n",
      "Epoch 21::Minibatch 771::LR 0.0538461538462 --> Loss 0.00359729846319\n",
      "Epoch 21::Minibatch 772::LR 0.0538461538462 --> Loss 0.00346659739812\n",
      "Epoch 21::Minibatch 773::LR 0.0538461538462 --> Loss 0.00314363837242\n",
      "Epoch 21::Minibatch 774::LR 0.0538461538462 --> Loss 0.0018150772651\n",
      "Epoch 21::Minibatch 775::LR 0.0538461538462 --> Loss 0.00362292369207\n",
      "Epoch 21::Minibatch 776::LR 0.0538461538462 --> Loss 0.00361509720484\n",
      "Epoch 21::Minibatch 777::LR 0.0538461538462 --> Loss 0.0069871711731\n",
      "Epoch 21::Minibatch 778::LR 0.0538461538462 --> Loss 0.00869684378306\n",
      "Epoch 21::Minibatch 779::LR 0.0538461538462 --> Loss 0.0023728642861\n",
      "Epoch 21::Minibatch 780::LR 0.0538461538462 --> Loss 0.00156958262126\n",
      "Epoch 21::Minibatch 781::LR 0.0538461538462 --> Loss 0.00343815366427\n",
      "Epoch 21::Minibatch 782::LR 0.0538461538462 --> Loss 0.00388499418894\n",
      "Epoch 21::Minibatch 783::LR 0.0538461538462 --> Loss 0.00228895862897\n",
      "Epoch 21::Minibatch 784::LR 0.0538461538462 --> Loss 0.000710581640402\n",
      "Epoch 21::Minibatch 785::LR 0.0538461538462 --> Loss 0.00329919735591\n",
      "Epoch 21::Minibatch 786::LR 0.0538461538462 --> Loss 0.0034177283446\n",
      "Epoch 21::Minibatch 787::LR 0.0538461538462 --> Loss 0.00264098485311\n",
      "Epoch 21::Minibatch 788::LR 0.0538461538462 --> Loss 0.00236279428005\n",
      "Epoch 21::Minibatch 789::LR 0.0538461538462 --> Loss 0.00073205858469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 790::LR 0.0538461538462 --> Loss 0.00313796540101\n",
      "Epoch 21::Minibatch 791::LR 0.0538461538462 --> Loss 0.00345145742098\n",
      "Epoch 21::Minibatch 792::LR 0.0538461538462 --> Loss 0.0030536031723\n",
      "Epoch 21::Minibatch 793::LR 0.0538461538462 --> Loss 0.00172015011311\n",
      "Epoch 21::Minibatch 794::LR 0.0538461538462 --> Loss 0.00100388050079\n",
      "Epoch 21::Minibatch 795::LR 0.0538461538462 --> Loss 0.00285941322645\n",
      "Epoch 21::Minibatch 796::LR 0.0538461538462 --> Loss 0.00533871889114\n",
      "Epoch 21::Minibatch 797::LR 0.0538461538462 --> Loss 0.00668920755386\n",
      "Epoch 21::Minibatch 798::LR 0.0538461538462 --> Loss 0.00318853398164\n",
      "Epoch 21::Minibatch 799::LR 0.0538461538462 --> Loss 0.00230715572834\n",
      "Epoch 21::Minibatch 800::LR 0.0538461538462 --> Loss 0.00201107919216\n",
      "Epoch 21::Minibatch 801::LR 0.0538461538462 --> Loss 0.00410101334254\n",
      "Epoch 21::Minibatch 802::LR 0.0538461538462 --> Loss 0.00126851369937\n",
      "Epoch 21::Minibatch 803::LR 0.0538461538462 --> Loss 0.00289035061995\n",
      "Epoch 21::Minibatch 804::LR 0.0538461538462 --> Loss 0.00213461399078\n",
      "Epoch 21::Minibatch 805::LR 0.0538461538462 --> Loss 0.00223339796066\n",
      "Epoch 21::Minibatch 806::LR 0.0538461538462 --> Loss 0.00337129354477\n",
      "Epoch 21::Minibatch 807::LR 0.0538461538462 --> Loss 0.00304212450981\n",
      "Epoch 21::Minibatch 808::LR 0.0538461538462 --> Loss 0.00268896619479\n",
      "Epoch 21::Minibatch 809::LR 0.0538461538462 --> Loss 0.00346587061882\n",
      "Epoch 21::Minibatch 810::LR 0.0538461538462 --> Loss 0.00474275191625\n",
      "Epoch 21::Minibatch 811::LR 0.0538461538462 --> Loss 0.00449735800425\n",
      "Epoch 21::Minibatch 812::LR 0.0538461538462 --> Loss 0.00411640445391\n",
      "Epoch 21::Minibatch 813::LR 0.0538461538462 --> Loss 0.00358724713326\n",
      "Epoch 21::Minibatch 814::LR 0.0538461538462 --> Loss 0.00164623320103\n",
      "Epoch 21::Minibatch 815::LR 0.0538461538462 --> Loss 0.0036738272508\n",
      "Epoch 21::Minibatch 816::LR 0.0538461538462 --> Loss 0.00407984972\n",
      "Epoch 21::Minibatch 817::LR 0.0538461538462 --> Loss 0.00542532444\n",
      "Epoch 21::Minibatch 818::LR 0.0538461538462 --> Loss 0.00125580678384\n",
      "Epoch 21::Minibatch 819::LR 0.0538461538462 --> Loss 0.000705033193032\n",
      "Epoch 21::Minibatch 820::LR 0.0538461538462 --> Loss 0.00524982690811\n",
      "Epoch 21::Minibatch 821::LR 0.0538461538462 --> Loss 0.00310392479102\n",
      "Epoch 21::Minibatch 822::LR 0.0538461538462 --> Loss 0.00368191401164\n",
      "Epoch 21::Minibatch 823::LR 0.0538461538462 --> Loss 0.00128313352664\n",
      "Epoch 21::Minibatch 824::LR 0.0538461538462 --> Loss 0.00136923650901\n",
      "Epoch 21::Minibatch 825::LR 0.0538461538462 --> Loss 0.00365874886513\n",
      "Epoch 21::Minibatch 826::LR 0.0538461538462 --> Loss 0.00403875350952\n",
      "Epoch 21::Minibatch 827::LR 0.0538461538462 --> Loss 0.00207186122735\n",
      "Epoch 21::Minibatch 828::LR 0.0538461538462 --> Loss 0.0005101014177\n",
      "Epoch 21::Minibatch 829::LR 0.0538461538462 --> Loss 0.0023289479812\n",
      "Epoch 21::Minibatch 830::LR 0.0538461538462 --> Loss 0.00424232761065\n",
      "Epoch 21::Minibatch 831::LR 0.0538461538462 --> Loss 0.00250684003035\n",
      "Epoch 21::Minibatch 832::LR 0.0538461538462 --> Loss 0.00219627400239\n",
      "Epoch 21::Minibatch 833::LR 0.0538461538462 --> Loss 0.00183462361495\n",
      "Epoch 21::Minibatch 834::LR 0.0538461538462 --> Loss 0.000775176584721\n",
      "Epoch 21::Minibatch 835::LR 0.0538461538462 --> Loss 0.0037686808904\n",
      "Epoch 21::Minibatch 836::LR 0.0538461538462 --> Loss 0.00365205685298\n",
      "Epoch 21::Minibatch 837::LR 0.0538461538462 --> Loss 0.00219265262286\n",
      "Epoch 21::Minibatch 838::LR 0.0538461538462 --> Loss 0.000631350229184\n",
      "Epoch 21::Minibatch 839::LR 0.0538461538462 --> Loss 0.0024432961146\n",
      "Epoch 21::Minibatch 840::LR 0.0538461538462 --> Loss 0.00287211139997\n",
      "Epoch 21::Minibatch 841::LR 0.0538461538462 --> Loss 0.0027932771047\n",
      "Epoch 21::Minibatch 842::LR 0.0538461538462 --> Loss 0.00207360823949\n",
      "Epoch 21::Minibatch 843::LR 0.0538461538462 --> Loss 0.000995641847452\n",
      "Epoch 21::Minibatch 844::LR 0.0538461538462 --> Loss 0.00148061563571\n",
      "Epoch 21::Minibatch 845::LR 0.0538461538462 --> Loss 0.00422300815582\n",
      "Epoch 21::Minibatch 846::LR 0.0538461538462 --> Loss 0.00166909694672\n",
      "Epoch 21::Minibatch 847::LR 0.0538461538462 --> Loss 0.00228740096092\n",
      "Epoch 21::Minibatch 848::LR 0.0538461538462 --> Loss 0.00103052149216\n",
      "Epoch 21::Minibatch 849::LR 0.0538461538462 --> Loss 0.00181222875913\n",
      "Epoch 21::Minibatch 850::LR 0.0538461538462 --> Loss 0.00315887928009\n",
      "Epoch 21::Minibatch 851::LR 0.0538461538462 --> Loss 0.00260899265607\n",
      "Epoch 21::Minibatch 852::LR 0.0538461538462 --> Loss 0.00108593861262\n",
      "Epoch 21::Minibatch 853::LR 0.0538461538462 --> Loss 0.00130173395077\n",
      "Epoch 21::Minibatch 854::LR 0.0538461538462 --> Loss 0.0025583722194\n",
      "Epoch 21::Minibatch 855::LR 0.0538461538462 --> Loss 0.00214927693208\n",
      "Epoch 21::Minibatch 856::LR 0.0538461538462 --> Loss 0.00178993900617\n",
      "Epoch 21::Minibatch 857::LR 0.0538461538462 --> Loss 0.00121023039023\n",
      "Epoch 21::Minibatch 858::LR 0.0538461538462 --> Loss 0.00059310177962\n",
      "Epoch 21::Minibatch 859::LR 0.0538461538462 --> Loss 0.00192186037699\n",
      "Epoch 21::Minibatch 860::LR 0.0538461538462 --> Loss 0.00126139660676\n",
      "Epoch 21::Minibatch 861::LR 0.0538461538462 --> Loss 0.000936057070891\n",
      "Epoch 21::Minibatch 862::LR 0.0538461538462 --> Loss 0.00365285515785\n",
      "Epoch 21::Minibatch 863::LR 0.0538461538462 --> Loss 0.00339153210322\n",
      "Epoch 21::Minibatch 864::LR 0.0538461538462 --> Loss 0.00277484158675\n",
      "Epoch 21::Minibatch 865::LR 0.0538461538462 --> Loss 0.000446045100689\n",
      "Epoch 21::Minibatch 866::LR 0.0538461538462 --> Loss 0.00211831748486\n",
      "Epoch 21::Minibatch 867::LR 0.0538461538462 --> Loss 0.0029301704963\n",
      "Epoch 21::Minibatch 868::LR 0.0538461538462 --> Loss 0.00241492112478\n",
      "Epoch 21::Minibatch 869::LR 0.0538461538462 --> Loss 0.0021134831508\n",
      "Epoch 21::Minibatch 870::LR 0.0538461538462 --> Loss 0.00345366398493\n",
      "Epoch 21::Minibatch 871::LR 0.0538461538462 --> Loss 0.00154700954755\n",
      "Epoch 21::Minibatch 872::LR 0.0538461538462 --> Loss 0.00222461382548\n",
      "Epoch 21::Minibatch 873::LR 0.0538461538462 --> Loss 0.00246280829112\n",
      "Epoch 21::Minibatch 874::LR 0.0538461538462 --> Loss 0.00588127573331\n",
      "Epoch 21::Minibatch 875::LR 0.0538461538462 --> Loss 0.000539300094048\n",
      "Epoch 21::Minibatch 876::LR 0.0538461538462 --> Loss 0.00302553653717\n",
      "Epoch 21::Minibatch 877::LR 0.0538461538462 --> Loss 0.0054600862662\n",
      "Epoch 21::Minibatch 878::LR 0.0538461538462 --> Loss 0.00314971824487\n",
      "Epoch 21::Minibatch 879::LR 0.0538461538462 --> Loss 0.00397646784782\n",
      "Epoch 21::Minibatch 880::LR 0.0538461538462 --> Loss 0.00481687029203\n",
      "Epoch 21::Minibatch 881::LR 0.0538461538462 --> Loss 0.00426820357641\n",
      "Epoch 21::Minibatch 882::LR 0.0538461538462 --> Loss 0.00195131182671\n",
      "Epoch 21::Minibatch 883::LR 0.0538461538462 --> Loss 0.00346507151922\n",
      "Epoch 21::Minibatch 884::LR 0.0538461538462 --> Loss 0.00272678633531\n",
      "Epoch 21::Minibatch 885::LR 0.0538461538462 --> Loss 0.00254891375701\n",
      "Epoch 21::Minibatch 886::LR 0.0538461538462 --> Loss 0.000472901910543\n",
      "Epoch 21::Minibatch 887::LR 0.0538461538462 --> Loss 0.00527773896853\n",
      "Epoch 21::Minibatch 888::LR 0.0538461538462 --> Loss 0.00256751000881\n",
      "Epoch 21::Minibatch 889::LR 0.0538461538462 --> Loss 0.00271530111631\n",
      "Epoch 21::Minibatch 890::LR 0.0538461538462 --> Loss 0.00399823387464\n",
      "Epoch 21::Minibatch 891::LR 0.0538461538462 --> Loss 0.00180747767289\n",
      "Epoch 21::Minibatch 892::LR 0.0538461538462 --> Loss 0.000835200647513\n",
      "Epoch 21::Minibatch 893::LR 0.0538461538462 --> Loss 0.00238187472026\n",
      "Epoch 21::Minibatch 894::LR 0.0538461538462 --> Loss 0.0021031409502\n",
      "Epoch 21::Minibatch 895::LR 0.0538461538462 --> Loss 0.00235845704873\n",
      "Epoch 21::Minibatch 896::LR 0.0538461538462 --> Loss 0.00124809434017\n",
      "Epoch 21::Minibatch 897::LR 0.0538461538462 --> Loss 0.000696393599113\n",
      "Epoch 21::Minibatch 898::LR 0.0538461538462 --> Loss 0.0020887307326\n",
      "Epoch 21::Minibatch 899::LR 0.0538461538462 --> Loss 0.00246963997682\n",
      "Epoch 21::Minibatch 900::LR 0.0538461538462 --> Loss 0.00317637145519\n",
      "Epoch 21::Minibatch 901::LR 0.0538461538462 --> Loss 0.000587542951107\n",
      "Epoch 21::Minibatch 902::LR 0.0538461538462 --> Loss 0.00140911976496\n",
      "Epoch 21::Minibatch 903::LR 0.0538461538462 --> Loss 0.00254295627276\n",
      "Epoch 21::Minibatch 904::LR 0.0538461538462 --> Loss 0.00187740584215\n",
      "Epoch 21::Minibatch 905::LR 0.0538461538462 --> Loss 0.00142347673575\n",
      "Epoch 21::Minibatch 906::LR 0.0538461538462 --> Loss 0.00106069902579\n",
      "Epoch 21::Minibatch 907::LR 0.0538461538462 --> Loss 0.00157516906659\n",
      "Epoch 21::Minibatch 908::LR 0.0538461538462 --> Loss 0.00213981469472\n",
      "Epoch 21::Minibatch 909::LR 0.0538461538462 --> Loss 0.00197162171205\n",
      "Epoch 21::Minibatch 910::LR 0.0538461538462 --> Loss 0.000834233562152\n",
      "Epoch 21::Minibatch 911::LR 0.0538461538462 --> Loss 0.0012418961525\n",
      "Epoch 21::Minibatch 912::LR 0.0538461538462 --> Loss 0.00199814756711\n",
      "Epoch 21::Minibatch 913::LR 0.0538461538462 --> Loss 0.00218136429787\n",
      "Epoch 21::Minibatch 914::LR 0.0538461538462 --> Loss 0.00117940555016\n",
      "Epoch 21::Minibatch 915::LR 0.0538461538462 --> Loss 0.000497616678476\n",
      "Epoch 21::Minibatch 916::LR 0.0538461538462 --> Loss 0.00219558537006\n",
      "Epoch 21::Minibatch 917::LR 0.0538461538462 --> Loss 0.00360616803169\n",
      "Epoch 21::Minibatch 918::LR 0.0538461538462 --> Loss 0.00558543523153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 919::LR 0.0538461538462 --> Loss 0.00055132796367\n",
      "Epoch 21::Minibatch 920::LR 0.0538461538462 --> Loss 0.0121162192027\n",
      "Epoch 21::Minibatch 921::LR 0.0538461538462 --> Loss 0.00281559944153\n",
      "Epoch 21::Minibatch 922::LR 0.0538461538462 --> Loss 0.0029471039772\n",
      "Epoch 21::Minibatch 923::LR 0.0538461538462 --> Loss 0.00138815452655\n",
      "Epoch 21::Minibatch 924::LR 0.0538461538462 --> Loss 0.00337878346443\n",
      "Epoch 21::Minibatch 925::LR 0.0538461538462 --> Loss 0.00227989514669\n",
      "Epoch 21::Minibatch 926::LR 0.0538461538462 --> Loss 0.00512150684992\n",
      "Epoch 21::Minibatch 927::LR 0.0538461538462 --> Loss 0.00685808499654\n",
      "Epoch 21::Minibatch 928::LR 0.0538461538462 --> Loss 0.00625311255455\n",
      "Epoch 21::Minibatch 929::LR 0.0538461538462 --> Loss 0.00623501261075\n",
      "Epoch 21::Minibatch 930::LR 0.0538461538462 --> Loss 0.0090892179807\n",
      "Epoch 21::Minibatch 931::LR 0.0538461538462 --> Loss 0.00331377724806\n",
      "Epoch 21::Minibatch 932::LR 0.0538461538462 --> Loss 0.0063258155187\n",
      "Epoch 21::Minibatch 933::LR 0.0538461538462 --> Loss 0.00308003862699\n",
      "Epoch 21::Minibatch 934::LR 0.0538461538462 --> Loss 0.00405373891195\n",
      "Epoch 21::Minibatch 935::LR 0.0538461538462 --> Loss 0.00578471938769\n",
      "Epoch 21::Minibatch 936::LR 0.0538461538462 --> Loss 0.00129703362783\n",
      "Epoch 21::Minibatch 937::LR 0.0538461538462 --> Loss 0.00300344109535\n",
      "Epoch 21::Minibatch 938::LR 0.0538461538462 --> Loss 0.00267205893993\n",
      "Epoch 21::Minibatch 939::LR 0.0538461538462 --> Loss 0.00277135630449\n",
      "Epoch 21::Minibatch 940::LR 0.0538461538462 --> Loss 0.000991127689679\n",
      "Epoch 21::Minibatch 941::LR 0.0538461538462 --> Loss 0.000814948827028\n",
      "Epoch 21::Minibatch 942::LR 0.0538461538462 --> Loss 0.00245432098707\n",
      "Epoch 21::Minibatch 943::LR 0.0538461538462 --> Loss 0.00268698612849\n",
      "Epoch 21::Minibatch 944::LR 0.0538461538462 --> Loss 0.00193840285142\n",
      "Epoch 21::Minibatch 945::LR 0.0538461538462 --> Loss 0.00111733784278\n",
      "Epoch 21::Minibatch 946::LR 0.0538461538462 --> Loss 0.00285492062569\n",
      "Epoch 21::Minibatch 947::LR 0.0538461538462 --> Loss 0.00256688495477\n",
      "Epoch 21::Minibatch 948::LR 0.0538461538462 --> Loss 0.00480059027672\n",
      "Epoch 21::Minibatch 949::LR 0.0538461538462 --> Loss 0.00182042519252\n",
      "Epoch 21::Minibatch 950::LR 0.0538461538462 --> Loss 0.000729847997427\n",
      "Epoch 21::Minibatch 951::LR 0.0538461538462 --> Loss 0.00338860313098\n",
      "Epoch 21::Minibatch 952::LR 0.0538461538462 --> Loss 0.00239307324092\n",
      "Epoch 21::Minibatch 953::LR 0.0538461538462 --> Loss 0.0013940457503\n",
      "Epoch 21::Minibatch 954::LR 0.0538461538462 --> Loss 0.000958330730597\n",
      "Epoch 21::Minibatch 955::LR 0.0538461538462 --> Loss 0.00253267566363\n",
      "Epoch 21::Minibatch 956::LR 0.0538461538462 --> Loss 0.00351737459501\n",
      "Epoch 21::Minibatch 957::LR 0.0538461538462 --> Loss 0.00185345987479\n",
      "Epoch 21::Minibatch 958::LR 0.0538461538462 --> Loss 0.00223089694977\n",
      "Epoch 21::Minibatch 959::LR 0.0538461538462 --> Loss 0.00272670646509\n",
      "Epoch 21::Minibatch 960::LR 0.0538461538462 --> Loss 0.00600892424583\n",
      "Epoch 21::Minibatch 961::LR 0.0538461538462 --> Loss 0.00321140189966\n",
      "Epoch 21::Minibatch 962::LR 0.0538461538462 --> Loss 0.00271921038628\n",
      "Epoch 21::Minibatch 963::LR 0.0538461538462 --> Loss 0.00103324532509\n",
      "Epoch 21::Minibatch 964::LR 0.0538461538462 --> Loss 0.00235859910647\n",
      "Epoch 21::Minibatch 965::LR 0.0538461538462 --> Loss 0.00707467953364\n",
      "Epoch 21::Minibatch 966::LR 0.0538461538462 --> Loss 0.00507238785426\n",
      "Epoch 21::Minibatch 967::LR 0.0538461538462 --> Loss 0.00143752624591\n",
      "Epoch 21::Minibatch 968::LR 0.0538461538462 --> Loss 0.00127023925384\n",
      "Epoch 21::Minibatch 969::LR 0.0538461538462 --> Loss 0.00582602580388\n",
      "Epoch 21::Minibatch 970::LR 0.0538461538462 --> Loss 0.00538276473681\n",
      "Epoch 21::Minibatch 971::LR 0.0538461538462 --> Loss 0.00344442168872\n",
      "Epoch 21::Minibatch 972::LR 0.0538461538462 --> Loss 0.00960282961528\n",
      "Epoch 21::Minibatch 973::LR 0.0538461538462 --> Loss 0.00900391976039\n",
      "Epoch 21::Minibatch 974::LR 0.0538461538462 --> Loss 0.0082745162646\n",
      "Epoch 21::Minibatch 975::LR 0.0538461538462 --> Loss 0.0045404835542\n",
      "Epoch 21::Minibatch 976::LR 0.0538461538462 --> Loss 0.00406889239947\n",
      "Epoch 21::Minibatch 977::LR 0.0538461538462 --> Loss 0.0040315258503\n",
      "Epoch 21::Minibatch 978::LR 0.0538461538462 --> Loss 0.00402810176214\n",
      "Epoch 21::Minibatch 979::LR 0.0538461538462 --> Loss 0.00394273797671\n",
      "Epoch 21::Minibatch 980::LR 0.0538461538462 --> Loss 0.00397306879361\n",
      "Epoch 21::Minibatch 981::LR 0.0538461538462 --> Loss 0.00517680287361\n",
      "Epoch 21::Minibatch 982::LR 0.0538461538462 --> Loss 0.00622971812884\n",
      "Epoch 21::Minibatch 983::LR 0.0538461538462 --> Loss 0.00299424827099\n",
      "Epoch 21::Minibatch 984::LR 0.0538461538462 --> Loss 0.00249610543251\n",
      "Epoch 21::Minibatch 985::LR 0.0538461538462 --> Loss 0.00427300254504\n",
      "Epoch 21::Minibatch 986::LR 0.0538461538462 --> Loss 0.00394273122152\n",
      "Epoch 21::Minibatch 987::LR 0.0538461538462 --> Loss 0.00422302166621\n",
      "Epoch 21::Minibatch 988::LR 0.0538461538462 --> Loss 0.00336185097694\n",
      "Epoch 21::Minibatch 989::LR 0.0538461538462 --> Loss 0.00350961009661\n",
      "Epoch 21::Minibatch 990::LR 0.0538461538462 --> Loss 0.00316757043203\n",
      "Epoch 21::Minibatch 991::LR 0.0538461538462 --> Loss 0.0017824747165\n",
      "Epoch 21::Minibatch 992::LR 0.0538461538462 --> Loss 0.00194231251876\n",
      "Epoch 21::Minibatch 993::LR 0.0538461538462 --> Loss 0.00347266554832\n",
      "Epoch 21::Minibatch 994::LR 0.0538461538462 --> Loss 0.00219116866589\n",
      "Epoch 21::Minibatch 995::LR 0.0538461538462 --> Loss 0.000908402502537\n",
      "Epoch 21::Minibatch 996::LR 0.0538461538462 --> Loss 0.00304439485073\n",
      "Epoch 21::Minibatch 997::LR 0.0538461538462 --> Loss 0.00232547561328\n",
      "Epoch 21::Minibatch 998::LR 0.0538461538462 --> Loss 0.00260188996792\n",
      "Epoch 21::Minibatch 999::LR 0.0538461538462 --> Loss 0.00216131269932\n",
      "Epoch 21::Minibatch 1000::LR 0.0538461538462 --> Loss 0.00254932622115\n",
      "Epoch 21::Minibatch 1001::LR 0.0538461538462 --> Loss 0.00206863860289\n",
      "Epoch 21::Minibatch 1002::LR 0.0538461538462 --> Loss 0.00214052160581\n",
      "Epoch 21::Minibatch 1003::LR 0.0538461538462 --> Loss 0.0032263537248\n",
      "Epoch 21::Minibatch 1004::LR 0.0538461538462 --> Loss 0.00110969891151\n",
      "Epoch 21::Minibatch 1005::LR 0.0538461538462 --> Loss 0.00327541410923\n",
      "Epoch 21::Minibatch 1006::LR 0.0538461538462 --> Loss 0.00186401943366\n",
      "Epoch 21::Minibatch 1007::LR 0.0538461538462 --> Loss 0.00230021357536\n",
      "Epoch 21::Minibatch 1008::LR 0.0538461538462 --> Loss 0.000993768970172\n",
      "Epoch 21::Minibatch 1009::LR 0.0538461538462 --> Loss 0.00141600777706\n",
      "Epoch 21::Minibatch 1010::LR 0.0538461538462 --> Loss 0.00125770578782\n",
      "Epoch 21::Minibatch 1011::LR 0.0538461538462 --> Loss 0.0022175693512\n",
      "Epoch 21::Minibatch 1012::LR 0.0538461538462 --> Loss 0.00156533628702\n",
      "Epoch 21::Minibatch 1013::LR 0.0538461538462 --> Loss 0.00407390594482\n",
      "Epoch 21::Minibatch 1014::LR 0.0538461538462 --> Loss 0.00384522954623\n",
      "Epoch 21::Minibatch 1015::LR 0.0538461538462 --> Loss 0.0016682100296\n",
      "Epoch 21::Minibatch 1016::LR 0.0538461538462 --> Loss 0.0048331618309\n",
      "Epoch 21::Minibatch 1017::LR 0.0538461538462 --> Loss 0.00277616143227\n",
      "Epoch 21::Minibatch 1018::LR 0.0538461538462 --> Loss 0.00280500988166\n",
      "Epoch 21::Minibatch 1019::LR 0.0538461538462 --> Loss 0.001863326629\n",
      "Epoch 21::Minibatch 1020::LR 0.0538461538462 --> Loss 0.00190481166045\n",
      "Epoch 21::Minibatch 1021::LR 0.0538461538462 --> Loss 0.00195680439472\n",
      "Epoch 21::Minibatch 1022::LR 0.0538461538462 --> Loss 0.00146979262431\n",
      "Epoch 21::Minibatch 1023::LR 0.0538461538462 --> Loss 0.00112116326888\n",
      "Epoch 21::Minibatch 1024::LR 0.0538461538462 --> Loss 0.00110410283009\n",
      "Epoch 21::Minibatch 1025::LR 0.0538461538462 --> Loss 0.00139791280031\n",
      "Epoch 21::Minibatch 1026::LR 0.0538461538462 --> Loss 0.000781320830186\n",
      "Epoch 21::Minibatch 1027::LR 0.0538461538462 --> Loss 0.00101591100295\n",
      "Epoch 21::Minibatch 1028::LR 0.0538461538462 --> Loss 0.000778020868699\n",
      "Epoch 21::Minibatch 1029::LR 0.0538461538462 --> Loss 0.000765932450692\n",
      "Epoch 21::Minibatch 1030::LR 0.0538461538462 --> Loss 0.000944576164087\n",
      "Epoch 21::Minibatch 1031::LR 0.0538461538462 --> Loss 0.00073391670982\n",
      "Epoch 21::Minibatch 1032::LR 0.0538461538462 --> Loss 0.000779422074556\n",
      "Epoch 21::Minibatch 1033::LR 0.0538461538462 --> Loss 0.000662818004688\n",
      "Epoch 21::Minibatch 1034::LR 0.0538461538462 --> Loss 0.00063696205616\n",
      "Epoch 21::Minibatch 1035::LR 0.0538461538462 --> Loss 0.000437132666508\n",
      "Epoch 21::Minibatch 1036::LR 0.0538461538462 --> Loss 0.000350448687871\n",
      "Epoch 21::Minibatch 1037::LR 0.0538461538462 --> Loss 0.000583548496167\n",
      "Epoch 21::Minibatch 1038::LR 0.0538461538462 --> Loss 0.00123868157466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21::Minibatch 1039::LR 0.0538461538462 --> Loss 0.000946374634902\n",
      "Epoch 21::Minibatch 1040::LR 0.0538461538462 --> Loss 0.000387366935611\n",
      "Epoch 21::Minibatch 1041::LR 0.0538461538462 --> Loss 0.000554445634286\n",
      "Epoch 22::Minibatch 1::LR 0.0515384615385 --> Loss 0.00877446810404\n",
      "Epoch 22::Minibatch 2::LR 0.0515384615385 --> Loss 0.00564901471138\n",
      "Epoch 22::Minibatch 3::LR 0.0515384615385 --> Loss 0.00364412069321\n",
      "Epoch 22::Minibatch 4::LR 0.0515384615385 --> Loss 0.00418021798134\n",
      "Epoch 22::Minibatch 5::LR 0.0515384615385 --> Loss 0.00462376515071\n",
      "Epoch 22::Minibatch 6::LR 0.0515384615385 --> Loss 0.00228895922502\n",
      "Epoch 22::Minibatch 7::LR 0.0515384615385 --> Loss 0.00759978850683\n",
      "Epoch 22::Minibatch 8::LR 0.0515384615385 --> Loss 0.00720733563105\n",
      "Epoch 22::Minibatch 9::LR 0.0515384615385 --> Loss 0.00539077480634\n",
      "Epoch 22::Minibatch 10::LR 0.0515384615385 --> Loss 0.00265221297741\n",
      "Epoch 22::Minibatch 11::LR 0.0515384615385 --> Loss 0.00237513840199\n",
      "Epoch 22::Minibatch 12::LR 0.0515384615385 --> Loss 0.00349706927935\n",
      "Epoch 22::Minibatch 13::LR 0.0515384615385 --> Loss 0.00535214662552\n",
      "Epoch 22::Minibatch 14::LR 0.0515384615385 --> Loss 0.00529938459396\n",
      "Epoch 22::Minibatch 15::LR 0.0515384615385 --> Loss 0.0044815381368\n",
      "Epoch 22::Minibatch 16::LR 0.0515384615385 --> Loss 0.000817366838455\n",
      "Epoch 22::Minibatch 17::LR 0.0515384615385 --> Loss 0.00315235892932\n",
      "Epoch 22::Minibatch 18::LR 0.0515384615385 --> Loss 0.00256348013878\n",
      "Epoch 22::Minibatch 19::LR 0.0515384615385 --> Loss 0.0013912225763\n",
      "Epoch 22::Minibatch 20::LR 0.0515384615385 --> Loss 0.00189415415128\n",
      "Epoch 22::Minibatch 21::LR 0.0515384615385 --> Loss 0.00330058435599\n",
      "Epoch 22::Minibatch 22::LR 0.0515384615385 --> Loss 0.00225761413574\n",
      "Epoch 22::Minibatch 23::LR 0.0515384615385 --> Loss 0.000818800727526\n",
      "Epoch 22::Minibatch 24::LR 0.0515384615385 --> Loss 0.000407735258341\n",
      "Epoch 22::Minibatch 25::LR 0.0515384615385 --> Loss 0.00117800335089\n",
      "Epoch 22::Minibatch 26::LR 0.0515384615385 --> Loss 0.00137899597486\n",
      "Epoch 22::Minibatch 27::LR 0.0515384615385 --> Loss 0.000979000528653\n",
      "Epoch 22::Minibatch 28::LR 0.0515384615385 --> Loss 0.000417466710011\n",
      "Epoch 22::Minibatch 29::LR 0.0515384615385 --> Loss 0.000439543028673\n",
      "Epoch 22::Minibatch 30::LR 0.0515384615385 --> Loss 0.000915517906348\n",
      "Epoch 22::Minibatch 31::LR 0.0515384615385 --> Loss 0.00140436490377\n",
      "Epoch 22::Minibatch 32::LR 0.0515384615385 --> Loss 0.00129543741544\n",
      "Epoch 22::Minibatch 33::LR 0.0515384615385 --> Loss 0.000779058833917\n",
      "Epoch 22::Minibatch 34::LR 0.0515384615385 --> Loss 0.00222288866838\n",
      "Epoch 22::Minibatch 35::LR 0.0515384615385 --> Loss 0.00360216418902\n",
      "Epoch 22::Minibatch 36::LR 0.0515384615385 --> Loss 0.00223372300466\n",
      "Epoch 22::Minibatch 37::LR 0.0515384615385 --> Loss 0.000646985471249\n",
      "Epoch 22::Minibatch 38::LR 0.0515384615385 --> Loss 0.000718255837758\n",
      "Epoch 22::Minibatch 39::LR 0.0515384615385 --> Loss 0.00230398495992\n",
      "Epoch 22::Minibatch 40::LR 0.0515384615385 --> Loss 0.00326067487399\n",
      "Epoch 22::Minibatch 41::LR 0.0515384615385 --> Loss 0.00265276193619\n",
      "Epoch 22::Minibatch 42::LR 0.0515384615385 --> Loss 0.00555079738299\n",
      "Epoch 22::Minibatch 43::LR 0.0515384615385 --> Loss 0.00189351360003\n",
      "Epoch 22::Minibatch 44::LR 0.0515384615385 --> Loss 0.00311370849609\n",
      "Epoch 22::Minibatch 45::LR 0.0515384615385 --> Loss 0.00241704980532\n",
      "Epoch 22::Minibatch 46::LR 0.0515384615385 --> Loss 0.00327464222908\n",
      "Epoch 22::Minibatch 47::LR 0.0515384615385 --> Loss 0.00400972406069\n",
      "Epoch 22::Minibatch 48::LR 0.0515384615385 --> Loss 0.00554899136225\n",
      "Epoch 22::Minibatch 49::LR 0.0515384615385 --> Loss 0.00599050958951\n",
      "Epoch 22::Minibatch 50::LR 0.0515384615385 --> Loss 0.00609972675641\n",
      "Epoch 22::Minibatch 51::LR 0.0515384615385 --> Loss 0.00586468458176\n",
      "Epoch 22::Minibatch 52::LR 0.0515384615385 --> Loss 0.0034475628535\n",
      "Epoch 22::Minibatch 53::LR 0.0515384615385 --> Loss 0.00338521877925\n",
      "Epoch 22::Minibatch 54::LR 0.0515384615385 --> Loss 0.00400899569194\n",
      "Epoch 22::Minibatch 55::LR 0.0515384615385 --> Loss 0.000983655452728\n",
      "Epoch 22::Minibatch 56::LR 0.0515384615385 --> Loss 0.00268610080083\n",
      "Epoch 22::Minibatch 57::LR 0.0515384615385 --> Loss 0.00518293261528\n",
      "Epoch 22::Minibatch 58::LR 0.0515384615385 --> Loss 0.00328484177589\n",
      "Epoch 22::Minibatch 59::LR 0.0515384615385 --> Loss 0.00243396361669\n",
      "Epoch 22::Minibatch 60::LR 0.0515384615385 --> Loss 0.00239095687866\n",
      "Epoch 22::Minibatch 61::LR 0.0515384615385 --> Loss 0.000806387762229\n",
      "Epoch 22::Minibatch 62::LR 0.0515384615385 --> Loss 0.00289906561375\n",
      "Epoch 22::Minibatch 63::LR 0.0515384615385 --> Loss 0.00204132994016\n",
      "Epoch 22::Minibatch 64::LR 0.0515384615385 --> Loss 0.00086532553037\n",
      "Epoch 22::Minibatch 65::LR 0.0515384615385 --> Loss 0.00226759413878\n",
      "Epoch 22::Minibatch 66::LR 0.0515384615385 --> Loss 0.00274808049202\n",
      "Epoch 22::Minibatch 67::LR 0.0515384615385 --> Loss 0.00268198688825\n",
      "Epoch 22::Minibatch 68::LR 0.0515384615385 --> Loss 0.0019171645244\n",
      "Epoch 22::Minibatch 69::LR 0.0515384615385 --> Loss 0.00385118405024\n",
      "Epoch 22::Minibatch 70::LR 0.0515384615385 --> Loss 0.00337179978689\n",
      "Epoch 22::Minibatch 71::LR 0.0515384615385 --> Loss 0.0022942250967\n",
      "Epoch 22::Minibatch 72::LR 0.0515384615385 --> Loss 0.000536834597588\n",
      "Epoch 22::Minibatch 73::LR 0.0515384615385 --> Loss 0.00384750127792\n",
      "Epoch 22::Minibatch 74::LR 0.0515384615385 --> Loss 0.004090162913\n",
      "Epoch 22::Minibatch 75::LR 0.0515384615385 --> Loss 0.00230533599854\n",
      "Epoch 22::Minibatch 76::LR 0.0515384615385 --> Loss 0.000554663191239\n",
      "Epoch 22::Minibatch 77::LR 0.0515384615385 --> Loss 0.00365016619364\n",
      "Epoch 22::Minibatch 78::LR 0.0515384615385 --> Loss 0.00384727120399\n",
      "Epoch 22::Minibatch 79::LR 0.0515384615385 --> Loss 0.00187708954016\n",
      "Epoch 22::Minibatch 80::LR 0.0515384615385 --> Loss 0.00309839447339\n",
      "Epoch 22::Minibatch 81::LR 0.0515384615385 --> Loss 0.00269314865271\n",
      "Epoch 22::Minibatch 82::LR 0.0515384615385 --> Loss 0.0019498415788\n",
      "Epoch 22::Minibatch 83::LR 0.0515384615385 --> Loss 0.00433963338534\n",
      "Epoch 22::Minibatch 84::LR 0.0515384615385 --> Loss 0.00194674650828\n",
      "Epoch 22::Minibatch 85::LR 0.0515384615385 --> Loss 0.00268787880739\n",
      "Epoch 22::Minibatch 86::LR 0.0515384615385 --> Loss 0.00217316687107\n",
      "Epoch 22::Minibatch 87::LR 0.0515384615385 --> Loss 0.00237417340279\n",
      "Epoch 22::Minibatch 88::LR 0.0515384615385 --> Loss 0.00174175639947\n",
      "Epoch 22::Minibatch 89::LR 0.0515384615385 --> Loss 0.0022785170873\n",
      "Epoch 22::Minibatch 90::LR 0.0515384615385 --> Loss 0.00108079572519\n",
      "Epoch 22::Minibatch 91::LR 0.0515384615385 --> Loss 0.000874685645103\n",
      "Epoch 22::Minibatch 92::LR 0.0515384615385 --> Loss 0.00264988044898\n",
      "Epoch 22::Minibatch 93::LR 0.0515384615385 --> Loss 0.00173538903395\n",
      "Epoch 22::Minibatch 94::LR 0.0515384615385 --> Loss 0.00175257623196\n",
      "Epoch 22::Minibatch 95::LR 0.0515384615385 --> Loss 0.00183709303538\n",
      "Epoch 22::Minibatch 96::LR 0.0515384615385 --> Loss 0.00544436852137\n",
      "Epoch 22::Minibatch 97::LR 0.0515384615385 --> Loss 0.00310457070669\n",
      "Epoch 22::Minibatch 98::LR 0.0515384615385 --> Loss 0.00101082185904\n",
      "Epoch 22::Minibatch 99::LR 0.0515384615385 --> Loss 0.0013344279925\n",
      "Epoch 22::Minibatch 100::LR 0.0515384615385 --> Loss 0.00482203006744\n",
      "Epoch 22::Minibatch 101::LR 0.0515384615385 --> Loss 0.000913620491823\n",
      "Epoch 22::Minibatch 102::LR 0.0515384615385 --> Loss 0.00388300498327\n",
      "Epoch 22::Minibatch 103::LR 0.0515384615385 --> Loss 0.0039874235789\n",
      "Epoch 22::Minibatch 104::LR 0.0515384615385 --> Loss 0.00272533436616\n",
      "Epoch 22::Minibatch 105::LR 0.0515384615385 --> Loss 0.0024889677763\n",
      "Epoch 22::Minibatch 106::LR 0.0515384615385 --> Loss 0.0164268048604\n",
      "Epoch 22::Minibatch 107::LR 0.0515384615385 --> Loss 0.00484502037366\n",
      "Epoch 22::Minibatch 108::LR 0.0515384615385 --> Loss 0.00100280940533\n",
      "Epoch 22::Minibatch 109::LR 0.0515384615385 --> Loss 0.00432650486628\n",
      "Epoch 22::Minibatch 110::LR 0.0515384615385 --> Loss 0.00231837471326\n",
      "Epoch 22::Minibatch 111::LR 0.0515384615385 --> Loss 0.000905138850212\n",
      "Epoch 22::Minibatch 112::LR 0.0515384615385 --> Loss 0.00344922661781\n",
      "Epoch 22::Minibatch 113::LR 0.0515384615385 --> Loss 0.00255573511124\n",
      "Epoch 22::Minibatch 114::LR 0.0515384615385 --> Loss 0.00141601920128\n",
      "Epoch 22::Minibatch 115::LR 0.0515384615385 --> Loss 0.00125904738903\n",
      "Epoch 22::Minibatch 116::LR 0.0515384615385 --> Loss 0.00271743953228\n",
      "Epoch 22::Minibatch 117::LR 0.0515384615385 --> Loss 0.00387649178505\n",
      "Epoch 22::Minibatch 118::LR 0.0515384615385 --> Loss 0.00680175701777\n",
      "Epoch 22::Minibatch 119::LR 0.0515384615385 --> Loss 0.000590474257867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 120::LR 0.0515384615385 --> Loss 0.00170629680157\n",
      "Epoch 22::Minibatch 121::LR 0.0515384615385 --> Loss 0.00254672269026\n",
      "Epoch 22::Minibatch 122::LR 0.0515384615385 --> Loss 0.00372920910517\n",
      "Epoch 22::Minibatch 123::LR 0.0515384615385 --> Loss 0.000901738305887\n",
      "Epoch 22::Minibatch 124::LR 0.0515384615385 --> Loss 0.00269632577896\n",
      "Epoch 22::Minibatch 125::LR 0.0515384615385 --> Loss 0.00455050269763\n",
      "Epoch 22::Minibatch 126::LR 0.0515384615385 --> Loss 0.00262880722682\n",
      "Epoch 22::Minibatch 127::LR 0.0515384615385 --> Loss 0.00448478102684\n",
      "Epoch 22::Minibatch 128::LR 0.0515384615385 --> Loss 0.00358650843302\n",
      "Epoch 22::Minibatch 129::LR 0.0515384615385 --> Loss 0.00260771075885\n",
      "Epoch 22::Minibatch 130::LR 0.0515384615385 --> Loss 0.00434965809186\n",
      "Epoch 22::Minibatch 131::LR 0.0515384615385 --> Loss 0.00176472385724\n",
      "Epoch 22::Minibatch 132::LR 0.0515384615385 --> Loss 0.00300153752168\n",
      "Epoch 22::Minibatch 133::LR 0.0515384615385 --> Loss 0.00285948415597\n",
      "Epoch 22::Minibatch 134::LR 0.0515384615385 --> Loss 0.00228359858195\n",
      "Epoch 22::Minibatch 135::LR 0.0515384615385 --> Loss 0.00147858907779\n",
      "Epoch 22::Minibatch 136::LR 0.0515384615385 --> Loss 0.00262722015381\n",
      "Epoch 22::Minibatch 137::LR 0.0515384615385 --> Loss 0.00359953840574\n",
      "Epoch 22::Minibatch 138::LR 0.0515384615385 --> Loss 0.00127744197845\n",
      "Epoch 22::Minibatch 139::LR 0.0515384615385 --> Loss 0.00190710266431\n",
      "Epoch 22::Minibatch 140::LR 0.0515384615385 --> Loss 0.00244466662407\n",
      "Epoch 22::Minibatch 141::LR 0.0515384615385 --> Loss 0.00295693993568\n",
      "Epoch 22::Minibatch 142::LR 0.0515384615385 --> Loss 0.00280251781146\n",
      "Epoch 22::Minibatch 143::LR 0.0515384615385 --> Loss 0.000584157655636\n",
      "Epoch 22::Minibatch 144::LR 0.0515384615385 --> Loss 0.00326942364375\n",
      "Epoch 22::Minibatch 145::LR 0.0515384615385 --> Loss 0.00425584872564\n",
      "Epoch 22::Minibatch 146::LR 0.0515384615385 --> Loss 0.00255161603292\n",
      "Epoch 22::Minibatch 147::LR 0.0515384615385 --> Loss 0.00180595993996\n",
      "Epoch 22::Minibatch 148::LR 0.0515384615385 --> Loss 0.0010006270806\n",
      "Epoch 22::Minibatch 149::LR 0.0515384615385 --> Loss 0.00283741394679\n",
      "Epoch 22::Minibatch 150::LR 0.0515384615385 --> Loss 0.00269881804784\n",
      "Epoch 22::Minibatch 151::LR 0.0515384615385 --> Loss 0.00424983064334\n",
      "Epoch 22::Minibatch 152::LR 0.0515384615385 --> Loss 0.000914731323719\n",
      "Epoch 22::Minibatch 153::LR 0.0515384615385 --> Loss 0.00176248510679\n",
      "Epoch 22::Minibatch 154::LR 0.0515384615385 --> Loss 0.00204134762287\n",
      "Epoch 22::Minibatch 155::LR 0.0515384615385 --> Loss 0.00435827334722\n",
      "Epoch 22::Minibatch 156::LR 0.0515384615385 --> Loss 0.0023818397522\n",
      "Epoch 22::Minibatch 157::LR 0.0515384615385 --> Loss 0.000695681323608\n",
      "Epoch 22::Minibatch 158::LR 0.0515384615385 --> Loss 0.00308382372061\n",
      "Epoch 22::Minibatch 159::LR 0.0515384615385 --> Loss 0.0027436564366\n",
      "Epoch 22::Minibatch 160::LR 0.0515384615385 --> Loss 0.00263065139453\n",
      "Epoch 22::Minibatch 161::LR 0.0515384615385 --> Loss 0.00101524571578\n",
      "Epoch 22::Minibatch 162::LR 0.0515384615385 --> Loss 0.00380742073059\n",
      "Epoch 22::Minibatch 163::LR 0.0515384615385 --> Loss 0.00239434619745\n",
      "Epoch 22::Minibatch 164::LR 0.0515384615385 --> Loss 0.00250104745229\n",
      "Epoch 22::Minibatch 165::LR 0.0515384615385 --> Loss 0.000518961250782\n",
      "Epoch 22::Minibatch 166::LR 0.0515384615385 --> Loss 0.00176293651263\n",
      "Epoch 22::Minibatch 167::LR 0.0515384615385 --> Loss 0.00245778282483\n",
      "Epoch 22::Minibatch 168::LR 0.0515384615385 --> Loss 0.00216964344184\n",
      "Epoch 22::Minibatch 169::LR 0.0515384615385 --> Loss 0.00100672433774\n",
      "Epoch 22::Minibatch 170::LR 0.0515384615385 --> Loss 0.000980417629083\n",
      "Epoch 22::Minibatch 171::LR 0.0515384615385 --> Loss 0.00250309904416\n",
      "Epoch 22::Minibatch 172::LR 0.0515384615385 --> Loss 0.00436928749084\n",
      "Epoch 22::Minibatch 173::LR 0.0515384615385 --> Loss 0.00195249716441\n",
      "Epoch 22::Minibatch 174::LR 0.0515384615385 --> Loss 0.00101855317752\n",
      "Epoch 22::Minibatch 175::LR 0.0515384615385 --> Loss 0.00231439689795\n",
      "Epoch 22::Minibatch 176::LR 0.0515384615385 --> Loss 0.00323682308197\n",
      "Epoch 22::Minibatch 177::LR 0.0515384615385 --> Loss 0.00447260181109\n",
      "Epoch 22::Minibatch 178::LR 0.0515384615385 --> Loss 0.00160059114297\n",
      "Epoch 22::Minibatch 179::LR 0.0515384615385 --> Loss 0.00132562885682\n",
      "Epoch 22::Minibatch 180::LR 0.0515384615385 --> Loss 0.00356101791064\n",
      "Epoch 22::Minibatch 181::LR 0.0515384615385 --> Loss 0.00320109367371\n",
      "Epoch 22::Minibatch 182::LR 0.0515384615385 --> Loss 0.000757040629784\n",
      "Epoch 22::Minibatch 183::LR 0.0515384615385 --> Loss 0.00165635108948\n",
      "Epoch 22::Minibatch 184::LR 0.0515384615385 --> Loss 0.0034302230676\n",
      "Epoch 22::Minibatch 185::LR 0.0515384615385 --> Loss 0.00280866245429\n",
      "Epoch 22::Minibatch 186::LR 0.0515384615385 --> Loss 0.000963006814321\n",
      "Epoch 22::Minibatch 187::LR 0.0515384615385 --> Loss 0.00127237031857\n",
      "Epoch 22::Minibatch 188::LR 0.0515384615385 --> Loss 0.00417154550552\n",
      "Epoch 22::Minibatch 189::LR 0.0515384615385 --> Loss 0.00435821413994\n",
      "Epoch 22::Minibatch 190::LR 0.0515384615385 --> Loss 0.00232438504696\n",
      "Epoch 22::Minibatch 191::LR 0.0515384615385 --> Loss 0.00047069032987\n",
      "Epoch 22::Minibatch 192::LR 0.0515384615385 --> Loss 0.00273383239905\n",
      "Epoch 22::Minibatch 193::LR 0.0515384615385 --> Loss 0.00260313252608\n",
      "Epoch 22::Minibatch 194::LR 0.0515384615385 --> Loss 0.00177111228307\n",
      "Epoch 22::Minibatch 195::LR 0.0515384615385 --> Loss 0.000383928293983\n",
      "Epoch 22::Minibatch 196::LR 0.0515384615385 --> Loss 0.00126588255167\n",
      "Epoch 22::Minibatch 197::LR 0.0515384615385 --> Loss 0.00289757510026\n",
      "Epoch 22::Minibatch 198::LR 0.0515384615385 --> Loss 0.00223426540693\n",
      "Epoch 22::Minibatch 199::LR 0.0515384615385 --> Loss 0.000288851807515\n",
      "Epoch 22::Minibatch 200::LR 0.0515384615385 --> Loss 0.00205143590768\n",
      "Epoch 22::Minibatch 201::LR 0.0515384615385 --> Loss 0.00194694300493\n",
      "Epoch 22::Minibatch 202::LR 0.0515384615385 --> Loss 0.00185152212779\n",
      "Epoch 22::Minibatch 203::LR 0.0515384615385 --> Loss 0.00176047503948\n",
      "Epoch 22::Minibatch 204::LR 0.0515384615385 --> Loss 0.00144054075082\n",
      "Epoch 22::Minibatch 205::LR 0.0515384615385 --> Loss 0.00220240573088\n",
      "Epoch 22::Minibatch 206::LR 0.0515384615385 --> Loss 0.00617346167564\n",
      "Epoch 22::Minibatch 207::LR 0.0515384615385 --> Loss 0.00139572938283\n",
      "Epoch 22::Minibatch 208::LR 0.0515384615385 --> Loss 0.00111858059963\n",
      "Epoch 22::Minibatch 209::LR 0.0515384615385 --> Loss 0.00227775176366\n",
      "Epoch 22::Minibatch 210::LR 0.0515384615385 --> Loss 0.00217492103577\n",
      "Epoch 22::Minibatch 211::LR 0.0515384615385 --> Loss 0.00238135198752\n",
      "Epoch 22::Minibatch 212::LR 0.0515384615385 --> Loss 0.00391627589862\n",
      "Epoch 22::Minibatch 213::LR 0.0515384615385 --> Loss 0.00572880029678\n",
      "Epoch 22::Minibatch 214::LR 0.0515384615385 --> Loss 0.00859311262767\n",
      "Epoch 22::Minibatch 215::LR 0.0515384615385 --> Loss 0.00137712756793\n",
      "Epoch 22::Minibatch 216::LR 0.0515384615385 --> Loss 0.00545305887858\n",
      "Epoch 22::Minibatch 217::LR 0.0515384615385 --> Loss 0.00610007603963\n",
      "Epoch 22::Minibatch 218::LR 0.0515384615385 --> Loss 0.00392218748728\n",
      "Epoch 22::Minibatch 219::LR 0.0515384615385 --> Loss 0.00421216169993\n",
      "Epoch 22::Minibatch 220::LR 0.0515384615385 --> Loss 0.0044709444046\n",
      "Epoch 22::Minibatch 221::LR 0.0515384615385 --> Loss 0.00425099253654\n",
      "Epoch 22::Minibatch 222::LR 0.0515384615385 --> Loss 0.00322496275107\n",
      "Epoch 22::Minibatch 223::LR 0.0515384615385 --> Loss 0.00140611797571\n",
      "Epoch 22::Minibatch 224::LR 0.0515384615385 --> Loss 0.00170631249746\n",
      "Epoch 22::Minibatch 225::LR 0.0515384615385 --> Loss 0.00742098331451\n",
      "Epoch 22::Minibatch 226::LR 0.0515384615385 --> Loss 0.00375925858816\n",
      "Epoch 22::Minibatch 227::LR 0.0515384615385 --> Loss 0.00168802936872\n",
      "Epoch 22::Minibatch 228::LR 0.0515384615385 --> Loss 0.000713204840819\n",
      "Epoch 22::Minibatch 229::LR 0.0515384615385 --> Loss 0.00474992314974\n",
      "Epoch 22::Minibatch 230::LR 0.0515384615385 --> Loss 0.00387113014857\n",
      "Epoch 22::Minibatch 231::LR 0.0515384615385 --> Loss 0.0026450073719\n",
      "Epoch 22::Minibatch 232::LR 0.0515384615385 --> Loss 0.00119971940915\n",
      "Epoch 22::Minibatch 233::LR 0.0515384615385 --> Loss 0.00243477801482\n",
      "Epoch 22::Minibatch 234::LR 0.0515384615385 --> Loss 0.00703748146693\n",
      "Epoch 22::Minibatch 235::LR 0.0515384615385 --> Loss 0.00464657664299\n",
      "Epoch 22::Minibatch 236::LR 0.0515384615385 --> Loss 0.00173880040646\n",
      "Epoch 22::Minibatch 237::LR 0.0515384615385 --> Loss 0.00065517137448\n",
      "Epoch 22::Minibatch 238::LR 0.0515384615385 --> Loss 0.00341314673424\n",
      "Epoch 22::Minibatch 239::LR 0.0515384615385 --> Loss 0.00296004414558\n",
      "Epoch 22::Minibatch 240::LR 0.0515384615385 --> Loss 0.00324263115724\n",
      "Epoch 22::Minibatch 241::LR 0.0515384615385 --> Loss 0.000755533228318\n",
      "Epoch 22::Minibatch 242::LR 0.0515384615385 --> Loss 0.00694804747899\n",
      "Epoch 22::Minibatch 243::LR 0.0515384615385 --> Loss 0.00344943006833\n",
      "Epoch 22::Minibatch 244::LR 0.0515384615385 --> Loss 0.00288619418939\n",
      "Epoch 22::Minibatch 245::LR 0.0515384615385 --> Loss 0.00046132594347\n",
      "Epoch 22::Minibatch 246::LR 0.0515384615385 --> Loss 0.00202011724313\n",
      "Epoch 22::Minibatch 247::LR 0.0515384615385 --> Loss 0.0122834825516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 248::LR 0.0515384615385 --> Loss 0.00443941354752\n",
      "Epoch 22::Minibatch 249::LR 0.0515384615385 --> Loss 0.00261458118757\n",
      "Epoch 22::Minibatch 250::LR 0.0515384615385 --> Loss 0.00250774164995\n",
      "Epoch 22::Minibatch 251::LR 0.0515384615385 --> Loss 0.00246268590291\n",
      "Epoch 22::Minibatch 252::LR 0.0515384615385 --> Loss 0.00173499902089\n",
      "Epoch 22::Minibatch 253::LR 0.0515384615385 --> Loss 0.00301179587841\n",
      "Epoch 22::Minibatch 254::LR 0.0515384615385 --> Loss 0.00504217505455\n",
      "Epoch 22::Minibatch 255::LR 0.0515384615385 --> Loss 0.00386126319567\n",
      "Epoch 22::Minibatch 256::LR 0.0515384615385 --> Loss 0.00156746516625\n",
      "Epoch 22::Minibatch 257::LR 0.0515384615385 --> Loss 0.00120027393103\n",
      "Epoch 22::Minibatch 258::LR 0.0515384615385 --> Loss 0.00363310217857\n",
      "Epoch 22::Minibatch 259::LR 0.0515384615385 --> Loss 0.00173337121805\n",
      "Epoch 22::Minibatch 260::LR 0.0515384615385 --> Loss 0.00187722166379\n",
      "Epoch 22::Minibatch 261::LR 0.0515384615385 --> Loss 0.00281688551108\n",
      "Epoch 22::Minibatch 262::LR 0.0515384615385 --> Loss 0.00189599692822\n",
      "Epoch 22::Minibatch 263::LR 0.0515384615385 --> Loss 0.00234747330348\n",
      "Epoch 22::Minibatch 264::LR 0.0515384615385 --> Loss 0.00361922184626\n",
      "Epoch 22::Minibatch 265::LR 0.0515384615385 --> Loss 0.0100816321373\n",
      "Epoch 22::Minibatch 266::LR 0.0515384615385 --> Loss 0.000978753765424\n",
      "Epoch 22::Minibatch 267::LR 0.0515384615385 --> Loss 0.00974310398102\n",
      "Epoch 22::Minibatch 268::LR 0.0515384615385 --> Loss 0.00114370296399\n",
      "Epoch 22::Minibatch 269::LR 0.0515384615385 --> Loss 0.00348722219467\n",
      "Epoch 22::Minibatch 270::LR 0.0515384615385 --> Loss 0.00682553370794\n",
      "Epoch 22::Minibatch 271::LR 0.0515384615385 --> Loss 0.00262918372949\n",
      "Epoch 22::Minibatch 272::LR 0.0515384615385 --> Loss 0.00419034401576\n",
      "Epoch 22::Minibatch 273::LR 0.0515384615385 --> Loss 0.00158706108729\n",
      "Epoch 22::Minibatch 274::LR 0.0515384615385 --> Loss 0.00179037551085\n",
      "Epoch 22::Minibatch 275::LR 0.0515384615385 --> Loss 0.00260096291701\n",
      "Epoch 22::Minibatch 276::LR 0.0515384615385 --> Loss 0.00344042539597\n",
      "Epoch 22::Minibatch 277::LR 0.0515384615385 --> Loss 0.000961958765984\n",
      "Epoch 22::Minibatch 278::LR 0.0515384615385 --> Loss 0.00261253476143\n",
      "Epoch 22::Minibatch 279::LR 0.0515384615385 --> Loss 0.00226676424344\n",
      "Epoch 22::Minibatch 280::LR 0.0515384615385 --> Loss 0.00198296586672\n",
      "Epoch 22::Minibatch 281::LR 0.0515384615385 --> Loss 0.001249969999\n",
      "Epoch 22::Minibatch 282::LR 0.0515384615385 --> Loss 0.00217533051968\n",
      "Epoch 22::Minibatch 283::LR 0.0515384615385 --> Loss 0.00210750480493\n",
      "Epoch 22::Minibatch 284::LR 0.0515384615385 --> Loss 0.00169446210066\n",
      "Epoch 22::Minibatch 285::LR 0.0515384615385 --> Loss 0.00119409362475\n",
      "Epoch 22::Minibatch 286::LR 0.0515384615385 --> Loss 0.0020980177323\n",
      "Epoch 22::Minibatch 287::LR 0.0515384615385 --> Loss 0.00204935789108\n",
      "Epoch 22::Minibatch 288::LR 0.0515384615385 --> Loss 0.00110635558764\n",
      "Epoch 22::Minibatch 289::LR 0.0515384615385 --> Loss 0.0015995401144\n",
      "Epoch 22::Minibatch 290::LR 0.0515384615385 --> Loss 0.00192630887032\n",
      "Epoch 22::Minibatch 291::LR 0.0515384615385 --> Loss 0.00171799878279\n",
      "Epoch 22::Minibatch 292::LR 0.0515384615385 --> Loss 0.000602880418301\n",
      "Epoch 22::Minibatch 293::LR 0.0515384615385 --> Loss 0.00150420129299\n",
      "Epoch 22::Minibatch 294::LR 0.0515384615385 --> Loss 0.00158875674009\n",
      "Epoch 22::Minibatch 295::LR 0.0515384615385 --> Loss 0.00187697331111\n",
      "Epoch 22::Minibatch 296::LR 0.0515384615385 --> Loss 0.0016287612915\n",
      "Epoch 22::Minibatch 297::LR 0.0515384615385 --> Loss 0.00141386389732\n",
      "Epoch 22::Minibatch 298::LR 0.0515384615385 --> Loss 0.00140567958355\n",
      "Epoch 22::Minibatch 299::LR 0.0515384615385 --> Loss 0.000804465164741\n",
      "Epoch 22::Minibatch 300::LR 0.0515384615385 --> Loss 0.0027720862627\n",
      "Epoch 22::Minibatch 301::LR 0.0515384615385 --> Loss 0.00268429219723\n",
      "Epoch 22::Minibatch 302::LR 0.0515384615385 --> Loss 0.00246721883615\n",
      "Epoch 22::Minibatch 303::LR 0.0515384615385 --> Loss 0.00085179567337\n",
      "Epoch 22::Minibatch 304::LR 0.0515384615385 --> Loss 0.00305357058843\n",
      "Epoch 22::Minibatch 305::LR 0.0515384615385 --> Loss 0.00169902404149\n",
      "Epoch 22::Minibatch 306::LR 0.0515384615385 --> Loss 0.000934620002906\n",
      "Epoch 22::Minibatch 307::LR 0.0515384615385 --> Loss 0.00244022548199\n",
      "Epoch 22::Minibatch 308::LR 0.0515384615385 --> Loss 0.00200628658136\n",
      "Epoch 22::Minibatch 309::LR 0.0515384615385 --> Loss 0.00101839045684\n",
      "Epoch 22::Minibatch 310::LR 0.0515384615385 --> Loss 0.0011492695411\n",
      "Epoch 22::Minibatch 311::LR 0.0515384615385 --> Loss 0.00175275305907\n",
      "Epoch 22::Minibatch 312::LR 0.0515384615385 --> Loss 0.00291571517785\n",
      "Epoch 22::Minibatch 313::LR 0.0515384615385 --> Loss 0.00237888892492\n",
      "Epoch 22::Minibatch 314::LR 0.0515384615385 --> Loss 0.00192015926043\n",
      "Epoch 22::Minibatch 315::LR 0.0515384615385 --> Loss 0.00101524055004\n",
      "Epoch 22::Minibatch 316::LR 0.0515384615385 --> Loss 0.00233464539051\n",
      "Epoch 22::Minibatch 317::LR 0.0515384615385 --> Loss 0.00155171821515\n",
      "Epoch 22::Minibatch 318::LR 0.0515384615385 --> Loss 0.00125661849976\n",
      "Epoch 22::Minibatch 319::LR 0.0515384615385 --> Loss 0.00229946176211\n",
      "Epoch 22::Minibatch 320::LR 0.0515384615385 --> Loss 0.0031386089325\n",
      "Epoch 22::Minibatch 321::LR 0.0515384615385 --> Loss 0.000844495991866\n",
      "Epoch 22::Minibatch 322::LR 0.0515384615385 --> Loss 0.00359865903854\n",
      "Epoch 22::Minibatch 323::LR 0.0515384615385 --> Loss 0.0034931397438\n",
      "Epoch 22::Minibatch 324::LR 0.0515384615385 --> Loss 0.00263765295347\n",
      "Epoch 22::Minibatch 325::LR 0.0515384615385 --> Loss 0.00239051977793\n",
      "Epoch 22::Minibatch 326::LR 0.0515384615385 --> Loss 0.00545905868212\n",
      "Epoch 22::Minibatch 327::LR 0.0515384615385 --> Loss 0.00224956830343\n",
      "Epoch 22::Minibatch 328::LR 0.0515384615385 --> Loss 0.00315449118614\n",
      "Epoch 22::Minibatch 329::LR 0.0515384615385 --> Loss 0.0012141430378\n",
      "Epoch 22::Minibatch 330::LR 0.0515384615385 --> Loss 0.0015954665343\n",
      "Epoch 22::Minibatch 331::LR 0.0515384615385 --> Loss 0.00253950019677\n",
      "Epoch 22::Minibatch 332::LR 0.0515384615385 --> Loss 0.00248749713103\n",
      "Epoch 22::Minibatch 333::LR 0.0515384615385 --> Loss 0.00145333806674\n",
      "Epoch 22::Minibatch 334::LR 0.0515384615385 --> Loss 0.00441145976384\n",
      "Epoch 22::Minibatch 335::LR 0.0515384615385 --> Loss 0.00188862383366\n",
      "Epoch 22::Minibatch 336::LR 0.0515384615385 --> Loss 0.00220053076744\n",
      "Epoch 22::Minibatch 337::LR 0.0515384615385 --> Loss 0.00353871862094\n",
      "Epoch 22::Minibatch 338::LR 0.0515384615385 --> Loss 0.000531583825747\n",
      "Epoch 22::Minibatch 339::LR 0.0515384615385 --> Loss 0.00330569783847\n",
      "Epoch 22::Minibatch 340::LR 0.0515384615385 --> Loss 0.00392680128415\n",
      "Epoch 22::Minibatch 341::LR 0.0515384615385 --> Loss 0.00463964541753\n",
      "Epoch 22::Minibatch 342::LR 0.0515384615385 --> Loss 0.00309459288915\n",
      "Epoch 22::Minibatch 343::LR 0.0515384615385 --> Loss 0.00165847311417\n",
      "Epoch 22::Minibatch 344::LR 0.0515384615385 --> Loss 0.00314761837324\n",
      "Epoch 22::Minibatch 345::LR 0.0515384615385 --> Loss 0.00420489907265\n",
      "Epoch 22::Minibatch 346::LR 0.0515384615385 --> Loss 0.00557407180468\n",
      "Epoch 22::Minibatch 347::LR 0.0515384615385 --> Loss 0.000843297342459\n",
      "Epoch 22::Minibatch 348::LR 0.0515384615385 --> Loss 0.00326260050138\n",
      "Epoch 22::Minibatch 349::LR 0.0515384615385 --> Loss 0.00346992293994\n",
      "Epoch 22::Minibatch 350::LR 0.0515384615385 --> Loss 0.00172380030155\n",
      "Epoch 22::Minibatch 351::LR 0.0515384615385 --> Loss 0.003498711586\n",
      "Epoch 22::Minibatch 352::LR 0.0515384615385 --> Loss 0.00491402347883\n",
      "Epoch 22::Minibatch 353::LR 0.0515384615385 --> Loss 0.00353847662608\n",
      "Epoch 22::Minibatch 354::LR 0.0515384615385 --> Loss 0.00293912132581\n",
      "Epoch 22::Minibatch 355::LR 0.0515384615385 --> Loss 0.00616744716962\n",
      "Epoch 22::Minibatch 356::LR 0.0515384615385 --> Loss 0.0031292372942\n",
      "Epoch 22::Minibatch 357::LR 0.0515384615385 --> Loss 0.00114963928858\n",
      "Epoch 22::Minibatch 358::LR 0.0515384615385 --> Loss 0.0020664036274\n",
      "Epoch 22::Minibatch 359::LR 0.0515384615385 --> Loss 0.00270513852437\n",
      "Epoch 22::Minibatch 360::LR 0.0515384615385 --> Loss 0.00238411664963\n",
      "Epoch 22::Minibatch 361::LR 0.0515384615385 --> Loss 0.00236281534036\n",
      "Epoch 22::Minibatch 362::LR 0.0515384615385 --> Loss 0.00234305838744\n",
      "Epoch 22::Minibatch 363::LR 0.0515384615385 --> Loss 0.000649061749379\n",
      "Epoch 22::Minibatch 364::LR 0.0515384615385 --> Loss 0.00199068089326\n",
      "Epoch 22::Minibatch 365::LR 0.0515384615385 --> Loss 0.00205944955349\n",
      "Epoch 22::Minibatch 366::LR 0.0515384615385 --> Loss 0.0021958309412\n",
      "Epoch 22::Minibatch 367::LR 0.0515384615385 --> Loss 0.00104848434528\n",
      "Epoch 22::Minibatch 368::LR 0.0515384615385 --> Loss 0.000977176725864\n",
      "Epoch 22::Minibatch 369::LR 0.0515384615385 --> Loss 0.00284131149451\n",
      "Epoch 22::Minibatch 370::LR 0.0515384615385 --> Loss 0.00224569916725\n",
      "Epoch 22::Minibatch 371::LR 0.0515384615385 --> Loss 0.00186837077141\n",
      "Epoch 22::Minibatch 372::LR 0.0515384615385 --> Loss 0.000430470009645\n",
      "Epoch 22::Minibatch 373::LR 0.0515384615385 --> Loss 0.00178129712741\n",
      "Epoch 22::Minibatch 374::LR 0.0515384615385 --> Loss 0.00221102158229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 375::LR 0.0515384615385 --> Loss 0.00185400605202\n",
      "Epoch 22::Minibatch 376::LR 0.0515384615385 --> Loss 0.00122936785221\n",
      "Epoch 22::Minibatch 377::LR 0.0515384615385 --> Loss 0.00192893942197\n",
      "Epoch 22::Minibatch 378::LR 0.0515384615385 --> Loss 0.00211612939835\n",
      "Epoch 22::Minibatch 379::LR 0.0515384615385 --> Loss 0.00235373874505\n",
      "Epoch 22::Minibatch 380::LR 0.0515384615385 --> Loss 0.00157717307409\n",
      "Epoch 22::Minibatch 381::LR 0.0515384615385 --> Loss 0.000982975959778\n",
      "Epoch 22::Minibatch 382::LR 0.0515384615385 --> Loss 0.0020163098971\n",
      "Epoch 22::Minibatch 383::LR 0.0515384615385 --> Loss 0.00196359932423\n",
      "Epoch 22::Minibatch 384::LR 0.0515384615385 --> Loss 0.00107027620077\n",
      "Epoch 22::Minibatch 385::LR 0.0515384615385 --> Loss 0.00103943437338\n",
      "Epoch 22::Minibatch 386::LR 0.0515384615385 --> Loss 0.00219430347284\n",
      "Epoch 22::Minibatch 387::LR 0.0515384615385 --> Loss 0.00234617630641\n",
      "Epoch 22::Minibatch 388::LR 0.0515384615385 --> Loss 0.00116927027702\n",
      "Epoch 22::Minibatch 389::LR 0.0515384615385 --> Loss 0.00178992648919\n",
      "Epoch 22::Minibatch 390::LR 0.0515384615385 --> Loss 0.00344052712123\n",
      "Epoch 22::Minibatch 391::LR 0.0515384615385 --> Loss 0.00262515127659\n",
      "Epoch 22::Minibatch 392::LR 0.0515384615385 --> Loss 0.0025958977143\n",
      "Epoch 22::Minibatch 393::LR 0.0515384615385 --> Loss 0.00275285144647\n",
      "Epoch 22::Minibatch 394::LR 0.0515384615385 --> Loss 0.00206181983153\n",
      "Epoch 22::Minibatch 395::LR 0.0515384615385 --> Loss 0.00205657521884\n",
      "Epoch 22::Minibatch 396::LR 0.0515384615385 --> Loss 0.00193199475606\n",
      "Epoch 22::Minibatch 397::LR 0.0515384615385 --> Loss 0.00206739823023\n",
      "Epoch 22::Minibatch 398::LR 0.0515384615385 --> Loss 0.00205327451229\n",
      "Epoch 22::Minibatch 399::LR 0.0515384615385 --> Loss 0.00236311376095\n",
      "Epoch 22::Minibatch 400::LR 0.0515384615385 --> Loss 0.00200367689133\n",
      "Epoch 22::Minibatch 401::LR 0.0515384615385 --> Loss 0.00344670414925\n",
      "Epoch 22::Minibatch 402::LR 0.0515384615385 --> Loss 0.00176111578941\n",
      "Epoch 22::Minibatch 403::LR 0.0515384615385 --> Loss 0.00143490145604\n",
      "Epoch 22::Minibatch 404::LR 0.0515384615385 --> Loss 0.00141239633163\n",
      "Epoch 22::Minibatch 405::LR 0.0515384615385 --> Loss 0.00342151165009\n",
      "Epoch 22::Minibatch 406::LR 0.0515384615385 --> Loss 0.00240691641967\n",
      "Epoch 22::Minibatch 407::LR 0.0515384615385 --> Loss 0.00171717902025\n",
      "Epoch 22::Minibatch 408::LR 0.0515384615385 --> Loss 0.000430968900522\n",
      "Epoch 22::Minibatch 409::LR 0.0515384615385 --> Loss 0.00225487569968\n",
      "Epoch 22::Minibatch 410::LR 0.0515384615385 --> Loss 0.00316210349401\n",
      "Epoch 22::Minibatch 411::LR 0.0515384615385 --> Loss 0.00163444072008\n",
      "Epoch 22::Minibatch 412::LR 0.0515384615385 --> Loss 0.000945939918359\n",
      "Epoch 22::Minibatch 413::LR 0.0515384615385 --> Loss 0.00195610940456\n",
      "Epoch 22::Minibatch 414::LR 0.0515384615385 --> Loss 0.00183892885844\n",
      "Epoch 22::Minibatch 415::LR 0.0515384615385 --> Loss 0.00114488065243\n",
      "Epoch 22::Minibatch 416::LR 0.0515384615385 --> Loss 0.000795735915502\n",
      "Epoch 22::Minibatch 417::LR 0.0515384615385 --> Loss 0.00168019016584\n",
      "Epoch 22::Minibatch 418::LR 0.0515384615385 --> Loss 0.0026640021801\n",
      "Epoch 22::Minibatch 419::LR 0.0515384615385 --> Loss 0.000486463457346\n",
      "Epoch 22::Minibatch 420::LR 0.0515384615385 --> Loss 0.000680262247721\n",
      "Epoch 22::Minibatch 421::LR 0.0515384615385 --> Loss 0.00189513544242\n",
      "Epoch 22::Minibatch 422::LR 0.0515384615385 --> Loss 0.00209350148837\n",
      "Epoch 22::Minibatch 423::LR 0.0515384615385 --> Loss 0.000959965785344\n",
      "Epoch 22::Minibatch 424::LR 0.0515384615385 --> Loss 0.00152372042338\n",
      "Epoch 22::Minibatch 425::LR 0.0515384615385 --> Loss 0.00288542906443\n",
      "Epoch 22::Minibatch 426::LR 0.0515384615385 --> Loss 0.00198174099127\n",
      "Epoch 22::Minibatch 427::LR 0.0515384615385 --> Loss 0.000708173513412\n",
      "Epoch 22::Minibatch 428::LR 0.0515384615385 --> Loss 0.000993065436681\n",
      "Epoch 22::Minibatch 429::LR 0.0515384615385 --> Loss 0.00231208165487\n",
      "Epoch 22::Minibatch 430::LR 0.0515384615385 --> Loss 0.00891992727915\n",
      "Epoch 22::Minibatch 431::LR 0.0515384615385 --> Loss 0.00375390609105\n",
      "Epoch 22::Minibatch 432::LR 0.0515384615385 --> Loss 0.00428179542224\n",
      "Epoch 22::Minibatch 433::LR 0.0515384615385 --> Loss 0.00255071441332\n",
      "Epoch 22::Minibatch 434::LR 0.0515384615385 --> Loss 0.00250096996625\n",
      "Epoch 22::Minibatch 435::LR 0.0515384615385 --> Loss 0.00229036450386\n",
      "Epoch 22::Minibatch 436::LR 0.0515384615385 --> Loss 0.00164369324843\n",
      "Epoch 22::Minibatch 437::LR 0.0515384615385 --> Loss 0.00305034637451\n",
      "Epoch 22::Minibatch 438::LR 0.0515384615385 --> Loss 0.00244765500228\n",
      "Epoch 22::Minibatch 439::LR 0.0515384615385 --> Loss 0.00200393180052\n",
      "Epoch 22::Minibatch 440::LR 0.0515384615385 --> Loss 0.00311052600543\n",
      "Epoch 22::Minibatch 441::LR 0.0515384615385 --> Loss 0.00290295561155\n",
      "Epoch 22::Minibatch 442::LR 0.0515384615385 --> Loss 0.00263353645802\n",
      "Epoch 22::Minibatch 443::LR 0.0515384615385 --> Loss 0.00356962164243\n",
      "Epoch 22::Minibatch 444::LR 0.0515384615385 --> Loss 0.00278085768223\n",
      "Epoch 22::Minibatch 445::LR 0.0515384615385 --> Loss 0.000871202647686\n",
      "Epoch 22::Minibatch 446::LR 0.0515384615385 --> Loss 0.00140981316566\n",
      "Epoch 22::Minibatch 447::LR 0.0515384615385 --> Loss 0.00236941277981\n",
      "Epoch 22::Minibatch 448::LR 0.0515384615385 --> Loss 0.00235645254453\n",
      "Epoch 22::Minibatch 449::LR 0.0515384615385 --> Loss 0.00365767002106\n",
      "Epoch 22::Minibatch 450::LR 0.0515384615385 --> Loss 0.00222047487895\n",
      "Epoch 22::Minibatch 451::LR 0.0515384615385 --> Loss 0.00394048015277\n",
      "Epoch 22::Minibatch 452::LR 0.0515384615385 --> Loss 0.00233813107014\n",
      "Epoch 22::Minibatch 453::LR 0.0515384615385 --> Loss 0.000361297180255\n",
      "Epoch 22::Minibatch 454::LR 0.0515384615385 --> Loss 0.00354398965836\n",
      "Epoch 22::Minibatch 455::LR 0.0515384615385 --> Loss 0.00264979461829\n",
      "Epoch 22::Minibatch 456::LR 0.0515384615385 --> Loss 0.00308211485545\n",
      "Epoch 22::Minibatch 457::LR 0.0515384615385 --> Loss 0.00191616654396\n",
      "Epoch 22::Minibatch 458::LR 0.0515384615385 --> Loss 0.00073221852382\n",
      "Epoch 22::Minibatch 459::LR 0.0515384615385 --> Loss 0.00398221651713\n",
      "Epoch 22::Minibatch 460::LR 0.0515384615385 --> Loss 0.00250671664874\n",
      "Epoch 22::Minibatch 461::LR 0.0515384615385 --> Loss 0.00380830287933\n",
      "Epoch 22::Minibatch 462::LR 0.0515384615385 --> Loss 0.000380247657498\n",
      "Epoch 22::Minibatch 463::LR 0.0515384615385 --> Loss 0.00436287879944\n",
      "Epoch 22::Minibatch 464::LR 0.0515384615385 --> Loss 0.00199404001236\n",
      "Epoch 22::Minibatch 465::LR 0.0515384615385 --> Loss 0.00492801507314\n",
      "Epoch 22::Minibatch 466::LR 0.0515384615385 --> Loss 0.00506540020307\n",
      "Epoch 22::Minibatch 467::LR 0.0515384615385 --> Loss 0.00542077422142\n",
      "Epoch 22::Minibatch 468::LR 0.0515384615385 --> Loss 0.00589603900909\n",
      "Epoch 22::Minibatch 469::LR 0.0515384615385 --> Loss 0.00610884984334\n",
      "Epoch 22::Minibatch 470::LR 0.0515384615385 --> Loss 0.0036668519179\n",
      "Epoch 22::Minibatch 471::LR 0.0515384615385 --> Loss 0.00170006473859\n",
      "Epoch 22::Minibatch 472::LR 0.0515384615385 --> Loss 0.00354596138\n",
      "Epoch 22::Minibatch 473::LR 0.0515384615385 --> Loss 0.00227401852608\n",
      "Epoch 22::Minibatch 474::LR 0.0515384615385 --> Loss 0.000693735033274\n",
      "Epoch 22::Minibatch 475::LR 0.0515384615385 --> Loss 0.00502521197001\n",
      "Epoch 22::Minibatch 476::LR 0.0515384615385 --> Loss 0.00777762095133\n",
      "Epoch 22::Minibatch 477::LR 0.0515384615385 --> Loss 0.000920960704486\n",
      "Epoch 22::Minibatch 478::LR 0.0515384615385 --> Loss 0.00243572076162\n",
      "Epoch 22::Minibatch 479::LR 0.0515384615385 --> Loss 0.00196067810059\n",
      "Epoch 22::Minibatch 480::LR 0.0515384615385 --> Loss 0.00152444670598\n",
      "Epoch 22::Minibatch 481::LR 0.0515384615385 --> Loss 0.000955877701441\n",
      "Epoch 22::Minibatch 482::LR 0.0515384615385 --> Loss 0.00208336691062\n",
      "Epoch 22::Minibatch 483::LR 0.0515384615385 --> Loss 0.00310457984606\n",
      "Epoch 22::Minibatch 484::LR 0.0515384615385 --> Loss 0.00348276297251\n",
      "Epoch 22::Minibatch 485::LR 0.0515384615385 --> Loss 0.000758856634299\n",
      "Epoch 22::Minibatch 486::LR 0.0515384615385 --> Loss 0.00287604351838\n",
      "Epoch 22::Minibatch 487::LR 0.0515384615385 --> Loss 0.00333048264186\n",
      "Epoch 22::Minibatch 488::LR 0.0515384615385 --> Loss 0.00203449209531\n",
      "Epoch 22::Minibatch 489::LR 0.0515384615385 --> Loss 0.00313558240732\n",
      "Epoch 22::Minibatch 490::LR 0.0515384615385 --> Loss 0.00040923645099\n",
      "Epoch 22::Minibatch 491::LR 0.0515384615385 --> Loss 0.00348521431287\n",
      "Epoch 22::Minibatch 492::LR 0.0515384615385 --> Loss 0.00305927614371\n",
      "Epoch 22::Minibatch 493::LR 0.0515384615385 --> Loss 0.00303198317687\n",
      "Epoch 22::Minibatch 494::LR 0.0515384615385 --> Loss 0.000735342999299\n",
      "Epoch 22::Minibatch 495::LR 0.0515384615385 --> Loss 0.00185562948386\n",
      "Epoch 22::Minibatch 496::LR 0.0515384615385 --> Loss 0.0028347214063\n",
      "Epoch 22::Minibatch 497::LR 0.0515384615385 --> Loss 0.000921250780423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 498::LR 0.0515384615385 --> Loss 0.00055558120211\n",
      "Epoch 22::Minibatch 499::LR 0.0515384615385 --> Loss 0.00352128307025\n",
      "Epoch 22::Minibatch 500::LR 0.0515384615385 --> Loss 0.00143559416135\n",
      "Epoch 22::Minibatch 501::LR 0.0515384615385 --> Loss 0.00214128533999\n",
      "Epoch 22::Minibatch 502::LR 0.0515384615385 --> Loss 0.00378526250521\n",
      "Epoch 22::Minibatch 503::LR 0.0515384615385 --> Loss 0.00751115163167\n",
      "Epoch 22::Minibatch 504::LR 0.0515384615385 --> Loss 0.007256731987\n",
      "Epoch 22::Minibatch 505::LR 0.0515384615385 --> Loss 0.00414394060771\n",
      "Epoch 22::Minibatch 506::LR 0.0515384615385 --> Loss 0.00339621027311\n",
      "Epoch 22::Minibatch 507::LR 0.0515384615385 --> Loss 0.00592431823413\n",
      "Epoch 22::Minibatch 508::LR 0.0515384615385 --> Loss 0.00340440392494\n",
      "Epoch 22::Minibatch 509::LR 0.0515384615385 --> Loss 0.00443164547284\n",
      "Epoch 22::Minibatch 510::LR 0.0515384615385 --> Loss 0.00449442704519\n",
      "Epoch 22::Minibatch 511::LR 0.0515384615385 --> Loss 0.0039463408788\n",
      "Epoch 22::Minibatch 512::LR 0.0515384615385 --> Loss 0.00268424630165\n",
      "Epoch 22::Minibatch 513::LR 0.0515384615385 --> Loss 0.000621870607138\n",
      "Epoch 22::Minibatch 514::LR 0.0515384615385 --> Loss 0.00264673292637\n",
      "Epoch 22::Minibatch 515::LR 0.0515384615385 --> Loss 0.003002414306\n",
      "Epoch 22::Minibatch 516::LR 0.0515384615385 --> Loss 0.00400663455327\n",
      "Epoch 22::Minibatch 517::LR 0.0515384615385 --> Loss 0.00355092167854\n",
      "Epoch 22::Minibatch 518::LR 0.0515384615385 --> Loss 0.00257688224316\n",
      "Epoch 22::Minibatch 519::LR 0.0515384615385 --> Loss 0.00349023063978\n",
      "Epoch 22::Minibatch 520::LR 0.0515384615385 --> Loss 0.00542044878006\n",
      "Epoch 22::Minibatch 521::LR 0.0515384615385 --> Loss 0.00551040967306\n",
      "Epoch 22::Minibatch 522::LR 0.0515384615385 --> Loss 0.00767423470815\n",
      "Epoch 22::Minibatch 523::LR 0.0515384615385 --> Loss 0.00063497732083\n",
      "Epoch 22::Minibatch 524::LR 0.0515384615385 --> Loss 0.00141086101532\n",
      "Epoch 22::Minibatch 525::LR 0.0515384615385 --> Loss 0.00316512048244\n",
      "Epoch 22::Minibatch 526::LR 0.0515384615385 --> Loss 0.00389107584953\n",
      "Epoch 22::Minibatch 527::LR 0.0515384615385 --> Loss 0.00219921131929\n",
      "Epoch 22::Minibatch 528::LR 0.0515384615385 --> Loss 0.000992608467738\n",
      "Epoch 22::Minibatch 529::LR 0.0515384615385 --> Loss 0.00397733688354\n",
      "Epoch 22::Minibatch 530::LR 0.0515384615385 --> Loss 0.00398575703303\n",
      "Epoch 22::Minibatch 531::LR 0.0515384615385 --> Loss 0.0035023756822\n",
      "Epoch 22::Minibatch 532::LR 0.0515384615385 --> Loss 0.00265948653221\n",
      "Epoch 22::Minibatch 533::LR 0.0515384615385 --> Loss 0.00492415030797\n",
      "Epoch 22::Minibatch 534::LR 0.0515384615385 --> Loss 0.00375363111496\n",
      "Epoch 22::Minibatch 535::LR 0.0515384615385 --> Loss 0.00325697084268\n",
      "Epoch 22::Minibatch 536::LR 0.0515384615385 --> Loss 0.00210763931274\n",
      "Epoch 22::Minibatch 537::LR 0.0515384615385 --> Loss 0.000603933682044\n",
      "Epoch 22::Minibatch 538::LR 0.0515384615385 --> Loss 0.00166521837314\n",
      "Epoch 22::Minibatch 539::LR 0.0515384615385 --> Loss 0.00338178753853\n",
      "Epoch 22::Minibatch 540::LR 0.0515384615385 --> Loss 0.0034118715922\n",
      "Epoch 22::Minibatch 541::LR 0.0515384615385 --> Loss 0.00287937919299\n",
      "Epoch 22::Minibatch 542::LR 0.0515384615385 --> Loss 0.00247639795144\n",
      "Epoch 22::Minibatch 543::LR 0.0515384615385 --> Loss 0.00267146706581\n",
      "Epoch 22::Minibatch 544::LR 0.0515384615385 --> Loss 0.00393004337947\n",
      "Epoch 22::Minibatch 545::LR 0.0515384615385 --> Loss 0.00201831161976\n",
      "Epoch 22::Minibatch 546::LR 0.0515384615385 --> Loss 0.000653635958831\n",
      "Epoch 22::Minibatch 547::LR 0.0515384615385 --> Loss 0.00260416825612\n",
      "Epoch 22::Minibatch 548::LR 0.0515384615385 --> Loss 0.00355999310811\n",
      "Epoch 22::Minibatch 549::LR 0.0515384615385 --> Loss 0.0087423491478\n",
      "Epoch 22::Minibatch 550::LR 0.0515384615385 --> Loss 0.00117362717787\n",
      "Epoch 22::Minibatch 551::LR 0.0515384615385 --> Loss 0.00245032429695\n",
      "Epoch 22::Minibatch 552::LR 0.0515384615385 --> Loss 0.00349640885989\n",
      "Epoch 22::Minibatch 553::LR 0.0515384615385 --> Loss 0.00310489296913\n",
      "Epoch 22::Minibatch 554::LR 0.0515384615385 --> Loss 0.00369974851608\n",
      "Epoch 22::Minibatch 555::LR 0.0515384615385 --> Loss 0.00096274415652\n",
      "Epoch 22::Minibatch 556::LR 0.0515384615385 --> Loss 0.00195918460687\n",
      "Epoch 22::Minibatch 557::LR 0.0515384615385 --> Loss 0.00240919629733\n",
      "Epoch 22::Minibatch 558::LR 0.0515384615385 --> Loss 0.00365763783455\n",
      "Epoch 22::Minibatch 559::LR 0.0515384615385 --> Loss 0.00369585434596\n",
      "Epoch 22::Minibatch 560::LR 0.0515384615385 --> Loss 0.00306585669518\n",
      "Epoch 22::Minibatch 561::LR 0.0515384615385 --> Loss 0.00266371369362\n",
      "Epoch 22::Minibatch 562::LR 0.0515384615385 --> Loss 0.00235686639945\n",
      "Epoch 22::Minibatch 563::LR 0.0515384615385 --> Loss 0.00400168418884\n",
      "Epoch 22::Minibatch 564::LR 0.0515384615385 --> Loss 0.00308465619882\n",
      "Epoch 22::Minibatch 565::LR 0.0515384615385 --> Loss 0.00363667170207\n",
      "Epoch 22::Minibatch 566::LR 0.0515384615385 --> Loss 0.00223486622175\n",
      "Epoch 22::Minibatch 567::LR 0.0515384615385 --> Loss 0.00254677772522\n",
      "Epoch 22::Minibatch 568::LR 0.0515384615385 --> Loss 0.00178351898988\n",
      "Epoch 22::Minibatch 569::LR 0.0515384615385 --> Loss 0.000562247981628\n",
      "Epoch 22::Minibatch 570::LR 0.0515384615385 --> Loss 0.00166978398959\n",
      "Epoch 22::Minibatch 571::LR 0.0515384615385 --> Loss 0.00215845644474\n",
      "Epoch 22::Minibatch 572::LR 0.0515384615385 --> Loss 0.00230782945951\n",
      "Epoch 22::Minibatch 573::LR 0.0515384615385 --> Loss 0.00148064881563\n",
      "Epoch 22::Minibatch 574::LR 0.0515384615385 --> Loss 0.00104674776395\n",
      "Epoch 22::Minibatch 575::LR 0.0515384615385 --> Loss 0.00175771474838\n",
      "Epoch 22::Minibatch 576::LR 0.0515384615385 --> Loss 0.00207756241163\n",
      "Epoch 22::Minibatch 577::LR 0.0515384615385 --> Loss 0.00163935194413\n",
      "Epoch 22::Minibatch 578::LR 0.0515384615385 --> Loss 0.00127870599429\n",
      "Epoch 22::Minibatch 579::LR 0.0515384615385 --> Loss 0.00119299997886\n",
      "Epoch 22::Minibatch 580::LR 0.0515384615385 --> Loss 0.00193370342255\n",
      "Epoch 22::Minibatch 581::LR 0.0515384615385 --> Loss 0.0017123601834\n",
      "Epoch 22::Minibatch 582::LR 0.0515384615385 --> Loss 0.00414893627167\n",
      "Epoch 22::Minibatch 583::LR 0.0515384615385 --> Loss 0.000945132772128\n",
      "Epoch 22::Minibatch 584::LR 0.0515384615385 --> Loss 0.00130769193172\n",
      "Epoch 22::Minibatch 585::LR 0.0515384615385 --> Loss 0.00417104999224\n",
      "Epoch 22::Minibatch 586::LR 0.0515384615385 --> Loss 0.00388340075811\n",
      "Epoch 22::Minibatch 587::LR 0.0515384615385 --> Loss 0.00112290114164\n",
      "Epoch 22::Minibatch 588::LR 0.0515384615385 --> Loss 0.00139415929715\n",
      "Epoch 22::Minibatch 589::LR 0.0515384615385 --> Loss 0.00276205102603\n",
      "Epoch 22::Minibatch 590::LR 0.0515384615385 --> Loss 0.0018861224254\n",
      "Epoch 22::Minibatch 591::LR 0.0515384615385 --> Loss 0.00290226181348\n",
      "Epoch 22::Minibatch 592::LR 0.0515384615385 --> Loss 0.00116819401582\n",
      "Epoch 22::Minibatch 593::LR 0.0515384615385 --> Loss 0.00255049129327\n",
      "Epoch 22::Minibatch 594::LR 0.0515384615385 --> Loss 0.00267914772034\n",
      "Epoch 22::Minibatch 595::LR 0.0515384615385 --> Loss 0.00304560581843\n",
      "Epoch 22::Minibatch 596::LR 0.0515384615385 --> Loss 0.00190171897411\n",
      "Epoch 22::Minibatch 597::LR 0.0515384615385 --> Loss 0.00118396113316\n",
      "Epoch 22::Minibatch 598::LR 0.0515384615385 --> Loss 0.00292516708374\n",
      "Epoch 22::Minibatch 599::LR 0.0515384615385 --> Loss 0.0018324637413\n",
      "Epoch 22::Minibatch 600::LR 0.0515384615385 --> Loss 0.00218520959218\n",
      "Epoch 22::Minibatch 601::LR 0.0515384615385 --> Loss 0.00383016347885\n",
      "Epoch 22::Minibatch 602::LR 0.0515384615385 --> Loss 0.00210590581099\n",
      "Epoch 22::Minibatch 603::LR 0.0515384615385 --> Loss 0.00263564507167\n",
      "Epoch 22::Minibatch 604::LR 0.0515384615385 --> Loss 0.00164744923512\n",
      "Epoch 22::Minibatch 605::LR 0.0515384615385 --> Loss 0.00234124163787\n",
      "Epoch 22::Minibatch 606::LR 0.0515384615385 --> Loss 0.00190078258514\n",
      "Epoch 22::Minibatch 607::LR 0.0515384615385 --> Loss 0.000837341745694\n",
      "Epoch 22::Minibatch 608::LR 0.0515384615385 --> Loss 0.0015740797917\n",
      "Epoch 22::Minibatch 609::LR 0.0515384615385 --> Loss 0.00240570624669\n",
      "Epoch 22::Minibatch 610::LR 0.0515384615385 --> Loss 0.00403354247411\n",
      "Epoch 22::Minibatch 611::LR 0.0515384615385 --> Loss 0.00263728439808\n",
      "Epoch 22::Minibatch 612::LR 0.0515384615385 --> Loss 0.000478375951449\n",
      "Epoch 22::Minibatch 613::LR 0.0515384615385 --> Loss 0.00131144771973\n",
      "Epoch 22::Minibatch 614::LR 0.0515384615385 --> Loss 0.00243673344453\n",
      "Epoch 22::Minibatch 615::LR 0.0515384615385 --> Loss 0.0016748358806\n",
      "Epoch 22::Minibatch 616::LR 0.0515384615385 --> Loss 0.000923534631729\n",
      "Epoch 22::Minibatch 617::LR 0.0515384615385 --> Loss 0.000497570981582\n",
      "Epoch 22::Minibatch 618::LR 0.0515384615385 --> Loss 0.00279807825883\n",
      "Epoch 22::Minibatch 619::LR 0.0515384615385 --> Loss 0.00192698140939\n",
      "Epoch 22::Minibatch 620::LR 0.0515384615385 --> Loss 0.00171036760012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 621::LR 0.0515384615385 --> Loss 0.000850969155629\n",
      "Epoch 22::Minibatch 622::LR 0.0515384615385 --> Loss 0.000791669487953\n",
      "Epoch 22::Minibatch 623::LR 0.0515384615385 --> Loss 0.00222209235032\n",
      "Epoch 22::Minibatch 624::LR 0.0515384615385 --> Loss 0.00179684797923\n",
      "Epoch 22::Minibatch 625::LR 0.0515384615385 --> Loss 0.00283041616281\n",
      "Epoch 22::Minibatch 626::LR 0.0515384615385 --> Loss 0.00408982197444\n",
      "Epoch 22::Minibatch 627::LR 0.0515384615385 --> Loss 0.00129918396473\n",
      "Epoch 22::Minibatch 628::LR 0.0515384615385 --> Loss 0.000890049835046\n",
      "Epoch 22::Minibatch 629::LR 0.0515384615385 --> Loss 0.0032774579525\n",
      "Epoch 22::Minibatch 630::LR 0.0515384615385 --> Loss 0.00319900890191\n",
      "Epoch 22::Minibatch 631::LR 0.0515384615385 --> Loss 0.00586811065674\n",
      "Epoch 22::Minibatch 632::LR 0.0515384615385 --> Loss 0.000791798283656\n",
      "Epoch 22::Minibatch 633::LR 0.0515384615385 --> Loss 0.00164149900277\n",
      "Epoch 22::Minibatch 634::LR 0.0515384615385 --> Loss 0.0032269469897\n",
      "Epoch 22::Minibatch 635::LR 0.0515384615385 --> Loss 0.00545349876086\n",
      "Epoch 22::Minibatch 636::LR 0.0515384615385 --> Loss 0.0048780242602\n",
      "Epoch 22::Minibatch 637::LR 0.0515384615385 --> Loss 0.000752419879039\n",
      "Epoch 22::Minibatch 638::LR 0.0515384615385 --> Loss 0.00149801532427\n",
      "Epoch 22::Minibatch 639::LR 0.0515384615385 --> Loss 0.00325783054034\n",
      "Epoch 22::Minibatch 640::LR 0.0515384615385 --> Loss 0.00483974615733\n",
      "Epoch 22::Minibatch 641::LR 0.0515384615385 --> Loss 0.00309894482295\n",
      "Epoch 22::Minibatch 642::LR 0.0515384615385 --> Loss 0.000538598696391\n",
      "Epoch 22::Minibatch 643::LR 0.0515384615385 --> Loss 0.00233146568139\n",
      "Epoch 22::Minibatch 644::LR 0.0515384615385 --> Loss 0.00393939614296\n",
      "Epoch 22::Minibatch 645::LR 0.0515384615385 --> Loss 0.00428034186363\n",
      "Epoch 22::Minibatch 646::LR 0.0515384615385 --> Loss 0.00150602479776\n",
      "Epoch 22::Minibatch 647::LR 0.0515384615385 --> Loss 0.000498813390732\n",
      "Epoch 22::Minibatch 648::LR 0.0515384615385 --> Loss 0.00289663354556\n",
      "Epoch 22::Minibatch 649::LR 0.0515384615385 --> Loss 0.00343064904213\n",
      "Epoch 22::Minibatch 650::LR 0.0515384615385 --> Loss 0.00327202280362\n",
      "Epoch 22::Minibatch 651::LR 0.0515384615385 --> Loss 0.00136396775643\n",
      "Epoch 22::Minibatch 652::LR 0.0515384615385 --> Loss 0.000791954944531\n",
      "Epoch 22::Minibatch 653::LR 0.0515384615385 --> Loss 0.00284020384153\n",
      "Epoch 22::Minibatch 654::LR 0.0515384615385 --> Loss 0.00312482992808\n",
      "Epoch 22::Minibatch 655::LR 0.0515384615385 --> Loss 0.00354116757711\n",
      "Epoch 22::Minibatch 656::LR 0.0515384615385 --> Loss 0.000756229162216\n",
      "Epoch 22::Minibatch 657::LR 0.0515384615385 --> Loss 0.00225557764371\n",
      "Epoch 22::Minibatch 658::LR 0.0515384615385 --> Loss 0.00475285967191\n",
      "Epoch 22::Minibatch 659::LR 0.0515384615385 --> Loss 0.00227654417356\n",
      "Epoch 22::Minibatch 660::LR 0.0515384615385 --> Loss 0.00261956095695\n",
      "Epoch 22::Minibatch 661::LR 0.0515384615385 --> Loss 0.00241131166617\n",
      "Epoch 22::Minibatch 662::LR 0.0515384615385 --> Loss 0.00180856347084\n",
      "Epoch 22::Minibatch 663::LR 0.0515384615385 --> Loss 0.00369006911914\n",
      "Epoch 22::Minibatch 664::LR 0.0515384615385 --> Loss 0.00332170049349\n",
      "Epoch 22::Minibatch 665::LR 0.0515384615385 --> Loss 0.000716082006693\n",
      "Epoch 22::Minibatch 666::LR 0.0515384615385 --> Loss 0.00391412138939\n",
      "Epoch 22::Minibatch 667::LR 0.0515384615385 --> Loss 0.00254777908325\n",
      "Epoch 22::Minibatch 668::LR 0.0515384615385 --> Loss 0.00673219283422\n",
      "Epoch 22::Minibatch 669::LR 0.0515384615385 --> Loss 0.00109199772278\n",
      "Epoch 22::Minibatch 670::LR 0.0515384615385 --> Loss 0.00134416341782\n",
      "Epoch 22::Minibatch 671::LR 0.0515384615385 --> Loss 0.00525848905245\n",
      "Epoch 22::Minibatch 672::LR 0.0515384615385 --> Loss 0.00360358595848\n",
      "Epoch 22::Minibatch 673::LR 0.0515384615385 --> Loss 0.00161825537682\n",
      "Epoch 22::Minibatch 674::LR 0.0515384615385 --> Loss 0.000511620640755\n",
      "Epoch 22::Minibatch 675::LR 0.0515384615385 --> Loss 0.00218680977821\n",
      "Epoch 22::Minibatch 676::LR 0.0515384615385 --> Loss 0.00213349759579\n",
      "Epoch 22::Minibatch 677::LR 0.0515384615385 --> Loss 0.00276416361332\n",
      "Epoch 22::Minibatch 678::LR 0.0515384615385 --> Loss 0.00190549810727\n",
      "Epoch 22::Minibatch 679::LR 0.0515384615385 --> Loss 0.0034306871891\n",
      "Epoch 22::Minibatch 680::LR 0.0515384615385 --> Loss 0.00213752508163\n",
      "Epoch 22::Minibatch 681::LR 0.0515384615385 --> Loss 0.00242336432139\n",
      "Epoch 22::Minibatch 682::LR 0.0515384615385 --> Loss 0.000760825375716\n",
      "Epoch 22::Minibatch 683::LR 0.0515384615385 --> Loss 0.00235256413619\n",
      "Epoch 22::Minibatch 684::LR 0.0515384615385 --> Loss 0.00234609921773\n",
      "Epoch 22::Minibatch 685::LR 0.0515384615385 --> Loss 0.00287570138772\n",
      "Epoch 22::Minibatch 686::LR 0.0515384615385 --> Loss 0.0015665152669\n",
      "Epoch 22::Minibatch 687::LR 0.0515384615385 --> Loss 0.000858865876993\n",
      "Epoch 22::Minibatch 688::LR 0.0515384615385 --> Loss 0.00277335782846\n",
      "Epoch 22::Minibatch 689::LR 0.0515384615385 --> Loss 0.00251001775265\n",
      "Epoch 22::Minibatch 690::LR 0.0515384615385 --> Loss 0.00190645635128\n",
      "Epoch 22::Minibatch 691::LR 0.0515384615385 --> Loss 0.000658487528563\n",
      "Epoch 22::Minibatch 692::LR 0.0515384615385 --> Loss 0.00245628635089\n",
      "Epoch 22::Minibatch 693::LR 0.0515384615385 --> Loss 0.00258935729663\n",
      "Epoch 22::Minibatch 694::LR 0.0515384615385 --> Loss 0.00301488558451\n",
      "Epoch 22::Minibatch 695::LR 0.0515384615385 --> Loss 0.00176127235095\n",
      "Epoch 22::Minibatch 696::LR 0.0515384615385 --> Loss 0.00204470674197\n",
      "Epoch 22::Minibatch 697::LR 0.0515384615385 --> Loss 0.00140464901924\n",
      "Epoch 22::Minibatch 698::LR 0.0515384615385 --> Loss 0.00164501537879\n",
      "Epoch 22::Minibatch 699::LR 0.0515384615385 --> Loss 0.00380357583364\n",
      "Epoch 22::Minibatch 700::LR 0.0515384615385 --> Loss 0.00264392912388\n",
      "Epoch 22::Minibatch 701::LR 0.0515384615385 --> Loss 0.00194974184036\n",
      "Epoch 22::Minibatch 702::LR 0.0515384615385 --> Loss 0.00166448374589\n",
      "Epoch 22::Minibatch 703::LR 0.0515384615385 --> Loss 0.00432778477669\n",
      "Epoch 22::Minibatch 704::LR 0.0515384615385 --> Loss 0.00180445730686\n",
      "Epoch 22::Minibatch 705::LR 0.0515384615385 --> Loss 0.00286459664504\n",
      "Epoch 22::Minibatch 706::LR 0.0515384615385 --> Loss 0.00223514695962\n",
      "Epoch 22::Minibatch 707::LR 0.0515384615385 --> Loss 0.00118347336849\n",
      "Epoch 22::Minibatch 708::LR 0.0515384615385 --> Loss 0.0017330467701\n",
      "Epoch 22::Minibatch 709::LR 0.0515384615385 --> Loss 0.0016793859005\n",
      "Epoch 22::Minibatch 710::LR 0.0515384615385 --> Loss 0.00254615068436\n",
      "Epoch 22::Minibatch 711::LR 0.0515384615385 --> Loss 0.00194276889165\n",
      "Epoch 22::Minibatch 712::LR 0.0515384615385 --> Loss 0.00134109765291\n",
      "Epoch 22::Minibatch 713::LR 0.0515384615385 --> Loss 0.00177307347457\n",
      "Epoch 22::Minibatch 714::LR 0.0515384615385 --> Loss 0.00279290020466\n",
      "Epoch 22::Minibatch 715::LR 0.0515384615385 --> Loss 0.00293443461259\n",
      "Epoch 22::Minibatch 716::LR 0.0515384615385 --> Loss 0.00163182814916\n",
      "Epoch 22::Minibatch 717::LR 0.0515384615385 --> Loss 0.00163485636314\n",
      "Epoch 22::Minibatch 718::LR 0.0515384615385 --> Loss 0.00126268466314\n",
      "Epoch 22::Minibatch 719::LR 0.0515384615385 --> Loss 0.00168870131175\n",
      "Epoch 22::Minibatch 720::LR 0.0515384615385 --> Loss 0.00261628230413\n",
      "Epoch 22::Minibatch 721::LR 0.0515384615385 --> Loss 0.000613123079141\n",
      "Epoch 22::Minibatch 722::LR 0.0515384615385 --> Loss 0.00471705595652\n",
      "Epoch 22::Minibatch 723::LR 0.0515384615385 --> Loss 0.00488195260366\n",
      "Epoch 22::Minibatch 724::LR 0.0515384615385 --> Loss 0.000965929925442\n",
      "Epoch 22::Minibatch 725::LR 0.0515384615385 --> Loss 0.00212830305099\n",
      "Epoch 22::Minibatch 726::LR 0.0515384615385 --> Loss 0.00423395911853\n",
      "Epoch 22::Minibatch 727::LR 0.0515384615385 --> Loss 0.00320776780446\n",
      "Epoch 22::Minibatch 728::LR 0.0515384615385 --> Loss 0.000643432686726\n",
      "Epoch 22::Minibatch 729::LR 0.0515384615385 --> Loss 0.000734755744537\n",
      "Epoch 22::Minibatch 730::LR 0.0515384615385 --> Loss 0.00286039570967\n",
      "Epoch 22::Minibatch 731::LR 0.0515384615385 --> Loss 0.00254468222459\n",
      "Epoch 22::Minibatch 732::LR 0.0515384615385 --> Loss 0.00215381840865\n",
      "Epoch 22::Minibatch 733::LR 0.0515384615385 --> Loss 0.000646198093891\n",
      "Epoch 22::Minibatch 734::LR 0.0515384615385 --> Loss 0.00169614851475\n",
      "Epoch 22::Minibatch 735::LR 0.0515384615385 --> Loss 0.00239403009415\n",
      "Epoch 22::Minibatch 736::LR 0.0515384615385 --> Loss 0.00347239732742\n",
      "Epoch 22::Minibatch 737::LR 0.0515384615385 --> Loss 0.00302815854549\n",
      "Epoch 22::Minibatch 738::LR 0.0515384615385 --> Loss 0.00151408096155\n",
      "Epoch 22::Minibatch 739::LR 0.0515384615385 --> Loss 0.00243476430575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 740::LR 0.0515384615385 --> Loss 0.00382081309954\n",
      "Epoch 22::Minibatch 741::LR 0.0515384615385 --> Loss 0.00262029409409\n",
      "Epoch 22::Minibatch 742::LR 0.0515384615385 --> Loss 0.00210470199585\n",
      "Epoch 22::Minibatch 743::LR 0.0515384615385 --> Loss 0.00143599549929\n",
      "Epoch 22::Minibatch 744::LR 0.0515384615385 --> Loss 0.00182052453359\n",
      "Epoch 22::Minibatch 745::LR 0.0515384615385 --> Loss 0.00281363030275\n",
      "Epoch 22::Minibatch 746::LR 0.0515384615385 --> Loss 0.00293108185132\n",
      "Epoch 22::Minibatch 747::LR 0.0515384615385 --> Loss 0.00178255577882\n",
      "Epoch 22::Minibatch 748::LR 0.0515384615385 --> Loss 0.000622263550758\n",
      "Epoch 22::Minibatch 749::LR 0.0515384615385 --> Loss 0.00165627797445\n",
      "Epoch 22::Minibatch 750::LR 0.0515384615385 --> Loss 0.00244632860025\n",
      "Epoch 22::Minibatch 751::LR 0.0515384615385 --> Loss 0.00280687014262\n",
      "Epoch 22::Minibatch 752::LR 0.0515384615385 --> Loss 0.0012741702795\n",
      "Epoch 22::Minibatch 753::LR 0.0515384615385 --> Loss 0.00220868209998\n",
      "Epoch 22::Minibatch 754::LR 0.0515384615385 --> Loss 0.00240553716818\n",
      "Epoch 22::Minibatch 755::LR 0.0515384615385 --> Loss 0.00266458590825\n",
      "Epoch 22::Minibatch 756::LR 0.0515384615385 --> Loss 0.00135202695926\n",
      "Epoch 22::Minibatch 757::LR 0.0515384615385 --> Loss 0.000704605430365\n",
      "Epoch 22::Minibatch 758::LR 0.0515384615385 --> Loss 0.0015912587444\n",
      "Epoch 22::Minibatch 759::LR 0.0515384615385 --> Loss 0.0036390932401\n",
      "Epoch 22::Minibatch 760::LR 0.0515384615385 --> Loss 0.0029024408261\n",
      "Epoch 22::Minibatch 761::LR 0.0515384615385 --> Loss 0.00605808178584\n",
      "Epoch 22::Minibatch 762::LR 0.0515384615385 --> Loss 0.00369617938995\n",
      "Epoch 22::Minibatch 763::LR 0.0515384615385 --> Loss 0.00350981076558\n",
      "Epoch 22::Minibatch 764::LR 0.0515384615385 --> Loss 0.00313319265842\n",
      "Epoch 22::Minibatch 765::LR 0.0515384615385 --> Loss 0.00128701676925\n",
      "Epoch 22::Minibatch 766::LR 0.0515384615385 --> Loss 0.00228722969691\n",
      "Epoch 22::Minibatch 767::LR 0.0515384615385 --> Loss 0.00491320411364\n",
      "Epoch 22::Minibatch 768::LR 0.0515384615385 --> Loss 0.00364982922872\n",
      "Epoch 22::Minibatch 769::LR 0.0515384615385 --> Loss 0.00187068363031\n",
      "Epoch 22::Minibatch 770::LR 0.0515384615385 --> Loss 0.00147623300552\n",
      "Epoch 22::Minibatch 771::LR 0.0515384615385 --> Loss 0.00357725302378\n",
      "Epoch 22::Minibatch 772::LR 0.0515384615385 --> Loss 0.00348031083743\n",
      "Epoch 22::Minibatch 773::LR 0.0515384615385 --> Loss 0.0031484891971\n",
      "Epoch 22::Minibatch 774::LR 0.0515384615385 --> Loss 0.00181955118974\n",
      "Epoch 22::Minibatch 775::LR 0.0515384615385 --> Loss 0.0035848681132\n",
      "Epoch 22::Minibatch 776::LR 0.0515384615385 --> Loss 0.00362449447314\n",
      "Epoch 22::Minibatch 777::LR 0.0515384615385 --> Loss 0.00689298709234\n",
      "Epoch 22::Minibatch 778::LR 0.0515384615385 --> Loss 0.00855768839518\n",
      "Epoch 22::Minibatch 779::LR 0.0515384615385 --> Loss 0.00238986412684\n",
      "Epoch 22::Minibatch 780::LR 0.0515384615385 --> Loss 0.00156314084927\n",
      "Epoch 22::Minibatch 781::LR 0.0515384615385 --> Loss 0.00344341397285\n",
      "Epoch 22::Minibatch 782::LR 0.0515384615385 --> Loss 0.00386928319931\n",
      "Epoch 22::Minibatch 783::LR 0.0515384615385 --> Loss 0.00228476087252\n",
      "Epoch 22::Minibatch 784::LR 0.0515384615385 --> Loss 0.000708059867223\n",
      "Epoch 22::Minibatch 785::LR 0.0515384615385 --> Loss 0.00327811936537\n",
      "Epoch 22::Minibatch 786::LR 0.0515384615385 --> Loss 0.00341398755709\n",
      "Epoch 22::Minibatch 787::LR 0.0515384615385 --> Loss 0.00262981037299\n",
      "Epoch 22::Minibatch 788::LR 0.0515384615385 --> Loss 0.00235846201579\n",
      "Epoch 22::Minibatch 789::LR 0.0515384615385 --> Loss 0.000731495072444\n",
      "Epoch 22::Minibatch 790::LR 0.0515384615385 --> Loss 0.00313447634379\n",
      "Epoch 22::Minibatch 791::LR 0.0515384615385 --> Loss 0.00343894163767\n",
      "Epoch 22::Minibatch 792::LR 0.0515384615385 --> Loss 0.0030394111077\n",
      "Epoch 22::Minibatch 793::LR 0.0515384615385 --> Loss 0.00171138048172\n",
      "Epoch 22::Minibatch 794::LR 0.0515384615385 --> Loss 0.00100016474724\n",
      "Epoch 22::Minibatch 795::LR 0.0515384615385 --> Loss 0.00283334275087\n",
      "Epoch 22::Minibatch 796::LR 0.0515384615385 --> Loss 0.00528331915538\n",
      "Epoch 22::Minibatch 797::LR 0.0515384615385 --> Loss 0.00654118418694\n",
      "Epoch 22::Minibatch 798::LR 0.0515384615385 --> Loss 0.00316814363003\n",
      "Epoch 22::Minibatch 799::LR 0.0515384615385 --> Loss 0.00230103890101\n",
      "Epoch 22::Minibatch 800::LR 0.0515384615385 --> Loss 0.00201109945774\n",
      "Epoch 22::Minibatch 801::LR 0.0515384615385 --> Loss 0.00408326029778\n",
      "Epoch 22::Minibatch 802::LR 0.0515384615385 --> Loss 0.00126070171595\n",
      "Epoch 22::Minibatch 803::LR 0.0515384615385 --> Loss 0.00289556801319\n",
      "Epoch 22::Minibatch 804::LR 0.0515384615385 --> Loss 0.0021266156435\n",
      "Epoch 22::Minibatch 805::LR 0.0515384615385 --> Loss 0.00222750325998\n",
      "Epoch 22::Minibatch 806::LR 0.0515384615385 --> Loss 0.00337683558464\n",
      "Epoch 22::Minibatch 807::LR 0.0515384615385 --> Loss 0.0030447713534\n",
      "Epoch 22::Minibatch 808::LR 0.0515384615385 --> Loss 0.00269710143407\n",
      "Epoch 22::Minibatch 809::LR 0.0515384615385 --> Loss 0.00342710892359\n",
      "Epoch 22::Minibatch 810::LR 0.0515384615385 --> Loss 0.00469477812449\n",
      "Epoch 22::Minibatch 811::LR 0.0515384615385 --> Loss 0.00445451299349\n",
      "Epoch 22::Minibatch 812::LR 0.0515384615385 --> Loss 0.00407740632693\n",
      "Epoch 22::Minibatch 813::LR 0.0515384615385 --> Loss 0.00354103604952\n",
      "Epoch 22::Minibatch 814::LR 0.0515384615385 --> Loss 0.00162838975588\n",
      "Epoch 22::Minibatch 815::LR 0.0515384615385 --> Loss 0.0036560746034\n",
      "Epoch 22::Minibatch 816::LR 0.0515384615385 --> Loss 0.00407091975212\n",
      "Epoch 22::Minibatch 817::LR 0.0515384615385 --> Loss 0.00539016604424\n",
      "Epoch 22::Minibatch 818::LR 0.0515384615385 --> Loss 0.00125701705615\n",
      "Epoch 22::Minibatch 819::LR 0.0515384615385 --> Loss 0.000705975592136\n",
      "Epoch 22::Minibatch 820::LR 0.0515384615385 --> Loss 0.00523437142372\n",
      "Epoch 22::Minibatch 821::LR 0.0515384615385 --> Loss 0.00309592743715\n",
      "Epoch 22::Minibatch 822::LR 0.0515384615385 --> Loss 0.00367701172829\n",
      "Epoch 22::Minibatch 823::LR 0.0515384615385 --> Loss 0.00128100097179\n",
      "Epoch 22::Minibatch 824::LR 0.0515384615385 --> Loss 0.00136697987715\n",
      "Epoch 22::Minibatch 825::LR 0.0515384615385 --> Loss 0.00365927259127\n",
      "Epoch 22::Minibatch 826::LR 0.0515384615385 --> Loss 0.00406385382016\n",
      "Epoch 22::Minibatch 827::LR 0.0515384615385 --> Loss 0.00206727663676\n",
      "Epoch 22::Minibatch 828::LR 0.0515384615385 --> Loss 0.000505455533663\n",
      "Epoch 22::Minibatch 829::LR 0.0515384615385 --> Loss 0.00232029000918\n",
      "Epoch 22::Minibatch 830::LR 0.0515384615385 --> Loss 0.00421679019928\n",
      "Epoch 22::Minibatch 831::LR 0.0515384615385 --> Loss 0.0024928410848\n",
      "Epoch 22::Minibatch 832::LR 0.0515384615385 --> Loss 0.00218495865663\n",
      "Epoch 22::Minibatch 833::LR 0.0515384615385 --> Loss 0.00183170080185\n",
      "Epoch 22::Minibatch 834::LR 0.0515384615385 --> Loss 0.000775921742121\n",
      "Epoch 22::Minibatch 835::LR 0.0515384615385 --> Loss 0.00376412947973\n",
      "Epoch 22::Minibatch 836::LR 0.0515384615385 --> Loss 0.00364247043928\n",
      "Epoch 22::Minibatch 837::LR 0.0515384615385 --> Loss 0.00219604372978\n",
      "Epoch 22::Minibatch 838::LR 0.0515384615385 --> Loss 0.000631942997376\n",
      "Epoch 22::Minibatch 839::LR 0.0515384615385 --> Loss 0.00243916710218\n",
      "Epoch 22::Minibatch 840::LR 0.0515384615385 --> Loss 0.00286760489146\n",
      "Epoch 22::Minibatch 841::LR 0.0515384615385 --> Loss 0.00278974314531\n",
      "Epoch 22::Minibatch 842::LR 0.0515384615385 --> Loss 0.00207629819711\n",
      "Epoch 22::Minibatch 843::LR 0.0515384615385 --> Loss 0.000993791321913\n",
      "Epoch 22::Minibatch 844::LR 0.0515384615385 --> Loss 0.00147870659828\n",
      "Epoch 22::Minibatch 845::LR 0.0515384615385 --> Loss 0.00420034209887\n",
      "Epoch 22::Minibatch 846::LR 0.0515384615385 --> Loss 0.00166743954023\n",
      "Epoch 22::Minibatch 847::LR 0.0515384615385 --> Loss 0.00229529817899\n",
      "Epoch 22::Minibatch 848::LR 0.0515384615385 --> Loss 0.0010359514753\n",
      "Epoch 22::Minibatch 849::LR 0.0515384615385 --> Loss 0.0018083212773\n",
      "Epoch 22::Minibatch 850::LR 0.0515384615385 --> Loss 0.00315736532211\n",
      "Epoch 22::Minibatch 851::LR 0.0515384615385 --> Loss 0.00260333617528\n",
      "Epoch 22::Minibatch 852::LR 0.0515384615385 --> Loss 0.00108903596799\n",
      "Epoch 22::Minibatch 853::LR 0.0515384615385 --> Loss 0.00130120436351\n",
      "Epoch 22::Minibatch 854::LR 0.0515384615385 --> Loss 0.00255477984746\n",
      "Epoch 22::Minibatch 855::LR 0.0515384615385 --> Loss 0.00214188059171\n",
      "Epoch 22::Minibatch 856::LR 0.0515384615385 --> Loss 0.00178602715333\n",
      "Epoch 22::Minibatch 857::LR 0.0515384615385 --> Loss 0.00120866000652\n",
      "Epoch 22::Minibatch 858::LR 0.0515384615385 --> Loss 0.000593337814013\n",
      "Epoch 22::Minibatch 859::LR 0.0515384615385 --> Loss 0.00192432959874\n",
      "Epoch 22::Minibatch 860::LR 0.0515384615385 --> Loss 0.0012644491593\n",
      "Epoch 22::Minibatch 861::LR 0.0515384615385 --> Loss 0.000936603446802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 862::LR 0.0515384615385 --> Loss 0.0036553478241\n",
      "Epoch 22::Minibatch 863::LR 0.0515384615385 --> Loss 0.00338983853658\n",
      "Epoch 22::Minibatch 864::LR 0.0515384615385 --> Loss 0.00275758067767\n",
      "Epoch 22::Minibatch 865::LR 0.0515384615385 --> Loss 0.000449121743441\n",
      "Epoch 22::Minibatch 866::LR 0.0515384615385 --> Loss 0.00211303194364\n",
      "Epoch 22::Minibatch 867::LR 0.0515384615385 --> Loss 0.00292296906312\n",
      "Epoch 22::Minibatch 868::LR 0.0515384615385 --> Loss 0.00241116543611\n",
      "Epoch 22::Minibatch 869::LR 0.0515384615385 --> Loss 0.00211216886838\n",
      "Epoch 22::Minibatch 870::LR 0.0515384615385 --> Loss 0.00342890659968\n",
      "Epoch 22::Minibatch 871::LR 0.0515384615385 --> Loss 0.00155247688293\n",
      "Epoch 22::Minibatch 872::LR 0.0515384615385 --> Loss 0.00221631685893\n",
      "Epoch 22::Minibatch 873::LR 0.0515384615385 --> Loss 0.00246113836765\n",
      "Epoch 22::Minibatch 874::LR 0.0515384615385 --> Loss 0.00582754055659\n",
      "Epoch 22::Minibatch 875::LR 0.0515384615385 --> Loss 0.000544245292743\n",
      "Epoch 22::Minibatch 876::LR 0.0515384615385 --> Loss 0.0029954880476\n",
      "Epoch 22::Minibatch 877::LR 0.0515384615385 --> Loss 0.00538495381673\n",
      "Epoch 22::Minibatch 878::LR 0.0515384615385 --> Loss 0.00313643117746\n",
      "Epoch 22::Minibatch 879::LR 0.0515384615385 --> Loss 0.0039716553688\n",
      "Epoch 22::Minibatch 880::LR 0.0515384615385 --> Loss 0.0048207227389\n",
      "Epoch 22::Minibatch 881::LR 0.0515384615385 --> Loss 0.00426549871763\n",
      "Epoch 22::Minibatch 882::LR 0.0515384615385 --> Loss 0.00194731652737\n",
      "Epoch 22::Minibatch 883::LR 0.0515384615385 --> Loss 0.00347574392955\n",
      "Epoch 22::Minibatch 884::LR 0.0515384615385 --> Loss 0.0027278149128\n",
      "Epoch 22::Minibatch 885::LR 0.0515384615385 --> Loss 0.00255057036877\n",
      "Epoch 22::Minibatch 886::LR 0.0515384615385 --> Loss 0.000466416875521\n",
      "Epoch 22::Minibatch 887::LR 0.0515384615385 --> Loss 0.00528137962023\n",
      "Epoch 22::Minibatch 888::LR 0.0515384615385 --> Loss 0.00255064407984\n",
      "Epoch 22::Minibatch 889::LR 0.0515384615385 --> Loss 0.00269482791424\n",
      "Epoch 22::Minibatch 890::LR 0.0515384615385 --> Loss 0.00396049698194\n",
      "Epoch 22::Minibatch 891::LR 0.0515384615385 --> Loss 0.00179880003134\n",
      "Epoch 22::Minibatch 892::LR 0.0515384615385 --> Loss 0.000829794903596\n",
      "Epoch 22::Minibatch 893::LR 0.0515384615385 --> Loss 0.00236812690894\n",
      "Epoch 22::Minibatch 894::LR 0.0515384615385 --> Loss 0.00208689153194\n",
      "Epoch 22::Minibatch 895::LR 0.0515384615385 --> Loss 0.00234410981337\n",
      "Epoch 22::Minibatch 896::LR 0.0515384615385 --> Loss 0.00124573220809\n",
      "Epoch 22::Minibatch 897::LR 0.0515384615385 --> Loss 0.000693044861158\n",
      "Epoch 22::Minibatch 898::LR 0.0515384615385 --> Loss 0.00207865754763\n",
      "Epoch 22::Minibatch 899::LR 0.0515384615385 --> Loss 0.00246238966783\n",
      "Epoch 22::Minibatch 900::LR 0.0515384615385 --> Loss 0.00316530267398\n",
      "Epoch 22::Minibatch 901::LR 0.0515384615385 --> Loss 0.000586146215598\n",
      "Epoch 22::Minibatch 902::LR 0.0515384615385 --> Loss 0.00140482604504\n",
      "Epoch 22::Minibatch 903::LR 0.0515384615385 --> Loss 0.00253928422928\n",
      "Epoch 22::Minibatch 904::LR 0.0515384615385 --> Loss 0.001865888834\n",
      "Epoch 22::Minibatch 905::LR 0.0515384615385 --> Loss 0.0014166717728\n",
      "Epoch 22::Minibatch 906::LR 0.0515384615385 --> Loss 0.00105431030194\n",
      "Epoch 22::Minibatch 907::LR 0.0515384615385 --> Loss 0.00157123148441\n",
      "Epoch 22::Minibatch 908::LR 0.0515384615385 --> Loss 0.00213034749031\n",
      "Epoch 22::Minibatch 909::LR 0.0515384615385 --> Loss 0.00196853379409\n",
      "Epoch 22::Minibatch 910::LR 0.0515384615385 --> Loss 0.000832885454098\n",
      "Epoch 22::Minibatch 911::LR 0.0515384615385 --> Loss 0.00124253431956\n",
      "Epoch 22::Minibatch 912::LR 0.0515384615385 --> Loss 0.00200223068396\n",
      "Epoch 22::Minibatch 913::LR 0.0515384615385 --> Loss 0.0021851404508\n",
      "Epoch 22::Minibatch 914::LR 0.0515384615385 --> Loss 0.0011826240023\n",
      "Epoch 22::Minibatch 915::LR 0.0515384615385 --> Loss 0.000499279399713\n",
      "Epoch 22::Minibatch 916::LR 0.0515384615385 --> Loss 0.00218408644199\n",
      "Epoch 22::Minibatch 917::LR 0.0515384615385 --> Loss 0.00359964807828\n",
      "Epoch 22::Minibatch 918::LR 0.0515384615385 --> Loss 0.00555137435595\n",
      "Epoch 22::Minibatch 919::LR 0.0515384615385 --> Loss 0.000546762595574\n",
      "Epoch 22::Minibatch 920::LR 0.0515384615385 --> Loss 0.0122256445885\n",
      "Epoch 22::Minibatch 921::LR 0.0515384615385 --> Loss 0.0028323729833\n",
      "Epoch 22::Minibatch 922::LR 0.0515384615385 --> Loss 0.0029453064998\n",
      "Epoch 22::Minibatch 923::LR 0.0515384615385 --> Loss 0.0013684173425\n",
      "Epoch 22::Minibatch 924::LR 0.0515384615385 --> Loss 0.00335868040721\n",
      "Epoch 22::Minibatch 925::LR 0.0515384615385 --> Loss 0.00226743837198\n",
      "Epoch 22::Minibatch 926::LR 0.0515384615385 --> Loss 0.00508665998777\n",
      "Epoch 22::Minibatch 927::LR 0.0515384615385 --> Loss 0.0067071445783\n",
      "Epoch 22::Minibatch 928::LR 0.0515384615385 --> Loss 0.00622508247693\n",
      "Epoch 22::Minibatch 929::LR 0.0515384615385 --> Loss 0.0061448264122\n",
      "Epoch 22::Minibatch 930::LR 0.0515384615385 --> Loss 0.00901129643122\n",
      "Epoch 22::Minibatch 931::LR 0.0515384615385 --> Loss 0.00327977379163\n",
      "Epoch 22::Minibatch 932::LR 0.0515384615385 --> Loss 0.00619747956594\n",
      "Epoch 22::Minibatch 933::LR 0.0515384615385 --> Loss 0.00300374011199\n",
      "Epoch 22::Minibatch 934::LR 0.0515384615385 --> Loss 0.00395094116529\n",
      "Epoch 22::Minibatch 935::LR 0.0515384615385 --> Loss 0.00566147406896\n",
      "Epoch 22::Minibatch 936::LR 0.0515384615385 --> Loss 0.00125540624062\n",
      "Epoch 22::Minibatch 937::LR 0.0515384615385 --> Loss 0.00293887873491\n",
      "Epoch 22::Minibatch 938::LR 0.0515384615385 --> Loss 0.00260559062163\n",
      "Epoch 22::Minibatch 939::LR 0.0515384615385 --> Loss 0.00271311839422\n",
      "Epoch 22::Minibatch 940::LR 0.0515384615385 --> Loss 0.000980951289336\n",
      "Epoch 22::Minibatch 941::LR 0.0515384615385 --> Loss 0.000806968162457\n",
      "Epoch 22::Minibatch 942::LR 0.0515384615385 --> Loss 0.00245135049025\n",
      "Epoch 22::Minibatch 943::LR 0.0515384615385 --> Loss 0.00264663855235\n",
      "Epoch 22::Minibatch 944::LR 0.0515384615385 --> Loss 0.00191308836142\n",
      "Epoch 22::Minibatch 945::LR 0.0515384615385 --> Loss 0.00110168268283\n",
      "Epoch 22::Minibatch 946::LR 0.0515384615385 --> Loss 0.00280873378118\n",
      "Epoch 22::Minibatch 947::LR 0.0515384615385 --> Loss 0.0025322864453\n",
      "Epoch 22::Minibatch 948::LR 0.0515384615385 --> Loss 0.00473072648048\n",
      "Epoch 22::Minibatch 949::LR 0.0515384615385 --> Loss 0.00180343151093\n",
      "Epoch 22::Minibatch 950::LR 0.0515384615385 --> Loss 0.000727472851674\n",
      "Epoch 22::Minibatch 951::LR 0.0515384615385 --> Loss 0.00337790250778\n",
      "Epoch 22::Minibatch 952::LR 0.0515384615385 --> Loss 0.00237788498402\n",
      "Epoch 22::Minibatch 953::LR 0.0515384615385 --> Loss 0.00139138261477\n",
      "Epoch 22::Minibatch 954::LR 0.0515384615385 --> Loss 0.000956232845783\n",
      "Epoch 22::Minibatch 955::LR 0.0515384615385 --> Loss 0.00252381821473\n",
      "Epoch 22::Minibatch 956::LR 0.0515384615385 --> Loss 0.0034706457456\n",
      "Epoch 22::Minibatch 957::LR 0.0515384615385 --> Loss 0.00184237003326\n",
      "Epoch 22::Minibatch 958::LR 0.0515384615385 --> Loss 0.00222093363603\n",
      "Epoch 22::Minibatch 959::LR 0.0515384615385 --> Loss 0.00270532151063\n",
      "Epoch 22::Minibatch 960::LR 0.0515384615385 --> Loss 0.00594037810961\n",
      "Epoch 22::Minibatch 961::LR 0.0515384615385 --> Loss 0.00319199919701\n",
      "Epoch 22::Minibatch 962::LR 0.0515384615385 --> Loss 0.0026891930898\n",
      "Epoch 22::Minibatch 963::LR 0.0515384615385 --> Loss 0.00103632787863\n",
      "Epoch 22::Minibatch 964::LR 0.0515384615385 --> Loss 0.00235582490762\n",
      "Epoch 22::Minibatch 965::LR 0.0515384615385 --> Loss 0.00700285514196\n",
      "Epoch 22::Minibatch 966::LR 0.0515384615385 --> Loss 0.00504816651344\n",
      "Epoch 22::Minibatch 967::LR 0.0515384615385 --> Loss 0.00141724735498\n",
      "Epoch 22::Minibatch 968::LR 0.0515384615385 --> Loss 0.00124506115913\n",
      "Epoch 22::Minibatch 969::LR 0.0515384615385 --> Loss 0.00570668896039\n",
      "Epoch 22::Minibatch 970::LR 0.0515384615385 --> Loss 0.00530954202016\n",
      "Epoch 22::Minibatch 971::LR 0.0515384615385 --> Loss 0.00342239896456\n",
      "Epoch 22::Minibatch 972::LR 0.0515384615385 --> Loss 0.00969875892003\n",
      "Epoch 22::Minibatch 973::LR 0.0515384615385 --> Loss 0.00899435361226\n",
      "Epoch 22::Minibatch 974::LR 0.0515384615385 --> Loss 0.00771792252858\n",
      "Epoch 22::Minibatch 975::LR 0.0515384615385 --> Loss 0.00446366270383\n",
      "Epoch 22::Minibatch 976::LR 0.0515384615385 --> Loss 0.00395597020785\n",
      "Epoch 22::Minibatch 977::LR 0.0515384615385 --> Loss 0.00388767917951\n",
      "Epoch 22::Minibatch 978::LR 0.0515384615385 --> Loss 0.00385437647502\n",
      "Epoch 22::Minibatch 979::LR 0.0515384615385 --> Loss 0.0037415154775\n",
      "Epoch 22::Minibatch 980::LR 0.0515384615385 --> Loss 0.00385709087054\n",
      "Epoch 22::Minibatch 981::LR 0.0515384615385 --> Loss 0.00498674233754\n",
      "Epoch 22::Minibatch 982::LR 0.0515384615385 --> Loss 0.00590512712797\n",
      "Epoch 22::Minibatch 983::LR 0.0515384615385 --> Loss 0.00287066876888\n",
      "Epoch 22::Minibatch 984::LR 0.0515384615385 --> Loss 0.00227953930696\n",
      "Epoch 22::Minibatch 985::LR 0.0515384615385 --> Loss 0.00405240615209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22::Minibatch 986::LR 0.0515384615385 --> Loss 0.00371198614438\n",
      "Epoch 22::Minibatch 987::LR 0.0515384615385 --> Loss 0.00398891886075\n",
      "Epoch 22::Minibatch 988::LR 0.0515384615385 --> Loss 0.00315011878808\n",
      "Epoch 22::Minibatch 989::LR 0.0515384615385 --> Loss 0.00332612256209\n",
      "Epoch 22::Minibatch 990::LR 0.0515384615385 --> Loss 0.00303652346134\n",
      "Epoch 22::Minibatch 991::LR 0.0515384615385 --> Loss 0.00160994807879\n",
      "Epoch 22::Minibatch 992::LR 0.0515384615385 --> Loss 0.00179839968681\n",
      "Epoch 22::Minibatch 993::LR 0.0515384615385 --> Loss 0.00328412691752\n",
      "Epoch 22::Minibatch 994::LR 0.0515384615385 --> Loss 0.00207181453705\n",
      "Epoch 22::Minibatch 995::LR 0.0515384615385 --> Loss 0.000846265355746\n",
      "Epoch 22::Minibatch 996::LR 0.0515384615385 --> Loss 0.00291462222735\n",
      "Epoch 22::Minibatch 997::LR 0.0515384615385 --> Loss 0.00218272089958\n",
      "Epoch 22::Minibatch 998::LR 0.0515384615385 --> Loss 0.00246278007825\n",
      "Epoch 22::Minibatch 999::LR 0.0515384615385 --> Loss 0.00205880184968\n",
      "Epoch 22::Minibatch 1000::LR 0.0515384615385 --> Loss 0.00244004487991\n",
      "Epoch 22::Minibatch 1001::LR 0.0515384615385 --> Loss 0.0019469956557\n",
      "Epoch 22::Minibatch 1002::LR 0.0515384615385 --> Loss 0.00197483976682\n",
      "Epoch 22::Minibatch 1003::LR 0.0515384615385 --> Loss 0.00307061612606\n",
      "Epoch 22::Minibatch 1004::LR 0.0515384615385 --> Loss 0.00104558567206\n",
      "Epoch 22::Minibatch 1005::LR 0.0515384615385 --> Loss 0.00309925794601\n",
      "Epoch 22::Minibatch 1006::LR 0.0515384615385 --> Loss 0.00171413838863\n",
      "Epoch 22::Minibatch 1007::LR 0.0515384615385 --> Loss 0.00217182477315\n",
      "Epoch 22::Minibatch 1008::LR 0.0515384615385 --> Loss 0.000930281082789\n",
      "Epoch 22::Minibatch 1009::LR 0.0515384615385 --> Loss 0.00135294506947\n",
      "Epoch 22::Minibatch 1010::LR 0.0515384615385 --> Loss 0.0012257595857\n",
      "Epoch 22::Minibatch 1011::LR 0.0515384615385 --> Loss 0.00227444171906\n",
      "Epoch 22::Minibatch 1012::LR 0.0515384615385 --> Loss 0.00145787239075\n",
      "Epoch 22::Minibatch 1013::LR 0.0515384615385 --> Loss 0.00395466923714\n",
      "Epoch 22::Minibatch 1014::LR 0.0515384615385 --> Loss 0.0037198082606\n",
      "Epoch 22::Minibatch 1015::LR 0.0515384615385 --> Loss 0.00159176419179\n",
      "Epoch 22::Minibatch 1016::LR 0.0515384615385 --> Loss 0.00475019375483\n",
      "Epoch 22::Minibatch 1017::LR 0.0515384615385 --> Loss 0.0032310650746\n",
      "Epoch 22::Minibatch 1018::LR 0.0515384615385 --> Loss 0.00276084641616\n",
      "Epoch 22::Minibatch 1019::LR 0.0515384615385 --> Loss 0.00183933397134\n",
      "Epoch 22::Minibatch 1020::LR 0.0515384615385 --> Loss 0.00189728081226\n",
      "Epoch 22::Minibatch 1021::LR 0.0515384615385 --> Loss 0.00196677108606\n",
      "Epoch 22::Minibatch 1022::LR 0.0515384615385 --> Loss 0.00148606797059\n",
      "Epoch 22::Minibatch 1023::LR 0.0515384615385 --> Loss 0.00112836589416\n",
      "Epoch 22::Minibatch 1024::LR 0.0515384615385 --> Loss 0.0011037059625\n",
      "Epoch 22::Minibatch 1025::LR 0.0515384615385 --> Loss 0.00140196541945\n",
      "Epoch 22::Minibatch 1026::LR 0.0515384615385 --> Loss 0.000773471246163\n",
      "Epoch 22::Minibatch 1027::LR 0.0515384615385 --> Loss 0.00101211716731\n",
      "Epoch 22::Minibatch 1028::LR 0.0515384615385 --> Loss 0.000774746040503\n",
      "Epoch 22::Minibatch 1029::LR 0.0515384615385 --> Loss 0.000763145784537\n",
      "Epoch 22::Minibatch 1030::LR 0.0515384615385 --> Loss 0.000941843787829\n",
      "Epoch 22::Minibatch 1031::LR 0.0515384615385 --> Loss 0.000733601152897\n",
      "Epoch 22::Minibatch 1032::LR 0.0515384615385 --> Loss 0.000782574464877\n",
      "Epoch 22::Minibatch 1033::LR 0.0515384615385 --> Loss 0.000663713415464\n",
      "Epoch 22::Minibatch 1034::LR 0.0515384615385 --> Loss 0.000639043947061\n",
      "Epoch 22::Minibatch 1035::LR 0.0515384615385 --> Loss 0.00043398881952\n",
      "Epoch 22::Minibatch 1036::LR 0.0515384615385 --> Loss 0.00034831682841\n",
      "Epoch 22::Minibatch 1037::LR 0.0515384615385 --> Loss 0.000587280790011\n",
      "Epoch 22::Minibatch 1038::LR 0.0515384615385 --> Loss 0.00122786790133\n",
      "Epoch 22::Minibatch 1039::LR 0.0515384615385 --> Loss 0.000946119626363\n",
      "Epoch 22::Minibatch 1040::LR 0.0515384615385 --> Loss 0.000381830334663\n",
      "Epoch 22::Minibatch 1041::LR 0.0515384615385 --> Loss 0.000548121531804\n",
      "Epoch 23::Minibatch 1::LR 0.0492307692308 --> Loss 0.00864955266317\n",
      "Epoch 23::Minibatch 2::LR 0.0492307692308 --> Loss 0.00525618076324\n",
      "Epoch 23::Minibatch 3::LR 0.0492307692308 --> Loss 0.00351612210274\n",
      "Epoch 23::Minibatch 4::LR 0.0492307692308 --> Loss 0.00406552116076\n",
      "Epoch 23::Minibatch 5::LR 0.0492307692308 --> Loss 0.00458158334096\n",
      "Epoch 23::Minibatch 6::LR 0.0492307692308 --> Loss 0.00225455641747\n",
      "Epoch 23::Minibatch 7::LR 0.0492307692308 --> Loss 0.0074729124705\n",
      "Epoch 23::Minibatch 8::LR 0.0492307692308 --> Loss 0.00703172683716\n",
      "Epoch 23::Minibatch 9::LR 0.0492307692308 --> Loss 0.00527424176534\n",
      "Epoch 23::Minibatch 10::LR 0.0492307692308 --> Loss 0.00258739213149\n",
      "Epoch 23::Minibatch 11::LR 0.0492307692308 --> Loss 0.00233501334985\n",
      "Epoch 23::Minibatch 12::LR 0.0492307692308 --> Loss 0.003421732982\n",
      "Epoch 23::Minibatch 13::LR 0.0492307692308 --> Loss 0.00523744185766\n",
      "Epoch 23::Minibatch 14::LR 0.0492307692308 --> Loss 0.00525293310483\n",
      "Epoch 23::Minibatch 15::LR 0.0492307692308 --> Loss 0.00447010318438\n",
      "Epoch 23::Minibatch 16::LR 0.0492307692308 --> Loss 0.000795245269934\n",
      "Epoch 23::Minibatch 17::LR 0.0492307692308 --> Loss 0.00310669203599\n",
      "Epoch 23::Minibatch 18::LR 0.0492307692308 --> Loss 0.00256445984046\n",
      "Epoch 23::Minibatch 19::LR 0.0492307692308 --> Loss 0.00141592015823\n",
      "Epoch 23::Minibatch 20::LR 0.0492307692308 --> Loss 0.00190860609214\n",
      "Epoch 23::Minibatch 21::LR 0.0492307692308 --> Loss 0.00330216507117\n",
      "Epoch 23::Minibatch 22::LR 0.0492307692308 --> Loss 0.00224841197332\n",
      "Epoch 23::Minibatch 23::LR 0.0492307692308 --> Loss 0.00081388498346\n",
      "Epoch 23::Minibatch 24::LR 0.0492307692308 --> Loss 0.000413815751672\n",
      "Epoch 23::Minibatch 25::LR 0.0492307692308 --> Loss 0.00118402073781\n",
      "Epoch 23::Minibatch 26::LR 0.0492307692308 --> Loss 0.00138812323411\n",
      "Epoch 23::Minibatch 27::LR 0.0492307692308 --> Loss 0.000982106228669\n",
      "Epoch 23::Minibatch 28::LR 0.0492307692308 --> Loss 0.000422144681215\n",
      "Epoch 23::Minibatch 29::LR 0.0492307692308 --> Loss 0.000451203882694\n",
      "Epoch 23::Minibatch 30::LR 0.0492307692308 --> Loss 0.000925293366114\n",
      "Epoch 23::Minibatch 31::LR 0.0492307692308 --> Loss 0.00141467938821\n",
      "Epoch 23::Minibatch 32::LR 0.0492307692308 --> Loss 0.00129435787598\n",
      "Epoch 23::Minibatch 33::LR 0.0492307692308 --> Loss 0.00078050767382\n",
      "Epoch 23::Minibatch 34::LR 0.0492307692308 --> Loss 0.00214495102564\n",
      "Epoch 23::Minibatch 35::LR 0.0492307692308 --> Loss 0.00364005247752\n",
      "Epoch 23::Minibatch 36::LR 0.0492307692308 --> Loss 0.00227971216043\n",
      "Epoch 23::Minibatch 37::LR 0.0492307692308 --> Loss 0.00066160072883\n",
      "Epoch 23::Minibatch 38::LR 0.0492307692308 --> Loss 0.000722706218561\n",
      "Epoch 23::Minibatch 39::LR 0.0492307692308 --> Loss 0.00229827503363\n",
      "Epoch 23::Minibatch 40::LR 0.0492307692308 --> Loss 0.00323675533136\n",
      "Epoch 23::Minibatch 41::LR 0.0492307692308 --> Loss 0.00262408494949\n",
      "Epoch 23::Minibatch 42::LR 0.0492307692308 --> Loss 0.00547191182772\n",
      "Epoch 23::Minibatch 43::LR 0.0492307692308 --> Loss 0.00190417766571\n",
      "Epoch 23::Minibatch 44::LR 0.0492307692308 --> Loss 0.00312811454137\n",
      "Epoch 23::Minibatch 45::LR 0.0492307692308 --> Loss 0.00240878125032\n",
      "Epoch 23::Minibatch 46::LR 0.0492307692308 --> Loss 0.00325201928616\n",
      "Epoch 23::Minibatch 47::LR 0.0492307692308 --> Loss 0.00393723368645\n",
      "Epoch 23::Minibatch 48::LR 0.0492307692308 --> Loss 0.00547252456347\n",
      "Epoch 23::Minibatch 49::LR 0.0492307692308 --> Loss 0.00594191551208\n",
      "Epoch 23::Minibatch 50::LR 0.0492307692308 --> Loss 0.00609092394511\n",
      "Epoch 23::Minibatch 51::LR 0.0492307692308 --> Loss 0.00565810918808\n",
      "Epoch 23::Minibatch 52::LR 0.0492307692308 --> Loss 0.00344396710396\n",
      "Epoch 23::Minibatch 53::LR 0.0492307692308 --> Loss 0.00339371403058\n",
      "Epoch 23::Minibatch 54::LR 0.0492307692308 --> Loss 0.00401542147001\n",
      "Epoch 23::Minibatch 55::LR 0.0492307692308 --> Loss 0.000986147324244\n",
      "Epoch 23::Minibatch 56::LR 0.0492307692308 --> Loss 0.00269367376963\n",
      "Epoch 23::Minibatch 57::LR 0.0492307692308 --> Loss 0.00511213858922\n",
      "Epoch 23::Minibatch 58::LR 0.0492307692308 --> Loss 0.00327514092127\n",
      "Epoch 23::Minibatch 59::LR 0.0492307692308 --> Loss 0.00242795129617\n",
      "Epoch 23::Minibatch 60::LR 0.0492307692308 --> Loss 0.00239598433177\n",
      "Epoch 23::Minibatch 61::LR 0.0492307692308 --> Loss 0.000794425110022\n",
      "Epoch 23::Minibatch 62::LR 0.0492307692308 --> Loss 0.00284890433153\n",
      "Epoch 23::Minibatch 63::LR 0.0492307692308 --> Loss 0.00203079044819\n",
      "Epoch 23::Minibatch 64::LR 0.0492307692308 --> Loss 0.000860113501549\n",
      "Epoch 23::Minibatch 65::LR 0.0492307692308 --> Loss 0.00225551565488\n",
      "Epoch 23::Minibatch 66::LR 0.0492307692308 --> Loss 0.0027394336462\n",
      "Epoch 23::Minibatch 67::LR 0.0492307692308 --> Loss 0.00265986243884\n",
      "Epoch 23::Minibatch 68::LR 0.0492307692308 --> Loss 0.00191016296546\n",
      "Epoch 23::Minibatch 69::LR 0.0492307692308 --> Loss 0.0038213566939\n",
      "Epoch 23::Minibatch 70::LR 0.0492307692308 --> Loss 0.00333300113678\n",
      "Epoch 23::Minibatch 71::LR 0.0492307692308 --> Loss 0.00228814005852\n",
      "Epoch 23::Minibatch 72::LR 0.0492307692308 --> Loss 0.000542877266804\n",
      "Epoch 23::Minibatch 73::LR 0.0492307692308 --> Loss 0.00382819612821\n",
      "Epoch 23::Minibatch 74::LR 0.0492307692308 --> Loss 0.00408482432365\n",
      "Epoch 23::Minibatch 75::LR 0.0492307692308 --> Loss 0.00228223621845\n",
      "Epoch 23::Minibatch 76::LR 0.0492307692308 --> Loss 0.000546838591496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 77::LR 0.0492307692308 --> Loss 0.00360014120738\n",
      "Epoch 23::Minibatch 78::LR 0.0492307692308 --> Loss 0.00385108232498\n",
      "Epoch 23::Minibatch 79::LR 0.0492307692308 --> Loss 0.00185307423274\n",
      "Epoch 23::Minibatch 80::LR 0.0492307692308 --> Loss 0.00306816895803\n",
      "Epoch 23::Minibatch 81::LR 0.0492307692308 --> Loss 0.00267090757688\n",
      "Epoch 23::Minibatch 82::LR 0.0492307692308 --> Loss 0.00194025834401\n",
      "Epoch 23::Minibatch 83::LR 0.0492307692308 --> Loss 0.00428851524989\n",
      "Epoch 23::Minibatch 84::LR 0.0492307692308 --> Loss 0.00193766713142\n",
      "Epoch 23::Minibatch 85::LR 0.0492307692308 --> Loss 0.00267032225927\n",
      "Epoch 23::Minibatch 86::LR 0.0492307692308 --> Loss 0.00216089487076\n",
      "Epoch 23::Minibatch 87::LR 0.0492307692308 --> Loss 0.00235650678476\n",
      "Epoch 23::Minibatch 88::LR 0.0492307692308 --> Loss 0.00173366288344\n",
      "Epoch 23::Minibatch 89::LR 0.0492307692308 --> Loss 0.00226846734683\n",
      "Epoch 23::Minibatch 90::LR 0.0492307692308 --> Loss 0.0010717668136\n",
      "Epoch 23::Minibatch 91::LR 0.0492307692308 --> Loss 0.000871294935544\n",
      "Epoch 23::Minibatch 92::LR 0.0492307692308 --> Loss 0.00264029363791\n",
      "Epoch 23::Minibatch 93::LR 0.0492307692308 --> Loss 0.00173289239407\n",
      "Epoch 23::Minibatch 94::LR 0.0492307692308 --> Loss 0.00174684802691\n",
      "Epoch 23::Minibatch 95::LR 0.0492307692308 --> Loss 0.0018471121788\n",
      "Epoch 23::Minibatch 96::LR 0.0492307692308 --> Loss 0.00537237087886\n",
      "Epoch 23::Minibatch 97::LR 0.0492307692308 --> Loss 0.00309305091699\n",
      "Epoch 23::Minibatch 98::LR 0.0492307692308 --> Loss 0.00101899564266\n",
      "Epoch 23::Minibatch 99::LR 0.0492307692308 --> Loss 0.0013420043389\n",
      "Epoch 23::Minibatch 100::LR 0.0492307692308 --> Loss 0.0047589580218\n",
      "Epoch 23::Minibatch 101::LR 0.0492307692308 --> Loss 0.000911677181721\n",
      "Epoch 23::Minibatch 102::LR 0.0492307692308 --> Loss 0.00388971567154\n",
      "Epoch 23::Minibatch 103::LR 0.0492307692308 --> Loss 0.00398139595985\n",
      "Epoch 23::Minibatch 104::LR 0.0492307692308 --> Loss 0.00272023359934\n",
      "Epoch 23::Minibatch 105::LR 0.0492307692308 --> Loss 0.00241868317127\n",
      "Epoch 23::Minibatch 106::LR 0.0492307692308 --> Loss 0.0162551752726\n",
      "Epoch 23::Minibatch 107::LR 0.0492307692308 --> Loss 0.00483526070913\n",
      "Epoch 23::Minibatch 108::LR 0.0492307692308 --> Loss 0.000994847317537\n",
      "Epoch 23::Minibatch 109::LR 0.0492307692308 --> Loss 0.00431375980377\n",
      "Epoch 23::Minibatch 110::LR 0.0492307692308 --> Loss 0.00230176568031\n",
      "Epoch 23::Minibatch 111::LR 0.0492307692308 --> Loss 0.000889538327853\n",
      "Epoch 23::Minibatch 112::LR 0.0492307692308 --> Loss 0.0034250219663\n",
      "Epoch 23::Minibatch 113::LR 0.0492307692308 --> Loss 0.00253464082877\n",
      "Epoch 23::Minibatch 114::LR 0.0492307692308 --> Loss 0.00140579799811\n",
      "Epoch 23::Minibatch 115::LR 0.0492307692308 --> Loss 0.00124502559503\n",
      "Epoch 23::Minibatch 116::LR 0.0492307692308 --> Loss 0.00269621431828\n",
      "Epoch 23::Minibatch 117::LR 0.0492307692308 --> Loss 0.00389530817668\n",
      "Epoch 23::Minibatch 118::LR 0.0492307692308 --> Loss 0.00677845795949\n",
      "Epoch 23::Minibatch 119::LR 0.0492307692308 --> Loss 0.000580337693294\n",
      "Epoch 23::Minibatch 120::LR 0.0492307692308 --> Loss 0.00169247627258\n",
      "Epoch 23::Minibatch 121::LR 0.0492307692308 --> Loss 0.00252315064271\n",
      "Epoch 23::Minibatch 122::LR 0.0492307692308 --> Loss 0.0037349096934\n",
      "Epoch 23::Minibatch 123::LR 0.0492307692308 --> Loss 0.000873194734255\n",
      "Epoch 23::Minibatch 124::LR 0.0492307692308 --> Loss 0.00268090367317\n",
      "Epoch 23::Minibatch 125::LR 0.0492307692308 --> Loss 0.00453318436941\n",
      "Epoch 23::Minibatch 126::LR 0.0492307692308 --> Loss 0.0026122490565\n",
      "Epoch 23::Minibatch 127::LR 0.0492307692308 --> Loss 0.00451141834259\n",
      "Epoch 23::Minibatch 128::LR 0.0492307692308 --> Loss 0.00357699950536\n",
      "Epoch 23::Minibatch 129::LR 0.0492307692308 --> Loss 0.00258660316467\n",
      "Epoch 23::Minibatch 130::LR 0.0492307692308 --> Loss 0.00434175809224\n",
      "Epoch 23::Minibatch 131::LR 0.0492307692308 --> Loss 0.00175876835982\n",
      "Epoch 23::Minibatch 132::LR 0.0492307692308 --> Loss 0.00298038562139\n",
      "Epoch 23::Minibatch 133::LR 0.0492307692308 --> Loss 0.00283625880877\n",
      "Epoch 23::Minibatch 134::LR 0.0492307692308 --> Loss 0.00225939452648\n",
      "Epoch 23::Minibatch 135::LR 0.0492307692308 --> Loss 0.00145667821169\n",
      "Epoch 23::Minibatch 136::LR 0.0492307692308 --> Loss 0.00260344942411\n",
      "Epoch 23::Minibatch 137::LR 0.0492307692308 --> Loss 0.00357538700104\n",
      "Epoch 23::Minibatch 138::LR 0.0492307692308 --> Loss 0.00127160946528\n",
      "Epoch 23::Minibatch 139::LR 0.0492307692308 --> Loss 0.00190499305725\n",
      "Epoch 23::Minibatch 140::LR 0.0492307692308 --> Loss 0.00244180480639\n",
      "Epoch 23::Minibatch 141::LR 0.0492307692308 --> Loss 0.00294951697191\n",
      "Epoch 23::Minibatch 142::LR 0.0492307692308 --> Loss 0.00278391997019\n",
      "Epoch 23::Minibatch 143::LR 0.0492307692308 --> Loss 0.000581270307302\n",
      "Epoch 23::Minibatch 144::LR 0.0492307692308 --> Loss 0.00327806810538\n",
      "Epoch 23::Minibatch 145::LR 0.0492307692308 --> Loss 0.00424108743668\n",
      "Epoch 23::Minibatch 146::LR 0.0492307692308 --> Loss 0.00254682143529\n",
      "Epoch 23::Minibatch 147::LR 0.0492307692308 --> Loss 0.00180472612381\n",
      "Epoch 23::Minibatch 148::LR 0.0492307692308 --> Loss 0.000998711585999\n",
      "Epoch 23::Minibatch 149::LR 0.0492307692308 --> Loss 0.00283951679866\n",
      "Epoch 23::Minibatch 150::LR 0.0492307692308 --> Loss 0.00269757131735\n",
      "Epoch 23::Minibatch 151::LR 0.0492307692308 --> Loss 0.00425320625305\n",
      "Epoch 23::Minibatch 152::LR 0.0492307692308 --> Loss 0.000914653440317\n",
      "Epoch 23::Minibatch 153::LR 0.0492307692308 --> Loss 0.00175315598647\n",
      "Epoch 23::Minibatch 154::LR 0.0492307692308 --> Loss 0.00204105377197\n",
      "Epoch 23::Minibatch 155::LR 0.0492307692308 --> Loss 0.00430410385132\n",
      "Epoch 23::Minibatch 156::LR 0.0492307692308 --> Loss 0.00238038122654\n",
      "Epoch 23::Minibatch 157::LR 0.0492307692308 --> Loss 0.000696289936701\n",
      "Epoch 23::Minibatch 158::LR 0.0492307692308 --> Loss 0.0030931476752\n",
      "Epoch 23::Minibatch 159::LR 0.0492307692308 --> Loss 0.00274301250776\n",
      "Epoch 23::Minibatch 160::LR 0.0492307692308 --> Loss 0.00263185242812\n",
      "Epoch 23::Minibatch 161::LR 0.0492307692308 --> Loss 0.00101479232311\n",
      "Epoch 23::Minibatch 162::LR 0.0492307692308 --> Loss 0.00382211009661\n",
      "Epoch 23::Minibatch 163::LR 0.0492307692308 --> Loss 0.00239493290583\n",
      "Epoch 23::Minibatch 164::LR 0.0492307692308 --> Loss 0.00250428676605\n",
      "Epoch 23::Minibatch 165::LR 0.0492307692308 --> Loss 0.000518549134334\n",
      "Epoch 23::Minibatch 166::LR 0.0492307692308 --> Loss 0.00175944626331\n",
      "Epoch 23::Minibatch 167::LR 0.0492307692308 --> Loss 0.00246172308922\n",
      "Epoch 23::Minibatch 168::LR 0.0492307692308 --> Loss 0.0021686877807\n",
      "Epoch 23::Minibatch 169::LR 0.0492307692308 --> Loss 0.00100734601418\n",
      "Epoch 23::Minibatch 170::LR 0.0492307692308 --> Loss 0.000979120333989\n",
      "Epoch 23::Minibatch 171::LR 0.0492307692308 --> Loss 0.00250107228756\n",
      "Epoch 23::Minibatch 172::LR 0.0492307692308 --> Loss 0.00434642116229\n",
      "Epoch 23::Minibatch 173::LR 0.0492307692308 --> Loss 0.00195385317008\n",
      "Epoch 23::Minibatch 174::LR 0.0492307692308 --> Loss 0.00101398219665\n",
      "Epoch 23::Minibatch 175::LR 0.0492307692308 --> Loss 0.00231894393762\n",
      "Epoch 23::Minibatch 176::LR 0.0492307692308 --> Loss 0.00321101943652\n",
      "Epoch 23::Minibatch 177::LR 0.0492307692308 --> Loss 0.00445787906647\n",
      "Epoch 23::Minibatch 178::LR 0.0492307692308 --> Loss 0.00158859590689\n",
      "Epoch 23::Minibatch 179::LR 0.0492307692308 --> Loss 0.00129869838556\n",
      "Epoch 23::Minibatch 180::LR 0.0492307692308 --> Loss 0.00351095557213\n",
      "Epoch 23::Minibatch 181::LR 0.0492307692308 --> Loss 0.00318363885085\n",
      "Epoch 23::Minibatch 182::LR 0.0492307692308 --> Loss 0.000750579982996\n",
      "Epoch 23::Minibatch 183::LR 0.0492307692308 --> Loss 0.00164448261261\n",
      "Epoch 23::Minibatch 184::LR 0.0492307692308 --> Loss 0.00343232591947\n",
      "Epoch 23::Minibatch 185::LR 0.0492307692308 --> Loss 0.00278058131536\n",
      "Epoch 23::Minibatch 186::LR 0.0492307692308 --> Loss 0.000961715678374\n",
      "Epoch 23::Minibatch 187::LR 0.0492307692308 --> Loss 0.00127205848694\n",
      "Epoch 23::Minibatch 188::LR 0.0492307692308 --> Loss 0.00415332913399\n",
      "Epoch 23::Minibatch 189::LR 0.0492307692308 --> Loss 0.0043267039458\n",
      "Epoch 23::Minibatch 190::LR 0.0492307692308 --> Loss 0.00232520123323\n",
      "Epoch 23::Minibatch 191::LR 0.0492307692308 --> Loss 0.000467630575101\n",
      "Epoch 23::Minibatch 192::LR 0.0492307692308 --> Loss 0.00273739437262\n",
      "Epoch 23::Minibatch 193::LR 0.0492307692308 --> Loss 0.00260939578215\n",
      "Epoch 23::Minibatch 194::LR 0.0492307692308 --> Loss 0.00176957885424\n",
      "Epoch 23::Minibatch 195::LR 0.0492307692308 --> Loss 0.000380702714125\n",
      "Epoch 23::Minibatch 196::LR 0.0492307692308 --> Loss 0.00126758635044\n",
      "Epoch 23::Minibatch 197::LR 0.0492307692308 --> Loss 0.00289920608203\n",
      "Epoch 23::Minibatch 198::LR 0.0492307692308 --> Loss 0.00223825613658\n",
      "Epoch 23::Minibatch 199::LR 0.0492307692308 --> Loss 0.00028695633014\n",
      "Epoch 23::Minibatch 200::LR 0.0492307692308 --> Loss 0.00205025196075\n",
      "Epoch 23::Minibatch 201::LR 0.0492307692308 --> Loss 0.0019447316726\n",
      "Epoch 23::Minibatch 202::LR 0.0492307692308 --> Loss 0.00184930682182\n",
      "Epoch 23::Minibatch 203::LR 0.0492307692308 --> Loss 0.00175340215365\n",
      "Epoch 23::Minibatch 204::LR 0.0492307692308 --> Loss 0.00143494447072\n",
      "Epoch 23::Minibatch 205::LR 0.0492307692308 --> Loss 0.00220197180907\n",
      "Epoch 23::Minibatch 206::LR 0.0492307692308 --> Loss 0.00611024697622\n",
      "Epoch 23::Minibatch 207::LR 0.0492307692308 --> Loss 0.00139552682638\n",
      "Epoch 23::Minibatch 208::LR 0.0492307692308 --> Loss 0.00111594478289\n",
      "Epoch 23::Minibatch 209::LR 0.0492307692308 --> Loss 0.00229642430941\n",
      "Epoch 23::Minibatch 210::LR 0.0492307692308 --> Loss 0.00219004233678\n",
      "Epoch 23::Minibatch 211::LR 0.0492307692308 --> Loss 0.00240838726362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 212::LR 0.0492307692308 --> Loss 0.00390031298002\n",
      "Epoch 23::Minibatch 213::LR 0.0492307692308 --> Loss 0.00569377462069\n",
      "Epoch 23::Minibatch 214::LR 0.0492307692308 --> Loss 0.0084132194519\n",
      "Epoch 23::Minibatch 215::LR 0.0492307692308 --> Loss 0.00137061635653\n",
      "Epoch 23::Minibatch 216::LR 0.0492307692308 --> Loss 0.00542877713839\n",
      "Epoch 23::Minibatch 217::LR 0.0492307692308 --> Loss 0.00607411901156\n",
      "Epoch 23::Minibatch 218::LR 0.0492307692308 --> Loss 0.00392381509145\n",
      "Epoch 23::Minibatch 219::LR 0.0492307692308 --> Loss 0.00423358122508\n",
      "Epoch 23::Minibatch 220::LR 0.0492307692308 --> Loss 0.00445107857386\n",
      "Epoch 23::Minibatch 221::LR 0.0492307692308 --> Loss 0.00424380143483\n",
      "Epoch 23::Minibatch 222::LR 0.0492307692308 --> Loss 0.00321648875872\n",
      "Epoch 23::Minibatch 223::LR 0.0492307692308 --> Loss 0.00140375802914\n",
      "Epoch 23::Minibatch 224::LR 0.0492307692308 --> Loss 0.00169248342514\n",
      "Epoch 23::Minibatch 225::LR 0.0492307692308 --> Loss 0.00745497385661\n",
      "Epoch 23::Minibatch 226::LR 0.0492307692308 --> Loss 0.00374978462855\n",
      "Epoch 23::Minibatch 227::LR 0.0492307692308 --> Loss 0.00168608049552\n",
      "Epoch 23::Minibatch 228::LR 0.0492307692308 --> Loss 0.000707327077786\n",
      "Epoch 23::Minibatch 229::LR 0.0492307692308 --> Loss 0.00474525650342\n",
      "Epoch 23::Minibatch 230::LR 0.0492307692308 --> Loss 0.00385488788287\n",
      "Epoch 23::Minibatch 231::LR 0.0492307692308 --> Loss 0.00265104293823\n",
      "Epoch 23::Minibatch 232::LR 0.0492307692308 --> Loss 0.00119505524635\n",
      "Epoch 23::Minibatch 233::LR 0.0492307692308 --> Loss 0.00243574500084\n",
      "Epoch 23::Minibatch 234::LR 0.0492307692308 --> Loss 0.00706314563751\n",
      "Epoch 23::Minibatch 235::LR 0.0492307692308 --> Loss 0.00462868014971\n",
      "Epoch 23::Minibatch 236::LR 0.0492307692308 --> Loss 0.00173150002956\n",
      "Epoch 23::Minibatch 237::LR 0.0492307692308 --> Loss 0.00064994653066\n",
      "Epoch 23::Minibatch 238::LR 0.0492307692308 --> Loss 0.00341346859932\n",
      "Epoch 23::Minibatch 239::LR 0.0492307692308 --> Loss 0.00295954346657\n",
      "Epoch 23::Minibatch 240::LR 0.0492307692308 --> Loss 0.00324104944865\n",
      "Epoch 23::Minibatch 241::LR 0.0492307692308 --> Loss 0.000753716478745\n",
      "Epoch 23::Minibatch 242::LR 0.0492307692308 --> Loss 0.0069234752655\n",
      "Epoch 23::Minibatch 243::LR 0.0492307692308 --> Loss 0.00342259327571\n",
      "Epoch 23::Minibatch 244::LR 0.0492307692308 --> Loss 0.00286862293879\n",
      "Epoch 23::Minibatch 245::LR 0.0492307692308 --> Loss 0.000459613253673\n",
      "Epoch 23::Minibatch 246::LR 0.0492307692308 --> Loss 0.00201226135095\n",
      "Epoch 23::Minibatch 247::LR 0.0492307692308 --> Loss 0.0121192709605\n",
      "Epoch 23::Minibatch 248::LR 0.0492307692308 --> Loss 0.00442952156067\n",
      "Epoch 23::Minibatch 249::LR 0.0492307692308 --> Loss 0.00259041468302\n",
      "Epoch 23::Minibatch 250::LR 0.0492307692308 --> Loss 0.00248528778553\n",
      "Epoch 23::Minibatch 251::LR 0.0492307692308 --> Loss 0.0024438560009\n",
      "Epoch 23::Minibatch 252::LR 0.0492307692308 --> Loss 0.00171869397163\n",
      "Epoch 23::Minibatch 253::LR 0.0492307692308 --> Loss 0.0029887843132\n",
      "Epoch 23::Minibatch 254::LR 0.0492307692308 --> Loss 0.00502764979998\n",
      "Epoch 23::Minibatch 255::LR 0.0492307692308 --> Loss 0.00382740338643\n",
      "Epoch 23::Minibatch 256::LR 0.0492307692308 --> Loss 0.00155112147331\n",
      "Epoch 23::Minibatch 257::LR 0.0492307692308 --> Loss 0.00119063625733\n",
      "Epoch 23::Minibatch 258::LR 0.0492307692308 --> Loss 0.0036357764403\n",
      "Epoch 23::Minibatch 259::LR 0.0492307692308 --> Loss 0.00172001341979\n",
      "Epoch 23::Minibatch 260::LR 0.0492307692308 --> Loss 0.00186909536521\n",
      "Epoch 23::Minibatch 261::LR 0.0492307692308 --> Loss 0.00277645687262\n",
      "Epoch 23::Minibatch 262::LR 0.0492307692308 --> Loss 0.00188503841559\n",
      "Epoch 23::Minibatch 263::LR 0.0492307692308 --> Loss 0.00234343787034\n",
      "Epoch 23::Minibatch 264::LR 0.0492307692308 --> Loss 0.00361137111982\n",
      "Epoch 23::Minibatch 265::LR 0.0492307692308 --> Loss 0.0100727971395\n",
      "Epoch 23::Minibatch 266::LR 0.0492307692308 --> Loss 0.00096817145745\n",
      "Epoch 23::Minibatch 267::LR 0.0492307692308 --> Loss 0.0096787516276\n",
      "Epoch 23::Minibatch 268::LR 0.0492307692308 --> Loss 0.00113103091717\n",
      "Epoch 23::Minibatch 269::LR 0.0492307692308 --> Loss 0.00351176699003\n",
      "Epoch 23::Minibatch 270::LR 0.0492307692308 --> Loss 0.00686176458995\n",
      "Epoch 23::Minibatch 271::LR 0.0492307692308 --> Loss 0.00260527332624\n",
      "Epoch 23::Minibatch 272::LR 0.0492307692308 --> Loss 0.00423069914182\n",
      "Epoch 23::Minibatch 273::LR 0.0492307692308 --> Loss 0.00156373262405\n",
      "Epoch 23::Minibatch 274::LR 0.0492307692308 --> Loss 0.00178676803907\n",
      "Epoch 23::Minibatch 275::LR 0.0492307692308 --> Loss 0.00258485297362\n",
      "Epoch 23::Minibatch 276::LR 0.0492307692308 --> Loss 0.00343041181564\n",
      "Epoch 23::Minibatch 277::LR 0.0492307692308 --> Loss 0.000952352583408\n",
      "Epoch 23::Minibatch 278::LR 0.0492307692308 --> Loss 0.00260309040546\n",
      "Epoch 23::Minibatch 279::LR 0.0492307692308 --> Loss 0.0022411886851\n",
      "Epoch 23::Minibatch 280::LR 0.0492307692308 --> Loss 0.00196151137352\n",
      "Epoch 23::Minibatch 281::LR 0.0492307692308 --> Loss 0.00123891035716\n",
      "Epoch 23::Minibatch 282::LR 0.0492307692308 --> Loss 0.00215919454892\n",
      "Epoch 23::Minibatch 283::LR 0.0492307692308 --> Loss 0.00209023177624\n",
      "Epoch 23::Minibatch 284::LR 0.0492307692308 --> Loss 0.00168150345484\n",
      "Epoch 23::Minibatch 285::LR 0.0492307692308 --> Loss 0.00118869980176\n",
      "Epoch 23::Minibatch 286::LR 0.0492307692308 --> Loss 0.00208582917849\n",
      "Epoch 23::Minibatch 287::LR 0.0492307692308 --> Loss 0.00203811685244\n",
      "Epoch 23::Minibatch 288::LR 0.0492307692308 --> Loss 0.00110247602065\n",
      "Epoch 23::Minibatch 289::LR 0.0492307692308 --> Loss 0.00159852127234\n",
      "Epoch 23::Minibatch 290::LR 0.0492307692308 --> Loss 0.00191993196805\n",
      "Epoch 23::Minibatch 291::LR 0.0492307692308 --> Loss 0.00171260416508\n",
      "Epoch 23::Minibatch 292::LR 0.0492307692308 --> Loss 0.000602025638024\n",
      "Epoch 23::Minibatch 293::LR 0.0492307692308 --> Loss 0.00150306731462\n",
      "Epoch 23::Minibatch 294::LR 0.0492307692308 --> Loss 0.00159135262171\n",
      "Epoch 23::Minibatch 295::LR 0.0492307692308 --> Loss 0.00187801480293\n",
      "Epoch 23::Minibatch 296::LR 0.0492307692308 --> Loss 0.00162906140089\n",
      "Epoch 23::Minibatch 297::LR 0.0492307692308 --> Loss 0.0014149526755\n",
      "Epoch 23::Minibatch 298::LR 0.0492307692308 --> Loss 0.00140715758006\n",
      "Epoch 23::Minibatch 299::LR 0.0492307692308 --> Loss 0.000805750638247\n",
      "Epoch 23::Minibatch 300::LR 0.0492307692308 --> Loss 0.00276376028856\n",
      "Epoch 23::Minibatch 301::LR 0.0492307692308 --> Loss 0.00267699321111\n",
      "Epoch 23::Minibatch 302::LR 0.0492307692308 --> Loss 0.00245510598024\n",
      "Epoch 23::Minibatch 303::LR 0.0492307692308 --> Loss 0.000852228403091\n",
      "Epoch 23::Minibatch 304::LR 0.0492307692308 --> Loss 0.00304412961006\n",
      "Epoch 23::Minibatch 305::LR 0.0492307692308 --> Loss 0.00170107364655\n",
      "Epoch 23::Minibatch 306::LR 0.0492307692308 --> Loss 0.000937078297138\n",
      "Epoch 23::Minibatch 307::LR 0.0492307692308 --> Loss 0.00243896702925\n",
      "Epoch 23::Minibatch 308::LR 0.0492307692308 --> Loss 0.00200951099396\n",
      "Epoch 23::Minibatch 309::LR 0.0492307692308 --> Loss 0.00102178523938\n",
      "Epoch 23::Minibatch 310::LR 0.0492307692308 --> Loss 0.0011554624637\n",
      "Epoch 23::Minibatch 311::LR 0.0492307692308 --> Loss 0.00175960938136\n",
      "Epoch 23::Minibatch 312::LR 0.0492307692308 --> Loss 0.00290628731251\n",
      "Epoch 23::Minibatch 313::LR 0.0492307692308 --> Loss 0.00237680137157\n",
      "Epoch 23::Minibatch 314::LR 0.0492307692308 --> Loss 0.00192071219285\n",
      "Epoch 23::Minibatch 315::LR 0.0492307692308 --> Loss 0.00102096011241\n",
      "Epoch 23::Minibatch 316::LR 0.0492307692308 --> Loss 0.00233593920867\n",
      "Epoch 23::Minibatch 317::LR 0.0492307692308 --> Loss 0.00155457327763\n",
      "Epoch 23::Minibatch 318::LR 0.0492307692308 --> Loss 0.00126452147961\n",
      "Epoch 23::Minibatch 319::LR 0.0492307692308 --> Loss 0.00230116605759\n",
      "Epoch 23::Minibatch 320::LR 0.0492307692308 --> Loss 0.00312728464603\n",
      "Epoch 23::Minibatch 321::LR 0.0492307692308 --> Loss 0.000842473506927\n",
      "Epoch 23::Minibatch 322::LR 0.0492307692308 --> Loss 0.00358444094658\n",
      "Epoch 23::Minibatch 323::LR 0.0492307692308 --> Loss 0.00348250587781\n",
      "Epoch 23::Minibatch 324::LR 0.0492307692308 --> Loss 0.00264126638571\n",
      "Epoch 23::Minibatch 325::LR 0.0492307692308 --> Loss 0.00238688826561\n",
      "Epoch 23::Minibatch 326::LR 0.0492307692308 --> Loss 0.00544329484304\n",
      "Epoch 23::Minibatch 327::LR 0.0492307692308 --> Loss 0.00225018024445\n",
      "Epoch 23::Minibatch 328::LR 0.0492307692308 --> Loss 0.0031338518858\n",
      "Epoch 23::Minibatch 329::LR 0.0492307692308 --> Loss 0.0012090921402\n",
      "Epoch 23::Minibatch 330::LR 0.0492307692308 --> Loss 0.00159475455681\n",
      "Epoch 23::Minibatch 331::LR 0.0492307692308 --> Loss 0.00253787676493\n",
      "Epoch 23::Minibatch 332::LR 0.0492307692308 --> Loss 0.00248556315899\n",
      "Epoch 23::Minibatch 333::LR 0.0492307692308 --> Loss 0.00145355701447\n",
      "Epoch 23::Minibatch 334::LR 0.0492307692308 --> Loss 0.00441768407822\n",
      "Epoch 23::Minibatch 335::LR 0.0492307692308 --> Loss 0.00188804785411\n",
      "Epoch 23::Minibatch 336::LR 0.0492307692308 --> Loss 0.00220725576083\n",
      "Epoch 23::Minibatch 337::LR 0.0492307692308 --> Loss 0.00356074651082\n",
      "Epoch 23::Minibatch 338::LR 0.0492307692308 --> Loss 0.000535139789184\n",
      "Epoch 23::Minibatch 339::LR 0.0492307692308 --> Loss 0.00330136020978\n",
      "Epoch 23::Minibatch 340::LR 0.0492307692308 --> Loss 0.00389472325643\n",
      "Epoch 23::Minibatch 341::LR 0.0492307692308 --> Loss 0.00460230747859\n",
      "Epoch 23::Minibatch 342::LR 0.0492307692308 --> Loss 0.00309051990509\n",
      "Epoch 23::Minibatch 343::LR 0.0492307692308 --> Loss 0.00165566752354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 344::LR 0.0492307692308 --> Loss 0.00315079291662\n",
      "Epoch 23::Minibatch 345::LR 0.0492307692308 --> Loss 0.00419277985891\n",
      "Epoch 23::Minibatch 346::LR 0.0492307692308 --> Loss 0.00555658141772\n",
      "Epoch 23::Minibatch 347::LR 0.0492307692308 --> Loss 0.000829394708077\n",
      "Epoch 23::Minibatch 348::LR 0.0492307692308 --> Loss 0.0032268289725\n",
      "Epoch 23::Minibatch 349::LR 0.0492307692308 --> Loss 0.00345108111699\n",
      "Epoch 23::Minibatch 350::LR 0.0492307692308 --> Loss 0.00169988393784\n",
      "Epoch 23::Minibatch 351::LR 0.0492307692308 --> Loss 0.00347251415253\n",
      "Epoch 23::Minibatch 352::LR 0.0492307692308 --> Loss 0.00492349584897\n",
      "Epoch 23::Minibatch 353::LR 0.0492307692308 --> Loss 0.00353602806727\n",
      "Epoch 23::Minibatch 354::LR 0.0492307692308 --> Loss 0.00294741769632\n",
      "Epoch 23::Minibatch 355::LR 0.0492307692308 --> Loss 0.00617446541786\n",
      "Epoch 23::Minibatch 356::LR 0.0492307692308 --> Loss 0.00312890172005\n",
      "Epoch 23::Minibatch 357::LR 0.0492307692308 --> Loss 0.00113632768393\n",
      "Epoch 23::Minibatch 358::LR 0.0492307692308 --> Loss 0.00205428798993\n",
      "Epoch 23::Minibatch 359::LR 0.0492307692308 --> Loss 0.00270214637121\n",
      "Epoch 23::Minibatch 360::LR 0.0492307692308 --> Loss 0.00237454096476\n",
      "Epoch 23::Minibatch 361::LR 0.0492307692308 --> Loss 0.00235599776109\n",
      "Epoch 23::Minibatch 362::LR 0.0492307692308 --> Loss 0.00233172198137\n",
      "Epoch 23::Minibatch 363::LR 0.0492307692308 --> Loss 0.000647990653912\n",
      "Epoch 23::Minibatch 364::LR 0.0492307692308 --> Loss 0.00198922852675\n",
      "Epoch 23::Minibatch 365::LR 0.0492307692308 --> Loss 0.00205576856931\n",
      "Epoch 23::Minibatch 366::LR 0.0492307692308 --> Loss 0.00218759338061\n",
      "Epoch 23::Minibatch 367::LR 0.0492307692308 --> Loss 0.00104312608639\n",
      "Epoch 23::Minibatch 368::LR 0.0492307692308 --> Loss 0.000977761348089\n",
      "Epoch 23::Minibatch 369::LR 0.0492307692308 --> Loss 0.00283501843611\n",
      "Epoch 23::Minibatch 370::LR 0.0492307692308 --> Loss 0.00224356989066\n",
      "Epoch 23::Minibatch 371::LR 0.0492307692308 --> Loss 0.00186596632004\n",
      "Epoch 23::Minibatch 372::LR 0.0492307692308 --> Loss 0.000430727054675\n",
      "Epoch 23::Minibatch 373::LR 0.0492307692308 --> Loss 0.00178497890631\n",
      "Epoch 23::Minibatch 374::LR 0.0492307692308 --> Loss 0.0022169760863\n",
      "Epoch 23::Minibatch 375::LR 0.0492307692308 --> Loss 0.00185696403186\n",
      "Epoch 23::Minibatch 376::LR 0.0492307692308 --> Loss 0.00122819741567\n",
      "Epoch 23::Minibatch 377::LR 0.0492307692308 --> Loss 0.00192756553491\n",
      "Epoch 23::Minibatch 378::LR 0.0492307692308 --> Loss 0.0021156146129\n",
      "Epoch 23::Minibatch 379::LR 0.0492307692308 --> Loss 0.00235292772452\n",
      "Epoch 23::Minibatch 380::LR 0.0492307692308 --> Loss 0.00157683690389\n",
      "Epoch 23::Minibatch 381::LR 0.0492307692308 --> Loss 0.000984577337901\n",
      "Epoch 23::Minibatch 382::LR 0.0492307692308 --> Loss 0.00201841652393\n",
      "Epoch 23::Minibatch 383::LR 0.0492307692308 --> Loss 0.00196684380372\n",
      "Epoch 23::Minibatch 384::LR 0.0492307692308 --> Loss 0.00107349485159\n",
      "Epoch 23::Minibatch 385::LR 0.0492307692308 --> Loss 0.00104140082995\n",
      "Epoch 23::Minibatch 386::LR 0.0492307692308 --> Loss 0.00219868878524\n",
      "Epoch 23::Minibatch 387::LR 0.0492307692308 --> Loss 0.00234980344772\n",
      "Epoch 23::Minibatch 388::LR 0.0492307692308 --> Loss 0.00117381940285\n",
      "Epoch 23::Minibatch 389::LR 0.0492307692308 --> Loss 0.00178944687049\n",
      "Epoch 23::Minibatch 390::LR 0.0492307692308 --> Loss 0.00342202941577\n",
      "Epoch 23::Minibatch 391::LR 0.0492307692308 --> Loss 0.00261735260487\n",
      "Epoch 23::Minibatch 392::LR 0.0492307692308 --> Loss 0.00258987148603\n",
      "Epoch 23::Minibatch 393::LR 0.0492307692308 --> Loss 0.00275025983651\n",
      "Epoch 23::Minibatch 394::LR 0.0492307692308 --> Loss 0.00205361147722\n",
      "Epoch 23::Minibatch 395::LR 0.0492307692308 --> Loss 0.00205763022105\n",
      "Epoch 23::Minibatch 396::LR 0.0492307692308 --> Loss 0.00193130731583\n",
      "Epoch 23::Minibatch 397::LR 0.0492307692308 --> Loss 0.00206724246343\n",
      "Epoch 23::Minibatch 398::LR 0.0492307692308 --> Loss 0.00205360571543\n",
      "Epoch 23::Minibatch 399::LR 0.0492307692308 --> Loss 0.00236365218957\n",
      "Epoch 23::Minibatch 400::LR 0.0492307692308 --> Loss 0.0020031162103\n",
      "Epoch 23::Minibatch 401::LR 0.0492307692308 --> Loss 0.003434719642\n",
      "Epoch 23::Minibatch 402::LR 0.0492307692308 --> Loss 0.00174761692683\n",
      "Epoch 23::Minibatch 403::LR 0.0492307692308 --> Loss 0.00143154770136\n",
      "Epoch 23::Minibatch 404::LR 0.0492307692308 --> Loss 0.0014021846652\n",
      "Epoch 23::Minibatch 405::LR 0.0492307692308 --> Loss 0.0034098525842\n",
      "Epoch 23::Minibatch 406::LR 0.0492307692308 --> Loss 0.00239257435004\n",
      "Epoch 23::Minibatch 407::LR 0.0492307692308 --> Loss 0.00171116113663\n",
      "Epoch 23::Minibatch 408::LR 0.0492307692308 --> Loss 0.000430664569139\n",
      "Epoch 23::Minibatch 409::LR 0.0492307692308 --> Loss 0.00226009984811\n",
      "Epoch 23::Minibatch 410::LR 0.0492307692308 --> Loss 0.00315534373124\n",
      "Epoch 23::Minibatch 411::LR 0.0492307692308 --> Loss 0.00163458625476\n",
      "Epoch 23::Minibatch 412::LR 0.0492307692308 --> Loss 0.000942982633909\n",
      "Epoch 23::Minibatch 413::LR 0.0492307692308 --> Loss 0.00195508897305\n",
      "Epoch 23::Minibatch 414::LR 0.0492307692308 --> Loss 0.00183958093325\n",
      "Epoch 23::Minibatch 415::LR 0.0492307692308 --> Loss 0.0011436889569\n",
      "Epoch 23::Minibatch 416::LR 0.0492307692308 --> Loss 0.000793212205172\n",
      "Epoch 23::Minibatch 417::LR 0.0492307692308 --> Loss 0.00167697906494\n",
      "Epoch 23::Minibatch 418::LR 0.0492307692308 --> Loss 0.00265307823817\n",
      "Epoch 23::Minibatch 419::LR 0.0492307692308 --> Loss 0.000487066308657\n",
      "Epoch 23::Minibatch 420::LR 0.0492307692308 --> Loss 0.000682745873928\n",
      "Epoch 23::Minibatch 421::LR 0.0492307692308 --> Loss 0.00189279119174\n",
      "Epoch 23::Minibatch 422::LR 0.0492307692308 --> Loss 0.00208904743195\n",
      "Epoch 23::Minibatch 423::LR 0.0492307692308 --> Loss 0.000961866478125\n",
      "Epoch 23::Minibatch 424::LR 0.0492307692308 --> Loss 0.00152205765247\n",
      "Epoch 23::Minibatch 425::LR 0.0492307692308 --> Loss 0.00288399298986\n",
      "Epoch 23::Minibatch 426::LR 0.0492307692308 --> Loss 0.00198132415613\n",
      "Epoch 23::Minibatch 427::LR 0.0492307692308 --> Loss 0.000709564487139\n",
      "Epoch 23::Minibatch 428::LR 0.0492307692308 --> Loss 0.000984804232915\n",
      "Epoch 23::Minibatch 429::LR 0.0492307692308 --> Loss 0.00230373620987\n",
      "Epoch 23::Minibatch 430::LR 0.0492307692308 --> Loss 0.00883037646612\n",
      "Epoch 23::Minibatch 431::LR 0.0492307692308 --> Loss 0.00373965581258\n",
      "Epoch 23::Minibatch 432::LR 0.0492307692308 --> Loss 0.00425555904706\n",
      "Epoch 23::Minibatch 433::LR 0.0492307692308 --> Loss 0.00254544059436\n",
      "Epoch 23::Minibatch 434::LR 0.0492307692308 --> Loss 0.00249323228995\n",
      "Epoch 23::Minibatch 435::LR 0.0492307692308 --> Loss 0.0022833977143\n",
      "Epoch 23::Minibatch 436::LR 0.0492307692308 --> Loss 0.00163655281067\n",
      "Epoch 23::Minibatch 437::LR 0.0492307692308 --> Loss 0.00301780084769\n",
      "Epoch 23::Minibatch 438::LR 0.0492307692308 --> Loss 0.00242327511311\n",
      "Epoch 23::Minibatch 439::LR 0.0492307692308 --> Loss 0.00199074784915\n",
      "Epoch 23::Minibatch 440::LR 0.0492307692308 --> Loss 0.00309059798717\n",
      "Epoch 23::Minibatch 441::LR 0.0492307692308 --> Loss 0.00288572311401\n",
      "Epoch 23::Minibatch 442::LR 0.0492307692308 --> Loss 0.00261206964652\n",
      "Epoch 23::Minibatch 443::LR 0.0492307692308 --> Loss 0.00355437318484\n",
      "Epoch 23::Minibatch 444::LR 0.0492307692308 --> Loss 0.00276428421338\n",
      "Epoch 23::Minibatch 445::LR 0.0492307692308 --> Loss 0.000867412686348\n",
      "Epoch 23::Minibatch 446::LR 0.0492307692308 --> Loss 0.00140254835288\n",
      "Epoch 23::Minibatch 447::LR 0.0492307692308 --> Loss 0.00235723614693\n",
      "Epoch 23::Minibatch 448::LR 0.0492307692308 --> Loss 0.0023473149538\n",
      "Epoch 23::Minibatch 449::LR 0.0492307692308 --> Loss 0.00364591121674\n",
      "Epoch 23::Minibatch 450::LR 0.0492307692308 --> Loss 0.00220639407635\n",
      "Epoch 23::Minibatch 451::LR 0.0492307692308 --> Loss 0.00392384648323\n",
      "Epoch 23::Minibatch 452::LR 0.0492307692308 --> Loss 0.00233109692732\n",
      "Epoch 23::Minibatch 453::LR 0.0492307692308 --> Loss 0.000359396686157\n",
      "Epoch 23::Minibatch 454::LR 0.0492307692308 --> Loss 0.00353216807048\n",
      "Epoch 23::Minibatch 455::LR 0.0492307692308 --> Loss 0.00264083862305\n",
      "Epoch 23::Minibatch 456::LR 0.0492307692308 --> Loss 0.00307475308577\n",
      "Epoch 23::Minibatch 457::LR 0.0492307692308 --> Loss 0.0019085286061\n",
      "Epoch 23::Minibatch 458::LR 0.0492307692308 --> Loss 0.000728767315547\n",
      "Epoch 23::Minibatch 459::LR 0.0492307692308 --> Loss 0.00396813750267\n",
      "Epoch 23::Minibatch 460::LR 0.0492307692308 --> Loss 0.00249337454637\n",
      "Epoch 23::Minibatch 461::LR 0.0492307692308 --> Loss 0.00379164059957\n",
      "Epoch 23::Minibatch 462::LR 0.0492307692308 --> Loss 0.000378473550081\n",
      "Epoch 23::Minibatch 463::LR 0.0492307692308 --> Loss 0.00434894680977\n",
      "Epoch 23::Minibatch 464::LR 0.0492307692308 --> Loss 0.00198650260766\n",
      "Epoch 23::Minibatch 465::LR 0.0492307692308 --> Loss 0.00488050460815\n",
      "Epoch 23::Minibatch 466::LR 0.0492307692308 --> Loss 0.0050373574098\n",
      "Epoch 23::Minibatch 467::LR 0.0492307692308 --> Loss 0.0053734989961\n",
      "Epoch 23::Minibatch 468::LR 0.0492307692308 --> Loss 0.00586471875509\n",
      "Epoch 23::Minibatch 469::LR 0.0492307692308 --> Loss 0.0062997965018\n",
      "Epoch 23::Minibatch 470::LR 0.0492307692308 --> Loss 0.00364562511444\n",
      "Epoch 23::Minibatch 471::LR 0.0492307692308 --> Loss 0.00168762266636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 472::LR 0.0492307692308 --> Loss 0.00354502121607\n",
      "Epoch 23::Minibatch 473::LR 0.0492307692308 --> Loss 0.0022781364123\n",
      "Epoch 23::Minibatch 474::LR 0.0492307692308 --> Loss 0.000692033072313\n",
      "Epoch 23::Minibatch 475::LR 0.0492307692308 --> Loss 0.00483637770017\n",
      "Epoch 23::Minibatch 476::LR 0.0492307692308 --> Loss 0.00765297412872\n",
      "Epoch 23::Minibatch 477::LR 0.0492307692308 --> Loss 0.000918974777063\n",
      "Epoch 23::Minibatch 478::LR 0.0492307692308 --> Loss 0.0024340603749\n",
      "Epoch 23::Minibatch 479::LR 0.0492307692308 --> Loss 0.00195860187213\n",
      "Epoch 23::Minibatch 480::LR 0.0492307692308 --> Loss 0.00152151763439\n",
      "Epoch 23::Minibatch 481::LR 0.0492307692308 --> Loss 0.000955707232157\n",
      "Epoch 23::Minibatch 482::LR 0.0492307692308 --> Loss 0.00207945923011\n",
      "Epoch 23::Minibatch 483::LR 0.0492307692308 --> Loss 0.00309218386809\n",
      "Epoch 23::Minibatch 484::LR 0.0492307692308 --> Loss 0.00346949378649\n",
      "Epoch 23::Minibatch 485::LR 0.0492307692308 --> Loss 0.000757109274467\n",
      "Epoch 23::Minibatch 486::LR 0.0492307692308 --> Loss 0.00286361058553\n",
      "Epoch 23::Minibatch 487::LR 0.0492307692308 --> Loss 0.0033246221145\n",
      "Epoch 23::Minibatch 488::LR 0.0492307692308 --> Loss 0.00203135530154\n",
      "Epoch 23::Minibatch 489::LR 0.0492307692308 --> Loss 0.00313462773959\n",
      "Epoch 23::Minibatch 490::LR 0.0492307692308 --> Loss 0.00040943702062\n",
      "Epoch 23::Minibatch 491::LR 0.0492307692308 --> Loss 0.00344924926758\n",
      "Epoch 23::Minibatch 492::LR 0.0492307692308 --> Loss 0.00305922488372\n",
      "Epoch 23::Minibatch 493::LR 0.0492307692308 --> Loss 0.00302704910437\n",
      "Epoch 23::Minibatch 494::LR 0.0492307692308 --> Loss 0.000734908183416\n",
      "Epoch 23::Minibatch 495::LR 0.0492307692308 --> Loss 0.0018547185262\n",
      "Epoch 23::Minibatch 496::LR 0.0492307692308 --> Loss 0.00282435198625\n",
      "Epoch 23::Minibatch 497::LR 0.0492307692308 --> Loss 0.000918269753456\n",
      "Epoch 23::Minibatch 498::LR 0.0492307692308 --> Loss 0.000554046034813\n",
      "Epoch 23::Minibatch 499::LR 0.0492307692308 --> Loss 0.00350699504217\n",
      "Epoch 23::Minibatch 500::LR 0.0492307692308 --> Loss 0.00143347730239\n",
      "Epoch 23::Minibatch 501::LR 0.0492307692308 --> Loss 0.00213169395924\n",
      "Epoch 23::Minibatch 502::LR 0.0492307692308 --> Loss 0.00377767682076\n",
      "Epoch 23::Minibatch 503::LR 0.0492307692308 --> Loss 0.00740541855494\n",
      "Epoch 23::Minibatch 504::LR 0.0492307692308 --> Loss 0.00718837976456\n",
      "Epoch 23::Minibatch 505::LR 0.0492307692308 --> Loss 0.00412261843681\n",
      "Epoch 23::Minibatch 506::LR 0.0492307692308 --> Loss 0.00338329195976\n",
      "Epoch 23::Minibatch 507::LR 0.0492307692308 --> Loss 0.00590460737546\n",
      "Epoch 23::Minibatch 508::LR 0.0492307692308 --> Loss 0.00340146541595\n",
      "Epoch 23::Minibatch 509::LR 0.0492307692308 --> Loss 0.00440582076708\n",
      "Epoch 23::Minibatch 510::LR 0.0492307692308 --> Loss 0.00447726090749\n",
      "Epoch 23::Minibatch 511::LR 0.0492307692308 --> Loss 0.00394912282626\n",
      "Epoch 23::Minibatch 512::LR 0.0492307692308 --> Loss 0.00268317262332\n",
      "Epoch 23::Minibatch 513::LR 0.0492307692308 --> Loss 0.000617998143037\n",
      "Epoch 23::Minibatch 514::LR 0.0492307692308 --> Loss 0.00264861762524\n",
      "Epoch 23::Minibatch 515::LR 0.0492307692308 --> Loss 0.00299992104371\n",
      "Epoch 23::Minibatch 516::LR 0.0492307692308 --> Loss 0.00399176160494\n",
      "Epoch 23::Minibatch 517::LR 0.0492307692308 --> Loss 0.00355716228485\n",
      "Epoch 23::Minibatch 518::LR 0.0492307692308 --> Loss 0.00257891257604\n",
      "Epoch 23::Minibatch 519::LR 0.0492307692308 --> Loss 0.00349229375521\n",
      "Epoch 23::Minibatch 520::LR 0.0492307692308 --> Loss 0.00543206214905\n",
      "Epoch 23::Minibatch 521::LR 0.0492307692308 --> Loss 0.00554097572962\n",
      "Epoch 23::Minibatch 522::LR 0.0492307692308 --> Loss 0.00763279994329\n",
      "Epoch 23::Minibatch 523::LR 0.0492307692308 --> Loss 0.000632336835066\n",
      "Epoch 23::Minibatch 524::LR 0.0492307692308 --> Loss 0.00140767335892\n",
      "Epoch 23::Minibatch 525::LR 0.0492307692308 --> Loss 0.00315179109573\n",
      "Epoch 23::Minibatch 526::LR 0.0492307692308 --> Loss 0.00386714617411\n",
      "Epoch 23::Minibatch 527::LR 0.0492307692308 --> Loss 0.00218496918678\n",
      "Epoch 23::Minibatch 528::LR 0.0492307692308 --> Loss 0.000982797642549\n",
      "Epoch 23::Minibatch 529::LR 0.0492307692308 --> Loss 0.00397358616193\n",
      "Epoch 23::Minibatch 530::LR 0.0492307692308 --> Loss 0.00400135914485\n",
      "Epoch 23::Minibatch 531::LR 0.0492307692308 --> Loss 0.0035492225488\n",
      "Epoch 23::Minibatch 532::LR 0.0492307692308 --> Loss 0.00266297360261\n",
      "Epoch 23::Minibatch 533::LR 0.0492307692308 --> Loss 0.00496983488401\n",
      "Epoch 23::Minibatch 534::LR 0.0492307692308 --> Loss 0.00375337600708\n",
      "Epoch 23::Minibatch 535::LR 0.0492307692308 --> Loss 0.0032810296615\n",
      "Epoch 23::Minibatch 536::LR 0.0492307692308 --> Loss 0.00210530678431\n",
      "Epoch 23::Minibatch 537::LR 0.0492307692308 --> Loss 0.000601175030073\n",
      "Epoch 23::Minibatch 538::LR 0.0492307692308 --> Loss 0.00166022747755\n",
      "Epoch 23::Minibatch 539::LR 0.0492307692308 --> Loss 0.00337242881457\n",
      "Epoch 23::Minibatch 540::LR 0.0492307692308 --> Loss 0.00340779145559\n",
      "Epoch 23::Minibatch 541::LR 0.0492307692308 --> Loss 0.00287495136261\n",
      "Epoch 23::Minibatch 542::LR 0.0492307692308 --> Loss 0.00248063703378\n",
      "Epoch 23::Minibatch 543::LR 0.0492307692308 --> Loss 0.00265854736169\n",
      "Epoch 23::Minibatch 544::LR 0.0492307692308 --> Loss 0.00393736481667\n",
      "Epoch 23::Minibatch 545::LR 0.0492307692308 --> Loss 0.00201228817304\n",
      "Epoch 23::Minibatch 546::LR 0.0492307692308 --> Loss 0.000653024415175\n",
      "Epoch 23::Minibatch 547::LR 0.0492307692308 --> Loss 0.00260079960028\n",
      "Epoch 23::Minibatch 548::LR 0.0492307692308 --> Loss 0.00354048252106\n",
      "Epoch 23::Minibatch 549::LR 0.0492307692308 --> Loss 0.00874280532201\n",
      "Epoch 23::Minibatch 550::LR 0.0492307692308 --> Loss 0.00117338766654\n",
      "Epoch 23::Minibatch 551::LR 0.0492307692308 --> Loss 0.00244998474916\n",
      "Epoch 23::Minibatch 552::LR 0.0492307692308 --> Loss 0.00348533391953\n",
      "Epoch 23::Minibatch 553::LR 0.0492307692308 --> Loss 0.00308809618155\n",
      "Epoch 23::Minibatch 554::LR 0.0492307692308 --> Loss 0.00369085828463\n",
      "Epoch 23::Minibatch 555::LR 0.0492307692308 --> Loss 0.000959200064341\n",
      "Epoch 23::Minibatch 556::LR 0.0492307692308 --> Loss 0.00195275783539\n",
      "Epoch 23::Minibatch 557::LR 0.0492307692308 --> Loss 0.0024203201135\n",
      "Epoch 23::Minibatch 558::LR 0.0492307692308 --> Loss 0.00366033792496\n",
      "Epoch 23::Minibatch 559::LR 0.0492307692308 --> Loss 0.00369060635567\n",
      "Epoch 23::Minibatch 560::LR 0.0492307692308 --> Loss 0.00307047565778\n",
      "Epoch 23::Minibatch 561::LR 0.0492307692308 --> Loss 0.00265824019909\n",
      "Epoch 23::Minibatch 562::LR 0.0492307692308 --> Loss 0.00235626995564\n",
      "Epoch 23::Minibatch 563::LR 0.0492307692308 --> Loss 0.00399702906609\n",
      "Epoch 23::Minibatch 564::LR 0.0492307692308 --> Loss 0.00307978332043\n",
      "Epoch 23::Minibatch 565::LR 0.0492307692308 --> Loss 0.00362591266632\n",
      "Epoch 23::Minibatch 566::LR 0.0492307692308 --> Loss 0.00222652415435\n",
      "Epoch 23::Minibatch 567::LR 0.0492307692308 --> Loss 0.00254258215427\n",
      "Epoch 23::Minibatch 568::LR 0.0492307692308 --> Loss 0.00177679677804\n",
      "Epoch 23::Minibatch 569::LR 0.0492307692308 --> Loss 0.000561544050773\n",
      "Epoch 23::Minibatch 570::LR 0.0492307692308 --> Loss 0.00166234642267\n",
      "Epoch 23::Minibatch 571::LR 0.0492307692308 --> Loss 0.00214488605658\n",
      "Epoch 23::Minibatch 572::LR 0.0492307692308 --> Loss 0.00229469319185\n",
      "Epoch 23::Minibatch 573::LR 0.0492307692308 --> Loss 0.00147343665361\n",
      "Epoch 23::Minibatch 574::LR 0.0492307692308 --> Loss 0.00104578981797\n",
      "Epoch 23::Minibatch 575::LR 0.0492307692308 --> Loss 0.00175088206927\n",
      "Epoch 23::Minibatch 576::LR 0.0492307692308 --> Loss 0.00207083622615\n",
      "Epoch 23::Minibatch 577::LR 0.0492307692308 --> Loss 0.00163376351198\n",
      "Epoch 23::Minibatch 578::LR 0.0492307692308 --> Loss 0.00127498368422\n",
      "Epoch 23::Minibatch 579::LR 0.0492307692308 --> Loss 0.00119091699521\n",
      "Epoch 23::Minibatch 580::LR 0.0492307692308 --> Loss 0.00192927757899\n",
      "Epoch 23::Minibatch 581::LR 0.0492307692308 --> Loss 0.00171049237251\n",
      "Epoch 23::Minibatch 582::LR 0.0492307692308 --> Loss 0.00415069937706\n",
      "Epoch 23::Minibatch 583::LR 0.0492307692308 --> Loss 0.000945530037085\n",
      "Epoch 23::Minibatch 584::LR 0.0492307692308 --> Loss 0.00130709409714\n",
      "Epoch 23::Minibatch 585::LR 0.0492307692308 --> Loss 0.00413576404254\n",
      "Epoch 23::Minibatch 586::LR 0.0492307692308 --> Loss 0.0038631550471\n",
      "Epoch 23::Minibatch 587::LR 0.0492307692308 --> Loss 0.00112041513125\n",
      "Epoch 23::Minibatch 588::LR 0.0492307692308 --> Loss 0.00139076322317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 589::LR 0.0492307692308 --> Loss 0.00275934278965\n",
      "Epoch 23::Minibatch 590::LR 0.0492307692308 --> Loss 0.00187535663446\n",
      "Epoch 23::Minibatch 591::LR 0.0492307692308 --> Loss 0.00287703692913\n",
      "Epoch 23::Minibatch 592::LR 0.0492307692308 --> Loss 0.00116601427396\n",
      "Epoch 23::Minibatch 593::LR 0.0492307692308 --> Loss 0.00253970742226\n",
      "Epoch 23::Minibatch 594::LR 0.0492307692308 --> Loss 0.00266597469648\n",
      "Epoch 23::Minibatch 595::LR 0.0492307692308 --> Loss 0.00304519116879\n",
      "Epoch 23::Minibatch 596::LR 0.0492307692308 --> Loss 0.00189444482327\n",
      "Epoch 23::Minibatch 597::LR 0.0492307692308 --> Loss 0.0011822805802\n",
      "Epoch 23::Minibatch 598::LR 0.0492307692308 --> Loss 0.00290961047014\n",
      "Epoch 23::Minibatch 599::LR 0.0492307692308 --> Loss 0.00182804942131\n",
      "Epoch 23::Minibatch 600::LR 0.0492307692308 --> Loss 0.00217807432016\n",
      "Epoch 23::Minibatch 601::LR 0.0492307692308 --> Loss 0.00381712158521\n",
      "Epoch 23::Minibatch 602::LR 0.0492307692308 --> Loss 0.0021025633812\n",
      "Epoch 23::Minibatch 603::LR 0.0492307692308 --> Loss 0.00263256847858\n",
      "Epoch 23::Minibatch 604::LR 0.0492307692308 --> Loss 0.00164611240228\n",
      "Epoch 23::Minibatch 605::LR 0.0492307692308 --> Loss 0.00233194271723\n",
      "Epoch 23::Minibatch 606::LR 0.0492307692308 --> Loss 0.00189477463563\n",
      "Epoch 23::Minibatch 607::LR 0.0492307692308 --> Loss 0.000836119353771\n",
      "Epoch 23::Minibatch 608::LR 0.0492307692308 --> Loss 0.00157154202461\n",
      "Epoch 23::Minibatch 609::LR 0.0492307692308 --> Loss 0.00240755339464\n",
      "Epoch 23::Minibatch 610::LR 0.0492307692308 --> Loss 0.00403211871783\n",
      "Epoch 23::Minibatch 611::LR 0.0492307692308 --> Loss 0.00263686736425\n",
      "Epoch 23::Minibatch 612::LR 0.0492307692308 --> Loss 0.000477322389682\n",
      "Epoch 23::Minibatch 613::LR 0.0492307692308 --> Loss 0.00131081928809\n",
      "Epoch 23::Minibatch 614::LR 0.0492307692308 --> Loss 0.00243170877298\n",
      "Epoch 23::Minibatch 615::LR 0.0492307692308 --> Loss 0.00167208373547\n",
      "Epoch 23::Minibatch 616::LR 0.0492307692308 --> Loss 0.000922401845455\n",
      "Epoch 23::Minibatch 617::LR 0.0492307692308 --> Loss 0.000496760308743\n",
      "Epoch 23::Minibatch 618::LR 0.0492307692308 --> Loss 0.00280503650506\n",
      "Epoch 23::Minibatch 619::LR 0.0492307692308 --> Loss 0.00192752043406\n",
      "Epoch 23::Minibatch 620::LR 0.0492307692308 --> Loss 0.0017062997818\n",
      "Epoch 23::Minibatch 621::LR 0.0492307692308 --> Loss 0.000849126776059\n",
      "Epoch 23::Minibatch 622::LR 0.0492307692308 --> Loss 0.000789697269599\n",
      "Epoch 23::Minibatch 623::LR 0.0492307692308 --> Loss 0.00222211758296\n",
      "Epoch 23::Minibatch 624::LR 0.0492307692308 --> Loss 0.00179093380769\n",
      "Epoch 23::Minibatch 625::LR 0.0492307692308 --> Loss 0.00280679583549\n",
      "Epoch 23::Minibatch 626::LR 0.0492307692308 --> Loss 0.00403049310048\n",
      "Epoch 23::Minibatch 627::LR 0.0492307692308 --> Loss 0.0012942464153\n",
      "Epoch 23::Minibatch 628::LR 0.0492307692308 --> Loss 0.000888048211734\n",
      "Epoch 23::Minibatch 629::LR 0.0492307692308 --> Loss 0.00325455923875\n",
      "Epoch 23::Minibatch 630::LR 0.0492307692308 --> Loss 0.00317749917507\n",
      "Epoch 23::Minibatch 631::LR 0.0492307692308 --> Loss 0.00578037699064\n",
      "Epoch 23::Minibatch 632::LR 0.0492307692308 --> Loss 0.000791290799777\n",
      "Epoch 23::Minibatch 633::LR 0.0492307692308 --> Loss 0.00163906365633\n",
      "Epoch 23::Minibatch 634::LR 0.0492307692308 --> Loss 0.00322202920914\n",
      "Epoch 23::Minibatch 635::LR 0.0492307692308 --> Loss 0.00546764969826\n",
      "Epoch 23::Minibatch 636::LR 0.0492307692308 --> Loss 0.00483790318171\n",
      "Epoch 23::Minibatch 637::LR 0.0492307692308 --> Loss 0.000746702104807\n",
      "Epoch 23::Minibatch 638::LR 0.0492307692308 --> Loss 0.00149508744478\n",
      "Epoch 23::Minibatch 639::LR 0.0492307692308 --> Loss 0.0032488600413\n",
      "Epoch 23::Minibatch 640::LR 0.0492307692308 --> Loss 0.0048113656044\n",
      "Epoch 23::Minibatch 641::LR 0.0492307692308 --> Loss 0.0030925488472\n",
      "Epoch 23::Minibatch 642::LR 0.0492307692308 --> Loss 0.00053704281648\n",
      "Epoch 23::Minibatch 643::LR 0.0492307692308 --> Loss 0.00232809921106\n",
      "Epoch 23::Minibatch 644::LR 0.0492307692308 --> Loss 0.00392880558968\n",
      "Epoch 23::Minibatch 645::LR 0.0492307692308 --> Loss 0.00429521242778\n",
      "Epoch 23::Minibatch 646::LR 0.0492307692308 --> Loss 0.00150368829568\n",
      "Epoch 23::Minibatch 647::LR 0.0492307692308 --> Loss 0.00049402654171\n",
      "Epoch 23::Minibatch 648::LR 0.0492307692308 --> Loss 0.00288180609544\n",
      "Epoch 23::Minibatch 649::LR 0.0492307692308 --> Loss 0.00340809265773\n",
      "Epoch 23::Minibatch 650::LR 0.0492307692308 --> Loss 0.00326066414515\n",
      "Epoch 23::Minibatch 651::LR 0.0492307692308 --> Loss 0.00135917852322\n",
      "Epoch 23::Minibatch 652::LR 0.0492307692308 --> Loss 0.000789282570283\n",
      "Epoch 23::Minibatch 653::LR 0.0492307692308 --> Loss 0.00283567388852\n",
      "Epoch 23::Minibatch 654::LR 0.0492307692308 --> Loss 0.00312469005585\n",
      "Epoch 23::Minibatch 655::LR 0.0492307692308 --> Loss 0.00354852318764\n",
      "Epoch 23::Minibatch 656::LR 0.0492307692308 --> Loss 0.000755415161451\n",
      "Epoch 23::Minibatch 657::LR 0.0492307692308 --> Loss 0.00225763817628\n",
      "Epoch 23::Minibatch 658::LR 0.0492307692308 --> Loss 0.00472379922867\n",
      "Epoch 23::Minibatch 659::LR 0.0492307692308 --> Loss 0.00227105796337\n",
      "Epoch 23::Minibatch 660::LR 0.0492307692308 --> Loss 0.00261566718419\n",
      "Epoch 23::Minibatch 661::LR 0.0492307692308 --> Loss 0.00239585280418\n",
      "Epoch 23::Minibatch 662::LR 0.0492307692308 --> Loss 0.00180467029413\n",
      "Epoch 23::Minibatch 663::LR 0.0492307692308 --> Loss 0.0036902252833\n",
      "Epoch 23::Minibatch 664::LR 0.0492307692308 --> Loss 0.00330806632837\n",
      "Epoch 23::Minibatch 665::LR 0.0492307692308 --> Loss 0.000712543477615\n",
      "Epoch 23::Minibatch 666::LR 0.0492307692308 --> Loss 0.00391163508097\n",
      "Epoch 23::Minibatch 667::LR 0.0492307692308 --> Loss 0.00254628360271\n",
      "Epoch 23::Minibatch 668::LR 0.0492307692308 --> Loss 0.00668521563212\n",
      "Epoch 23::Minibatch 669::LR 0.0492307692308 --> Loss 0.00109106957912\n",
      "Epoch 23::Minibatch 670::LR 0.0492307692308 --> Loss 0.001341586411\n",
      "Epoch 23::Minibatch 671::LR 0.0492307692308 --> Loss 0.00523676514626\n",
      "Epoch 23::Minibatch 672::LR 0.0492307692308 --> Loss 0.00357880075773\n",
      "Epoch 23::Minibatch 673::LR 0.0492307692308 --> Loss 0.0016168153286\n",
      "Epoch 23::Minibatch 674::LR 0.0492307692308 --> Loss 0.000511045654615\n",
      "Epoch 23::Minibatch 675::LR 0.0492307692308 --> Loss 0.00218716879686\n",
      "Epoch 23::Minibatch 676::LR 0.0492307692308 --> Loss 0.00213514288266\n",
      "Epoch 23::Minibatch 677::LR 0.0492307692308 --> Loss 0.00275702794393\n",
      "Epoch 23::Minibatch 678::LR 0.0492307692308 --> Loss 0.00190047899882\n",
      "Epoch 23::Minibatch 679::LR 0.0492307692308 --> Loss 0.0034151939551\n",
      "Epoch 23::Minibatch 680::LR 0.0492307692308 --> Loss 0.00213585356871\n",
      "Epoch 23::Minibatch 681::LR 0.0492307692308 --> Loss 0.00242029428482\n",
      "Epoch 23::Minibatch 682::LR 0.0492307692308 --> Loss 0.000760953426361\n",
      "Epoch 23::Minibatch 683::LR 0.0492307692308 --> Loss 0.00234830737114\n",
      "Epoch 23::Minibatch 684::LR 0.0492307692308 --> Loss 0.00234384636084\n",
      "Epoch 23::Minibatch 685::LR 0.0492307692308 --> Loss 0.00286809841792\n",
      "Epoch 23::Minibatch 686::LR 0.0492307692308 --> Loss 0.00156851897637\n",
      "Epoch 23::Minibatch 687::LR 0.0492307692308 --> Loss 0.000860847930113\n",
      "Epoch 23::Minibatch 688::LR 0.0492307692308 --> Loss 0.00277557353179\n",
      "Epoch 23::Minibatch 689::LR 0.0492307692308 --> Loss 0.00250535964966\n",
      "Epoch 23::Minibatch 690::LR 0.0492307692308 --> Loss 0.00190297722816\n",
      "Epoch 23::Minibatch 691::LR 0.0492307692308 --> Loss 0.000658276379108\n",
      "Epoch 23::Minibatch 692::LR 0.0492307692308 --> Loss 0.00245342036088\n",
      "Epoch 23::Minibatch 693::LR 0.0492307692308 --> Loss 0.00259083708127\n",
      "Epoch 23::Minibatch 694::LR 0.0492307692308 --> Loss 0.00301316042741\n",
      "Epoch 23::Minibatch 695::LR 0.0492307692308 --> Loss 0.00176576415698\n",
      "Epoch 23::Minibatch 696::LR 0.0492307692308 --> Loss 0.00204380194346\n",
      "Epoch 23::Minibatch 697::LR 0.0492307692308 --> Loss 0.00140379379193\n",
      "Epoch 23::Minibatch 698::LR 0.0492307692308 --> Loss 0.00164682984352\n",
      "Epoch 23::Minibatch 699::LR 0.0492307692308 --> Loss 0.00379444956779\n",
      "Epoch 23::Minibatch 700::LR 0.0492307692308 --> Loss 0.00263677179813\n",
      "Epoch 23::Minibatch 701::LR 0.0492307692308 --> Loss 0.00194295485814\n",
      "Epoch 23::Minibatch 702::LR 0.0492307692308 --> Loss 0.00166462351878\n",
      "Epoch 23::Minibatch 703::LR 0.0492307692308 --> Loss 0.00432987848918\n",
      "Epoch 23::Minibatch 704::LR 0.0492307692308 --> Loss 0.00180484513442\n",
      "Epoch 23::Minibatch 705::LR 0.0492307692308 --> Loss 0.00286195178827\n",
      "Epoch 23::Minibatch 706::LR 0.0492307692308 --> Loss 0.00223080833753\n",
      "Epoch 23::Minibatch 707::LR 0.0492307692308 --> Loss 0.00118084361156\n",
      "Epoch 23::Minibatch 708::LR 0.0492307692308 --> Loss 0.00173293371995\n",
      "Epoch 23::Minibatch 709::LR 0.0492307692308 --> Loss 0.00167846659819\n",
      "Epoch 23::Minibatch 710::LR 0.0492307692308 --> Loss 0.00255037864049\n",
      "Epoch 23::Minibatch 711::LR 0.0492307692308 --> Loss 0.00194521864255\n",
      "Epoch 23::Minibatch 712::LR 0.0492307692308 --> Loss 0.00134298553069\n",
      "Epoch 23::Minibatch 713::LR 0.0492307692308 --> Loss 0.0017758311828\n",
      "Epoch 23::Minibatch 714::LR 0.0492307692308 --> Loss 0.00280032853285\n",
      "Epoch 23::Minibatch 715::LR 0.0492307692308 --> Loss 0.002932989796\n",
      "Epoch 23::Minibatch 716::LR 0.0492307692308 --> Loss 0.00163513571024\n",
      "Epoch 23::Minibatch 717::LR 0.0492307692308 --> Loss 0.00163883437713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 718::LR 0.0492307692308 --> Loss 0.00126484721899\n",
      "Epoch 23::Minibatch 719::LR 0.0492307692308 --> Loss 0.0016920097669\n",
      "Epoch 23::Minibatch 720::LR 0.0492307692308 --> Loss 0.00262978831927\n",
      "Epoch 23::Minibatch 721::LR 0.0492307692308 --> Loss 0.000611726740996\n",
      "Epoch 23::Minibatch 722::LR 0.0492307692308 --> Loss 0.00470380822817\n",
      "Epoch 23::Minibatch 723::LR 0.0492307692308 --> Loss 0.00487728238106\n",
      "Epoch 23::Minibatch 724::LR 0.0492307692308 --> Loss 0.000965996881326\n",
      "Epoch 23::Minibatch 725::LR 0.0492307692308 --> Loss 0.00212380111217\n",
      "Epoch 23::Minibatch 726::LR 0.0492307692308 --> Loss 0.00417106588682\n",
      "Epoch 23::Minibatch 727::LR 0.0492307692308 --> Loss 0.00319862484932\n",
      "Epoch 23::Minibatch 728::LR 0.0492307692308 --> Loss 0.000642995635668\n",
      "Epoch 23::Minibatch 729::LR 0.0492307692308 --> Loss 0.000732530355453\n",
      "Epoch 23::Minibatch 730::LR 0.0492307692308 --> Loss 0.00287083288034\n",
      "Epoch 23::Minibatch 731::LR 0.0492307692308 --> Loss 0.00255326092243\n",
      "Epoch 23::Minibatch 732::LR 0.0492307692308 --> Loss 0.00214071214199\n",
      "Epoch 23::Minibatch 733::LR 0.0492307692308 --> Loss 0.000637095769246\n",
      "Epoch 23::Minibatch 734::LR 0.0492307692308 --> Loss 0.00169269541899\n",
      "Epoch 23::Minibatch 735::LR 0.0492307692308 --> Loss 0.002400624156\n",
      "Epoch 23::Minibatch 736::LR 0.0492307692308 --> Loss 0.00347323298454\n",
      "Epoch 23::Minibatch 737::LR 0.0492307692308 --> Loss 0.00301814258099\n",
      "Epoch 23::Minibatch 738::LR 0.0492307692308 --> Loss 0.00150170604388\n",
      "Epoch 23::Minibatch 739::LR 0.0492307692308 --> Loss 0.00243546624978\n",
      "Epoch 23::Minibatch 740::LR 0.0492307692308 --> Loss 0.00381526947021\n",
      "Epoch 23::Minibatch 741::LR 0.0492307692308 --> Loss 0.00260957876841\n",
      "Epoch 23::Minibatch 742::LR 0.0492307692308 --> Loss 0.00210163116455\n",
      "Epoch 23::Minibatch 743::LR 0.0492307692308 --> Loss 0.00144432197014\n",
      "Epoch 23::Minibatch 744::LR 0.0492307692308 --> Loss 0.00182533939679\n",
      "Epoch 23::Minibatch 745::LR 0.0492307692308 --> Loss 0.00280938029289\n",
      "Epoch 23::Minibatch 746::LR 0.0492307692308 --> Loss 0.00292335808277\n",
      "Epoch 23::Minibatch 747::LR 0.0492307692308 --> Loss 0.00178030312061\n",
      "Epoch 23::Minibatch 748::LR 0.0492307692308 --> Loss 0.000621236066024\n",
      "Epoch 23::Minibatch 749::LR 0.0492307692308 --> Loss 0.00165729482969\n",
      "Epoch 23::Minibatch 750::LR 0.0492307692308 --> Loss 0.00244407494863\n",
      "Epoch 23::Minibatch 751::LR 0.0492307692308 --> Loss 0.00281723419825\n",
      "Epoch 23::Minibatch 752::LR 0.0492307692308 --> Loss 0.00128997216622\n",
      "Epoch 23::Minibatch 753::LR 0.0492307692308 --> Loss 0.0022060662508\n",
      "Epoch 23::Minibatch 754::LR 0.0492307692308 --> Loss 0.00240607857704\n",
      "Epoch 23::Minibatch 755::LR 0.0492307692308 --> Loss 0.00266567468643\n",
      "Epoch 23::Minibatch 756::LR 0.0492307692308 --> Loss 0.00134648849567\n",
      "Epoch 23::Minibatch 757::LR 0.0492307692308 --> Loss 0.000691278676192\n",
      "Epoch 23::Minibatch 758::LR 0.0492307692308 --> Loss 0.00158751567205\n",
      "Epoch 23::Minibatch 759::LR 0.0492307692308 --> Loss 0.00361165364583\n",
      "Epoch 23::Minibatch 760::LR 0.0492307692308 --> Loss 0.0029041659832\n",
      "Epoch 23::Minibatch 761::LR 0.0492307692308 --> Loss 0.00601461251577\n",
      "Epoch 23::Minibatch 762::LR 0.0492307692308 --> Loss 0.00367933154106\n",
      "Epoch 23::Minibatch 763::LR 0.0492307692308 --> Loss 0.00350016037623\n",
      "Epoch 23::Minibatch 764::LR 0.0492307692308 --> Loss 0.00310833156109\n",
      "Epoch 23::Minibatch 765::LR 0.0492307692308 --> Loss 0.00128209551175\n",
      "Epoch 23::Minibatch 766::LR 0.0492307692308 --> Loss 0.00228865742683\n",
      "Epoch 23::Minibatch 767::LR 0.0492307692308 --> Loss 0.00490024407705\n",
      "Epoch 23::Minibatch 768::LR 0.0492307692308 --> Loss 0.00365152239799\n",
      "Epoch 23::Minibatch 769::LR 0.0492307692308 --> Loss 0.00186445792516\n",
      "Epoch 23::Minibatch 770::LR 0.0492307692308 --> Loss 0.0014826670289\n",
      "Epoch 23::Minibatch 771::LR 0.0492307692308 --> Loss 0.00356028914452\n",
      "Epoch 23::Minibatch 772::LR 0.0492307692308 --> Loss 0.0034948750337\n",
      "Epoch 23::Minibatch 773::LR 0.0492307692308 --> Loss 0.00315090159575\n",
      "Epoch 23::Minibatch 774::LR 0.0492307692308 --> Loss 0.00182787398497\n",
      "Epoch 23::Minibatch 775::LR 0.0492307692308 --> Loss 0.00355111638705\n",
      "Epoch 23::Minibatch 776::LR 0.0492307692308 --> Loss 0.0036379301548\n",
      "Epoch 23::Minibatch 777::LR 0.0492307692308 --> Loss 0.006804347833\n",
      "Epoch 23::Minibatch 778::LR 0.0492307692308 --> Loss 0.00841336647669\n",
      "Epoch 23::Minibatch 779::LR 0.0492307692308 --> Loss 0.00240379234155\n",
      "Epoch 23::Minibatch 780::LR 0.0492307692308 --> Loss 0.00155609607697\n",
      "Epoch 23::Minibatch 781::LR 0.0492307692308 --> Loss 0.00343978126844\n",
      "Epoch 23::Minibatch 782::LR 0.0492307692308 --> Loss 0.00385420004527\n",
      "Epoch 23::Minibatch 783::LR 0.0492307692308 --> Loss 0.00228256881237\n",
      "Epoch 23::Minibatch 784::LR 0.0492307692308 --> Loss 0.000708211511374\n",
      "Epoch 23::Minibatch 785::LR 0.0492307692308 --> Loss 0.00326417227586\n",
      "Epoch 23::Minibatch 786::LR 0.0492307692308 --> Loss 0.00341252009074\n",
      "Epoch 23::Minibatch 787::LR 0.0492307692308 --> Loss 0.0026196295023\n",
      "Epoch 23::Minibatch 788::LR 0.0492307692308 --> Loss 0.00235541860263\n",
      "Epoch 23::Minibatch 789::LR 0.0492307692308 --> Loss 0.00073013573885\n",
      "Epoch 23::Minibatch 790::LR 0.0492307692308 --> Loss 0.00313012778759\n",
      "Epoch 23::Minibatch 791::LR 0.0492307692308 --> Loss 0.00341243187586\n",
      "Epoch 23::Minibatch 792::LR 0.0492307692308 --> Loss 0.00302419523398\n",
      "Epoch 23::Minibatch 793::LR 0.0492307692308 --> Loss 0.00170093894005\n",
      "Epoch 23::Minibatch 794::LR 0.0492307692308 --> Loss 0.000997160375118\n",
      "Epoch 23::Minibatch 795::LR 0.0492307692308 --> Loss 0.00280878563722\n",
      "Epoch 23::Minibatch 796::LR 0.0492307692308 --> Loss 0.00523443539937\n",
      "Epoch 23::Minibatch 797::LR 0.0492307692308 --> Loss 0.00646758198738\n",
      "Epoch 23::Minibatch 798::LR 0.0492307692308 --> Loss 0.00314673344294\n",
      "Epoch 23::Minibatch 799::LR 0.0492307692308 --> Loss 0.00229172229767\n",
      "Epoch 23::Minibatch 800::LR 0.0492307692308 --> Loss 0.00200868169467\n",
      "Epoch 23::Minibatch 801::LR 0.0492307692308 --> Loss 0.00406856576602\n",
      "Epoch 23::Minibatch 802::LR 0.0492307692308 --> Loss 0.00125497271617\n",
      "Epoch 23::Minibatch 803::LR 0.0492307692308 --> Loss 0.00290226082007\n",
      "Epoch 23::Minibatch 804::LR 0.0492307692308 --> Loss 0.00212114393711\n",
      "Epoch 23::Minibatch 805::LR 0.0492307692308 --> Loss 0.00222170313199\n",
      "Epoch 23::Minibatch 806::LR 0.0492307692308 --> Loss 0.00338361223539\n",
      "Epoch 23::Minibatch 807::LR 0.0492307692308 --> Loss 0.00304926753044\n",
      "Epoch 23::Minibatch 808::LR 0.0492307692308 --> Loss 0.0027073208491\n",
      "Epoch 23::Minibatch 809::LR 0.0492307692308 --> Loss 0.0033811489741\n",
      "Epoch 23::Minibatch 810::LR 0.0492307692308 --> Loss 0.00464249253273\n",
      "Epoch 23::Minibatch 811::LR 0.0492307692308 --> Loss 0.0044093132019\n",
      "Epoch 23::Minibatch 812::LR 0.0492307692308 --> Loss 0.00403751254082\n",
      "Epoch 23::Minibatch 813::LR 0.0492307692308 --> Loss 0.00349524259567\n",
      "Epoch 23::Minibatch 814::LR 0.0492307692308 --> Loss 0.0016130288442\n",
      "Epoch 23::Minibatch 815::LR 0.0492307692308 --> Loss 0.00363520701726\n",
      "Epoch 23::Minibatch 816::LR 0.0492307692308 --> Loss 0.0040541557471\n",
      "Epoch 23::Minibatch 817::LR 0.0492307692308 --> Loss 0.00534699956576\n",
      "Epoch 23::Minibatch 818::LR 0.0492307692308 --> Loss 0.00125251998504\n",
      "Epoch 23::Minibatch 819::LR 0.0492307692308 --> Loss 0.000706376433372\n",
      "Epoch 23::Minibatch 820::LR 0.0492307692308 --> Loss 0.00521697004636\n",
      "Epoch 23::Minibatch 821::LR 0.0492307692308 --> Loss 0.00308804452419\n",
      "Epoch 23::Minibatch 822::LR 0.0492307692308 --> Loss 0.00367016633352\n",
      "Epoch 23::Minibatch 823::LR 0.0492307692308 --> Loss 0.00127826382716\n",
      "Epoch 23::Minibatch 824::LR 0.0492307692308 --> Loss 0.00136509299278\n",
      "Epoch 23::Minibatch 825::LR 0.0492307692308 --> Loss 0.00365825374921\n",
      "Epoch 23::Minibatch 826::LR 0.0492307692308 --> Loss 0.0040888885657\n",
      "Epoch 23::Minibatch 827::LR 0.0492307692308 --> Loss 0.00206325968107\n",
      "Epoch 23::Minibatch 828::LR 0.0492307692308 --> Loss 0.000501833756765\n",
      "Epoch 23::Minibatch 829::LR 0.0492307692308 --> Loss 0.00231281618277\n",
      "Epoch 23::Minibatch 830::LR 0.0492307692308 --> Loss 0.004197961092\n",
      "Epoch 23::Minibatch 831::LR 0.0492307692308 --> Loss 0.0024850432078\n",
      "Epoch 23::Minibatch 832::LR 0.0492307692308 --> Loss 0.00217883010705\n",
      "Epoch 23::Minibatch 833::LR 0.0492307692308 --> Loss 0.0018314598004\n",
      "Epoch 23::Minibatch 834::LR 0.0492307692308 --> Loss 0.000776857733727\n",
      "Epoch 23::Minibatch 835::LR 0.0492307692308 --> Loss 0.00376073559125\n",
      "Epoch 23::Minibatch 836::LR 0.0492307692308 --> Loss 0.00363172252973\n",
      "Epoch 23::Minibatch 837::LR 0.0492307692308 --> Loss 0.0021964520216\n",
      "Epoch 23::Minibatch 838::LR 0.0492307692308 --> Loss 0.000632688750823\n",
      "Epoch 23::Minibatch 839::LR 0.0492307692308 --> Loss 0.00243403832118\n",
      "Epoch 23::Minibatch 840::LR 0.0492307692308 --> Loss 0.00286269783974\n",
      "Epoch 23::Minibatch 841::LR 0.0492307692308 --> Loss 0.00278110524019\n",
      "Epoch 23::Minibatch 842::LR 0.0492307692308 --> Loss 0.00207486669223\n",
      "Epoch 23::Minibatch 843::LR 0.0492307692308 --> Loss 0.000991817414761\n",
      "Epoch 23::Minibatch 844::LR 0.0492307692308 --> Loss 0.0014767691493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 845::LR 0.0492307692308 --> Loss 0.00418360789617\n",
      "Epoch 23::Minibatch 846::LR 0.0492307692308 --> Loss 0.00166682263215\n",
      "Epoch 23::Minibatch 847::LR 0.0492307692308 --> Loss 0.00229582488537\n",
      "Epoch 23::Minibatch 848::LR 0.0492307692308 --> Loss 0.00104168266058\n",
      "Epoch 23::Minibatch 849::LR 0.0492307692308 --> Loss 0.00180397987366\n",
      "Epoch 23::Minibatch 850::LR 0.0492307692308 --> Loss 0.00315301120281\n",
      "Epoch 23::Minibatch 851::LR 0.0492307692308 --> Loss 0.00259120007356\n",
      "Epoch 23::Minibatch 852::LR 0.0492307692308 --> Loss 0.00109153191249\n",
      "Epoch 23::Minibatch 853::LR 0.0492307692308 --> Loss 0.00130069365104\n",
      "Epoch 23::Minibatch 854::LR 0.0492307692308 --> Loss 0.00255234003067\n",
      "Epoch 23::Minibatch 855::LR 0.0492307692308 --> Loss 0.00214068631331\n",
      "Epoch 23::Minibatch 856::LR 0.0492307692308 --> Loss 0.00178764164448\n",
      "Epoch 23::Minibatch 857::LR 0.0492307692308 --> Loss 0.00120933175087\n",
      "Epoch 23::Minibatch 858::LR 0.0492307692308 --> Loss 0.000593501975139\n",
      "Epoch 23::Minibatch 859::LR 0.0492307692308 --> Loss 0.0019283358256\n",
      "Epoch 23::Minibatch 860::LR 0.0492307692308 --> Loss 0.00126768896977\n",
      "Epoch 23::Minibatch 861::LR 0.0492307692308 --> Loss 0.000937160154184\n",
      "Epoch 23::Minibatch 862::LR 0.0492307692308 --> Loss 0.00366069316864\n",
      "Epoch 23::Minibatch 863::LR 0.0492307692308 --> Loss 0.00338409821192\n",
      "Epoch 23::Minibatch 864::LR 0.0492307692308 --> Loss 0.0027383706967\n",
      "Epoch 23::Minibatch 865::LR 0.0492307692308 --> Loss 0.000452738304933\n",
      "Epoch 23::Minibatch 866::LR 0.0492307692308 --> Loss 0.00210909982522\n",
      "Epoch 23::Minibatch 867::LR 0.0492307692308 --> Loss 0.00291592021783\n",
      "Epoch 23::Minibatch 868::LR 0.0492307692308 --> Loss 0.00240750630697\n",
      "Epoch 23::Minibatch 869::LR 0.0492307692308 --> Loss 0.00211457868417\n",
      "Epoch 23::Minibatch 870::LR 0.0492307692308 --> Loss 0.00341799696287\n",
      "Epoch 23::Minibatch 871::LR 0.0492307692308 --> Loss 0.00155758341153\n",
      "Epoch 23::Minibatch 872::LR 0.0492307692308 --> Loss 0.00220786770185\n",
      "Epoch 23::Minibatch 873::LR 0.0492307692308 --> Loss 0.00245923260848\n",
      "Epoch 23::Minibatch 874::LR 0.0492307692308 --> Loss 0.00576822241147\n",
      "Epoch 23::Minibatch 875::LR 0.0492307692308 --> Loss 0.00054946616292\n",
      "Epoch 23::Minibatch 876::LR 0.0492307692308 --> Loss 0.00296776076158\n",
      "Epoch 23::Minibatch 877::LR 0.0492307692308 --> Loss 0.00531287630399\n",
      "Epoch 23::Minibatch 878::LR 0.0492307692308 --> Loss 0.00312130530675\n",
      "Epoch 23::Minibatch 879::LR 0.0492307692308 --> Loss 0.003967405955\n",
      "Epoch 23::Minibatch 880::LR 0.0492307692308 --> Loss 0.00482516328494\n",
      "Epoch 23::Minibatch 881::LR 0.0492307692308 --> Loss 0.00426384528478\n",
      "Epoch 23::Minibatch 882::LR 0.0492307692308 --> Loss 0.00194430450598\n",
      "Epoch 23::Minibatch 883::LR 0.0492307692308 --> Loss 0.00348794301351\n",
      "Epoch 23::Minibatch 884::LR 0.0492307692308 --> Loss 0.00273548662663\n",
      "Epoch 23::Minibatch 885::LR 0.0492307692308 --> Loss 0.00255617598693\n",
      "Epoch 23::Minibatch 886::LR 0.0492307692308 --> Loss 0.000461096962293\n",
      "Epoch 23::Minibatch 887::LR 0.0492307692308 --> Loss 0.0052882707119\n",
      "Epoch 23::Minibatch 888::LR 0.0492307692308 --> Loss 0.00254375020663\n",
      "Epoch 23::Minibatch 889::LR 0.0492307692308 --> Loss 0.00266857683659\n",
      "Epoch 23::Minibatch 890::LR 0.0492307692308 --> Loss 0.00391623020172\n",
      "Epoch 23::Minibatch 891::LR 0.0492307692308 --> Loss 0.00178836524487\n",
      "Epoch 23::Minibatch 892::LR 0.0492307692308 --> Loss 0.000825867901246\n",
      "Epoch 23::Minibatch 893::LR 0.0492307692308 --> Loss 0.00235786557198\n",
      "Epoch 23::Minibatch 894::LR 0.0492307692308 --> Loss 0.00208009580771\n",
      "Epoch 23::Minibatch 895::LR 0.0492307692308 --> Loss 0.00234015564124\n",
      "Epoch 23::Minibatch 896::LR 0.0492307692308 --> Loss 0.00124311973651\n",
      "Epoch 23::Minibatch 897::LR 0.0492307692308 --> Loss 0.000690485388041\n",
      "Epoch 23::Minibatch 898::LR 0.0492307692308 --> Loss 0.00206879059474\n",
      "Epoch 23::Minibatch 899::LR 0.0492307692308 --> Loss 0.00246569911639\n",
      "Epoch 23::Minibatch 900::LR 0.0492307692308 --> Loss 0.0031563770771\n",
      "Epoch 23::Minibatch 901::LR 0.0492307692308 --> Loss 0.000585852166017\n",
      "Epoch 23::Minibatch 902::LR 0.0492307692308 --> Loss 0.00140555093686\n",
      "Epoch 23::Minibatch 903::LR 0.0492307692308 --> Loss 0.00253509581089\n",
      "Epoch 23::Minibatch 904::LR 0.0492307692308 --> Loss 0.00185719251633\n",
      "Epoch 23::Minibatch 905::LR 0.0492307692308 --> Loss 0.00141733994087\n",
      "Epoch 23::Minibatch 906::LR 0.0492307692308 --> Loss 0.00105264176925\n",
      "Epoch 23::Minibatch 907::LR 0.0492307692308 --> Loss 0.00156938095888\n",
      "Epoch 23::Minibatch 908::LR 0.0492307692308 --> Loss 0.00212100565434\n",
      "Epoch 23::Minibatch 909::LR 0.0492307692308 --> Loss 0.00195981502533\n",
      "Epoch 23::Minibatch 910::LR 0.0492307692308 --> Loss 0.00083531409502\n",
      "Epoch 23::Minibatch 911::LR 0.0492307692308 --> Loss 0.00124591946602\n",
      "Epoch 23::Minibatch 912::LR 0.0492307692308 --> Loss 0.00200363238653\n",
      "Epoch 23::Minibatch 913::LR 0.0492307692308 --> Loss 0.00219153265158\n",
      "Epoch 23::Minibatch 914::LR 0.0492307692308 --> Loss 0.00118559052547\n",
      "Epoch 23::Minibatch 915::LR 0.0492307692308 --> Loss 0.000501641432444\n",
      "Epoch 23::Minibatch 916::LR 0.0492307692308 --> Loss 0.00216691315174\n",
      "Epoch 23::Minibatch 917::LR 0.0492307692308 --> Loss 0.00354704538981\n",
      "Epoch 23::Minibatch 918::LR 0.0492307692308 --> Loss 0.00552076617877\n",
      "Epoch 23::Minibatch 919::LR 0.0492307692308 --> Loss 0.000543317496777\n",
      "Epoch 23::Minibatch 920::LR 0.0492307692308 --> Loss 0.0123064144452\n",
      "Epoch 23::Minibatch 921::LR 0.0492307692308 --> Loss 0.00283159792423\n",
      "Epoch 23::Minibatch 922::LR 0.0492307692308 --> Loss 0.00294291079044\n",
      "Epoch 23::Minibatch 923::LR 0.0492307692308 --> Loss 0.00134912500779\n",
      "Epoch 23::Minibatch 924::LR 0.0492307692308 --> Loss 0.00333932757378\n",
      "Epoch 23::Minibatch 925::LR 0.0492307692308 --> Loss 0.00224783480167\n",
      "Epoch 23::Minibatch 926::LR 0.0492307692308 --> Loss 0.00504784782728\n",
      "Epoch 23::Minibatch 927::LR 0.0492307692308 --> Loss 0.00655627409617\n",
      "Epoch 23::Minibatch 928::LR 0.0492307692308 --> Loss 0.00619007786115\n",
      "Epoch 23::Minibatch 929::LR 0.0492307692308 --> Loss 0.00605560342471\n",
      "Epoch 23::Minibatch 930::LR 0.0492307692308 --> Loss 0.00895218213399\n",
      "Epoch 23::Minibatch 931::LR 0.0492307692308 --> Loss 0.00324582278728\n",
      "Epoch 23::Minibatch 932::LR 0.0492307692308 --> Loss 0.00607650876045\n",
      "Epoch 23::Minibatch 933::LR 0.0492307692308 --> Loss 0.00292844732602\n",
      "Epoch 23::Minibatch 934::LR 0.0492307692308 --> Loss 0.00384906490644\n",
      "Epoch 23::Minibatch 935::LR 0.0492307692308 --> Loss 0.00553473035494\n",
      "Epoch 23::Minibatch 936::LR 0.0492307692308 --> Loss 0.0012163606286\n",
      "Epoch 23::Minibatch 937::LR 0.0492307692308 --> Loss 0.00287822028001\n",
      "Epoch 23::Minibatch 938::LR 0.0492307692308 --> Loss 0.00253991087278\n",
      "Epoch 23::Minibatch 939::LR 0.0492307692308 --> Loss 0.00265242238839\n",
      "Epoch 23::Minibatch 940::LR 0.0492307692308 --> Loss 0.000975635846456\n",
      "Epoch 23::Minibatch 941::LR 0.0492307692308 --> Loss 0.000802225073179\n",
      "Epoch 23::Minibatch 942::LR 0.0492307692308 --> Loss 0.00245834271113\n",
      "Epoch 23::Minibatch 943::LR 0.0492307692308 --> Loss 0.00260947108269\n",
      "Epoch 23::Minibatch 944::LR 0.0492307692308 --> Loss 0.00188557386398\n",
      "Epoch 23::Minibatch 945::LR 0.0492307692308 --> Loss 0.00108585486809\n",
      "Epoch 23::Minibatch 946::LR 0.0492307692308 --> Loss 0.00276398877303\n",
      "Epoch 23::Minibatch 947::LR 0.0492307692308 --> Loss 0.00249606609344\n",
      "Epoch 23::Minibatch 948::LR 0.0492307692308 --> Loss 0.00465841809909\n",
      "Epoch 23::Minibatch 949::LR 0.0492307692308 --> Loss 0.00179736018181\n",
      "Epoch 23::Minibatch 950::LR 0.0492307692308 --> Loss 0.000725889702638\n",
      "Epoch 23::Minibatch 951::LR 0.0492307692308 --> Loss 0.00338098963102\n",
      "Epoch 23::Minibatch 952::LR 0.0492307692308 --> Loss 0.00237869302432\n",
      "Epoch 23::Minibatch 953::LR 0.0492307692308 --> Loss 0.00139703820149\n",
      "Epoch 23::Minibatch 954::LR 0.0492307692308 --> Loss 0.000955983599027\n",
      "Epoch 23::Minibatch 955::LR 0.0492307692308 --> Loss 0.00253093341986\n",
      "Epoch 23::Minibatch 956::LR 0.0492307692308 --> Loss 0.00342374404271\n",
      "Epoch 23::Minibatch 957::LR 0.0492307692308 --> Loss 0.00184146285057\n",
      "Epoch 23::Minibatch 958::LR 0.0492307692308 --> Loss 0.00221107423306\n",
      "Epoch 23::Minibatch 959::LR 0.0492307692308 --> Loss 0.00268336474895\n",
      "Epoch 23::Minibatch 960::LR 0.0492307692308 --> Loss 0.0058721669515\n",
      "Epoch 23::Minibatch 961::LR 0.0492307692308 --> Loss 0.0031711880366\n",
      "Epoch 23::Minibatch 962::LR 0.0492307692308 --> Loss 0.00265924553076\n",
      "Epoch 23::Minibatch 963::LR 0.0492307692308 --> Loss 0.00103788296382\n",
      "Epoch 23::Minibatch 964::LR 0.0492307692308 --> Loss 0.00235270361106\n",
      "Epoch 23::Minibatch 965::LR 0.0492307692308 --> Loss 0.00691704670588\n",
      "Epoch 23::Minibatch 966::LR 0.0492307692308 --> Loss 0.00501923004786\n",
      "Epoch 23::Minibatch 967::LR 0.0492307692308 --> Loss 0.00139576435089\n",
      "Epoch 23::Minibatch 968::LR 0.0492307692308 --> Loss 0.00122147430976\n",
      "Epoch 23::Minibatch 969::LR 0.0492307692308 --> Loss 0.0055880455176\n",
      "Epoch 23::Minibatch 970::LR 0.0492307692308 --> Loss 0.005231594642\n",
      "Epoch 23::Minibatch 971::LR 0.0492307692308 --> Loss 0.00341972827911\n",
      "Epoch 23::Minibatch 972::LR 0.0492307692308 --> Loss 0.00945918401082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23::Minibatch 973::LR 0.0492307692308 --> Loss 0.00900979280472\n",
      "Epoch 23::Minibatch 974::LR 0.0492307692308 --> Loss 0.00827597618103\n",
      "Epoch 23::Minibatch 975::LR 0.0492307692308 --> Loss 0.00446461439133\n",
      "Epoch 23::Minibatch 976::LR 0.0492307692308 --> Loss 0.00396214445432\n",
      "Epoch 23::Minibatch 977::LR 0.0492307692308 --> Loss 0.00388813614845\n",
      "Epoch 23::Minibatch 978::LR 0.0492307692308 --> Loss 0.003872098128\n",
      "Epoch 23::Minibatch 979::LR 0.0492307692308 --> Loss 0.00375556906064\n",
      "Epoch 23::Minibatch 980::LR 0.0492307692308 --> Loss 0.00386749943097\n",
      "Epoch 23::Minibatch 981::LR 0.0492307692308 --> Loss 0.00500674446424\n",
      "Epoch 23::Minibatch 982::LR 0.0492307692308 --> Loss 0.00586074153582\n",
      "Epoch 23::Minibatch 983::LR 0.0492307692308 --> Loss 0.0028966375192\n",
      "Epoch 23::Minibatch 984::LR 0.0492307692308 --> Loss 0.00232367734114\n",
      "Epoch 23::Minibatch 985::LR 0.0492307692308 --> Loss 0.00407887935638\n",
      "Epoch 23::Minibatch 986::LR 0.0492307692308 --> Loss 0.00375314394633\n",
      "Epoch 23::Minibatch 987::LR 0.0492307692308 --> Loss 0.00403049508731\n",
      "Epoch 23::Minibatch 988::LR 0.0492307692308 --> Loss 0.00321553309759\n",
      "Epoch 23::Minibatch 989::LR 0.0492307692308 --> Loss 0.00339370449384\n",
      "Epoch 23::Minibatch 990::LR 0.0492307692308 --> Loss 0.00308004061381\n",
      "Epoch 23::Minibatch 991::LR 0.0492307692308 --> Loss 0.00168815056483\n",
      "Epoch 23::Minibatch 992::LR 0.0492307692308 --> Loss 0.00185577253501\n",
      "Epoch 23::Minibatch 993::LR 0.0492307692308 --> Loss 0.00336870749791\n",
      "Epoch 23::Minibatch 994::LR 0.0492307692308 --> Loss 0.00214354813099\n",
      "Epoch 23::Minibatch 995::LR 0.0492307692308 --> Loss 0.000879382590453\n",
      "Epoch 23::Minibatch 996::LR 0.0492307692308 --> Loss 0.00295575340589\n",
      "Epoch 23::Minibatch 997::LR 0.0492307692308 --> Loss 0.00228105843067\n",
      "Epoch 23::Minibatch 998::LR 0.0492307692308 --> Loss 0.00256950179736\n",
      "Epoch 23::Minibatch 999::LR 0.0492307692308 --> Loss 0.00215027650197\n",
      "Epoch 23::Minibatch 1000::LR 0.0492307692308 --> Loss 0.00254044592381\n",
      "Epoch 23::Minibatch 1001::LR 0.0492307692308 --> Loss 0.00204846382141\n",
      "Epoch 23::Minibatch 1002::LR 0.0492307692308 --> Loss 0.00197745680809\n",
      "Epoch 23::Minibatch 1003::LR 0.0492307692308 --> Loss 0.0030539282163\n",
      "Epoch 23::Minibatch 1004::LR 0.0492307692308 --> Loss 0.00109392484029\n",
      "Epoch 23::Minibatch 1005::LR 0.0492307692308 --> Loss 0.00306694845359\n",
      "Epoch 23::Minibatch 1006::LR 0.0492307692308 --> Loss 0.00168391207854\n",
      "Epoch 23::Minibatch 1007::LR 0.0492307692308 --> Loss 0.00213829576969\n",
      "Epoch 23::Minibatch 1008::LR 0.0492307692308 --> Loss 0.000969905952613\n",
      "Epoch 23::Minibatch 1009::LR 0.0492307692308 --> Loss 0.00134939273198\n",
      "Epoch 23::Minibatch 1010::LR 0.0492307692308 --> Loss 0.00120823214451\n",
      "Epoch 23::Minibatch 1011::LR 0.0492307692308 --> Loss 0.00213512063026\n",
      "Epoch 23::Minibatch 1012::LR 0.0492307692308 --> Loss 0.00150685439507\n",
      "Epoch 23::Minibatch 1013::LR 0.0492307692308 --> Loss 0.00394106944402\n",
      "Epoch 23::Minibatch 1014::LR 0.0492307692308 --> Loss 0.00371193289757\n",
      "Epoch 23::Minibatch 1015::LR 0.0492307692308 --> Loss 0.00162704487642\n",
      "Epoch 23::Minibatch 1016::LR 0.0492307692308 --> Loss 0.00475258270899\n",
      "Epoch 23::Minibatch 1017::LR 0.0492307692308 --> Loss 0.00288439353307\n",
      "Epoch 23::Minibatch 1018::LR 0.0492307692308 --> Loss 0.00273794213931\n",
      "Epoch 23::Minibatch 1019::LR 0.0492307692308 --> Loss 0.00180156886578\n",
      "Epoch 23::Minibatch 1020::LR 0.0492307692308 --> Loss 0.0018602458636\n",
      "Epoch 23::Minibatch 1021::LR 0.0492307692308 --> Loss 0.00192980209986\n",
      "Epoch 23::Minibatch 1022::LR 0.0492307692308 --> Loss 0.00144596209129\n",
      "Epoch 23::Minibatch 1023::LR 0.0492307692308 --> Loss 0.00109829038382\n",
      "Epoch 23::Minibatch 1024::LR 0.0492307692308 --> Loss 0.00108339766661\n",
      "Epoch 23::Minibatch 1025::LR 0.0492307692308 --> Loss 0.00139102697372\n",
      "Epoch 23::Minibatch 1026::LR 0.0492307692308 --> Loss 0.000763310492039\n",
      "Epoch 23::Minibatch 1027::LR 0.0492307692308 --> Loss 0.00100618084272\n",
      "Epoch 23::Minibatch 1028::LR 0.0492307692308 --> Loss 0.000769077887138\n",
      "Epoch 23::Minibatch 1029::LR 0.0492307692308 --> Loss 0.000759701530139\n",
      "Epoch 23::Minibatch 1030::LR 0.0492307692308 --> Loss 0.000937069753806\n",
      "Epoch 23::Minibatch 1031::LR 0.0492307692308 --> Loss 0.000726755658786\n",
      "Epoch 23::Minibatch 1032::LR 0.0492307692308 --> Loss 0.000779211918513\n",
      "Epoch 23::Minibatch 1033::LR 0.0492307692308 --> Loss 0.000662238697211\n",
      "Epoch 23::Minibatch 1034::LR 0.0492307692308 --> Loss 0.000634651233753\n",
      "Epoch 23::Minibatch 1035::LR 0.0492307692308 --> Loss 0.000430461913347\n",
      "Epoch 23::Minibatch 1036::LR 0.0492307692308 --> Loss 0.000345657467842\n",
      "Epoch 23::Minibatch 1037::LR 0.0492307692308 --> Loss 0.000586829731862\n",
      "Epoch 23::Minibatch 1038::LR 0.0492307692308 --> Loss 0.00121323019266\n",
      "Epoch 23::Minibatch 1039::LR 0.0492307692308 --> Loss 0.000930461684863\n",
      "Epoch 23::Minibatch 1040::LR 0.0492307692308 --> Loss 0.00037641428411\n",
      "Epoch 23::Minibatch 1041::LR 0.0492307692308 --> Loss 0.000541244447231\n",
      "Epoch 24::Minibatch 1::LR 0.0469230769231 --> Loss 0.00851693471273\n",
      "Epoch 24::Minibatch 2::LR 0.0469230769231 --> Loss 0.0054722348849\n",
      "Epoch 24::Minibatch 3::LR 0.0469230769231 --> Loss 0.00351299246152\n",
      "Epoch 24::Minibatch 4::LR 0.0469230769231 --> Loss 0.00409819841385\n",
      "Epoch 24::Minibatch 5::LR 0.0469230769231 --> Loss 0.00457292675972\n",
      "Epoch 24::Minibatch 6::LR 0.0469230769231 --> Loss 0.00224298218886\n",
      "Epoch 24::Minibatch 7::LR 0.0469230769231 --> Loss 0.00750682195028\n",
      "Epoch 24::Minibatch 8::LR 0.0469230769231 --> Loss 0.00708211978277\n",
      "Epoch 24::Minibatch 9::LR 0.0469230769231 --> Loss 0.00534211198489\n",
      "Epoch 24::Minibatch 10::LR 0.0469230769231 --> Loss 0.00259357710679\n",
      "Epoch 24::Minibatch 11::LR 0.0469230769231 --> Loss 0.00234336217244\n",
      "Epoch 24::Minibatch 12::LR 0.0469230769231 --> Loss 0.00346682667732\n",
      "Epoch 24::Minibatch 13::LR 0.0469230769231 --> Loss 0.00533921202024\n",
      "Epoch 24::Minibatch 14::LR 0.0469230769231 --> Loss 0.00530029892921\n",
      "Epoch 24::Minibatch 15::LR 0.0469230769231 --> Loss 0.00450690587362\n",
      "Epoch 24::Minibatch 16::LR 0.0469230769231 --> Loss 0.000791476964951\n",
      "Epoch 24::Minibatch 17::LR 0.0469230769231 --> Loss 0.00315387666225\n",
      "Epoch 24::Minibatch 18::LR 0.0469230769231 --> Loss 0.00257575949033\n",
      "Epoch 24::Minibatch 19::LR 0.0469230769231 --> Loss 0.00142974893252\n",
      "Epoch 24::Minibatch 20::LR 0.0469230769231 --> Loss 0.00193782130877\n",
      "Epoch 24::Minibatch 21::LR 0.0469230769231 --> Loss 0.00331160406272\n",
      "Epoch 24::Minibatch 22::LR 0.0469230769231 --> Loss 0.0022447981437\n",
      "Epoch 24::Minibatch 23::LR 0.0469230769231 --> Loss 0.000833558340867\n",
      "Epoch 24::Minibatch 24::LR 0.0469230769231 --> Loss 0.000423192977905\n",
      "Epoch 24::Minibatch 25::LR 0.0469230769231 --> Loss 0.00120414823294\n",
      "Epoch 24::Minibatch 26::LR 0.0469230769231 --> Loss 0.00140591929356\n",
      "Epoch 24::Minibatch 27::LR 0.0469230769231 --> Loss 0.00100584596395\n",
      "Epoch 24::Minibatch 28::LR 0.0469230769231 --> Loss 0.000432298928499\n",
      "Epoch 24::Minibatch 29::LR 0.0469230769231 --> Loss 0.000467795630296\n",
      "Epoch 24::Minibatch 30::LR 0.0469230769231 --> Loss 0.0009441614151\n",
      "Epoch 24::Minibatch 31::LR 0.0469230769231 --> Loss 0.00143489688635\n",
      "Epoch 24::Minibatch 32::LR 0.0469230769231 --> Loss 0.0013105498751\n",
      "Epoch 24::Minibatch 33::LR 0.0469230769231 --> Loss 0.000782313495874\n",
      "Epoch 24::Minibatch 34::LR 0.0469230769231 --> Loss 0.00217175920804\n",
      "Epoch 24::Minibatch 35::LR 0.0469230769231 --> Loss 0.00347474376361\n",
      "Epoch 24::Minibatch 36::LR 0.0469230769231 --> Loss 0.00223857363065\n",
      "Epoch 24::Minibatch 37::LR 0.0469230769231 --> Loss 0.000657842556636\n",
      "Epoch 24::Minibatch 38::LR 0.0469230769231 --> Loss 0.000715097337961\n",
      "Epoch 24::Minibatch 39::LR 0.0469230769231 --> Loss 0.0022692044576\n",
      "Epoch 24::Minibatch 40::LR 0.0469230769231 --> Loss 0.00319942931334\n",
      "Epoch 24::Minibatch 41::LR 0.0469230769231 --> Loss 0.00259301205476\n",
      "Epoch 24::Minibatch 42::LR 0.0469230769231 --> Loss 0.00536383072535\n",
      "Epoch 24::Minibatch 43::LR 0.0469230769231 --> Loss 0.00191473166148\n",
      "Epoch 24::Minibatch 44::LR 0.0469230769231 --> Loss 0.00313279529413\n",
      "Epoch 24::Minibatch 45::LR 0.0469230769231 --> Loss 0.00240059256554\n",
      "Epoch 24::Minibatch 46::LR 0.0469230769231 --> Loss 0.00322389940421\n",
      "Epoch 24::Minibatch 47::LR 0.0469230769231 --> Loss 0.00385535399119\n",
      "Epoch 24::Minibatch 48::LR 0.0469230769231 --> Loss 0.0053982436657\n",
      "Epoch 24::Minibatch 49::LR 0.0469230769231 --> Loss 0.00589660088221\n",
      "Epoch 24::Minibatch 50::LR 0.0469230769231 --> Loss 0.00609112858772\n",
      "Epoch 24::Minibatch 51::LR 0.0469230769231 --> Loss 0.00547660668691\n",
      "Epoch 24::Minibatch 52::LR 0.0469230769231 --> Loss 0.00344231685003\n",
      "Epoch 24::Minibatch 53::LR 0.0469230769231 --> Loss 0.00338027834892\n",
      "Epoch 24::Minibatch 54::LR 0.0469230769231 --> Loss 0.0040050637722\n",
      "Epoch 24::Minibatch 55::LR 0.0469230769231 --> Loss 0.000984897613525\n",
      "Epoch 24::Minibatch 56::LR 0.0469230769231 --> Loss 0.00269137144089\n",
      "Epoch 24::Minibatch 57::LR 0.0469230769231 --> Loss 0.00503489573797\n",
      "Epoch 24::Minibatch 58::LR 0.0469230769231 --> Loss 0.00326374153296\n",
      "Epoch 24::Minibatch 59::LR 0.0469230769231 --> Loss 0.00242807964484\n",
      "Epoch 24::Minibatch 60::LR 0.0469230769231 --> Loss 0.00240604241689\n",
      "Epoch 24::Minibatch 61::LR 0.0469230769231 --> Loss 0.000783707847198\n",
      "Epoch 24::Minibatch 62::LR 0.0469230769231 --> Loss 0.00280321419239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 63::LR 0.0469230769231 --> Loss 0.00202322324117\n",
      "Epoch 24::Minibatch 64::LR 0.0469230769231 --> Loss 0.000851901868979\n",
      "Epoch 24::Minibatch 65::LR 0.0469230769231 --> Loss 0.00223459144433\n",
      "Epoch 24::Minibatch 66::LR 0.0469230769231 --> Loss 0.00272964815299\n",
      "Epoch 24::Minibatch 67::LR 0.0469230769231 --> Loss 0.00264307777087\n",
      "Epoch 24::Minibatch 68::LR 0.0469230769231 --> Loss 0.00189442038536\n",
      "Epoch 24::Minibatch 69::LR 0.0469230769231 --> Loss 0.00379388173421\n",
      "Epoch 24::Minibatch 70::LR 0.0469230769231 --> Loss 0.00333322783311\n",
      "Epoch 24::Minibatch 71::LR 0.0469230769231 --> Loss 0.002280519406\n",
      "Epoch 24::Minibatch 72::LR 0.0469230769231 --> Loss 0.000537120749553\n",
      "Epoch 24::Minibatch 73::LR 0.0469230769231 --> Loss 0.00381300330162\n",
      "Epoch 24::Minibatch 74::LR 0.0469230769231 --> Loss 0.00406577626864\n",
      "Epoch 24::Minibatch 75::LR 0.0469230769231 --> Loss 0.0022550602754\n",
      "Epoch 24::Minibatch 76::LR 0.0469230769231 --> Loss 0.00054370328784\n",
      "Epoch 24::Minibatch 77::LR 0.0469230769231 --> Loss 0.00355959177017\n",
      "Epoch 24::Minibatch 78::LR 0.0469230769231 --> Loss 0.0038533949852\n",
      "Epoch 24::Minibatch 79::LR 0.0469230769231 --> Loss 0.00183661778768\n",
      "Epoch 24::Minibatch 80::LR 0.0469230769231 --> Loss 0.00303555468718\n",
      "Epoch 24::Minibatch 81::LR 0.0469230769231 --> Loss 0.00264770587285\n",
      "Epoch 24::Minibatch 82::LR 0.0469230769231 --> Loss 0.00192406137784\n",
      "Epoch 24::Minibatch 83::LR 0.0469230769231 --> Loss 0.00422801216443\n",
      "Epoch 24::Minibatch 84::LR 0.0469230769231 --> Loss 0.00192436416944\n",
      "Epoch 24::Minibatch 85::LR 0.0469230769231 --> Loss 0.00265187422434\n",
      "Epoch 24::Minibatch 86::LR 0.0469230769231 --> Loss 0.00215007483959\n",
      "Epoch 24::Minibatch 87::LR 0.0469230769231 --> Loss 0.0023334467411\n",
      "Epoch 24::Minibatch 88::LR 0.0469230769231 --> Loss 0.00172089298566\n",
      "Epoch 24::Minibatch 89::LR 0.0469230769231 --> Loss 0.00225587109725\n",
      "Epoch 24::Minibatch 90::LR 0.0469230769231 --> Loss 0.00106688857079\n",
      "Epoch 24::Minibatch 91::LR 0.0469230769231 --> Loss 0.000869393646717\n",
      "Epoch 24::Minibatch 92::LR 0.0469230769231 --> Loss 0.00262545843919\n",
      "Epoch 24::Minibatch 93::LR 0.0469230769231 --> Loss 0.00172482987245\n",
      "Epoch 24::Minibatch 94::LR 0.0469230769231 --> Loss 0.00174721717834\n",
      "Epoch 24::Minibatch 95::LR 0.0469230769231 --> Loss 0.00185011188189\n",
      "Epoch 24::Minibatch 96::LR 0.0469230769231 --> Loss 0.00529271960258\n",
      "Epoch 24::Minibatch 97::LR 0.0469230769231 --> Loss 0.00308044334253\n",
      "Epoch 24::Minibatch 98::LR 0.0469230769231 --> Loss 0.00102391163508\n",
      "Epoch 24::Minibatch 99::LR 0.0469230769231 --> Loss 0.00134617656469\n",
      "Epoch 24::Minibatch 100::LR 0.0469230769231 --> Loss 0.00468406558037\n",
      "Epoch 24::Minibatch 101::LR 0.0469230769231 --> Loss 0.000907532970111\n",
      "Epoch 24::Minibatch 102::LR 0.0469230769231 --> Loss 0.00388794541359\n",
      "Epoch 24::Minibatch 103::LR 0.0469230769231 --> Loss 0.00396859447161\n",
      "Epoch 24::Minibatch 104::LR 0.0469230769231 --> Loss 0.00270722548167\n",
      "Epoch 24::Minibatch 105::LR 0.0469230769231 --> Loss 0.0023910955588\n",
      "Epoch 24::Minibatch 106::LR 0.0469230769231 --> Loss 0.0159176015854\n",
      "Epoch 24::Minibatch 107::LR 0.0469230769231 --> Loss 0.00482488512993\n",
      "Epoch 24::Minibatch 108::LR 0.0469230769231 --> Loss 0.000981156527996\n",
      "Epoch 24::Minibatch 109::LR 0.0469230769231 --> Loss 0.00430849631627\n",
      "Epoch 24::Minibatch 110::LR 0.0469230769231 --> Loss 0.00228557447592\n",
      "Epoch 24::Minibatch 111::LR 0.0469230769231 --> Loss 0.00087940633297\n",
      "Epoch 24::Minibatch 112::LR 0.0469230769231 --> Loss 0.00340110262235\n",
      "Epoch 24::Minibatch 113::LR 0.0469230769231 --> Loss 0.00250887473424\n",
      "Epoch 24::Minibatch 114::LR 0.0469230769231 --> Loss 0.00139256139596\n",
      "Epoch 24::Minibatch 115::LR 0.0469230769231 --> Loss 0.00122668107351\n",
      "Epoch 24::Minibatch 116::LR 0.0469230769231 --> Loss 0.0026860477527\n",
      "Epoch 24::Minibatch 117::LR 0.0469230769231 --> Loss 0.00391181906064\n",
      "Epoch 24::Minibatch 118::LR 0.0469230769231 --> Loss 0.00674687147141\n",
      "Epoch 24::Minibatch 119::LR 0.0469230769231 --> Loss 0.000566433767478\n",
      "Epoch 24::Minibatch 120::LR 0.0469230769231 --> Loss 0.00167530477047\n",
      "Epoch 24::Minibatch 121::LR 0.0469230769231 --> Loss 0.00249561131001\n",
      "Epoch 24::Minibatch 122::LR 0.0469230769231 --> Loss 0.00374030550321\n",
      "Epoch 24::Minibatch 123::LR 0.0469230769231 --> Loss 0.000846750934919\n",
      "Epoch 24::Minibatch 124::LR 0.0469230769231 --> Loss 0.0026611995697\n",
      "Epoch 24::Minibatch 125::LR 0.0469230769231 --> Loss 0.00451199730237\n",
      "Epoch 24::Minibatch 126::LR 0.0469230769231 --> Loss 0.00258633633455\n",
      "Epoch 24::Minibatch 127::LR 0.0469230769231 --> Loss 0.0045408654213\n",
      "Epoch 24::Minibatch 128::LR 0.0469230769231 --> Loss 0.00356728553772\n",
      "Epoch 24::Minibatch 129::LR 0.0469230769231 --> Loss 0.00255911986033\n",
      "Epoch 24::Minibatch 130::LR 0.0469230769231 --> Loss 0.00434032003085\n",
      "Epoch 24::Minibatch 131::LR 0.0469230769231 --> Loss 0.00175031224887\n",
      "Epoch 24::Minibatch 132::LR 0.0469230769231 --> Loss 0.00296036243439\n",
      "Epoch 24::Minibatch 133::LR 0.0469230769231 --> Loss 0.00282345116138\n",
      "Epoch 24::Minibatch 134::LR 0.0469230769231 --> Loss 0.00224172572295\n",
      "Epoch 24::Minibatch 135::LR 0.0469230769231 --> Loss 0.0014342512687\n",
      "Epoch 24::Minibatch 136::LR 0.0469230769231 --> Loss 0.0025839304924\n",
      "Epoch 24::Minibatch 137::LR 0.0469230769231 --> Loss 0.00355521440506\n",
      "Epoch 24::Minibatch 138::LR 0.0469230769231 --> Loss 0.00126249154409\n",
      "Epoch 24::Minibatch 139::LR 0.0469230769231 --> Loss 0.00190029601256\n",
      "Epoch 24::Minibatch 140::LR 0.0469230769231 --> Loss 0.00243270218372\n",
      "Epoch 24::Minibatch 141::LR 0.0469230769231 --> Loss 0.00294393062592\n",
      "Epoch 24::Minibatch 142::LR 0.0469230769231 --> Loss 0.00276916146278\n",
      "Epoch 24::Minibatch 143::LR 0.0469230769231 --> Loss 0.000574042598406\n",
      "Epoch 24::Minibatch 144::LR 0.0469230769231 --> Loss 0.003284034729\n",
      "Epoch 24::Minibatch 145::LR 0.0469230769231 --> Loss 0.00422324975332\n",
      "Epoch 24::Minibatch 146::LR 0.0469230769231 --> Loss 0.00253708481789\n",
      "Epoch 24::Minibatch 147::LR 0.0469230769231 --> Loss 0.00179986516635\n",
      "Epoch 24::Minibatch 148::LR 0.0469230769231 --> Loss 0.000994543234507\n",
      "Epoch 24::Minibatch 149::LR 0.0469230769231 --> Loss 0.00283814986547\n",
      "Epoch 24::Minibatch 150::LR 0.0469230769231 --> Loss 0.00268816749255\n",
      "Epoch 24::Minibatch 151::LR 0.0469230769231 --> Loss 0.00425180951754\n",
      "Epoch 24::Minibatch 152::LR 0.0469230769231 --> Loss 0.000911696056525\n",
      "Epoch 24::Minibatch 153::LR 0.0469230769231 --> Loss 0.00173574705919\n",
      "Epoch 24::Minibatch 154::LR 0.0469230769231 --> Loss 0.00203397651513\n",
      "Epoch 24::Minibatch 155::LR 0.0469230769231 --> Loss 0.00429031650225\n",
      "Epoch 24::Minibatch 156::LR 0.0469230769231 --> Loss 0.00237346132596\n",
      "Epoch 24::Minibatch 157::LR 0.0469230769231 --> Loss 0.00069371898969\n",
      "Epoch 24::Minibatch 158::LR 0.0469230769231 --> Loss 0.00309729735057\n",
      "Epoch 24::Minibatch 159::LR 0.0469230769231 --> Loss 0.00273734947046\n",
      "Epoch 24::Minibatch 160::LR 0.0469230769231 --> Loss 0.00263032595317\n",
      "Epoch 24::Minibatch 161::LR 0.0469230769231 --> Loss 0.00101219763358\n",
      "Epoch 24::Minibatch 162::LR 0.0469230769231 --> Loss 0.00383063634237\n",
      "Epoch 24::Minibatch 163::LR 0.0469230769231 --> Loss 0.0023916298151\n",
      "Epoch 24::Minibatch 164::LR 0.0469230769231 --> Loss 0.00250344634056\n",
      "Epoch 24::Minibatch 165::LR 0.0469230769231 --> Loss 0.000514669617017\n",
      "Epoch 24::Minibatch 166::LR 0.0469230769231 --> Loss 0.00175053675969\n",
      "Epoch 24::Minibatch 167::LR 0.0469230769231 --> Loss 0.00245824793975\n",
      "Epoch 24::Minibatch 168::LR 0.0469230769231 --> Loss 0.00216245472431\n",
      "Epoch 24::Minibatch 169::LR 0.0469230769231 --> Loss 0.00100363483032\n",
      "Epoch 24::Minibatch 170::LR 0.0469230769231 --> Loss 0.000975813170274\n",
      "Epoch 24::Minibatch 171::LR 0.0469230769231 --> Loss 0.00250068724155\n",
      "Epoch 24::Minibatch 172::LR 0.0469230769231 --> Loss 0.00432509263357\n",
      "Epoch 24::Minibatch 173::LR 0.0469230769231 --> Loss 0.00195525546869\n",
      "Epoch 24::Minibatch 174::LR 0.0469230769231 --> Loss 0.00100619902213\n",
      "Epoch 24::Minibatch 175::LR 0.0469230769231 --> Loss 0.00231915235519\n",
      "Epoch 24::Minibatch 176::LR 0.0469230769231 --> Loss 0.00321400721868\n",
      "Epoch 24::Minibatch 177::LR 0.0469230769231 --> Loss 0.00442765752474\n",
      "Epoch 24::Minibatch 178::LR 0.0469230769231 --> Loss 0.001583297352\n",
      "Epoch 24::Minibatch 179::LR 0.0469230769231 --> Loss 0.00130571742853\n",
      "Epoch 24::Minibatch 180::LR 0.0469230769231 --> Loss 0.00353150129318\n",
      "Epoch 24::Minibatch 181::LR 0.0469230769231 --> Loss 0.0031723767519\n",
      "Epoch 24::Minibatch 182::LR 0.0469230769231 --> Loss 0.000747545411189\n",
      "Epoch 24::Minibatch 183::LR 0.0469230769231 --> Loss 0.00164014011621\n",
      "Epoch 24::Minibatch 184::LR 0.0469230769231 --> Loss 0.00342799226443\n",
      "Epoch 24::Minibatch 185::LR 0.0469230769231 --> Loss 0.00279033581416\n",
      "Epoch 24::Minibatch 186::LR 0.0469230769231 --> Loss 0.000957568685214\n",
      "Epoch 24::Minibatch 187::LR 0.0469230769231 --> Loss 0.00127539098263\n",
      "Epoch 24::Minibatch 188::LR 0.0469230769231 --> Loss 0.00415711363157\n",
      "Epoch 24::Minibatch 189::LR 0.0469230769231 --> Loss 0.00431479175886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 190::LR 0.0469230769231 --> Loss 0.00232510228952\n",
      "Epoch 24::Minibatch 191::LR 0.0469230769231 --> Loss 0.000466871360938\n",
      "Epoch 24::Minibatch 192::LR 0.0469230769231 --> Loss 0.00274312853813\n",
      "Epoch 24::Minibatch 193::LR 0.0469230769231 --> Loss 0.00262137452761\n",
      "Epoch 24::Minibatch 194::LR 0.0469230769231 --> Loss 0.00176521023115\n",
      "Epoch 24::Minibatch 195::LR 0.0469230769231 --> Loss 0.000382584656278\n",
      "Epoch 24::Minibatch 196::LR 0.0469230769231 --> Loss 0.0012818946441\n",
      "Epoch 24::Minibatch 197::LR 0.0469230769231 --> Loss 0.00291123429934\n",
      "Epoch 24::Minibatch 198::LR 0.0469230769231 --> Loss 0.00224756697814\n",
      "Epoch 24::Minibatch 199::LR 0.0469230769231 --> Loss 0.000289305796226\n",
      "Epoch 24::Minibatch 200::LR 0.0469230769231 --> Loss 0.00204760293166\n",
      "Epoch 24::Minibatch 201::LR 0.0469230769231 --> Loss 0.0019428006808\n",
      "Epoch 24::Minibatch 202::LR 0.0469230769231 --> Loss 0.00184378941854\n",
      "Epoch 24::Minibatch 203::LR 0.0469230769231 --> Loss 0.00175582786401\n",
      "Epoch 24::Minibatch 204::LR 0.0469230769231 --> Loss 0.00143270124992\n",
      "Epoch 24::Minibatch 205::LR 0.0469230769231 --> Loss 0.00220076461633\n",
      "Epoch 24::Minibatch 206::LR 0.0469230769231 --> Loss 0.00604490439097\n",
      "Epoch 24::Minibatch 207::LR 0.0469230769231 --> Loss 0.0013962144653\n",
      "Epoch 24::Minibatch 208::LR 0.0469230769231 --> Loss 0.00111470053593\n",
      "Epoch 24::Minibatch 209::LR 0.0469230769231 --> Loss 0.00231463988622\n",
      "Epoch 24::Minibatch 210::LR 0.0469230769231 --> Loss 0.00220600744088\n",
      "Epoch 24::Minibatch 211::LR 0.0469230769231 --> Loss 0.00243621985118\n",
      "Epoch 24::Minibatch 212::LR 0.0469230769231 --> Loss 0.00388189951579\n",
      "Epoch 24::Minibatch 213::LR 0.0469230769231 --> Loss 0.00565529108047\n",
      "Epoch 24::Minibatch 214::LR 0.0469230769231 --> Loss 0.00829873482386\n",
      "Epoch 24::Minibatch 215::LR 0.0469230769231 --> Loss 0.0013705894351\n",
      "Epoch 24::Minibatch 216::LR 0.0469230769231 --> Loss 0.00542072852453\n",
      "Epoch 24::Minibatch 217::LR 0.0469230769231 --> Loss 0.00605434497197\n",
      "Epoch 24::Minibatch 218::LR 0.0469230769231 --> Loss 0.00391259948413\n",
      "Epoch 24::Minibatch 219::LR 0.0469230769231 --> Loss 0.00425766348839\n",
      "Epoch 24::Minibatch 220::LR 0.0469230769231 --> Loss 0.00444446047147\n",
      "Epoch 24::Minibatch 221::LR 0.0469230769231 --> Loss 0.00424498558044\n",
      "Epoch 24::Minibatch 222::LR 0.0469230769231 --> Loss 0.00320900440216\n",
      "Epoch 24::Minibatch 223::LR 0.0469230769231 --> Loss 0.00140043983857\n",
      "Epoch 24::Minibatch 224::LR 0.0469230769231 --> Loss 0.00168066680431\n",
      "Epoch 24::Minibatch 225::LR 0.0469230769231 --> Loss 0.00748951037725\n",
      "Epoch 24::Minibatch 226::LR 0.0469230769231 --> Loss 0.00374220490456\n",
      "Epoch 24::Minibatch 227::LR 0.0469230769231 --> Loss 0.00168439924717\n",
      "Epoch 24::Minibatch 228::LR 0.0469230769231 --> Loss 0.000699731856585\n",
      "Epoch 24::Minibatch 229::LR 0.0469230769231 --> Loss 0.00473831574122\n",
      "Epoch 24::Minibatch 230::LR 0.0469230769231 --> Loss 0.00383662859599\n",
      "Epoch 24::Minibatch 231::LR 0.0469230769231 --> Loss 0.00264774084091\n",
      "Epoch 24::Minibatch 232::LR 0.0469230769231 --> Loss 0.00119102825721\n",
      "Epoch 24::Minibatch 233::LR 0.0469230769231 --> Loss 0.0024388118585\n",
      "Epoch 24::Minibatch 234::LR 0.0469230769231 --> Loss 0.00708715438843\n",
      "Epoch 24::Minibatch 235::LR 0.0469230769231 --> Loss 0.00461206118266\n",
      "Epoch 24::Minibatch 236::LR 0.0469230769231 --> Loss 0.0017249049743\n",
      "Epoch 24::Minibatch 237::LR 0.0469230769231 --> Loss 0.000641844222943\n",
      "Epoch 24::Minibatch 238::LR 0.0469230769231 --> Loss 0.00341223239899\n",
      "Epoch 24::Minibatch 239::LR 0.0469230769231 --> Loss 0.00295870701472\n",
      "Epoch 24::Minibatch 240::LR 0.0469230769231 --> Loss 0.00324049949646\n",
      "Epoch 24::Minibatch 241::LR 0.0469230769231 --> Loss 0.000751112997532\n",
      "Epoch 24::Minibatch 242::LR 0.0469230769231 --> Loss 0.00689614534378\n",
      "Epoch 24::Minibatch 243::LR 0.0469230769231 --> Loss 0.00341178774834\n",
      "Epoch 24::Minibatch 244::LR 0.0469230769231 --> Loss 0.00285691519578\n",
      "Epoch 24::Minibatch 245::LR 0.0469230769231 --> Loss 0.00045492152373\n",
      "Epoch 24::Minibatch 246::LR 0.0469230769231 --> Loss 0.00199958642324\n",
      "Epoch 24::Minibatch 247::LR 0.0469230769231 --> Loss 0.0119524359703\n",
      "Epoch 24::Minibatch 248::LR 0.0469230769231 --> Loss 0.00441600282987\n",
      "Epoch 24::Minibatch 249::LR 0.0469230769231 --> Loss 0.00256772081057\n",
      "Epoch 24::Minibatch 250::LR 0.0469230769231 --> Loss 0.00246772189935\n",
      "Epoch 24::Minibatch 251::LR 0.0469230769231 --> Loss 0.00243137061596\n",
      "Epoch 24::Minibatch 252::LR 0.0469230769231 --> Loss 0.00170787215233\n",
      "Epoch 24::Minibatch 253::LR 0.0469230769231 --> Loss 0.00297029534976\n",
      "Epoch 24::Minibatch 254::LR 0.0469230769231 --> Loss 0.00499497095744\n",
      "Epoch 24::Minibatch 255::LR 0.0469230769231 --> Loss 0.00384704391162\n",
      "Epoch 24::Minibatch 256::LR 0.0469230769231 --> Loss 0.00153299301863\n",
      "Epoch 24::Minibatch 257::LR 0.0469230769231 --> Loss 0.00118476043145\n",
      "Epoch 24::Minibatch 258::LR 0.0469230769231 --> Loss 0.00363350669543\n",
      "Epoch 24::Minibatch 259::LR 0.0469230769231 --> Loss 0.00170580903689\n",
      "Epoch 24::Minibatch 260::LR 0.0469230769231 --> Loss 0.00186889410019\n",
      "Epoch 24::Minibatch 261::LR 0.0469230769231 --> Loss 0.0027817205588\n",
      "Epoch 24::Minibatch 262::LR 0.0469230769231 --> Loss 0.00187829494476\n",
      "Epoch 24::Minibatch 263::LR 0.0469230769231 --> Loss 0.00233520011107\n",
      "Epoch 24::Minibatch 264::LR 0.0469230769231 --> Loss 0.00360537846883\n",
      "Epoch 24::Minibatch 265::LR 0.0469230769231 --> Loss 0.01004352808\n",
      "Epoch 24::Minibatch 266::LR 0.0469230769231 --> Loss 0.000961561997732\n",
      "Epoch 24::Minibatch 267::LR 0.0469230769231 --> Loss 0.00961773792903\n",
      "Epoch 24::Minibatch 268::LR 0.0469230769231 --> Loss 0.00112366656462\n",
      "Epoch 24::Minibatch 269::LR 0.0469230769231 --> Loss 0.00347867647807\n",
      "Epoch 24::Minibatch 270::LR 0.0469230769231 --> Loss 0.00690356731415\n",
      "Epoch 24::Minibatch 271::LR 0.0469230769231 --> Loss 0.00259142657121\n",
      "Epoch 24::Minibatch 272::LR 0.0469230769231 --> Loss 0.00422889987628\n",
      "Epoch 24::Minibatch 273::LR 0.0469230769231 --> Loss 0.00154984285434\n",
      "Epoch 24::Minibatch 274::LR 0.0469230769231 --> Loss 0.00178714652856\n",
      "Epoch 24::Minibatch 275::LR 0.0469230769231 --> Loss 0.00257581412792\n",
      "Epoch 24::Minibatch 276::LR 0.0469230769231 --> Loss 0.00342699130376\n",
      "Epoch 24::Minibatch 277::LR 0.0469230769231 --> Loss 0.000945423046748\n",
      "Epoch 24::Minibatch 278::LR 0.0469230769231 --> Loss 0.00260048429171\n",
      "Epoch 24::Minibatch 279::LR 0.0469230769231 --> Loss 0.00222029646238\n",
      "Epoch 24::Minibatch 280::LR 0.0469230769231 --> Loss 0.00194657643636\n",
      "Epoch 24::Minibatch 281::LR 0.0469230769231 --> Loss 0.0012292427818\n",
      "Epoch 24::Minibatch 282::LR 0.0469230769231 --> Loss 0.00215002218882\n",
      "Epoch 24::Minibatch 283::LR 0.0469230769231 --> Loss 0.00207654297352\n",
      "Epoch 24::Minibatch 284::LR 0.0469230769231 --> Loss 0.00167464514573\n",
      "Epoch 24::Minibatch 285::LR 0.0469230769231 --> Loss 0.00118428438902\n",
      "Epoch 24::Minibatch 286::LR 0.0469230769231 --> Loss 0.00207712709904\n",
      "Epoch 24::Minibatch 287::LR 0.0469230769231 --> Loss 0.00203428785006\n",
      "Epoch 24::Minibatch 288::LR 0.0469230769231 --> Loss 0.00110071827968\n",
      "Epoch 24::Minibatch 289::LR 0.0469230769231 --> Loss 0.0015980771184\n",
      "Epoch 24::Minibatch 290::LR 0.0469230769231 --> Loss 0.00191608627637\n",
      "Epoch 24::Minibatch 291::LR 0.0469230769231 --> Loss 0.00171120365461\n",
      "Epoch 24::Minibatch 292::LR 0.0469230769231 --> Loss 0.000601524909337\n",
      "Epoch 24::Minibatch 293::LR 0.0469230769231 --> Loss 0.00150645136833\n",
      "Epoch 24::Minibatch 294::LR 0.0469230769231 --> Loss 0.0015955170989\n",
      "Epoch 24::Minibatch 295::LR 0.0469230769231 --> Loss 0.00188200215499\n",
      "Epoch 24::Minibatch 296::LR 0.0469230769231 --> Loss 0.00163334866365\n",
      "Epoch 24::Minibatch 297::LR 0.0469230769231 --> Loss 0.00141879638036\n",
      "Epoch 24::Minibatch 298::LR 0.0469230769231 --> Loss 0.00141317079465\n",
      "Epoch 24::Minibatch 299::LR 0.0469230769231 --> Loss 0.000807760010163\n",
      "Epoch 24::Minibatch 300::LR 0.0469230769231 --> Loss 0.00275532106558\n",
      "Epoch 24::Minibatch 301::LR 0.0469230769231 --> Loss 0.00266680300236\n",
      "Epoch 24::Minibatch 302::LR 0.0469230769231 --> Loss 0.00244795938333\n",
      "Epoch 24::Minibatch 303::LR 0.0469230769231 --> Loss 0.000848409136136\n",
      "Epoch 24::Minibatch 304::LR 0.0469230769231 --> Loss 0.00303080221017\n",
      "Epoch 24::Minibatch 305::LR 0.0469230769231 --> Loss 0.00170248468717\n",
      "Epoch 24::Minibatch 306::LR 0.0469230769231 --> Loss 0.000936381022135\n",
      "Epoch 24::Minibatch 307::LR 0.0469230769231 --> Loss 0.00243155499299\n",
      "Epoch 24::Minibatch 308::LR 0.0469230769231 --> Loss 0.00201211571693\n",
      "Epoch 24::Minibatch 309::LR 0.0469230769231 --> Loss 0.00102501700322\n",
      "Epoch 24::Minibatch 310::LR 0.0469230769231 --> Loss 0.00116086731354\n",
      "Epoch 24::Minibatch 311::LR 0.0469230769231 --> Loss 0.00176387727261\n",
      "Epoch 24::Minibatch 312::LR 0.0469230769231 --> Loss 0.00289950986703\n",
      "Epoch 24::Minibatch 313::LR 0.0469230769231 --> Loss 0.00237134357293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 314::LR 0.0469230769231 --> Loss 0.00192148387432\n",
      "Epoch 24::Minibatch 315::LR 0.0469230769231 --> Loss 0.00102274954319\n",
      "Epoch 24::Minibatch 316::LR 0.0469230769231 --> Loss 0.00233656744162\n",
      "Epoch 24::Minibatch 317::LR 0.0469230769231 --> Loss 0.00155418227116\n",
      "Epoch 24::Minibatch 318::LR 0.0469230769231 --> Loss 0.00126874645551\n",
      "Epoch 24::Minibatch 319::LR 0.0469230769231 --> Loss 0.00230179091295\n",
      "Epoch 24::Minibatch 320::LR 0.0469230769231 --> Loss 0.00311686376731\n",
      "Epoch 24::Minibatch 321::LR 0.0469230769231 --> Loss 0.000842784047127\n",
      "Epoch 24::Minibatch 322::LR 0.0469230769231 --> Loss 0.00357062101364\n",
      "Epoch 24::Minibatch 323::LR 0.0469230769231 --> Loss 0.0034749464194\n",
      "Epoch 24::Minibatch 324::LR 0.0469230769231 --> Loss 0.0026396727562\n",
      "Epoch 24::Minibatch 325::LR 0.0469230769231 --> Loss 0.00238537708918\n",
      "Epoch 24::Minibatch 326::LR 0.0469230769231 --> Loss 0.00542891780535\n",
      "Epoch 24::Minibatch 327::LR 0.0469230769231 --> Loss 0.00224592467149\n",
      "Epoch 24::Minibatch 328::LR 0.0469230769231 --> Loss 0.00310971975327\n",
      "Epoch 24::Minibatch 329::LR 0.0469230769231 --> Loss 0.00120891372363\n",
      "Epoch 24::Minibatch 330::LR 0.0469230769231 --> Loss 0.00159257531166\n",
      "Epoch 24::Minibatch 331::LR 0.0469230769231 --> Loss 0.00253658473492\n",
      "Epoch 24::Minibatch 332::LR 0.0469230769231 --> Loss 0.00248062868913\n",
      "Epoch 24::Minibatch 333::LR 0.0469230769231 --> Loss 0.00145564973354\n",
      "Epoch 24::Minibatch 334::LR 0.0469230769231 --> Loss 0.00441652377446\n",
      "Epoch 24::Minibatch 335::LR 0.0469230769231 --> Loss 0.00189004361629\n",
      "Epoch 24::Minibatch 336::LR 0.0469230769231 --> Loss 0.00221509913603\n",
      "Epoch 24::Minibatch 337::LR 0.0469230769231 --> Loss 0.00357961535454\n",
      "Epoch 24::Minibatch 338::LR 0.0469230769231 --> Loss 0.000536046872536\n",
      "Epoch 24::Minibatch 339::LR 0.0469230769231 --> Loss 0.00329621950785\n",
      "Epoch 24::Minibatch 340::LR 0.0469230769231 --> Loss 0.00386431097984\n",
      "Epoch 24::Minibatch 341::LR 0.0469230769231 --> Loss 0.00456340789795\n",
      "Epoch 24::Minibatch 342::LR 0.0469230769231 --> Loss 0.00308471600215\n",
      "Epoch 24::Minibatch 343::LR 0.0469230769231 --> Loss 0.00165215015411\n",
      "Epoch 24::Minibatch 344::LR 0.0469230769231 --> Loss 0.00315241436164\n",
      "Epoch 24::Minibatch 345::LR 0.0469230769231 --> Loss 0.00417900602023\n",
      "Epoch 24::Minibatch 346::LR 0.0469230769231 --> Loss 0.00553630312284\n",
      "Epoch 24::Minibatch 347::LR 0.0469230769231 --> Loss 0.00083562841018\n",
      "Epoch 24::Minibatch 348::LR 0.0469230769231 --> Loss 0.00320577581724\n",
      "Epoch 24::Minibatch 349::LR 0.0469230769231 --> Loss 0.00345188776652\n",
      "Epoch 24::Minibatch 350::LR 0.0469230769231 --> Loss 0.00170435210069\n",
      "Epoch 24::Minibatch 351::LR 0.0469230769231 --> Loss 0.00348297874133\n",
      "Epoch 24::Minibatch 352::LR 0.0469230769231 --> Loss 0.00492103815079\n",
      "Epoch 24::Minibatch 353::LR 0.0469230769231 --> Loss 0.00353291193644\n",
      "Epoch 24::Minibatch 354::LR 0.0469230769231 --> Loss 0.00293861369292\n",
      "Epoch 24::Minibatch 355::LR 0.0469230769231 --> Loss 0.00617673675219\n",
      "Epoch 24::Minibatch 356::LR 0.0469230769231 --> Loss 0.00313169439634\n",
      "Epoch 24::Minibatch 357::LR 0.0469230769231 --> Loss 0.00115003714959\n",
      "Epoch 24::Minibatch 358::LR 0.0469230769231 --> Loss 0.00203963597616\n",
      "Epoch 24::Minibatch 359::LR 0.0469230769231 --> Loss 0.002697767814\n",
      "Epoch 24::Minibatch 360::LR 0.0469230769231 --> Loss 0.00236542681853\n",
      "Epoch 24::Minibatch 361::LR 0.0469230769231 --> Loss 0.00234229703744\n",
      "Epoch 24::Minibatch 362::LR 0.0469230769231 --> Loss 0.00232281247775\n",
      "Epoch 24::Minibatch 363::LR 0.0469230769231 --> Loss 0.000645141154528\n",
      "Epoch 24::Minibatch 364::LR 0.0469230769231 --> Loss 0.00198539932569\n",
      "Epoch 24::Minibatch 365::LR 0.0469230769231 --> Loss 0.00204720775286\n",
      "Epoch 24::Minibatch 366::LR 0.0469230769231 --> Loss 0.00217966636022\n",
      "Epoch 24::Minibatch 367::LR 0.0469230769231 --> Loss 0.00103669822216\n",
      "Epoch 24::Minibatch 368::LR 0.0469230769231 --> Loss 0.000975204010804\n",
      "Epoch 24::Minibatch 369::LR 0.0469230769231 --> Loss 0.00282680769761\n",
      "Epoch 24::Minibatch 370::LR 0.0469230769231 --> Loss 0.00223884205023\n",
      "Epoch 24::Minibatch 371::LR 0.0469230769231 --> Loss 0.00186513384183\n",
      "Epoch 24::Minibatch 372::LR 0.0469230769231 --> Loss 0.000429431994756\n",
      "Epoch 24::Minibatch 373::LR 0.0469230769231 --> Loss 0.00178595443567\n",
      "Epoch 24::Minibatch 374::LR 0.0469230769231 --> Loss 0.00222058057785\n",
      "Epoch 24::Minibatch 375::LR 0.0469230769231 --> Loss 0.001860272487\n",
      "Epoch 24::Minibatch 376::LR 0.0469230769231 --> Loss 0.00122624397278\n",
      "Epoch 24::Minibatch 377::LR 0.0469230769231 --> Loss 0.00192440390587\n",
      "Epoch 24::Minibatch 378::LR 0.0469230769231 --> Loss 0.0021113328139\n",
      "Epoch 24::Minibatch 379::LR 0.0469230769231 --> Loss 0.00234724720319\n",
      "Epoch 24::Minibatch 380::LR 0.0469230769231 --> Loss 0.00157456696033\n",
      "Epoch 24::Minibatch 381::LR 0.0469230769231 --> Loss 0.00098445435365\n",
      "Epoch 24::Minibatch 382::LR 0.0469230769231 --> Loss 0.00201895952225\n",
      "Epoch 24::Minibatch 383::LR 0.0469230769231 --> Loss 0.00196847995122\n",
      "Epoch 24::Minibatch 384::LR 0.0469230769231 --> Loss 0.00107861171166\n",
      "Epoch 24::Minibatch 385::LR 0.0469230769231 --> Loss 0.00104208340247\n",
      "Epoch 24::Minibatch 386::LR 0.0469230769231 --> Loss 0.00220220625401\n",
      "Epoch 24::Minibatch 387::LR 0.0469230769231 --> Loss 0.00234966059526\n",
      "Epoch 24::Minibatch 388::LR 0.0469230769231 --> Loss 0.00117743730545\n",
      "Epoch 24::Minibatch 389::LR 0.0469230769231 --> Loss 0.00178724547227\n",
      "Epoch 24::Minibatch 390::LR 0.0469230769231 --> Loss 0.0034033258756\n",
      "Epoch 24::Minibatch 391::LR 0.0469230769231 --> Loss 0.00260873874029\n",
      "Epoch 24::Minibatch 392::LR 0.0469230769231 --> Loss 0.00258556981881\n",
      "Epoch 24::Minibatch 393::LR 0.0469230769231 --> Loss 0.00274668435256\n",
      "Epoch 24::Minibatch 394::LR 0.0469230769231 --> Loss 0.00204486807187\n",
      "Epoch 24::Minibatch 395::LR 0.0469230769231 --> Loss 0.00205802083015\n",
      "Epoch 24::Minibatch 396::LR 0.0469230769231 --> Loss 0.00193090518316\n",
      "Epoch 24::Minibatch 397::LR 0.0469230769231 --> Loss 0.00206663350264\n",
      "Epoch 24::Minibatch 398::LR 0.0469230769231 --> Loss 0.00205309649309\n",
      "Epoch 24::Minibatch 399::LR 0.0469230769231 --> Loss 0.00236302057902\n",
      "Epoch 24::Minibatch 400::LR 0.0469230769231 --> Loss 0.00200243910154\n",
      "Epoch 24::Minibatch 401::LR 0.0469230769231 --> Loss 0.0034363869826\n",
      "Epoch 24::Minibatch 402::LR 0.0469230769231 --> Loss 0.00174918353558\n",
      "Epoch 24::Minibatch 403::LR 0.0469230769231 --> Loss 0.00143137534459\n",
      "Epoch 24::Minibatch 404::LR 0.0469230769231 --> Loss 0.00139288703601\n",
      "Epoch 24::Minibatch 405::LR 0.0469230769231 --> Loss 0.00339703679085\n",
      "Epoch 24::Minibatch 406::LR 0.0469230769231 --> Loss 0.00239083011945\n",
      "Epoch 24::Minibatch 407::LR 0.0469230769231 --> Loss 0.00171191513538\n",
      "Epoch 24::Minibatch 408::LR 0.0469230769231 --> Loss 0.000429589202007\n",
      "Epoch 24::Minibatch 409::LR 0.0469230769231 --> Loss 0.00224022408326\n",
      "Epoch 24::Minibatch 410::LR 0.0469230769231 --> Loss 0.00315152645111\n",
      "Epoch 24::Minibatch 411::LR 0.0469230769231 --> Loss 0.00163748850425\n",
      "Epoch 24::Minibatch 412::LR 0.0469230769231 --> Loss 0.000943345328172\n",
      "Epoch 24::Minibatch 413::LR 0.0469230769231 --> Loss 0.00195619324843\n",
      "Epoch 24::Minibatch 414::LR 0.0469230769231 --> Loss 0.00184420267741\n",
      "Epoch 24::Minibatch 415::LR 0.0469230769231 --> Loss 0.00114825357993\n",
      "Epoch 24::Minibatch 416::LR 0.0469230769231 --> Loss 0.000792814294497\n",
      "Epoch 24::Minibatch 417::LR 0.0469230769231 --> Loss 0.00167685906092\n",
      "Epoch 24::Minibatch 418::LR 0.0469230769231 --> Loss 0.0026409604152\n",
      "Epoch 24::Minibatch 419::LR 0.0469230769231 --> Loss 0.000485600084066\n",
      "Epoch 24::Minibatch 420::LR 0.0469230769231 --> Loss 0.000679866522551\n",
      "Epoch 24::Minibatch 421::LR 0.0469230769231 --> Loss 0.00188683668772\n",
      "Epoch 24::Minibatch 422::LR 0.0469230769231 --> Loss 0.00208273887634\n",
      "Epoch 24::Minibatch 423::LR 0.0469230769231 --> Loss 0.000962593853474\n",
      "Epoch 24::Minibatch 424::LR 0.0469230769231 --> Loss 0.00151884198189\n",
      "Epoch 24::Minibatch 425::LR 0.0469230769231 --> Loss 0.00288032909234\n",
      "Epoch 24::Minibatch 426::LR 0.0469230769231 --> Loss 0.0019803527991\n",
      "Epoch 24::Minibatch 427::LR 0.0469230769231 --> Loss 0.00071121275425\n",
      "Epoch 24::Minibatch 428::LR 0.0469230769231 --> Loss 0.000979868968328\n",
      "Epoch 24::Minibatch 429::LR 0.0469230769231 --> Loss 0.00229336957137\n",
      "Epoch 24::Minibatch 430::LR 0.0469230769231 --> Loss 0.00873927911123\n",
      "Epoch 24::Minibatch 431::LR 0.0469230769231 --> Loss 0.00372201482455\n",
      "Epoch 24::Minibatch 432::LR 0.0469230769231 --> Loss 0.00422967354457\n",
      "Epoch 24::Minibatch 433::LR 0.0469230769231 --> Loss 0.00254373550415\n",
      "Epoch 24::Minibatch 434::LR 0.0469230769231 --> Loss 0.00248750329018\n",
      "Epoch 24::Minibatch 435::LR 0.0469230769231 --> Loss 0.00227756738663\n",
      "Epoch 24::Minibatch 436::LR 0.0469230769231 --> Loss 0.00163013160229\n",
      "Epoch 24::Minibatch 437::LR 0.0469230769231 --> Loss 0.00299193938573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 438::LR 0.0469230769231 --> Loss 0.00240295290947\n",
      "Epoch 24::Minibatch 439::LR 0.0469230769231 --> Loss 0.0019806989034\n",
      "Epoch 24::Minibatch 440::LR 0.0469230769231 --> Loss 0.00307423472404\n",
      "Epoch 24::Minibatch 441::LR 0.0469230769231 --> Loss 0.00286939541499\n",
      "Epoch 24::Minibatch 442::LR 0.0469230769231 --> Loss 0.00259512325128\n",
      "Epoch 24::Minibatch 443::LR 0.0469230769231 --> Loss 0.00354009509087\n",
      "Epoch 24::Minibatch 444::LR 0.0469230769231 --> Loss 0.00275138894717\n",
      "Epoch 24::Minibatch 445::LR 0.0469230769231 --> Loss 0.000864390631517\n",
      "Epoch 24::Minibatch 446::LR 0.0469230769231 --> Loss 0.00139670431614\n",
      "Epoch 24::Minibatch 447::LR 0.0469230769231 --> Loss 0.00234822352727\n",
      "Epoch 24::Minibatch 448::LR 0.0469230769231 --> Loss 0.00234148104986\n",
      "Epoch 24::Minibatch 449::LR 0.0469230769231 --> Loss 0.00363297899564\n",
      "Epoch 24::Minibatch 450::LR 0.0469230769231 --> Loss 0.00219500303268\n",
      "Epoch 24::Minibatch 451::LR 0.0469230769231 --> Loss 0.00391081929207\n",
      "Epoch 24::Minibatch 452::LR 0.0469230769231 --> Loss 0.00232529858748\n",
      "Epoch 24::Minibatch 453::LR 0.0469230769231 --> Loss 0.000357564290365\n",
      "Epoch 24::Minibatch 454::LR 0.0469230769231 --> Loss 0.00351898749669\n",
      "Epoch 24::Minibatch 455::LR 0.0469230769231 --> Loss 0.00263341248035\n",
      "Epoch 24::Minibatch 456::LR 0.0469230769231 --> Loss 0.00306895097097\n",
      "Epoch 24::Minibatch 457::LR 0.0469230769231 --> Loss 0.0019026084741\n",
      "Epoch 24::Minibatch 458::LR 0.0469230769231 --> Loss 0.000726143618425\n",
      "Epoch 24::Minibatch 459::LR 0.0469230769231 --> Loss 0.00395065267881\n",
      "Epoch 24::Minibatch 460::LR 0.0469230769231 --> Loss 0.00248385270437\n",
      "Epoch 24::Minibatch 461::LR 0.0469230769231 --> Loss 0.003777440389\n",
      "Epoch 24::Minibatch 462::LR 0.0469230769231 --> Loss 0.000376876915495\n",
      "Epoch 24::Minibatch 463::LR 0.0469230769231 --> Loss 0.00431542913119\n",
      "Epoch 24::Minibatch 464::LR 0.0469230769231 --> Loss 0.00198053518931\n",
      "Epoch 24::Minibatch 465::LR 0.0469230769231 --> Loss 0.00483552177747\n",
      "Epoch 24::Minibatch 466::LR 0.0469230769231 --> Loss 0.00504025538762\n",
      "Epoch 24::Minibatch 467::LR 0.0469230769231 --> Loss 0.00533205668132\n",
      "Epoch 24::Minibatch 468::LR 0.0469230769231 --> Loss 0.00583738883336\n",
      "Epoch 24::Minibatch 469::LR 0.0469230769231 --> Loss 0.00612306555112\n",
      "Epoch 24::Minibatch 470::LR 0.0469230769231 --> Loss 0.00364014148712\n",
      "Epoch 24::Minibatch 471::LR 0.0469230769231 --> Loss 0.00168882886569\n",
      "Epoch 24::Minibatch 472::LR 0.0469230769231 --> Loss 0.00354864796003\n",
      "Epoch 24::Minibatch 473::LR 0.0469230769231 --> Loss 0.00228246529897\n",
      "Epoch 24::Minibatch 474::LR 0.0469230769231 --> Loss 0.000692291508118\n",
      "Epoch 24::Minibatch 475::LR 0.0469230769231 --> Loss 0.00494499723117\n",
      "Epoch 24::Minibatch 476::LR 0.0469230769231 --> Loss 0.00773150205612\n",
      "Epoch 24::Minibatch 477::LR 0.0469230769231 --> Loss 0.000918982128302\n",
      "Epoch 24::Minibatch 478::LR 0.0469230769231 --> Loss 0.00243080238501\n",
      "Epoch 24::Minibatch 479::LR 0.0469230769231 --> Loss 0.00196131229401\n",
      "Epoch 24::Minibatch 480::LR 0.0469230769231 --> Loss 0.00152186801036\n",
      "Epoch 24::Minibatch 481::LR 0.0469230769231 --> Loss 0.000955903232098\n",
      "Epoch 24::Minibatch 482::LR 0.0469230769231 --> Loss 0.00207880834738\n",
      "Epoch 24::Minibatch 483::LR 0.0469230769231 --> Loss 0.00308274328709\n",
      "Epoch 24::Minibatch 484::LR 0.0469230769231 --> Loss 0.00346175869306\n",
      "Epoch 24::Minibatch 485::LR 0.0469230769231 --> Loss 0.000759396503369\n",
      "Epoch 24::Minibatch 486::LR 0.0469230769231 --> Loss 0.0028534334898\n",
      "Epoch 24::Minibatch 487::LR 0.0469230769231 --> Loss 0.00332020362218\n",
      "Epoch 24::Minibatch 488::LR 0.0469230769231 --> Loss 0.00203077594439\n",
      "Epoch 24::Minibatch 489::LR 0.0469230769231 --> Loss 0.00312464515368\n",
      "Epoch 24::Minibatch 490::LR 0.0469230769231 --> Loss 0.000409419561426\n",
      "Epoch 24::Minibatch 491::LR 0.0469230769231 --> Loss 0.00341643730799\n",
      "Epoch 24::Minibatch 492::LR 0.0469230769231 --> Loss 0.0030605785052\n",
      "Epoch 24::Minibatch 493::LR 0.0469230769231 --> Loss 0.00302981197834\n",
      "Epoch 24::Minibatch 494::LR 0.0469230769231 --> Loss 0.000734482208888\n",
      "Epoch 24::Minibatch 495::LR 0.0469230769231 --> Loss 0.00184971868992\n",
      "Epoch 24::Minibatch 496::LR 0.0469230769231 --> Loss 0.00281826714675\n",
      "Epoch 24::Minibatch 497::LR 0.0469230769231 --> Loss 0.000919057428837\n",
      "Epoch 24::Minibatch 498::LR 0.0469230769231 --> Loss 0.000553643306096\n",
      "Epoch 24::Minibatch 499::LR 0.0469230769231 --> Loss 0.00348966598511\n",
      "Epoch 24::Minibatch 500::LR 0.0469230769231 --> Loss 0.00143270810445\n",
      "Epoch 24::Minibatch 501::LR 0.0469230769231 --> Loss 0.002117583553\n",
      "Epoch 24::Minibatch 502::LR 0.0469230769231 --> Loss 0.00377195398013\n",
      "Epoch 24::Minibatch 503::LR 0.0469230769231 --> Loss 0.00731082677841\n",
      "Epoch 24::Minibatch 504::LR 0.0469230769231 --> Loss 0.00712386608124\n",
      "Epoch 24::Minibatch 505::LR 0.0469230769231 --> Loss 0.00410042802493\n",
      "Epoch 24::Minibatch 506::LR 0.0469230769231 --> Loss 0.00337490280469\n",
      "Epoch 24::Minibatch 507::LR 0.0469230769231 --> Loss 0.00588682015737\n",
      "Epoch 24::Minibatch 508::LR 0.0469230769231 --> Loss 0.0034003897508\n",
      "Epoch 24::Minibatch 509::LR 0.0469230769231 --> Loss 0.00438378135363\n",
      "Epoch 24::Minibatch 510::LR 0.0469230769231 --> Loss 0.00446657657623\n",
      "Epoch 24::Minibatch 511::LR 0.0469230769231 --> Loss 0.00395456234614\n",
      "Epoch 24::Minibatch 512::LR 0.0469230769231 --> Loss 0.00268253902594\n",
      "Epoch 24::Minibatch 513::LR 0.0469230769231 --> Loss 0.000614907989899\n",
      "Epoch 24::Minibatch 514::LR 0.0469230769231 --> Loss 0.00265193025271\n",
      "Epoch 24::Minibatch 515::LR 0.0469230769231 --> Loss 0.00299926638603\n",
      "Epoch 24::Minibatch 516::LR 0.0469230769231 --> Loss 0.00398098786672\n",
      "Epoch 24::Minibatch 517::LR 0.0469230769231 --> Loss 0.0035651020209\n",
      "Epoch 24::Minibatch 518::LR 0.0469230769231 --> Loss 0.00257840752602\n",
      "Epoch 24::Minibatch 519::LR 0.0469230769231 --> Loss 0.00349814375242\n",
      "Epoch 24::Minibatch 520::LR 0.0469230769231 --> Loss 0.00544746756554\n",
      "Epoch 24::Minibatch 521::LR 0.0469230769231 --> Loss 0.00553868452708\n",
      "Epoch 24::Minibatch 522::LR 0.0469230769231 --> Loss 0.00755865653356\n",
      "Epoch 24::Minibatch 523::LR 0.0469230769231 --> Loss 0.000631168484688\n",
      "Epoch 24::Minibatch 524::LR 0.0469230769231 --> Loss 0.0014062171181\n",
      "Epoch 24::Minibatch 525::LR 0.0469230769231 --> Loss 0.00314059217771\n",
      "Epoch 24::Minibatch 526::LR 0.0469230769231 --> Loss 0.00384783585866\n",
      "Epoch 24::Minibatch 527::LR 0.0469230769231 --> Loss 0.00217919925849\n",
      "Epoch 24::Minibatch 528::LR 0.0469230769231 --> Loss 0.000974976122379\n",
      "Epoch 24::Minibatch 529::LR 0.0469230769231 --> Loss 0.00394041657448\n",
      "Epoch 24::Minibatch 530::LR 0.0469230769231 --> Loss 0.00393878817558\n",
      "Epoch 24::Minibatch 531::LR 0.0469230769231 --> Loss 0.00347165465355\n",
      "Epoch 24::Minibatch 532::LR 0.0469230769231 --> Loss 0.0026447614034\n",
      "Epoch 24::Minibatch 533::LR 0.0469230769231 --> Loss 0.0049137767156\n",
      "Epoch 24::Minibatch 534::LR 0.0469230769231 --> Loss 0.00373386820157\n",
      "Epoch 24::Minibatch 535::LR 0.0469230769231 --> Loss 0.00326549510161\n",
      "Epoch 24::Minibatch 536::LR 0.0469230769231 --> Loss 0.00210587879022\n",
      "Epoch 24::Minibatch 537::LR 0.0469230769231 --> Loss 0.000598139166832\n",
      "Epoch 24::Minibatch 538::LR 0.0469230769231 --> Loss 0.00165718962749\n",
      "Epoch 24::Minibatch 539::LR 0.0469230769231 --> Loss 0.00336598753929\n",
      "Epoch 24::Minibatch 540::LR 0.0469230769231 --> Loss 0.00340752879779\n",
      "Epoch 24::Minibatch 541::LR 0.0469230769231 --> Loss 0.00287015179793\n",
      "Epoch 24::Minibatch 542::LR 0.0469230769231 --> Loss 0.00246416548888\n",
      "Epoch 24::Minibatch 543::LR 0.0469230769231 --> Loss 0.00264777223269\n",
      "Epoch 24::Minibatch 544::LR 0.0469230769231 --> Loss 0.00394417842229\n",
      "Epoch 24::Minibatch 545::LR 0.0469230769231 --> Loss 0.00200944979986\n",
      "Epoch 24::Minibatch 546::LR 0.0469230769231 --> Loss 0.000654260416826\n",
      "Epoch 24::Minibatch 547::LR 0.0469230769231 --> Loss 0.00259749650955\n",
      "Epoch 24::Minibatch 548::LR 0.0469230769231 --> Loss 0.00351989706357\n",
      "Epoch 24::Minibatch 549::LR 0.0469230769231 --> Loss 0.00874963839849\n",
      "Epoch 24::Minibatch 550::LR 0.0469230769231 --> Loss 0.00117571800947\n",
      "Epoch 24::Minibatch 551::LR 0.0469230769231 --> Loss 0.00245067675908\n",
      "Epoch 24::Minibatch 552::LR 0.0469230769231 --> Loss 0.00347780267398\n",
      "Epoch 24::Minibatch 553::LR 0.0469230769231 --> Loss 0.00307227532069\n",
      "Epoch 24::Minibatch 554::LR 0.0469230769231 --> Loss 0.00368510564168\n",
      "Epoch 24::Minibatch 555::LR 0.0469230769231 --> Loss 0.000957260131836\n",
      "Epoch 24::Minibatch 556::LR 0.0469230769231 --> Loss 0.00194902857145\n",
      "Epoch 24::Minibatch 557::LR 0.0469230769231 --> Loss 0.00240434924761\n",
      "Epoch 24::Minibatch 558::LR 0.0469230769231 --> Loss 0.00364515105883\n",
      "Epoch 24::Minibatch 559::LR 0.0469230769231 --> Loss 0.0036830997467\n",
      "Epoch 24::Minibatch 560::LR 0.0469230769231 --> Loss 0.00306586583455\n",
      "Epoch 24::Minibatch 561::LR 0.0469230769231 --> Loss 0.00265119373798\n",
      "Epoch 24::Minibatch 562::LR 0.0469230769231 --> Loss 0.00235157509645\n",
      "Epoch 24::Minibatch 563::LR 0.0469230769231 --> Loss 0.00399160027504\n",
      "Epoch 24::Minibatch 564::LR 0.0469230769231 --> Loss 0.00307295799255\n",
      "Epoch 24::Minibatch 565::LR 0.0469230769231 --> Loss 0.00362186193466\n",
      "Epoch 24::Minibatch 566::LR 0.0469230769231 --> Loss 0.00221991797288\n",
      "Epoch 24::Minibatch 567::LR 0.0469230769231 --> Loss 0.00254116714001\n",
      "Epoch 24::Minibatch 568::LR 0.0469230769231 --> Loss 0.00177261312803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 569::LR 0.0469230769231 --> Loss 0.000561662813028\n",
      "Epoch 24::Minibatch 570::LR 0.0469230769231 --> Loss 0.00165819873412\n",
      "Epoch 24::Minibatch 571::LR 0.0469230769231 --> Loss 0.00213479558627\n",
      "Epoch 24::Minibatch 572::LR 0.0469230769231 --> Loss 0.00228646874428\n",
      "Epoch 24::Minibatch 573::LR 0.0469230769231 --> Loss 0.00147075901429\n",
      "Epoch 24::Minibatch 574::LR 0.0469230769231 --> Loss 0.00104575981696\n",
      "Epoch 24::Minibatch 575::LR 0.0469230769231 --> Loss 0.00174781958262\n",
      "Epoch 24::Minibatch 576::LR 0.0469230769231 --> Loss 0.00206488668919\n",
      "Epoch 24::Minibatch 577::LR 0.0469230769231 --> Loss 0.00163144061963\n",
      "Epoch 24::Minibatch 578::LR 0.0469230769231 --> Loss 0.00127484281858\n",
      "Epoch 24::Minibatch 579::LR 0.0469230769231 --> Loss 0.00118986765544\n",
      "Epoch 24::Minibatch 580::LR 0.0469230769231 --> Loss 0.00192931135496\n",
      "Epoch 24::Minibatch 581::LR 0.0469230769231 --> Loss 0.00171018123627\n",
      "Epoch 24::Minibatch 582::LR 0.0469230769231 --> Loss 0.00415595293045\n",
      "Epoch 24::Minibatch 583::LR 0.0469230769231 --> Loss 0.000946409900983\n",
      "Epoch 24::Minibatch 584::LR 0.0469230769231 --> Loss 0.00130737493436\n",
      "Epoch 24::Minibatch 585::LR 0.0469230769231 --> Loss 0.00410530765851\n",
      "Epoch 24::Minibatch 586::LR 0.0469230769231 --> Loss 0.00384585777918\n",
      "Epoch 24::Minibatch 587::LR 0.0469230769231 --> Loss 0.00112024605274\n",
      "Epoch 24::Minibatch 588::LR 0.0469230769231 --> Loss 0.00138845036427\n",
      "Epoch 24::Minibatch 589::LR 0.0469230769231 --> Loss 0.00275740762552\n",
      "Epoch 24::Minibatch 590::LR 0.0469230769231 --> Loss 0.00186501463254\n",
      "Epoch 24::Minibatch 591::LR 0.0469230769231 --> Loss 0.00285487830639\n",
      "Epoch 24::Minibatch 592::LR 0.0469230769231 --> Loss 0.00116356452306\n",
      "Epoch 24::Minibatch 593::LR 0.0469230769231 --> Loss 0.00252938091755\n",
      "Epoch 24::Minibatch 594::LR 0.0469230769231 --> Loss 0.00265227675438\n",
      "Epoch 24::Minibatch 595::LR 0.0469230769231 --> Loss 0.00304402351379\n",
      "Epoch 24::Minibatch 596::LR 0.0469230769231 --> Loss 0.00188718795776\n",
      "Epoch 24::Minibatch 597::LR 0.0469230769231 --> Loss 0.00118026057879\n",
      "Epoch 24::Minibatch 598::LR 0.0469230769231 --> Loss 0.00289561947187\n",
      "Epoch 24::Minibatch 599::LR 0.0469230769231 --> Loss 0.00182173907757\n",
      "Epoch 24::Minibatch 600::LR 0.0469230769231 --> Loss 0.00217064479987\n",
      "Epoch 24::Minibatch 601::LR 0.0469230769231 --> Loss 0.00380553762118\n",
      "Epoch 24::Minibatch 602::LR 0.0469230769231 --> Loss 0.00210000733534\n",
      "Epoch 24::Minibatch 603::LR 0.0469230769231 --> Loss 0.00263023793697\n",
      "Epoch 24::Minibatch 604::LR 0.0469230769231 --> Loss 0.00164300898711\n",
      "Epoch 24::Minibatch 605::LR 0.0469230769231 --> Loss 0.00232595761617\n",
      "Epoch 24::Minibatch 606::LR 0.0469230769231 --> Loss 0.00188961366812\n",
      "Epoch 24::Minibatch 607::LR 0.0469230769231 --> Loss 0.000834234555562\n",
      "Epoch 24::Minibatch 608::LR 0.0469230769231 --> Loss 0.00156897505124\n",
      "Epoch 24::Minibatch 609::LR 0.0469230769231 --> Loss 0.00240878085295\n",
      "Epoch 24::Minibatch 610::LR 0.0469230769231 --> Loss 0.00403080781301\n",
      "Epoch 24::Minibatch 611::LR 0.0469230769231 --> Loss 0.00263740897179\n",
      "Epoch 24::Minibatch 612::LR 0.0469230769231 --> Loss 0.000475788861513\n",
      "Epoch 24::Minibatch 613::LR 0.0469230769231 --> Loss 0.00131061116854\n",
      "Epoch 24::Minibatch 614::LR 0.0469230769231 --> Loss 0.00242757836978\n",
      "Epoch 24::Minibatch 615::LR 0.0469230769231 --> Loss 0.00166940232118\n",
      "Epoch 24::Minibatch 616::LR 0.0469230769231 --> Loss 0.0009214797616\n",
      "Epoch 24::Minibatch 617::LR 0.0469230769231 --> Loss 0.000495489736398\n",
      "Epoch 24::Minibatch 618::LR 0.0469230769231 --> Loss 0.00281132042408\n",
      "Epoch 24::Minibatch 619::LR 0.0469230769231 --> Loss 0.00192670881748\n",
      "Epoch 24::Minibatch 620::LR 0.0469230769231 --> Loss 0.00170526762803\n",
      "Epoch 24::Minibatch 621::LR 0.0469230769231 --> Loss 0.000849232872327\n",
      "Epoch 24::Minibatch 622::LR 0.0469230769231 --> Loss 0.000788231492043\n",
      "Epoch 24::Minibatch 623::LR 0.0469230769231 --> Loss 0.00222101032734\n",
      "Epoch 24::Minibatch 624::LR 0.0469230769231 --> Loss 0.00178981602192\n",
      "Epoch 24::Minibatch 625::LR 0.0469230769231 --> Loss 0.00278720676899\n",
      "Epoch 24::Minibatch 626::LR 0.0469230769231 --> Loss 0.00397478977839\n",
      "Epoch 24::Minibatch 627::LR 0.0469230769231 --> Loss 0.00129090189934\n",
      "Epoch 24::Minibatch 628::LR 0.0469230769231 --> Loss 0.00088615745306\n",
      "Epoch 24::Minibatch 629::LR 0.0469230769231 --> Loss 0.00323253134886\n",
      "Epoch 24::Minibatch 630::LR 0.0469230769231 --> Loss 0.00315672755241\n",
      "Epoch 24::Minibatch 631::LR 0.0469230769231 --> Loss 0.00569858749708\n",
      "Epoch 24::Minibatch 632::LR 0.0469230769231 --> Loss 0.000791207055251\n",
      "Epoch 24::Minibatch 633::LR 0.0469230769231 --> Loss 0.00163592547178\n",
      "Epoch 24::Minibatch 634::LR 0.0469230769231 --> Loss 0.00321787854036\n",
      "Epoch 24::Minibatch 635::LR 0.0469230769231 --> Loss 0.00547698537509\n",
      "Epoch 24::Minibatch 636::LR 0.0469230769231 --> Loss 0.00480075558027\n",
      "Epoch 24::Minibatch 637::LR 0.0469230769231 --> Loss 0.000741683989763\n",
      "Epoch 24::Minibatch 638::LR 0.0469230769231 --> Loss 0.0014918979009\n",
      "Epoch 24::Minibatch 639::LR 0.0469230769231 --> Loss 0.003238859574\n",
      "Epoch 24::Minibatch 640::LR 0.0469230769231 --> Loss 0.00477942705154\n",
      "Epoch 24::Minibatch 641::LR 0.0469230769231 --> Loss 0.00308648467064\n",
      "Epoch 24::Minibatch 642::LR 0.0469230769231 --> Loss 0.000535881072283\n",
      "Epoch 24::Minibatch 643::LR 0.0469230769231 --> Loss 0.00232543269793\n",
      "Epoch 24::Minibatch 644::LR 0.0469230769231 --> Loss 0.00392065644264\n",
      "Epoch 24::Minibatch 645::LR 0.0469230769231 --> Loss 0.00431212504705\n",
      "Epoch 24::Minibatch 646::LR 0.0469230769231 --> Loss 0.00150290757418\n",
      "Epoch 24::Minibatch 647::LR 0.0469230769231 --> Loss 0.000489394913117\n",
      "Epoch 24::Minibatch 648::LR 0.0469230769231 --> Loss 0.00286690553029\n",
      "Epoch 24::Minibatch 649::LR 0.0469230769231 --> Loss 0.00338589310646\n",
      "Epoch 24::Minibatch 650::LR 0.0469230769231 --> Loss 0.00325085977713\n",
      "Epoch 24::Minibatch 651::LR 0.0469230769231 --> Loss 0.00135554661353\n",
      "Epoch 24::Minibatch 652::LR 0.0469230769231 --> Loss 0.000786680181821\n",
      "Epoch 24::Minibatch 653::LR 0.0469230769231 --> Loss 0.00283103108406\n",
      "Epoch 24::Minibatch 654::LR 0.0469230769231 --> Loss 0.00312660475572\n",
      "Epoch 24::Minibatch 655::LR 0.0469230769231 --> Loss 0.00355817278226\n",
      "Epoch 24::Minibatch 656::LR 0.0469230769231 --> Loss 0.000755023310582\n",
      "Epoch 24::Minibatch 657::LR 0.0469230769231 --> Loss 0.00225982785225\n",
      "Epoch 24::Minibatch 658::LR 0.0469230769231 --> Loss 0.00469626625379\n",
      "Epoch 24::Minibatch 659::LR 0.0469230769231 --> Loss 0.00226177891095\n",
      "Epoch 24::Minibatch 660::LR 0.0469230769231 --> Loss 0.00262141644955\n",
      "Epoch 24::Minibatch 661::LR 0.0469230769231 --> Loss 0.00238012989362\n",
      "Epoch 24::Minibatch 662::LR 0.0469230769231 --> Loss 0.00180423180262\n",
      "Epoch 24::Minibatch 663::LR 0.0469230769231 --> Loss 0.00369188785553\n",
      "Epoch 24::Minibatch 664::LR 0.0469230769231 --> Loss 0.00328745563825\n",
      "Epoch 24::Minibatch 665::LR 0.0469230769231 --> Loss 0.000710153083007\n",
      "Epoch 24::Minibatch 666::LR 0.0469230769231 --> Loss 0.00390978892644\n",
      "Epoch 24::Minibatch 667::LR 0.0469230769231 --> Loss 0.00254506011804\n",
      "Epoch 24::Minibatch 668::LR 0.0469230769231 --> Loss 0.00664160132408\n",
      "Epoch 24::Minibatch 669::LR 0.0469230769231 --> Loss 0.0010903425018\n",
      "Epoch 24::Minibatch 670::LR 0.0469230769231 --> Loss 0.00134003976981\n",
      "Epoch 24::Minibatch 671::LR 0.0469230769231 --> Loss 0.00521615465482\n",
      "Epoch 24::Minibatch 672::LR 0.0469230769231 --> Loss 0.00355502883593\n",
      "Epoch 24::Minibatch 673::LR 0.0469230769231 --> Loss 0.00161538849274\n",
      "Epoch 24::Minibatch 674::LR 0.0469230769231 --> Loss 0.000510456413031\n",
      "Epoch 24::Minibatch 675::LR 0.0469230769231 --> Loss 0.00218724131584\n",
      "Epoch 24::Minibatch 676::LR 0.0469230769231 --> Loss 0.00213650087516\n",
      "Epoch 24::Minibatch 677::LR 0.0469230769231 --> Loss 0.00275034169356\n",
      "Epoch 24::Minibatch 678::LR 0.0469230769231 --> Loss 0.00189548909664\n",
      "Epoch 24::Minibatch 679::LR 0.0469230769231 --> Loss 0.00340223749479\n",
      "Epoch 24::Minibatch 680::LR 0.0469230769231 --> Loss 0.00213351607323\n",
      "Epoch 24::Minibatch 681::LR 0.0469230769231 --> Loss 0.00241607864698\n",
      "Epoch 24::Minibatch 682::LR 0.0469230769231 --> Loss 0.000760707755884\n",
      "Epoch 24::Minibatch 683::LR 0.0469230769231 --> Loss 0.00234338581562\n",
      "Epoch 24::Minibatch 684::LR 0.0469230769231 --> Loss 0.0023428752025\n",
      "Epoch 24::Minibatch 685::LR 0.0469230769231 --> Loss 0.00286188900471\n",
      "Epoch 24::Minibatch 686::LR 0.0469230769231 --> Loss 0.00157131423553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 687::LR 0.0469230769231 --> Loss 0.000862773458163\n",
      "Epoch 24::Minibatch 688::LR 0.0469230769231 --> Loss 0.00277808507284\n",
      "Epoch 24::Minibatch 689::LR 0.0469230769231 --> Loss 0.00250073611736\n",
      "Epoch 24::Minibatch 690::LR 0.0469230769231 --> Loss 0.00190092682838\n",
      "Epoch 24::Minibatch 691::LR 0.0469230769231 --> Loss 0.000658027976751\n",
      "Epoch 24::Minibatch 692::LR 0.0469230769231 --> Loss 0.0024521680673\n",
      "Epoch 24::Minibatch 693::LR 0.0469230769231 --> Loss 0.00259310245514\n",
      "Epoch 24::Minibatch 694::LR 0.0469230769231 --> Loss 0.00301034450531\n",
      "Epoch 24::Minibatch 695::LR 0.0469230769231 --> Loss 0.00176805853844\n",
      "Epoch 24::Minibatch 696::LR 0.0469230769231 --> Loss 0.00204253653685\n",
      "Epoch 24::Minibatch 697::LR 0.0469230769231 --> Loss 0.00140321711699\n",
      "Epoch 24::Minibatch 698::LR 0.0469230769231 --> Loss 0.00164879143238\n",
      "Epoch 24::Minibatch 699::LR 0.0469230769231 --> Loss 0.00378455082575\n",
      "Epoch 24::Minibatch 700::LR 0.0469230769231 --> Loss 0.00263014872869\n",
      "Epoch 24::Minibatch 701::LR 0.0469230769231 --> Loss 0.00193576733271\n",
      "Epoch 24::Minibatch 702::LR 0.0469230769231 --> Loss 0.00166429231564\n",
      "Epoch 24::Minibatch 703::LR 0.0469230769231 --> Loss 0.00433120171229\n",
      "Epoch 24::Minibatch 704::LR 0.0469230769231 --> Loss 0.00180381973584\n",
      "Epoch 24::Minibatch 705::LR 0.0469230769231 --> Loss 0.00286125898361\n",
      "Epoch 24::Minibatch 706::LR 0.0469230769231 --> Loss 0.0022290935119\n",
      "Epoch 24::Minibatch 707::LR 0.0469230769231 --> Loss 0.00118168224891\n",
      "Epoch 24::Minibatch 708::LR 0.0469230769231 --> Loss 0.00173207680384\n",
      "Epoch 24::Minibatch 709::LR 0.0469230769231 --> Loss 0.00167697409789\n",
      "Epoch 24::Minibatch 710::LR 0.0469230769231 --> Loss 0.00255534569422\n",
      "Epoch 24::Minibatch 711::LR 0.0469230769231 --> Loss 0.00194849888484\n",
      "Epoch 24::Minibatch 712::LR 0.0469230769231 --> Loss 0.00134418477615\n",
      "Epoch 24::Minibatch 713::LR 0.0469230769231 --> Loss 0.00177718301614\n",
      "Epoch 24::Minibatch 714::LR 0.0469230769231 --> Loss 0.00280757506688\n",
      "Epoch 24::Minibatch 715::LR 0.0469230769231 --> Loss 0.00293213407199\n",
      "Epoch 24::Minibatch 716::LR 0.0469230769231 --> Loss 0.00163804401954\n",
      "Epoch 24::Minibatch 717::LR 0.0469230769231 --> Loss 0.00164146194855\n",
      "Epoch 24::Minibatch 718::LR 0.0469230769231 --> Loss 0.00126518388589\n",
      "Epoch 24::Minibatch 719::LR 0.0469230769231 --> Loss 0.00169593652089\n",
      "Epoch 24::Minibatch 720::LR 0.0469230769231 --> Loss 0.00264561613401\n",
      "Epoch 24::Minibatch 721::LR 0.0469230769231 --> Loss 0.000610186606646\n",
      "Epoch 24::Minibatch 722::LR 0.0469230769231 --> Loss 0.00469087362289\n",
      "Epoch 24::Minibatch 723::LR 0.0469230769231 --> Loss 0.00487108667692\n",
      "Epoch 24::Minibatch 724::LR 0.0469230769231 --> Loss 0.000965308845043\n",
      "Epoch 24::Minibatch 725::LR 0.0469230769231 --> Loss 0.00211363693078\n",
      "Epoch 24::Minibatch 726::LR 0.0469230769231 --> Loss 0.00410841504733\n",
      "Epoch 24::Minibatch 727::LR 0.0469230769231 --> Loss 0.00318814198176\n",
      "Epoch 24::Minibatch 728::LR 0.0469230769231 --> Loss 0.000642350961765\n",
      "Epoch 24::Minibatch 729::LR 0.0469230769231 --> Loss 0.000730307648579\n",
      "Epoch 24::Minibatch 730::LR 0.0469230769231 --> Loss 0.00288035213947\n",
      "Epoch 24::Minibatch 731::LR 0.0469230769231 --> Loss 0.00256183723609\n",
      "Epoch 24::Minibatch 732::LR 0.0469230769231 --> Loss 0.00212965369225\n",
      "Epoch 24::Minibatch 733::LR 0.0469230769231 --> Loss 0.000634247461955\n",
      "Epoch 24::Minibatch 734::LR 0.0469230769231 --> Loss 0.00168535987536\n",
      "Epoch 24::Minibatch 735::LR 0.0469230769231 --> Loss 0.00240839878718\n",
      "Epoch 24::Minibatch 736::LR 0.0469230769231 --> Loss 0.00347307125727\n",
      "Epoch 24::Minibatch 737::LR 0.0469230769231 --> Loss 0.00300829907258\n",
      "Epoch 24::Minibatch 738::LR 0.0469230769231 --> Loss 0.00148965070645\n",
      "Epoch 24::Minibatch 739::LR 0.0469230769231 --> Loss 0.00242795030276\n",
      "Epoch 24::Minibatch 740::LR 0.0469230769231 --> Loss 0.00380919774373\n",
      "Epoch 24::Minibatch 741::LR 0.0469230769231 --> Loss 0.00259841839472\n",
      "Epoch 24::Minibatch 742::LR 0.0469230769231 --> Loss 0.00209958434105\n",
      "Epoch 24::Minibatch 743::LR 0.0469230769231 --> Loss 0.00145241638025\n",
      "Epoch 24::Minibatch 744::LR 0.0469230769231 --> Loss 0.00183004597823\n",
      "Epoch 24::Minibatch 745::LR 0.0469230769231 --> Loss 0.00280355075995\n",
      "Epoch 24::Minibatch 746::LR 0.0469230769231 --> Loss 0.00291338245074\n",
      "Epoch 24::Minibatch 747::LR 0.0469230769231 --> Loss 0.00177791833878\n",
      "Epoch 24::Minibatch 748::LR 0.0469230769231 --> Loss 0.000620760122935\n",
      "Epoch 24::Minibatch 749::LR 0.0469230769231 --> Loss 0.00165909101566\n",
      "Epoch 24::Minibatch 750::LR 0.0469230769231 --> Loss 0.00243973294894\n",
      "Epoch 24::Minibatch 751::LR 0.0469230769231 --> Loss 0.00282863080502\n",
      "Epoch 24::Minibatch 752::LR 0.0469230769231 --> Loss 0.00130593458811\n",
      "Epoch 24::Minibatch 753::LR 0.0469230769231 --> Loss 0.00220282018185\n",
      "Epoch 24::Minibatch 754::LR 0.0469230769231 --> Loss 0.00240707755089\n",
      "Epoch 24::Minibatch 755::LR 0.0469230769231 --> Loss 0.00266416509946\n",
      "Epoch 24::Minibatch 756::LR 0.0469230769231 --> Loss 0.00134174476067\n",
      "Epoch 24::Minibatch 757::LR 0.0469230769231 --> Loss 0.000679977039496\n",
      "Epoch 24::Minibatch 758::LR 0.0469230769231 --> Loss 0.00158427655697\n",
      "Epoch 24::Minibatch 759::LR 0.0469230769231 --> Loss 0.0035944489638\n",
      "Epoch 24::Minibatch 760::LR 0.0469230769231 --> Loss 0.00288317024708\n",
      "Epoch 24::Minibatch 761::LR 0.0469230769231 --> Loss 0.00597512404124\n",
      "Epoch 24::Minibatch 762::LR 0.0469230769231 --> Loss 0.00367100040118\n",
      "Epoch 24::Minibatch 763::LR 0.0469230769231 --> Loss 0.00349581003189\n",
      "Epoch 24::Minibatch 764::LR 0.0469230769231 --> Loss 0.00311141033967\n",
      "Epoch 24::Minibatch 765::LR 0.0469230769231 --> Loss 0.00127878000339\n",
      "Epoch 24::Minibatch 766::LR 0.0469230769231 --> Loss 0.00229074319204\n",
      "Epoch 24::Minibatch 767::LR 0.0469230769231 --> Loss 0.00488766074181\n",
      "Epoch 24::Minibatch 768::LR 0.0469230769231 --> Loss 0.00365448713303\n",
      "Epoch 24::Minibatch 769::LR 0.0469230769231 --> Loss 0.00186302979787\n",
      "Epoch 24::Minibatch 770::LR 0.0469230769231 --> Loss 0.00148469130198\n",
      "Epoch 24::Minibatch 771::LR 0.0469230769231 --> Loss 0.00354146162669\n",
      "Epoch 24::Minibatch 772::LR 0.0469230769231 --> Loss 0.00350775559743\n",
      "Epoch 24::Minibatch 773::LR 0.0469230769231 --> Loss 0.00315552314123\n",
      "Epoch 24::Minibatch 774::LR 0.0469230769231 --> Loss 0.00183422307173\n",
      "Epoch 24::Minibatch 775::LR 0.0469230769231 --> Loss 0.00351719935735\n",
      "Epoch 24::Minibatch 776::LR 0.0469230769231 --> Loss 0.00365052183469\n",
      "Epoch 24::Minibatch 777::LR 0.0469230769231 --> Loss 0.00671528577805\n",
      "Epoch 24::Minibatch 778::LR 0.0469230769231 --> Loss 0.00827721675237\n",
      "Epoch 24::Minibatch 779::LR 0.0469230769231 --> Loss 0.00241889377435\n",
      "Epoch 24::Minibatch 780::LR 0.0469230769231 --> Loss 0.00154957850774\n",
      "Epoch 24::Minibatch 781::LR 0.0469230769231 --> Loss 0.00344656984011\n",
      "Epoch 24::Minibatch 782::LR 0.0469230769231 --> Loss 0.00384158611298\n",
      "Epoch 24::Minibatch 783::LR 0.0469230769231 --> Loss 0.00227952917417\n",
      "Epoch 24::Minibatch 784::LR 0.0469230769231 --> Loss 0.000706920226415\n",
      "Epoch 24::Minibatch 785::LR 0.0469230769231 --> Loss 0.00325402816137\n",
      "Epoch 24::Minibatch 786::LR 0.0469230769231 --> Loss 0.00341362833977\n",
      "Epoch 24::Minibatch 787::LR 0.0469230769231 --> Loss 0.00261006514231\n",
      "Epoch 24::Minibatch 788::LR 0.0469230769231 --> Loss 0.00235413312912\n",
      "Epoch 24::Minibatch 789::LR 0.0469230769231 --> Loss 0.000729253043731\n",
      "Epoch 24::Minibatch 790::LR 0.0469230769231 --> Loss 0.00312839726607\n",
      "Epoch 24::Minibatch 791::LR 0.0469230769231 --> Loss 0.00340037385623\n",
      "Epoch 24::Minibatch 792::LR 0.0469230769231 --> Loss 0.00301347672939\n",
      "Epoch 24::Minibatch 793::LR 0.0469230769231 --> Loss 0.00169307172298\n",
      "Epoch 24::Minibatch 794::LR 0.0469230769231 --> Loss 0.000994022190571\n",
      "Epoch 24::Minibatch 795::LR 0.0469230769231 --> Loss 0.00278588632743\n",
      "Epoch 24::Minibatch 796::LR 0.0469230769231 --> Loss 0.00518597841263\n",
      "Epoch 24::Minibatch 797::LR 0.0469230769231 --> Loss 0.00634566346804\n",
      "Epoch 24::Minibatch 798::LR 0.0469230769231 --> Loss 0.00312730967999\n",
      "Epoch 24::Minibatch 799::LR 0.0469230769231 --> Loss 0.00228593925635\n",
      "Epoch 24::Minibatch 800::LR 0.0469230769231 --> Loss 0.00200811982155\n",
      "Epoch 24::Minibatch 801::LR 0.0469230769231 --> Loss 0.00405014157295\n",
      "Epoch 24::Minibatch 802::LR 0.0469230769231 --> Loss 0.00124825656414\n",
      "Epoch 24::Minibatch 803::LR 0.0469230769231 --> Loss 0.00290701965491\n",
      "Epoch 24::Minibatch 804::LR 0.0469230769231 --> Loss 0.00211420158545\n",
      "Epoch 24::Minibatch 805::LR 0.0469230769231 --> Loss 0.0022165175279\n",
      "Epoch 24::Minibatch 806::LR 0.0469230769231 --> Loss 0.00338758269946\n",
      "Epoch 24::Minibatch 807::LR 0.0469230769231 --> Loss 0.00305272261302\n",
      "Epoch 24::Minibatch 808::LR 0.0469230769231 --> Loss 0.00271942098935\n",
      "Epoch 24::Minibatch 809::LR 0.0469230769231 --> Loss 0.00334488670031\n",
      "Epoch 24::Minibatch 810::LR 0.0469230769231 --> Loss 0.00459507743518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 811::LR 0.0469230769231 --> Loss 0.00436736146609\n",
      "Epoch 24::Minibatch 812::LR 0.0469230769231 --> Loss 0.00399992346764\n",
      "Epoch 24::Minibatch 813::LR 0.0469230769231 --> Loss 0.00344966888428\n",
      "Epoch 24::Minibatch 814::LR 0.0469230769231 --> Loss 0.00159908950329\n",
      "Epoch 24::Minibatch 815::LR 0.0469230769231 --> Loss 0.00362010081609\n",
      "Epoch 24::Minibatch 816::LR 0.0469230769231 --> Loss 0.00404433608055\n",
      "Epoch 24::Minibatch 817::LR 0.0469230769231 --> Loss 0.00530219554901\n",
      "Epoch 24::Minibatch 818::LR 0.0469230769231 --> Loss 0.00125260194143\n",
      "Epoch 24::Minibatch 819::LR 0.0469230769231 --> Loss 0.000707540363073\n",
      "Epoch 24::Minibatch 820::LR 0.0469230769231 --> Loss 0.0052012248834\n",
      "Epoch 24::Minibatch 821::LR 0.0469230769231 --> Loss 0.00308136820793\n",
      "Epoch 24::Minibatch 822::LR 0.0469230769231 --> Loss 0.00366645137469\n",
      "Epoch 24::Minibatch 823::LR 0.0469230769231 --> Loss 0.00127587556839\n",
      "Epoch 24::Minibatch 824::LR 0.0469230769231 --> Loss 0.00136336565018\n",
      "Epoch 24::Minibatch 825::LR 0.0469230769231 --> Loss 0.00366082111994\n",
      "Epoch 24::Minibatch 826::LR 0.0469230769231 --> Loss 0.00411637187004\n",
      "Epoch 24::Minibatch 827::LR 0.0469230769231 --> Loss 0.00206045130889\n",
      "Epoch 24::Minibatch 828::LR 0.0469230769231 --> Loss 0.000498654594024\n",
      "Epoch 24::Minibatch 829::LR 0.0469230769231 --> Loss 0.00230472385883\n",
      "Epoch 24::Minibatch 830::LR 0.0469230769231 --> Loss 0.00417400956154\n",
      "Epoch 24::Minibatch 831::LR 0.0469230769231 --> Loss 0.00247250894705\n",
      "Epoch 24::Minibatch 832::LR 0.0469230769231 --> Loss 0.00216886401176\n",
      "Epoch 24::Minibatch 833::LR 0.0469230769231 --> Loss 0.00182857076327\n",
      "Epoch 24::Minibatch 834::LR 0.0469230769231 --> Loss 0.000777683009704\n",
      "Epoch 24::Minibatch 835::LR 0.0469230769231 --> Loss 0.00375762939453\n",
      "Epoch 24::Minibatch 836::LR 0.0469230769231 --> Loss 0.00362263719241\n",
      "Epoch 24::Minibatch 837::LR 0.0469230769231 --> Loss 0.00219992041588\n",
      "Epoch 24::Minibatch 838::LR 0.0469230769231 --> Loss 0.000633322546879\n",
      "Epoch 24::Minibatch 839::LR 0.0469230769231 --> Loss 0.002429352204\n",
      "Epoch 24::Minibatch 840::LR 0.0469230769231 --> Loss 0.00285835623741\n",
      "Epoch 24::Minibatch 841::LR 0.0469230769231 --> Loss 0.00277738114198\n",
      "Epoch 24::Minibatch 842::LR 0.0469230769231 --> Loss 0.00207735617956\n",
      "Epoch 24::Minibatch 843::LR 0.0469230769231 --> Loss 0.000989850958188\n",
      "Epoch 24::Minibatch 844::LR 0.0469230769231 --> Loss 0.0014748492837\n",
      "Epoch 24::Minibatch 845::LR 0.0469230769231 --> Loss 0.00416288057963\n",
      "Epoch 24::Minibatch 846::LR 0.0469230769231 --> Loss 0.00166571666797\n",
      "Epoch 24::Minibatch 847::LR 0.0469230769231 --> Loss 0.00230269352595\n",
      "Epoch 24::Minibatch 848::LR 0.0469230769231 --> Loss 0.00104744503895\n",
      "Epoch 24::Minibatch 849::LR 0.0469230769231 --> Loss 0.0018005446593\n",
      "Epoch 24::Minibatch 850::LR 0.0469230769231 --> Loss 0.00315141876539\n",
      "Epoch 24::Minibatch 851::LR 0.0469230769231 --> Loss 0.0025855110089\n",
      "Epoch 24::Minibatch 852::LR 0.0469230769231 --> Loss 0.00109451750914\n",
      "Epoch 24::Minibatch 853::LR 0.0469230769231 --> Loss 0.00130037317673\n",
      "Epoch 24::Minibatch 854::LR 0.0469230769231 --> Loss 0.00254892329375\n",
      "Epoch 24::Minibatch 855::LR 0.0469230769231 --> Loss 0.00213478724162\n",
      "Epoch 24::Minibatch 856::LR 0.0469230769231 --> Loss 0.00178502837817\n",
      "Epoch 24::Minibatch 857::LR 0.0469230769231 --> Loss 0.00120843460162\n",
      "Epoch 24::Minibatch 858::LR 0.0469230769231 --> Loss 0.000593716800213\n",
      "Epoch 24::Minibatch 859::LR 0.0469230769231 --> Loss 0.00193135201931\n",
      "Epoch 24::Minibatch 860::LR 0.0469230769231 --> Loss 0.00127052485943\n",
      "Epoch 24::Minibatch 861::LR 0.0469230769231 --> Loss 0.000937691728274\n",
      "Epoch 24::Minibatch 862::LR 0.0469230769231 --> Loss 0.00366404334704\n",
      "Epoch 24::Minibatch 863::LR 0.0469230769231 --> Loss 0.00338333964348\n",
      "Epoch 24::Minibatch 864::LR 0.0469230769231 --> Loss 0.00272151708603\n",
      "Epoch 24::Minibatch 865::LR 0.0469230769231 --> Loss 0.000456670820713\n",
      "Epoch 24::Minibatch 866::LR 0.0469230769231 --> Loss 0.00210505723953\n",
      "Epoch 24::Minibatch 867::LR 0.0469230769231 --> Loss 0.00291024506092\n",
      "Epoch 24::Minibatch 868::LR 0.0469230769231 --> Loss 0.00240542411804\n",
      "Epoch 24::Minibatch 869::LR 0.0469230769231 --> Loss 0.00211447556814\n",
      "Epoch 24::Minibatch 870::LR 0.0469230769231 --> Loss 0.00339681863785\n",
      "Epoch 24::Minibatch 871::LR 0.0469230769231 --> Loss 0.00156325648228\n",
      "Epoch 24::Minibatch 872::LR 0.0469230769231 --> Loss 0.00219905515512\n",
      "Epoch 24::Minibatch 873::LR 0.0469230769231 --> Loss 0.0024574671189\n",
      "Epoch 24::Minibatch 874::LR 0.0469230769231 --> Loss 0.0057114370664\n",
      "Epoch 24::Minibatch 875::LR 0.0469230769231 --> Loss 0.000555110226075\n",
      "Epoch 24::Minibatch 876::LR 0.0469230769231 --> Loss 0.00294075071812\n",
      "Epoch 24::Minibatch 877::LR 0.0469230769231 --> Loss 0.00524291714032\n",
      "Epoch 24::Minibatch 878::LR 0.0469230769231 --> Loss 0.00310758550962\n",
      "Epoch 24::Minibatch 879::LR 0.0469230769231 --> Loss 0.00396273851395\n",
      "Epoch 24::Minibatch 880::LR 0.0469230769231 --> Loss 0.00482930819194\n",
      "Epoch 24::Minibatch 881::LR 0.0469230769231 --> Loss 0.00426074028015\n",
      "Epoch 24::Minibatch 882::LR 0.0469230769231 --> Loss 0.00194058040778\n",
      "Epoch 24::Minibatch 883::LR 0.0469230769231 --> Loss 0.00349932789803\n",
      "Epoch 24::Minibatch 884::LR 0.0469230769231 --> Loss 0.00273831943671\n",
      "Epoch 24::Minibatch 885::LR 0.0469230769231 --> Loss 0.00255858580271\n",
      "Epoch 24::Minibatch 886::LR 0.0469230769231 --> Loss 0.00045596425732\n",
      "Epoch 24::Minibatch 887::LR 0.0469230769231 --> Loss 0.00529668132464\n",
      "Epoch 24::Minibatch 888::LR 0.0469230769231 --> Loss 0.00252975563208\n",
      "Epoch 24::Minibatch 889::LR 0.0469230769231 --> Loss 0.00264954368273\n",
      "Epoch 24::Minibatch 890::LR 0.0469230769231 --> Loss 0.00388003269831\n",
      "Epoch 24::Minibatch 891::LR 0.0469230769231 --> Loss 0.0017803577582\n",
      "Epoch 24::Minibatch 892::LR 0.0469230769231 --> Loss 0.000821207165718\n",
      "Epoch 24::Minibatch 893::LR 0.0469230769231 --> Loss 0.00234544932842\n",
      "Epoch 24::Minibatch 894::LR 0.0469230769231 --> Loss 0.00206656138102\n",
      "Epoch 24::Minibatch 895::LR 0.0469230769231 --> Loss 0.00232895255089\n",
      "Epoch 24::Minibatch 896::LR 0.0469230769231 --> Loss 0.00124188959599\n",
      "Epoch 24::Minibatch 897::LR 0.0469230769231 --> Loss 0.000687571018934\n",
      "Epoch 24::Minibatch 898::LR 0.0469230769231 --> Loss 0.00205987711747\n",
      "Epoch 24::Minibatch 899::LR 0.0469230769231 --> Loss 0.00246102154255\n",
      "Epoch 24::Minibatch 900::LR 0.0469230769231 --> Loss 0.00314607699712\n",
      "Epoch 24::Minibatch 901::LR 0.0469230769231 --> Loss 0.000584954023361\n",
      "Epoch 24::Minibatch 902::LR 0.0469230769231 --> Loss 0.00140246291955\n",
      "Epoch 24::Minibatch 903::LR 0.0469230769231 --> Loss 0.00253300865491\n",
      "Epoch 24::Minibatch 904::LR 0.0469230769231 --> Loss 0.00184765319029\n",
      "Epoch 24::Minibatch 905::LR 0.0469230769231 --> Loss 0.0014124734203\n",
      "Epoch 24::Minibatch 906::LR 0.0469230769231 --> Loss 0.00104758014282\n",
      "Epoch 24::Minibatch 907::LR 0.0469230769231 --> Loss 0.0015656871597\n",
      "Epoch 24::Minibatch 908::LR 0.0469230769231 --> Loss 0.00211243351301\n",
      "Epoch 24::Minibatch 909::LR 0.0469230769231 --> Loss 0.00195647835732\n",
      "Epoch 24::Minibatch 910::LR 0.0469230769231 --> Loss 0.000834383467833\n",
      "Epoch 24::Minibatch 911::LR 0.0469230769231 --> Loss 0.00124729543924\n",
      "Epoch 24::Minibatch 912::LR 0.0469230769231 --> Loss 0.00200786252817\n",
      "Epoch 24::Minibatch 913::LR 0.0469230769231 --> Loss 0.00219658911228\n",
      "Epoch 24::Minibatch 914::LR 0.0469230769231 --> Loss 0.00118959118923\n",
      "Epoch 24::Minibatch 915::LR 0.0469230769231 --> Loss 0.00050372928381\n",
      "Epoch 24::Minibatch 916::LR 0.0469230769231 --> Loss 0.00215558469296\n",
      "Epoch 24::Minibatch 917::LR 0.0469230769231 --> Loss 0.00353725353877\n",
      "Epoch 24::Minibatch 918::LR 0.0469230769231 --> Loss 0.00547986586889\n",
      "Epoch 24::Minibatch 919::LR 0.0469230769231 --> Loss 0.000540031939745\n",
      "Epoch 24::Minibatch 920::LR 0.0469230769231 --> Loss 0.0123928610484\n",
      "Epoch 24::Minibatch 921::LR 0.0469230769231 --> Loss 0.00285035868486\n",
      "Epoch 24::Minibatch 922::LR 0.0469230769231 --> Loss 0.00294251263142\n",
      "Epoch 24::Minibatch 923::LR 0.0469230769231 --> Loss 0.00132928788662\n",
      "Epoch 24::Minibatch 924::LR 0.0469230769231 --> Loss 0.00331529418627\n",
      "Epoch 24::Minibatch 925::LR 0.0469230769231 --> Loss 0.0022380510966\n",
      "Epoch 24::Minibatch 926::LR 0.0469230769231 --> Loss 0.00500956455866\n",
      "Epoch 24::Minibatch 927::LR 0.0469230769231 --> Loss 0.0064074420929\n",
      "Epoch 24::Minibatch 928::LR 0.0469230769231 --> Loss 0.00616210897764\n",
      "Epoch 24::Minibatch 929::LR 0.0469230769231 --> Loss 0.00597287972768\n",
      "Epoch 24::Minibatch 930::LR 0.0469230769231 --> Loss 0.00891452471415\n",
      "Epoch 24::Minibatch 931::LR 0.0469230769231 --> Loss 0.0032157744964\n",
      "Epoch 24::Minibatch 932::LR 0.0469230769231 --> Loss 0.00596769213676\n",
      "Epoch 24::Minibatch 933::LR 0.0469230769231 --> Loss 0.00286035954952\n",
      "Epoch 24::Minibatch 934::LR 0.0469230769231 --> Loss 0.00375494003296\n",
      "Epoch 24::Minibatch 935::LR 0.0469230769231 --> Loss 0.00542088270187\n",
      "Epoch 24::Minibatch 936::LR 0.0469230769231 --> Loss 0.00117933700482\n",
      "Epoch 24::Minibatch 937::LR 0.0469230769231 --> Loss 0.00282028357188\n",
      "Epoch 24::Minibatch 938::LR 0.0469230769231 --> Loss 0.00248071372509\n",
      "Epoch 24::Minibatch 939::LR 0.0469230769231 --> Loss 0.00260120670001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24::Minibatch 940::LR 0.0469230769231 --> Loss 0.000967556337516\n",
      "Epoch 24::Minibatch 941::LR 0.0469230769231 --> Loss 0.000795207023621\n",
      "Epoch 24::Minibatch 942::LR 0.0469230769231 --> Loss 0.00245920519034\n",
      "Epoch 24::Minibatch 943::LR 0.0469230769231 --> Loss 0.00257500370344\n",
      "Epoch 24::Minibatch 944::LR 0.0469230769231 --> Loss 0.00186325569948\n",
      "Epoch 24::Minibatch 945::LR 0.0469230769231 --> Loss 0.00107185482979\n",
      "Epoch 24::Minibatch 946::LR 0.0469230769231 --> Loss 0.00272369503975\n",
      "Epoch 24::Minibatch 947::LR 0.0469230769231 --> Loss 0.00246652523677\n",
      "Epoch 24::Minibatch 948::LR 0.0469230769231 --> Loss 0.00459358652433\n",
      "Epoch 24::Minibatch 949::LR 0.0469230769231 --> Loss 0.00178466916084\n",
      "Epoch 24::Minibatch 950::LR 0.0469230769231 --> Loss 0.000723092754682\n",
      "Epoch 24::Minibatch 951::LR 0.0469230769231 --> Loss 0.00337325135867\n",
      "Epoch 24::Minibatch 952::LR 0.0469230769231 --> Loss 0.00236864984035\n",
      "Epoch 24::Minibatch 953::LR 0.0469230769231 --> Loss 0.00139640420675\n",
      "Epoch 24::Minibatch 954::LR 0.0469230769231 --> Loss 0.000953791240851\n",
      "Epoch 24::Minibatch 955::LR 0.0469230769231 --> Loss 0.00252655009429\n",
      "Epoch 24::Minibatch 956::LR 0.0469230769231 --> Loss 0.00338372588158\n",
      "Epoch 24::Minibatch 957::LR 0.0469230769231 --> Loss 0.00183481415113\n",
      "Epoch 24::Minibatch 958::LR 0.0469230769231 --> Loss 0.00220548133055\n",
      "Epoch 24::Minibatch 959::LR 0.0469230769231 --> Loss 0.00266574680805\n",
      "Epoch 24::Minibatch 960::LR 0.0469230769231 --> Loss 0.00581003546715\n",
      "Epoch 24::Minibatch 961::LR 0.0469230769231 --> Loss 0.00315355082353\n",
      "Epoch 24::Minibatch 962::LR 0.0469230769231 --> Loss 0.00263058900833\n",
      "Epoch 24::Minibatch 963::LR 0.0469230769231 --> Loss 0.0010406618317\n",
      "Epoch 24::Minibatch 964::LR 0.0469230769231 --> Loss 0.00235160509745\n",
      "Epoch 24::Minibatch 965::LR 0.0469230769231 --> Loss 0.00684005816778\n",
      "Epoch 24::Minibatch 966::LR 0.0469230769231 --> Loss 0.00499651034673\n",
      "Epoch 24::Minibatch 967::LR 0.0469230769231 --> Loss 0.0013783043623\n",
      "Epoch 24::Minibatch 968::LR 0.0469230769231 --> Loss 0.00119889507691\n",
      "Epoch 24::Minibatch 969::LR 0.0469230769231 --> Loss 0.00547530412674\n",
      "Epoch 24::Minibatch 970::LR 0.0469230769231 --> Loss 0.00515609343847\n",
      "Epoch 24::Minibatch 971::LR 0.0469230769231 --> Loss 0.00340458393097\n",
      "Epoch 24::Minibatch 972::LR 0.0469230769231 --> Loss 0.00944255272547\n",
      "Epoch 24::Minibatch 973::LR 0.0469230769231 --> Loss 0.00902353048325\n",
      "Epoch 24::Minibatch 974::LR 0.0469230769231 --> Loss 0.00799021800359\n",
      "Epoch 24::Minibatch 975::LR 0.0469230769231 --> Loss 0.00442029158274\n",
      "Epoch 24::Minibatch 976::LR 0.0469230769231 --> Loss 0.0038852373759\n",
      "Epoch 24::Minibatch 977::LR 0.0469230769231 --> Loss 0.00378604571025\n",
      "Epoch 24::Minibatch 978::LR 0.0469230769231 --> Loss 0.00375133434931\n",
      "Epoch 24::Minibatch 979::LR 0.0469230769231 --> Loss 0.0036144777139\n",
      "Epoch 24::Minibatch 980::LR 0.0469230769231 --> Loss 0.00378477374713\n",
      "Epoch 24::Minibatch 981::LR 0.0469230769231 --> Loss 0.00487154444059\n",
      "Epoch 24::Minibatch 982::LR 0.0469230769231 --> Loss 0.0056117161115\n",
      "Epoch 24::Minibatch 983::LR 0.0469230769231 --> Loss 0.00281592428684\n",
      "Epoch 24::Minibatch 984::LR 0.0469230769231 --> Loss 0.00218423287074\n",
      "Epoch 24::Minibatch 985::LR 0.0469230769231 --> Loss 0.00392856637637\n",
      "Epoch 24::Minibatch 986::LR 0.0469230769231 --> Loss 0.00359931985537\n",
      "Epoch 24::Minibatch 987::LR 0.0469230769231 --> Loss 0.00387613177299\n",
      "Epoch 24::Minibatch 988::LR 0.0469230769231 --> Loss 0.00308193902175\n",
      "Epoch 24::Minibatch 989::LR 0.0469230769231 --> Loss 0.00327997008959\n",
      "Epoch 24::Minibatch 990::LR 0.0469230769231 --> Loss 0.00299751619498\n",
      "Epoch 24::Minibatch 991::LR 0.0469230769231 --> Loss 0.00158815383911\n",
      "Epoch 24::Minibatch 992::LR 0.0469230769231 --> Loss 0.00177388985952\n",
      "Epoch 24::Minibatch 993::LR 0.0469230769231 --> Loss 0.00325794279575\n",
      "Epoch 24::Minibatch 994::LR 0.0469230769231 --> Loss 0.00207742114862\n",
      "Epoch 24::Minibatch 995::LR 0.0469230769231 --> Loss 0.000845326383909\n",
      "Epoch 24::Minibatch 996::LR 0.0469230769231 --> Loss 0.0028775348266\n",
      "Epoch 24::Minibatch 997::LR 0.0469230769231 --> Loss 0.00220916469892\n",
      "Epoch 24::Minibatch 998::LR 0.0469230769231 --> Loss 0.00250059485435\n",
      "Epoch 24::Minibatch 999::LR 0.0469230769231 --> Loss 0.00210147380829\n",
      "Epoch 24::Minibatch 1000::LR 0.0469230769231 --> Loss 0.00249225258827\n",
      "Epoch 24::Minibatch 1001::LR 0.0469230769231 --> Loss 0.00199054876963\n",
      "Epoch 24::Minibatch 1002::LR 0.0469230769231 --> Loss 0.00189624011517\n",
      "Epoch 24::Minibatch 1003::LR 0.0469230769231 --> Loss 0.00295172631741\n",
      "Epoch 24::Minibatch 1004::LR 0.0469230769231 --> Loss 0.00106097489595\n",
      "Epoch 24::Minibatch 1005::LR 0.0469230769231 --> Loss 0.00296326398849\n",
      "Epoch 24::Minibatch 1006::LR 0.0469230769231 --> Loss 0.00160480211178\n",
      "Epoch 24::Minibatch 1007::LR 0.0469230769231 --> Loss 0.00205642183622\n",
      "Epoch 24::Minibatch 1008::LR 0.0469230769231 --> Loss 0.000936154723167\n",
      "Epoch 24::Minibatch 1009::LR 0.0469230769231 --> Loss 0.00131422261397\n",
      "Epoch 24::Minibatch 1010::LR 0.0469230769231 --> Loss 0.00118897298972\n",
      "Epoch 24::Minibatch 1011::LR 0.0469230769231 --> Loss 0.00210834125678\n",
      "Epoch 24::Minibatch 1012::LR 0.0469230769231 --> Loss 0.00144846767187\n",
      "Epoch 24::Minibatch 1013::LR 0.0469230769231 --> Loss 0.00385585546494\n",
      "Epoch 24::Minibatch 1014::LR 0.0469230769231 --> Loss 0.00362284024556\n",
      "Epoch 24::Minibatch 1015::LR 0.0469230769231 --> Loss 0.00158271392186\n",
      "Epoch 24::Minibatch 1016::LR 0.0469230769231 --> Loss 0.00469578663508\n",
      "Epoch 24::Minibatch 1017::LR 0.0469230769231 --> Loss 0.00314212302367\n",
      "Epoch 24::Minibatch 1018::LR 0.0469230769231 --> Loss 0.00270037889481\n",
      "Epoch 24::Minibatch 1019::LR 0.0469230769231 --> Loss 0.00177411814531\n",
      "Epoch 24::Minibatch 1020::LR 0.0469230769231 --> Loss 0.00184464633465\n",
      "Epoch 24::Minibatch 1021::LR 0.0469230769231 --> Loss 0.00192624052366\n",
      "Epoch 24::Minibatch 1022::LR 0.0469230769231 --> Loss 0.0014456636707\n",
      "Epoch 24::Minibatch 1023::LR 0.0469230769231 --> Loss 0.00109507113695\n",
      "Epoch 24::Minibatch 1024::LR 0.0469230769231 --> Loss 0.00107736319304\n",
      "Epoch 24::Minibatch 1025::LR 0.0469230769231 --> Loss 0.00139090110858\n",
      "Epoch 24::Minibatch 1026::LR 0.0469230769231 --> Loss 0.000755341698726\n",
      "Epoch 24::Minibatch 1027::LR 0.0469230769231 --> Loss 0.00100212236245\n",
      "Epoch 24::Minibatch 1028::LR 0.0469230769231 --> Loss 0.000765023877223\n",
      "Epoch 24::Minibatch 1029::LR 0.0469230769231 --> Loss 0.000757121245066\n",
      "Epoch 24::Minibatch 1030::LR 0.0469230769231 --> Loss 0.000933901866277\n",
      "Epoch 24::Minibatch 1031::LR 0.0469230769231 --> Loss 0.000724577109019\n",
      "Epoch 24::Minibatch 1032::LR 0.0469230769231 --> Loss 0.000780531068643\n",
      "Epoch 24::Minibatch 1033::LR 0.0469230769231 --> Loss 0.000662587682406\n",
      "Epoch 24::Minibatch 1034::LR 0.0469230769231 --> Loss 0.000635031511386\n",
      "Epoch 24::Minibatch 1035::LR 0.0469230769231 --> Loss 0.000427484015624\n",
      "Epoch 24::Minibatch 1036::LR 0.0469230769231 --> Loss 0.000342985788981\n",
      "Epoch 24::Minibatch 1037::LR 0.0469230769231 --> Loss 0.000589596132437\n",
      "Epoch 24::Minibatch 1038::LR 0.0469230769231 --> Loss 0.00120002259811\n",
      "Epoch 24::Minibatch 1039::LR 0.0469230769231 --> Loss 0.00092645585537\n",
      "Epoch 24::Minibatch 1040::LR 0.0469230769231 --> Loss 0.000371379504601\n",
      "Epoch 24::Minibatch 1041::LR 0.0469230769231 --> Loss 0.000534919599692\n",
      "Epoch 25::Minibatch 1::LR 0.0446153846154 --> Loss 0.00839563926061\n",
      "Epoch 25::Minibatch 2::LR 0.0446153846154 --> Loss 0.00511910835902\n",
      "Epoch 25::Minibatch 3::LR 0.0446153846154 --> Loss 0.00341713905334\n",
      "Epoch 25::Minibatch 4::LR 0.0446153846154 --> Loss 0.00400626182556\n",
      "Epoch 25::Minibatch 5::LR 0.0446153846154 --> Loss 0.00453567663829\n",
      "Epoch 25::Minibatch 6::LR 0.0446153846154 --> Loss 0.00221449375153\n",
      "Epoch 25::Minibatch 7::LR 0.0446153846154 --> Loss 0.00740695158641\n",
      "Epoch 25::Minibatch 8::LR 0.0446153846154 --> Loss 0.00693708340327\n",
      "Epoch 25::Minibatch 9::LR 0.0446153846154 --> Loss 0.00525455117226\n",
      "Epoch 25::Minibatch 10::LR 0.0446153846154 --> Loss 0.00253712793191\n",
      "Epoch 25::Minibatch 11::LR 0.0446153846154 --> Loss 0.00231718043486\n",
      "Epoch 25::Minibatch 12::LR 0.0446153846154 --> Loss 0.00340570807457\n",
      "Epoch 25::Minibatch 13::LR 0.0446153846154 --> Loss 0.00525136470795\n",
      "Epoch 25::Minibatch 14::LR 0.0446153846154 --> Loss 0.0052608970801\n",
      "Epoch 25::Minibatch 15::LR 0.0446153846154 --> Loss 0.00450053215027\n",
      "Epoch 25::Minibatch 16::LR 0.0446153846154 --> Loss 0.000776521265507\n",
      "Epoch 25::Minibatch 17::LR 0.0446153846154 --> Loss 0.00313091655572\n",
      "Epoch 25::Minibatch 18::LR 0.0446153846154 --> Loss 0.00257932007313\n",
      "Epoch 25::Minibatch 19::LR 0.0446153846154 --> Loss 0.00145580391089\n",
      "Epoch 25::Minibatch 20::LR 0.0446153846154 --> Loss 0.00195811867714\n",
      "Epoch 25::Minibatch 21::LR 0.0446153846154 --> Loss 0.00331490159035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 22::LR 0.0446153846154 --> Loss 0.00223779320717\n",
      "Epoch 25::Minibatch 23::LR 0.0446153846154 --> Loss 0.000832543472449\n",
      "Epoch 25::Minibatch 24::LR 0.0446153846154 --> Loss 0.000431955407063\n",
      "Epoch 25::Minibatch 25::LR 0.0446153846154 --> Loss 0.00121668199698\n",
      "Epoch 25::Minibatch 26::LR 0.0446153846154 --> Loss 0.00141791403294\n",
      "Epoch 25::Minibatch 27::LR 0.0446153846154 --> Loss 0.00101291745901\n",
      "Epoch 25::Minibatch 28::LR 0.0446153846154 --> Loss 0.000438206841548\n",
      "Epoch 25::Minibatch 29::LR 0.0446153846154 --> Loss 0.000482778251171\n",
      "Epoch 25::Minibatch 30::LR 0.0446153846154 --> Loss 0.00095865269502\n",
      "Epoch 25::Minibatch 31::LR 0.0446153846154 --> Loss 0.00144783089558\n",
      "Epoch 25::Minibatch 32::LR 0.0446153846154 --> Loss 0.00131289641062\n",
      "Epoch 25::Minibatch 33::LR 0.0446153846154 --> Loss 0.000784552494685\n",
      "Epoch 25::Minibatch 34::LR 0.0446153846154 --> Loss 0.00211210866769\n",
      "Epoch 25::Minibatch 35::LR 0.0446153846154 --> Loss 0.00348829269409\n",
      "Epoch 25::Minibatch 36::LR 0.0446153846154 --> Loss 0.00227869133155\n",
      "Epoch 25::Minibatch 37::LR 0.0446153846154 --> Loss 0.00067231853803\n",
      "Epoch 25::Minibatch 38::LR 0.0446153846154 --> Loss 0.000719794283311\n",
      "Epoch 25::Minibatch 39::LR 0.0446153846154 --> Loss 0.00226123034954\n",
      "Epoch 25::Minibatch 40::LR 0.0446153846154 --> Loss 0.003182117939\n",
      "Epoch 25::Minibatch 41::LR 0.0446153846154 --> Loss 0.00256840268771\n",
      "Epoch 25::Minibatch 42::LR 0.0446153846154 --> Loss 0.00527600487073\n",
      "Epoch 25::Minibatch 43::LR 0.0446153846154 --> Loss 0.00192669014136\n",
      "Epoch 25::Minibatch 44::LR 0.0446153846154 --> Loss 0.00315169155598\n",
      "Epoch 25::Minibatch 45::LR 0.0446153846154 --> Loss 0.00239555537701\n",
      "Epoch 25::Minibatch 46::LR 0.0446153846154 --> Loss 0.00320267796516\n",
      "Epoch 25::Minibatch 47::LR 0.0446153846154 --> Loss 0.00378349423409\n",
      "Epoch 25::Minibatch 48::LR 0.0446153846154 --> Loss 0.00532147169113\n",
      "Epoch 25::Minibatch 49::LR 0.0446153846154 --> Loss 0.00584389527639\n",
      "Epoch 25::Minibatch 50::LR 0.0446153846154 --> Loss 0.00607675989469\n",
      "Epoch 25::Minibatch 51::LR 0.0446153846154 --> Loss 0.00529378533363\n",
      "Epoch 25::Minibatch 52::LR 0.0446153846154 --> Loss 0.00344114025434\n",
      "Epoch 25::Minibatch 53::LR 0.0446153846154 --> Loss 0.00338903903961\n",
      "Epoch 25::Minibatch 54::LR 0.0446153846154 --> Loss 0.00400972406069\n",
      "Epoch 25::Minibatch 55::LR 0.0446153846154 --> Loss 0.000987445513407\n",
      "Epoch 25::Minibatch 56::LR 0.0446153846154 --> Loss 0.00270095725854\n",
      "Epoch 25::Minibatch 57::LR 0.0446153846154 --> Loss 0.00496951897939\n",
      "Epoch 25::Minibatch 58::LR 0.0446153846154 --> Loss 0.00325459241867\n",
      "Epoch 25::Minibatch 59::LR 0.0446153846154 --> Loss 0.0024252863725\n",
      "Epoch 25::Minibatch 60::LR 0.0446153846154 --> Loss 0.00241392950217\n",
      "Epoch 25::Minibatch 61::LR 0.0446153846154 --> Loss 0.000773387899001\n",
      "Epoch 25::Minibatch 62::LR 0.0446153846154 --> Loss 0.00275744080544\n",
      "Epoch 25::Minibatch 63::LR 0.0446153846154 --> Loss 0.0020171503226\n",
      "Epoch 25::Minibatch 64::LR 0.0446153846154 --> Loss 0.000847683449586\n",
      "Epoch 25::Minibatch 65::LR 0.0446153846154 --> Loss 0.00222333371639\n",
      "Epoch 25::Minibatch 66::LR 0.0446153846154 --> Loss 0.00272542893887\n",
      "Epoch 25::Minibatch 67::LR 0.0446153846154 --> Loss 0.00262214799722\n",
      "Epoch 25::Minibatch 68::LR 0.0446153846154 --> Loss 0.00188730796178\n",
      "Epoch 25::Minibatch 69::LR 0.0446153846154 --> Loss 0.00376537958781\n",
      "Epoch 25::Minibatch 70::LR 0.0446153846154 --> Loss 0.00329908927282\n",
      "Epoch 25::Minibatch 71::LR 0.0446153846154 --> Loss 0.0022744768858\n",
      "Epoch 25::Minibatch 72::LR 0.0446153846154 --> Loss 0.000542946358522\n",
      "Epoch 25::Minibatch 73::LR 0.0446153846154 --> Loss 0.0037898393472\n",
      "Epoch 25::Minibatch 74::LR 0.0446153846154 --> Loss 0.00405899206797\n",
      "Epoch 25::Minibatch 75::LR 0.0446153846154 --> Loss 0.00223053475221\n",
      "Epoch 25::Minibatch 76::LR 0.0446153846154 --> Loss 0.000537714113792\n",
      "Epoch 25::Minibatch 77::LR 0.0446153846154 --> Loss 0.00351410428683\n",
      "Epoch 25::Minibatch 78::LR 0.0446153846154 --> Loss 0.00385995030403\n",
      "Epoch 25::Minibatch 79::LR 0.0446153846154 --> Loss 0.00181461135546\n",
      "Epoch 25::Minibatch 80::LR 0.0446153846154 --> Loss 0.00300602316856\n",
      "Epoch 25::Minibatch 81::LR 0.0446153846154 --> Loss 0.00262664854527\n",
      "Epoch 25::Minibatch 82::LR 0.0446153846154 --> Loss 0.00191382785638\n",
      "Epoch 25::Minibatch 83::LR 0.0446153846154 --> Loss 0.00417855302493\n",
      "Epoch 25::Minibatch 84::LR 0.0446153846154 --> Loss 0.00191548844179\n",
      "Epoch 25::Minibatch 85::LR 0.0446153846154 --> Loss 0.00263395965099\n",
      "Epoch 25::Minibatch 86::LR 0.0446153846154 --> Loss 0.00213896453381\n",
      "Epoch 25::Minibatch 87::LR 0.0446153846154 --> Loss 0.00231613894304\n",
      "Epoch 25::Minibatch 88::LR 0.0446153846154 --> Loss 0.00171324690183\n",
      "Epoch 25::Minibatch 89::LR 0.0446153846154 --> Loss 0.00224596440792\n",
      "Epoch 25::Minibatch 90::LR 0.0446153846154 --> Loss 0.00106037576993\n",
      "Epoch 25::Minibatch 91::LR 0.0446153846154 --> Loss 0.000867890218894\n",
      "Epoch 25::Minibatch 92::LR 0.0446153846154 --> Loss 0.00261579195658\n",
      "Epoch 25::Minibatch 93::LR 0.0446153846154 --> Loss 0.00172211090724\n",
      "Epoch 25::Minibatch 94::LR 0.0446153846154 --> Loss 0.00174268742402\n",
      "Epoch 25::Minibatch 95::LR 0.0446153846154 --> Loss 0.00185983657837\n",
      "Epoch 25::Minibatch 96::LR 0.0446153846154 --> Loss 0.00521852215131\n",
      "Epoch 25::Minibatch 97::LR 0.0446153846154 --> Loss 0.0030701982975\n",
      "Epoch 25::Minibatch 98::LR 0.0446153846154 --> Loss 0.00103231817484\n",
      "Epoch 25::Minibatch 99::LR 0.0446153846154 --> Loss 0.00135484447082\n",
      "Epoch 25::Minibatch 100::LR 0.0446153846154 --> Loss 0.00462004144986\n",
      "Epoch 25::Minibatch 101::LR 0.0446153846154 --> Loss 0.000906030436357\n",
      "Epoch 25::Minibatch 102::LR 0.0446153846154 --> Loss 0.00388947804769\n",
      "Epoch 25::Minibatch 103::LR 0.0446153846154 --> Loss 0.00396084666252\n",
      "Epoch 25::Minibatch 104::LR 0.0446153846154 --> Loss 0.00270171006521\n",
      "Epoch 25::Minibatch 105::LR 0.0446153846154 --> Loss 0.00232994039853\n",
      "Epoch 25::Minibatch 106::LR 0.0446153846154 --> Loss 0.0156450192134\n",
      "Epoch 25::Minibatch 107::LR 0.0446153846154 --> Loss 0.00481524546941\n",
      "Epoch 25::Minibatch 108::LR 0.0446153846154 --> Loss 0.000973975658417\n",
      "Epoch 25::Minibatch 109::LR 0.0446153846154 --> Loss 0.00430217583974\n",
      "Epoch 25::Minibatch 110::LR 0.0446153846154 --> Loss 0.0022714471817\n",
      "Epoch 25::Minibatch 111::LR 0.0446153846154 --> Loss 0.000866216818492\n",
      "Epoch 25::Minibatch 112::LR 0.0446153846154 --> Loss 0.00337885181109\n",
      "Epoch 25::Minibatch 113::LR 0.0446153846154 --> Loss 0.00248931964238\n",
      "Epoch 25::Minibatch 114::LR 0.0446153846154 --> Loss 0.00138270397981\n",
      "Epoch 25::Minibatch 115::LR 0.0446153846154 --> Loss 0.00121310750643\n",
      "Epoch 25::Minibatch 116::LR 0.0446153846154 --> Loss 0.00266763289769\n",
      "Epoch 25::Minibatch 117::LR 0.0446153846154 --> Loss 0.00393211960793\n",
      "Epoch 25::Minibatch 118::LR 0.0446153846154 --> Loss 0.00672112305959\n",
      "Epoch 25::Minibatch 119::LR 0.0446153846154 --> Loss 0.000556448201338\n",
      "Epoch 25::Minibatch 120::LR 0.0446153846154 --> Loss 0.00166346758604\n",
      "Epoch 25::Minibatch 121::LR 0.0446153846154 --> Loss 0.00247326294581\n",
      "Epoch 25::Minibatch 122::LR 0.0446153846154 --> Loss 0.00374974131584\n",
      "Epoch 25::Minibatch 123::LR 0.0446153846154 --> Loss 0.000819817086061\n",
      "Epoch 25::Minibatch 124::LR 0.0446153846154 --> Loss 0.00264738917351\n",
      "Epoch 25::Minibatch 125::LR 0.0446153846154 --> Loss 0.0044956111908\n",
      "Epoch 25::Minibatch 126::LR 0.0446153846154 --> Loss 0.00256937642892\n",
      "Epoch 25::Minibatch 127::LR 0.0446153846154 --> Loss 0.00456638058027\n",
      "Epoch 25::Minibatch 128::LR 0.0446153846154 --> Loss 0.00355851689974\n",
      "Epoch 25::Minibatch 129::LR 0.0446153846154 --> Loss 0.00253815829754\n",
      "Epoch 25::Minibatch 130::LR 0.0446153846154 --> Loss 0.00433392683665\n",
      "Epoch 25::Minibatch 131::LR 0.0446153846154 --> Loss 0.00174484173457\n",
      "Epoch 25::Minibatch 132::LR 0.0446153846154 --> Loss 0.00293987572193\n",
      "Epoch 25::Minibatch 133::LR 0.0446153846154 --> Loss 0.00280282358329\n",
      "Epoch 25::Minibatch 134::LR 0.0446153846154 --> Loss 0.00221919675668\n",
      "Epoch 25::Minibatch 135::LR 0.0446153846154 --> Loss 0.00141249408325\n",
      "Epoch 25::Minibatch 136::LR 0.0446153846154 --> Loss 0.00256042659283\n",
      "Epoch 25::Minibatch 137::LR 0.0446153846154 --> Loss 0.00353053132693\n",
      "Epoch 25::Minibatch 138::LR 0.0446153846154 --> Loss 0.0012566524744\n",
      "Epoch 25::Minibatch 139::LR 0.0446153846154 --> Loss 0.00189765115579\n",
      "Epoch 25::Minibatch 140::LR 0.0446153846154 --> Loss 0.00242877105872\n",
      "Epoch 25::Minibatch 141::LR 0.0446153846154 --> Loss 0.00293605009715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 142::LR 0.0446153846154 --> Loss 0.00275393168132\n",
      "Epoch 25::Minibatch 143::LR 0.0446153846154 --> Loss 0.00057072420915\n",
      "Epoch 25::Minibatch 144::LR 0.0446153846154 --> Loss 0.00329379916191\n",
      "Epoch 25::Minibatch 145::LR 0.0446153846154 --> Loss 0.00420942584674\n",
      "Epoch 25::Minibatch 146::LR 0.0446153846154 --> Loss 0.00253237744172\n",
      "Epoch 25::Minibatch 147::LR 0.0446153846154 --> Loss 0.00179866870244\n",
      "Epoch 25::Minibatch 148::LR 0.0446153846154 --> Loss 0.0009923812747\n",
      "Epoch 25::Minibatch 149::LR 0.0446153846154 --> Loss 0.00284093161424\n",
      "Epoch 25::Minibatch 150::LR 0.0446153846154 --> Loss 0.00268676280975\n",
      "Epoch 25::Minibatch 151::LR 0.0446153846154 --> Loss 0.00425555229187\n",
      "Epoch 25::Minibatch 152::LR 0.0446153846154 --> Loss 0.000911419689655\n",
      "Epoch 25::Minibatch 153::LR 0.0446153846154 --> Loss 0.00172550499439\n",
      "Epoch 25::Minibatch 154::LR 0.0446153846154 --> Loss 0.00203332483768\n",
      "Epoch 25::Minibatch 155::LR 0.0446153846154 --> Loss 0.00424303770065\n",
      "Epoch 25::Minibatch 156::LR 0.0446153846154 --> Loss 0.00237198829651\n",
      "Epoch 25::Minibatch 157::LR 0.0446153846154 --> Loss 0.000693915486336\n",
      "Epoch 25::Minibatch 158::LR 0.0446153846154 --> Loss 0.00310385962327\n",
      "Epoch 25::Minibatch 159::LR 0.0446153846154 --> Loss 0.00273692448934\n",
      "Epoch 25::Minibatch 160::LR 0.0446153846154 --> Loss 0.00263226469358\n",
      "Epoch 25::Minibatch 161::LR 0.0446153846154 --> Loss 0.00101156423489\n",
      "Epoch 25::Minibatch 162::LR 0.0446153846154 --> Loss 0.00384538888931\n",
      "Epoch 25::Minibatch 163::LR 0.0446153846154 --> Loss 0.002392685016\n",
      "Epoch 25::Minibatch 164::LR 0.0446153846154 --> Loss 0.00250696380933\n",
      "Epoch 25::Minibatch 165::LR 0.0446153846154 --> Loss 0.000513951977094\n",
      "Epoch 25::Minibatch 166::LR 0.0446153846154 --> Loss 0.00174679199855\n",
      "Epoch 25::Minibatch 167::LR 0.0446153846154 --> Loss 0.00246225059032\n",
      "Epoch 25::Minibatch 168::LR 0.0446153846154 --> Loss 0.00216136515141\n",
      "Epoch 25::Minibatch 169::LR 0.0446153846154 --> Loss 0.00100380927324\n",
      "Epoch 25::Minibatch 170::LR 0.0446153846154 --> Loss 0.000974027514458\n",
      "Epoch 25::Minibatch 171::LR 0.0446153846154 --> Loss 0.00249941070875\n",
      "Epoch 25::Minibatch 172::LR 0.0446153846154 --> Loss 0.0043063334624\n",
      "Epoch 25::Minibatch 173::LR 0.0446153846154 --> Loss 0.00195753574371\n",
      "Epoch 25::Minibatch 174::LR 0.0446153846154 --> Loss 0.00100136429071\n",
      "Epoch 25::Minibatch 175::LR 0.0446153846154 --> Loss 0.002324026227\n",
      "Epoch 25::Minibatch 176::LR 0.0446153846154 --> Loss 0.00319191873074\n",
      "Epoch 25::Minibatch 177::LR 0.0446153846154 --> Loss 0.00441086173058\n",
      "Epoch 25::Minibatch 178::LR 0.0446153846154 --> Loss 0.00157122125228\n",
      "Epoch 25::Minibatch 179::LR 0.0446153846154 --> Loss 0.00128132949273\n",
      "Epoch 25::Minibatch 180::LR 0.0446153846154 --> Loss 0.00348812540372\n",
      "Epoch 25::Minibatch 181::LR 0.0446153846154 --> Loss 0.00315472682317\n",
      "Epoch 25::Minibatch 182::LR 0.0446153846154 --> Loss 0.000741034547488\n",
      "Epoch 25::Minibatch 183::LR 0.0446153846154 --> Loss 0.00162861128648\n",
      "Epoch 25::Minibatch 184::LR 0.0446153846154 --> Loss 0.00342831850052\n",
      "Epoch 25::Minibatch 185::LR 0.0446153846154 --> Loss 0.00276325484117\n",
      "Epoch 25::Minibatch 186::LR 0.0446153846154 --> Loss 0.000955571333567\n",
      "Epoch 25::Minibatch 187::LR 0.0446153846154 --> Loss 0.0012750885884\n",
      "Epoch 25::Minibatch 188::LR 0.0446153846154 --> Loss 0.00413716832797\n",
      "Epoch 25::Minibatch 189::LR 0.0446153846154 --> Loss 0.00428409695625\n",
      "Epoch 25::Minibatch 190::LR 0.0446153846154 --> Loss 0.00232517043749\n",
      "Epoch 25::Minibatch 191::LR 0.0446153846154 --> Loss 0.00046404744188\n",
      "Epoch 25::Minibatch 192::LR 0.0446153846154 --> Loss 0.00274597525597\n",
      "Epoch 25::Minibatch 193::LR 0.0446153846154 --> Loss 0.0026271935304\n",
      "Epoch 25::Minibatch 194::LR 0.0446153846154 --> Loss 0.00176327486833\n",
      "Epoch 25::Minibatch 195::LR 0.0446153846154 --> Loss 0.000379833057523\n",
      "Epoch 25::Minibatch 196::LR 0.0446153846154 --> Loss 0.00128456115723\n",
      "Epoch 25::Minibatch 197::LR 0.0446153846154 --> Loss 0.00291318575541\n",
      "Epoch 25::Minibatch 198::LR 0.0446153846154 --> Loss 0.00225255330404\n",
      "Epoch 25::Minibatch 199::LR 0.0446153846154 --> Loss 0.000287819082538\n",
      "Epoch 25::Minibatch 200::LR 0.0446153846154 --> Loss 0.002046525081\n",
      "Epoch 25::Minibatch 201::LR 0.0446153846154 --> Loss 0.00194128115972\n",
      "Epoch 25::Minibatch 202::LR 0.0446153846154 --> Loss 0.00184175014496\n",
      "Epoch 25::Minibatch 203::LR 0.0446153846154 --> Loss 0.00175046801567\n",
      "Epoch 25::Minibatch 204::LR 0.0446153846154 --> Loss 0.00142834822337\n",
      "Epoch 25::Minibatch 205::LR 0.0446153846154 --> Loss 0.00220117648443\n",
      "Epoch 25::Minibatch 206::LR 0.0446153846154 --> Loss 0.00598273396492\n",
      "Epoch 25::Minibatch 207::LR 0.0446153846154 --> Loss 0.0013963017861\n",
      "Epoch 25::Minibatch 208::LR 0.0446153846154 --> Loss 0.00111256827911\n",
      "Epoch 25::Minibatch 209::LR 0.0446153846154 --> Loss 0.00233402033647\n",
      "Epoch 25::Minibatch 210::LR 0.0446153846154 --> Loss 0.00222126464049\n",
      "Epoch 25::Minibatch 211::LR 0.0446153846154 --> Loss 0.00246381640434\n",
      "Epoch 25::Minibatch 212::LR 0.0446153846154 --> Loss 0.00386784235636\n",
      "Epoch 25::Minibatch 213::LR 0.0446153846154 --> Loss 0.00562268336614\n",
      "Epoch 25::Minibatch 214::LR 0.0446153846154 --> Loss 0.00814357121785\n",
      "Epoch 25::Minibatch 215::LR 0.0446153846154 --> Loss 0.00136541903019\n",
      "Epoch 25::Minibatch 216::LR 0.0446153846154 --> Loss 0.00539823492368\n",
      "Epoch 25::Minibatch 217::LR 0.0446153846154 --> Loss 0.0060272415479\n",
      "Epoch 25::Minibatch 218::LR 0.0446153846154 --> Loss 0.0039141468207\n",
      "Epoch 25::Minibatch 219::LR 0.0446153846154 --> Loss 0.0042739768823\n",
      "Epoch 25::Minibatch 220::LR 0.0446153846154 --> Loss 0.0044269100825\n",
      "Epoch 25::Minibatch 221::LR 0.0446153846154 --> Loss 0.00423944751422\n",
      "Epoch 25::Minibatch 222::LR 0.0446153846154 --> Loss 0.00320158998171\n",
      "Epoch 25::Minibatch 223::LR 0.0446153846154 --> Loss 0.00139870216449\n",
      "Epoch 25::Minibatch 224::LR 0.0446153846154 --> Loss 0.00166865130266\n",
      "Epoch 25::Minibatch 225::LR 0.0446153846154 --> Loss 0.00752446810404\n",
      "Epoch 25::Minibatch 226::LR 0.0446153846154 --> Loss 0.00373239159584\n",
      "Epoch 25::Minibatch 227::LR 0.0446153846154 --> Loss 0.0016833114624\n",
      "Epoch 25::Minibatch 228::LR 0.0446153846154 --> Loss 0.000694719254971\n",
      "Epoch 25::Minibatch 229::LR 0.0446153846154 --> Loss 0.00472806612651\n",
      "Epoch 25::Minibatch 230::LR 0.0446153846154 --> Loss 0.00382018287977\n",
      "Epoch 25::Minibatch 231::LR 0.0446153846154 --> Loss 0.00265325943629\n",
      "Epoch 25::Minibatch 232::LR 0.0446153846154 --> Loss 0.00118738998969\n",
      "Epoch 25::Minibatch 233::LR 0.0446153846154 --> Loss 0.00244077523549\n",
      "Epoch 25::Minibatch 234::LR 0.0446153846154 --> Loss 0.00711366653442\n",
      "Epoch 25::Minibatch 235::LR 0.0446153846154 --> Loss 0.00460068305333\n",
      "Epoch 25::Minibatch 236::LR 0.0446153846154 --> Loss 0.00171859959761\n",
      "Epoch 25::Minibatch 237::LR 0.0446153846154 --> Loss 0.000636875281731\n",
      "Epoch 25::Minibatch 238::LR 0.0446153846154 --> Loss 0.0034138349692\n",
      "Epoch 25::Minibatch 239::LR 0.0446153846154 --> Loss 0.00295873483022\n",
      "Epoch 25::Minibatch 240::LR 0.0446153846154 --> Loss 0.00324003318946\n",
      "Epoch 25::Minibatch 241::LR 0.0446153846154 --> Loss 0.000749829510848\n",
      "Epoch 25::Minibatch 242::LR 0.0446153846154 --> Loss 0.00687257289886\n",
      "Epoch 25::Minibatch 243::LR 0.0446153846154 --> Loss 0.00338692943255\n",
      "Epoch 25::Minibatch 244::LR 0.0446153846154 --> Loss 0.00284037848314\n",
      "Epoch 25::Minibatch 245::LR 0.0446153846154 --> Loss 0.000453231930733\n",
      "Epoch 25::Minibatch 246::LR 0.0446153846154 --> Loss 0.00199124773343\n",
      "Epoch 25::Minibatch 247::LR 0.0446153846154 --> Loss 0.0117887163162\n",
      "Epoch 25::Minibatch 248::LR 0.0446153846154 --> Loss 0.00440743327141\n",
      "Epoch 25::Minibatch 249::LR 0.0446153846154 --> Loss 0.00254581491152\n",
      "Epoch 25::Minibatch 250::LR 0.0446153846154 --> Loss 0.00244793554147\n",
      "Epoch 25::Minibatch 251::LR 0.0446153846154 --> Loss 0.00241504271825\n",
      "Epoch 25::Minibatch 252::LR 0.0446153846154 --> Loss 0.00169332464536\n",
      "Epoch 25::Minibatch 253::LR 0.0446153846154 --> Loss 0.00294795711835\n",
      "Epoch 25::Minibatch 254::LR 0.0446153846154 --> Loss 0.00498067100843\n",
      "Epoch 25::Minibatch 255::LR 0.0446153846154 --> Loss 0.00382104833921\n",
      "Epoch 25::Minibatch 256::LR 0.0446153846154 --> Loss 0.00151733388503\n",
      "Epoch 25::Minibatch 257::LR 0.0446153846154 --> Loss 0.00117663870255\n",
      "Epoch 25::Minibatch 258::LR 0.0446153846154 --> Loss 0.00363686958949\n",
      "Epoch 25::Minibatch 259::LR 0.0446153846154 --> Loss 0.00169292052587\n",
      "Epoch 25::Minibatch 260::LR 0.0446153846154 --> Loss 0.00186191320419\n",
      "Epoch 25::Minibatch 261::LR 0.0446153846154 --> Loss 0.00274572928747\n",
      "Epoch 25::Minibatch 262::LR 0.0446153846154 --> Loss 0.00186829030514\n",
      "Epoch 25::Minibatch 263::LR 0.0446153846154 --> Loss 0.00233088612556\n",
      "Epoch 25::Minibatch 264::LR 0.0446153846154 --> Loss 0.00359788020452\n",
      "Epoch 25::Minibatch 265::LR 0.0446153846154 --> Loss 0.0100196798642\n",
      "Epoch 25::Minibatch 266::LR 0.0446153846154 --> Loss 0.000951325794061\n",
      "Epoch 25::Minibatch 267::LR 0.0446153846154 --> Loss 0.00955190976461\n",
      "Epoch 25::Minibatch 268::LR 0.0446153846154 --> Loss 0.00111171672742\n",
      "Epoch 25::Minibatch 269::LR 0.0446153846154 --> Loss 0.00349953095118\n",
      "Epoch 25::Minibatch 270::LR 0.0446153846154 --> Loss 0.00694127162298\n",
      "Epoch 25::Minibatch 271::LR 0.0446153846154 --> Loss 0.00256857653459\n",
      "Epoch 25::Minibatch 272::LR 0.0446153846154 --> Loss 0.00426678299904\n",
      "Epoch 25::Minibatch 273::LR 0.0446153846154 --> Loss 0.0015270314614\n",
      "Epoch 25::Minibatch 274::LR 0.0446153846154 --> Loss 0.0017840496699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 275::LR 0.0446153846154 --> Loss 0.00256036102772\n",
      "Epoch 25::Minibatch 276::LR 0.0446153846154 --> Loss 0.0034167222182\n",
      "Epoch 25::Minibatch 277::LR 0.0446153846154 --> Loss 0.000935847759247\n",
      "Epoch 25::Minibatch 278::LR 0.0446153846154 --> Loss 0.00259129365285\n",
      "Epoch 25::Minibatch 279::LR 0.0446153846154 --> Loss 0.00219414492448\n",
      "Epoch 25::Minibatch 280::LR 0.0446153846154 --> Loss 0.00192459642887\n",
      "Epoch 25::Minibatch 281::LR 0.0446153846154 --> Loss 0.00121763507525\n",
      "Epoch 25::Minibatch 282::LR 0.0446153846154 --> Loss 0.00213340163231\n",
      "Epoch 25::Minibatch 283::LR 0.0446153846154 --> Loss 0.00205822229385\n",
      "Epoch 25::Minibatch 284::LR 0.0446153846154 --> Loss 0.00166110982498\n",
      "Epoch 25::Minibatch 285::LR 0.0446153846154 --> Loss 0.00117824673653\n",
      "Epoch 25::Minibatch 286::LR 0.0446153846154 --> Loss 0.00206384440263\n",
      "Epoch 25::Minibatch 287::LR 0.0446153846154 --> Loss 0.00202215035756\n",
      "Epoch 25::Minibatch 288::LR 0.0446153846154 --> Loss 0.00109618425369\n",
      "Epoch 25::Minibatch 289::LR 0.0446153846154 --> Loss 0.00159545878569\n",
      "Epoch 25::Minibatch 290::LR 0.0446153846154 --> Loss 0.00190857271353\n",
      "Epoch 25::Minibatch 291::LR 0.0446153846154 --> Loss 0.00170495470365\n",
      "Epoch 25::Minibatch 292::LR 0.0446153846154 --> Loss 0.000600298643112\n",
      "Epoch 25::Minibatch 293::LR 0.0446153846154 --> Loss 0.00150448511044\n",
      "Epoch 25::Minibatch 294::LR 0.0446153846154 --> Loss 0.00159800777833\n",
      "Epoch 25::Minibatch 295::LR 0.0446153846154 --> Loss 0.00188218851884\n",
      "Epoch 25::Minibatch 296::LR 0.0446153846154 --> Loss 0.00163252810637\n",
      "Epoch 25::Minibatch 297::LR 0.0446153846154 --> Loss 0.00141931096713\n",
      "Epoch 25::Minibatch 298::LR 0.0446153846154 --> Loss 0.00141411334276\n",
      "Epoch 25::Minibatch 299::LR 0.0446153846154 --> Loss 0.000808954586585\n",
      "Epoch 25::Minibatch 300::LR 0.0446153846154 --> Loss 0.00274735689163\n",
      "Epoch 25::Minibatch 301::LR 0.0446153846154 --> Loss 0.00265946765741\n",
      "Epoch 25::Minibatch 302::LR 0.0446153846154 --> Loss 0.00243723452091\n",
      "Epoch 25::Minibatch 303::LR 0.0446153846154 --> Loss 0.000848618149757\n",
      "Epoch 25::Minibatch 304::LR 0.0446153846154 --> Loss 0.00302121639252\n",
      "Epoch 25::Minibatch 305::LR 0.0446153846154 --> Loss 0.00170478423436\n",
      "Epoch 25::Minibatch 306::LR 0.0446153846154 --> Loss 0.000938690205415\n",
      "Epoch 25::Minibatch 307::LR 0.0446153846154 --> Loss 0.00242988566558\n",
      "Epoch 25::Minibatch 308::LR 0.0446153846154 --> Loss 0.00201484700044\n",
      "Epoch 25::Minibatch 309::LR 0.0446153846154 --> Loss 0.00102833886941\n",
      "Epoch 25::Minibatch 310::LR 0.0446153846154 --> Loss 0.00116663406293\n",
      "Epoch 25::Minibatch 311::LR 0.0446153846154 --> Loss 0.00177040278912\n",
      "Epoch 25::Minibatch 312::LR 0.0446153846154 --> Loss 0.00289139886697\n",
      "Epoch 25::Minibatch 313::LR 0.0446153846154 --> Loss 0.00236876686414\n",
      "Epoch 25::Minibatch 314::LR 0.0446153846154 --> Loss 0.00192202866077\n",
      "Epoch 25::Minibatch 315::LR 0.0446153846154 --> Loss 0.00102818707625\n",
      "Epoch 25::Minibatch 316::LR 0.0446153846154 --> Loss 0.00233837723732\n",
      "Epoch 25::Minibatch 317::LR 0.0446153846154 --> Loss 0.00155703306198\n",
      "Epoch 25::Minibatch 318::LR 0.0446153846154 --> Loss 0.00127595523993\n",
      "Epoch 25::Minibatch 319::LR 0.0446153846154 --> Loss 0.00230358044306\n",
      "Epoch 25::Minibatch 320::LR 0.0446153846154 --> Loss 0.0031058549881\n",
      "Epoch 25::Minibatch 321::LR 0.0446153846154 --> Loss 0.000841461122036\n",
      "Epoch 25::Minibatch 322::LR 0.0446153846154 --> Loss 0.00355623563131\n",
      "Epoch 25::Minibatch 323::LR 0.0446153846154 --> Loss 0.0034652586778\n",
      "Epoch 25::Minibatch 324::LR 0.0446153846154 --> Loss 0.00264302949111\n",
      "Epoch 25::Minibatch 325::LR 0.0446153846154 --> Loss 0.00238230427106\n",
      "Epoch 25::Minibatch 326::LR 0.0446153846154 --> Loss 0.00541219711304\n",
      "Epoch 25::Minibatch 327::LR 0.0446153846154 --> Loss 0.00224616090457\n",
      "Epoch 25::Minibatch 328::LR 0.0446153846154 --> Loss 0.0030897996823\n",
      "Epoch 25::Minibatch 329::LR 0.0446153846154 --> Loss 0.00120466222366\n",
      "Epoch 25::Minibatch 330::LR 0.0446153846154 --> Loss 0.00159237484137\n",
      "Epoch 25::Minibatch 331::LR 0.0446153846154 --> Loss 0.00253584305445\n",
      "Epoch 25::Minibatch 332::LR 0.0446153846154 --> Loss 0.00247850616773\n",
      "Epoch 25::Minibatch 333::LR 0.0446153846154 --> Loss 0.00145651638508\n",
      "Epoch 25::Minibatch 334::LR 0.0446153846154 --> Loss 0.00441992600759\n",
      "Epoch 25::Minibatch 335::LR 0.0446153846154 --> Loss 0.00189014554024\n",
      "Epoch 25::Minibatch 336::LR 0.0446153846154 --> Loss 0.00222132722537\n",
      "Epoch 25::Minibatch 337::LR 0.0446153846154 --> Loss 0.00360115011533\n",
      "Epoch 25::Minibatch 338::LR 0.0446153846154 --> Loss 0.000539699395498\n",
      "Epoch 25::Minibatch 339::LR 0.0446153846154 --> Loss 0.00329157729944\n",
      "Epoch 25::Minibatch 340::LR 0.0446153846154 --> Loss 0.00383601864179\n",
      "Epoch 25::Minibatch 341::LR 0.0446153846154 --> Loss 0.00452821016312\n",
      "Epoch 25::Minibatch 342::LR 0.0446153846154 --> Loss 0.00308130860329\n",
      "Epoch 25::Minibatch 343::LR 0.0446153846154 --> Loss 0.00164991557598\n",
      "Epoch 25::Minibatch 344::LR 0.0446153846154 --> Loss 0.00315484046936\n",
      "Epoch 25::Minibatch 345::LR 0.0446153846154 --> Loss 0.00416777133942\n",
      "Epoch 25::Minibatch 346::LR 0.0446153846154 --> Loss 0.00551762382189\n",
      "Epoch 25::Minibatch 347::LR 0.0446153846154 --> Loss 0.000824293891589\n",
      "Epoch 25::Minibatch 348::LR 0.0446153846154 --> Loss 0.00317328035831\n",
      "Epoch 25::Minibatch 349::LR 0.0446153846154 --> Loss 0.00343444347382\n",
      "Epoch 25::Minibatch 350::LR 0.0446153846154 --> Loss 0.00168373922507\n",
      "Epoch 25::Minibatch 351::LR 0.0446153846154 --> Loss 0.0034602089723\n",
      "Epoch 25::Minibatch 352::LR 0.0446153846154 --> Loss 0.00492716908455\n",
      "Epoch 25::Minibatch 353::LR 0.0446153846154 --> Loss 0.00352993130684\n",
      "Epoch 25::Minibatch 354::LR 0.0446153846154 --> Loss 0.00294550597668\n",
      "Epoch 25::Minibatch 355::LR 0.0446153846154 --> Loss 0.00618552605311\n",
      "Epoch 25::Minibatch 356::LR 0.0446153846154 --> Loss 0.00313201665878\n",
      "Epoch 25::Minibatch 357::LR 0.0446153846154 --> Loss 0.00113936185837\n",
      "Epoch 25::Minibatch 358::LR 0.0446153846154 --> Loss 0.00202853381634\n",
      "Epoch 25::Minibatch 359::LR 0.0446153846154 --> Loss 0.0026949797074\n",
      "Epoch 25::Minibatch 360::LR 0.0446153846154 --> Loss 0.00235634346803\n",
      "Epoch 25::Minibatch 361::LR 0.0446153846154 --> Loss 0.00233519931634\n",
      "Epoch 25::Minibatch 362::LR 0.0446153846154 --> Loss 0.00231271584829\n",
      "Epoch 25::Minibatch 363::LR 0.0446153846154 --> Loss 0.00064458027482\n",
      "Epoch 25::Minibatch 364::LR 0.0446153846154 --> Loss 0.00198433101177\n",
      "Epoch 25::Minibatch 365::LR 0.0446153846154 --> Loss 0.00204357186953\n",
      "Epoch 25::Minibatch 366::LR 0.0446153846154 --> Loss 0.00217226584752\n",
      "Epoch 25::Minibatch 367::LR 0.0446153846154 --> Loss 0.00103185514609\n",
      "Epoch 25::Minibatch 368::LR 0.0446153846154 --> Loss 0.000976057151953\n",
      "Epoch 25::Minibatch 369::LR 0.0446153846154 --> Loss 0.00282043099403\n",
      "Epoch 25::Minibatch 370::LR 0.0446153846154 --> Loss 0.00223671476046\n",
      "Epoch 25::Minibatch 371::LR 0.0446153846154 --> Loss 0.00186297933261\n",
      "Epoch 25::Minibatch 372::LR 0.0446153846154 --> Loss 0.000429928203424\n",
      "Epoch 25::Minibatch 373::LR 0.0446153846154 --> Loss 0.00178972959518\n",
      "Epoch 25::Minibatch 374::LR 0.0446153846154 --> Loss 0.00222641527653\n",
      "Epoch 25::Minibatch 375::LR 0.0446153846154 --> Loss 0.00186383187771\n",
      "Epoch 25::Minibatch 376::LR 0.0446153846154 --> Loss 0.00122504095236\n",
      "Epoch 25::Minibatch 377::LR 0.0446153846154 --> Loss 0.00192328075568\n",
      "Epoch 25::Minibatch 378::LR 0.0446153846154 --> Loss 0.00211066762606\n",
      "Epoch 25::Minibatch 379::LR 0.0446153846154 --> Loss 0.00234619160493\n",
      "Epoch 25::Minibatch 380::LR 0.0446153846154 --> Loss 0.00157452265422\n",
      "Epoch 25::Minibatch 381::LR 0.0446153846154 --> Loss 0.000986213684082\n",
      "Epoch 25::Minibatch 382::LR 0.0446153846154 --> Loss 0.00202141304811\n",
      "Epoch 25::Minibatch 383::LR 0.0446153846154 --> Loss 0.00197195907434\n",
      "Epoch 25::Minibatch 384::LR 0.0446153846154 --> Loss 0.00108271072308\n",
      "Epoch 25::Minibatch 385::LR 0.0446153846154 --> Loss 0.00104425807794\n",
      "Epoch 25::Minibatch 386::LR 0.0446153846154 --> Loss 0.00220697720846\n",
      "Epoch 25::Minibatch 387::LR 0.0446153846154 --> Loss 0.00235312541326\n",
      "Epoch 25::Minibatch 388::LR 0.0446153846154 --> Loss 0.00118230372667\n",
      "Epoch 25::Minibatch 389::LR 0.0446153846154 --> Loss 0.00178702851137\n",
      "Epoch 25::Minibatch 390::LR 0.0446153846154 --> Loss 0.003385724624\n",
      "Epoch 25::Minibatch 391::LR 0.0446153846154 --> Loss 0.00260137935479\n",
      "Epoch 25::Minibatch 392::LR 0.0446153846154 --> Loss 0.00258067905903\n",
      "Epoch 25::Minibatch 393::LR 0.0446153846154 --> Loss 0.00274434963862\n",
      "Epoch 25::Minibatch 394::LR 0.0446153846154 --> Loss 0.00203755458196\n",
      "Epoch 25::Minibatch 395::LR 0.0446153846154 --> Loss 0.00205941994985\n",
      "Epoch 25::Minibatch 396::LR 0.0446153846154 --> Loss 0.00193104465803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 397::LR 0.0446153846154 --> Loss 0.00206686735153\n",
      "Epoch 25::Minibatch 398::LR 0.0446153846154 --> Loss 0.00205389579137\n",
      "Epoch 25::Minibatch 399::LR 0.0446153846154 --> Loss 0.00236393411954\n",
      "Epoch 25::Minibatch 400::LR 0.0446153846154 --> Loss 0.00200235585372\n",
      "Epoch 25::Minibatch 401::LR 0.0446153846154 --> Loss 0.003426207304\n",
      "Epoch 25::Minibatch 402::LR 0.0446153846154 --> Loss 0.00173762281736\n",
      "Epoch 25::Minibatch 403::LR 0.0446153846154 --> Loss 0.0014277963837\n",
      "Epoch 25::Minibatch 404::LR 0.0446153846154 --> Loss 0.00138440211614\n",
      "Epoch 25::Minibatch 405::LR 0.0446153846154 --> Loss 0.00338706453641\n",
      "Epoch 25::Minibatch 406::LR 0.0446153846154 --> Loss 0.00237797101339\n",
      "Epoch 25::Minibatch 407::LR 0.0446153846154 --> Loss 0.00170733789603\n",
      "Epoch 25::Minibatch 408::LR 0.0446153846154 --> Loss 0.000430010259151\n",
      "Epoch 25::Minibatch 409::LR 0.0446153846154 --> Loss 0.00224479516347\n",
      "Epoch 25::Minibatch 410::LR 0.0446153846154 --> Loss 0.0031461250782\n",
      "Epoch 25::Minibatch 411::LR 0.0446153846154 --> Loss 0.00163821955522\n",
      "Epoch 25::Minibatch 412::LR 0.0446153846154 --> Loss 0.000940990547339\n",
      "Epoch 25::Minibatch 413::LR 0.0446153846154 --> Loss 0.00195601582527\n",
      "Epoch 25::Minibatch 414::LR 0.0446153846154 --> Loss 0.00184531768163\n",
      "Epoch 25::Minibatch 415::LR 0.0446153846154 --> Loss 0.00114791790644\n",
      "Epoch 25::Minibatch 416::LR 0.0446153846154 --> Loss 0.000790972113609\n",
      "Epoch 25::Minibatch 417::LR 0.0446153846154 --> Loss 0.0016744796435\n",
      "Epoch 25::Minibatch 418::LR 0.0446153846154 --> Loss 0.00263229548931\n",
      "Epoch 25::Minibatch 419::LR 0.0446153846154 --> Loss 0.000486651261648\n",
      "Epoch 25::Minibatch 420::LR 0.0446153846154 --> Loss 0.00068237627546\n",
      "Epoch 25::Minibatch 421::LR 0.0446153846154 --> Loss 0.00188490728537\n",
      "Epoch 25::Minibatch 422::LR 0.0446153846154 --> Loss 0.00207933108012\n",
      "Epoch 25::Minibatch 423::LR 0.0446153846154 --> Loss 0.000965154767036\n",
      "Epoch 25::Minibatch 424::LR 0.0446153846154 --> Loss 0.00151798854272\n",
      "Epoch 25::Minibatch 425::LR 0.0446153846154 --> Loss 0.00287876526515\n",
      "Epoch 25::Minibatch 426::LR 0.0446153846154 --> Loss 0.0019807134072\n",
      "Epoch 25::Minibatch 427::LR 0.0446153846154 --> Loss 0.000713449815909\n",
      "Epoch 25::Minibatch 428::LR 0.0446153846154 --> Loss 0.000973638494809\n",
      "Epoch 25::Minibatch 429::LR 0.0446153846154 --> Loss 0.00228533665339\n",
      "Epoch 25::Minibatch 430::LR 0.0446153846154 --> Loss 0.0086439649264\n",
      "Epoch 25::Minibatch 431::LR 0.0446153846154 --> Loss 0.00370573997498\n",
      "Epoch 25::Minibatch 432::LR 0.0446153846154 --> Loss 0.00420391599337\n",
      "Epoch 25::Minibatch 433::LR 0.0446153846154 --> Loss 0.00253946781158\n",
      "Epoch 25::Minibatch 434::LR 0.0446153846154 --> Loss 0.00248052597046\n",
      "Epoch 25::Minibatch 435::LR 0.0446153846154 --> Loss 0.00227161924044\n",
      "Epoch 25::Minibatch 436::LR 0.0446153846154 --> Loss 0.00162419150273\n",
      "Epoch 25::Minibatch 437::LR 0.0446153846154 --> Loss 0.0029646440347\n",
      "Epoch 25::Minibatch 438::LR 0.0446153846154 --> Loss 0.00238244891167\n",
      "Epoch 25::Minibatch 439::LR 0.0446153846154 --> Loss 0.00197079261144\n",
      "Epoch 25::Minibatch 440::LR 0.0446153846154 --> Loss 0.00305764337381\n",
      "Epoch 25::Minibatch 441::LR 0.0446153846154 --> Loss 0.00285446266333\n",
      "Epoch 25::Minibatch 442::LR 0.0446153846154 --> Loss 0.00257734298706\n",
      "Epoch 25::Minibatch 443::LR 0.0446153846154 --> Loss 0.00352581699689\n",
      "Epoch 25::Minibatch 444::LR 0.0446153846154 --> Loss 0.00273769994577\n",
      "Epoch 25::Minibatch 445::LR 0.0446153846154 --> Loss 0.000861484805743\n",
      "Epoch 25::Minibatch 446::LR 0.0446153846154 --> Loss 0.0013912020127\n",
      "Epoch 25::Minibatch 447::LR 0.0446153846154 --> Loss 0.00233823696772\n",
      "Epoch 25::Minibatch 448::LR 0.0446153846154 --> Loss 0.00233487665653\n",
      "Epoch 25::Minibatch 449::LR 0.0446153846154 --> Loss 0.0036232872804\n",
      "Epoch 25::Minibatch 450::LR 0.0446153846154 --> Loss 0.00218345940113\n",
      "Epoch 25::Minibatch 451::LR 0.0446153846154 --> Loss 0.00389708558718\n",
      "Epoch 25::Minibatch 452::LR 0.0446153846154 --> Loss 0.00231955587864\n",
      "Epoch 25::Minibatch 453::LR 0.0446153846154 --> Loss 0.00035606858631\n",
      "Epoch 25::Minibatch 454::LR 0.0446153846154 --> Loss 0.00350567539533\n",
      "Epoch 25::Minibatch 455::LR 0.0446153846154 --> Loss 0.00262545208136\n",
      "Epoch 25::Minibatch 456::LR 0.0446153846154 --> Loss 0.00306361079216\n",
      "Epoch 25::Minibatch 457::LR 0.0446153846154 --> Loss 0.00189674695333\n",
      "Epoch 25::Minibatch 458::LR 0.0446153846154 --> Loss 0.000723882913589\n",
      "Epoch 25::Minibatch 459::LR 0.0446153846154 --> Loss 0.00393281579018\n",
      "Epoch 25::Minibatch 460::LR 0.0446153846154 --> Loss 0.00247330327829\n",
      "Epoch 25::Minibatch 461::LR 0.0446153846154 --> Loss 0.00376274267832\n",
      "Epoch 25::Minibatch 462::LR 0.0446153846154 --> Loss 0.000375528136889\n",
      "Epoch 25::Minibatch 463::LR 0.0446153846154 --> Loss 0.00428883035978\n",
      "Epoch 25::Minibatch 464::LR 0.0446153846154 --> Loss 0.00197423716386\n",
      "Epoch 25::Minibatch 465::LR 0.0446153846154 --> Loss 0.00478972792625\n",
      "Epoch 25::Minibatch 466::LR 0.0446153846154 --> Loss 0.00501967867215\n",
      "Epoch 25::Minibatch 467::LR 0.0446153846154 --> Loss 0.00528952598572\n",
      "Epoch 25::Minibatch 468::LR 0.0446153846154 --> Loss 0.00580884655317\n",
      "Epoch 25::Minibatch 469::LR 0.0446153846154 --> Loss 0.0062021112442\n",
      "Epoch 25::Minibatch 470::LR 0.0446153846154 --> Loss 0.00362417260806\n",
      "Epoch 25::Minibatch 471::LR 0.0446153846154 --> Loss 0.00168054858843\n",
      "Epoch 25::Minibatch 472::LR 0.0446153846154 --> Loss 0.00354806462924\n",
      "Epoch 25::Minibatch 473::LR 0.0446153846154 --> Loss 0.00228584011396\n",
      "Epoch 25::Minibatch 474::LR 0.0446153846154 --> Loss 0.000691260745128\n",
      "Epoch 25::Minibatch 475::LR 0.0446153846154 --> Loss 0.00485234181086\n",
      "Epoch 25::Minibatch 476::LR 0.0446153846154 --> Loss 0.00766112327576\n",
      "Epoch 25::Minibatch 477::LR 0.0446153846154 --> Loss 0.000917666256428\n",
      "Epoch 25::Minibatch 478::LR 0.0446153846154 --> Loss 0.00242651343346\n",
      "Epoch 25::Minibatch 479::LR 0.0446153846154 --> Loss 0.00195973257224\n",
      "Epoch 25::Minibatch 480::LR 0.0446153846154 --> Loss 0.00151976366838\n",
      "Epoch 25::Minibatch 481::LR 0.0446153846154 --> Loss 0.000956120093664\n",
      "Epoch 25::Minibatch 482::LR 0.0446153846154 --> Loss 0.00207625667254\n",
      "Epoch 25::Minibatch 483::LR 0.0446153846154 --> Loss 0.00307247658571\n",
      "Epoch 25::Minibatch 484::LR 0.0446153846154 --> Loss 0.00344999154409\n",
      "Epoch 25::Minibatch 485::LR 0.0446153846154 --> Loss 0.000758227308591\n",
      "Epoch 25::Minibatch 486::LR 0.0446153846154 --> Loss 0.00284361561139\n",
      "Epoch 25::Minibatch 487::LR 0.0446153846154 --> Loss 0.00331583321095\n",
      "Epoch 25::Minibatch 488::LR 0.0446153846154 --> Loss 0.00202834149202\n",
      "Epoch 25::Minibatch 489::LR 0.0446153846154 --> Loss 0.00311703960101\n",
      "Epoch 25::Minibatch 490::LR 0.0446153846154 --> Loss 0.000409830609957\n",
      "Epoch 25::Minibatch 491::LR 0.0446153846154 --> Loss 0.00338420112928\n",
      "Epoch 25::Minibatch 492::LR 0.0446153846154 --> Loss 0.00306102772554\n",
      "Epoch 25::Minibatch 493::LR 0.0446153846154 --> Loss 0.00302633444468\n",
      "Epoch 25::Minibatch 494::LR 0.0446153846154 --> Loss 0.000734382669131\n",
      "Epoch 25::Minibatch 495::LR 0.0446153846154 --> Loss 0.00184699416161\n",
      "Epoch 25::Minibatch 496::LR 0.0446153846154 --> Loss 0.00281062404315\n",
      "Epoch 25::Minibatch 497::LR 0.0446153846154 --> Loss 0.000916838347912\n",
      "Epoch 25::Minibatch 498::LR 0.0446153846154 --> Loss 0.000552596946557\n",
      "Epoch 25::Minibatch 499::LR 0.0446153846154 --> Loss 0.00347714940707\n",
      "Epoch 25::Minibatch 500::LR 0.0446153846154 --> Loss 0.00143101950487\n",
      "Epoch 25::Minibatch 501::LR 0.0446153846154 --> Loss 0.00210805654526\n",
      "Epoch 25::Minibatch 502::LR 0.0446153846154 --> Loss 0.00376595258713\n",
      "Epoch 25::Minibatch 503::LR 0.0446153846154 --> Loss 0.00722141742706\n",
      "Epoch 25::Minibatch 504::LR 0.0446153846154 --> Loss 0.00706104516983\n",
      "Epoch 25::Minibatch 505::LR 0.0446153846154 --> Loss 0.00407858928045\n",
      "Epoch 25::Minibatch 506::LR 0.0446153846154 --> Loss 0.00336414456367\n",
      "Epoch 25::Minibatch 507::LR 0.0446153846154 --> Loss 0.0058673286438\n",
      "Epoch 25::Minibatch 508::LR 0.0446153846154 --> Loss 0.00339784582456\n",
      "Epoch 25::Minibatch 509::LR 0.0446153846154 --> Loss 0.00436047116915\n",
      "Epoch 25::Minibatch 510::LR 0.0446153846154 --> Loss 0.00445170323054\n",
      "Epoch 25::Minibatch 511::LR 0.0446153846154 --> Loss 0.0039584728082\n",
      "Epoch 25::Minibatch 512::LR 0.0446153846154 --> Loss 0.002682082057\n",
      "Epoch 25::Minibatch 513::LR 0.0446153846154 --> Loss 0.000611934413513\n",
      "Epoch 25::Minibatch 514::LR 0.0446153846154 --> Loss 0.00264845728874\n",
      "Epoch 25::Minibatch 515::LR 0.0446153846154 --> Loss 0.00299762050311\n",
      "Epoch 25::Minibatch 516::LR 0.0446153846154 --> Loss 0.00396823724111\n",
      "Epoch 25::Minibatch 517::LR 0.0446153846154 --> Loss 0.00357179284096\n",
      "Epoch 25::Minibatch 518::LR 0.0446153846154 --> Loss 0.00257870475451\n",
      "Epoch 25::Minibatch 519::LR 0.0446153846154 --> Loss 0.00350133577983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 520::LR 0.0446153846154 --> Loss 0.00546046455701\n",
      "Epoch 25::Minibatch 521::LR 0.0446153846154 --> Loss 0.00556312203407\n",
      "Epoch 25::Minibatch 522::LR 0.0446153846154 --> Loss 0.00751567920049\n",
      "Epoch 25::Minibatch 523::LR 0.0446153846154 --> Loss 0.000629115353028\n",
      "Epoch 25::Minibatch 524::LR 0.0446153846154 --> Loss 0.00140363494555\n",
      "Epoch 25::Minibatch 525::LR 0.0446153846154 --> Loss 0.00312822461128\n",
      "Epoch 25::Minibatch 526::LR 0.0446153846154 --> Loss 0.00382586995761\n",
      "Epoch 25::Minibatch 527::LR 0.0446153846154 --> Loss 0.00216853876909\n",
      "Epoch 25::Minibatch 528::LR 0.0446153846154 --> Loss 0.000966958602269\n",
      "Epoch 25::Minibatch 529::LR 0.0446153846154 --> Loss 0.00393377741178\n",
      "Epoch 25::Minibatch 530::LR 0.0446153846154 --> Loss 0.00394990642865\n",
      "Epoch 25::Minibatch 531::LR 0.0446153846154 --> Loss 0.00350851178169\n",
      "Epoch 25::Minibatch 532::LR 0.0446153846154 --> Loss 0.00264686644077\n",
      "Epoch 25::Minibatch 533::LR 0.0446153846154 --> Loss 0.00495196580887\n",
      "Epoch 25::Minibatch 534::LR 0.0446153846154 --> Loss 0.00373417655627\n",
      "Epoch 25::Minibatch 535::LR 0.0446153846154 --> Loss 0.00328879654408\n",
      "Epoch 25::Minibatch 536::LR 0.0446153846154 --> Loss 0.00210466047128\n",
      "Epoch 25::Minibatch 537::LR 0.0446153846154 --> Loss 0.000595972190301\n",
      "Epoch 25::Minibatch 538::LR 0.0446153846154 --> Loss 0.00165311167638\n",
      "Epoch 25::Minibatch 539::LR 0.0446153846154 --> Loss 0.00335712393125\n",
      "Epoch 25::Minibatch 540::LR 0.0446153846154 --> Loss 0.00340359926224\n",
      "Epoch 25::Minibatch 541::LR 0.0446153846154 --> Loss 0.00286633253098\n",
      "Epoch 25::Minibatch 542::LR 0.0446153846154 --> Loss 0.00246852894624\n",
      "Epoch 25::Minibatch 543::LR 0.0446153846154 --> Loss 0.0026363158226\n",
      "Epoch 25::Minibatch 544::LR 0.0446153846154 --> Loss 0.00395320971807\n",
      "Epoch 25::Minibatch 545::LR 0.0446153846154 --> Loss 0.0020039053758\n",
      "Epoch 25::Minibatch 546::LR 0.0446153846154 --> Loss 0.000654288679361\n",
      "Epoch 25::Minibatch 547::LR 0.0446153846154 --> Loss 0.00259480098883\n",
      "Epoch 25::Minibatch 548::LR 0.0446153846154 --> Loss 0.00350249210993\n",
      "Epoch 25::Minibatch 549::LR 0.0446153846154 --> Loss 0.00875453074773\n",
      "Epoch 25::Minibatch 550::LR 0.0446153846154 --> Loss 0.00117604722579\n",
      "Epoch 25::Minibatch 551::LR 0.0446153846154 --> Loss 0.00245118816694\n",
      "Epoch 25::Minibatch 552::LR 0.0446153846154 --> Loss 0.00346868515015\n",
      "Epoch 25::Minibatch 553::LR 0.0446153846154 --> Loss 0.00305656691392\n",
      "Epoch 25::Minibatch 554::LR 0.0446153846154 --> Loss 0.00367688457171\n",
      "Epoch 25::Minibatch 555::LR 0.0446153846154 --> Loss 0.000954324603081\n",
      "Epoch 25::Minibatch 556::LR 0.0446153846154 --> Loss 0.0019435975949\n",
      "Epoch 25::Minibatch 557::LR 0.0446153846154 --> Loss 0.00241497377555\n",
      "Epoch 25::Minibatch 558::LR 0.0446153846154 --> Loss 0.00363856832186\n",
      "Epoch 25::Minibatch 559::LR 0.0446153846154 --> Loss 0.00367839574814\n",
      "Epoch 25::Minibatch 560::LR 0.0446153846154 --> Loss 0.00306417822838\n",
      "Epoch 25::Minibatch 561::LR 0.0446153846154 --> Loss 0.00264663497607\n",
      "Epoch 25::Minibatch 562::LR 0.0446153846154 --> Loss 0.00235119024913\n",
      "Epoch 25::Minibatch 563::LR 0.0446153846154 --> Loss 0.00398773749669\n",
      "Epoch 25::Minibatch 564::LR 0.0446153846154 --> Loss 0.00306883295377\n",
      "Epoch 25::Minibatch 565::LR 0.0446153846154 --> Loss 0.00361220320066\n",
      "Epoch 25::Minibatch 566::LR 0.0446153846154 --> Loss 0.00221262057622\n",
      "Epoch 25::Minibatch 567::LR 0.0446153846154 --> Loss 0.00253808200359\n",
      "Epoch 25::Minibatch 568::LR 0.0446153846154 --> Loss 0.00176651239395\n",
      "Epoch 25::Minibatch 569::LR 0.0446153846154 --> Loss 0.000561258395513\n",
      "Epoch 25::Minibatch 570::LR 0.0446153846154 --> Loss 0.00165172050397\n",
      "Epoch 25::Minibatch 571::LR 0.0446153846154 --> Loss 0.00212200462818\n",
      "Epoch 25::Minibatch 572::LR 0.0446153846154 --> Loss 0.00227391441663\n",
      "Epoch 25::Minibatch 573::LR 0.0446153846154 --> Loss 0.00146437128385\n",
      "Epoch 25::Minibatch 574::LR 0.0446153846154 --> Loss 0.00104520748059\n",
      "Epoch 25::Minibatch 575::LR 0.0446153846154 --> Loss 0.00174176096916\n",
      "Epoch 25::Minibatch 576::LR 0.0446153846154 --> Loss 0.0020587682724\n",
      "Epoch 25::Minibatch 577::LR 0.0446153846154 --> Loss 0.00162645548582\n",
      "Epoch 25::Minibatch 578::LR 0.0446153846154 --> Loss 0.00127174387376\n",
      "Epoch 25::Minibatch 579::LR 0.0446153846154 --> Loss 0.00118827700615\n",
      "Epoch 25::Minibatch 580::LR 0.0446153846154 --> Loss 0.00192592362563\n",
      "Epoch 25::Minibatch 581::LR 0.0446153846154 --> Loss 0.0017087350289\n",
      "Epoch 25::Minibatch 582::LR 0.0446153846154 --> Loss 0.00415846625964\n",
      "Epoch 25::Minibatch 583::LR 0.0446153846154 --> Loss 0.000947169065475\n",
      "Epoch 25::Minibatch 584::LR 0.0446153846154 --> Loss 0.00130734831095\n",
      "Epoch 25::Minibatch 585::LR 0.0446153846154 --> Loss 0.00407547473907\n",
      "Epoch 25::Minibatch 586::LR 0.0446153846154 --> Loss 0.00382770379384\n",
      "Epoch 25::Minibatch 587::LR 0.0446153846154 --> Loss 0.00111818681161\n",
      "Epoch 25::Minibatch 588::LR 0.0446153846154 --> Loss 0.00138548970222\n",
      "Epoch 25::Minibatch 589::LR 0.0446153846154 --> Loss 0.00275480469068\n",
      "Epoch 25::Minibatch 590::LR 0.0446153846154 --> Loss 0.00185493528843\n",
      "Epoch 25::Minibatch 591::LR 0.0446153846154 --> Loss 0.00283112545808\n",
      "Epoch 25::Minibatch 592::LR 0.0446153846154 --> Loss 0.00116165926059\n",
      "Epoch 25::Minibatch 593::LR 0.0446153846154 --> Loss 0.00251932700475\n",
      "Epoch 25::Minibatch 594::LR 0.0446153846154 --> Loss 0.00263909916083\n",
      "Epoch 25::Minibatch 595::LR 0.0446153846154 --> Loss 0.00304347038269\n",
      "Epoch 25::Minibatch 596::LR 0.0446153846154 --> Loss 0.00188033103943\n",
      "Epoch 25::Minibatch 597::LR 0.0446153846154 --> Loss 0.00117858370145\n",
      "Epoch 25::Minibatch 598::LR 0.0446153846154 --> Loss 0.0028813268741\n",
      "Epoch 25::Minibatch 599::LR 0.0446153846154 --> Loss 0.0018175693353\n",
      "Epoch 25::Minibatch 600::LR 0.0446153846154 --> Loss 0.00216393709183\n",
      "Epoch 25::Minibatch 601::LR 0.0446153846154 --> Loss 0.00379309574763\n",
      "Epoch 25::Minibatch 602::LR 0.0446153846154 --> Loss 0.00209705134233\n",
      "Epoch 25::Minibatch 603::LR 0.0446153846154 --> Loss 0.00262739578883\n",
      "Epoch 25::Minibatch 604::LR 0.0446153846154 --> Loss 0.00164170900981\n",
      "Epoch 25::Minibatch 605::LR 0.0446153846154 --> Loss 0.0023178990682\n",
      "Epoch 25::Minibatch 606::LR 0.0446153846154 --> Loss 0.00188402871291\n",
      "Epoch 25::Minibatch 607::LR 0.0446153846154 --> Loss 0.000833207120498\n",
      "Epoch 25::Minibatch 608::LR 0.0446153846154 --> Loss 0.00156656285127\n",
      "Epoch 25::Minibatch 609::LR 0.0446153846154 --> Loss 0.00241078356902\n",
      "Epoch 25::Minibatch 610::LR 0.0446153846154 --> Loss 0.00403040369352\n",
      "Epoch 25::Minibatch 611::LR 0.0446153846154 --> Loss 0.00263893981775\n",
      "Epoch 25::Minibatch 612::LR 0.0446153846154 --> Loss 0.000475082993507\n",
      "Epoch 25::Minibatch 613::LR 0.0446153846154 --> Loss 0.00131053427855\n",
      "Epoch 25::Minibatch 614::LR 0.0446153846154 --> Loss 0.00242351055145\n",
      "Epoch 25::Minibatch 615::LR 0.0446153846154 --> Loss 0.0016668287913\n",
      "Epoch 25::Minibatch 616::LR 0.0446153846154 --> Loss 0.000920623938243\n",
      "Epoch 25::Minibatch 617::LR 0.0446153846154 --> Loss 0.000495033462842\n",
      "Epoch 25::Minibatch 618::LR 0.0446153846154 --> Loss 0.00281925797462\n",
      "Epoch 25::Minibatch 619::LR 0.0446153846154 --> Loss 0.00192732771238\n",
      "Epoch 25::Minibatch 620::LR 0.0446153846154 --> Loss 0.00170171479384\n",
      "Epoch 25::Minibatch 621::LR 0.0446153846154 --> Loss 0.000847859879335\n",
      "Epoch 25::Minibatch 622::LR 0.0446153846154 --> Loss 0.000786760548751\n",
      "Epoch 25::Minibatch 623::LR 0.0446153846154 --> Loss 0.00222102880478\n",
      "Epoch 25::Minibatch 624::LR 0.0446153846154 --> Loss 0.00178571005662\n",
      "Epoch 25::Minibatch 625::LR 0.0446153846154 --> Loss 0.00276643335819\n",
      "Epoch 25::Minibatch 626::LR 0.0446153846154 --> Loss 0.00391900340716\n",
      "Epoch 25::Minibatch 627::LR 0.0446153846154 --> Loss 0.00128654122353\n",
      "Epoch 25::Minibatch 628::LR 0.0446153846154 --> Loss 0.000884480973085\n",
      "Epoch 25::Minibatch 629::LR 0.0446153846154 --> Loss 0.00321026186148\n",
      "Epoch 25::Minibatch 630::LR 0.0446153846154 --> Loss 0.00313569525878\n",
      "Epoch 25::Minibatch 631::LR 0.0446153846154 --> Loss 0.00561796029409\n",
      "Epoch 25::Minibatch 632::LR 0.0446153846154 --> Loss 0.000791038821141\n",
      "Epoch 25::Minibatch 633::LR 0.0446153846154 --> Loss 0.00163362443447\n",
      "Epoch 25::Minibatch 634::LR 0.0446153846154 --> Loss 0.00321312010288\n",
      "Epoch 25::Minibatch 635::LR 0.0446153846154 --> Loss 0.00548114577929\n",
      "Epoch 25::Minibatch 636::LR 0.0446153846154 --> Loss 0.00476487000783\n",
      "Epoch 25::Minibatch 637::LR 0.0446153846154 --> Loss 0.000736820151409\n",
      "Epoch 25::Minibatch 638::LR 0.0446153846154 --> Loss 0.001489952902\n",
      "Epoch 25::Minibatch 639::LR 0.0446153846154 --> Loss 0.00322995940844\n",
      "Epoch 25::Minibatch 640::LR 0.0446153846154 --> Loss 0.00474874854088\n",
      "Epoch 25::Minibatch 641::LR 0.0446153846154 --> Loss 0.00307869474093\n",
      "Epoch 25::Minibatch 642::LR 0.0446153846154 --> Loss 0.000534770339727\n",
      "Epoch 25::Minibatch 643::LR 0.0446153846154 --> Loss 0.0023226449887\n",
      "Epoch 25::Minibatch 644::LR 0.0446153846154 --> Loss 0.0039110271136\n",
      "Epoch 25::Minibatch 645::LR 0.0446153846154 --> Loss 0.00432923197746\n",
      "Epoch 25::Minibatch 646::LR 0.0446153846154 --> Loss 0.00150151083867\n",
      "Epoch 25::Minibatch 647::LR 0.0446153846154 --> Loss 0.000485409200191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 648::LR 0.0446153846154 --> Loss 0.00285216331482\n",
      "Epoch 25::Minibatch 649::LR 0.0446153846154 --> Loss 0.0033628209432\n",
      "Epoch 25::Minibatch 650::LR 0.0446153846154 --> Loss 0.00323897004128\n",
      "Epoch 25::Minibatch 651::LR 0.0446153846154 --> Loss 0.00135109146436\n",
      "Epoch 25::Minibatch 652::LR 0.0446153846154 --> Loss 0.000784728129705\n",
      "Epoch 25::Minibatch 653::LR 0.0446153846154 --> Loss 0.00282677352428\n",
      "Epoch 25::Minibatch 654::LR 0.0446153846154 --> Loss 0.00312637130419\n",
      "Epoch 25::Minibatch 655::LR 0.0446153846154 --> Loss 0.00356653134028\n",
      "Epoch 25::Minibatch 656::LR 0.0446153846154 --> Loss 0.000754532168309\n",
      "Epoch 25::Minibatch 657::LR 0.0446153846154 --> Loss 0.00226165393988\n",
      "Epoch 25::Minibatch 658::LR 0.0446153846154 --> Loss 0.00466830968857\n",
      "Epoch 25::Minibatch 659::LR 0.0446153846154 --> Loss 0.00225639204184\n",
      "Epoch 25::Minibatch 660::LR 0.0446153846154 --> Loss 0.00262257417043\n",
      "Epoch 25::Minibatch 661::LR 0.0446153846154 --> Loss 0.00236413558324\n",
      "Epoch 25::Minibatch 662::LR 0.0446153846154 --> Loss 0.00180105725924\n",
      "Epoch 25::Minibatch 663::LR 0.0446153846154 --> Loss 0.00369086186091\n",
      "Epoch 25::Minibatch 664::LR 0.0446153846154 --> Loss 0.00327277739843\n",
      "Epoch 25::Minibatch 665::LR 0.0446153846154 --> Loss 0.000707514733076\n",
      "Epoch 25::Minibatch 666::LR 0.0446153846154 --> Loss 0.00390824079514\n",
      "Epoch 25::Minibatch 667::LR 0.0446153846154 --> Loss 0.00254401842753\n",
      "Epoch 25::Minibatch 668::LR 0.0446153846154 --> Loss 0.00659685691198\n",
      "Epoch 25::Minibatch 669::LR 0.0446153846154 --> Loss 0.00108955949545\n",
      "Epoch 25::Minibatch 670::LR 0.0446153846154 --> Loss 0.00133786151807\n",
      "Epoch 25::Minibatch 671::LR 0.0446153846154 --> Loss 0.00519586920738\n",
      "Epoch 25::Minibatch 672::LR 0.0446153846154 --> Loss 0.00353160540263\n",
      "Epoch 25::Minibatch 673::LR 0.0446153846154 --> Loss 0.00161394099394\n",
      "Epoch 25::Minibatch 674::LR 0.0446153846154 --> Loss 0.000510269453128\n",
      "Epoch 25::Minibatch 675::LR 0.0446153846154 --> Loss 0.00218816717466\n",
      "Epoch 25::Minibatch 676::LR 0.0446153846154 --> Loss 0.00213897605737\n",
      "Epoch 25::Minibatch 677::LR 0.0446153846154 --> Loss 0.00274426798026\n",
      "Epoch 25::Minibatch 678::LR 0.0446153846154 --> Loss 0.00189098079999\n",
      "Epoch 25::Minibatch 679::LR 0.0446153846154 --> Loss 0.00338806827863\n",
      "Epoch 25::Minibatch 680::LR 0.0446153846154 --> Loss 0.00213218708833\n",
      "Epoch 25::Minibatch 681::LR 0.0446153846154 --> Loss 0.00241266965866\n",
      "Epoch 25::Minibatch 682::LR 0.0446153846154 --> Loss 0.000761082470417\n",
      "Epoch 25::Minibatch 683::LR 0.0446153846154 --> Loss 0.0023392889897\n",
      "Epoch 25::Minibatch 684::LR 0.0446153846154 --> Loss 0.00234151005745\n",
      "Epoch 25::Minibatch 685::LR 0.0446153846154 --> Loss 0.00285499672095\n",
      "Epoch 25::Minibatch 686::LR 0.0446153846154 --> Loss 0.00157323976358\n",
      "Epoch 25::Minibatch 687::LR 0.0446153846154 --> Loss 0.000865046779315\n",
      "Epoch 25::Minibatch 688::LR 0.0446153846154 --> Loss 0.00278102934361\n",
      "Epoch 25::Minibatch 689::LR 0.0446153846154 --> Loss 0.00249623298645\n",
      "Epoch 25::Minibatch 690::LR 0.0446153846154 --> Loss 0.00189763665199\n",
      "Epoch 25::Minibatch 691::LR 0.0446153846154 --> Loss 0.000658074220022\n",
      "Epoch 25::Minibatch 692::LR 0.0446153846154 --> Loss 0.00245001773039\n",
      "Epoch 25::Minibatch 693::LR 0.0446153846154 --> Loss 0.00259503960609\n",
      "Epoch 25::Minibatch 694::LR 0.0446153846154 --> Loss 0.00300871908665\n",
      "Epoch 25::Minibatch 695::LR 0.0446153846154 --> Loss 0.00177242517471\n",
      "Epoch 25::Minibatch 696::LR 0.0446153846154 --> Loss 0.00204138934612\n",
      "Epoch 25::Minibatch 697::LR 0.0446153846154 --> Loss 0.00140271176895\n",
      "Epoch 25::Minibatch 698::LR 0.0446153846154 --> Loss 0.0016508714358\n",
      "Epoch 25::Minibatch 699::LR 0.0446153846154 --> Loss 0.0037734178702\n",
      "Epoch 25::Minibatch 700::LR 0.0446153846154 --> Loss 0.00262266596158\n",
      "Epoch 25::Minibatch 701::LR 0.0446153846154 --> Loss 0.00192898392677\n",
      "Epoch 25::Minibatch 702::LR 0.0446153846154 --> Loss 0.0016646455725\n",
      "Epoch 25::Minibatch 703::LR 0.0446153846154 --> Loss 0.00433124343554\n",
      "Epoch 25::Minibatch 704::LR 0.0446153846154 --> Loss 0.00180420339108\n",
      "Epoch 25::Minibatch 705::LR 0.0446153846154 --> Loss 0.00285857359568\n",
      "Epoch 25::Minibatch 706::LR 0.0446153846154 --> Loss 0.00222490787506\n",
      "Epoch 25::Minibatch 707::LR 0.0446153846154 --> Loss 0.00117991318305\n",
      "Epoch 25::Minibatch 708::LR 0.0446153846154 --> Loss 0.00173206706842\n",
      "Epoch 25::Minibatch 709::LR 0.0446153846154 --> Loss 0.0016760524114\n",
      "Epoch 25::Minibatch 710::LR 0.0446153846154 --> Loss 0.00255928099155\n",
      "Epoch 25::Minibatch 711::LR 0.0446153846154 --> Loss 0.00195161163807\n",
      "Epoch 25::Minibatch 712::LR 0.0446153846154 --> Loss 0.00134640455246\n",
      "Epoch 25::Minibatch 713::LR 0.0446153846154 --> Loss 0.00178006549676\n",
      "Epoch 25::Minibatch 714::LR 0.0446153846154 --> Loss 0.00281521340211\n",
      "Epoch 25::Minibatch 715::LR 0.0446153846154 --> Loss 0.00293113331\n",
      "Epoch 25::Minibatch 716::LR 0.0446153846154 --> Loss 0.00164151837428\n",
      "Epoch 25::Minibatch 717::LR 0.0446153846154 --> Loss 0.00164553989967\n",
      "Epoch 25::Minibatch 718::LR 0.0446153846154 --> Loss 0.00126754631599\n",
      "Epoch 25::Minibatch 719::LR 0.0446153846154 --> Loss 0.00169964114825\n",
      "Epoch 25::Minibatch 720::LR 0.0446153846154 --> Loss 0.00266099830468\n",
      "Epoch 25::Minibatch 721::LR 0.0446153846154 --> Loss 0.00060928011934\n",
      "Epoch 25::Minibatch 722::LR 0.0446153846154 --> Loss 0.00467841347059\n",
      "Epoch 25::Minibatch 723::LR 0.0446153846154 --> Loss 0.00486615777016\n",
      "Epoch 25::Minibatch 724::LR 0.0446153846154 --> Loss 0.000965511103471\n",
      "Epoch 25::Minibatch 725::LR 0.0446153846154 --> Loss 0.00210642854373\n",
      "Epoch 25::Minibatch 726::LR 0.0446153846154 --> Loss 0.004046895504\n",
      "Epoch 25::Minibatch 727::LR 0.0446153846154 --> Loss 0.00317575176557\n",
      "Epoch 25::Minibatch 728::LR 0.0446153846154 --> Loss 0.000642134646575\n",
      "Epoch 25::Minibatch 729::LR 0.0446153846154 --> Loss 0.000728425433238\n",
      "Epoch 25::Minibatch 730::LR 0.0446153846154 --> Loss 0.00288878083229\n",
      "Epoch 25::Minibatch 731::LR 0.0446153846154 --> Loss 0.0025705742836\n",
      "Epoch 25::Minibatch 732::LR 0.0446153846154 --> Loss 0.00211723128955\n",
      "Epoch 25::Minibatch 733::LR 0.0446153846154 --> Loss 0.000627306650082\n",
      "Epoch 25::Minibatch 734::LR 0.0446153846154 --> Loss 0.00167918403943\n",
      "Epoch 25::Minibatch 735::LR 0.0446153846154 --> Loss 0.00241627256076\n",
      "Epoch 25::Minibatch 736::LR 0.0446153846154 --> Loss 0.00347397526105\n",
      "Epoch 25::Minibatch 737::LR 0.0446153846154 --> Loss 0.00299802879492\n",
      "Epoch 25::Minibatch 738::LR 0.0446153846154 --> Loss 0.00147757261992\n",
      "Epoch 25::Minibatch 739::LR 0.0446153846154 --> Loss 0.0024236514171\n",
      "Epoch 25::Minibatch 740::LR 0.0446153846154 --> Loss 0.00380328496297\n",
      "Epoch 25::Minibatch 741::LR 0.0446153846154 --> Loss 0.0025882011652\n",
      "Epoch 25::Minibatch 742::LR 0.0446153846154 --> Loss 0.00209659636021\n",
      "Epoch 25::Minibatch 743::LR 0.0446153846154 --> Loss 0.00146065115929\n",
      "Epoch 25::Minibatch 744::LR 0.0446153846154 --> Loss 0.00183549106121\n",
      "Epoch 25::Minibatch 745::LR 0.0446153846154 --> Loss 0.00279907862345\n",
      "Epoch 25::Minibatch 746::LR 0.0446153846154 --> Loss 0.00290449917316\n",
      "Epoch 25::Minibatch 747::LR 0.0446153846154 --> Loss 0.00177527070045\n",
      "Epoch 25::Minibatch 748::LR 0.0446153846154 --> Loss 0.000620326250792\n",
      "Epoch 25::Minibatch 749::LR 0.0446153846154 --> Loss 0.00166055401166\n",
      "Epoch 25::Minibatch 750::LR 0.0446153846154 --> Loss 0.00243695855141\n",
      "Epoch 25::Minibatch 751::LR 0.0446153846154 --> Loss 0.00283967018127\n",
      "Epoch 25::Minibatch 752::LR 0.0446153846154 --> Loss 0.0013224842151\n",
      "Epoch 25::Minibatch 753::LR 0.0446153846154 --> Loss 0.00220075984796\n",
      "Epoch 25::Minibatch 754::LR 0.0446153846154 --> Loss 0.00240797440211\n",
      "Epoch 25::Minibatch 755::LR 0.0446153846154 --> Loss 0.00266467352708\n",
      "Epoch 25::Minibatch 756::LR 0.0446153846154 --> Loss 0.00133654912313\n",
      "Epoch 25::Minibatch 757::LR 0.0446153846154 --> Loss 0.000667876104514\n",
      "Epoch 25::Minibatch 758::LR 0.0446153846154 --> Loss 0.00158086250226\n",
      "Epoch 25::Minibatch 759::LR 0.0446153846154 --> Loss 0.00356779495875\n",
      "Epoch 25::Minibatch 760::LR 0.0446153846154 --> Loss 0.0028783617417\n",
      "Epoch 25::Minibatch 761::LR 0.0446153846154 --> Loss 0.0059309609731\n",
      "Epoch 25::Minibatch 762::LR 0.0446153846154 --> Loss 0.00365406354268\n",
      "Epoch 25::Minibatch 763::LR 0.0446153846154 --> Loss 0.00348723332087\n",
      "Epoch 25::Minibatch 764::LR 0.0446153846154 --> Loss 0.00308935801188\n",
      "Epoch 25::Minibatch 765::LR 0.0446153846154 --> Loss 0.00127418051163\n",
      "Epoch 25::Minibatch 766::LR 0.0446153846154 --> Loss 0.00229296366374\n",
      "Epoch 25::Minibatch 767::LR 0.0446153846154 --> Loss 0.00487506906192\n",
      "Epoch 25::Minibatch 768::LR 0.0446153846154 --> Loss 0.00365514278412\n",
      "Epoch 25::Minibatch 769::LR 0.0446153846154 --> Loss 0.00185765306155\n",
      "Epoch 25::Minibatch 770::LR 0.0446153846154 --> Loss 0.00148827751478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 771::LR 0.0446153846154 --> Loss 0.00352452278137\n",
      "Epoch 25::Minibatch 772::LR 0.0446153846154 --> Loss 0.00352392792702\n",
      "Epoch 25::Minibatch 773::LR 0.0446153846154 --> Loss 0.00315914690495\n",
      "Epoch 25::Minibatch 774::LR 0.0446153846154 --> Loss 0.00184146404266\n",
      "Epoch 25::Minibatch 775::LR 0.0446153846154 --> Loss 0.00348496874173\n",
      "Epoch 25::Minibatch 776::LR 0.0446153846154 --> Loss 0.0036651579539\n",
      "Epoch 25::Minibatch 777::LR 0.0446153846154 --> Loss 0.0066279788812\n",
      "Epoch 25::Minibatch 778::LR 0.0446153846154 --> Loss 0.00813801209132\n",
      "Epoch 25::Minibatch 779::LR 0.0446153846154 --> Loss 0.00243186374505\n",
      "Epoch 25::Minibatch 780::LR 0.0446153846154 --> Loss 0.0015433511138\n",
      "Epoch 25::Minibatch 781::LR 0.0446153846154 --> Loss 0.00344633539518\n",
      "Epoch 25::Minibatch 782::LR 0.0446153846154 --> Loss 0.00383018692334\n",
      "Epoch 25::Minibatch 783::LR 0.0446153846154 --> Loss 0.00227718770504\n",
      "Epoch 25::Minibatch 784::LR 0.0446153846154 --> Loss 0.000706921368837\n",
      "Epoch 25::Minibatch 785::LR 0.0446153846154 --> Loss 0.00324981252352\n",
      "Epoch 25::Minibatch 786::LR 0.0446153846154 --> Loss 0.00341818054517\n",
      "Epoch 25::Minibatch 787::LR 0.0446153846154 --> Loss 0.00260211189588\n",
      "Epoch 25::Minibatch 788::LR 0.0446153846154 --> Loss 0.00235364615917\n",
      "Epoch 25::Minibatch 789::LR 0.0446153846154 --> Loss 0.00072844127814\n",
      "Epoch 25::Minibatch 790::LR 0.0446153846154 --> Loss 0.00312597572803\n",
      "Epoch 25::Minibatch 791::LR 0.0446153846154 --> Loss 0.00337691307068\n",
      "Epoch 25::Minibatch 792::LR 0.0446153846154 --> Loss 0.00300276517868\n",
      "Epoch 25::Minibatch 793::LR 0.0446153846154 --> Loss 0.00168466766675\n",
      "Epoch 25::Minibatch 794::LR 0.0446153846154 --> Loss 0.00099197636048\n",
      "Epoch 25::Minibatch 795::LR 0.0446153846154 --> Loss 0.00276474734147\n",
      "Epoch 25::Minibatch 796::LR 0.0446153846154 --> Loss 0.00513963381449\n",
      "Epoch 25::Minibatch 797::LR 0.0446153846154 --> Loss 0.0062680097421\n",
      "Epoch 25::Minibatch 798::LR 0.0446153846154 --> Loss 0.00310820698738\n",
      "Epoch 25::Minibatch 799::LR 0.0446153846154 --> Loss 0.00227878173192\n",
      "Epoch 25::Minibatch 800::LR 0.0446153846154 --> Loss 0.00200657645861\n",
      "Epoch 25::Minibatch 801::LR 0.0446153846154 --> Loss 0.00403144359589\n",
      "Epoch 25::Minibatch 802::LR 0.0446153846154 --> Loss 0.00124257733425\n",
      "Epoch 25::Minibatch 803::LR 0.0446153846154 --> Loss 0.00291301767031\n",
      "Epoch 25::Minibatch 804::LR 0.0446153846154 --> Loss 0.00210883458455\n",
      "Epoch 25::Minibatch 805::LR 0.0446153846154 --> Loss 0.00221123655637\n",
      "Epoch 25::Minibatch 806::LR 0.0446153846154 --> Loss 0.00339185237885\n",
      "Epoch 25::Minibatch 807::LR 0.0446153846154 --> Loss 0.00305650949478\n",
      "Epoch 25::Minibatch 808::LR 0.0446153846154 --> Loss 0.00273285428683\n",
      "Epoch 25::Minibatch 809::LR 0.0446153846154 --> Loss 0.00330453713735\n",
      "Epoch 25::Minibatch 810::LR 0.0446153846154 --> Loss 0.00454509894053\n",
      "Epoch 25::Minibatch 811::LR 0.0446153846154 --> Loss 0.00432452162107\n",
      "Epoch 25::Minibatch 812::LR 0.0446153846154 --> Loss 0.00396190444628\n",
      "Epoch 25::Minibatch 813::LR 0.0446153846154 --> Loss 0.0034036886692\n",
      "Epoch 25::Minibatch 814::LR 0.0446153846154 --> Loss 0.00158675581217\n",
      "Epoch 25::Minibatch 815::LR 0.0446153846154 --> Loss 0.00360111276309\n",
      "Epoch 25::Minibatch 816::LR 0.0446153846154 --> Loss 0.00402909477552\n",
      "Epoch 25::Minibatch 817::LR 0.0446153846154 --> Loss 0.00525154987971\n",
      "Epoch 25::Minibatch 818::LR 0.0446153846154 --> Loss 0.00124956389268\n",
      "Epoch 25::Minibatch 819::LR 0.0446153846154 --> Loss 0.000708755056063\n",
      "Epoch 25::Minibatch 820::LR 0.0446153846154 --> Loss 0.0051844171683\n",
      "Epoch 25::Minibatch 821::LR 0.0446153846154 --> Loss 0.00307554423809\n",
      "Epoch 25::Minibatch 822::LR 0.0446153846154 --> Loss 0.00366182963053\n",
      "Epoch 25::Minibatch 823::LR 0.0446153846154 --> Loss 0.00127353648345\n",
      "Epoch 25::Minibatch 824::LR 0.0446153846154 --> Loss 0.00136232992013\n",
      "Epoch 25::Minibatch 825::LR 0.0446153846154 --> Loss 0.00366288304329\n",
      "Epoch 25::Minibatch 826::LR 0.0446153846154 --> Loss 0.00414441029231\n",
      "Epoch 25::Minibatch 827::LR 0.0446153846154 --> Loss 0.00205802838008\n",
      "Epoch 25::Minibatch 828::LR 0.0446153846154 --> Loss 0.000496215422948\n",
      "Epoch 25::Minibatch 829::LR 0.0446153846154 --> Loss 0.00229833185673\n",
      "Epoch 25::Minibatch 830::LR 0.0446153846154 --> Loss 0.0041538409392\n",
      "Epoch 25::Minibatch 831::LR 0.0446153846154 --> Loss 0.0024632893006\n",
      "Epoch 25::Minibatch 832::LR 0.0446153846154 --> Loss 0.00216167728106\n",
      "Epoch 25::Minibatch 833::LR 0.0446153846154 --> Loss 0.00182825605075\n",
      "Epoch 25::Minibatch 834::LR 0.0446153846154 --> Loss 0.000778926561276\n",
      "Epoch 25::Minibatch 835::LR 0.0446153846154 --> Loss 0.00375613768895\n",
      "Epoch 25::Minibatch 836::LR 0.0446153846154 --> Loss 0.00361332972844\n",
      "Epoch 25::Minibatch 837::LR 0.0446153846154 --> Loss 0.00220213572184\n",
      "Epoch 25::Minibatch 838::LR 0.0446153846154 --> Loss 0.00063440690438\n",
      "Epoch 25::Minibatch 839::LR 0.0446153846154 --> Loss 0.00242414573828\n",
      "Epoch 25::Minibatch 840::LR 0.0446153846154 --> Loss 0.00285442451636\n",
      "Epoch 25::Minibatch 841::LR 0.0446153846154 --> Loss 0.00277100523313\n",
      "Epoch 25::Minibatch 842::LR 0.0446153846154 --> Loss 0.00207740028699\n",
      "Epoch 25::Minibatch 843::LR 0.0446153846154 --> Loss 0.000988034804662\n",
      "Epoch 25::Minibatch 844::LR 0.0446153846154 --> Loss 0.00147331386805\n",
      "Epoch 25::Minibatch 845::LR 0.0446153846154 --> Loss 0.00414538900057\n",
      "Epoch 25::Minibatch 846::LR 0.0446153846154 --> Loss 0.0016653479139\n",
      "Epoch 25::Minibatch 847::LR 0.0446153846154 --> Loss 0.00230555335681\n",
      "Epoch 25::Minibatch 848::LR 0.0446153846154 --> Loss 0.00105389565229\n",
      "Epoch 25::Minibatch 849::LR 0.0446153846154 --> Loss 0.0017970575889\n",
      "Epoch 25::Minibatch 850::LR 0.0446153846154 --> Loss 0.00314849019051\n",
      "Epoch 25::Minibatch 851::LR 0.0446153846154 --> Loss 0.0025764666001\n",
      "Epoch 25::Minibatch 852::LR 0.0446153846154 --> Loss 0.00109757939974\n",
      "Epoch 25::Minibatch 853::LR 0.0446153846154 --> Loss 0.00130021065474\n",
      "Epoch 25::Minibatch 854::LR 0.0446153846154 --> Loss 0.00254612982273\n",
      "Epoch 25::Minibatch 855::LR 0.0446153846154 --> Loss 0.00213239451249\n",
      "Epoch 25::Minibatch 856::LR 0.0446153846154 --> Loss 0.00178531587124\n",
      "Epoch 25::Minibatch 857::LR 0.0446153846154 --> Loss 0.00120863199234\n",
      "Epoch 25::Minibatch 858::LR 0.0446153846154 --> Loss 0.00059416949749\n",
      "Epoch 25::Minibatch 859::LR 0.0446153846154 --> Loss 0.00193552811941\n",
      "Epoch 25::Minibatch 860::LR 0.0446153846154 --> Loss 0.00127358367046\n",
      "Epoch 25::Minibatch 861::LR 0.0446153846154 --> Loss 0.000938434799512\n",
      "Epoch 25::Minibatch 862::LR 0.0446153846154 --> Loss 0.00366927822431\n",
      "Epoch 25::Minibatch 863::LR 0.0446153846154 --> Loss 0.00337789217631\n",
      "Epoch 25::Minibatch 864::LR 0.0446153846154 --> Loss 0.0027037469546\n",
      "Epoch 25::Minibatch 865::LR 0.0446153846154 --> Loss 0.000461046546698\n",
      "Epoch 25::Minibatch 866::LR 0.0446153846154 --> Loss 0.00210073411465\n",
      "Epoch 25::Minibatch 867::LR 0.0446153846154 --> Loss 0.00290335416794\n",
      "Epoch 25::Minibatch 868::LR 0.0446153846154 --> Loss 0.00240334848563\n",
      "Epoch 25::Minibatch 869::LR 0.0446153846154 --> Loss 0.00211615025997\n",
      "Epoch 25::Minibatch 870::LR 0.0446153846154 --> Loss 0.00338268995285\n",
      "Epoch 25::Minibatch 871::LR 0.0446153846154 --> Loss 0.00156852841377\n",
      "Epoch 25::Minibatch 872::LR 0.0446153846154 --> Loss 0.00219030300776\n",
      "Epoch 25::Minibatch 873::LR 0.0446153846154 --> Loss 0.00245584726334\n",
      "Epoch 25::Minibatch 874::LR 0.0446153846154 --> Loss 0.00565086245537\n",
      "Epoch 25::Minibatch 875::LR 0.0446153846154 --> Loss 0.000561176687479\n",
      "Epoch 25::Minibatch 876::LR 0.0446153846154 --> Loss 0.00291516184807\n",
      "Epoch 25::Minibatch 877::LR 0.0446153846154 --> Loss 0.00517361760139\n",
      "Epoch 25::Minibatch 878::LR 0.0446153846154 --> Loss 0.00309221784274\n",
      "Epoch 25::Minibatch 879::LR 0.0446153846154 --> Loss 0.00395818630854\n",
      "Epoch 25::Minibatch 880::LR 0.0446153846154 --> Loss 0.00483381112417\n",
      "Epoch 25::Minibatch 881::LR 0.0446153846154 --> Loss 0.00425764918327\n",
      "Epoch 25::Minibatch 882::LR 0.0446153846154 --> Loss 0.00193755805492\n",
      "Epoch 25::Minibatch 883::LR 0.0446153846154 --> Loss 0.0035120177269\n",
      "Epoch 25::Minibatch 884::LR 0.0446153846154 --> Loss 0.00274508913358\n",
      "Epoch 25::Minibatch 885::LR 0.0446153846154 --> Loss 0.0025630658865\n",
      "Epoch 25::Minibatch 886::LR 0.0446153846154 --> Loss 0.000451922615369\n",
      "Epoch 25::Minibatch 887::LR 0.0446153846154 --> Loss 0.00530800660451\n",
      "Epoch 25::Minibatch 888::LR 0.0446153846154 --> Loss 0.00252069930236\n",
      "Epoch 25::Minibatch 889::LR 0.0446153846154 --> Loss 0.00262655953566\n",
      "Epoch 25::Minibatch 890::LR 0.0446153846154 --> Loss 0.00384049932162\n",
      "Epoch 25::Minibatch 891::LR 0.0446153846154 --> Loss 0.00177133083344\n",
      "Epoch 25::Minibatch 892::LR 0.0446153846154 --> Loss 0.000817542523146\n",
      "Epoch 25::Minibatch 893::LR 0.0446153846154 --> Loss 0.00233497480551\n",
      "Epoch 25::Minibatch 894::LR 0.0446153846154 --> Loss 0.00205826560656\n",
      "Epoch 25::Minibatch 895::LR 0.0446153846154 --> Loss 0.00232302149137\n",
      "Epoch 25::Minibatch 896::LR 0.0446153846154 --> Loss 0.00124055365721\n",
      "Epoch 25::Minibatch 897::LR 0.0446153846154 --> Loss 0.000685301522414\n",
      "Epoch 25::Minibatch 898::LR 0.0446153846154 --> Loss 0.00204943935076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 899::LR 0.0446153846154 --> Loss 0.00246188879013\n",
      "Epoch 25::Minibatch 900::LR 0.0446153846154 --> Loss 0.00313658813636\n",
      "Epoch 25::Minibatch 901::LR 0.0446153846154 --> Loss 0.00058474957943\n",
      "Epoch 25::Minibatch 902::LR 0.0446153846154 --> Loss 0.00140227675438\n",
      "Epoch 25::Minibatch 903::LR 0.0446153846154 --> Loss 0.00252983530362\n",
      "Epoch 25::Minibatch 904::LR 0.0446153846154 --> Loss 0.00183992187182\n",
      "Epoch 25::Minibatch 905::LR 0.0446153846154 --> Loss 0.0014115391175\n",
      "Epoch 25::Minibatch 906::LR 0.0446153846154 --> Loss 0.00104521761338\n",
      "Epoch 25::Minibatch 907::LR 0.0446153846154 --> Loss 0.00156350145737\n",
      "Epoch 25::Minibatch 908::LR 0.0446153846154 --> Loss 0.00210460166136\n",
      "Epoch 25::Minibatch 909::LR 0.0446153846154 --> Loss 0.00194997092088\n",
      "Epoch 25::Minibatch 910::LR 0.0446153846154 --> Loss 0.000836537679036\n",
      "Epoch 25::Minibatch 911::LR 0.0446153846154 --> Loss 0.0012502254049\n",
      "Epoch 25::Minibatch 912::LR 0.0446153846154 --> Loss 0.00201062619686\n",
      "Epoch 25::Minibatch 913::LR 0.0446153846154 --> Loss 0.00220312754313\n",
      "Epoch 25::Minibatch 914::LR 0.0446153846154 --> Loss 0.00119336386522\n",
      "Epoch 25::Minibatch 915::LR 0.0446153846154 --> Loss 0.000506291091442\n",
      "Epoch 25::Minibatch 916::LR 0.0446153846154 --> Loss 0.00214010000229\n",
      "Epoch 25::Minibatch 917::LR 0.0446153846154 --> Loss 0.00348876635234\n",
      "Epoch 25::Minibatch 918::LR 0.0446153846154 --> Loss 0.00543846567472\n",
      "Epoch 25::Minibatch 919::LR 0.0446153846154 --> Loss 0.000537823239962\n",
      "Epoch 25::Minibatch 920::LR 0.0446153846154 --> Loss 0.0124561802546\n",
      "Epoch 25::Minibatch 921::LR 0.0446153846154 --> Loss 0.00285369197528\n",
      "Epoch 25::Minibatch 922::LR 0.0446153846154 --> Loss 0.00294306218624\n",
      "Epoch 25::Minibatch 923::LR 0.0446153846154 --> Loss 0.00130998909473\n",
      "Epoch 25::Minibatch 924::LR 0.0446153846154 --> Loss 0.00329429407914\n",
      "Epoch 25::Minibatch 925::LR 0.0446153846154 --> Loss 0.0022232768933\n",
      "Epoch 25::Minibatch 926::LR 0.0446153846154 --> Loss 0.00496820688248\n",
      "Epoch 25::Minibatch 927::LR 0.0446153846154 --> Loss 0.00625886122386\n",
      "Epoch 25::Minibatch 928::LR 0.0446153846154 --> Loss 0.00612974405289\n",
      "Epoch 25::Minibatch 929::LR 0.0446153846154 --> Loss 0.00589036742846\n",
      "Epoch 25::Minibatch 930::LR 0.0446153846154 --> Loss 0.00889187018077\n",
      "Epoch 25::Minibatch 931::LR 0.0446153846154 --> Loss 0.00318661351999\n",
      "Epoch 25::Minibatch 932::LR 0.0446153846154 --> Loss 0.00586189389229\n",
      "Epoch 25::Minibatch 933::LR 0.0446153846154 --> Loss 0.00279307027658\n",
      "Epoch 25::Minibatch 934::LR 0.0446153846154 --> Loss 0.00366177558899\n",
      "Epoch 25::Minibatch 935::LR 0.0446153846154 --> Loss 0.00530548493067\n",
      "Epoch 25::Minibatch 936::LR 0.0446153846154 --> Loss 0.00114430020253\n",
      "Epoch 25::Minibatch 937::LR 0.0446153846154 --> Loss 0.00276496827602\n",
      "Epoch 25::Minibatch 938::LR 0.0446153846154 --> Loss 0.0024221932888\n",
      "Epoch 25::Minibatch 939::LR 0.0446153846154 --> Loss 0.00254875739415\n",
      "Epoch 25::Minibatch 940::LR 0.0446153846154 --> Loss 0.000962026317914\n",
      "Epoch 25::Minibatch 941::LR 0.0446153846154 --> Loss 0.000790241360664\n",
      "Epoch 25::Minibatch 942::LR 0.0446153846154 --> Loss 0.00246508717537\n",
      "Epoch 25::Minibatch 943::LR 0.0446153846154 --> Loss 0.00254255592823\n",
      "Epoch 25::Minibatch 944::LR 0.0446153846154 --> Loss 0.00183972497781\n",
      "Epoch 25::Minibatch 945::LR 0.0446153846154 --> Loss 0.00105753600597\n",
      "Epoch 25::Minibatch 946::LR 0.0446153846154 --> Loss 0.0026837327083\n",
      "Epoch 25::Minibatch 947::LR 0.0446153846154 --> Loss 0.00243556221326\n",
      "Epoch 25::Minibatch 948::LR 0.0446153846154 --> Loss 0.00452601949374\n",
      "Epoch 25::Minibatch 949::LR 0.0446153846154 --> Loss 0.00177741686503\n",
      "Epoch 25::Minibatch 950::LR 0.0446153846154 --> Loss 0.000720899353425\n",
      "Epoch 25::Minibatch 951::LR 0.0446153846154 --> Loss 0.00337353825569\n",
      "Epoch 25::Minibatch 952::LR 0.0446153846154 --> Loss 0.00236757338047\n",
      "Epoch 25::Minibatch 953::LR 0.0446153846154 --> Loss 0.00140041808287\n",
      "Epoch 25::Minibatch 954::LR 0.0446153846154 --> Loss 0.000952879985174\n",
      "Epoch 25::Minibatch 955::LR 0.0446153846154 --> Loss 0.00253130118052\n",
      "Epoch 25::Minibatch 956::LR 0.0446153846154 --> Loss 0.0033432606856\n",
      "Epoch 25::Minibatch 957::LR 0.0446153846154 --> Loss 0.00183347086112\n",
      "Epoch 25::Minibatch 958::LR 0.0446153846154 --> Loss 0.00219947477182\n",
      "Epoch 25::Minibatch 959::LR 0.0446153846154 --> Loss 0.00264759858449\n",
      "Epoch 25::Minibatch 960::LR 0.0446153846154 --> Loss 0.00574772675832\n",
      "Epoch 25::Minibatch 961::LR 0.0446153846154 --> Loss 0.00313382506371\n",
      "Epoch 25::Minibatch 962::LR 0.0446153846154 --> Loss 0.00260016798973\n",
      "Epoch 25::Minibatch 963::LR 0.0446153846154 --> Loss 0.00104238808155\n",
      "Epoch 25::Minibatch 964::LR 0.0446153846154 --> Loss 0.00234957377116\n",
      "Epoch 25::Minibatch 965::LR 0.0446153846154 --> Loss 0.00675668398539\n",
      "Epoch 25::Minibatch 966::LR 0.0446153846154 --> Loss 0.00497205575307\n",
      "Epoch 25::Minibatch 967::LR 0.0446153846154 --> Loss 0.00135987480481\n",
      "Epoch 25::Minibatch 968::LR 0.0446153846154 --> Loss 0.00117718090614\n",
      "Epoch 25::Minibatch 969::LR 0.0446153846154 --> Loss 0.00536305268606\n",
      "Epoch 25::Minibatch 970::LR 0.0446153846154 --> Loss 0.00507693926493\n",
      "Epoch 25::Minibatch 971::LR 0.0446153846154 --> Loss 0.00339994986852\n",
      "Epoch 25::Minibatch 972::LR 0.0446153846154 --> Loss 0.00926223913829\n",
      "Epoch 25::Minibatch 973::LR 0.0446153846154 --> Loss 0.00903850475947\n",
      "Epoch 25::Minibatch 974::LR 0.0446153846154 --> Loss 0.00827041864395\n",
      "Epoch 25::Minibatch 975::LR 0.0446153846154 --> Loss 0.00441058079402\n",
      "Epoch 25::Minibatch 976::LR 0.0446153846154 --> Loss 0.00386410395304\n",
      "Epoch 25::Minibatch 977::LR 0.0446153846154 --> Loss 0.00375003735224\n",
      "Epoch 25::Minibatch 978::LR 0.0446153846154 --> Loss 0.00372004826864\n",
      "Epoch 25::Minibatch 979::LR 0.0446153846154 --> Loss 0.00357284704844\n",
      "Epoch 25::Minibatch 980::LR 0.0446153846154 --> Loss 0.00376100460688\n",
      "Epoch 25::Minibatch 981::LR 0.0446153846154 --> Loss 0.00483392477036\n",
      "Epoch 25::Minibatch 982::LR 0.0446153846154 --> Loss 0.00549120465914\n",
      "Epoch 25::Minibatch 983::LR 0.0446153846154 --> Loss 0.00280318419139\n",
      "Epoch 25::Minibatch 984::LR 0.0446153846154 --> Loss 0.00216771602631\n",
      "Epoch 25::Minibatch 985::LR 0.0446153846154 --> Loss 0.00389148235321\n",
      "Epoch 25::Minibatch 986::LR 0.0446153846154 --> Loss 0.00357022007306\n",
      "Epoch 25::Minibatch 987::LR 0.0446153846154 --> Loss 0.00384741783142\n",
      "Epoch 25::Minibatch 988::LR 0.0446153846154 --> Loss 0.00307515223821\n",
      "Epoch 25::Minibatch 989::LR 0.0446153846154 --> Loss 0.0032805420955\n",
      "Epoch 25::Minibatch 990::LR 0.0446153846154 --> Loss 0.00299548049768\n",
      "Epoch 25::Minibatch 991::LR 0.0446153846154 --> Loss 0.00160182535648\n",
      "Epoch 25::Minibatch 992::LR 0.0446153846154 --> Loss 0.0017809599638\n",
      "Epoch 25::Minibatch 993::LR 0.0446153846154 --> Loss 0.00327192326387\n",
      "Epoch 25::Minibatch 994::LR 0.0446153846154 --> Loss 0.00209852377574\n",
      "Epoch 25::Minibatch 995::LR 0.0446153846154 --> Loss 0.000854097306728\n",
      "Epoch 25::Minibatch 996::LR 0.0446153846154 --> Loss 0.00287639021873\n",
      "Epoch 25::Minibatch 997::LR 0.0446153846154 --> Loss 0.00224583983421\n",
      "Epoch 25::Minibatch 998::LR 0.0446153846154 --> Loss 0.00254292786121\n",
      "Epoch 25::Minibatch 999::LR 0.0446153846154 --> Loss 0.00214124023914\n",
      "Epoch 25::Minibatch 1000::LR 0.0446153846154 --> Loss 0.00253813286622\n",
      "Epoch 25::Minibatch 1001::LR 0.0446153846154 --> Loss 0.00203495701154\n",
      "Epoch 25::Minibatch 1002::LR 0.0446153846154 --> Loss 0.00185852527618\n",
      "Epoch 25::Minibatch 1003::LR 0.0446153846154 --> Loss 0.00289762636026\n",
      "Epoch 25::Minibatch 1004::LR 0.0446153846154 --> Loss 0.00108154247204\n",
      "Epoch 25::Minibatch 1005::LR 0.0446153846154 --> Loss 0.00290017704169\n",
      "Epoch 25::Minibatch 1006::LR 0.0446153846154 --> Loss 0.00155694703261\n",
      "Epoch 25::Minibatch 1007::LR 0.0446153846154 --> Loss 0.00200849950314\n",
      "Epoch 25::Minibatch 1008::LR 0.0446153846154 --> Loss 0.000951056281726\n",
      "Epoch 25::Minibatch 1009::LR 0.0446153846154 --> Loss 0.0013012928764\n",
      "Epoch 25::Minibatch 1010::LR 0.0446153846154 --> Loss 0.00117540349563\n",
      "Epoch 25::Minibatch 1011::LR 0.0446153846154 --> Loss 0.0020351421833\n",
      "Epoch 25::Minibatch 1012::LR 0.0446153846154 --> Loss 0.00146604935328\n",
      "Epoch 25::Minibatch 1013::LR 0.0446153846154 --> Loss 0.00382156769435\n",
      "Epoch 25::Minibatch 1014::LR 0.0446153846154 --> Loss 0.00359060486158\n",
      "Epoch 25::Minibatch 1015::LR 0.0446153846154 --> Loss 0.00159331709146\n",
      "Epoch 25::Minibatch 1016::LR 0.0446153846154 --> Loss 0.00468088030815\n",
      "Epoch 25::Minibatch 1017::LR 0.0446153846154 --> Loss 0.0029918106397\n",
      "Epoch 25::Minibatch 1018::LR 0.0446153846154 --> Loss 0.0026763655742\n",
      "Epoch 25::Minibatch 1019::LR 0.0446153846154 --> Loss 0.00174379448096\n",
      "Epoch 25::Minibatch 1020::LR 0.0446153846154 --> Loss 0.00181882580121\n",
      "Epoch 25::Minibatch 1021::LR 0.0446153846154 --> Loss 0.0019045996666\n",
      "Epoch 25::Minibatch 1022::LR 0.0446153846154 --> Loss 0.00142261693875\n",
      "Epoch 25::Minibatch 1023::LR 0.0446153846154 --> Loss 0.00107679675023\n",
      "Epoch 25::Minibatch 1024::LR 0.0446153846154 --> Loss 0.0010639205575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25::Minibatch 1025::LR 0.0446153846154 --> Loss 0.00138482302427\n",
      "Epoch 25::Minibatch 1026::LR 0.0446153846154 --> Loss 0.000746661374966\n",
      "Epoch 25::Minibatch 1027::LR 0.0446153846154 --> Loss 0.000997366110484\n",
      "Epoch 25::Minibatch 1028::LR 0.0446153846154 --> Loss 0.000759924699863\n",
      "Epoch 25::Minibatch 1029::LR 0.0446153846154 --> Loss 0.000754405260086\n",
      "Epoch 25::Minibatch 1030::LR 0.0446153846154 --> Loss 0.000929889877637\n",
      "Epoch 25::Minibatch 1031::LR 0.0446153846154 --> Loss 0.000719686448574\n",
      "Epoch 25::Minibatch 1032::LR 0.0446153846154 --> Loss 0.000779120077689\n",
      "Epoch 25::Minibatch 1033::LR 0.0446153846154 --> Loss 0.000661945442359\n",
      "Epoch 25::Minibatch 1034::LR 0.0446153846154 --> Loss 0.000632683485746\n",
      "Epoch 25::Minibatch 1035::LR 0.0446153846154 --> Loss 0.000424679517746\n",
      "Epoch 25::Minibatch 1036::LR 0.0446153846154 --> Loss 0.000340933203697\n",
      "Epoch 25::Minibatch 1037::LR 0.0446153846154 --> Loss 0.000590689331293\n",
      "Epoch 25::Minibatch 1038::LR 0.0446153846154 --> Loss 0.00118469605843\n",
      "Epoch 25::Minibatch 1039::LR 0.0446153846154 --> Loss 0.000916016995907\n",
      "Epoch 25::Minibatch 1040::LR 0.0446153846154 --> Loss 0.000366814931234\n",
      "Epoch 25::Minibatch 1041::LR 0.0446153846154 --> Loss 0.000528685698907\n",
      "Epoch 26::Minibatch 1::LR 0.0423076923077 --> Loss 0.00827378749847\n",
      "Epoch 26::Minibatch 2::LR 0.0423076923077 --> Loss 0.00529756069183\n",
      "Epoch 26::Minibatch 3::LR 0.0423076923077 --> Loss 0.00339105725288\n",
      "Epoch 26::Minibatch 4::LR 0.0423076923077 --> Loss 0.00402029514313\n",
      "Epoch 26::Minibatch 5::LR 0.0423076923077 --> Loss 0.00452329277992\n",
      "Epoch 26::Minibatch 6::LR 0.0423076923077 --> Loss 0.00219967941443\n",
      "Epoch 26::Minibatch 7::LR 0.0423076923077 --> Loss 0.00741309960683\n",
      "Epoch 26::Minibatch 8::LR 0.0423076923077 --> Loss 0.00696215391159\n",
      "Epoch 26::Minibatch 9::LR 0.0423076923077 --> Loss 0.00529604156812\n",
      "Epoch 26::Minibatch 10::LR 0.0423076923077 --> Loss 0.0025352782011\n",
      "Epoch 26::Minibatch 11::LR 0.0423076923077 --> Loss 0.00231329600016\n",
      "Epoch 26::Minibatch 12::LR 0.0423076923077 --> Loss 0.00343737602234\n",
      "Epoch 26::Minibatch 13::LR 0.0423076923077 --> Loss 0.00532885829608\n",
      "Epoch 26::Minibatch 14::LR 0.0423076923077 --> Loss 0.0052977557977\n",
      "Epoch 26::Minibatch 15::LR 0.0423076923077 --> Loss 0.00452751159668\n",
      "Epoch 26::Minibatch 16::LR 0.0423076923077 --> Loss 0.000769549310207\n",
      "Epoch 26::Minibatch 17::LR 0.0423076923077 --> Loss 0.00316122372945\n",
      "Epoch 26::Minibatch 18::LR 0.0423076923077 --> Loss 0.00259099801381\n",
      "Epoch 26::Minibatch 19::LR 0.0423076923077 --> Loss 0.00146963715553\n",
      "Epoch 26::Minibatch 20::LR 0.0423076923077 --> Loss 0.00198311010997\n",
      "Epoch 26::Minibatch 21::LR 0.0423076923077 --> Loss 0.00332540512085\n",
      "Epoch 26::Minibatch 22::LR 0.0423076923077 --> Loss 0.00223628004392\n",
      "Epoch 26::Minibatch 23::LR 0.0423076923077 --> Loss 0.000850267807643\n",
      "Epoch 26::Minibatch 24::LR 0.0423076923077 --> Loss 0.000441206892331\n",
      "Epoch 26::Minibatch 25::LR 0.0423076923077 --> Loss 0.00123554348946\n",
      "Epoch 26::Minibatch 26::LR 0.0423076923077 --> Loss 0.00143642524878\n",
      "Epoch 26::Minibatch 27::LR 0.0423076923077 --> Loss 0.00103710363309\n",
      "Epoch 26::Minibatch 28::LR 0.0423076923077 --> Loss 0.000448765407006\n",
      "Epoch 26::Minibatch 29::LR 0.0423076923077 --> Loss 0.000499395082394\n",
      "Epoch 26::Minibatch 30::LR 0.0423076923077 --> Loss 0.000978209674358\n",
      "Epoch 26::Minibatch 31::LR 0.0423076923077 --> Loss 0.00146932611863\n",
      "Epoch 26::Minibatch 32::LR 0.0423076923077 --> Loss 0.00132938891649\n",
      "Epoch 26::Minibatch 33::LR 0.0423076923077 --> Loss 0.000787199735641\n",
      "Epoch 26::Minibatch 34::LR 0.0423076923077 --> Loss 0.00212641398112\n",
      "Epoch 26::Minibatch 35::LR 0.0423076923077 --> Loss 0.00333871483803\n",
      "Epoch 26::Minibatch 36::LR 0.0423076923077 --> Loss 0.00224181811015\n",
      "Epoch 26::Minibatch 37::LR 0.0423076923077 --> Loss 0.000670492549737\n",
      "Epoch 26::Minibatch 38::LR 0.0423076923077 --> Loss 0.000715246697267\n",
      "Epoch 26::Minibatch 39::LR 0.0423076923077 --> Loss 0.00223662177722\n",
      "Epoch 26::Minibatch 40::LR 0.0423076923077 --> Loss 0.00315266509851\n",
      "Epoch 26::Minibatch 41::LR 0.0423076923077 --> Loss 0.00254245201747\n",
      "Epoch 26::Minibatch 42::LR 0.0423076923077 --> Loss 0.00516369024913\n",
      "Epoch 26::Minibatch 43::LR 0.0423076923077 --> Loss 0.00194048285484\n",
      "Epoch 26::Minibatch 44::LR 0.0423076923077 --> Loss 0.00316579083602\n",
      "Epoch 26::Minibatch 45::LR 0.0423076923077 --> Loss 0.00239266037941\n",
      "Epoch 26::Minibatch 46::LR 0.0423076923077 --> Loss 0.0031776257356\n",
      "Epoch 26::Minibatch 47::LR 0.0423076923077 --> Loss 0.0037052444617\n",
      "Epoch 26::Minibatch 48::LR 0.0423076923077 --> Loss 0.00524537563324\n",
      "Epoch 26::Minibatch 49::LR 0.0423076923077 --> Loss 0.00579284270604\n",
      "Epoch 26::Minibatch 50::LR 0.0423076923077 --> Loss 0.00607248663902\n",
      "Epoch 26::Minibatch 51::LR 0.0423076923077 --> Loss 0.00513108849525\n",
      "Epoch 26::Minibatch 52::LR 0.0423076923077 --> Loss 0.00343558549881\n",
      "Epoch 26::Minibatch 53::LR 0.0423076923077 --> Loss 0.00337909817696\n",
      "Epoch 26::Minibatch 54::LR 0.0423076923077 --> Loss 0.00400145888329\n",
      "Epoch 26::Minibatch 55::LR 0.0423076923077 --> Loss 0.000986717144648\n",
      "Epoch 26::Minibatch 56::LR 0.0423076923077 --> Loss 0.00270079751809\n",
      "Epoch 26::Minibatch 57::LR 0.0423076923077 --> Loss 0.00490019957225\n",
      "Epoch 26::Minibatch 58::LR 0.0423076923077 --> Loss 0.00324457665284\n",
      "Epoch 26::Minibatch 59::LR 0.0423076923077 --> Loss 0.00242879112562\n",
      "Epoch 26::Minibatch 60::LR 0.0423076923077 --> Loss 0.00242574433486\n",
      "Epoch 26::Minibatch 61::LR 0.0423076923077 --> Loss 0.000763712823391\n",
      "Epoch 26::Minibatch 62::LR 0.0423076923077 --> Loss 0.00271595954895\n",
      "Epoch 26::Minibatch 63::LR 0.0423076923077 --> Loss 0.0020139926672\n",
      "Epoch 26::Minibatch 64::LR 0.0423076923077 --> Loss 0.000840432246526\n",
      "Epoch 26::Minibatch 65::LR 0.0423076923077 --> Loss 0.00220424473286\n",
      "Epoch 26::Minibatch 66::LR 0.0423076923077 --> Loss 0.00272065500418\n",
      "Epoch 26::Minibatch 67::LR 0.0423076923077 --> Loss 0.0026047005256\n",
      "Epoch 26::Minibatch 68::LR 0.0423076923077 --> Loss 0.00187355021636\n",
      "Epoch 26::Minibatch 69::LR 0.0423076923077 --> Loss 0.00373882055283\n",
      "Epoch 26::Minibatch 70::LR 0.0423076923077 --> Loss 0.00329556882381\n",
      "Epoch 26::Minibatch 71::LR 0.0423076923077 --> Loss 0.00226795772711\n",
      "Epoch 26::Minibatch 72::LR 0.0423076923077 --> Loss 0.000538378010194\n",
      "Epoch 26::Minibatch 73::LR 0.0423076923077 --> Loss 0.00377575715383\n",
      "Epoch 26::Minibatch 74::LR 0.0423076923077 --> Loss 0.0040413014094\n",
      "Epoch 26::Minibatch 75::LR 0.0423076923077 --> Loss 0.00220588664214\n",
      "Epoch 26::Minibatch 76::LR 0.0423076923077 --> Loss 0.00053491850694\n",
      "Epoch 26::Minibatch 77::LR 0.0423076923077 --> Loss 0.00347715814908\n",
      "Epoch 26::Minibatch 78::LR 0.0423076923077 --> Loss 0.00386660019557\n",
      "Epoch 26::Minibatch 79::LR 0.0423076923077 --> Loss 0.00179830253124\n",
      "Epoch 26::Minibatch 80::LR 0.0423076923077 --> Loss 0.00297488212585\n",
      "Epoch 26::Minibatch 81::LR 0.0423076923077 --> Loss 0.0026051880916\n",
      "Epoch 26::Minibatch 82::LR 0.0423076923077 --> Loss 0.0018977667888\n",
      "Epoch 26::Minibatch 83::LR 0.0423076923077 --> Loss 0.00412181019783\n",
      "Epoch 26::Minibatch 84::LR 0.0423076923077 --> Loss 0.0019029768308\n",
      "Epoch 26::Minibatch 85::LR 0.0423076923077 --> Loss 0.00261521061261\n",
      "Epoch 26::Minibatch 86::LR 0.0423076923077 --> Loss 0.00212904155254\n",
      "Epoch 26::Minibatch 87::LR 0.0423076923077 --> Loss 0.00229473114014\n",
      "Epoch 26::Minibatch 88::LR 0.0423076923077 --> Loss 0.00170197983583\n",
      "Epoch 26::Minibatch 89::LR 0.0423076923077 --> Loss 0.00223460078239\n",
      "Epoch 26::Minibatch 90::LR 0.0423076923077 --> Loss 0.00105717658997\n",
      "Epoch 26::Minibatch 91::LR 0.0423076923077 --> Loss 0.000867298146089\n",
      "Epoch 26::Minibatch 92::LR 0.0423076923077 --> Loss 0.00260202070077\n",
      "Epoch 26::Minibatch 93::LR 0.0423076923077 --> Loss 0.001715229551\n",
      "Epoch 26::Minibatch 94::LR 0.0423076923077 --> Loss 0.00174331188202\n",
      "Epoch 26::Minibatch 95::LR 0.0423076923077 --> Loss 0.00186339835326\n",
      "Epoch 26::Minibatch 96::LR 0.0423076923077 --> Loss 0.00513652761777\n",
      "Epoch 26::Minibatch 97::LR 0.0423076923077 --> Loss 0.00305923263232\n",
      "Epoch 26::Minibatch 98::LR 0.0423076923077 --> Loss 0.001037872533\n",
      "Epoch 26::Minibatch 99::LR 0.0423076923077 --> Loss 0.00135974138975\n",
      "Epoch 26::Minibatch 100::LR 0.0423076923077 --> Loss 0.0045475657781\n",
      "Epoch 26::Minibatch 101::LR 0.0423076923077 --> Loss 0.000902900397778\n",
      "Epoch 26::Minibatch 102::LR 0.0423076923077 --> Loss 0.00388633131981\n",
      "Epoch 26::Minibatch 103::LR 0.0423076923077 --> Loss 0.00394733428955\n",
      "Epoch 26::Minibatch 104::LR 0.0423076923077 --> Loss 0.00269026299318\n",
      "Epoch 26::Minibatch 105::LR 0.0423076923077 --> Loss 0.00230049232642\n",
      "Epoch 26::Minibatch 106::LR 0.0423076923077 --> Loss 0.0153471962611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 107::LR 0.0423076923077 --> Loss 0.00480518897374\n",
      "Epoch 26::Minibatch 108::LR 0.0423076923077 --> Loss 0.000962456067403\n",
      "Epoch 26::Minibatch 109::LR 0.0423076923077 --> Loss 0.00429793198903\n",
      "Epoch 26::Minibatch 110::LR 0.0423076923077 --> Loss 0.00225803434849\n",
      "Epoch 26::Minibatch 111::LR 0.0423076923077 --> Loss 0.000857173105081\n",
      "Epoch 26::Minibatch 112::LR 0.0423076923077 --> Loss 0.00335739215215\n",
      "Epoch 26::Minibatch 113::LR 0.0423076923077 --> Loss 0.00246622959773\n",
      "Epoch 26::Minibatch 114::LR 0.0423076923077 --> Loss 0.00137159973383\n",
      "Epoch 26::Minibatch 115::LR 0.0423076923077 --> Loss 0.00119632393122\n",
      "Epoch 26::Minibatch 116::LR 0.0423076923077 --> Loss 0.00265970110893\n",
      "Epoch 26::Minibatch 117::LR 0.0423076923077 --> Loss 0.0039509610335\n",
      "Epoch 26::Minibatch 118::LR 0.0423076923077 --> Loss 0.00669091304143\n",
      "Epoch 26::Minibatch 119::LR 0.0423076923077 --> Loss 0.000544311652581\n",
      "Epoch 26::Minibatch 120::LR 0.0423076923077 --> Loss 0.00165072083473\n",
      "Epoch 26::Minibatch 121::LR 0.0423076923077 --> Loss 0.00244892120361\n",
      "Epoch 26::Minibatch 122::LR 0.0423076923077 --> Loss 0.00375910242399\n",
      "Epoch 26::Minibatch 123::LR 0.0423076923077 --> Loss 0.000795233249664\n",
      "Epoch 26::Minibatch 124::LR 0.0423076923077 --> Loss 0.00263164798419\n",
      "Epoch 26::Minibatch 125::LR 0.0423076923077 --> Loss 0.00447699546814\n",
      "Epoch 26::Minibatch 126::LR 0.0423076923077 --> Loss 0.00254482507706\n",
      "Epoch 26::Minibatch 127::LR 0.0423076923077 --> Loss 0.00460256020228\n",
      "Epoch 26::Minibatch 128::LR 0.0423076923077 --> Loss 0.00354930361112\n",
      "Epoch 26::Minibatch 129::LR 0.0423076923077 --> Loss 0.00251169284185\n",
      "Epoch 26::Minibatch 130::LR 0.0423076923077 --> Loss 0.00433241844177\n",
      "Epoch 26::Minibatch 131::LR 0.0423076923077 --> Loss 0.00173733373483\n",
      "Epoch 26::Minibatch 132::LR 0.0423076923077 --> Loss 0.00292054732641\n",
      "Epoch 26::Minibatch 133::LR 0.0423076923077 --> Loss 0.00279095649719\n",
      "Epoch 26::Minibatch 134::LR 0.0423076923077 --> Loss 0.00220251917839\n",
      "Epoch 26::Minibatch 135::LR 0.0423076923077 --> Loss 0.00139086037874\n",
      "Epoch 26::Minibatch 136::LR 0.0423076923077 --> Loss 0.00254075825214\n",
      "Epoch 26::Minibatch 137::LR 0.0423076923077 --> Loss 0.00350911736488\n",
      "Epoch 26::Minibatch 138::LR 0.0423076923077 --> Loss 0.00124816149473\n",
      "Epoch 26::Minibatch 139::LR 0.0423076923077 --> Loss 0.00189281304677\n",
      "Epoch 26::Minibatch 140::LR 0.0423076923077 --> Loss 0.0024196956555\n",
      "Epoch 26::Minibatch 141::LR 0.0423076923077 --> Loss 0.00292993426323\n",
      "Epoch 26::Minibatch 142::LR 0.0423076923077 --> Loss 0.00274189492067\n",
      "Epoch 26::Minibatch 143::LR 0.0423076923077 --> Loss 0.000564101288716\n",
      "Epoch 26::Minibatch 144::LR 0.0423076923077 --> Loss 0.00330067694187\n",
      "Epoch 26::Minibatch 145::LR 0.0423076923077 --> Loss 0.00419202923775\n",
      "Epoch 26::Minibatch 146::LR 0.0423076923077 --> Loss 0.00252395669619\n",
      "Epoch 26::Minibatch 147::LR 0.0423076923077 --> Loss 0.00179480274518\n",
      "Epoch 26::Minibatch 148::LR 0.0423076923077 --> Loss 0.000988430877527\n",
      "Epoch 26::Minibatch 149::LR 0.0423076923077 --> Loss 0.00284060994784\n",
      "Epoch 26::Minibatch 150::LR 0.0423076923077 --> Loss 0.00267892320951\n",
      "Epoch 26::Minibatch 151::LR 0.0423076923077 --> Loss 0.00425575574239\n",
      "Epoch 26::Minibatch 152::LR 0.0423076923077 --> Loss 0.000909026364485\n",
      "Epoch 26::Minibatch 153::LR 0.0423076923077 --> Loss 0.00170905629794\n",
      "Epoch 26::Minibatch 154::LR 0.0423076923077 --> Loss 0.00202717125416\n",
      "Epoch 26::Minibatch 155::LR 0.0423076923077 --> Loss 0.00423253099124\n",
      "Epoch 26::Minibatch 156::LR 0.0423076923077 --> Loss 0.00236677308877\n",
      "Epoch 26::Minibatch 157::LR 0.0423076923077 --> Loss 0.000691621949275\n",
      "Epoch 26::Minibatch 158::LR 0.0423076923077 --> Loss 0.00311010440191\n",
      "Epoch 26::Minibatch 159::LR 0.0423076923077 --> Loss 0.00273232877254\n",
      "Epoch 26::Minibatch 160::LR 0.0423076923077 --> Loss 0.00263228058815\n",
      "Epoch 26::Minibatch 161::LR 0.0423076923077 --> Loss 0.00100937535365\n",
      "Epoch 26::Minibatch 162::LR 0.0423076923077 --> Loss 0.00385412295659\n",
      "Epoch 26::Minibatch 163::LR 0.0423076923077 --> Loss 0.00239087661107\n",
      "Epoch 26::Minibatch 164::LR 0.0423076923077 --> Loss 0.00250753422578\n",
      "Epoch 26::Minibatch 165::LR 0.0423076923077 --> Loss 0.000510513484478\n",
      "Epoch 26::Minibatch 166::LR 0.0423076923077 --> Loss 0.00173875848452\n",
      "Epoch 26::Minibatch 167::LR 0.0423076923077 --> Loss 0.00246023197969\n",
      "Epoch 26::Minibatch 168::LR 0.0423076923077 --> Loss 0.00215607424577\n",
      "Epoch 26::Minibatch 169::LR 0.0423076923077 --> Loss 0.00100058565537\n",
      "Epoch 26::Minibatch 170::LR 0.0423076923077 --> Loss 0.000970854063829\n",
      "Epoch 26::Minibatch 171::LR 0.0423076923077 --> Loss 0.00250007629395\n",
      "Epoch 26::Minibatch 172::LR 0.0423076923077 --> Loss 0.0042909749349\n",
      "Epoch 26::Minibatch 173::LR 0.0423076923077 --> Loss 0.00196110924085\n",
      "Epoch 26::Minibatch 174::LR 0.0423076923077 --> Loss 0.000994141101837\n",
      "Epoch 26::Minibatch 175::LR 0.0423076923077 --> Loss 0.0023255465428\n",
      "Epoch 26::Minibatch 176::LR 0.0423076923077 --> Loss 0.00319153467814\n",
      "Epoch 26::Minibatch 177::LR 0.0423076923077 --> Loss 0.00438544869423\n",
      "Epoch 26::Minibatch 178::LR 0.0423076923077 --> Loss 0.00156536857287\n",
      "Epoch 26::Minibatch 179::LR 0.0423076923077 --> Loss 0.00128423084815\n",
      "Epoch 26::Minibatch 180::LR 0.0423076923077 --> Loss 0.00350076993306\n",
      "Epoch 26::Minibatch 181::LR 0.0423076923077 --> Loss 0.00314275304476\n",
      "Epoch 26::Minibatch 182::LR 0.0423076923077 --> Loss 0.000738037079573\n",
      "Epoch 26::Minibatch 183::LR 0.0423076923077 --> Loss 0.00162340472142\n",
      "Epoch 26::Minibatch 184::LR 0.0423076923077 --> Loss 0.00342349012693\n",
      "Epoch 26::Minibatch 185::LR 0.0423076923077 --> Loss 0.00276905953884\n",
      "Epoch 26::Minibatch 186::LR 0.0423076923077 --> Loss 0.000951846043269\n",
      "Epoch 26::Minibatch 187::LR 0.0423076923077 --> Loss 0.00127728323142\n",
      "Epoch 26::Minibatch 188::LR 0.0423076923077 --> Loss 0.00413816452026\n",
      "Epoch 26::Minibatch 189::LR 0.0423076923077 --> Loss 0.00427097241084\n",
      "Epoch 26::Minibatch 190::LR 0.0423076923077 --> Loss 0.00232504208883\n",
      "Epoch 26::Minibatch 191::LR 0.0423076923077 --> Loss 0.000463106930256\n",
      "Epoch 26::Minibatch 192::LR 0.0423076923077 --> Loss 0.00275222460429\n",
      "Epoch 26::Minibatch 193::LR 0.0423076923077 --> Loss 0.00263907015324\n",
      "Epoch 26::Minibatch 194::LR 0.0423076923077 --> Loss 0.00175937434038\n",
      "Epoch 26::Minibatch 195::LR 0.0423076923077 --> Loss 0.000381198525429\n",
      "Epoch 26::Minibatch 196::LR 0.0423076923077 --> Loss 0.00129897723595\n",
      "Epoch 26::Minibatch 197::LR 0.0423076923077 --> Loss 0.00292435566584\n",
      "Epoch 26::Minibatch 198::LR 0.0423076923077 --> Loss 0.00226190249125\n",
      "Epoch 26::Minibatch 199::LR 0.0423076923077 --> Loss 0.00028977488478\n",
      "Epoch 26::Minibatch 200::LR 0.0423076923077 --> Loss 0.00204445918401\n",
      "Epoch 26::Minibatch 201::LR 0.0423076923077 --> Loss 0.00193944334984\n",
      "Epoch 26::Minibatch 202::LR 0.0423076923077 --> Loss 0.00183686276277\n",
      "Epoch 26::Minibatch 203::LR 0.0423076923077 --> Loss 0.00175285200278\n",
      "Epoch 26::Minibatch 204::LR 0.0423076923077 --> Loss 0.00142682294051\n",
      "Epoch 26::Minibatch 205::LR 0.0423076923077 --> Loss 0.00220097581546\n",
      "Epoch 26::Minibatch 206::LR 0.0423076923077 --> Loss 0.00591763615608\n",
      "Epoch 26::Minibatch 207::LR 0.0423076923077 --> Loss 0.00139692415794\n",
      "Epoch 26::Minibatch 208::LR 0.0423076923077 --> Loss 0.0011116712292\n",
      "Epoch 26::Minibatch 209::LR 0.0423076923077 --> Loss 0.00235311528047\n",
      "Epoch 26::Minibatch 210::LR 0.0423076923077 --> Loss 0.00223700602849\n",
      "Epoch 26::Minibatch 211::LR 0.0423076923077 --> Loss 0.00249142765999\n",
      "Epoch 26::Minibatch 212::LR 0.0423076923077 --> Loss 0.00385134577751\n",
      "Epoch 26::Minibatch 213::LR 0.0423076923077 --> Loss 0.00558744192123\n",
      "Epoch 26::Minibatch 214::LR 0.0423076923077 --> Loss 0.0080130314827\n",
      "Epoch 26::Minibatch 215::LR 0.0423076923077 --> Loss 0.0013660266002\n",
      "Epoch 26::Minibatch 216::LR 0.0423076923077 --> Loss 0.00538949251175\n",
      "Epoch 26::Minibatch 217::LR 0.0423076923077 --> Loss 0.00600499312083\n",
      "Epoch 26::Minibatch 218::LR 0.0423076923077 --> Loss 0.0039057246844\n",
      "Epoch 26::Minibatch 219::LR 0.0423076923077 --> Loss 0.00429675777753\n",
      "Epoch 26::Minibatch 220::LR 0.0423076923077 --> Loss 0.00441969633102\n",
      "Epoch 26::Minibatch 221::LR 0.0423076923077 --> Loss 0.00424146413803\n",
      "Epoch 26::Minibatch 222::LR 0.0423076923077 --> Loss 0.0031949621439\n",
      "Epoch 26::Minibatch 223::LR 0.0423076923077 --> Loss 0.00139564196269\n",
      "Epoch 26::Minibatch 224::LR 0.0423076923077 --> Loss 0.00165763368209\n",
      "Epoch 26::Minibatch 225::LR 0.0423076923077 --> Loss 0.007559791406\n",
      "Epoch 26::Minibatch 226::LR 0.0423076923077 --> Loss 0.00372370362282\n",
      "Epoch 26::Minibatch 227::LR 0.0423076923077 --> Loss 0.00168188671271\n",
      "Epoch 26::Minibatch 228::LR 0.0423076923077 --> Loss 0.000687652528286\n",
      "Epoch 26::Minibatch 229::LR 0.0423076923077 --> Loss 0.0047267361482\n",
      "Epoch 26::Minibatch 230::LR 0.0423076923077 --> Loss 0.00380146185557\n",
      "Epoch 26::Minibatch 231::LR 0.0423076923077 --> Loss 0.00265094359716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 232::LR 0.0423076923077 --> Loss 0.00118365824223\n",
      "Epoch 26::Minibatch 233::LR 0.0423076923077 --> Loss 0.00244373699029\n",
      "Epoch 26::Minibatch 234::LR 0.0423076923077 --> Loss 0.00713943401972\n",
      "Epoch 26::Minibatch 235::LR 0.0423076923077 --> Loss 0.00458941737811\n",
      "Epoch 26::Minibatch 236::LR 0.0423076923077 --> Loss 0.001712094148\n",
      "Epoch 26::Minibatch 237::LR 0.0423076923077 --> Loss 0.000629193037748\n",
      "Epoch 26::Minibatch 238::LR 0.0423076923077 --> Loss 0.00341374238332\n",
      "Epoch 26::Minibatch 239::LR 0.0423076923077 --> Loss 0.00295801659425\n",
      "Epoch 26::Minibatch 240::LR 0.0423076923077 --> Loss 0.00323976496855\n",
      "Epoch 26::Minibatch 241::LR 0.0423076923077 --> Loss 0.000747964531183\n",
      "Epoch 26::Minibatch 242::LR 0.0423076923077 --> Loss 0.00684753020604\n",
      "Epoch 26::Minibatch 243::LR 0.0423076923077 --> Loss 0.00337562004725\n",
      "Epoch 26::Minibatch 244::LR 0.0423076923077 --> Loss 0.00282844324907\n",
      "Epoch 26::Minibatch 245::LR 0.0423076923077 --> Loss 0.000448849797249\n",
      "Epoch 26::Minibatch 246::LR 0.0423076923077 --> Loss 0.00197909792264\n",
      "Epoch 26::Minibatch 247::LR 0.0423076923077 --> Loss 0.0116230336825\n",
      "Epoch 26::Minibatch 248::LR 0.0423076923077 --> Loss 0.0043957722187\n",
      "Epoch 26::Minibatch 249::LR 0.0423076923077 --> Loss 0.00252500553926\n",
      "Epoch 26::Minibatch 250::LR 0.0423076923077 --> Loss 0.00243264297644\n",
      "Epoch 26::Minibatch 251::LR 0.0423076923077 --> Loss 0.00240371982257\n",
      "Epoch 26::Minibatch 252::LR 0.0423076923077 --> Loss 0.00168301065763\n",
      "Epoch 26::Minibatch 253::LR 0.0423076923077 --> Loss 0.00292937457561\n",
      "Epoch 26::Minibatch 254::LR 0.0423076923077 --> Loss 0.00495181004206\n",
      "Epoch 26::Minibatch 255::LR 0.0423076923077 --> Loss 0.00383866985639\n",
      "Epoch 26::Minibatch 256::LR 0.0423076923077 --> Loss 0.00150004277627\n",
      "Epoch 26::Minibatch 257::LR 0.0423076923077 --> Loss 0.00117136577765\n",
      "Epoch 26::Minibatch 258::LR 0.0423076923077 --> Loss 0.00363615870476\n",
      "Epoch 26::Minibatch 259::LR 0.0423076923077 --> Loss 0.00167911032836\n",
      "Epoch 26::Minibatch 260::LR 0.0423076923077 --> Loss 0.00186184843381\n",
      "Epoch 26::Minibatch 261::LR 0.0423076923077 --> Loss 0.00274899085363\n",
      "Epoch 26::Minibatch 262::LR 0.0423076923077 --> Loss 0.00186175386111\n",
      "Epoch 26::Minibatch 263::LR 0.0423076923077 --> Loss 0.00232314785322\n",
      "Epoch 26::Minibatch 264::LR 0.0423076923077 --> Loss 0.00359212795893\n",
      "Epoch 26::Minibatch 265::LR 0.0423076923077 --> Loss 0.010002044042\n",
      "Epoch 26::Minibatch 266::LR 0.0423076923077 --> Loss 0.000943997005622\n",
      "Epoch 26::Minibatch 267::LR 0.0423076923077 --> Loss 0.00949129740397\n",
      "Epoch 26::Minibatch 268::LR 0.0423076923077 --> Loss 0.00110373685757\n",
      "Epoch 26::Minibatch 269::LR 0.0423076923077 --> Loss 0.00347241838773\n",
      "Epoch 26::Minibatch 270::LR 0.0423076923077 --> Loss 0.00698572079341\n",
      "Epoch 26::Minibatch 271::LR 0.0423076923077 --> Loss 0.00255367577076\n",
      "Epoch 26::Minibatch 272::LR 0.0423076923077 --> Loss 0.00426992456118\n",
      "Epoch 26::Minibatch 273::LR 0.0423076923077 --> Loss 0.00151193271081\n",
      "Epoch 26::Minibatch 274::LR 0.0423076923077 --> Loss 0.00178404152393\n",
      "Epoch 26::Minibatch 275::LR 0.0423076923077 --> Loss 0.00255080064138\n",
      "Epoch 26::Minibatch 276::LR 0.0423076923077 --> Loss 0.0034123357137\n",
      "Epoch 26::Minibatch 277::LR 0.0423076923077 --> Loss 0.000928545494874\n",
      "Epoch 26::Minibatch 278::LR 0.0423076923077 --> Loss 0.00258755842845\n",
      "Epoch 26::Minibatch 279::LR 0.0423076923077 --> Loss 0.0021721214056\n",
      "Epoch 26::Minibatch 280::LR 0.0423076923077 --> Loss 0.00190845926603\n",
      "Epoch 26::Minibatch 281::LR 0.0423076923077 --> Loss 0.00120711266994\n",
      "Epoch 26::Minibatch 282::LR 0.0423076923077 --> Loss 0.00212229112784\n",
      "Epoch 26::Minibatch 283::LR 0.0423076923077 --> Loss 0.00204318741957\n",
      "Epoch 26::Minibatch 284::LR 0.0423076923077 --> Loss 0.00165283799171\n",
      "Epoch 26::Minibatch 285::LR 0.0423076923077 --> Loss 0.0011730825901\n",
      "Epoch 26::Minibatch 286::LR 0.0423076923077 --> Loss 0.00205372353395\n",
      "Epoch 26::Minibatch 287::LR 0.0423076923077 --> Loss 0.00201657334963\n",
      "Epoch 26::Minibatch 288::LR 0.0423076923077 --> Loss 0.00109345595042\n",
      "Epoch 26::Minibatch 289::LR 0.0423076923077 --> Loss 0.00159340620041\n",
      "Epoch 26::Minibatch 290::LR 0.0423076923077 --> Loss 0.00190367996693\n",
      "Epoch 26::Minibatch 291::LR 0.0423076923077 --> Loss 0.00170252462228\n",
      "Epoch 26::Minibatch 292::LR 0.0423076923077 --> Loss 0.000599570026\n",
      "Epoch 26::Minibatch 293::LR 0.0423076923077 --> Loss 0.00150644371907\n",
      "Epoch 26::Minibatch 294::LR 0.0423076923077 --> Loss 0.0016018029054\n",
      "Epoch 26::Minibatch 295::LR 0.0423076923077 --> Loss 0.00188525140285\n",
      "Epoch 26::Minibatch 296::LR 0.0423076923077 --> Loss 0.00163550406694\n",
      "Epoch 26::Minibatch 297::LR 0.0423076923077 --> Loss 0.0014223314325\n",
      "Epoch 26::Minibatch 298::LR 0.0423076923077 --> Loss 0.00141908456882\n",
      "Epoch 26::Minibatch 299::LR 0.0423076923077 --> Loss 0.000810731252035\n",
      "Epoch 26::Minibatch 300::LR 0.0423076923077 --> Loss 0.00273879011472\n",
      "Epoch 26::Minibatch 301::LR 0.0423076923077 --> Loss 0.00264959573746\n",
      "Epoch 26::Minibatch 302::LR 0.0423076923077 --> Loss 0.00243012368679\n",
      "Epoch 26::Minibatch 303::LR 0.0423076923077 --> Loss 0.000845103462537\n",
      "Epoch 26::Minibatch 304::LR 0.0423076923077 --> Loss 0.00300804316998\n",
      "Epoch 26::Minibatch 305::LR 0.0423076923077 --> Loss 0.00170603613059\n",
      "Epoch 26::Minibatch 306::LR 0.0423076923077 --> Loss 0.000938022136688\n",
      "Epoch 26::Minibatch 307::LR 0.0423076923077 --> Loss 0.00242312888304\n",
      "Epoch 26::Minibatch 308::LR 0.0423076923077 --> Loss 0.00201686481635\n",
      "Epoch 26::Minibatch 309::LR 0.0423076923077 --> Loss 0.00103135655324\n",
      "Epoch 26::Minibatch 310::LR 0.0423076923077 --> Loss 0.00117157449325\n",
      "Epoch 26::Minibatch 311::LR 0.0423076923077 --> Loss 0.00177425007025\n",
      "Epoch 26::Minibatch 312::LR 0.0423076923077 --> Loss 0.00288528442383\n",
      "Epoch 26::Minibatch 313::LR 0.0423076923077 --> Loss 0.0023636229833\n",
      "Epoch 26::Minibatch 314::LR 0.0423076923077 --> Loss 0.00192271212737\n",
      "Epoch 26::Minibatch 315::LR 0.0423076923077 --> Loss 0.0010301844279\n",
      "Epoch 26::Minibatch 316::LR 0.0423076923077 --> Loss 0.00233906189601\n",
      "Epoch 26::Minibatch 317::LR 0.0423076923077 --> Loss 0.00155704826117\n",
      "Epoch 26::Minibatch 318::LR 0.0423076923077 --> Loss 0.00128025154273\n",
      "Epoch 26::Minibatch 319::LR 0.0423076923077 --> Loss 0.00230438550313\n",
      "Epoch 26::Minibatch 320::LR 0.0423076923077 --> Loss 0.00309584875902\n",
      "Epoch 26::Minibatch 321::LR 0.0423076923077 --> Loss 0.000842060844103\n",
      "Epoch 26::Minibatch 322::LR 0.0423076923077 --> Loss 0.00354199171066\n",
      "Epoch 26::Minibatch 323::LR 0.0423076923077 --> Loss 0.00345847407977\n",
      "Epoch 26::Minibatch 324::LR 0.0423076923077 --> Loss 0.0026420456171\n",
      "Epoch 26::Minibatch 325::LR 0.0423076923077 --> Loss 0.00238101661205\n",
      "Epoch 26::Minibatch 326::LR 0.0423076923077 --> Loss 0.00539626836777\n",
      "Epoch 26::Minibatch 327::LR 0.0423076923077 --> Loss 0.00224252899488\n",
      "Epoch 26::Minibatch 328::LR 0.0423076923077 --> Loss 0.00306684692701\n",
      "Epoch 26::Minibatch 329::LR 0.0423076923077 --> Loss 0.00120440701644\n",
      "Epoch 26::Minibatch 330::LR 0.0423076923077 --> Loss 0.0015908023715\n",
      "Epoch 26::Minibatch 331::LR 0.0423076923077 --> Loss 0.00253508925438\n",
      "Epoch 26::Minibatch 332::LR 0.0423076923077 --> Loss 0.00247383912404\n",
      "Epoch 26::Minibatch 333::LR 0.0423076923077 --> Loss 0.00145882705847\n",
      "Epoch 26::Minibatch 334::LR 0.0423076923077 --> Loss 0.00441883444786\n",
      "Epoch 26::Minibatch 335::LR 0.0423076923077 --> Loss 0.00189222236474\n",
      "Epoch 26::Minibatch 336::LR 0.0423076923077 --> Loss 0.00222850263119\n",
      "Epoch 26::Minibatch 337::LR 0.0423076923077 --> Loss 0.00362079143524\n",
      "Epoch 26::Minibatch 338::LR 0.0423076923077 --> Loss 0.000540835807721\n",
      "Epoch 26::Minibatch 339::LR 0.0423076923077 --> Loss 0.0032855484883\n",
      "Epoch 26::Minibatch 340::LR 0.0423076923077 --> Loss 0.00380987644196\n",
      "Epoch 26::Minibatch 341::LR 0.0423076923077 --> Loss 0.00449218988419\n",
      "Epoch 26::Minibatch 342::LR 0.0423076923077 --> Loss 0.00307661970456\n",
      "Epoch 26::Minibatch 343::LR 0.0423076923077 --> Loss 0.00164737552404\n",
      "Epoch 26::Minibatch 344::LR 0.0423076923077 --> Loss 0.00315622270107\n",
      "Epoch 26::Minibatch 345::LR 0.0423076923077 --> Loss 0.00415426969528\n",
      "Epoch 26::Minibatch 346::LR 0.0423076923077 --> Loss 0.00549688180288\n",
      "Epoch 26::Minibatch 347::LR 0.0423076923077 --> Loss 0.000829556882381\n",
      "Epoch 26::Minibatch 348::LR 0.0423076923077 --> Loss 0.00314947326978\n",
      "Epoch 26::Minibatch 349::LR 0.0423076923077 --> Loss 0.00343275348345\n",
      "Epoch 26::Minibatch 350::LR 0.0423076923077 --> Loss 0.00168740332127\n",
      "Epoch 26::Minibatch 351::LR 0.0423076923077 --> Loss 0.00346843123436\n",
      "Epoch 26::Minibatch 352::LR 0.0423076923077 --> Loss 0.00492387890816\n",
      "Epoch 26::Minibatch 353::LR 0.0423076923077 --> Loss 0.00352681597074\n",
      "Epoch 26::Minibatch 354::LR 0.0423076923077 --> Loss 0.0029388632377\n",
      "Epoch 26::Minibatch 355::LR 0.0423076923077 --> Loss 0.00619054675102\n",
      "Epoch 26::Minibatch 356::LR 0.0423076923077 --> Loss 0.00313568572203\n",
      "Epoch 26::Minibatch 357::LR 0.0423076923077 --> Loss 0.00115265627702\n",
      "Epoch 26::Minibatch 358::LR 0.0423076923077 --> Loss 0.00201504071554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 359::LR 0.0423076923077 --> Loss 0.00269109169642\n",
      "Epoch 26::Minibatch 360::LR 0.0423076923077 --> Loss 0.00234723269939\n",
      "Epoch 26::Minibatch 361::LR 0.0423076923077 --> Loss 0.00232235829035\n",
      "Epoch 26::Minibatch 362::LR 0.0423076923077 --> Loss 0.00230400304\n",
      "Epoch 26::Minibatch 363::LR 0.0423076923077 --> Loss 0.000642174631357\n",
      "Epoch 26::Minibatch 364::LR 0.0423076923077 --> Loss 0.00198102136453\n",
      "Epoch 26::Minibatch 365::LR 0.0423076923077 --> Loss 0.00203576962153\n",
      "Epoch 26::Minibatch 366::LR 0.0423076923077 --> Loss 0.00216461241245\n",
      "Epoch 26::Minibatch 367::LR 0.0423076923077 --> Loss 0.00102576345205\n",
      "Epoch 26::Minibatch 368::LR 0.0423076923077 --> Loss 0.000974071423213\n",
      "Epoch 26::Minibatch 369::LR 0.0423076923077 --> Loss 0.00281195263068\n",
      "Epoch 26::Minibatch 370::LR 0.0423076923077 --> Loss 0.00223206261794\n",
      "Epoch 26::Minibatch 371::LR 0.0423076923077 --> Loss 0.00186154445012\n",
      "Epoch 26::Minibatch 372::LR 0.0423076923077 --> Loss 0.000428945769866\n",
      "Epoch 26::Minibatch 373::LR 0.0423076923077 --> Loss 0.00179096440474\n",
      "Epoch 26::Minibatch 374::LR 0.0423076923077 --> Loss 0.00222996373971\n",
      "Epoch 26::Minibatch 375::LR 0.0423076923077 --> Loss 0.00186726828416\n",
      "Epoch 26::Minibatch 376::LR 0.0423076923077 --> Loss 0.00122273673614\n",
      "Epoch 26::Minibatch 377::LR 0.0423076923077 --> Loss 0.00192045489947\n",
      "Epoch 26::Minibatch 378::LR 0.0423076923077 --> Loss 0.00210669775804\n",
      "Epoch 26::Minibatch 379::LR 0.0423076923077 --> Loss 0.00234094023705\n",
      "Epoch 26::Minibatch 380::LR 0.0423076923077 --> Loss 0.00157218406598\n",
      "Epoch 26::Minibatch 381::LR 0.0423076923077 --> Loss 0.000986399352551\n",
      "Epoch 26::Minibatch 382::LR 0.0423076923077 --> Loss 0.00202235976855\n",
      "Epoch 26::Minibatch 383::LR 0.0423076923077 --> Loss 0.00197380145391\n",
      "Epoch 26::Minibatch 384::LR 0.0423076923077 --> Loss 0.00108792155981\n",
      "Epoch 26::Minibatch 385::LR 0.0423076923077 --> Loss 0.00104523817698\n",
      "Epoch 26::Minibatch 386::LR 0.0423076923077 --> Loss 0.00221148073673\n",
      "Epoch 26::Minibatch 387::LR 0.0423076923077 --> Loss 0.00235328833262\n",
      "Epoch 26::Minibatch 388::LR 0.0423076923077 --> Loss 0.00118611147006\n",
      "Epoch 26::Minibatch 389::LR 0.0423076923077 --> Loss 0.00178542693456\n",
      "Epoch 26::Minibatch 390::LR 0.0423076923077 --> Loss 0.00336797356606\n",
      "Epoch 26::Minibatch 391::LR 0.0423076923077 --> Loss 0.00259361565113\n",
      "Epoch 26::Minibatch 392::LR 0.0423076923077 --> Loss 0.00257714827855\n",
      "Epoch 26::Minibatch 393::LR 0.0423076923077 --> Loss 0.00274132827918\n",
      "Epoch 26::Minibatch 394::LR 0.0423076923077 --> Loss 0.00203032056491\n",
      "Epoch 26::Minibatch 395::LR 0.0423076923077 --> Loss 0.00206027030945\n",
      "Epoch 26::Minibatch 396::LR 0.0423076923077 --> Loss 0.00193127850691\n",
      "Epoch 26::Minibatch 397::LR 0.0423076923077 --> Loss 0.00206697821617\n",
      "Epoch 26::Minibatch 398::LR 0.0423076923077 --> Loss 0.00205410857995\n",
      "Epoch 26::Minibatch 399::LR 0.0423076923077 --> Loss 0.00236374060313\n",
      "Epoch 26::Minibatch 400::LR 0.0423076923077 --> Loss 0.00200224419435\n",
      "Epoch 26::Minibatch 401::LR 0.0423076923077 --> Loss 0.00342767794927\n",
      "Epoch 26::Minibatch 402::LR 0.0423076923077 --> Loss 0.00173932333787\n",
      "Epoch 26::Minibatch 403::LR 0.0423076923077 --> Loss 0.00142890642087\n",
      "Epoch 26::Minibatch 404::LR 0.0423076923077 --> Loss 0.00137586305539\n",
      "Epoch 26::Minibatch 405::LR 0.0423076923077 --> Loss 0.0033761314551\n",
      "Epoch 26::Minibatch 406::LR 0.0423076923077 --> Loss 0.00237597882748\n",
      "Epoch 26::Minibatch 407::LR 0.0423076923077 --> Loss 0.00170794844627\n",
      "Epoch 26::Minibatch 408::LR 0.0423076923077 --> Loss 0.000429174154997\n",
      "Epoch 26::Minibatch 409::LR 0.0423076923077 --> Loss 0.00222870250543\n",
      "Epoch 26::Minibatch 410::LR 0.0423076923077 --> Loss 0.00314347743988\n",
      "Epoch 26::Minibatch 411::LR 0.0423076923077 --> Loss 0.00164168705543\n",
      "Epoch 26::Minibatch 412::LR 0.0423076923077 --> Loss 0.000941701233387\n",
      "Epoch 26::Minibatch 413::LR 0.0423076923077 --> Loss 0.00195786118507\n",
      "Epoch 26::Minibatch 414::LR 0.0423076923077 --> Loss 0.00185007154942\n",
      "Epoch 26::Minibatch 415::LR 0.0423076923077 --> Loss 0.00115251511335\n",
      "Epoch 26::Minibatch 416::LR 0.0423076923077 --> Loss 0.000790846347809\n",
      "Epoch 26::Minibatch 417::LR 0.0423076923077 --> Loss 0.00167455037435\n",
      "Epoch 26::Minibatch 418::LR 0.0423076923077 --> Loss 0.00262233038743\n",
      "Epoch 26::Minibatch 419::LR 0.0423076923077 --> Loss 0.000485602170229\n",
      "Epoch 26::Minibatch 420::LR 0.0423076923077 --> Loss 0.000680520435174\n",
      "Epoch 26::Minibatch 421::LR 0.0423076923077 --> Loss 0.00187989989916\n",
      "Epoch 26::Minibatch 422::LR 0.0423076923077 --> Loss 0.00207402070363\n",
      "Epoch 26::Minibatch 423::LR 0.0423076923077 --> Loss 0.000966144303481\n",
      "Epoch 26::Minibatch 424::LR 0.0423076923077 --> Loss 0.00151563048363\n",
      "Epoch 26::Minibatch 425::LR 0.0423076923077 --> Loss 0.0028750038147\n",
      "Epoch 26::Minibatch 426::LR 0.0423076923077 --> Loss 0.001980240345\n",
      "Epoch 26::Minibatch 427::LR 0.0423076923077 --> Loss 0.000715277045965\n",
      "Epoch 26::Minibatch 428::LR 0.0423076923077 --> Loss 0.000967589418093\n",
      "Epoch 26::Minibatch 429::LR 0.0423076923077 --> Loss 0.00227648317814\n",
      "Epoch 26::Minibatch 430::LR 0.0423076923077 --> Loss 0.00854692776998\n",
      "Epoch 26::Minibatch 431::LR 0.0423076923077 --> Loss 0.00368735829989\n",
      "Epoch 26::Minibatch 432::LR 0.0423076923077 --> Loss 0.00417783856392\n",
      "Epoch 26::Minibatch 433::LR 0.0423076923077 --> Loss 0.00253809670607\n",
      "Epoch 26::Minibatch 434::LR 0.0423076923077 --> Loss 0.0024745541811\n",
      "Epoch 26::Minibatch 435::LR 0.0423076923077 --> Loss 0.00226707438628\n",
      "Epoch 26::Minibatch 436::LR 0.0423076923077 --> Loss 0.00161890467008\n",
      "Epoch 26::Minibatch 437::LR 0.0423076923077 --> Loss 0.00294035772483\n",
      "Epoch 26::Minibatch 438::LR 0.0423076923077 --> Loss 0.00236302693685\n",
      "Epoch 26::Minibatch 439::LR 0.0423076923077 --> Loss 0.0019614726305\n",
      "Epoch 26::Minibatch 440::LR 0.0423076923077 --> Loss 0.00304188112418\n",
      "Epoch 26::Minibatch 441::LR 0.0423076923077 --> Loss 0.00283976058165\n",
      "Epoch 26::Minibatch 442::LR 0.0423076923077 --> Loss 0.00256089230378\n",
      "Epoch 26::Minibatch 443::LR 0.0423076923077 --> Loss 0.00351355671883\n",
      "Epoch 26::Minibatch 444::LR 0.0423076923077 --> Loss 0.00272540549437\n",
      "Epoch 26::Minibatch 445::LR 0.0423076923077 --> Loss 0.000858687758446\n",
      "Epoch 26::Minibatch 446::LR 0.0423076923077 --> Loss 0.00138567825158\n",
      "Epoch 26::Minibatch 447::LR 0.0423076923077 --> Loss 0.00232929249605\n",
      "Epoch 26::Minibatch 448::LR 0.0423076923077 --> Loss 0.00232937832673\n",
      "Epoch 26::Minibatch 449::LR 0.0423076923077 --> Loss 0.00361107428869\n",
      "Epoch 26::Minibatch 450::LR 0.0423076923077 --> Loss 0.00217300375303\n",
      "Epoch 26::Minibatch 451::LR 0.0423076923077 --> Loss 0.00388447920481\n",
      "Epoch 26::Minibatch 452::LR 0.0423076923077 --> Loss 0.0023141070207\n",
      "Epoch 26::Minibatch 453::LR 0.0423076923077 --> Loss 0.00035458261768\n",
      "Epoch 26::Minibatch 454::LR 0.0423076923077 --> Loss 0.00349334478378\n",
      "Epoch 26::Minibatch 455::LR 0.0423076923077 --> Loss 0.00261814276377\n",
      "Epoch 26::Minibatch 456::LR 0.0423076923077 --> Loss 0.00305864791075\n",
      "Epoch 26::Minibatch 457::LR 0.0423076923077 --> Loss 0.00189144810041\n",
      "Epoch 26::Minibatch 458::LR 0.0423076923077 --> Loss 0.000721634825071\n",
      "Epoch 26::Minibatch 459::LR 0.0423076923077 --> Loss 0.00391727805138\n",
      "Epoch 26::Minibatch 460::LR 0.0423076923077 --> Loss 0.002464483579\n",
      "Epoch 26::Minibatch 461::LR 0.0423076923077 --> Loss 0.00374897003174\n",
      "Epoch 26::Minibatch 462::LR 0.0423076923077 --> Loss 0.000374239087105\n",
      "Epoch 26::Minibatch 463::LR 0.0423076923077 --> Loss 0.00426209489504\n",
      "Epoch 26::Minibatch 464::LR 0.0423076923077 --> Loss 0.00196869492531\n",
      "Epoch 26::Minibatch 465::LR 0.0423076923077 --> Loss 0.00474645455678\n",
      "Epoch 26::Minibatch 466::LR 0.0423076923077 --> Loss 0.00501422405243\n",
      "Epoch 26::Minibatch 467::LR 0.0423076923077 --> Loss 0.00525174101194\n",
      "Epoch 26::Minibatch 468::LR 0.0423076923077 --> Loss 0.0057824409008\n",
      "Epoch 26::Minibatch 469::LR 0.0423076923077 --> Loss 0.00611507296562\n",
      "Epoch 26::Minibatch 470::LR 0.0423076923077 --> Loss 0.00361736138662\n",
      "Epoch 26::Minibatch 471::LR 0.0423076923077 --> Loss 0.00167966584365\n",
      "Epoch 26::Minibatch 472::LR 0.0423076923077 --> Loss 0.00355130076408\n",
      "Epoch 26::Minibatch 473::LR 0.0423076923077 --> Loss 0.00229006389777\n",
      "Epoch 26::Minibatch 474::LR 0.0423076923077 --> Loss 0.000691420286894\n",
      "Epoch 26::Minibatch 475::LR 0.0423076923077 --> Loss 0.00488743861516\n",
      "Epoch 26::Minibatch 476::LR 0.0423076923077 --> Loss 0.00769346952438\n",
      "Epoch 26::Minibatch 477::LR 0.0423076923077 --> Loss 0.000917812883854\n",
      "Epoch 26::Minibatch 478::LR 0.0423076923077 --> Loss 0.00242511550585\n",
      "Epoch 26::Minibatch 479::LR 0.0423076923077 --> Loss 0.00196182549\n",
      "Epoch 26::Minibatch 480::LR 0.0423076923077 --> Loss 0.00151966422796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 481::LR 0.0423076923077 --> Loss 0.000956319868565\n",
      "Epoch 26::Minibatch 482::LR 0.0423076923077 --> Loss 0.00207510193189\n",
      "Epoch 26::Minibatch 483::LR 0.0423076923077 --> Loss 0.00306357304255\n",
      "Epoch 26::Minibatch 484::LR 0.0423076923077 --> Loss 0.00344170729319\n",
      "Epoch 26::Minibatch 485::LR 0.0423076923077 --> Loss 0.00076017588377\n",
      "Epoch 26::Minibatch 486::LR 0.0423076923077 --> Loss 0.00283554255962\n",
      "Epoch 26::Minibatch 487::LR 0.0423076923077 --> Loss 0.00331171631813\n",
      "Epoch 26::Minibatch 488::LR 0.0423076923077 --> Loss 0.00202754358451\n",
      "Epoch 26::Minibatch 489::LR 0.0423076923077 --> Loss 0.00311004837354\n",
      "Epoch 26::Minibatch 490::LR 0.0423076923077 --> Loss 0.000409937401613\n",
      "Epoch 26::Minibatch 491::LR 0.0423076923077 --> Loss 0.00335415442785\n",
      "Epoch 26::Minibatch 492::LR 0.0423076923077 --> Loss 0.00306183536847\n",
      "Epoch 26::Minibatch 493::LR 0.0423076923077 --> Loss 0.0030273660024\n",
      "Epoch 26::Minibatch 494::LR 0.0423076923077 --> Loss 0.000733942886194\n",
      "Epoch 26::Minibatch 495::LR 0.0423076923077 --> Loss 0.00184345881144\n",
      "Epoch 26::Minibatch 496::LR 0.0423076923077 --> Loss 0.00280497789383\n",
      "Epoch 26::Minibatch 497::LR 0.0423076923077 --> Loss 0.000917584796747\n",
      "Epoch 26::Minibatch 498::LR 0.0423076923077 --> Loss 0.000552332550287\n",
      "Epoch 26::Minibatch 499::LR 0.0423076923077 --> Loss 0.00346231778463\n",
      "Epoch 26::Minibatch 500::LR 0.0423076923077 --> Loss 0.00143035382032\n",
      "Epoch 26::Minibatch 501::LR 0.0423076923077 --> Loss 0.00209475914637\n",
      "Epoch 26::Minibatch 502::LR 0.0423076923077 --> Loss 0.00376096685727\n",
      "Epoch 26::Minibatch 503::LR 0.0423076923077 --> Loss 0.00714025338491\n",
      "Epoch 26::Minibatch 504::LR 0.0423076923077 --> Loss 0.00700086275736\n",
      "Epoch 26::Minibatch 505::LR 0.0423076923077 --> Loss 0.00405775864919\n",
      "Epoch 26::Minibatch 506::LR 0.0423076923077 --> Loss 0.00335549155871\n",
      "Epoch 26::Minibatch 507::LR 0.0423076923077 --> Loss 0.00584918022156\n",
      "Epoch 26::Minibatch 508::LR 0.0423076923077 --> Loss 0.00339642564456\n",
      "Epoch 26::Minibatch 509::LR 0.0423076923077 --> Loss 0.0043394668897\n",
      "Epoch 26::Minibatch 510::LR 0.0423076923077 --> Loss 0.00444079558055\n",
      "Epoch 26::Minibatch 511::LR 0.0423076923077 --> Loss 0.00396381696065\n",
      "Epoch 26::Minibatch 512::LR 0.0423076923077 --> Loss 0.00268144806226\n",
      "Epoch 26::Minibatch 513::LR 0.0423076923077 --> Loss 0.00060921271642\n",
      "Epoch 26::Minibatch 514::LR 0.0423076923077 --> Loss 0.00265148162842\n",
      "Epoch 26::Minibatch 515::LR 0.0423076923077 --> Loss 0.00299661795298\n",
      "Epoch 26::Minibatch 516::LR 0.0423076923077 --> Loss 0.00395810564359\n",
      "Epoch 26::Minibatch 517::LR 0.0423076923077 --> Loss 0.00357934594154\n",
      "Epoch 26::Minibatch 518::LR 0.0423076923077 --> Loss 0.00257849713167\n",
      "Epoch 26::Minibatch 519::LR 0.0423076923077 --> Loss 0.00350720961889\n",
      "Epoch 26::Minibatch 520::LR 0.0423076923077 --> Loss 0.0054752322038\n",
      "Epoch 26::Minibatch 521::LR 0.0423076923077 --> Loss 0.00556039492289\n",
      "Epoch 26::Minibatch 522::LR 0.0423076923077 --> Loss 0.00744592110316\n",
      "Epoch 26::Minibatch 523::LR 0.0423076923077 --> Loss 0.000628301600615\n",
      "Epoch 26::Minibatch 524::LR 0.0423076923077 --> Loss 0.00140205979347\n",
      "Epoch 26::Minibatch 525::LR 0.0423076923077 --> Loss 0.00311672270298\n",
      "Epoch 26::Minibatch 526::LR 0.0423076923077 --> Loss 0.00380757729212\n",
      "Epoch 26::Minibatch 527::LR 0.0423076923077 --> Loss 0.00216204424699\n",
      "Epoch 26::Minibatch 528::LR 0.0423076923077 --> Loss 0.000959728161494\n",
      "Epoch 26::Minibatch 529::LR 0.0423076923077 --> Loss 0.00390505472819\n",
      "Epoch 26::Minibatch 530::LR 0.0423076923077 --> Loss 0.00389484286308\n",
      "Epoch 26::Minibatch 531::LR 0.0423076923077 --> Loss 0.00344234744708\n",
      "Epoch 26::Minibatch 532::LR 0.0423076923077 --> Loss 0.00263085385164\n",
      "Epoch 26::Minibatch 533::LR 0.0423076923077 --> Loss 0.00490414222082\n",
      "Epoch 26::Minibatch 534::LR 0.0423076923077 --> Loss 0.00371653318405\n",
      "Epoch 26::Minibatch 535::LR 0.0423076923077 --> Loss 0.00327602942785\n",
      "Epoch 26::Minibatch 536::LR 0.0423076923077 --> Loss 0.00210473895073\n",
      "Epoch 26::Minibatch 537::LR 0.0423076923077 --> Loss 0.000593377153079\n",
      "Epoch 26::Minibatch 538::LR 0.0423076923077 --> Loss 0.00165011276801\n",
      "Epoch 26::Minibatch 539::LR 0.0423076923077 --> Loss 0.00335114161174\n",
      "Epoch 26::Minibatch 540::LR 0.0423076923077 --> Loss 0.0034028784434\n",
      "Epoch 26::Minibatch 541::LR 0.0423076923077 --> Loss 0.0028615963459\n",
      "Epoch 26::Minibatch 542::LR 0.0423076923077 --> Loss 0.00245381434759\n",
      "Epoch 26::Minibatch 543::LR 0.0423076923077 --> Loss 0.00262576361497\n",
      "Epoch 26::Minibatch 544::LR 0.0423076923077 --> Loss 0.00396157582601\n",
      "Epoch 26::Minibatch 545::LR 0.0423076923077 --> Loss 0.00200064003468\n",
      "Epoch 26::Minibatch 546::LR 0.0423076923077 --> Loss 0.00065552358826\n",
      "Epoch 26::Minibatch 547::LR 0.0423076923077 --> Loss 0.00259170810382\n",
      "Epoch 26::Minibatch 548::LR 0.0423076923077 --> Loss 0.00348388791084\n",
      "Epoch 26::Minibatch 549::LR 0.0423076923077 --> Loss 0.00876441319784\n",
      "Epoch 26::Minibatch 550::LR 0.0423076923077 --> Loss 0.00117818802595\n",
      "Epoch 26::Minibatch 551::LR 0.0423076923077 --> Loss 0.00245213091373\n",
      "Epoch 26::Minibatch 552::LR 0.0423076923077 --> Loss 0.00346204519272\n",
      "Epoch 26::Minibatch 553::LR 0.0423076923077 --> Loss 0.00304103930791\n",
      "Epoch 26::Minibatch 554::LR 0.0423076923077 --> Loss 0.00367057124774\n",
      "Epoch 26::Minibatch 555::LR 0.0423076923077 --> Loss 0.000952463348707\n",
      "Epoch 26::Minibatch 556::LR 0.0423076923077 --> Loss 0.00194009800752\n",
      "Epoch 26::Minibatch 557::LR 0.0423076923077 --> Loss 0.00240200579166\n",
      "Epoch 26::Minibatch 558::LR 0.0423076923077 --> Loss 0.00362927397092\n",
      "Epoch 26::Minibatch 559::LR 0.0423076923077 --> Loss 0.00367232441902\n",
      "Epoch 26::Minibatch 560::LR 0.0423076923077 --> Loss 0.00306313792864\n",
      "Epoch 26::Minibatch 561::LR 0.0423076923077 --> Loss 0.00264088650544\n",
      "Epoch 26::Minibatch 562::LR 0.0423076923077 --> Loss 0.00234725415707\n",
      "Epoch 26::Minibatch 563::LR 0.0423076923077 --> Loss 0.00398284435272\n",
      "Epoch 26::Minibatch 564::LR 0.0423076923077 --> Loss 0.00306269486745\n",
      "Epoch 26::Minibatch 565::LR 0.0423076923077 --> Loss 0.00360725998878\n",
      "Epoch 26::Minibatch 566::LR 0.0423076923077 --> Loss 0.00220651229223\n",
      "Epoch 26::Minibatch 567::LR 0.0423076923077 --> Loss 0.00253774285316\n",
      "Epoch 26::Minibatch 568::LR 0.0423076923077 --> Loss 0.00176228562991\n",
      "Epoch 26::Minibatch 569::LR 0.0423076923077 --> Loss 0.000561318049828\n",
      "Epoch 26::Minibatch 570::LR 0.0423076923077 --> Loss 0.00164738595486\n",
      "Epoch 26::Minibatch 571::LR 0.0423076923077 --> Loss 0.00211206456025\n",
      "Epoch 26::Minibatch 572::LR 0.0423076923077 --> Loss 0.00226560473442\n",
      "Epoch 26::Minibatch 573::LR 0.0423076923077 --> Loss 0.00146131614844\n",
      "Epoch 26::Minibatch 574::LR 0.0423076923077 --> Loss 0.00104507178068\n",
      "Epoch 26::Minibatch 575::LR 0.0423076923077 --> Loss 0.00173846721649\n",
      "Epoch 26::Minibatch 576::LR 0.0423076923077 --> Loss 0.00205349246661\n",
      "Epoch 26::Minibatch 577::LR 0.0423076923077 --> Loss 0.00162413378557\n",
      "Epoch 26::Minibatch 578::LR 0.0423076923077 --> Loss 0.0012712948521\n",
      "Epoch 26::Minibatch 579::LR 0.0423076923077 --> Loss 0.0011871740222\n",
      "Epoch 26::Minibatch 580::LR 0.0423076923077 --> Loss 0.00192573964596\n",
      "Epoch 26::Minibatch 581::LR 0.0423076923077 --> Loss 0.00170839607716\n",
      "Epoch 26::Minibatch 582::LR 0.0423076923077 --> Loss 0.00416372299194\n",
      "Epoch 26::Minibatch 583::LR 0.0423076923077 --> Loss 0.00094803382953\n",
      "Epoch 26::Minibatch 584::LR 0.0423076923077 --> Loss 0.00130754083395\n",
      "Epoch 26::Minibatch 585::LR 0.0423076923077 --> Loss 0.00404862244924\n",
      "Epoch 26::Minibatch 586::LR 0.0423076923077 --> Loss 0.00381160736084\n",
      "Epoch 26::Minibatch 587::LR 0.0423076923077 --> Loss 0.00111797193686\n",
      "Epoch 26::Minibatch 588::LR 0.0423076923077 --> Loss 0.0013831259807\n",
      "Epoch 26::Minibatch 589::LR 0.0423076923077 --> Loss 0.00275219241778\n",
      "Epoch 26::Minibatch 590::LR 0.0423076923077 --> Loss 0.00184529165427\n",
      "Epoch 26::Minibatch 591::LR 0.0423076923077 --> Loss 0.00280940930049\n",
      "Epoch 26::Minibatch 592::LR 0.0423076923077 --> Loss 0.00115926653147\n",
      "Epoch 26::Minibatch 593::LR 0.0423076923077 --> Loss 0.00250910480817\n",
      "Epoch 26::Minibatch 594::LR 0.0423076923077 --> Loss 0.0026257032156\n",
      "Epoch 26::Minibatch 595::LR 0.0423076923077 --> Loss 0.00304268538952\n",
      "Epoch 26::Minibatch 596::LR 0.0423076923077 --> Loss 0.00187321782112\n",
      "Epoch 26::Minibatch 597::LR 0.0423076923077 --> Loss 0.00117645124594\n",
      "Epoch 26::Minibatch 598::LR 0.0423076923077 --> Loss 0.0028676768144\n",
      "Epoch 26::Minibatch 599::LR 0.0423076923077 --> Loss 0.00181169271469\n",
      "Epoch 26::Minibatch 600::LR 0.0423076923077 --> Loss 0.00215659519037\n",
      "Epoch 26::Minibatch 601::LR 0.0423076923077 --> Loss 0.00378213723501\n",
      "Epoch 26::Minibatch 602::LR 0.0423076923077 --> Loss 0.00209453483423\n",
      "Epoch 26::Minibatch 603::LR 0.0423076923077 --> Loss 0.00262524406115\n",
      "Epoch 26::Minibatch 604::LR 0.0423076923077 --> Loss 0.00163845578829\n",
      "Epoch 26::Minibatch 605::LR 0.0423076923077 --> Loss 0.00231140057246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 606::LR 0.0423076923077 --> Loss 0.00187857091427\n",
      "Epoch 26::Minibatch 607::LR 0.0423076923077 --> Loss 0.000831369012594\n",
      "Epoch 26::Minibatch 608::LR 0.0423076923077 --> Loss 0.0015638478597\n",
      "Epoch 26::Minibatch 609::LR 0.0423076923077 --> Loss 0.00241168518861\n",
      "Epoch 26::Minibatch 610::LR 0.0423076923077 --> Loss 0.00402986009916\n",
      "Epoch 26::Minibatch 611::LR 0.0423076923077 --> Loss 0.00264088292917\n",
      "Epoch 26::Minibatch 612::LR 0.0423076923077 --> Loss 0.000473774572213\n",
      "Epoch 26::Minibatch 613::LR 0.0423076923077 --> Loss 0.00131023744742\n",
      "Epoch 26::Minibatch 614::LR 0.0423076923077 --> Loss 0.00241947054863\n",
      "Epoch 26::Minibatch 615::LR 0.0423076923077 --> Loss 0.0016640835007\n",
      "Epoch 26::Minibatch 616::LR 0.0423076923077 --> Loss 0.000919607579708\n",
      "Epoch 26::Minibatch 617::LR 0.0423076923077 --> Loss 0.000493929733833\n",
      "Epoch 26::Minibatch 618::LR 0.0423076923077 --> Loss 0.0028264472882\n",
      "Epoch 26::Minibatch 619::LR 0.0423076923077 --> Loss 0.00192669034004\n",
      "Epoch 26::Minibatch 620::LR 0.0423076923077 --> Loss 0.00170045554638\n",
      "Epoch 26::Minibatch 621::LR 0.0423076923077 --> Loss 0.00084790199995\n",
      "Epoch 26::Minibatch 622::LR 0.0423076923077 --> Loss 0.000785422126452\n",
      "Epoch 26::Minibatch 623::LR 0.0423076923077 --> Loss 0.0022197675705\n",
      "Epoch 26::Minibatch 624::LR 0.0423076923077 --> Loss 0.00178327043851\n",
      "Epoch 26::Minibatch 625::LR 0.0423076923077 --> Loss 0.00274801313877\n",
      "Epoch 26::Minibatch 626::LR 0.0423076923077 --> Loss 0.00386590162913\n",
      "Epoch 26::Minibatch 627::LR 0.0423076923077 --> Loss 0.00128362695376\n",
      "Epoch 26::Minibatch 628::LR 0.0423076923077 --> Loss 0.000882967313131\n",
      "Epoch 26::Minibatch 629::LR 0.0423076923077 --> Loss 0.00318811078866\n",
      "Epoch 26::Minibatch 630::LR 0.0423076923077 --> Loss 0.0031148870786\n",
      "Epoch 26::Minibatch 631::LR 0.0423076923077 --> Loss 0.00554159323374\n",
      "Epoch 26::Minibatch 632::LR 0.0423076923077 --> Loss 0.000791208694379\n",
      "Epoch 26::Minibatch 633::LR 0.0423076923077 --> Loss 0.00163050353527\n",
      "Epoch 26::Minibatch 634::LR 0.0423076923077 --> Loss 0.003208471934\n",
      "Epoch 26::Minibatch 635::LR 0.0423076923077 --> Loss 0.0054808362325\n",
      "Epoch 26::Minibatch 636::LR 0.0423076923077 --> Loss 0.00473107457161\n",
      "Epoch 26::Minibatch 637::LR 0.0423076923077 --> Loss 0.000732387801011\n",
      "Epoch 26::Minibatch 638::LR 0.0423076923077 --> Loss 0.00148760606845\n",
      "Epoch 26::Minibatch 639::LR 0.0423076923077 --> Loss 0.00322104851405\n",
      "Epoch 26::Minibatch 640::LR 0.0423076923077 --> Loss 0.00471818407377\n",
      "Epoch 26::Minibatch 641::LR 0.0423076923077 --> Loss 0.00307288547357\n",
      "Epoch 26::Minibatch 642::LR 0.0423076923077 --> Loss 0.000534063577652\n",
      "Epoch 26::Minibatch 643::LR 0.0423076923077 --> Loss 0.002320069472\n",
      "Epoch 26::Minibatch 644::LR 0.0423076923077 --> Loss 0.00390295624733\n",
      "Epoch 26::Minibatch 645::LR 0.0423076923077 --> Loss 0.00434746742249\n",
      "Epoch 26::Minibatch 646::LR 0.0423076923077 --> Loss 0.00150132586559\n",
      "Epoch 26::Minibatch 647::LR 0.0423076923077 --> Loss 0.00048144792517\n",
      "Epoch 26::Minibatch 648::LR 0.0423076923077 --> Loss 0.00283715188503\n",
      "Epoch 26::Minibatch 649::LR 0.0423076923077 --> Loss 0.00333941499392\n",
      "Epoch 26::Minibatch 650::LR 0.0423076923077 --> Loss 0.00322790165742\n",
      "Epoch 26::Minibatch 651::LR 0.0423076923077 --> Loss 0.00134749501944\n",
      "Epoch 26::Minibatch 652::LR 0.0423076923077 --> Loss 0.000782733261585\n",
      "Epoch 26::Minibatch 653::LR 0.0423076923077 --> Loss 0.00282219072183\n",
      "Epoch 26::Minibatch 654::LR 0.0423076923077 --> Loss 0.00312732100487\n",
      "Epoch 26::Minibatch 655::LR 0.0423076923077 --> Loss 0.00357630729675\n",
      "Epoch 26::Minibatch 656::LR 0.0423076923077 --> Loss 0.000754531174898\n",
      "Epoch 26::Minibatch 657::LR 0.0423076923077 --> Loss 0.00226308027903\n",
      "Epoch 26::Minibatch 658::LR 0.0423076923077 --> Loss 0.00464152693748\n",
      "Epoch 26::Minibatch 659::LR 0.0423076923077 --> Loss 0.00224766135216\n",
      "Epoch 26::Minibatch 660::LR 0.0423076923077 --> Loss 0.00262554486593\n",
      "Epoch 26::Minibatch 661::LR 0.0423076923077 --> Loss 0.00234954357147\n",
      "Epoch 26::Minibatch 662::LR 0.0423076923077 --> Loss 0.00180069406827\n",
      "Epoch 26::Minibatch 663::LR 0.0423076923077 --> Loss 0.00369053403536\n",
      "Epoch 26::Minibatch 664::LR 0.0423076923077 --> Loss 0.0032528090477\n",
      "Epoch 26::Minibatch 665::LR 0.0423076923077 --> Loss 0.000705345571041\n",
      "Epoch 26::Minibatch 666::LR 0.0423076923077 --> Loss 0.00390704552333\n",
      "Epoch 26::Minibatch 667::LR 0.0423076923077 --> Loss 0.00254301011562\n",
      "Epoch 26::Minibatch 668::LR 0.0423076923077 --> Loss 0.00655307928721\n",
      "Epoch 26::Minibatch 669::LR 0.0423076923077 --> Loss 0.00108858505885\n",
      "Epoch 26::Minibatch 670::LR 0.0423076923077 --> Loss 0.0013365154465\n",
      "Epoch 26::Minibatch 671::LR 0.0423076923077 --> Loss 0.00517572641373\n",
      "Epoch 26::Minibatch 672::LR 0.0423076923077 --> Loss 0.00350813150406\n",
      "Epoch 26::Minibatch 673::LR 0.0423076923077 --> Loss 0.00161231885354\n",
      "Epoch 26::Minibatch 674::LR 0.0423076923077 --> Loss 0.000509838064512\n",
      "Epoch 26::Minibatch 675::LR 0.0423076923077 --> Loss 0.0021885830164\n",
      "Epoch 26::Minibatch 676::LR 0.0423076923077 --> Loss 0.00214053034782\n",
      "Epoch 26::Minibatch 677::LR 0.0423076923077 --> Loss 0.0027377508084\n",
      "Epoch 26::Minibatch 678::LR 0.0423076923077 --> Loss 0.0018862893184\n",
      "Epoch 26::Minibatch 679::LR 0.0423076923077 --> Loss 0.00337579250336\n",
      "Epoch 26::Minibatch 680::LR 0.0423076923077 --> Loss 0.00212993899981\n",
      "Epoch 26::Minibatch 681::LR 0.0423076923077 --> Loss 0.0024081303676\n",
      "Epoch 26::Minibatch 682::LR 0.0423076923077 --> Loss 0.000760885477066\n",
      "Epoch 26::Minibatch 683::LR 0.0423076923077 --> Loss 0.00233428279559\n",
      "Epoch 26::Minibatch 684::LR 0.0423076923077 --> Loss 0.0023406046629\n",
      "Epoch 26::Minibatch 685::LR 0.0423076923077 --> Loss 0.00284895102183\n",
      "Epoch 26::Minibatch 686::LR 0.0423076923077 --> Loss 0.0015754883488\n",
      "Epoch 26::Minibatch 687::LR 0.0423076923077 --> Loss 0.000866943597794\n",
      "Epoch 26::Minibatch 688::LR 0.0423076923077 --> Loss 0.00278366088867\n",
      "Epoch 26::Minibatch 689::LR 0.0423076923077 --> Loss 0.00249161303043\n",
      "Epoch 26::Minibatch 690::LR 0.0423076923077 --> Loss 0.00189513484637\n",
      "Epoch 26::Minibatch 691::LR 0.0423076923077 --> Loss 0.00065782353282\n",
      "Epoch 26::Minibatch 692::LR 0.0423076923077 --> Loss 0.00244887133439\n",
      "Epoch 26::Minibatch 693::LR 0.0423076923077 --> Loss 0.00259740173817\n",
      "Epoch 26::Minibatch 694::LR 0.0423076923077 --> Loss 0.00300568958124\n",
      "Epoch 26::Minibatch 695::LR 0.0423076923077 --> Loss 0.00177483638128\n",
      "Epoch 26::Minibatch 696::LR 0.0423076923077 --> Loss 0.00203979810079\n",
      "Epoch 26::Minibatch 697::LR 0.0423076923077 --> Loss 0.00140205760797\n",
      "Epoch 26::Minibatch 698::LR 0.0423076923077 --> Loss 0.00165259192387\n",
      "Epoch 26::Minibatch 699::LR 0.0423076923077 --> Loss 0.00376136620839\n",
      "Epoch 26::Minibatch 700::LR 0.0423076923077 --> Loss 0.00261612375577\n",
      "Epoch 26::Minibatch 701::LR 0.0423076923077 --> Loss 0.00192210634549\n",
      "Epoch 26::Minibatch 702::LR 0.0423076923077 --> Loss 0.00166442016761\n",
      "Epoch 26::Minibatch 703::LR 0.0423076923077 --> Loss 0.0043297235171\n",
      "Epoch 26::Minibatch 704::LR 0.0423076923077 --> Loss 0.00180333971977\n",
      "Epoch 26::Minibatch 705::LR 0.0423076923077 --> Loss 0.00285667896271\n",
      "Epoch 26::Minibatch 706::LR 0.0423076923077 --> Loss 0.00222266634305\n",
      "Epoch 26::Minibatch 707::LR 0.0423076923077 --> Loss 0.00118041177591\n",
      "Epoch 26::Minibatch 708::LR 0.0423076923077 --> Loss 0.00173143605391\n",
      "Epoch 26::Minibatch 709::LR 0.0423076923077 --> Loss 0.00167492926121\n",
      "Epoch 26::Minibatch 710::LR 0.0423076923077 --> Loss 0.002564021945\n",
      "Epoch 26::Minibatch 711::LR 0.0423076923077 --> Loss 0.00195481876532\n",
      "Epoch 26::Minibatch 712::LR 0.0423076923077 --> Loss 0.0013477687041\n",
      "Epoch 26::Minibatch 713::LR 0.0423076923077 --> Loss 0.00178151945273\n",
      "Epoch 26::Minibatch 714::LR 0.0423076923077 --> Loss 0.00282242417336\n",
      "Epoch 26::Minibatch 715::LR 0.0423076923077 --> Loss 0.00293025314808\n",
      "Epoch 26::Minibatch 716::LR 0.0423076923077 --> Loss 0.00164449046055\n",
      "Epoch 26::Minibatch 717::LR 0.0423076923077 --> Loss 0.00164826283852\n",
      "Epoch 26::Minibatch 718::LR 0.0423076923077 --> Loss 0.00126833955447\n",
      "Epoch 26::Minibatch 719::LR 0.0423076923077 --> Loss 0.00170346120993\n",
      "Epoch 26::Minibatch 720::LR 0.0423076923077 --> Loss 0.00267683645089\n",
      "Epoch 26::Minibatch 721::LR 0.0423076923077 --> Loss 0.000607926845551\n",
      "Epoch 26::Minibatch 722::LR 0.0423076923077 --> Loss 0.00466567238172\n",
      "Epoch 26::Minibatch 723::LR 0.0423076923077 --> Loss 0.00485963265101\n",
      "Epoch 26::Minibatch 724::LR 0.0423076923077 --> Loss 0.00096492211024\n",
      "Epoch 26::Minibatch 725::LR 0.0423076923077 --> Loss 0.00209848682086\n",
      "Epoch 26::Minibatch 726::LR 0.0423076923077 --> Loss 0.00398527979851\n",
      "Epoch 26::Minibatch 727::LR 0.0423076923077 --> Loss 0.00316177010536\n",
      "Epoch 26::Minibatch 728::LR 0.0423076923077 --> Loss 0.000641580621401\n",
      "Epoch 26::Minibatch 729::LR 0.0423076923077 --> Loss 0.000726343393326\n",
      "Epoch 26::Minibatch 730::LR 0.0423076923077 --> Loss 0.00289576947689\n",
      "Epoch 26::Minibatch 731::LR 0.0423076923077 --> Loss 0.00257840116819\n",
      "Epoch 26::Minibatch 732::LR 0.0423076923077 --> Loss 0.00210554361343\n",
      "Epoch 26::Minibatch 733::LR 0.0423076923077 --> Loss 0.000623292028904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 734::LR 0.0423076923077 --> Loss 0.00167349596818\n",
      "Epoch 26::Minibatch 735::LR 0.0423076923077 --> Loss 0.00242451270421\n",
      "Epoch 26::Minibatch 736::LR 0.0423076923077 --> Loss 0.00347375750542\n",
      "Epoch 26::Minibatch 737::LR 0.0423076923077 --> Loss 0.00298753321171\n",
      "Epoch 26::Minibatch 738::LR 0.0423076923077 --> Loss 0.00146539270878\n",
      "Epoch 26::Minibatch 739::LR 0.0423076923077 --> Loss 0.00241844097773\n",
      "Epoch 26::Minibatch 740::LR 0.0423076923077 --> Loss 0.0037969660759\n",
      "Epoch 26::Minibatch 741::LR 0.0423076923077 --> Loss 0.00257775902748\n",
      "Epoch 26::Minibatch 742::LR 0.0423076923077 --> Loss 0.00209399998188\n",
      "Epoch 26::Minibatch 743::LR 0.0423076923077 --> Loss 0.00146842757861\n",
      "Epoch 26::Minibatch 744::LR 0.0423076923077 --> Loss 0.00184062262376\n",
      "Epoch 26::Minibatch 745::LR 0.0423076923077 --> Loss 0.0027938491106\n",
      "Epoch 26::Minibatch 746::LR 0.0423076923077 --> Loss 0.00289557913939\n",
      "Epoch 26::Minibatch 747::LR 0.0423076923077 --> Loss 0.00177292307218\n",
      "Epoch 26::Minibatch 748::LR 0.0423076923077 --> Loss 0.000620088924964\n",
      "Epoch 26::Minibatch 749::LR 0.0423076923077 --> Loss 0.00166266024113\n",
      "Epoch 26::Minibatch 750::LR 0.0423076923077 --> Loss 0.00243343174458\n",
      "Epoch 26::Minibatch 751::LR 0.0423076923077 --> Loss 0.00285144527753\n",
      "Epoch 26::Minibatch 752::LR 0.0423076923077 --> Loss 0.00133902360996\n",
      "Epoch 26::Minibatch 753::LR 0.0423076923077 --> Loss 0.00219816664855\n",
      "Epoch 26::Minibatch 754::LR 0.0423076923077 --> Loss 0.00240887125333\n",
      "Epoch 26::Minibatch 755::LR 0.0423076923077 --> Loss 0.00266367057959\n",
      "Epoch 26::Minibatch 756::LR 0.0423076923077 --> Loss 0.00133170048396\n",
      "Epoch 26::Minibatch 757::LR 0.0423076923077 --> Loss 0.000656867523988\n",
      "Epoch 26::Minibatch 758::LR 0.0423076923077 --> Loss 0.00157769799232\n",
      "Epoch 26::Minibatch 759::LR 0.0423076923077 --> Loss 0.0035485915343\n",
      "Epoch 26::Minibatch 760::LR 0.0423076923077 --> Loss 0.00286117851734\n",
      "Epoch 26::Minibatch 761::LR 0.0423076923077 --> Loss 0.00588800748189\n",
      "Epoch 26::Minibatch 762::LR 0.0423076923077 --> Loss 0.00364412506421\n",
      "Epoch 26::Minibatch 763::LR 0.0423076923077 --> Loss 0.00348170161247\n",
      "Epoch 26::Minibatch 764::LR 0.0423076923077 --> Loss 0.00308930158615\n",
      "Epoch 26::Minibatch 765::LR 0.0423076923077 --> Loss 0.00127079407374\n",
      "Epoch 26::Minibatch 766::LR 0.0423076923077 --> Loss 0.00229421714942\n",
      "Epoch 26::Minibatch 767::LR 0.0423076923077 --> Loss 0.00486235062281\n",
      "Epoch 26::Minibatch 768::LR 0.0423076923077 --> Loss 0.00365624547005\n",
      "Epoch 26::Minibatch 769::LR 0.0423076923077 --> Loss 0.00185543914636\n",
      "Epoch 26::Minibatch 770::LR 0.0423076923077 --> Loss 0.00149253149827\n",
      "Epoch 26::Minibatch 771::LR 0.0423076923077 --> Loss 0.00350653012594\n",
      "Epoch 26::Minibatch 772::LR 0.0423076923077 --> Loss 0.00353708267212\n",
      "Epoch 26::Minibatch 773::LR 0.0423076923077 --> Loss 0.00316366036733\n",
      "Epoch 26::Minibatch 774::LR 0.0423076923077 --> Loss 0.00184859573841\n",
      "Epoch 26::Minibatch 775::LR 0.0423076923077 --> Loss 0.00345393617948\n",
      "Epoch 26::Minibatch 776::LR 0.0423076923077 --> Loss 0.00368062019348\n",
      "Epoch 26::Minibatch 777::LR 0.0423076923077 --> Loss 0.00654320001602\n",
      "Epoch 26::Minibatch 778::LR 0.0423076923077 --> Loss 0.00800394455592\n",
      "Epoch 26::Minibatch 779::LR 0.0423076923077 --> Loss 0.00244481027126\n",
      "Epoch 26::Minibatch 780::LR 0.0423076923077 --> Loss 0.00153710871935\n",
      "Epoch 26::Minibatch 781::LR 0.0423076923077 --> Loss 0.00345410943031\n",
      "Epoch 26::Minibatch 782::LR 0.0423076923077 --> Loss 0.00382082382838\n",
      "Epoch 26::Minibatch 783::LR 0.0423076923077 --> Loss 0.00227484663328\n",
      "Epoch 26::Minibatch 784::LR 0.0423076923077 --> Loss 0.000706529517968\n",
      "Epoch 26::Minibatch 785::LR 0.0423076923077 --> Loss 0.00324999014537\n",
      "Epoch 26::Minibatch 786::LR 0.0423076923077 --> Loss 0.00342462142309\n",
      "Epoch 26::Minibatch 787::LR 0.0423076923077 --> Loss 0.00259420951207\n",
      "Epoch 26::Minibatch 788::LR 0.0423076923077 --> Loss 0.00235512455304\n",
      "Epoch 26::Minibatch 789::LR 0.0423076923077 --> Loss 0.000727637608846\n",
      "Epoch 26::Minibatch 790::LR 0.0423076923077 --> Loss 0.00312569737434\n",
      "Epoch 26::Minibatch 791::LR 0.0423076923077 --> Loss 0.00336491862933\n",
      "Epoch 26::Minibatch 792::LR 0.0423076923077 --> Loss 0.00299515783787\n",
      "Epoch 26::Minibatch 793::LR 0.0423076923077 --> Loss 0.00167757352193\n",
      "Epoch 26::Minibatch 794::LR 0.0423076923077 --> Loss 0.00098942498366\n",
      "Epoch 26::Minibatch 795::LR 0.0423076923077 --> Loss 0.00274437685808\n",
      "Epoch 26::Minibatch 796::LR 0.0423076923077 --> Loss 0.0050950674216\n",
      "Epoch 26::Minibatch 797::LR 0.0423076923077 --> Loss 0.00616982698441\n",
      "Epoch 26::Minibatch 798::LR 0.0423076923077 --> Loss 0.00308984994888\n",
      "Epoch 26::Minibatch 799::LR 0.0423076923077 --> Loss 0.00227330009143\n",
      "Epoch 26::Minibatch 800::LR 0.0423076923077 --> Loss 0.00200595140457\n",
      "Epoch 26::Minibatch 801::LR 0.0423076923077 --> Loss 0.00401155551275\n",
      "Epoch 26::Minibatch 802::LR 0.0423076923077 --> Loss 0.00123677780231\n",
      "Epoch 26::Minibatch 803::LR 0.0423076923077 --> Loss 0.00291767199834\n",
      "Epoch 26::Minibatch 804::LR 0.0423076923077 --> Loss 0.00210296928883\n",
      "Epoch 26::Minibatch 805::LR 0.0423076923077 --> Loss 0.00220693369706\n",
      "Epoch 26::Minibatch 806::LR 0.0423076923077 --> Loss 0.00339366277059\n",
      "Epoch 26::Minibatch 807::LR 0.0423076923077 --> Loss 0.00306038796902\n",
      "Epoch 26::Minibatch 808::LR 0.0423076923077 --> Loss 0.00274774372578\n",
      "Epoch 26::Minibatch 809::LR 0.0423076923077 --> Loss 0.00326981981595\n",
      "Epoch 26::Minibatch 810::LR 0.0423076923077 --> Loss 0.00449769814809\n",
      "Epoch 26::Minibatch 811::LR 0.0423076923077 --> Loss 0.0042833228906\n",
      "Epoch 26::Minibatch 812::LR 0.0423076923077 --> Loss 0.00392514308294\n",
      "Epoch 26::Minibatch 813::LR 0.0423076923077 --> Loss 0.00335920453072\n",
      "Epoch 26::Minibatch 814::LR 0.0423076923077 --> Loss 0.00157565613588\n",
      "Epoch 26::Minibatch 815::LR 0.0423076923077 --> Loss 0.00358752012253\n",
      "Epoch 26::Minibatch 816::LR 0.0423076923077 --> Loss 0.00401834368706\n",
      "Epoch 26::Minibatch 817::LR 0.0423076923077 --> Loss 0.00519872546196\n",
      "Epoch 26::Minibatch 818::LR 0.0423076923077 --> Loss 0.00124865680933\n",
      "Epoch 26::Minibatch 819::LR 0.0423076923077 --> Loss 0.000710127701362\n",
      "Epoch 26::Minibatch 820::LR 0.0423076923077 --> Loss 0.00516837199529\n",
      "Epoch 26::Minibatch 821::LR 0.0423076923077 --> Loss 0.00307018101215\n",
      "Epoch 26::Minibatch 822::LR 0.0423076923077 --> Loss 0.00365944862366\n",
      "Epoch 26::Minibatch 823::LR 0.0423076923077 --> Loss 0.00127098341783\n",
      "Epoch 26::Minibatch 824::LR 0.0423076923077 --> Loss 0.00136129210393\n",
      "Epoch 26::Minibatch 825::LR 0.0423076923077 --> Loss 0.00366732637088\n",
      "Epoch 26::Minibatch 826::LR 0.0423076923077 --> Loss 0.00417387763659\n",
      "Epoch 26::Minibatch 827::LR 0.0423076923077 --> Loss 0.002056483229\n",
      "Epoch 26::Minibatch 828::LR 0.0423076923077 --> Loss 0.000494065781434\n",
      "Epoch 26::Minibatch 829::LR 0.0423076923077 --> Loss 0.00229129652182\n",
      "Epoch 26::Minibatch 830::LR 0.0423076923077 --> Loss 0.00413034915924\n",
      "Epoch 26::Minibatch 831::LR 0.0423076923077 --> Loss 0.0024519097805\n",
      "Epoch 26::Minibatch 832::LR 0.0423076923077 --> Loss 0.00215280592442\n",
      "Epoch 26::Minibatch 833::LR 0.0423076923077 --> Loss 0.00182521680991\n",
      "Epoch 26::Minibatch 834::LR 0.0423076923077 --> Loss 0.00077994654576\n",
      "Epoch 26::Minibatch 835::LR 0.0423076923077 --> Loss 0.00375478863716\n",
      "Epoch 26::Minibatch 836::LR 0.0423076923077 --> Loss 0.00360496759415\n",
      "Epoch 26::Minibatch 837::LR 0.0423076923077 --> Loss 0.00220586180687\n",
      "Epoch 26::Minibatch 838::LR 0.0423076923077 --> Loss 0.000635152657827\n",
      "Epoch 26::Minibatch 839::LR 0.0423076923077 --> Loss 0.00241880456607\n",
      "Epoch 26::Minibatch 840::LR 0.0423076923077 --> Loss 0.00285037000974\n",
      "Epoch 26::Minibatch 841::LR 0.0423076923077 --> Loss 0.00276707450549\n",
      "Epoch 26::Minibatch 842::LR 0.0423076923077 --> Loss 0.00207973460356\n",
      "Epoch 26::Minibatch 843::LR 0.0423076923077 --> Loss 0.000986122786999\n",
      "Epoch 26::Minibatch 844::LR 0.0423076923077 --> Loss 0.00147167364756\n",
      "Epoch 26::Minibatch 845::LR 0.0423076923077 --> Loss 0.00412615140279\n",
      "Epoch 26::Minibatch 846::LR 0.0423076923077 --> Loss 0.00166484435399\n",
      "Epoch 26::Minibatch 847::LR 0.0423076923077 --> Loss 0.00231154123942\n",
      "Epoch 26::Minibatch 848::LR 0.0423076923077 --> Loss 0.00106014360984\n",
      "Epoch 26::Minibatch 849::LR 0.0423076923077 --> Loss 0.00179403463999\n",
      "Epoch 26::Minibatch 850::LR 0.0423076923077 --> Loss 0.00314683794975\n",
      "Epoch 26::Minibatch 851::LR 0.0423076923077 --> Loss 0.0025702859958\n",
      "Epoch 26::Minibatch 852::LR 0.0423076923077 --> Loss 0.00110061148802\n",
      "Epoch 26::Minibatch 853::LR 0.0423076923077 --> Loss 0.00130007177591\n",
      "Epoch 26::Minibatch 854::LR 0.0423076923077 --> Loss 0.00254292607307\n",
      "Epoch 26::Minibatch 855::LR 0.0423076923077 --> Loss 0.00212782820066\n",
      "Epoch 26::Minibatch 856::LR 0.0423076923077 --> Loss 0.00178379774094\n",
      "Epoch 26::Minibatch 857::LR 0.0423076923077 --> Loss 0.00120833218098\n",
      "Epoch 26::Minibatch 858::LR 0.0423076923077 --> Loss 0.000594548384349\n",
      "Epoch 26::Minibatch 859::LR 0.0423076923077 --> Loss 0.00193930645784\n",
      "Epoch 26::Minibatch 860::LR 0.0423076923077 --> Loss 0.00127651294072\n",
      "Epoch 26::Minibatch 861::LR 0.0423076923077 --> Loss 0.000939080019792\n",
      "Epoch 26::Minibatch 862::LR 0.0423076923077 --> Loss 0.00367342591286\n",
      "Epoch 26::Minibatch 863::LR 0.0423076923077 --> Loss 0.00337731202443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 864::LR 0.0423076923077 --> Loss 0.00268750886122\n",
      "Epoch 26::Minibatch 865::LR 0.0423076923077 --> Loss 0.000465693970521\n",
      "Epoch 26::Minibatch 866::LR 0.0423076923077 --> Loss 0.00209754546483\n",
      "Epoch 26::Minibatch 867::LR 0.0423076923077 --> Loss 0.00289864003658\n",
      "Epoch 26::Minibatch 868::LR 0.0423076923077 --> Loss 0.00240264296532\n",
      "Epoch 26::Minibatch 869::LR 0.0423076923077 --> Loss 0.00211689968904\n",
      "Epoch 26::Minibatch 870::LR 0.0423076923077 --> Loss 0.00336399356524\n",
      "Epoch 26::Minibatch 871::LR 0.0423076923077 --> Loss 0.00157430926959\n",
      "Epoch 26::Minibatch 872::LR 0.0423076923077 --> Loss 0.00218098143737\n",
      "Epoch 26::Minibatch 873::LR 0.0423076923077 --> Loss 0.00245405872663\n",
      "Epoch 26::Minibatch 874::LR 0.0423076923077 --> Loss 0.00559094349543\n",
      "Epoch 26::Minibatch 875::LR 0.0423076923077 --> Loss 0.000567522247632\n",
      "Epoch 26::Minibatch 876::LR 0.0423076923077 --> Loss 0.00288989742597\n",
      "Epoch 26::Minibatch 877::LR 0.0423076923077 --> Loss 0.00510366082191\n",
      "Epoch 26::Minibatch 878::LR 0.0423076923077 --> Loss 0.00307716667652\n",
      "Epoch 26::Minibatch 879::LR 0.0423076923077 --> Loss 0.00395284414291\n",
      "Epoch 26::Minibatch 880::LR 0.0423076923077 --> Loss 0.00483761588732\n",
      "Epoch 26::Minibatch 881::LR 0.0423076923077 --> Loss 0.00425321976344\n",
      "Epoch 26::Minibatch 882::LR 0.0423076923077 --> Loss 0.00193395853043\n",
      "Epoch 26::Minibatch 883::LR 0.0423076923077 --> Loss 0.0035241095225\n",
      "Epoch 26::Minibatch 884::LR 0.0423076923077 --> Loss 0.002749350667\n",
      "Epoch 26::Minibatch 885::LR 0.0423076923077 --> Loss 0.00256584882736\n",
      "Epoch 26::Minibatch 886::LR 0.0423076923077 --> Loss 0.000447962234418\n",
      "Epoch 26::Minibatch 887::LR 0.0423076923077 --> Loss 0.00532134413719\n",
      "Epoch 26::Minibatch 888::LR 0.0423076923077 --> Loss 0.00250885228316\n",
      "Epoch 26::Minibatch 889::LR 0.0423076923077 --> Loss 0.00260859231154\n",
      "Epoch 26::Minibatch 890::LR 0.0423076923077 --> Loss 0.00380587895711\n",
      "Epoch 26::Minibatch 891::LR 0.0423076923077 --> Loss 0.00176357607047\n",
      "Epoch 26::Minibatch 892::LR 0.0423076923077 --> Loss 0.000813464522362\n",
      "Epoch 26::Minibatch 893::LR 0.0423076923077 --> Loss 0.00232349654039\n",
      "Epoch 26::Minibatch 894::LR 0.0423076923077 --> Loss 0.00204667548339\n",
      "Epoch 26::Minibatch 895::LR 0.0423076923077 --> Loss 0.00231400668621\n",
      "Epoch 26::Minibatch 896::LR 0.0423076923077 --> Loss 0.00124006976684\n",
      "Epoch 26::Minibatch 897::LR 0.0423076923077 --> Loss 0.000682749648889\n",
      "Epoch 26::Minibatch 898::LR 0.0423076923077 --> Loss 0.00204115311305\n",
      "Epoch 26::Minibatch 899::LR 0.0423076923077 --> Loss 0.00245899657408\n",
      "Epoch 26::Minibatch 900::LR 0.0423076923077 --> Loss 0.00312658647696\n",
      "Epoch 26::Minibatch 901::LR 0.0423076923077 --> Loss 0.00058424115181\n",
      "Epoch 26::Minibatch 902::LR 0.0423076923077 --> Loss 0.00140016158422\n",
      "Epoch 26::Minibatch 903::LR 0.0423076923077 --> Loss 0.00252900818984\n",
      "Epoch 26::Minibatch 904::LR 0.0423076923077 --> Loss 0.0018319996198\n",
      "Epoch 26::Minibatch 905::LR 0.0423076923077 --> Loss 0.00140817423662\n",
      "Epoch 26::Minibatch 906::LR 0.0423076923077 --> Loss 0.00104121794303\n",
      "Epoch 26::Minibatch 907::LR 0.0423076923077 --> Loss 0.00156018167734\n",
      "Epoch 26::Minibatch 908::LR 0.0423076923077 --> Loss 0.00209685226281\n",
      "Epoch 26::Minibatch 909::LR 0.0423076923077 --> Loss 0.00194622437159\n",
      "Epoch 26::Minibatch 910::LR 0.0423076923077 --> Loss 0.000835961500804\n",
      "Epoch 26::Minibatch 911::LR 0.0423076923077 --> Loss 0.00125219712655\n",
      "Epoch 26::Minibatch 912::LR 0.0423076923077 --> Loss 0.00201478143533\n",
      "Epoch 26::Minibatch 913::LR 0.0423076923077 --> Loss 0.00220938007037\n",
      "Epoch 26::Minibatch 914::LR 0.0423076923077 --> Loss 0.00119798620542\n",
      "Epoch 26::Minibatch 915::LR 0.0423076923077 --> Loss 0.000508728871743\n",
      "Epoch 26::Minibatch 916::LR 0.0423076923077 --> Loss 0.00212812562784\n",
      "Epoch 26::Minibatch 917::LR 0.0423076923077 --> Loss 0.00347435077031\n",
      "Epoch 26::Minibatch 918::LR 0.0423076923077 --> Loss 0.00538755655289\n",
      "Epoch 26::Minibatch 919::LR 0.0423076923077 --> Loss 0.000535651892424\n",
      "Epoch 26::Minibatch 920::LR 0.0423076923077 --> Loss 0.0125155059497\n",
      "Epoch 26::Minibatch 921::LR 0.0423076923077 --> Loss 0.00287342468898\n",
      "Epoch 26::Minibatch 922::LR 0.0423076923077 --> Loss 0.00294385532538\n",
      "Epoch 26::Minibatch 923::LR 0.0423076923077 --> Loss 0.00128998726606\n",
      "Epoch 26::Minibatch 924::LR 0.0423076923077 --> Loss 0.00327021360397\n",
      "Epoch 26::Minibatch 925::LR 0.0423076923077 --> Loss 0.00221569458644\n",
      "Epoch 26::Minibatch 926::LR 0.0423076923077 --> Loss 0.00492594281832\n",
      "Epoch 26::Minibatch 927::LR 0.0423076923077 --> Loss 0.00611129959424\n",
      "Epoch 26::Minibatch 928::LR 0.0423076923077 --> Loss 0.00610161860784\n",
      "Epoch 26::Minibatch 929::LR 0.0423076923077 --> Loss 0.00581103404363\n",
      "Epoch 26::Minibatch 930::LR 0.0423076923077 --> Loss 0.00888541380564\n",
      "Epoch 26::Minibatch 931::LR 0.0423076923077 --> Loss 0.00315928339958\n",
      "Epoch 26::Minibatch 932::LR 0.0423076923077 --> Loss 0.00576590379079\n",
      "Epoch 26::Minibatch 933::LR 0.0423076923077 --> Loss 0.00273100912571\n",
      "Epoch 26::Minibatch 934::LR 0.0423076923077 --> Loss 0.00357334176699\n",
      "Epoch 26::Minibatch 935::LR 0.0423076923077 --> Loss 0.00519796530406\n",
      "Epoch 26::Minibatch 936::LR 0.0423076923077 --> Loss 0.00110966076454\n",
      "Epoch 26::Minibatch 937::LR 0.0423076923077 --> Loss 0.00271079242229\n",
      "Epoch 26::Minibatch 938::LR 0.0423076923077 --> Loss 0.00236695230007\n",
      "Epoch 26::Minibatch 939::LR 0.0423076923077 --> Loss 0.0025012131532\n",
      "Epoch 26::Minibatch 940::LR 0.0423076923077 --> Loss 0.000955512324969\n",
      "Epoch 26::Minibatch 941::LR 0.0423076923077 --> Loss 0.000783970952034\n",
      "Epoch 26::Minibatch 942::LR 0.0423076923077 --> Loss 0.00246853967508\n",
      "Epoch 26::Minibatch 943::LR 0.0423076923077 --> Loss 0.00251167714596\n",
      "Epoch 26::Minibatch 944::LR 0.0423076923077 --> Loss 0.00181851903598\n",
      "Epoch 26::Minibatch 945::LR 0.0423076923077 --> Loss 0.00104338337978\n",
      "Epoch 26::Minibatch 946::LR 0.0423076923077 --> Loss 0.00264615595341\n",
      "Epoch 26::Minibatch 947::LR 0.0423076923077 --> Loss 0.00240818878015\n",
      "Epoch 26::Minibatch 948::LR 0.0423076923077 --> Loss 0.00446268041929\n",
      "Epoch 26::Minibatch 949::LR 0.0423076923077 --> Loss 0.0017676003774\n",
      "Epoch 26::Minibatch 950::LR 0.0423076923077 --> Loss 0.000717781484127\n",
      "Epoch 26::Minibatch 951::LR 0.0423076923077 --> Loss 0.003368374904\n",
      "Epoch 26::Minibatch 952::LR 0.0423076923077 --> Loss 0.00236115177472\n",
      "Epoch 26::Minibatch 953::LR 0.0423076923077 --> Loss 0.00140129953623\n",
      "Epoch 26::Minibatch 954::LR 0.0423076923077 --> Loss 0.000950669149558\n",
      "Epoch 26::Minibatch 955::LR 0.0423076923077 --> Loss 0.00253061175346\n",
      "Epoch 26::Minibatch 956::LR 0.0423076923077 --> Loss 0.00330711940924\n",
      "Epoch 26::Minibatch 957::LR 0.0423076923077 --> Loss 0.0018300251166\n",
      "Epoch 26::Minibatch 958::LR 0.0423076923077 --> Loss 0.00219608128071\n",
      "Epoch 26::Minibatch 959::LR 0.0423076923077 --> Loss 0.00263150672118\n",
      "Epoch 26::Minibatch 960::LR 0.0423076923077 --> Loss 0.00569003740946\n",
      "Epoch 26::Minibatch 961::LR 0.0423076923077 --> Loss 0.0031158320109\n",
      "Epoch 26::Minibatch 962::LR 0.0423076923077 --> Loss 0.00257112960021\n",
      "Epoch 26::Minibatch 963::LR 0.0423076923077 --> Loss 0.001044104894\n",
      "Epoch 26::Minibatch 964::LR 0.0423076923077 --> Loss 0.00234839777152\n",
      "Epoch 26::Minibatch 965::LR 0.0423076923077 --> Loss 0.00668033679326\n",
      "Epoch 26::Minibatch 966::LR 0.0423076923077 --> Loss 0.00495114843051\n",
      "Epoch 26::Minibatch 967::LR 0.0423076923077 --> Loss 0.0013442971309\n",
      "Epoch 26::Minibatch 968::LR 0.0423076923077 --> Loss 0.00115627845128\n",
      "Epoch 26::Minibatch 969::LR 0.0423076923077 --> Loss 0.00525466958682\n",
      "Epoch 26::Minibatch 970::LR 0.0423076923077 --> Loss 0.0049970694383\n",
      "Epoch 26::Minibatch 971::LR 0.0423076923077 --> Loss 0.00338788668315\n",
      "Epoch 26::Minibatch 972::LR 0.0423076923077 --> Loss 0.00916848659515\n",
      "Epoch 26::Minibatch 973::LR 0.0423076923077 --> Loss 0.00906407992045\n",
      "Epoch 26::Minibatch 974::LR 0.0423076923077 --> Loss 0.00817029714584\n",
      "Epoch 26::Minibatch 975::LR 0.0423076923077 --> Loss 0.0043924387296\n",
      "Epoch 26::Minibatch 976::LR 0.0423076923077 --> Loss 0.00381191809972\n",
      "Epoch 26::Minibatch 977::LR 0.0423076923077 --> Loss 0.00367536862691\n",
      "Epoch 26::Minibatch 978::LR 0.0423076923077 --> Loss 0.0036334335804\n",
      "Epoch 26::Minibatch 979::LR 0.0423076923077 --> Loss 0.00347017645836\n",
      "Epoch 26::Minibatch 980::LR 0.0423076923077 --> Loss 0.00369956930478\n",
      "Epoch 26::Minibatch 981::LR 0.0423076923077 --> Loss 0.0047324458758\n",
      "Epoch 26::Minibatch 982::LR 0.0423076923077 --> Loss 0.00529053370158\n",
      "Epoch 26::Minibatch 983::LR 0.0423076923077 --> Loss 0.00274928510189\n",
      "Epoch 26::Minibatch 984::LR 0.0423076923077 --> Loss 0.00207811852296\n",
      "Epoch 26::Minibatch 985::LR 0.0423076923077 --> Loss 0.00378436406453\n",
      "Epoch 26::Minibatch 986::LR 0.0423076923077 --> Loss 0.00346367120743\n",
      "Epoch 26::Minibatch 987::LR 0.0423076923077 --> Loss 0.00374303420385\n",
      "Epoch 26::Minibatch 988::LR 0.0423076923077 --> Loss 0.00298872033755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26::Minibatch 989::LR 0.0423076923077 --> Loss 0.00320884505908\n",
      "Epoch 26::Minibatch 990::LR 0.0423076923077 --> Loss 0.00294311404228\n",
      "Epoch 26::Minibatch 991::LR 0.0423076923077 --> Loss 0.00154649893443\n",
      "Epoch 26::Minibatch 992::LR 0.0423076923077 --> Loss 0.00173677484194\n",
      "Epoch 26::Minibatch 993::LR 0.0423076923077 --> Loss 0.0032083038489\n",
      "Epoch 26::Minibatch 994::LR 0.0423076923077 --> Loss 0.00206459343433\n",
      "Epoch 26::Minibatch 995::LR 0.0423076923077 --> Loss 0.00083699186643\n",
      "Epoch 26::Minibatch 996::LR 0.0423076923077 --> Loss 0.00282942752043\n",
      "Epoch 26::Minibatch 997::LR 0.0423076923077 --> Loss 0.00221706370513\n",
      "Epoch 26::Minibatch 998::LR 0.0423076923077 --> Loss 0.00251629988352\n",
      "Epoch 26::Minibatch 999::LR 0.0423076923077 --> Loss 0.00212493081888\n",
      "Epoch 26::Minibatch 1000::LR 0.0423076923077 --> Loss 0.00252636830012\n",
      "Epoch 26::Minibatch 1001::LR 0.0423076923077 --> Loss 0.00201617101828\n",
      "Epoch 26::Minibatch 1002::LR 0.0423076923077 --> Loss 0.00181080877781\n",
      "Epoch 26::Minibatch 1003::LR 0.0423076923077 --> Loss 0.00283220926921\n",
      "Epoch 26::Minibatch 1004::LR 0.0423076923077 --> Loss 0.00106868634621\n",
      "Epoch 26::Minibatch 1005::LR 0.0423076923077 --> Loss 0.00283628066381\n",
      "Epoch 26::Minibatch 1006::LR 0.0423076923077 --> Loss 0.0015169424812\n",
      "Epoch 26::Minibatch 1007::LR 0.0423076923077 --> Loss 0.00195857067903\n",
      "Epoch 26::Minibatch 1008::LR 0.0423076923077 --> Loss 0.000936513940493\n",
      "Epoch 26::Minibatch 1009::LR 0.0423076923077 --> Loss 0.00128214627504\n",
      "Epoch 26::Minibatch 1010::LR 0.0423076923077 --> Loss 0.00116489162048\n",
      "Epoch 26::Minibatch 1011::LR 0.0423076923077 --> Loss 0.00197458386421\n",
      "Epoch 26::Minibatch 1012::LR 0.0423076923077 --> Loss 0.00145063817501\n",
      "Epoch 26::Minibatch 1013::LR 0.0423076923077 --> Loss 0.00375874241193\n",
      "Epoch 26::Minibatch 1014::LR 0.0423076923077 --> Loss 0.00352505326271\n",
      "Epoch 26::Minibatch 1015::LR 0.0423076923077 --> Loss 0.00157068441312\n",
      "Epoch 26::Minibatch 1016::LR 0.0423076923077 --> Loss 0.00464046955109\n",
      "Epoch 26::Minibatch 1017::LR 0.0423076923077 --> Loss 0.00310442070166\n",
      "Epoch 26::Minibatch 1018::LR 0.0423076923077 --> Loss 0.00264472623666\n",
      "Epoch 26::Minibatch 1019::LR 0.0423076923077 --> Loss 0.00171605110168\n",
      "Epoch 26::Minibatch 1020::LR 0.0423076923077 --> Loss 0.00179981966813\n",
      "Epoch 26::Minibatch 1021::LR 0.0423076923077 --> Loss 0.00189392348131\n",
      "Epoch 26::Minibatch 1022::LR 0.0423076923077 --> Loss 0.00141304145257\n",
      "Epoch 26::Minibatch 1023::LR 0.0423076923077 --> Loss 0.00106785744429\n",
      "Epoch 26::Minibatch 1024::LR 0.0423076923077 --> Loss 0.00105519374212\n",
      "Epoch 26::Minibatch 1025::LR 0.0423076923077 --> Loss 0.00138242344062\n",
      "Epoch 26::Minibatch 1026::LR 0.0423076923077 --> Loss 0.000738880137602\n",
      "Epoch 26::Minibatch 1027::LR 0.0423076923077 --> Loss 0.000993337333202\n",
      "Epoch 26::Minibatch 1028::LR 0.0423076923077 --> Loss 0.000755300571521\n",
      "Epoch 26::Minibatch 1029::LR 0.0423076923077 --> Loss 0.000752114752928\n",
      "Epoch 26::Minibatch 1030::LR 0.0423076923077 --> Loss 0.000926382144292\n",
      "Epoch 26::Minibatch 1031::LR 0.0423076923077 --> Loss 0.000716328918934\n",
      "Epoch 26::Minibatch 1032::LR 0.0423076923077 --> Loss 0.000779289503892\n",
      "Epoch 26::Minibatch 1033::LR 0.0423076923077 --> Loss 0.000661930441856\n",
      "Epoch 26::Minibatch 1034::LR 0.0423076923077 --> Loss 0.000632058978081\n",
      "Epoch 26::Minibatch 1035::LR 0.0423076923077 --> Loss 0.000422068983316\n",
      "Epoch 26::Minibatch 1036::LR 0.0423076923077 --> Loss 0.00033854568998\n",
      "Epoch 26::Minibatch 1037::LR 0.0423076923077 --> Loss 0.000592987289031\n",
      "Epoch 26::Minibatch 1038::LR 0.0423076923077 --> Loss 0.00116940329472\n",
      "Epoch 26::Minibatch 1039::LR 0.0423076923077 --> Loss 0.000910001198451\n",
      "Epoch 26::Minibatch 1040::LR 0.0423076923077 --> Loss 0.000362455571691\n",
      "Epoch 26::Minibatch 1041::LR 0.0423076923077 --> Loss 0.000522686044375\n",
      "Epoch 27::Minibatch 1::LR 0.04 --> Loss 0.00815674940745\n",
      "Epoch 27::Minibatch 2::LR 0.04 --> Loss 0.0049941722552\n",
      "Epoch 27::Minibatch 3::LR 0.04 --> Loss 0.00331196626027\n",
      "Epoch 27::Minibatch 4::LR 0.04 --> Loss 0.0039474372069\n",
      "Epoch 27::Minibatch 5::LR 0.04 --> Loss 0.00449024677277\n",
      "Epoch 27::Minibatch 6::LR 0.04 --> Loss 0.00217351317406\n",
      "Epoch 27::Minibatch 7::LR 0.04 --> Loss 0.00733072121938\n",
      "Epoch 27::Minibatch 8::LR 0.04 --> Loss 0.00684512058894\n",
      "Epoch 27::Minibatch 9::LR 0.04 --> Loss 0.00522879759471\n",
      "Epoch 27::Minibatch 10::LR 0.04 --> Loss 0.00248659392198\n",
      "Epoch 27::Minibatch 11::LR 0.04 --> Loss 0.00229147315025\n",
      "Epoch 27::Minibatch 12::LR 0.04 --> Loss 0.00338901321093\n",
      "Epoch 27::Minibatch 13::LR 0.04 --> Loss 0.00526456514994\n",
      "Epoch 27::Minibatch 14::LR 0.04 --> Loss 0.00526611129443\n",
      "Epoch 27::Minibatch 15::LR 0.04 --> Loss 0.00452374180158\n",
      "Epoch 27::Minibatch 16::LR 0.04 --> Loss 0.000757798204819\n",
      "Epoch 27::Minibatch 17::LR 0.04 --> Loss 0.00315005719662\n",
      "Epoch 27::Minibatch 18::LR 0.04 --> Loss 0.00259684940179\n",
      "Epoch 27::Minibatch 19::LR 0.04 --> Loss 0.00149499257406\n",
      "Epoch 27::Minibatch 20::LR 0.04 --> Loss 0.00200518608093\n",
      "Epoch 27::Minibatch 21::LR 0.04 --> Loss 0.0033312300841\n",
      "Epoch 27::Minibatch 22::LR 0.04 --> Loss 0.00223114709059\n",
      "Epoch 27::Minibatch 23::LR 0.04 --> Loss 0.000853324433168\n",
      "Epoch 27::Minibatch 24::LR 0.04 --> Loss 0.000451318522294\n",
      "Epoch 27::Minibatch 25::LR 0.04 --> Loss 0.00125158230464\n",
      "Epoch 27::Minibatch 26::LR 0.04 --> Loss 0.00145097812017\n",
      "Epoch 27::Minibatch 27::LR 0.04 --> Loss 0.00104859650135\n",
      "Epoch 27::Minibatch 28::LR 0.04 --> Loss 0.000455956608057\n",
      "Epoch 27::Minibatch 29::LR 0.04 --> Loss 0.000516494860252\n",
      "Epoch 27::Minibatch 30::LR 0.04 --> Loss 0.000996307730675\n",
      "Epoch 27::Minibatch 31::LR 0.04 --> Loss 0.00148509442806\n",
      "Epoch 27::Minibatch 32::LR 0.04 --> Loss 0.00133537987868\n",
      "Epoch 27::Minibatch 33::LR 0.04 --> Loss 0.000790357540051\n",
      "Epoch 27::Minibatch 34::LR 0.04 --> Loss 0.00208360572656\n",
      "Epoch 27::Minibatch 35::LR 0.04 --> Loss 0.00332839449247\n",
      "Epoch 27::Minibatch 36::LR 0.04 --> Loss 0.00227478126685\n",
      "Epoch 27::Minibatch 37::LR 0.04 --> Loss 0.000684568236272\n",
      "Epoch 27::Minibatch 38::LR 0.04 --> Loss 0.000720004886389\n",
      "Epoch 27::Minibatch 39::LR 0.04 --> Loss 0.00222271740437\n",
      "Epoch 27::Minibatch 40::LR 0.04 --> Loss 0.00313973327478\n",
      "Epoch 27::Minibatch 41::LR 0.04 --> Loss 0.00252242088318\n",
      "Epoch 27::Minibatch 42::LR 0.04 --> Loss 0.00506664474805\n",
      "Epoch 27::Minibatch 43::LR 0.04 --> Loss 0.001953424414\n",
      "Epoch 27::Minibatch 44::LR 0.04 --> Loss 0.00318945229053\n",
      "Epoch 27::Minibatch 45::LR 0.04 --> Loss 0.00239078680674\n",
      "Epoch 27::Minibatch 46::LR 0.04 --> Loss 0.00315711696943\n",
      "Epoch 27::Minibatch 47::LR 0.04 --> Loss 0.00363338112831\n",
      "Epoch 27::Minibatch 48::LR 0.04 --> Loss 0.00516733765602\n",
      "Epoch 27::Minibatch 49::LR 0.04 --> Loss 0.00573485533396\n",
      "Epoch 27::Minibatch 50::LR 0.04 --> Loss 0.00605576117833\n",
      "Epoch 27::Minibatch 51::LR 0.04 --> Loss 0.00496742169062\n",
      "Epoch 27::Minibatch 52::LR 0.04 --> Loss 0.00343460202217\n",
      "Epoch 27::Minibatch 53::LR 0.04 --> Loss 0.0033863222599\n",
      "Epoch 27::Minibatch 54::LR 0.04 --> Loss 0.00400413195292\n",
      "Epoch 27::Minibatch 55::LR 0.04 --> Loss 0.000988980134328\n",
      "Epoch 27::Minibatch 56::LR 0.04 --> Loss 0.00271170675755\n",
      "Epoch 27::Minibatch 57::LR 0.04 --> Loss 0.00483933766683\n",
      "Epoch 27::Minibatch 58::LR 0.04 --> Loss 0.00323579529921\n",
      "Epoch 27::Minibatch 59::LR 0.04 --> Loss 0.00242845952511\n",
      "Epoch 27::Minibatch 60::LR 0.04 --> Loss 0.00243559062481\n",
      "Epoch 27::Minibatch 61::LR 0.04 --> Loss 0.000754554023345\n",
      "Epoch 27::Minibatch 62::LR 0.04 --> Loss 0.00267439981302\n",
      "Epoch 27::Minibatch 63::LR 0.04 --> Loss 0.00201222380002\n",
      "Epoch 27::Minibatch 64::LR 0.04 --> Loss 0.000836621820927\n",
      "Epoch 27::Minibatch 65::LR 0.04 --> Loss 0.00219298581282\n",
      "Epoch 27::Minibatch 66::LR 0.04 --> Loss 0.00272275348504\n",
      "Epoch 27::Minibatch 67::LR 0.04 --> Loss 0.00258447229862\n",
      "Epoch 27::Minibatch 68::LR 0.04 --> Loss 0.00186625460784\n",
      "Epoch 27::Minibatch 69::LR 0.04 --> Loss 0.00371183872223\n",
      "Epoch 27::Minibatch 70::LR 0.04 --> Loss 0.00326627274354\n",
      "Epoch 27::Minibatch 71::LR 0.04 --> Loss 0.00226169705391\n",
      "Epoch 27::Minibatch 72::LR 0.04 --> Loss 0.000543318490187\n",
      "Epoch 27::Minibatch 73::LR 0.04 --> Loss 0.00375270009041\n",
      "Epoch 27::Minibatch 74::LR 0.04 --> Loss 0.00403307199478\n",
      "Epoch 27::Minibatch 75::LR 0.04 --> Loss 0.00218058248361\n",
      "Epoch 27::Minibatch 76::LR 0.04 --> Loss 0.000530406534672\n",
      "Epoch 27::Minibatch 77::LR 0.04 --> Loss 0.00343656142553\n",
      "Epoch 27::Minibatch 78::LR 0.04 --> Loss 0.00387619018555\n",
      "Epoch 27::Minibatch 79::LR 0.04 --> Loss 0.00177785297235\n",
      "Epoch 27::Minibatch 80::LR 0.04 --> Loss 0.00294588069121\n",
      "Epoch 27::Minibatch 81::LR 0.04 --> Loss 0.00258528530598\n",
      "Epoch 27::Minibatch 82::LR 0.04 --> Loss 0.00188650349776\n",
      "Epoch 27::Minibatch 83::LR 0.04 --> Loss 0.00407354195913\n",
      "Epoch 27::Minibatch 84::LR 0.04 --> Loss 0.00189389546712\n",
      "Epoch 27::Minibatch 85::LR 0.04 --> Loss 0.00259666879972\n",
      "Epoch 27::Minibatch 86::LR 0.04 --> Loss 0.00211880147457\n",
      "Epoch 27::Minibatch 87::LR 0.04 --> Loss 0.00227762182554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 88::LR 0.04 --> Loss 0.00169447859128\n",
      "Epoch 27::Minibatch 89::LR 0.04 --> Loss 0.00222485423088\n",
      "Epoch 27::Minibatch 90::LR 0.04 --> Loss 0.00105261435111\n",
      "Epoch 27::Minibatch 91::LR 0.04 --> Loss 0.000867048700651\n",
      "Epoch 27::Minibatch 92::LR 0.04 --> Loss 0.00259201089541\n",
      "Epoch 27::Minibatch 93::LR 0.04 --> Loss 0.00171212673187\n",
      "Epoch 27::Minibatch 94::LR 0.04 --> Loss 0.00173980534077\n",
      "Epoch 27::Minibatch 95::LR 0.04 --> Loss 0.00187248071035\n",
      "Epoch 27::Minibatch 96::LR 0.04 --> Loss 0.00505930741628\n",
      "Epoch 27::Minibatch 97::LR 0.04 --> Loss 0.00305007537206\n",
      "Epoch 27::Minibatch 98::LR 0.04 --> Loss 0.00104641844829\n",
      "Epoch 27::Minibatch 99::LR 0.04 --> Loss 0.00136882215738\n",
      "Epoch 27::Minibatch 100::LR 0.04 --> Loss 0.00448269486427\n",
      "Epoch 27::Minibatch 101::LR 0.04 --> Loss 0.000901815692584\n",
      "Epoch 27::Minibatch 102::LR 0.04 --> Loss 0.00388471921285\n",
      "Epoch 27::Minibatch 103::LR 0.04 --> Loss 0.00393741885821\n",
      "Epoch 27::Minibatch 104::LR 0.04 --> Loss 0.00268424510956\n",
      "Epoch 27::Minibatch 105::LR 0.04 --> Loss 0.00224693417549\n",
      "Epoch 27::Minibatch 106::LR 0.04 --> Loss 0.0150347598394\n",
      "Epoch 27::Minibatch 107::LR 0.04 --> Loss 0.00479557553927\n",
      "Epoch 27::Minibatch 108::LR 0.04 --> Loss 0.000955796142419\n",
      "Epoch 27::Minibatch 109::LR 0.04 --> Loss 0.0042967514197\n",
      "Epoch 27::Minibatch 110::LR 0.04 --> Loss 0.00224623938402\n",
      "Epoch 27::Minibatch 111::LR 0.04 --> Loss 0.000846213102341\n",
      "Epoch 27::Minibatch 112::LR 0.04 --> Loss 0.00333732128143\n",
      "Epoch 27::Minibatch 113::LR 0.04 --> Loss 0.00244804382324\n",
      "Epoch 27::Minibatch 114::LR 0.04 --> Loss 0.00136266102393\n",
      "Epoch 27::Minibatch 115::LR 0.04 --> Loss 0.00118318498135\n",
      "Epoch 27::Minibatch 116::LR 0.04 --> Loss 0.00264512081941\n",
      "Epoch 27::Minibatch 117::LR 0.04 --> Loss 0.00397362629573\n",
      "Epoch 27::Minibatch 118::LR 0.04 --> Loss 0.00666277289391\n",
      "Epoch 27::Minibatch 119::LR 0.04 --> Loss 0.000534775058428\n",
      "Epoch 27::Minibatch 120::LR 0.04 --> Loss 0.00164197136958\n",
      "Epoch 27::Minibatch 121::LR 0.04 --> Loss 0.00242804070314\n",
      "Epoch 27::Minibatch 122::LR 0.04 --> Loss 0.0037716126442\n",
      "Epoch 27::Minibatch 123::LR 0.04 --> Loss 0.000770222147306\n",
      "Epoch 27::Minibatch 124::LR 0.04 --> Loss 0.00262080947558\n",
      "Epoch 27::Minibatch 125::LR 0.04 --> Loss 0.00446159362793\n",
      "Epoch 27::Minibatch 126::LR 0.04 --> Loss 0.00252701659997\n",
      "Epoch 27::Minibatch 127::LR 0.04 --> Loss 0.00463536103566\n",
      "Epoch 27::Minibatch 128::LR 0.04 --> Loss 0.0035407269001\n",
      "Epoch 27::Minibatch 129::LR 0.04 --> Loss 0.0024903768301\n",
      "Epoch 27::Minibatch 130::LR 0.04 --> Loss 0.00432703057925\n",
      "Epoch 27::Minibatch 131::LR 0.04 --> Loss 0.00173209547997\n",
      "Epoch 27::Minibatch 132::LR 0.04 --> Loss 0.00290048221747\n",
      "Epoch 27::Minibatch 133::LR 0.04 --> Loss 0.0027728788058\n",
      "Epoch 27::Minibatch 134::LR 0.04 --> Loss 0.00218185106913\n",
      "Epoch 27::Minibatch 135::LR 0.04 --> Loss 0.00136957496405\n",
      "Epoch 27::Minibatch 136::LR 0.04 --> Loss 0.00251746535301\n",
      "Epoch 27::Minibatch 137::LR 0.04 --> Loss 0.00348408381144\n",
      "Epoch 27::Minibatch 138::LR 0.04 --> Loss 0.0012422867616\n",
      "Epoch 27::Minibatch 139::LR 0.04 --> Loss 0.00188947995504\n",
      "Epoch 27::Minibatch 140::LR 0.04 --> Loss 0.00241444091002\n",
      "Epoch 27::Minibatch 141::LR 0.04 --> Loss 0.00292164107164\n",
      "Epoch 27::Minibatch 142::LR 0.04 --> Loss 0.00272953550021\n",
      "Epoch 27::Minibatch 143::LR 0.04 --> Loss 0.000560505886873\n",
      "Epoch 27::Minibatch 144::LR 0.04 --> Loss 0.0033111590147\n",
      "Epoch 27::Minibatch 145::LR 0.04 --> Loss 0.00417870402336\n",
      "Epoch 27::Minibatch 146::LR 0.04 --> Loss 0.00251927713553\n",
      "Epoch 27::Minibatch 147::LR 0.04 --> Loss 0.00179367641608\n",
      "Epoch 27::Minibatch 148::LR 0.04 --> Loss 0.000985904534658\n",
      "Epoch 27::Minibatch 149::LR 0.04 --> Loss 0.00284409880638\n",
      "Epoch 27::Minibatch 150::LR 0.04 --> Loss 0.00267718553543\n",
      "Epoch 27::Minibatch 151::LR 0.04 --> Loss 0.00425996144613\n",
      "Epoch 27::Minibatch 152::LR 0.04 --> Loss 0.000908553103606\n",
      "Epoch 27::Minibatch 153::LR 0.04 --> Loss 0.00169806023439\n",
      "Epoch 27::Minibatch 154::LR 0.04 --> Loss 0.0020259787639\n",
      "Epoch 27::Minibatch 155::LR 0.04 --> Loss 0.00419014453888\n",
      "Epoch 27::Minibatch 156::LR 0.04 --> Loss 0.00236458917459\n",
      "Epoch 27::Minibatch 157::LR 0.04 --> Loss 0.00069147820274\n",
      "Epoch 27::Minibatch 158::LR 0.04 --> Loss 0.00311817208926\n",
      "Epoch 27::Minibatch 159::LR 0.04 --> Loss 0.00273183107376\n",
      "Epoch 27::Minibatch 160::LR 0.04 --> Loss 0.00263492087523\n",
      "Epoch 27::Minibatch 161::LR 0.04 --> Loss 0.00100848317146\n",
      "Epoch 27::Minibatch 162::LR 0.04 --> Loss 0.00386931379636\n",
      "Epoch 27::Minibatch 163::LR 0.04 --> Loss 0.00239235043526\n",
      "Epoch 27::Minibatch 164::LR 0.04 --> Loss 0.00251144746939\n",
      "Epoch 27::Minibatch 165::LR 0.04 --> Loss 0.000509443382422\n",
      "Epoch 27::Minibatch 166::LR 0.04 --> Loss 0.00173473695914\n",
      "Epoch 27::Minibatch 167::LR 0.04 --> Loss 0.00246411482493\n",
      "Epoch 27::Minibatch 168::LR 0.04 --> Loss 0.00215478003025\n",
      "Epoch 27::Minibatch 169::LR 0.04 --> Loss 0.00100025832653\n",
      "Epoch 27::Minibatch 170::LR 0.04 --> Loss 0.000968665083249\n",
      "Epoch 27::Minibatch 171::LR 0.04 --> Loss 0.00249979178111\n",
      "Epoch 27::Minibatch 172::LR 0.04 --> Loss 0.00427676916122\n",
      "Epoch 27::Minibatch 173::LR 0.04 --> Loss 0.00196465710799\n",
      "Epoch 27::Minibatch 174::LR 0.04 --> Loss 0.000989182988803\n",
      "Epoch 27::Minibatch 175::LR 0.04 --> Loss 0.00233087201913\n",
      "Epoch 27::Minibatch 176::LR 0.04 --> Loss 0.00317220846812\n",
      "Epoch 27::Minibatch 177::LR 0.04 --> Loss 0.00436817963918\n",
      "Epoch 27::Minibatch 178::LR 0.04 --> Loss 0.00155330657959\n",
      "Epoch 27::Minibatch 179::LR 0.04 --> Loss 0.00126225004594\n",
      "Epoch 27::Minibatch 180::LR 0.04 --> Loss 0.00346366763115\n",
      "Epoch 27::Minibatch 181::LR 0.04 --> Loss 0.00312657992045\n",
      "Epoch 27::Minibatch 182::LR 0.04 --> Loss 0.000731739997864\n",
      "Epoch 27::Minibatch 183::LR 0.04 --> Loss 0.00161207636197\n",
      "Epoch 27::Minibatch 184::LR 0.04 --> Loss 0.00342285474141\n",
      "Epoch 27::Minibatch 185::LR 0.04 --> Loss 0.00274315237999\n",
      "Epoch 27::Minibatch 186::LR 0.04 --> Loss 0.000949161251386\n",
      "Epoch 27::Minibatch 187::LR 0.04 --> Loss 0.00127668499947\n",
      "Epoch 27::Minibatch 188::LR 0.04 --> Loss 0.00411736885707\n",
      "Epoch 27::Minibatch 189::LR 0.04 --> Loss 0.00424199064573\n",
      "Epoch 27::Minibatch 190::LR 0.04 --> Loss 0.00232395311197\n",
      "Epoch 27::Minibatch 191::LR 0.04 --> Loss 0.000460570454597\n",
      "Epoch 27::Minibatch 192::LR 0.04 --> Loss 0.00275458931923\n",
      "Epoch 27::Minibatch 193::LR 0.04 --> Loss 0.00264458258947\n",
      "Epoch 27::Minibatch 194::LR 0.04 --> Loss 0.00175685385863\n",
      "Epoch 27::Minibatch 195::LR 0.04 --> Loss 0.000379005620877\n",
      "Epoch 27::Minibatch 196::LR 0.04 --> Loss 0.00130254109701\n",
      "Epoch 27::Minibatch 197::LR 0.04 --> Loss 0.00292652606964\n",
      "Epoch 27::Minibatch 198::LR 0.04 --> Loss 0.00226743857066\n",
      "Epoch 27::Minibatch 199::LR 0.04 --> Loss 0.000288735727469\n",
      "Epoch 27::Minibatch 200::LR 0.04 --> Loss 0.00204356213411\n",
      "Epoch 27::Minibatch 201::LR 0.04 --> Loss 0.00193817893664\n",
      "Epoch 27::Minibatch 202::LR 0.04 --> Loss 0.00183473050594\n",
      "Epoch 27::Minibatch 203::LR 0.04 --> Loss 0.00174907505512\n",
      "Epoch 27::Minibatch 204::LR 0.04 --> Loss 0.00142348190149\n",
      "Epoch 27::Minibatch 205::LR 0.04 --> Loss 0.00220203320185\n",
      "Epoch 27::Minibatch 206::LR 0.04 --> Loss 0.00585421880086\n",
      "Epoch 27::Minibatch 207::LR 0.04 --> Loss 0.00139713803927\n",
      "Epoch 27::Minibatch 208::LR 0.04 --> Loss 0.00111001312733\n",
      "Epoch 27::Minibatch 209::LR 0.04 --> Loss 0.00237295885881\n",
      "Epoch 27::Minibatch 210::LR 0.04 --> Loss 0.00225228806337\n",
      "Epoch 27::Minibatch 211::LR 0.04 --> Loss 0.00251881062984\n",
      "Epoch 27::Minibatch 212::LR 0.04 --> Loss 0.00383815685908\n",
      "Epoch 27::Minibatch 213::LR 0.04 --> Loss 0.00555694619815\n",
      "Epoch 27::Minibatch 214::LR 0.04 --> Loss 0.00787170330683\n",
      "Epoch 27::Minibatch 215::LR 0.04 --> Loss 0.00136191040277\n",
      "Epoch 27::Minibatch 216::LR 0.04 --> Loss 0.0053690858682\n",
      "Epoch 27::Minibatch 217::LR 0.04 --> Loss 0.00597748557727\n",
      "Epoch 27::Minibatch 218::LR 0.04 --> Loss 0.00390670895576\n",
      "Epoch 27::Minibatch 219::LR 0.04 --> Loss 0.00431037743886\n",
      "Epoch 27::Minibatch 220::LR 0.04 --> Loss 0.00440429766973\n",
      "Epoch 27::Minibatch 221::LR 0.04 --> Loss 0.00423785845439\n",
      "Epoch 27::Minibatch 222::LR 0.04 --> Loss 0.00318848073483\n",
      "Epoch 27::Minibatch 223::LR 0.04 --> Loss 0.00139409720898\n",
      "Epoch 27::Minibatch 224::LR 0.04 --> Loss 0.00164679030577\n",
      "Epoch 27::Minibatch 225::LR 0.04 --> Loss 0.00759544452031\n",
      "Epoch 27::Minibatch 226::LR 0.04 --> Loss 0.00371336658796\n",
      "Epoch 27::Minibatch 227::LR 0.04 --> Loss 0.0016812290748\n",
      "Epoch 27::Minibatch 228::LR 0.04 --> Loss 0.000683019608259\n",
      "Epoch 27::Minibatch 229::LR 0.04 --> Loss 0.00471725821495\n",
      "Epoch 27::Minibatch 230::LR 0.04 --> Loss 0.00378425399462\n",
      "Epoch 27::Minibatch 231::LR 0.04 --> Loss 0.00265557944775\n",
      "Epoch 27::Minibatch 232::LR 0.04 --> Loss 0.00118055820465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 233::LR 0.04 --> Loss 0.00244620025158\n",
      "Epoch 27::Minibatch 234::LR 0.04 --> Loss 0.00716664155324\n",
      "Epoch 27::Minibatch 235::LR 0.04 --> Loss 0.00458236018817\n",
      "Epoch 27::Minibatch 236::LR 0.04 --> Loss 0.00170633455118\n",
      "Epoch 27::Minibatch 237::LR 0.04 --> Loss 0.000624175071716\n",
      "Epoch 27::Minibatch 238::LR 0.04 --> Loss 0.00341644962629\n",
      "Epoch 27::Minibatch 239::LR 0.04 --> Loss 0.00295817176501\n",
      "Epoch 27::Minibatch 240::LR 0.04 --> Loss 0.00324015617371\n",
      "Epoch 27::Minibatch 241::LR 0.04 --> Loss 0.000747036635876\n",
      "Epoch 27::Minibatch 242::LR 0.04 --> Loss 0.0068256409963\n",
      "Epoch 27::Minibatch 243::LR 0.04 --> Loss 0.00335272510846\n",
      "Epoch 27::Minibatch 244::LR 0.04 --> Loss 0.00281263033549\n",
      "Epoch 27::Minibatch 245::LR 0.04 --> Loss 0.000446977217992\n",
      "Epoch 27::Minibatch 246::LR 0.04 --> Loss 0.00197010219097\n",
      "Epoch 27::Minibatch 247::LR 0.04 --> Loss 0.011459209919\n",
      "Epoch 27::Minibatch 248::LR 0.04 --> Loss 0.00438746889432\n",
      "Epoch 27::Minibatch 249::LR 0.04 --> Loss 0.00250503102938\n",
      "Epoch 27::Minibatch 250::LR 0.04 --> Loss 0.00241525689761\n",
      "Epoch 27::Minibatch 251::LR 0.04 --> Loss 0.00238959471385\n",
      "Epoch 27::Minibatch 252::LR 0.04 --> Loss 0.00166998445988\n",
      "Epoch 27::Minibatch 253::LR 0.04 --> Loss 0.00290762821833\n",
      "Epoch 27::Minibatch 254::LR 0.04 --> Loss 0.00493736505508\n",
      "Epoch 27::Minibatch 255::LR 0.04 --> Loss 0.00382022778193\n",
      "Epoch 27::Minibatch 256::LR 0.04 --> Loss 0.0014848981301\n",
      "Epoch 27::Minibatch 257::LR 0.04 --> Loss 0.00116451034943\n",
      "Epoch 27::Minibatch 258::LR 0.04 --> Loss 0.0036398212115\n",
      "Epoch 27::Minibatch 259::LR 0.04 --> Loss 0.0016664019227\n",
      "Epoch 27::Minibatch 260::LR 0.04 --> Loss 0.00185593048731\n",
      "Epoch 27::Minibatch 261::LR 0.04 --> Loss 0.00271802862485\n",
      "Epoch 27::Minibatch 262::LR 0.04 --> Loss 0.00185251494249\n",
      "Epoch 27::Minibatch 263::LR 0.04 --> Loss 0.00231839557489\n",
      "Epoch 27::Minibatch 264::LR 0.04 --> Loss 0.00358494997025\n",
      "Epoch 27::Minibatch 265::LR 0.04 --> Loss 0.0099772588412\n",
      "Epoch 27::Minibatch 266::LR 0.04 --> Loss 0.000933955609798\n",
      "Epoch 27::Minibatch 267::LR 0.04 --> Loss 0.00942570765813\n",
      "Epoch 27::Minibatch 268::LR 0.04 --> Loss 0.0010922908783\n",
      "Epoch 27::Minibatch 269::LR 0.04 --> Loss 0.00348874568939\n",
      "Epoch 27::Minibatch 270::LR 0.04 --> Loss 0.00702609141668\n",
      "Epoch 27::Minibatch 271::LR 0.04 --> Loss 0.002531589667\n",
      "Epoch 27::Minibatch 272::LR 0.04 --> Loss 0.00430467367172\n",
      "Epoch 27::Minibatch 273::LR 0.04 --> Loss 0.00148956269026\n",
      "Epoch 27::Minibatch 274::LR 0.04 --> Loss 0.0017812526226\n",
      "Epoch 27::Minibatch 275::LR 0.04 --> Loss 0.00253586312135\n",
      "Epoch 27::Minibatch 276::LR 0.04 --> Loss 0.0034016986688\n",
      "Epoch 27::Minibatch 277::LR 0.04 --> Loss 0.000918960769971\n",
      "Epoch 27::Minibatch 278::LR 0.04 --> Loss 0.0025784522295\n",
      "Epoch 27::Minibatch 279::LR 0.04 --> Loss 0.0021453589201\n",
      "Epoch 27::Minibatch 280::LR 0.04 --> Loss 0.00188601076603\n",
      "Epoch 27::Minibatch 281::LR 0.04 --> Loss 0.00119482984145\n",
      "Epoch 27::Minibatch 282::LR 0.04 --> Loss 0.00210501968861\n",
      "Epoch 27::Minibatch 283::LR 0.04 --> Loss 0.00202381372452\n",
      "Epoch 27::Minibatch 284::LR 0.04 --> Loss 0.00163866102695\n",
      "Epoch 27::Minibatch 285::LR 0.04 --> Loss 0.00116634170214\n",
      "Epoch 27::Minibatch 286::LR 0.04 --> Loss 0.00203934093316\n",
      "Epoch 27::Minibatch 287::LR 0.04 --> Loss 0.0020035280784\n",
      "Epoch 27::Minibatch 288::LR 0.04 --> Loss 0.00108819554249\n",
      "Epoch 27::Minibatch 289::LR 0.04 --> Loss 0.00158917983373\n",
      "Epoch 27::Minibatch 290::LR 0.04 --> Loss 0.00189500967662\n",
      "Epoch 27::Minibatch 291::LR 0.04 --> Loss 0.00169548730055\n",
      "Epoch 27::Minibatch 292::LR 0.04 --> Loss 0.000597977985938\n",
      "Epoch 27::Minibatch 293::LR 0.04 --> Loss 0.00150363544623\n",
      "Epoch 27::Minibatch 294::LR 0.04 --> Loss 0.00160409162442\n",
      "Epoch 27::Minibatch 295::LR 0.04 --> Loss 0.00188458065192\n",
      "Epoch 27::Minibatch 296::LR 0.04 --> Loss 0.00163357595603\n",
      "Epoch 27::Minibatch 297::LR 0.04 --> Loss 0.00142214864492\n",
      "Epoch 27::Minibatch 298::LR 0.04 --> Loss 0.00141941577196\n",
      "Epoch 27::Minibatch 299::LR 0.04 --> Loss 0.000811700423559\n",
      "Epoch 27::Minibatch 300::LR 0.04 --> Loss 0.00273060202599\n",
      "Epoch 27::Minibatch 301::LR 0.04 --> Loss 0.00264190057913\n",
      "Epoch 27::Minibatch 302::LR 0.04 --> Loss 0.00242056369781\n",
      "Epoch 27::Minibatch 303::LR 0.04 --> Loss 0.00084459900856\n",
      "Epoch 27::Minibatch 304::LR 0.04 --> Loss 0.00299769659837\n",
      "Epoch 27::Minibatch 305::LR 0.04 --> Loss 0.00170815209548\n",
      "Epoch 27::Minibatch 306::LR 0.04 --> Loss 0.000939710239569\n",
      "Epoch 27::Minibatch 307::LR 0.04 --> Loss 0.00242078383764\n",
      "Epoch 27::Minibatch 308::LR 0.04 --> Loss 0.00201874713103\n",
      "Epoch 27::Minibatch 309::LR 0.04 --> Loss 0.00103432406982\n",
      "Epoch 27::Minibatch 310::LR 0.04 --> Loss 0.00117663731178\n",
      "Epoch 27::Minibatch 311::LR 0.04 --> Loss 0.00177983860175\n",
      "Epoch 27::Minibatch 312::LR 0.04 --> Loss 0.00287826399008\n",
      "Epoch 27::Minibatch 313::LR 0.04 --> Loss 0.00236048618952\n",
      "Epoch 27::Minibatch 314::LR 0.04 --> Loss 0.00192310333252\n",
      "Epoch 27::Minibatch 315::LR 0.04 --> Loss 0.00103495836258\n",
      "Epoch 27::Minibatch 316::LR 0.04 --> Loss 0.00234075228373\n",
      "Epoch 27::Minibatch 317::LR 0.04 --> Loss 0.00155954798063\n",
      "Epoch 27::Minibatch 318::LR 0.04 --> Loss 0.00128660827875\n",
      "Epoch 27::Minibatch 319::LR 0.04 --> Loss 0.00230590422948\n",
      "Epoch 27::Minibatch 320::LR 0.04 --> Loss 0.00308502773444\n",
      "Epoch 27::Minibatch 321::LR 0.04 --> Loss 0.000841307540735\n",
      "Epoch 27::Minibatch 322::LR 0.04 --> Loss 0.00352717717489\n",
      "Epoch 27::Minibatch 323::LR 0.04 --> Loss 0.00344966173172\n",
      "Epoch 27::Minibatch 324::LR 0.04 --> Loss 0.00264499167601\n",
      "Epoch 27::Minibatch 325::LR 0.04 --> Loss 0.00237838168939\n",
      "Epoch 27::Minibatch 326::LR 0.04 --> Loss 0.00537821729978\n",
      "Epoch 27::Minibatch 327::LR 0.04 --> Loss 0.00224210222562\n",
      "Epoch 27::Minibatch 328::LR 0.04 --> Loss 0.00304715851943\n",
      "Epoch 27::Minibatch 329::LR 0.04 --> Loss 0.00120086054007\n",
      "Epoch 27::Minibatch 330::LR 0.04 --> Loss 0.00159078220526\n",
      "Epoch 27::Minibatch 331::LR 0.04 --> Loss 0.00253462831179\n",
      "Epoch 27::Minibatch 332::LR 0.04 --> Loss 0.00247129122416\n",
      "Epoch 27::Minibatch 333::LR 0.04 --> Loss 0.00146012753248\n",
      "Epoch 27::Minibatch 334::LR 0.04 --> Loss 0.00442000627518\n",
      "Epoch 27::Minibatch 335::LR 0.04 --> Loss 0.00189281702042\n",
      "Epoch 27::Minibatch 336::LR 0.04 --> Loss 0.00223424136639\n",
      "Epoch 27::Minibatch 337::LR 0.04 --> Loss 0.00364178737005\n",
      "Epoch 27::Minibatch 338::LR 0.04 --> Loss 0.00054429491361\n",
      "Epoch 27::Minibatch 339::LR 0.04 --> Loss 0.00328017572562\n",
      "Epoch 27::Minibatch 340::LR 0.04 --> Loss 0.00378467400869\n",
      "Epoch 27::Minibatch 341::LR 0.04 --> Loss 0.00445898691813\n",
      "Epoch 27::Minibatch 342::LR 0.04 --> Loss 0.00307350695133\n",
      "Epoch 27::Minibatch 343::LR 0.04 --> Loss 0.00164558877548\n",
      "Epoch 27::Minibatch 344::LR 0.04 --> Loss 0.00315796335538\n",
      "Epoch 27::Minibatch 345::LR 0.04 --> Loss 0.00414321780205\n",
      "Epoch 27::Minibatch 346::LR 0.04 --> Loss 0.00547694842021\n",
      "Epoch 27::Minibatch 347::LR 0.04 --> Loss 0.00082075342536\n",
      "Epoch 27::Minibatch 348::LR 0.04 --> Loss 0.00312053143978\n",
      "Epoch 27::Minibatch 349::LR 0.04 --> Loss 0.00341649095217\n",
      "Epoch 27::Minibatch 350::LR 0.04 --> Loss 0.00167032003403\n",
      "Epoch 27::Minibatch 351::LR 0.04 --> Loss 0.0034493748347\n",
      "Epoch 27::Minibatch 352::LR 0.04 --> Loss 0.00492634177208\n",
      "Epoch 27::Minibatch 353::LR 0.04 --> Loss 0.00352335015933\n",
      "Epoch 27::Minibatch 354::LR 0.04 --> Loss 0.00294416666031\n",
      "Epoch 27::Minibatch 355::LR 0.04 --> Loss 0.00620091080666\n",
      "Epoch 27::Minibatch 356::LR 0.04 --> Loss 0.00313663224379\n",
      "Epoch 27::Minibatch 357::LR 0.04 --> Loss 0.00114498029153\n",
      "Epoch 27::Minibatch 358::LR 0.04 --> Loss 0.00200460533301\n",
      "Epoch 27::Minibatch 359::LR 0.04 --> Loss 0.00268843670686\n",
      "Epoch 27::Minibatch 360::LR 0.04 --> Loss 0.00233837962151\n",
      "Epoch 27::Minibatch 361::LR 0.04 --> Loss 0.00231474975745\n",
      "Epoch 27::Minibatch 362::LR 0.04 --> Loss 0.00229472001394\n",
      "Epoch 27::Minibatch 363::LR 0.04 --> Loss 0.0006418227156\n",
      "Epoch 27::Minibatch 364::LR 0.04 --> Loss 0.0019800110658\n",
      "Epoch 27::Minibatch 365::LR 0.04 --> Loss 0.00203191856543\n",
      "Epoch 27::Minibatch 366::LR 0.04 --> Loss 0.00215767840544\n",
      "Epoch 27::Minibatch 367::LR 0.04 --> Loss 0.00102115700642\n",
      "Epoch 27::Minibatch 368::LR 0.04 --> Loss 0.000974896152814\n",
      "Epoch 27::Minibatch 369::LR 0.04 --> Loss 0.00280502756437\n",
      "Epoch 27::Minibatch 370::LR 0.04 --> Loss 0.00222958823045\n",
      "Epoch 27::Minibatch 371::LR 0.04 --> Loss 0.00185934881369\n",
      "Epoch 27::Minibatch 372::LR 0.04 --> Loss 0.000429481267929\n",
      "Epoch 27::Minibatch 373::LR 0.04 --> Loss 0.0017945476373\n",
      "Epoch 27::Minibatch 374::LR 0.04 --> Loss 0.00223531723022\n",
      "Epoch 27::Minibatch 375::LR 0.04 --> Loss 0.00187112510204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 376::LR 0.04 --> Loss 0.00122120549281\n",
      "Epoch 27::Minibatch 377::LR 0.04 --> Loss 0.00191931764285\n",
      "Epoch 27::Minibatch 378::LR 0.04 --> Loss 0.00210571030776\n",
      "Epoch 27::Minibatch 379::LR 0.04 --> Loss 0.00233934760094\n",
      "Epoch 27::Minibatch 380::LR 0.04 --> Loss 0.00157185504834\n",
      "Epoch 27::Minibatch 381::LR 0.04 --> Loss 0.000988148947557\n",
      "Epoch 27::Minibatch 382::LR 0.04 --> Loss 0.00202495435874\n",
      "Epoch 27::Minibatch 383::LR 0.04 --> Loss 0.00197723726432\n",
      "Epoch 27::Minibatch 384::LR 0.04 --> Loss 0.00109266360601\n",
      "Epoch 27::Minibatch 385::LR 0.04 --> Loss 0.00104748060306\n",
      "Epoch 27::Minibatch 386::LR 0.04 --> Loss 0.0022166877985\n",
      "Epoch 27::Minibatch 387::LR 0.04 --> Loss 0.00235641856988\n",
      "Epoch 27::Minibatch 388::LR 0.04 --> Loss 0.00119111279647\n",
      "Epoch 27::Minibatch 389::LR 0.04 --> Loss 0.00178537388643\n",
      "Epoch 27::Minibatch 390::LR 0.04 --> Loss 0.00335097312927\n",
      "Epoch 27::Minibatch 391::LR 0.04 --> Loss 0.00258672714233\n",
      "Epoch 27::Minibatch 392::LR 0.04 --> Loss 0.00257313251495\n",
      "Epoch 27::Minibatch 393::LR 0.04 --> Loss 0.00273929993312\n",
      "Epoch 27::Minibatch 394::LR 0.04 --> Loss 0.00202472945054\n",
      "Epoch 27::Minibatch 395::LR 0.04 --> Loss 0.00206195791562\n",
      "Epoch 27::Minibatch 396::LR 0.04 --> Loss 0.001932041049\n",
      "Epoch 27::Minibatch 397::LR 0.04 --> Loss 0.00206770161788\n",
      "Epoch 27::Minibatch 398::LR 0.04 --> Loss 0.002055366834\n",
      "Epoch 27::Minibatch 399::LR 0.04 --> Loss 0.00236489911874\n",
      "Epoch 27::Minibatch 400::LR 0.04 --> Loss 0.00200261354446\n",
      "Epoch 27::Minibatch 401::LR 0.04 --> Loss 0.0034192999204\n",
      "Epoch 27::Minibatch 402::LR 0.04 --> Loss 0.00172966281573\n",
      "Epoch 27::Minibatch 403::LR 0.04 --> Loss 0.00142537683249\n",
      "Epoch 27::Minibatch 404::LR 0.04 --> Loss 0.00136890014013\n",
      "Epoch 27::Minibatch 405::LR 0.04 --> Loss 0.00336770176888\n",
      "Epoch 27::Minibatch 406::LR 0.04 --> Loss 0.00236472745736\n",
      "Epoch 27::Minibatch 407::LR 0.04 --> Loss 0.00170468648275\n",
      "Epoch 27::Minibatch 408::LR 0.04 --> Loss 0.000430018703143\n",
      "Epoch 27::Minibatch 409::LR 0.04 --> Loss 0.00223220527172\n",
      "Epoch 27::Minibatch 410::LR 0.04 --> Loss 0.00313940227032\n",
      "Epoch 27::Minibatch 411::LR 0.04 --> Loss 0.00164308130741\n",
      "Epoch 27::Minibatch 412::LR 0.04 --> Loss 0.00094001442194\n",
      "Epoch 27::Minibatch 413::LR 0.04 --> Loss 0.00195859650771\n",
      "Epoch 27::Minibatch 414::LR 0.04 --> Loss 0.001851785779\n",
      "Epoch 27::Minibatch 415::LR 0.04 --> Loss 0.00115310927232\n",
      "Epoch 27::Minibatch 416::LR 0.04 --> Loss 0.000789664983749\n",
      "Epoch 27::Minibatch 417::LR 0.04 --> Loss 0.0016732052962\n",
      "Epoch 27::Minibatch 418::LR 0.04 --> Loss 0.00261538465818\n",
      "Epoch 27::Minibatch 419::LR 0.04 --> Loss 0.000486874977748\n",
      "Epoch 27::Minibatch 420::LR 0.04 --> Loss 0.000682952652375\n",
      "Epoch 27::Minibatch 421::LR 0.04 --> Loss 0.00187833944956\n",
      "Epoch 27::Minibatch 422::LR 0.04 --> Loss 0.0020713075002\n",
      "Epoch 27::Minibatch 423::LR 0.04 --> Loss 0.000969085892042\n",
      "Epoch 27::Minibatch 424::LR 0.04 --> Loss 0.0015155000488\n",
      "Epoch 27::Minibatch 425::LR 0.04 --> Loss 0.00287337064743\n",
      "Epoch 27::Minibatch 426::LR 0.04 --> Loss 0.0019812421004\n",
      "Epoch 27::Minibatch 427::LR 0.04 --> Loss 0.000718107968569\n",
      "Epoch 27::Minibatch 428::LR 0.04 --> Loss 0.000962529381116\n",
      "Epoch 27::Minibatch 429::LR 0.04 --> Loss 0.00226939857006\n",
      "Epoch 27::Minibatch 430::LR 0.04 --> Loss 0.0084459122022\n",
      "Epoch 27::Minibatch 431::LR 0.04 --> Loss 0.00366997798284\n",
      "Epoch 27::Minibatch 432::LR 0.04 --> Loss 0.00415146350861\n",
      "Epoch 27::Minibatch 433::LR 0.04 --> Loss 0.00253477652868\n",
      "Epoch 27::Minibatch 434::LR 0.04 --> Loss 0.00246799230576\n",
      "Epoch 27::Minibatch 435::LR 0.04 --> Loss 0.00226219097773\n",
      "Epoch 27::Minibatch 436::LR 0.04 --> Loss 0.00161390185356\n",
      "Epoch 27::Minibatch 437::LR 0.04 --> Loss 0.00291634082794\n",
      "Epoch 27::Minibatch 438::LR 0.04 --> Loss 0.00234441379706\n",
      "Epoch 27::Minibatch 439::LR 0.04 --> Loss 0.00195298214753\n",
      "Epoch 27::Minibatch 440::LR 0.04 --> Loss 0.00302672902743\n",
      "Epoch 27::Minibatch 441::LR 0.04 --> Loss 0.0028260542949\n",
      "Epoch 27::Minibatch 442::LR 0.04 --> Loss 0.00254492978255\n",
      "Epoch 27::Minibatch 443::LR 0.04 --> Loss 0.00350101947784\n",
      "Epoch 27::Minibatch 444::LR 0.04 --> Loss 0.00271333813667\n",
      "Epoch 27::Minibatch 445::LR 0.04 --> Loss 0.000856202046076\n",
      "Epoch 27::Minibatch 446::LR 0.04 --> Loss 0.0013807935516\n",
      "Epoch 27::Minibatch 447::LR 0.04 --> Loss 0.00232031504313\n",
      "Epoch 27::Minibatch 448::LR 0.04 --> Loss 0.00232405920823\n",
      "Epoch 27::Minibatch 449::LR 0.04 --> Loss 0.00360187411308\n",
      "Epoch 27::Minibatch 450::LR 0.04 --> Loss 0.00216299474239\n",
      "Epoch 27::Minibatch 451::LR 0.04 --> Loss 0.00387212634087\n",
      "Epoch 27::Minibatch 452::LR 0.04 --> Loss 0.00230898956458\n",
      "Epoch 27::Minibatch 453::LR 0.04 --> Loss 0.000353360151251\n",
      "Epoch 27::Minibatch 454::LR 0.04 --> Loss 0.00348038077354\n",
      "Epoch 27::Minibatch 455::LR 0.04 --> Loss 0.00261066774527\n",
      "Epoch 27::Minibatch 456::LR 0.04 --> Loss 0.00305452466011\n",
      "Epoch 27::Minibatch 457::LR 0.04 --> Loss 0.0018866455555\n",
      "Epoch 27::Minibatch 458::LR 0.04 --> Loss 0.000719928642114\n",
      "Epoch 27::Minibatch 459::LR 0.04 --> Loss 0.00390008648237\n",
      "Epoch 27::Minibatch 460::LR 0.04 --> Loss 0.00245570242405\n",
      "Epoch 27::Minibatch 461::LR 0.04 --> Loss 0.00373533050219\n",
      "Epoch 27::Minibatch 462::LR 0.04 --> Loss 0.000373167047898\n",
      "Epoch 27::Minibatch 463::LR 0.04 --> Loss 0.00423322439194\n",
      "Epoch 27::Minibatch 464::LR 0.04 --> Loss 0.00196318507195\n",
      "Epoch 27::Minibatch 465::LR 0.04 --> Loss 0.00470238447189\n",
      "Epoch 27::Minibatch 466::LR 0.04 --> Loss 0.00499770998955\n",
      "Epoch 27::Minibatch 467::LR 0.04 --> Loss 0.0052134446303\n",
      "Epoch 27::Minibatch 468::LR 0.04 --> Loss 0.00575592478116\n",
      "Epoch 27::Minibatch 469::LR 0.04 --> Loss 0.00612350185712\n",
      "Epoch 27::Minibatch 470::LR 0.04 --> Loss 0.00360515793165\n",
      "Epoch 27::Minibatch 471::LR 0.04 --> Loss 0.00167413413525\n",
      "Epoch 27::Minibatch 472::LR 0.04 --> Loss 0.00355095744133\n",
      "Epoch 27::Minibatch 473::LR 0.04 --> Loss 0.00229283372561\n",
      "Epoch 27::Minibatch 474::LR 0.04 --> Loss 0.000690660725037\n",
      "Epoch 27::Minibatch 475::LR 0.04 --> Loss 0.00484772642454\n",
      "Epoch 27::Minibatch 476::LR 0.04 --> Loss 0.00766084591548\n",
      "Epoch 27::Minibatch 477::LR 0.04 --> Loss 0.000916838645935\n",
      "Epoch 27::Minibatch 478::LR 0.04 --> Loss 0.00242066999276\n",
      "Epoch 27::Minibatch 479::LR 0.04 --> Loss 0.00196034232775\n",
      "Epoch 27::Minibatch 480::LR 0.04 --> Loss 0.00151789257924\n",
      "Epoch 27::Minibatch 481::LR 0.04 --> Loss 0.00095667531093\n",
      "Epoch 27::Minibatch 482::LR 0.04 --> Loss 0.0020731006066\n",
      "Epoch 27::Minibatch 483::LR 0.04 --> Loss 0.00305452764034\n",
      "Epoch 27::Minibatch 484::LR 0.04 --> Loss 0.00343088150024\n",
      "Epoch 27::Minibatch 485::LR 0.04 --> Loss 0.000759387413661\n",
      "Epoch 27::Minibatch 486::LR 0.04 --> Loss 0.00282813707987\n",
      "Epoch 27::Minibatch 487::LR 0.04 --> Loss 0.00330802718798\n",
      "Epoch 27::Minibatch 488::LR 0.04 --> Loss 0.00202537715435\n",
      "Epoch 27::Minibatch 489::LR 0.04 --> Loss 0.00310140371323\n",
      "Epoch 27::Minibatch 490::LR 0.04 --> Loss 0.000410426457723\n",
      "Epoch 27::Minibatch 491::LR 0.04 --> Loss 0.00332458257675\n",
      "Epoch 27::Minibatch 492::LR 0.04 --> Loss 0.00306226193905\n",
      "Epoch 27::Minibatch 493::LR 0.04 --> Loss 0.00302466789881\n",
      "Epoch 27::Minibatch 494::LR 0.04 --> Loss 0.000733891079823\n",
      "Epoch 27::Minibatch 495::LR 0.04 --> Loss 0.00184040526549\n",
      "Epoch 27::Minibatch 496::LR 0.04 --> Loss 0.00279897669951\n",
      "Epoch 27::Minibatch 497::LR 0.04 --> Loss 0.000915901660919\n",
      "Epoch 27::Minibatch 498::LR 0.04 --> Loss 0.000551553368568\n",
      "Epoch 27::Minibatch 499::LR 0.04 --> Loss 0.003451029857\n",
      "Epoch 27::Minibatch 500::LR 0.04 --> Loss 0.00142892201742\n",
      "Epoch 27::Minibatch 501::LR 0.04 --> Loss 0.00208498577277\n",
      "Epoch 27::Minibatch 502::LR 0.04 --> Loss 0.00375570893288\n",
      "Epoch 27::Minibatch 503::LR 0.04 --> Loss 0.00706376314163\n",
      "Epoch 27::Minibatch 504::LR 0.04 --> Loss 0.00694239139557\n",
      "Epoch 27::Minibatch 505::LR 0.04 --> Loss 0.00403636693954\n",
      "Epoch 27::Minibatch 506::LR 0.04 --> Loss 0.0033458785216\n",
      "Epoch 27::Minibatch 507::LR 0.04 --> Loss 0.00582977374395\n",
      "Epoch 27::Minibatch 508::LR 0.04 --> Loss 0.00339407602946\n",
      "Epoch 27::Minibatch 509::LR 0.04 --> Loss 0.00431885639826\n",
      "Epoch 27::Minibatch 510::LR 0.04 --> Loss 0.00442824006081\n",
      "Epoch 27::Minibatch 511::LR 0.04 --> Loss 0.00396853327751\n",
      "Epoch 27::Minibatch 512::LR 0.04 --> Loss 0.00268123408159\n",
      "Epoch 27::Minibatch 513::LR 0.04 --> Loss 0.000606773495674\n",
      "Epoch 27::Minibatch 514::LR 0.04 --> Loss 0.00264889140924\n",
      "Epoch 27::Minibatch 515::LR 0.04 --> Loss 0.00299538969994\n",
      "Epoch 27::Minibatch 516::LR 0.04 --> Loss 0.00394715428352\n",
      "Epoch 27::Minibatch 517::LR 0.04 --> Loss 0.00358633995056\n",
      "Epoch 27::Minibatch 518::LR 0.04 --> Loss 0.00257809340954\n",
      "Epoch 27::Minibatch 519::LR 0.04 --> Loss 0.00351164857546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 520::LR 0.04 --> Loss 0.00548947294553\n",
      "Epoch 27::Minibatch 521::LR 0.04 --> Loss 0.00558036327362\n",
      "Epoch 27::Minibatch 522::LR 0.04 --> Loss 0.00740089495977\n",
      "Epoch 27::Minibatch 523::LR 0.04 --> Loss 0.000626689990362\n",
      "Epoch 27::Minibatch 524::LR 0.04 --> Loss 0.00139966617028\n",
      "Epoch 27::Minibatch 525::LR 0.04 --> Loss 0.00310490469138\n",
      "Epoch 27::Minibatch 526::LR 0.04 --> Loss 0.00378708402316\n",
      "Epoch 27::Minibatch 527::LR 0.04 --> Loss 0.00215395172437\n",
      "Epoch 27::Minibatch 528::LR 0.04 --> Loss 0.00095301647981\n",
      "Epoch 27::Minibatch 529::LR 0.04 --> Loss 0.00389534473419\n",
      "Epoch 27::Minibatch 530::LR 0.04 --> Loss 0.00390023549398\n",
      "Epoch 27::Minibatch 531::LR 0.04 --> Loss 0.00346760590871\n",
      "Epoch 27::Minibatch 532::LR 0.04 --> Loss 0.00263109982014\n",
      "Epoch 27::Minibatch 533::LR 0.04 --> Loss 0.00493318478266\n",
      "Epoch 27::Minibatch 534::LR 0.04 --> Loss 0.00371661464373\n",
      "Epoch 27::Minibatch 535::LR 0.04 --> Loss 0.00329713424047\n",
      "Epoch 27::Minibatch 536::LR 0.04 --> Loss 0.00210428118706\n",
      "Epoch 27::Minibatch 537::LR 0.04 --> Loss 0.00059160048763\n",
      "Epoch 27::Minibatch 538::LR 0.04 --> Loss 0.00164640595516\n",
      "Epoch 27::Minibatch 539::LR 0.04 --> Loss 0.00334264556567\n",
      "Epoch 27::Minibatch 540::LR 0.04 --> Loss 0.00339881499608\n",
      "Epoch 27::Minibatch 541::LR 0.04 --> Loss 0.00285784304142\n",
      "Epoch 27::Minibatch 542::LR 0.04 --> Loss 0.0024573669831\n",
      "Epoch 27::Minibatch 543::LR 0.04 --> Loss 0.00261512915293\n",
      "Epoch 27::Minibatch 544::LR 0.04 --> Loss 0.00397197365761\n",
      "Epoch 27::Minibatch 545::LR 0.04 --> Loss 0.00199526329835\n",
      "Epoch 27::Minibatch 546::LR 0.04 --> Loss 0.000655882706245\n",
      "Epoch 27::Minibatch 547::LR 0.04 --> Loss 0.00258927007516\n",
      "Epoch 27::Minibatch 548::LR 0.04 --> Loss 0.00346807400386\n",
      "Epoch 27::Minibatch 549::LR 0.04 --> Loss 0.00877356529236\n",
      "Epoch 27::Minibatch 550::LR 0.04 --> Loss 0.0011788247029\n",
      "Epoch 27::Minibatch 551::LR 0.04 --> Loss 0.00245302697023\n",
      "Epoch 27::Minibatch 552::LR 0.04 --> Loss 0.00345453739166\n",
      "Epoch 27::Minibatch 553::LR 0.04 --> Loss 0.00302605768045\n",
      "Epoch 27::Minibatch 554::LR 0.04 --> Loss 0.00366240700086\n",
      "Epoch 27::Minibatch 555::LR 0.04 --> Loss 0.00094988544782\n",
      "Epoch 27::Minibatch 556::LR 0.04 --> Loss 0.0019351897637\n",
      "Epoch 27::Minibatch 557::LR 0.04 --> Loss 0.00241129934788\n",
      "Epoch 27::Minibatch 558::LR 0.04 --> Loss 0.00362189292908\n",
      "Epoch 27::Minibatch 559::LR 0.04 --> Loss 0.00366824706395\n",
      "Epoch 27::Minibatch 560::LR 0.04 --> Loss 0.00306040883064\n",
      "Epoch 27::Minibatch 561::LR 0.04 --> Loss 0.00263688504696\n",
      "Epoch 27::Minibatch 562::LR 0.04 --> Loss 0.00234679500262\n",
      "Epoch 27::Minibatch 563::LR 0.04 --> Loss 0.00397957722346\n",
      "Epoch 27::Minibatch 564::LR 0.04 --> Loss 0.00305890957514\n",
      "Epoch 27::Minibatch 565::LR 0.04 --> Loss 0.00359817107519\n",
      "Epoch 27::Minibatch 566::LR 0.04 --> Loss 0.00219973067443\n",
      "Epoch 27::Minibatch 567::LR 0.04 --> Loss 0.00253558139006\n",
      "Epoch 27::Minibatch 568::LR 0.04 --> Loss 0.00175653080146\n",
      "Epoch 27::Minibatch 569::LR 0.04 --> Loss 0.000561027278503\n",
      "Epoch 27::Minibatch 570::LR 0.04 --> Loss 0.00164133608341\n",
      "Epoch 27::Minibatch 571::LR 0.04 --> Loss 0.00209962546825\n",
      "Epoch 27::Minibatch 572::LR 0.04 --> Loss 0.00225345710913\n",
      "Epoch 27::Minibatch 573::LR 0.04 --> Loss 0.0014553925395\n",
      "Epoch 27::Minibatch 574::LR 0.04 --> Loss 0.00104464173317\n",
      "Epoch 27::Minibatch 575::LR 0.04 --> Loss 0.00173274914424\n",
      "Epoch 27::Minibatch 576::LR 0.04 --> Loss 0.00204776525497\n",
      "Epoch 27::Minibatch 577::LR 0.04 --> Loss 0.00161941627661\n",
      "Epoch 27::Minibatch 578::LR 0.04 --> Loss 0.00126855363448\n",
      "Epoch 27::Minibatch 579::LR 0.04 --> Loss 0.00118577867746\n",
      "Epoch 27::Minibatch 580::LR 0.04 --> Loss 0.00192284365495\n",
      "Epoch 27::Minibatch 581::LR 0.04 --> Loss 0.00170706570148\n",
      "Epoch 27::Minibatch 582::LR 0.04 --> Loss 0.00416655460993\n",
      "Epoch 27::Minibatch 583::LR 0.04 --> Loss 0.000948878924052\n",
      "Epoch 27::Minibatch 584::LR 0.04 --> Loss 0.00130770574013\n",
      "Epoch 27::Minibatch 585::LR 0.04 --> Loss 0.00402276317279\n",
      "Epoch 27::Minibatch 586::LR 0.04 --> Loss 0.00379512270292\n",
      "Epoch 27::Minibatch 587::LR 0.04 --> Loss 0.00111616194248\n",
      "Epoch 27::Minibatch 588::LR 0.04 --> Loss 0.00138030211131\n",
      "Epoch 27::Minibatch 589::LR 0.04 --> Loss 0.00274920046329\n",
      "Epoch 27::Minibatch 590::LR 0.04 --> Loss 0.00183563649654\n",
      "Epoch 27::Minibatch 591::LR 0.04 --> Loss 0.00278683900833\n",
      "Epoch 27::Minibatch 592::LR 0.04 --> Loss 0.00115744948387\n",
      "Epoch 27::Minibatch 593::LR 0.04 --> Loss 0.00249953826269\n",
      "Epoch 27::Minibatch 594::LR 0.04 --> Loss 0.00261231521765\n",
      "Epoch 27::Minibatch 595::LR 0.04 --> Loss 0.00304189165433\n",
      "Epoch 27::Minibatch 596::LR 0.04 --> Loss 0.00186656614145\n",
      "Epoch 27::Minibatch 597::LR 0.04 --> Loss 0.00117463479439\n",
      "Epoch 27::Minibatch 598::LR 0.04 --> Loss 0.00285422305266\n",
      "Epoch 27::Minibatch 599::LR 0.04 --> Loss 0.00180760641893\n",
      "Epoch 27::Minibatch 600::LR 0.04 --> Loss 0.0021500279506\n",
      "Epoch 27::Minibatch 601::LR 0.04 --> Loss 0.0037702703476\n",
      "Epoch 27::Minibatch 602::LR 0.04 --> Loss 0.00209176043669\n",
      "Epoch 27::Minibatch 603::LR 0.04 --> Loss 0.00262265404065\n",
      "Epoch 27::Minibatch 604::LR 0.04 --> Loss 0.00163687507312\n",
      "Epoch 27::Minibatch 605::LR 0.04 --> Loss 0.00230411012967\n",
      "Epoch 27::Minibatch 606::LR 0.04 --> Loss 0.00187317232291\n",
      "Epoch 27::Minibatch 607::LR 0.04 --> Loss 0.000830377290646\n",
      "Epoch 27::Minibatch 608::LR 0.04 --> Loss 0.00156134386857\n",
      "Epoch 27::Minibatch 609::LR 0.04 --> Loss 0.0024135218064\n",
      "Epoch 27::Minibatch 610::LR 0.04 --> Loss 0.00403037786484\n",
      "Epoch 27::Minibatch 611::LR 0.04 --> Loss 0.00264412025611\n",
      "Epoch 27::Minibatch 612::LR 0.04 --> Loss 0.00047323808074\n",
      "Epoch 27::Minibatch 613::LR 0.04 --> Loss 0.00131035884221\n",
      "Epoch 27::Minibatch 614::LR 0.04 --> Loss 0.00241593698661\n",
      "Epoch 27::Minibatch 615::LR 0.04 --> Loss 0.00166156490644\n",
      "Epoch 27::Minibatch 616::LR 0.04 --> Loss 0.000918847024441\n",
      "Epoch 27::Minibatch 617::LR 0.04 --> Loss 0.0004936170578\n",
      "Epoch 27::Minibatch 618::LR 0.04 --> Loss 0.00283543646336\n",
      "Epoch 27::Minibatch 619::LR 0.04 --> Loss 0.00192722380161\n",
      "Epoch 27::Minibatch 620::LR 0.04 --> Loss 0.00169711430868\n",
      "Epoch 27::Minibatch 621::LR 0.04 --> Loss 0.000846802592278\n",
      "Epoch 27::Minibatch 622::LR 0.04 --> Loss 0.000784180164337\n",
      "Epoch 27::Minibatch 623::LR 0.04 --> Loss 0.00221955776215\n",
      "Epoch 27::Minibatch 624::LR 0.04 --> Loss 0.00178025941054\n",
      "Epoch 27::Minibatch 625::LR 0.04 --> Loss 0.00272947649161\n",
      "Epoch 27::Minibatch 626::LR 0.04 --> Loss 0.00381330490112\n",
      "Epoch 27::Minibatch 627::LR 0.04 --> Loss 0.00127979318301\n",
      "Epoch 27::Minibatch 628::LR 0.04 --> Loss 0.000881487826506\n",
      "Epoch 27::Minibatch 629::LR 0.04 --> Loss 0.0031660870711\n",
      "Epoch 27::Minibatch 630::LR 0.04 --> Loss 0.00309421340624\n",
      "Epoch 27::Minibatch 631::LR 0.04 --> Loss 0.00546626766523\n",
      "Epoch 27::Minibatch 632::LR 0.04 --> Loss 0.000791303416093\n",
      "Epoch 27::Minibatch 633::LR 0.04 --> Loss 0.00162809997797\n",
      "Epoch 27::Minibatch 634::LR 0.04 --> Loss 0.00320352852345\n",
      "Epoch 27::Minibatch 635::LR 0.04 --> Loss 0.00547682881355\n",
      "Epoch 27::Minibatch 636::LR 0.04 --> Loss 0.00469861944516\n",
      "Epoch 27::Minibatch 637::LR 0.04 --> Loss 0.000728059063355\n",
      "Epoch 27::Minibatch 638::LR 0.04 --> Loss 0.00148637294769\n",
      "Epoch 27::Minibatch 639::LR 0.04 --> Loss 0.00321237226327\n",
      "Epoch 27::Minibatch 640::LR 0.04 --> Loss 0.00468636870384\n",
      "Epoch 27::Minibatch 641::LR 0.04 --> Loss 0.00306465625763\n",
      "Epoch 27::Minibatch 642::LR 0.04 --> Loss 0.00053329616785\n",
      "Epoch 27::Minibatch 643::LR 0.04 --> Loss 0.00231755654017\n",
      "Epoch 27::Minibatch 644::LR 0.04 --> Loss 0.00389396746953\n",
      "Epoch 27::Minibatch 645::LR 0.04 --> Loss 0.00436608036359\n",
      "Epoch 27::Minibatch 646::LR 0.04 --> Loss 0.00150078763564\n",
      "Epoch 27::Minibatch 647::LR 0.04 --> Loss 0.000478081007799\n",
      "Epoch 27::Minibatch 648::LR 0.04 --> Loss 0.00282233496507\n",
      "Epoch 27::Minibatch 649::LR 0.04 --> Loss 0.00331560373306\n",
      "Epoch 27::Minibatch 650::LR 0.04 --> Loss 0.00321523328622\n",
      "Epoch 27::Minibatch 651::LR 0.04 --> Loss 0.0013432687521\n",
      "Epoch 27::Minibatch 652::LR 0.04 --> Loss 0.000781325002511\n",
      "Epoch 27::Minibatch 653::LR 0.04 --> Loss 0.00281804263592\n",
      "Epoch 27::Minibatch 654::LR 0.04 --> Loss 0.003126633962\n",
      "Epoch 27::Minibatch 655::LR 0.04 --> Loss 0.00358521779378\n",
      "Epoch 27::Minibatch 656::LR 0.04 --> Loss 0.000754303683837\n",
      "Epoch 27::Minibatch 657::LR 0.04 --> Loss 0.00226444542408\n",
      "Epoch 27::Minibatch 658::LR 0.04 --> Loss 0.00461410045624\n",
      "Epoch 27::Minibatch 659::LR 0.04 --> Loss 0.00224211990833\n",
      "Epoch 27::Minibatch 660::LR 0.04 --> Loss 0.00262965301673\n",
      "Epoch 27::Minibatch 661::LR 0.04 --> Loss 0.00233341793219\n",
      "Epoch 27::Minibatch 662::LR 0.04 --> Loss 0.0017980325222\n",
      "Epoch 27::Minibatch 663::LR 0.04 --> Loss 0.00368774414063\n",
      "Epoch 27::Minibatch 664::LR 0.04 --> Loss 0.0032377521197\n",
      "Epoch 27::Minibatch 665::LR 0.04 --> Loss 0.000703300933043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 666::LR 0.04 --> Loss 0.00390612681707\n",
      "Epoch 27::Minibatch 667::LR 0.04 --> Loss 0.00254228730996\n",
      "Epoch 27::Minibatch 668::LR 0.04 --> Loss 0.00650882124901\n",
      "Epoch 27::Minibatch 669::LR 0.04 --> Loss 0.00108779986699\n",
      "Epoch 27::Minibatch 670::LR 0.04 --> Loss 0.00133454322815\n",
      "Epoch 27::Minibatch 671::LR 0.04 --> Loss 0.0051567641894\n",
      "Epoch 27::Minibatch 672::LR 0.04 --> Loss 0.00348503867785\n",
      "Epoch 27::Minibatch 673::LR 0.04 --> Loss 0.00161074260871\n",
      "Epoch 27::Minibatch 674::LR 0.04 --> Loss 0.000509869505962\n",
      "Epoch 27::Minibatch 675::LR 0.04 --> Loss 0.00218983610471\n",
      "Epoch 27::Minibatch 676::LR 0.04 --> Loss 0.00214343090852\n",
      "Epoch 27::Minibatch 677::LR 0.04 --> Loss 0.00273163994153\n",
      "Epoch 27::Minibatch 678::LR 0.04 --> Loss 0.00188207487265\n",
      "Epoch 27::Minibatch 679::LR 0.04 --> Loss 0.00336260795593\n",
      "Epoch 27::Minibatch 680::LR 0.04 --> Loss 0.00212872584661\n",
      "Epoch 27::Minibatch 681::LR 0.04 --> Loss 0.00240416785081\n",
      "Epoch 27::Minibatch 682::LR 0.04 --> Loss 0.000761318306128\n",
      "Epoch 27::Minibatch 683::LR 0.04 --> Loss 0.00232990443707\n",
      "Epoch 27::Minibatch 684::LR 0.04 --> Loss 0.0023398510615\n",
      "Epoch 27::Minibatch 685::LR 0.04 --> Loss 0.00284264604251\n",
      "Epoch 27::Minibatch 686::LR 0.04 --> Loss 0.00157720218102\n",
      "Epoch 27::Minibatch 687::LR 0.04 --> Loss 0.000869240164757\n",
      "Epoch 27::Minibatch 688::LR 0.04 --> Loss 0.00278693477313\n",
      "Epoch 27::Minibatch 689::LR 0.04 --> Loss 0.00248724897703\n",
      "Epoch 27::Minibatch 690::LR 0.04 --> Loss 0.0018918099006\n",
      "Epoch 27::Minibatch 691::LR 0.04 --> Loss 0.000657960871855\n",
      "Epoch 27::Minibatch 692::LR 0.04 --> Loss 0.00244720915953\n",
      "Epoch 27::Minibatch 693::LR 0.04 --> Loss 0.00259977082411\n",
      "Epoch 27::Minibatch 694::LR 0.04 --> Loss 0.00300391256809\n",
      "Epoch 27::Minibatch 695::LR 0.04 --> Loss 0.00177907546361\n",
      "Epoch 27::Minibatch 696::LR 0.04 --> Loss 0.0020383900404\n",
      "Epoch 27::Minibatch 697::LR 0.04 --> Loss 0.00140157530705\n",
      "Epoch 27::Minibatch 698::LR 0.04 --> Loss 0.00165452400843\n",
      "Epoch 27::Minibatch 699::LR 0.04 --> Loss 0.00374846816063\n",
      "Epoch 27::Minibatch 700::LR 0.04 --> Loss 0.00260835170746\n",
      "Epoch 27::Minibatch 701::LR 0.04 --> Loss 0.00191544830799\n",
      "Epoch 27::Minibatch 702::LR 0.04 --> Loss 0.00166493346294\n",
      "Epoch 27::Minibatch 703::LR 0.04 --> Loss 0.00432716568311\n",
      "Epoch 27::Minibatch 704::LR 0.04 --> Loss 0.00180371403694\n",
      "Epoch 27::Minibatch 705::LR 0.04 --> Loss 0.00285378416379\n",
      "Epoch 27::Minibatch 706::LR 0.04 --> Loss 0.00221863309542\n",
      "Epoch 27::Minibatch 707::LR 0.04 --> Loss 0.00117923458417\n",
      "Epoch 27::Minibatch 708::LR 0.04 --> Loss 0.00173134922981\n",
      "Epoch 27::Minibatch 709::LR 0.04 --> Loss 0.00167398353418\n",
      "Epoch 27::Minibatch 710::LR 0.04 --> Loss 0.00256766219934\n",
      "Epoch 27::Minibatch 711::LR 0.04 --> Loss 0.00195836563905\n",
      "Epoch 27::Minibatch 712::LR 0.04 --> Loss 0.00135022441546\n",
      "Epoch 27::Minibatch 713::LR 0.04 --> Loss 0.00178446412086\n",
      "Epoch 27::Minibatch 714::LR 0.04 --> Loss 0.00283008615176\n",
      "Epoch 27::Minibatch 715::LR 0.04 --> Loss 0.00292946894964\n",
      "Epoch 27::Minibatch 716::LR 0.04 --> Loss 0.00164802392324\n",
      "Epoch 27::Minibatch 717::LR 0.04 --> Loss 0.00165231645107\n",
      "Epoch 27::Minibatch 718::LR 0.04 --> Loss 0.00127082635959\n",
      "Epoch 27::Minibatch 719::LR 0.04 --> Loss 0.00170744260152\n",
      "Epoch 27::Minibatch 720::LR 0.04 --> Loss 0.00269176681836\n",
      "Epoch 27::Minibatch 721::LR 0.04 --> Loss 0.000607307801644\n",
      "Epoch 27::Minibatch 722::LR 0.04 --> Loss 0.00465338865916\n",
      "Epoch 27::Minibatch 723::LR 0.04 --> Loss 0.00485416769981\n",
      "Epoch 27::Minibatch 724::LR 0.04 --> Loss 0.00096516152223\n",
      "Epoch 27::Minibatch 725::LR 0.04 --> Loss 0.00209101557732\n",
      "Epoch 27::Minibatch 726::LR 0.04 --> Loss 0.0039250322183\n",
      "Epoch 27::Minibatch 727::LR 0.04 --> Loss 0.00314633786678\n",
      "Epoch 27::Minibatch 728::LR 0.04 --> Loss 0.000641554196676\n",
      "Epoch 27::Minibatch 729::LR 0.04 --> Loss 0.000724685192108\n",
      "Epoch 27::Minibatch 730::LR 0.04 --> Loss 0.00290176868439\n",
      "Epoch 27::Minibatch 731::LR 0.04 --> Loss 0.00258679687977\n",
      "Epoch 27::Minibatch 732::LR 0.04 --> Loss 0.00209349532922\n",
      "Epoch 27::Minibatch 733::LR 0.04 --> Loss 0.000617776215076\n",
      "Epoch 27::Minibatch 734::LR 0.04 --> Loss 0.0016672672828\n",
      "Epoch 27::Minibatch 735::LR 0.04 --> Loss 0.00243331273397\n",
      "Epoch 27::Minibatch 736::LR 0.04 --> Loss 0.00347465356191\n",
      "Epoch 27::Minibatch 737::LR 0.04 --> Loss 0.00297686994076\n",
      "Epoch 27::Minibatch 738::LR 0.04 --> Loss 0.00145319352547\n",
      "Epoch 27::Minibatch 739::LR 0.04 --> Loss 0.00241265098254\n",
      "Epoch 27::Minibatch 740::LR 0.04 --> Loss 0.00379065275192\n",
      "Epoch 27::Minibatch 741::LR 0.04 --> Loss 0.00256802399953\n",
      "Epoch 27::Minibatch 742::LR 0.04 --> Loss 0.00209096729755\n",
      "Epoch 27::Minibatch 743::LR 0.04 --> Loss 0.00147625813882\n",
      "Epoch 27::Minibatch 744::LR 0.04 --> Loss 0.00184636910756\n",
      "Epoch 27::Minibatch 745::LR 0.04 --> Loss 0.00278931458791\n",
      "Epoch 27::Minibatch 746::LR 0.04 --> Loss 0.00288612107436\n",
      "Epoch 27::Minibatch 747::LR 0.04 --> Loss 0.00177000025908\n",
      "Epoch 27::Minibatch 748::LR 0.04 --> Loss 0.000619991322358\n",
      "Epoch 27::Minibatch 749::LR 0.04 --> Loss 0.00166431248188\n",
      "Epoch 27::Minibatch 750::LR 0.04 --> Loss 0.00243032495181\n",
      "Epoch 27::Minibatch 751::LR 0.04 --> Loss 0.00286320110162\n",
      "Epoch 27::Minibatch 752::LR 0.04 --> Loss 0.00135620782773\n",
      "Epoch 27::Minibatch 753::LR 0.04 --> Loss 0.00219667871793\n",
      "Epoch 27::Minibatch 754::LR 0.04 --> Loss 0.00241012871265\n",
      "Epoch 27::Minibatch 755::LR 0.04 --> Loss 0.00266353627046\n",
      "Epoch 27::Minibatch 756::LR 0.04 --> Loss 0.00132670521736\n",
      "Epoch 27::Minibatch 757::LR 0.04 --> Loss 0.000645739684502\n",
      "Epoch 27::Minibatch 758::LR 0.04 --> Loss 0.0015746024251\n",
      "Epoch 27::Minibatch 759::LR 0.04 --> Loss 0.00352222363154\n",
      "Epoch 27::Minibatch 760::LR 0.04 --> Loss 0.00285419265429\n",
      "Epoch 27::Minibatch 761::LR 0.04 --> Loss 0.00584297060966\n",
      "Epoch 27::Minibatch 762::LR 0.04 --> Loss 0.00362752517064\n",
      "Epoch 27::Minibatch 763::LR 0.04 --> Loss 0.00347354094187\n",
      "Epoch 27::Minibatch 764::LR 0.04 --> Loss 0.0030700023969\n",
      "Epoch 27::Minibatch 765::LR 0.04 --> Loss 0.00126631051302\n",
      "Epoch 27::Minibatch 766::LR 0.04 --> Loss 0.00229662974675\n",
      "Epoch 27::Minibatch 767::LR 0.04 --> Loss 0.00484962145487\n",
      "Epoch 27::Minibatch 768::LR 0.04 --> Loss 0.00365553061167\n",
      "Epoch 27::Minibatch 769::LR 0.04 --> Loss 0.00185063918432\n",
      "Epoch 27::Minibatch 770::LR 0.04 --> Loss 0.00149602413177\n",
      "Epoch 27::Minibatch 771::LR 0.04 --> Loss 0.00348958094915\n",
      "Epoch 27::Minibatch 772::LR 0.04 --> Loss 0.00355372508367\n",
      "Epoch 27::Minibatch 773::LR 0.04 --> Loss 0.00316805680593\n",
      "Epoch 27::Minibatch 774::LR 0.04 --> Loss 0.001855768164\n",
      "Epoch 27::Minibatch 775::LR 0.04 --> Loss 0.0034237019221\n",
      "Epoch 27::Minibatch 776::LR 0.04 --> Loss 0.00369733611743\n",
      "Epoch 27::Minibatch 777::LR 0.04 --> Loss 0.00645913481712\n",
      "Epoch 27::Minibatch 778::LR 0.04 --> Loss 0.00786898295085\n",
      "Epoch 27::Minibatch 779::LR 0.04 --> Loss 0.00245594859123\n",
      "Epoch 27::Minibatch 780::LR 0.04 --> Loss 0.00153130660454\n",
      "Epoch 27::Minibatch 781::LR 0.04 --> Loss 0.00345659653346\n",
      "Epoch 27::Minibatch 782::LR 0.04 --> Loss 0.00381309509277\n",
      "Epoch 27::Minibatch 783::LR 0.04 --> Loss 0.00227273027102\n",
      "Epoch 27::Minibatch 784::LR 0.04 --> Loss 0.000706785420577\n",
      "Epoch 27::Minibatch 785::LR 0.04 --> Loss 0.00325525164604\n",
      "Epoch 27::Minibatch 786::LR 0.04 --> Loss 0.00343506614367\n",
      "Epoch 27::Minibatch 787::LR 0.04 --> Loss 0.00258821745714\n",
      "Epoch 27::Minibatch 788::LR 0.04 --> Loss 0.00235754350821\n",
      "Epoch 27::Minibatch 789::LR 0.04 --> Loss 0.000727054178715\n",
      "Epoch 27::Minibatch 790::LR 0.04 --> Loss 0.0031253973643\n",
      "Epoch 27::Minibatch 791::LR 0.04 --> Loss 0.00334409912427\n",
      "Epoch 27::Minibatch 792::LR 0.04 --> Loss 0.00298832535744\n",
      "Epoch 27::Minibatch 793::LR 0.04 --> Loss 0.00167058090369\n",
      "Epoch 27::Minibatch 794::LR 0.04 --> Loss 0.000988001724084\n",
      "Epoch 27::Minibatch 795::LR 0.04 --> Loss 0.00272591253122\n",
      "Epoch 27::Minibatch 796::LR 0.04 --> Loss 0.0050512111187\n",
      "Epoch 27::Minibatch 797::LR 0.04 --> Loss 0.00609261910121\n",
      "Epoch 27::Minibatch 798::LR 0.04 --> Loss 0.00307242055734\n",
      "Epoch 27::Minibatch 799::LR 0.04 --> Loss 0.00226768434048\n",
      "Epoch 27::Minibatch 800::LR 0.04 --> Loss 0.00200481891632\n",
      "Epoch 27::Minibatch 801::LR 0.04 --> Loss 0.00398992260297\n",
      "Epoch 27::Minibatch 802::LR 0.04 --> Loss 0.00123101452986\n",
      "Epoch 27::Minibatch 803::LR 0.04 --> Loss 0.00292296648026\n",
      "Epoch 27::Minibatch 804::LR 0.04 --> Loss 0.00209766586622\n",
      "Epoch 27::Minibatch 805::LR 0.04 --> Loss 0.00220201770465\n",
      "Epoch 27::Minibatch 806::LR 0.04 --> Loss 0.00339432795842\n",
      "Epoch 27::Minibatch 807::LR 0.04 --> Loss 0.00306319991748\n",
      "Epoch 27::Minibatch 808::LR 0.04 --> Loss 0.0027632021904\n",
      "Epoch 27::Minibatch 809::LR 0.04 --> Loss 0.00323402345181\n",
      "Epoch 27::Minibatch 810::LR 0.04 --> Loss 0.00444941600164\n",
      "Epoch 27::Minibatch 811::LR 0.04 --> Loss 0.00424214919408\n",
      "Epoch 27::Minibatch 812::LR 0.04 --> Loss 0.0038887544473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 813::LR 0.04 --> Loss 0.00331389069557\n",
      "Epoch 27::Minibatch 814::LR 0.04 --> Loss 0.00156579166651\n",
      "Epoch 27::Minibatch 815::LR 0.04 --> Loss 0.00357021808624\n",
      "Epoch 27::Minibatch 816::LR 0.04 --> Loss 0.00400434573491\n",
      "Epoch 27::Minibatch 817::LR 0.04 --> Loss 0.0051423060894\n",
      "Epoch 27::Minibatch 818::LR 0.04 --> Loss 0.00124659766754\n",
      "Epoch 27::Minibatch 819::LR 0.04 --> Loss 0.000711875756582\n",
      "Epoch 27::Minibatch 820::LR 0.04 --> Loss 0.00515199502309\n",
      "Epoch 27::Minibatch 821::LR 0.04 --> Loss 0.00306626001994\n",
      "Epoch 27::Minibatch 822::LR 0.04 --> Loss 0.00365698655446\n",
      "Epoch 27::Minibatch 823::LR 0.04 --> Loss 0.00126882473628\n",
      "Epoch 27::Minibatch 824::LR 0.04 --> Loss 0.00136091937621\n",
      "Epoch 27::Minibatch 825::LR 0.04 --> Loss 0.00367227355639\n",
      "Epoch 27::Minibatch 826::LR 0.04 --> Loss 0.00420421719551\n",
      "Epoch 27::Minibatch 827::LR 0.04 --> Loss 0.00205535292625\n",
      "Epoch 27::Minibatch 828::LR 0.04 --> Loss 0.000492457946142\n",
      "Epoch 27::Minibatch 829::LR 0.04 --> Loss 0.00228559076786\n",
      "Epoch 27::Minibatch 830::LR 0.04 --> Loss 0.00410855650902\n",
      "Epoch 27::Minibatch 831::LR 0.04 --> Loss 0.00244171380997\n",
      "Epoch 27::Minibatch 832::LR 0.04 --> Loss 0.00214482327302\n",
      "Epoch 27::Minibatch 833::LR 0.04 --> Loss 0.00182426770528\n",
      "Epoch 27::Minibatch 834::LR 0.04 --> Loss 0.00078127677242\n",
      "Epoch 27::Minibatch 835::LR 0.04 --> Loss 0.00375538110733\n",
      "Epoch 27::Minibatch 836::LR 0.04 --> Loss 0.00359722296397\n",
      "Epoch 27::Minibatch 837::LR 0.04 --> Loss 0.0022096914053\n",
      "Epoch 27::Minibatch 838::LR 0.04 --> Loss 0.000636498679717\n",
      "Epoch 27::Minibatch 839::LR 0.04 --> Loss 0.00241329709689\n",
      "Epoch 27::Minibatch 840::LR 0.04 --> Loss 0.00284737785657\n",
      "Epoch 27::Minibatch 841::LR 0.04 --> Loss 0.00276258707047\n",
      "Epoch 27::Minibatch 842::LR 0.04 --> Loss 0.00208091417948\n",
      "Epoch 27::Minibatch 843::LR 0.04 --> Loss 0.000984348356724\n",
      "Epoch 27::Minibatch 844::LR 0.04 --> Loss 0.00147035410007\n",
      "Epoch 27::Minibatch 845::LR 0.04 --> Loss 0.00410812854767\n",
      "Epoch 27::Minibatch 846::LR 0.04 --> Loss 0.0016647135218\n",
      "Epoch 27::Minibatch 847::LR 0.04 --> Loss 0.00231616397699\n",
      "Epoch 27::Minibatch 848::LR 0.04 --> Loss 0.00106729159753\n",
      "Epoch 27::Minibatch 849::LR 0.04 --> Loss 0.00179141958555\n",
      "Epoch 27::Minibatch 850::LR 0.04 --> Loss 0.00314524312814\n",
      "Epoch 27::Minibatch 851::LR 0.04 --> Loss 0.00256351093451\n",
      "Epoch 27::Minibatch 852::LR 0.04 --> Loss 0.00110417793194\n",
      "Epoch 27::Minibatch 853::LR 0.04 --> Loss 0.00130023896694\n",
      "Epoch 27::Minibatch 854::LR 0.04 --> Loss 0.00253989676634\n",
      "Epoch 27::Minibatch 855::LR 0.04 --> Loss 0.00212459445\n",
      "Epoch 27::Minibatch 856::LR 0.04 --> Loss 0.00178302705288\n",
      "Epoch 27::Minibatch 857::LR 0.04 --> Loss 0.00120804935694\n",
      "Epoch 27::Minibatch 858::LR 0.04 --> Loss 0.000595154464245\n",
      "Epoch 27::Minibatch 859::LR 0.04 --> Loss 0.00194364905357\n",
      "Epoch 27::Minibatch 860::LR 0.04 --> Loss 0.00127939611673\n",
      "Epoch 27::Minibatch 861::LR 0.04 --> Loss 0.000939914286137\n",
      "Epoch 27::Minibatch 862::LR 0.04 --> Loss 0.00367847601573\n",
      "Epoch 27::Minibatch 863::LR 0.04 --> Loss 0.0033721892039\n",
      "Epoch 27::Minibatch 864::LR 0.04 --> Loss 0.00267144242922\n",
      "Epoch 27::Minibatch 865::LR 0.04 --> Loss 0.00047081882755\n",
      "Epoch 27::Minibatch 866::LR 0.04 --> Loss 0.00209309776624\n",
      "Epoch 27::Minibatch 867::LR 0.04 --> Loss 0.00289218723774\n",
      "Epoch 27::Minibatch 868::LR 0.04 --> Loss 0.00240231752396\n",
      "Epoch 27::Minibatch 869::LR 0.04 --> Loss 0.00211836795012\n",
      "Epoch 27::Minibatch 870::LR 0.04 --> Loss 0.00334758996964\n",
      "Epoch 27::Minibatch 871::LR 0.04 --> Loss 0.00157981773218\n",
      "Epoch 27::Minibatch 872::LR 0.04 --> Loss 0.00217195967833\n",
      "Epoch 27::Minibatch 873::LR 0.04 --> Loss 0.00245288570722\n",
      "Epoch 27::Minibatch 874::LR 0.04 --> Loss 0.00552899638812\n",
      "Epoch 27::Minibatch 875::LR 0.04 --> Loss 0.000574441999197\n",
      "Epoch 27::Minibatch 876::LR 0.04 --> Loss 0.00286577324073\n",
      "Epoch 27::Minibatch 877::LR 0.04 --> Loss 0.00503281076749\n",
      "Epoch 27::Minibatch 878::LR 0.04 --> Loss 0.00306059539318\n",
      "Epoch 27::Minibatch 879::LR 0.04 --> Loss 0.00394746661186\n",
      "Epoch 27::Minibatch 880::LR 0.04 --> Loss 0.00484168410301\n",
      "Epoch 27::Minibatch 881::LR 0.04 --> Loss 0.00424813906352\n",
      "Epoch 27::Minibatch 882::LR 0.04 --> Loss 0.00193068663279\n",
      "Epoch 27::Minibatch 883::LR 0.04 --> Loss 0.003537063996\n",
      "Epoch 27::Minibatch 884::LR 0.04 --> Loss 0.00275552868843\n",
      "Epoch 27::Minibatch 885::LR 0.04 --> Loss 0.00256936967373\n",
      "Epoch 27::Minibatch 886::LR 0.04 --> Loss 0.00044502188762\n",
      "Epoch 27::Minibatch 887::LR 0.04 --> Loss 0.00533774892489\n",
      "Epoch 27::Minibatch 888::LR 0.04 --> Loss 0.00249860187372\n",
      "Epoch 27::Minibatch 889::LR 0.04 --> Loss 0.00258863071601\n",
      "Epoch 27::Minibatch 890::LR 0.04 --> Loss 0.00377083738645\n",
      "Epoch 27::Minibatch 891::LR 0.04 --> Loss 0.001755468448\n",
      "Epoch 27::Minibatch 892::LR 0.04 --> Loss 0.000809939006964\n",
      "Epoch 27::Minibatch 893::LR 0.04 --> Loss 0.00231299022834\n",
      "Epoch 27::Minibatch 894::LR 0.04 --> Loss 0.00203730642796\n",
      "Epoch 27::Minibatch 895::LR 0.04 --> Loss 0.00230684439341\n",
      "Epoch 27::Minibatch 896::LR 0.04 --> Loss 0.00123973657688\n",
      "Epoch 27::Minibatch 897::LR 0.04 --> Loss 0.000680654893319\n",
      "Epoch 27::Minibatch 898::LR 0.04 --> Loss 0.00203026294708\n",
      "Epoch 27::Minibatch 899::LR 0.04 --> Loss 0.00245803296566\n",
      "Epoch 27::Minibatch 900::LR 0.04 --> Loss 0.00311633229256\n",
      "Epoch 27::Minibatch 901::LR 0.04 --> Loss 0.000584055781364\n",
      "Epoch 27::Minibatch 902::LR 0.04 --> Loss 0.00139924754699\n",
      "Epoch 27::Minibatch 903::LR 0.04 --> Loss 0.00252706070741\n",
      "Epoch 27::Minibatch 904::LR 0.04 --> Loss 0.00182520290216\n",
      "Epoch 27::Minibatch 905::LR 0.04 --> Loss 0.00140612939994\n",
      "Epoch 27::Minibatch 906::LR 0.04 --> Loss 0.00103838205338\n",
      "Epoch 27::Minibatch 907::LR 0.04 --> Loss 0.00155772874753\n",
      "Epoch 27::Minibatch 908::LR 0.04 --> Loss 0.0020903925101\n",
      "Epoch 27::Minibatch 909::LR 0.04 --> Loss 0.00194144864877\n",
      "Epoch 27::Minibatch 910::LR 0.04 --> Loss 0.000837726891041\n",
      "Epoch 27::Minibatch 911::LR 0.04 --> Loss 0.00125476519267\n",
      "Epoch 27::Minibatch 912::LR 0.04 --> Loss 0.0020186885198\n",
      "Epoch 27::Minibatch 913::LR 0.04 --> Loss 0.00221626003583\n",
      "Epoch 27::Minibatch 914::LR 0.04 --> Loss 0.00120252708594\n",
      "Epoch 27::Minibatch 915::LR 0.04 --> Loss 0.000511442025503\n",
      "Epoch 27::Minibatch 916::LR 0.04 --> Loss 0.0021135699749\n",
      "Epoch 27::Minibatch 917::LR 0.04 --> Loss 0.00342955470085\n",
      "Epoch 27::Minibatch 918::LR 0.04 --> Loss 0.00533267299334\n",
      "Epoch 27::Minibatch 919::LR 0.04 --> Loss 0.000534581790368\n",
      "Epoch 27::Minibatch 920::LR 0.04 --> Loss 0.0125488042831\n",
      "Epoch 27::Minibatch 921::LR 0.04 --> Loss 0.00288052260876\n",
      "Epoch 27::Minibatch 922::LR 0.04 --> Loss 0.002946870327\n",
      "Epoch 27::Minibatch 923::LR 0.04 --> Loss 0.00127066334089\n",
      "Epoch 27::Minibatch 924::LR 0.04 --> Loss 0.00324777662754\n",
      "Epoch 27::Minibatch 925::LR 0.04 --> Loss 0.00220545152823\n",
      "Epoch 27::Minibatch 926::LR 0.04 --> Loss 0.00488129337629\n",
      "Epoch 27::Minibatch 927::LR 0.04 --> Loss 0.0059645152092\n",
      "Epoch 27::Minibatch 928::LR 0.04 --> Loss 0.00607177575429\n",
      "Epoch 27::Minibatch 929::LR 0.04 --> Loss 0.00573129653931\n",
      "Epoch 27::Minibatch 930::LR 0.04 --> Loss 0.00889211972555\n",
      "Epoch 27::Minibatch 931::LR 0.04 --> Loss 0.00313348174095\n",
      "Epoch 27::Minibatch 932::LR 0.04 --> Loss 0.0056718591849\n",
      "Epoch 27::Minibatch 933::LR 0.04 --> Loss 0.00267012655735\n",
      "Epoch 27::Minibatch 934::LR 0.04 --> Loss 0.00348651210467\n",
      "Epoch 27::Minibatch 935::LR 0.04 --> Loss 0.00509098132451\n",
      "Epoch 27::Minibatch 936::LR 0.04 --> Loss 0.00107658068339\n",
      "Epoch 27::Minibatch 937::LR 0.04 --> Loss 0.00265861352285\n",
      "Epoch 27::Minibatch 938::LR 0.04 --> Loss 0.00231279015541\n",
      "Epoch 27::Minibatch 939::LR 0.04 --> Loss 0.00245393157005\n",
      "Epoch 27::Minibatch 940::LR 0.04 --> Loss 0.000949827531974\n",
      "Epoch 27::Minibatch 941::LR 0.04 --> Loss 0.000778759072224\n",
      "Epoch 27::Minibatch 942::LR 0.04 --> Loss 0.00247370739778\n",
      "Epoch 27::Minibatch 943::LR 0.04 --> Loss 0.00248235523701\n",
      "Epoch 27::Minibatch 944::LR 0.04 --> Loss 0.00179703255494\n",
      "Epoch 27::Minibatch 945::LR 0.04 --> Loss 0.00102909316619\n",
      "Epoch 27::Minibatch 946::LR 0.04 --> Loss 0.00260863820712\n",
      "Epoch 27::Minibatch 947::LR 0.04 --> Loss 0.0023801112175\n",
      "Epoch 27::Minibatch 948::LR 0.04 --> Loss 0.00439716537793\n",
      "Epoch 27::Minibatch 949::LR 0.04 --> Loss 0.00175922056039\n",
      "Epoch 27::Minibatch 950::LR 0.04 --> Loss 0.000714883903662\n",
      "Epoch 27::Minibatch 951::LR 0.04 --> Loss 0.00336645881335\n",
      "Epoch 27::Minibatch 952::LR 0.04 --> Loss 0.00235833982627\n",
      "Epoch 27::Minibatch 953::LR 0.04 --> Loss 0.00140390833219\n",
      "Epoch 27::Minibatch 954::LR 0.04 --> Loss 0.000949016014735\n",
      "Epoch 27::Minibatch 955::LR 0.04 --> Loss 0.00253367900848\n",
      "Epoch 27::Minibatch 956::LR 0.04 --> Loss 0.00327086985111\n",
      "Epoch 27::Minibatch 957::LR 0.04 --> Loss 0.00182833830516\n",
      "Epoch 27::Minibatch 958::LR 0.04 --> Loss 0.00219231983026\n",
      "Epoch 27::Minibatch 959::LR 0.04 --> Loss 0.00261517484983\n",
      "Epoch 27::Minibatch 960::LR 0.04 --> Loss 0.00563247760137\n",
      "Epoch 27::Minibatch 961::LR 0.04 --> Loss 0.00309552570184\n",
      "Epoch 27::Minibatch 962::LR 0.04 --> Loss 0.00253930528959\n",
      "Epoch 27::Minibatch 963::LR 0.04 --> Loss 0.00104534218709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27::Minibatch 964::LR 0.04 --> Loss 0.00234638392925\n",
      "Epoch 27::Minibatch 965::LR 0.04 --> Loss 0.00660334904989\n",
      "Epoch 27::Minibatch 966::LR 0.04 --> Loss 0.00493041872978\n",
      "Epoch 27::Minibatch 967::LR 0.04 --> Loss 0.00132820357879\n",
      "Epoch 27::Minibatch 968::LR 0.04 --> Loss 0.00113584955533\n",
      "Epoch 27::Minibatch 969::LR 0.04 --> Loss 0.00514689167341\n",
      "Epoch 27::Minibatch 970::LR 0.04 --> Loss 0.00491505503654\n",
      "Epoch 27::Minibatch 971::LR 0.04 --> Loss 0.00338063279788\n",
      "Epoch 27::Minibatch 972::LR 0.04 --> Loss 0.00901101191839\n",
      "Epoch 27::Minibatch 973::LR 0.04 --> Loss 0.00909150044123\n",
      "Epoch 27::Minibatch 974::LR 0.04 --> Loss 0.00826768080393\n",
      "Epoch 27::Minibatch 975::LR 0.04 --> Loss 0.00438655177752\n",
      "Epoch 27::Minibatch 976::LR 0.04 --> Loss 0.00377830386162\n",
      "Epoch 27::Minibatch 977::LR 0.04 --> Loss 0.00362097859383\n",
      "Epoch 27::Minibatch 978::LR 0.04 --> Loss 0.00357677896818\n",
      "Epoch 27::Minibatch 979::LR 0.04 --> Loss 0.00339988271395\n",
      "Epoch 27::Minibatch 980::LR 0.04 --> Loss 0.00365702549616\n",
      "Epoch 27::Minibatch 981::LR 0.04 --> Loss 0.00466231743495\n",
      "Epoch 27::Minibatch 982::LR 0.04 --> Loss 0.00513065656026\n",
      "Epoch 27::Minibatch 983::LR 0.04 --> Loss 0.00271514395873\n",
      "Epoch 27::Minibatch 984::LR 0.04 --> Loss 0.00202926476796\n",
      "Epoch 27::Minibatch 985::LR 0.04 --> Loss 0.0037126382192\n",
      "Epoch 27::Minibatch 986::LR 0.04 --> Loss 0.00339620749156\n",
      "Epoch 27::Minibatch 987::LR 0.04 --> Loss 0.00367784063021\n",
      "Epoch 27::Minibatch 988::LR 0.04 --> Loss 0.00294182399909\n",
      "Epoch 27::Minibatch 989::LR 0.04 --> Loss 0.00317244966825\n",
      "Epoch 27::Minibatch 990::LR 0.04 --> Loss 0.00291610320409\n",
      "Epoch 27::Minibatch 991::LR 0.04 --> Loss 0.00152611931165\n",
      "Epoch 27::Minibatch 992::LR 0.04 --> Loss 0.00171987334887\n",
      "Epoch 27::Minibatch 993::LR 0.04 --> Loss 0.00318347732226\n",
      "Epoch 27::Minibatch 994::LR 0.04 --> Loss 0.00205774068832\n",
      "Epoch 27::Minibatch 995::LR 0.04 --> Loss 0.000833269556363\n",
      "Epoch 27::Minibatch 996::LR 0.04 --> Loss 0.00280643165112\n",
      "Epoch 27::Minibatch 997::LR 0.04 --> Loss 0.00222147802512\n",
      "Epoch 27::Minibatch 998::LR 0.04 --> Loss 0.00252382357915\n",
      "Epoch 27::Minibatch 999::LR 0.04 --> Loss 0.00213593065739\n",
      "Epoch 27::Minibatch 1000::LR 0.04 --> Loss 0.00254304091136\n",
      "Epoch 27::Minibatch 1001::LR 0.04 --> Loss 0.00202976425489\n",
      "Epoch 27::Minibatch 1002::LR 0.04 --> Loss 0.00176546136538\n",
      "Epoch 27::Minibatch 1003::LR 0.04 --> Loss 0.00278089821339\n",
      "Epoch 27::Minibatch 1004::LR 0.04 --> Loss 0.00107394993305\n",
      "Epoch 27::Minibatch 1005::LR 0.04 --> Loss 0.00277774771055\n",
      "Epoch 27::Minibatch 1006::LR 0.04 --> Loss 0.00148188879093\n",
      "Epoch 27::Minibatch 1007::LR 0.04 --> Loss 0.00191983640194\n",
      "Epoch 27::Minibatch 1008::LR 0.04 --> Loss 0.000938387016455\n",
      "Epoch 27::Minibatch 1009::LR 0.04 --> Loss 0.0012698551019\n",
      "Epoch 27::Minibatch 1010::LR 0.04 --> Loss 0.00115715066592\n",
      "Epoch 27::Minibatch 1011::LR 0.04 --> Loss 0.00191278239091\n",
      "Epoch 27::Minibatch 1012::LR 0.04 --> Loss 0.00144733905792\n",
      "Epoch 27::Minibatch 1013::LR 0.04 --> Loss 0.00371432264646\n",
      "Epoch 27::Minibatch 1014::LR 0.04 --> Loss 0.00348066449165\n",
      "Epoch 27::Minibatch 1015::LR 0.04 --> Loss 0.00156805266937\n",
      "Epoch 27::Minibatch 1016::LR 0.04 --> Loss 0.00461553454399\n",
      "Epoch 27::Minibatch 1017::LR 0.04 --> Loss 0.00306678553422\n",
      "Epoch 27::Minibatch 1018::LR 0.04 --> Loss 0.00261936227481\n",
      "Epoch 27::Minibatch 1019::LR 0.04 --> Loss 0.00168891489506\n",
      "Epoch 27::Minibatch 1020::LR 0.04 --> Loss 0.0017790522178\n",
      "Epoch 27::Minibatch 1021::LR 0.04 --> Loss 0.00187905510267\n",
      "Epoch 27::Minibatch 1022::LR 0.04 --> Loss 0.00139759858449\n",
      "Epoch 27::Minibatch 1023::LR 0.04 --> Loss 0.00105489482482\n",
      "Epoch 27::Minibatch 1024::LR 0.04 --> Loss 0.00104470938444\n",
      "Epoch 27::Minibatch 1025::LR 0.04 --> Loss 0.00137841840585\n",
      "Epoch 27::Minibatch 1026::LR 0.04 --> Loss 0.000731116334597\n",
      "Epoch 27::Minibatch 1027::LR 0.04 --> Loss 0.000989249845346\n",
      "Epoch 27::Minibatch 1028::LR 0.04 --> Loss 0.000750306646029\n",
      "Epoch 27::Minibatch 1029::LR 0.04 --> Loss 0.000749927610159\n",
      "Epoch 27::Minibatch 1030::LR 0.04 --> Loss 0.000922590990861\n",
      "Epoch 27::Minibatch 1031::LR 0.04 --> Loss 0.000712075630824\n",
      "Epoch 27::Minibatch 1032::LR 0.04 --> Loss 0.000778590341409\n",
      "Epoch 27::Minibatch 1033::LR 0.04 --> Loss 0.00066159705321\n",
      "Epoch 27::Minibatch 1034::LR 0.04 --> Loss 0.000630635172129\n",
      "Epoch 27::Minibatch 1035::LR 0.04 --> Loss 0.000419635375341\n",
      "Epoch 27::Minibatch 1036::LR 0.04 --> Loss 0.000336451381445\n",
      "Epoch 27::Minibatch 1037::LR 0.04 --> Loss 0.000594862550497\n",
      "Epoch 27::Minibatch 1038::LR 0.04 --> Loss 0.00115296234687\n",
      "Epoch 27::Minibatch 1039::LR 0.04 --> Loss 0.000902259945869\n",
      "Epoch 27::Minibatch 1040::LR 0.04 --> Loss 0.000358439857761\n",
      "Epoch 27::Minibatch 1041::LR 0.04 --> Loss 0.000516885022322\n",
      "Epoch 28::Minibatch 1::LR 0.0376923076923 --> Loss 0.00804338296254\n",
      "Epoch 28::Minibatch 2::LR 0.0376923076923 --> Loss 0.00512604554494\n",
      "Epoch 28::Minibatch 3::LR 0.0376923076923 --> Loss 0.00327495038509\n",
      "Epoch 28::Minibatch 4::LR 0.0376923076923 --> Loss 0.00394580523173\n",
      "Epoch 28::Minibatch 5::LR 0.0376923076923 --> Loss 0.00447495738665\n",
      "Epoch 28::Minibatch 6::LR 0.0376923076923 --> Loss 0.00215692599614\n",
      "Epoch 28::Minibatch 7::LR 0.0376923076923 --> Loss 0.00731896479925\n",
      "Epoch 28::Minibatch 8::LR 0.0376923076923 --> Loss 0.00684791644414\n",
      "Epoch 28::Minibatch 9::LR 0.0376923076923 --> Loss 0.00525075872739\n",
      "Epoch 28::Minibatch 10::LR 0.0376923076923 --> Loss 0.00247716804345\n",
      "Epoch 28::Minibatch 11::LR 0.0376923076923 --> Loss 0.00228244066238\n",
      "Epoch 28::Minibatch 12::LR 0.0376923076923 --> Loss 0.00340763489405\n",
      "Epoch 28::Minibatch 13::LR 0.0376923076923 --> Loss 0.00531915346781\n",
      "Epoch 28::Minibatch 14::LR 0.0376923076923 --> Loss 0.00529223402341\n",
      "Epoch 28::Minibatch 15::LR 0.0376923076923 --> Loss 0.00454356233279\n",
      "Epoch 28::Minibatch 16::LR 0.0376923076923 --> Loss 0.00075066447258\n",
      "Epoch 28::Minibatch 17::LR 0.0376923076923 --> Loss 0.00317249874274\n",
      "Epoch 28::Minibatch 18::LR 0.0376923076923 --> Loss 0.00260895808538\n",
      "Epoch 28::Minibatch 19::LR 0.0376923076923 --> Loss 0.00151073366404\n",
      "Epoch 28::Minibatch 20::LR 0.0376923076923 --> Loss 0.00202980399132\n",
      "Epoch 28::Minibatch 21::LR 0.0376923076923 --> Loss 0.00334358493487\n",
      "Epoch 28::Minibatch 22::LR 0.0376923076923 --> Loss 0.00223091463248\n",
      "Epoch 28::Minibatch 23::LR 0.0376923076923 --> Loss 0.000870656967163\n",
      "Epoch 28::Minibatch 24::LR 0.0376923076923 --> Loss 0.000461540122827\n",
      "Epoch 28::Minibatch 25::LR 0.0376923076923 --> Loss 0.00127189646165\n",
      "Epoch 28::Minibatch 26::LR 0.0376923076923 --> Loss 0.00147093653679\n",
      "Epoch 28::Minibatch 27::LR 0.0376923076923 --> Loss 0.00107368439436\n",
      "Epoch 28::Minibatch 28::LR 0.0376923076923 --> Loss 0.000467070738475\n",
      "Epoch 28::Minibatch 29::LR 0.0376923076923 --> Loss 0.000534595201413\n",
      "Epoch 28::Minibatch 30::LR 0.0376923076923 --> Loss 0.00101836154858\n",
      "Epoch 28::Minibatch 31::LR 0.0376923076923 --> Loss 0.00150817225377\n",
      "Epoch 28::Minibatch 32::LR 0.0376923076923 --> Loss 0.00135267963012\n",
      "Epoch 28::Minibatch 33::LR 0.0376923076923 --> Loss 0.000794037381808\n",
      "Epoch 28::Minibatch 34::LR 0.0376923076923 --> Loss 0.00208894709746\n",
      "Epoch 28::Minibatch 35::LR 0.0376923076923 --> Loss 0.00319534480572\n",
      "Epoch 28::Minibatch 36::LR 0.0376923076923 --> Loss 0.00224447866281\n",
      "Epoch 28::Minibatch 37::LR 0.0376923076923 --> Loss 0.000685157626867\n",
      "Epoch 28::Minibatch 38::LR 0.0376923076923 --> Loss 0.00071910833319\n",
      "Epoch 28::Minibatch 39::LR 0.0376923076923 --> Loss 0.00220105707645\n",
      "Epoch 28::Minibatch 40::LR 0.0376923076923 --> Loss 0.00311686317126\n",
      "Epoch 28::Minibatch 41::LR 0.0376923076923 --> Loss 0.00250228444735\n",
      "Epoch 28::Minibatch 42::LR 0.0376923076923 --> Loss 0.00494923353195\n",
      "Epoch 28::Minibatch 43::LR 0.0376923076923 --> Loss 0.0019689108928\n",
      "Epoch 28::Minibatch 44::LR 0.0376923076923 --> Loss 0.00321215689182\n",
      "Epoch 28::Minibatch 45::LR 0.0376923076923 --> Loss 0.00239255865415\n",
      "Epoch 28::Minibatch 46::LR 0.0376923076923 --> Loss 0.00313401301702\n",
      "Epoch 28::Minibatch 47::LR 0.0376923076923 --> Loss 0.00355792244275\n",
      "Epoch 28::Minibatch 48::LR 0.0376923076923 --> Loss 0.00508948842684\n",
      "Epoch 28::Minibatch 49::LR 0.0376923076923 --> Loss 0.00567762692769\n",
      "Epoch 28::Minibatch 50::LR 0.0376923076923 --> Loss 0.00604509592056\n",
      "Epoch 28::Minibatch 51::LR 0.0376923076923 --> Loss 0.00481916030248\n",
      "Epoch 28::Minibatch 52::LR 0.0376923076923 --> Loss 0.00342853585879\n",
      "Epoch 28::Minibatch 53::LR 0.0376923076923 --> Loss 0.00337889472644\n",
      "Epoch 28::Minibatch 54::LR 0.0376923076923 --> Loss 0.00399728099505\n",
      "Epoch 28::Minibatch 55::LR 0.0376923076923 --> Loss 0.000988862415155\n",
      "Epoch 28::Minibatch 56::LR 0.0376923076923 --> Loss 0.00271493534247\n",
      "Epoch 28::Minibatch 57::LR 0.0376923076923 --> Loss 0.00477676033974\n",
      "Epoch 28::Minibatch 58::LR 0.0376923076923 --> Loss 0.00322695672512\n",
      "Epoch 28::Minibatch 59::LR 0.0376923076923 --> Loss 0.00243299822013\n",
      "Epoch 28::Minibatch 60::LR 0.0376923076923 --> Loss 0.00244818429152\n",
      "Epoch 28::Minibatch 61::LR 0.0376923076923 --> Loss 0.000745918403069\n",
      "Epoch 28::Minibatch 62::LR 0.0376923076923 --> Loss 0.00263686776161\n",
      "Epoch 28::Minibatch 63::LR 0.0376923076923 --> Loss 0.00201308210691\n",
      "Epoch 28::Minibatch 64::LR 0.0376923076923 --> Loss 0.000830622712771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 65::LR 0.0376923076923 --> Loss 0.00217636247476\n",
      "Epoch 28::Minibatch 66::LR 0.0376923076923 --> Loss 0.00272441069285\n",
      "Epoch 28::Minibatch 67::LR 0.0376923076923 --> Loss 0.00256657123566\n",
      "Epoch 28::Minibatch 68::LR 0.0376923076923 --> Loss 0.00185453077157\n",
      "Epoch 28::Minibatch 69::LR 0.0376923076923 --> Loss 0.00368654052416\n",
      "Epoch 28::Minibatch 70::LR 0.0376923076923 --> Loss 0.00325941622257\n",
      "Epoch 28::Minibatch 71::LR 0.0376923076923 --> Loss 0.00225585341454\n",
      "Epoch 28::Minibatch 72::LR 0.0376923076923 --> Loss 0.0005404142042\n",
      "Epoch 28::Minibatch 73::LR 0.0376923076923 --> Loss 0.00373655716578\n",
      "Epoch 28::Minibatch 74::LR 0.0376923076923 --> Loss 0.00401681224505\n",
      "Epoch 28::Minibatch 75::LR 0.0376923076923 --> Loss 0.00215708176295\n",
      "Epoch 28::Minibatch 76::LR 0.0376923076923 --> Loss 0.00052805095911\n",
      "Epoch 28::Minibatch 77::LR 0.0376923076923 --> Loss 0.00340330521266\n",
      "Epoch 28::Minibatch 78::LR 0.0376923076923 --> Loss 0.00388686299324\n",
      "Epoch 28::Minibatch 79::LR 0.0376923076923 --> Loss 0.00176157812277\n",
      "Epoch 28::Minibatch 80::LR 0.0376923076923 --> Loss 0.00291592299938\n",
      "Epoch 28::Minibatch 81::LR 0.0376923076923 --> Loss 0.00256549477577\n",
      "Epoch 28::Minibatch 82::LR 0.0376923076923 --> Loss 0.00187073131402\n",
      "Epoch 28::Minibatch 83::LR 0.0376923076923 --> Loss 0.00402010361354\n",
      "Epoch 28::Minibatch 84::LR 0.0376923076923 --> Loss 0.00188211699327\n",
      "Epoch 28::Minibatch 85::LR 0.0376923076923 --> Loss 0.00257764836152\n",
      "Epoch 28::Minibatch 86::LR 0.0376923076923 --> Loss 0.00210960507393\n",
      "Epoch 28::Minibatch 87::LR 0.0376923076923 --> Loss 0.00225772102674\n",
      "Epoch 28::Minibatch 88::LR 0.0376923076923 --> Loss 0.00168451786041\n",
      "Epoch 28::Minibatch 89::LR 0.0376923076923 --> Loss 0.00221452732881\n",
      "Epoch 28::Minibatch 90::LR 0.0376923076923 --> Loss 0.00105056077242\n",
      "Epoch 28::Minibatch 91::LR 0.0376923076923 --> Loss 0.000867408216\n",
      "Epoch 28::Minibatch 92::LR 0.0376923076923 --> Loss 0.00257933457692\n",
      "Epoch 28::Minibatch 93::LR 0.0376923076923 --> Loss 0.00170600473881\n",
      "Epoch 28::Minibatch 94::LR 0.0376923076923 --> Loss 0.00174038310846\n",
      "Epoch 28::Minibatch 95::LR 0.0376923076923 --> Loss 0.00187675217787\n",
      "Epoch 28::Minibatch 96::LR 0.0376923076923 --> Loss 0.0049797129631\n",
      "Epoch 28::Minibatch 97::LR 0.0376923076923 --> Loss 0.00304048617681\n",
      "Epoch 28::Minibatch 98::LR 0.0376923076923 --> Loss 0.00105264504751\n",
      "Epoch 28::Minibatch 99::LR 0.0376923076923 --> Loss 0.00137499213219\n",
      "Epoch 28::Minibatch 100::LR 0.0376923076923 --> Loss 0.00441263596217\n",
      "Epoch 28::Minibatch 101::LR 0.0376923076923 --> Loss 0.000899631480376\n",
      "Epoch 28::Minibatch 102::LR 0.0376923076923 --> Loss 0.00387926300367\n",
      "Epoch 28::Minibatch 103::LR 0.0376923076923 --> Loss 0.00392297705015\n",
      "Epoch 28::Minibatch 104::LR 0.0376923076923 --> Loss 0.00267426331838\n",
      "Epoch 28::Minibatch 105::LR 0.0376923076923 --> Loss 0.0022159041961\n",
      "Epoch 28::Minibatch 106::LR 0.0376923076923 --> Loss 0.0147220404943\n",
      "Epoch 28::Minibatch 107::LR 0.0376923076923 --> Loss 0.0047857216994\n",
      "Epoch 28::Minibatch 108::LR 0.0376923076923 --> Loss 0.000946167906125\n",
      "Epoch 28::Minibatch 109::LR 0.0376923076923 --> Loss 0.00429431756337\n",
      "Epoch 28::Minibatch 110::LR 0.0376923076923 --> Loss 0.00223531206449\n",
      "Epoch 28::Minibatch 111::LR 0.0376923076923 --> Loss 0.000838144818942\n",
      "Epoch 28::Minibatch 112::LR 0.0376923076923 --> Loss 0.00331829388936\n",
      "Epoch 28::Minibatch 113::LR 0.0376923076923 --> Loss 0.00242745975653\n",
      "Epoch 28::Minibatch 114::LR 0.0376923076923 --> Loss 0.00135315040747\n",
      "Epoch 28::Minibatch 115::LR 0.0376923076923 --> Loss 0.00116779615482\n",
      "Epoch 28::Minibatch 116::LR 0.0376923076923 --> Loss 0.00263901551565\n",
      "Epoch 28::Minibatch 117::LR 0.0376923076923 --> Loss 0.00399298111598\n",
      "Epoch 28::Minibatch 118::LR 0.0376923076923 --> Loss 0.0066331688563\n",
      "Epoch 28::Minibatch 119::LR 0.0376923076923 --> Loss 0.000523919264476\n",
      "Epoch 28::Minibatch 120::LR 0.0376923076923 --> Loss 0.00163349012534\n",
      "Epoch 28::Minibatch 121::LR 0.0376923076923 --> Loss 0.00240628818671\n",
      "Epoch 28::Minibatch 122::LR 0.0376923076923 --> Loss 0.00378477096558\n",
      "Epoch 28::Minibatch 123::LR 0.0376923076923 --> Loss 0.000747183412313\n",
      "Epoch 28::Minibatch 124::LR 0.0376923076923 --> Loss 0.00260941247145\n",
      "Epoch 28::Minibatch 125::LR 0.0376923076923 --> Loss 0.00444517175357\n",
      "Epoch 28::Minibatch 126::LR 0.0376923076923 --> Loss 0.00250363965829\n",
      "Epoch 28::Minibatch 127::LR 0.0376923076923 --> Loss 0.00467311104139\n",
      "Epoch 28::Minibatch 128::LR 0.0376923076923 --> Loss 0.0035319407781\n",
      "Epoch 28::Minibatch 129::LR 0.0376923076923 --> Loss 0.00246488948663\n",
      "Epoch 28::Minibatch 130::LR 0.0376923076923 --> Loss 0.00432521303495\n",
      "Epoch 28::Minibatch 131::LR 0.0376923076923 --> Loss 0.0017251487573\n",
      "Epoch 28::Minibatch 132::LR 0.0376923076923 --> Loss 0.00288134276867\n",
      "Epoch 28::Minibatch 133::LR 0.0376923076923 --> Loss 0.00276153961817\n",
      "Epoch 28::Minibatch 134::LR 0.0376923076923 --> Loss 0.00216598490874\n",
      "Epoch 28::Minibatch 135::LR 0.0376923076923 --> Loss 0.0013483547171\n",
      "Epoch 28::Minibatch 136::LR 0.0376923076923 --> Loss 0.00249727447828\n",
      "Epoch 28::Minibatch 137::LR 0.0376923076923 --> Loss 0.00346129020055\n",
      "Epoch 28::Minibatch 138::LR 0.0376923076923 --> Loss 0.00123430808385\n",
      "Epoch 28::Minibatch 139::LR 0.0376923076923 --> Loss 0.00188446482023\n",
      "Epoch 28::Minibatch 140::LR 0.0376923076923 --> Loss 0.00240532835325\n",
      "Epoch 28::Minibatch 141::LR 0.0376923076923 --> Loss 0.00291464209557\n",
      "Epoch 28::Minibatch 142::LR 0.0376923076923 --> Loss 0.00271999955177\n",
      "Epoch 28::Minibatch 143::LR 0.0376923076923 --> Loss 0.000554393629233\n",
      "Epoch 28::Minibatch 144::LR 0.0376923076923 --> Loss 0.0033192884922\n",
      "Epoch 28::Minibatch 145::LR 0.0376923076923 --> Loss 0.0041627629598\n",
      "Epoch 28::Minibatch 146::LR 0.0376923076923 --> Loss 0.00251210014025\n",
      "Epoch 28::Minibatch 147::LR 0.0376923076923 --> Loss 0.00179077823957\n",
      "Epoch 28::Minibatch 148::LR 0.0376923076923 --> Loss 0.000981999337673\n",
      "Epoch 28::Minibatch 149::LR 0.0376923076923 --> Loss 0.00284473558267\n",
      "Epoch 28::Minibatch 150::LR 0.0376923076923 --> Loss 0.00267083128293\n",
      "Epoch 28::Minibatch 151::LR 0.0376923076923 --> Loss 0.00426191528638\n",
      "Epoch 28::Minibatch 152::LR 0.0376923076923 --> Loss 0.000906546413898\n",
      "Epoch 28::Minibatch 153::LR 0.0376923076923 --> Loss 0.00168237229188\n",
      "Epoch 28::Minibatch 154::LR 0.0376923076923 --> Loss 0.00202070613702\n",
      "Epoch 28::Minibatch 155::LR 0.0376923076923 --> Loss 0.00417474150658\n",
      "Epoch 28::Minibatch 156::LR 0.0376923076923 --> Loss 0.00236055175463\n",
      "Epoch 28::Minibatch 157::LR 0.0376923076923 --> Loss 0.000689402619998\n",
      "Epoch 28::Minibatch 158::LR 0.0376923076923 --> Loss 0.00312389115493\n",
      "Epoch 28::Minibatch 159::LR 0.0376923076923 --> Loss 0.00272824347019\n",
      "Epoch 28::Minibatch 160::LR 0.0376923076923 --> Loss 0.00263629396756\n",
      "Epoch 28::Minibatch 161::LR 0.0376923076923 --> Loss 0.00100652267536\n",
      "Epoch 28::Minibatch 162::LR 0.0376923076923 --> Loss 0.00388030131658\n",
      "Epoch 28::Minibatch 163::LR 0.0376923076923 --> Loss 0.00239193856716\n",
      "Epoch 28::Minibatch 164::LR 0.0376923076923 --> Loss 0.00251339972019\n",
      "Epoch 28::Minibatch 165::LR 0.0376923076923 --> Loss 0.00050630564491\n",
      "Epoch 28::Minibatch 166::LR 0.0376923076923 --> Loss 0.00172752797604\n",
      "Epoch 28::Minibatch 167::LR 0.0376923076923 --> Loss 0.00246356825034\n",
      "Epoch 28::Minibatch 168::LR 0.0376923076923 --> Loss 0.00215032140414\n",
      "Epoch 28::Minibatch 169::LR 0.0376923076923 --> Loss 0.000997304916382\n",
      "Epoch 28::Minibatch 170::LR 0.0376923076923 --> Loss 0.000965469976266\n",
      "Epoch 28::Minibatch 171::LR 0.0376923076923 --> Loss 0.00250118335088\n",
      "Epoch 28::Minibatch 172::LR 0.0376923076923 --> Loss 0.00426703174909\n",
      "Epoch 28::Minibatch 173::LR 0.0376923076923 --> Loss 0.00197016000748\n",
      "Epoch 28::Minibatch 174::LR 0.0376923076923 --> Loss 0.000982476472855\n",
      "Epoch 28::Minibatch 175::LR 0.0376923076923 --> Loss 0.00233383238316\n",
      "Epoch 28::Minibatch 176::LR 0.0376923076923 --> Loss 0.00316860318184\n",
      "Epoch 28::Minibatch 177::LR 0.0376923076923 --> Loss 0.00434596419334\n",
      "Epoch 28::Minibatch 178::LR 0.0376923076923 --> Loss 0.00154654512803\n",
      "Epoch 28::Minibatch 179::LR 0.0376923076923 --> Loss 0.00126074155172\n",
      "Epoch 28::Minibatch 180::LR 0.0376923076923 --> Loss 0.00346813122431\n",
      "Epoch 28::Minibatch 181::LR 0.0376923076923 --> Loss 0.00311313033104\n",
      "Epoch 28::Minibatch 182::LR 0.0376923076923 --> Loss 0.000728366126617\n",
      "Epoch 28::Minibatch 183::LR 0.0376923076923 --> Loss 0.00160576572021\n",
      "Epoch 28::Minibatch 184::LR 0.0376923076923 --> Loss 0.00341718236605\n",
      "Epoch 28::Minibatch 185::LR 0.0376923076923 --> Loss 0.00274371405443\n",
      "Epoch 28::Minibatch 186::LR 0.0376923076923 --> Loss 0.000945535004139\n",
      "Epoch 28::Minibatch 187::LR 0.0376923076923 --> Loss 0.00127775291602\n",
      "Epoch 28::Minibatch 188::LR 0.0376923076923 --> Loss 0.00411425352097\n",
      "Epoch 28::Minibatch 189::LR 0.0376923076923 --> Loss 0.00422667304675\n",
      "Epoch 28::Minibatch 190::LR 0.0376923076923 --> Loss 0.00232337196668\n",
      "Epoch 28::Minibatch 191::LR 0.0376923076923 --> Loss 0.000459252397219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 192::LR 0.0376923076923 --> Loss 0.00276052256425\n",
      "Epoch 28::Minibatch 193::LR 0.0376923076923 --> Loss 0.00265567739805\n",
      "Epoch 28::Minibatch 194::LR 0.0376923076923 --> Loss 0.00175314525763\n",
      "Epoch 28::Minibatch 195::LR 0.0376923076923 --> Loss 0.000379709204038\n",
      "Epoch 28::Minibatch 196::LR 0.0376923076923 --> Loss 0.00131647030512\n",
      "Epoch 28::Minibatch 197::LR 0.0376923076923 --> Loss 0.00293653210004\n",
      "Epoch 28::Minibatch 198::LR 0.0376923076923 --> Loss 0.00227666358153\n",
      "Epoch 28::Minibatch 199::LR 0.0376923076923 --> Loss 0.000290173366666\n",
      "Epoch 28::Minibatch 200::LR 0.0376923076923 --> Loss 0.00204187750816\n",
      "Epoch 28::Minibatch 201::LR 0.0376923076923 --> Loss 0.00193661530813\n",
      "Epoch 28::Minibatch 202::LR 0.0376923076923 --> Loss 0.00183046440283\n",
      "Epoch 28::Minibatch 203::LR 0.0376923076923 --> Loss 0.00175124704838\n",
      "Epoch 28::Minibatch 204::LR 0.0376923076923 --> Loss 0.00142242322365\n",
      "Epoch 28::Minibatch 205::LR 0.0376923076923 --> Loss 0.00220278759797\n",
      "Epoch 28::Minibatch 206::LR 0.0376923076923 --> Loss 0.0057882742087\n",
      "Epoch 28::Minibatch 207::LR 0.0376923076923 --> Loss 0.00139765699704\n",
      "Epoch 28::Minibatch 208::LR 0.0376923076923 --> Loss 0.00110922048489\n",
      "Epoch 28::Minibatch 209::LR 0.0376923076923 --> Loss 0.00239264567693\n",
      "Epoch 28::Minibatch 210::LR 0.0376923076923 --> Loss 0.00226792991161\n",
      "Epoch 28::Minibatch 211::LR 0.0376923076923 --> Loss 0.00254579683145\n",
      "Epoch 28::Minibatch 212::LR 0.0376923076923 --> Loss 0.00382314483325\n",
      "Epoch 28::Minibatch 213::LR 0.0376923076923 --> Loss 0.0055249885718\n",
      "Epoch 28::Minibatch 214::LR 0.0376923076923 --> Loss 0.00773562431335\n",
      "Epoch 28::Minibatch 215::LR 0.0376923076923 --> Loss 0.00136299322049\n",
      "Epoch 28::Minibatch 216::LR 0.0376923076923 --> Loss 0.00535886486371\n",
      "Epoch 28::Minibatch 217::LR 0.0376923076923 --> Loss 0.00595404187838\n",
      "Epoch 28::Minibatch 218::LR 0.0376923076923 --> Loss 0.00390108744303\n",
      "Epoch 28::Minibatch 219::LR 0.0376923076923 --> Loss 0.00433080474536\n",
      "Epoch 28::Minibatch 220::LR 0.0376923076923 --> Loss 0.0043968919913\n",
      "Epoch 28::Minibatch 221::LR 0.0376923076923 --> Loss 0.00424058039983\n",
      "Epoch 28::Minibatch 222::LR 0.0376923076923 --> Loss 0.00318271855513\n",
      "Epoch 28::Minibatch 223::LR 0.0376923076923 --> Loss 0.00139139344295\n",
      "Epoch 28::Minibatch 224::LR 0.0376923076923 --> Loss 0.00163683712482\n",
      "Epoch 28::Minibatch 225::LR 0.0376923076923 --> Loss 0.00763152519862\n",
      "Epoch 28::Minibatch 226::LR 0.0376923076923 --> Loss 0.00370344638824\n",
      "Epoch 28::Minibatch 227::LR 0.0376923076923 --> Loss 0.00168026427428\n",
      "Epoch 28::Minibatch 228::LR 0.0376923076923 --> Loss 0.000676677674055\n",
      "Epoch 28::Minibatch 229::LR 0.0376923076923 --> Loss 0.00471677382787\n",
      "Epoch 28::Minibatch 230::LR 0.0376923076923 --> Loss 0.00376505335172\n",
      "Epoch 28::Minibatch 231::LR 0.0376923076923 --> Loss 0.00265441854795\n",
      "Epoch 28::Minibatch 232::LR 0.0376923076923 --> Loss 0.00117721398671\n",
      "Epoch 28::Minibatch 233::LR 0.0376923076923 --> Loss 0.00244929611683\n",
      "Epoch 28::Minibatch 234::LR 0.0376923076923 --> Loss 0.00719492912292\n",
      "Epoch 28::Minibatch 235::LR 0.0376923076923 --> Loss 0.00457504272461\n",
      "Epoch 28::Minibatch 236::LR 0.0376923076923 --> Loss 0.00170011222363\n",
      "Epoch 28::Minibatch 237::LR 0.0376923076923 --> Loss 0.000616999914249\n",
      "Epoch 28::Minibatch 238::LR 0.0376923076923 --> Loss 0.00341798623403\n",
      "Epoch 28::Minibatch 239::LR 0.0376923076923 --> Loss 0.00295769353708\n",
      "Epoch 28::Minibatch 240::LR 0.0376923076923 --> Loss 0.00324062625567\n",
      "Epoch 28::Minibatch 241::LR 0.0376923076923 --> Loss 0.000745885024468\n",
      "Epoch 28::Minibatch 242::LR 0.0376923076923 --> Loss 0.00680294354757\n",
      "Epoch 28::Minibatch 243::LR 0.0376923076923 --> Loss 0.0033407886823\n",
      "Epoch 28::Minibatch 244::LR 0.0376923076923 --> Loss 0.00280051887035\n",
      "Epoch 28::Minibatch 245::LR 0.0376923076923 --> Loss 0.000442906320095\n",
      "Epoch 28::Minibatch 246::LR 0.0376923076923 --> Loss 0.0019582871596\n",
      "Epoch 28::Minibatch 247::LR 0.0376923076923 --> Loss 0.0112939103444\n",
      "Epoch 28::Minibatch 248::LR 0.0376923076923 --> Loss 0.00437739213308\n",
      "Epoch 28::Minibatch 249::LR 0.0376923076923 --> Loss 0.00248592019081\n",
      "Epoch 28::Minibatch 250::LR 0.0376923076923 --> Loss 0.0024017282327\n",
      "Epoch 28::Minibatch 251::LR 0.0376923076923 --> Loss 0.00237929562728\n",
      "Epoch 28::Minibatch 252::LR 0.0376923076923 --> Loss 0.00166000962257\n",
      "Epoch 28::Minibatch 253::LR 0.0376923076923 --> Loss 0.00288869659106\n",
      "Epoch 28::Minibatch 254::LR 0.0376923076923 --> Loss 0.00491211613019\n",
      "Epoch 28::Minibatch 255::LR 0.0376923076923 --> Loss 0.00383538126945\n",
      "Epoch 28::Minibatch 256::LR 0.0376923076923 --> Loss 0.00146833012501\n",
      "Epoch 28::Minibatch 257::LR 0.0376923076923 --> Loss 0.00115970472495\n",
      "Epoch 28::Minibatch 258::LR 0.0376923076923 --> Loss 0.00364064653714\n",
      "Epoch 28::Minibatch 259::LR 0.0376923076923 --> Loss 0.00165283530951\n",
      "Epoch 28::Minibatch 260::LR 0.0376923076923 --> Loss 0.00185577193896\n",
      "Epoch 28::Minibatch 261::LR 0.0376923076923 --> Loss 0.00271862149239\n",
      "Epoch 28::Minibatch 262::LR 0.0376923076923 --> Loss 0.00184612572193\n",
      "Epoch 28::Minibatch 263::LR 0.0376923076923 --> Loss 0.00231110433737\n",
      "Epoch 28::Minibatch 264::LR 0.0376923076923 --> Loss 0.00357933719953\n",
      "Epoch 28::Minibatch 265::LR 0.0376923076923 --> Loss 0.00996240297953\n",
      "Epoch 28::Minibatch 266::LR 0.0376923076923 --> Loss 0.000925854841868\n",
      "Epoch 28::Minibatch 267::LR 0.0376923076923 --> Loss 0.0093656206131\n",
      "Epoch 28::Minibatch 268::LR 0.0376923076923 --> Loss 0.00108360787233\n",
      "Epoch 28::Minibatch 269::LR 0.0376923076923 --> Loss 0.00346793015798\n",
      "Epoch 28::Minibatch 270::LR 0.0376923076923 --> Loss 0.00707285563151\n",
      "Epoch 28::Minibatch 271::LR 0.0376923076923 --> Loss 0.00251522481441\n",
      "Epoch 28::Minibatch 272::LR 0.0376923076923 --> Loss 0.00431264718374\n",
      "Epoch 28::Minibatch 273::LR 0.0376923076923 --> Loss 0.00147300332785\n",
      "Epoch 28::Minibatch 274::LR 0.0376923076923 --> Loss 0.001780646046\n",
      "Epoch 28::Minibatch 275::LR 0.0376923076923 --> Loss 0.00252536177635\n",
      "Epoch 28::Minibatch 276::LR 0.0376923076923 --> Loss 0.00339573661486\n",
      "Epoch 28::Minibatch 277::LR 0.0376923076923 --> Loss 0.000911053021749\n",
      "Epoch 28::Minibatch 278::LR 0.0376923076923 --> Loss 0.00257329543432\n",
      "Epoch 28::Minibatch 279::LR 0.0376923076923 --> Loss 0.00212179819743\n",
      "Epoch 28::Minibatch 280::LR 0.0376923076923 --> Loss 0.00186825652917\n",
      "Epoch 28::Minibatch 281::LR 0.0376923076923 --> Loss 0.0011832088232\n",
      "Epoch 28::Minibatch 282::LR 0.0376923076923 --> Loss 0.00209171553453\n",
      "Epoch 28::Minibatch 283::LR 0.0376923076923 --> Loss 0.00200700203578\n",
      "Epoch 28::Minibatch 284::LR 0.0376923076923 --> Loss 0.00162857909997\n",
      "Epoch 28::Minibatch 285::LR 0.0376923076923 --> Loss 0.00116016745567\n",
      "Epoch 28::Minibatch 286::LR 0.0376923076923 --> Loss 0.00202745099862\n",
      "Epoch 28::Minibatch 287::LR 0.0376923076923 --> Loss 0.00199577947458\n",
      "Epoch 28::Minibatch 288::LR 0.0376923076923 --> Loss 0.00108422716459\n",
      "Epoch 28::Minibatch 289::LR 0.0376923076923 --> Loss 0.00158521791299\n",
      "Epoch 28::Minibatch 290::LR 0.0376923076923 --> Loss 0.00188860853513\n",
      "Epoch 28::Minibatch 291::LR 0.0376923076923 --> Loss 0.00169155836105\n",
      "Epoch 28::Minibatch 292::LR 0.0376923076923 --> Loss 0.000596757034461\n",
      "Epoch 28::Minibatch 293::LR 0.0376923076923 --> Loss 0.00150378296773\n",
      "Epoch 28::Minibatch 294::LR 0.0376923076923 --> Loss 0.00160730739435\n",
      "Epoch 28::Minibatch 295::LR 0.0376923076923 --> Loss 0.00188617388407\n",
      "Epoch 28::Minibatch 296::LR 0.0376923076923 --> Loss 0.00163472344478\n",
      "Epoch 28::Minibatch 297::LR 0.0376923076923 --> Loss 0.00142394493024\n",
      "Epoch 28::Minibatch 298::LR 0.0376923076923 --> Loss 0.00142294545968\n",
      "Epoch 28::Minibatch 299::LR 0.0376923076923 --> Loss 0.000813061396281\n",
      "Epoch 28::Minibatch 300::LR 0.0376923076923 --> Loss 0.00272200008233\n",
      "Epoch 28::Minibatch 301::LR 0.0376923076923 --> Loss 0.00263242403666\n",
      "Epoch 28::Minibatch 302::LR 0.0376923076923 --> Loss 0.00241381982962\n",
      "Epoch 28::Minibatch 303::LR 0.0376923076923 --> Loss 0.000841430922349\n",
      "Epoch 28::Minibatch 304::LR 0.0376923076923 --> Loss 0.00298490762711\n",
      "Epoch 28::Minibatch 305::LR 0.0376923076923 --> Loss 0.00170934041341\n",
      "Epoch 28::Minibatch 306::LR 0.0376923076923 --> Loss 0.000939170718193\n",
      "Epoch 28::Minibatch 307::LR 0.0376923076923 --> Loss 0.00241495907307\n",
      "Epoch 28::Minibatch 308::LR 0.0376923076923 --> Loss 0.00202013274034\n",
      "Epoch 28::Minibatch 309::LR 0.0376923076923 --> Loss 0.00103703369697\n",
      "Epoch 28::Minibatch 310::LR 0.0376923076923 --> Loss 0.00118103345235\n",
      "Epoch 28::Minibatch 311::LR 0.0376923076923 --> Loss 0.00178348183632\n",
      "Epoch 28::Minibatch 312::LR 0.0376923076923 --> Loss 0.00287291983763\n",
      "Epoch 28::Minibatch 313::LR 0.0376923076923 --> Loss 0.00235559403896\n",
      "Epoch 28::Minibatch 314::LR 0.0376923076923 --> Loss 0.00192366480827\n",
      "Epoch 28::Minibatch 315::LR 0.0376923076923 --> Loss 0.00103717446327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 316::LR 0.0376923076923 --> Loss 0.00234167655309\n",
      "Epoch 28::Minibatch 317::LR 0.0376923076923 --> Loss 0.00155996521314\n",
      "Epoch 28::Minibatch 318::LR 0.0376923076923 --> Loss 0.00129087934891\n",
      "Epoch 28::Minibatch 319::LR 0.0376923076923 --> Loss 0.00230680982272\n",
      "Epoch 28::Minibatch 320::LR 0.0376923076923 --> Loss 0.00307522376378\n",
      "Epoch 28::Minibatch 321::LR 0.0376923076923 --> Loss 0.000842033624649\n",
      "Epoch 28::Minibatch 322::LR 0.0376923076923 --> Loss 0.00351245323817\n",
      "Epoch 28::Minibatch 323::LR 0.0376923076923 --> Loss 0.00344357053439\n",
      "Epoch 28::Minibatch 324::LR 0.0376923076923 --> Loss 0.00264473656813\n",
      "Epoch 28::Minibatch 325::LR 0.0376923076923 --> Loss 0.00237744351228\n",
      "Epoch 28::Minibatch 326::LR 0.0376923076923 --> Loss 0.00536057114601\n",
      "Epoch 28::Minibatch 327::LR 0.0376923076923 --> Loss 0.00223889291286\n",
      "Epoch 28::Minibatch 328::LR 0.0376923076923 --> Loss 0.00302539984385\n",
      "Epoch 28::Minibatch 329::LR 0.0376923076923 --> Loss 0.00120038400094\n",
      "Epoch 28::Minibatch 330::LR 0.0376923076923 --> Loss 0.00158979912599\n",
      "Epoch 28::Minibatch 331::LR 0.0376923076923 --> Loss 0.00253446022669\n",
      "Epoch 28::Minibatch 332::LR 0.0376923076923 --> Loss 0.00246689359347\n",
      "Epoch 28::Minibatch 333::LR 0.0376923076923 --> Loss 0.00146252383788\n",
      "Epoch 28::Minibatch 334::LR 0.0376923076923 --> Loss 0.0044183743\n",
      "Epoch 28::Minibatch 335::LR 0.0376923076923 --> Loss 0.00189491331577\n",
      "Epoch 28::Minibatch 336::LR 0.0376923076923 --> Loss 0.00224058528741\n",
      "Epoch 28::Minibatch 337::LR 0.0376923076923 --> Loss 0.00366155385971\n",
      "Epoch 28::Minibatch 338::LR 0.0376923076923 --> Loss 0.000545702129602\n",
      "Epoch 28::Minibatch 339::LR 0.0376923076923 --> Loss 0.00327365120252\n",
      "Epoch 28::Minibatch 340::LR 0.0376923076923 --> Loss 0.00376186410586\n",
      "Epoch 28::Minibatch 341::LR 0.0376923076923 --> Loss 0.00442559639613\n",
      "Epoch 28::Minibatch 342::LR 0.0376923076923 --> Loss 0.00306966821353\n",
      "Epoch 28::Minibatch 343::LR 0.0376923076923 --> Loss 0.00164380192757\n",
      "Epoch 28::Minibatch 344::LR 0.0376923076923 --> Loss 0.00315908928712\n",
      "Epoch 28::Minibatch 345::LR 0.0376923076923 --> Loss 0.00413017908732\n",
      "Epoch 28::Minibatch 346::LR 0.0376923076923 --> Loss 0.0054556675752\n",
      "Epoch 28::Minibatch 347::LR 0.0376923076923 --> Loss 0.000824929773808\n",
      "Epoch 28::Minibatch 348::LR 0.0376923076923 --> Loss 0.00309563378493\n",
      "Epoch 28::Minibatch 349::LR 0.0376923076923 --> Loss 0.00341216246287\n",
      "Epoch 28::Minibatch 350::LR 0.0376923076923 --> Loss 0.0016728635629\n",
      "Epoch 28::Minibatch 351::LR 0.0376923076923 --> Loss 0.00345500826836\n",
      "Epoch 28::Minibatch 352::LR 0.0376923076923 --> Loss 0.00492180864016\n",
      "Epoch 28::Minibatch 353::LR 0.0376923076923 --> Loss 0.00352001269658\n",
      "Epoch 28::Minibatch 354::LR 0.0376923076923 --> Loss 0.00293958206971\n",
      "Epoch 28::Minibatch 355::LR 0.0376923076923 --> Loss 0.00620869557063\n",
      "Epoch 28::Minibatch 356::LR 0.0376923076923 --> Loss 0.00314087291559\n",
      "Epoch 28::Minibatch 357::LR 0.0376923076923 --> Loss 0.00115733553966\n",
      "Epoch 28::Minibatch 358::LR 0.0376923076923 --> Loss 0.00199230690797\n",
      "Epoch 28::Minibatch 359::LR 0.0376923076923 --> Loss 0.00268494367599\n",
      "Epoch 28::Minibatch 360::LR 0.0376923076923 --> Loss 0.00232954084873\n",
      "Epoch 28::Minibatch 361::LR 0.0376923076923 --> Loss 0.00230277379354\n",
      "Epoch 28::Minibatch 362::LR 0.0376923076923 --> Loss 0.0022862893343\n",
      "Epoch 28::Minibatch 363::LR 0.0376923076923 --> Loss 0.000639908909798\n",
      "Epoch 28::Minibatch 364::LR 0.0376923076923 --> Loss 0.00197727958361\n",
      "Epoch 28::Minibatch 365::LR 0.0376923076923 --> Loss 0.00202490945657\n",
      "Epoch 28::Minibatch 366::LR 0.0376923076923 --> Loss 0.00215034206708\n",
      "Epoch 28::Minibatch 367::LR 0.0376923076923 --> Loss 0.00101543535789\n",
      "Epoch 28::Minibatch 368::LR 0.0376923076923 --> Loss 0.000973554650942\n",
      "Epoch 28::Minibatch 369::LR 0.0376923076923 --> Loss 0.00279629707336\n",
      "Epoch 28::Minibatch 370::LR 0.0376923076923 --> Loss 0.00222501953443\n",
      "Epoch 28::Minibatch 371::LR 0.0376923076923 --> Loss 0.00185741523902\n",
      "Epoch 28::Minibatch 372::LR 0.0376923076923 --> Loss 0.00042882040143\n",
      "Epoch 28::Minibatch 373::LR 0.0376923076923 --> Loss 0.00179615179698\n",
      "Epoch 28::Minibatch 374::LR 0.0376923076923 --> Loss 0.00223877112071\n",
      "Epoch 28::Minibatch 375::LR 0.0376923076923 --> Loss 0.00187472522259\n",
      "Epoch 28::Minibatch 376::LR 0.0376923076923 --> Loss 0.00121856768926\n",
      "Epoch 28::Minibatch 377::LR 0.0376923076923 --> Loss 0.0019168694814\n",
      "Epoch 28::Minibatch 378::LR 0.0376923076923 --> Loss 0.00210216164589\n",
      "Epoch 28::Minibatch 379::LR 0.0376923076923 --> Loss 0.00233457624912\n",
      "Epoch 28::Minibatch 380::LR 0.0376923076923 --> Loss 0.00156970749299\n",
      "Epoch 28::Minibatch 381::LR 0.0376923076923 --> Loss 0.00098867247502\n",
      "Epoch 28::Minibatch 382::LR 0.0376923076923 --> Loss 0.00202641646067\n",
      "Epoch 28::Minibatch 383::LR 0.0376923076923 --> Loss 0.00197926739852\n",
      "Epoch 28::Minibatch 384::LR 0.0376923076923 --> Loss 0.00109805891911\n",
      "Epoch 28::Minibatch 385::LR 0.0376923076923 --> Loss 0.00104879538218\n",
      "Epoch 28::Minibatch 386::LR 0.0376923076923 --> Loss 0.00222198367119\n",
      "Epoch 28::Minibatch 387::LR 0.0376923076923 --> Loss 0.00235689739386\n",
      "Epoch 28::Minibatch 388::LR 0.0376923076923 --> Loss 0.0011951627334\n",
      "Epoch 28::Minibatch 389::LR 0.0376923076923 --> Loss 0.0017843123277\n",
      "Epoch 28::Minibatch 390::LR 0.0376923076923 --> Loss 0.00333388884862\n",
      "Epoch 28::Minibatch 391::LR 0.0376923076923 --> Loss 0.00257963279883\n",
      "Epoch 28::Minibatch 392::LR 0.0376923076923 --> Loss 0.00257015963395\n",
      "Epoch 28::Minibatch 393::LR 0.0376923076923 --> Loss 0.00273681958516\n",
      "Epoch 28::Minibatch 394::LR 0.0376923076923 --> Loss 0.00201938986778\n",
      "Epoch 28::Minibatch 395::LR 0.0376923076923 --> Loss 0.00206328769525\n",
      "Epoch 28::Minibatch 396::LR 0.0376923076923 --> Loss 0.00193285008272\n",
      "Epoch 28::Minibatch 397::LR 0.0376923076923 --> Loss 0.00206847329934\n",
      "Epoch 28::Minibatch 398::LR 0.0376923076923 --> Loss 0.00205628434817\n",
      "Epoch 28::Minibatch 399::LR 0.0376923076923 --> Loss 0.00236522535483\n",
      "Epoch 28::Minibatch 400::LR 0.0376923076923 --> Loss 0.00200301627318\n",
      "Epoch 28::Minibatch 401::LR 0.0376923076923 --> Loss 0.00342033425967\n",
      "Epoch 28::Minibatch 402::LR 0.0376923076923 --> Loss 0.00173109571139\n",
      "Epoch 28::Minibatch 403::LR 0.0376923076923 --> Loss 0.00142730921507\n",
      "Epoch 28::Minibatch 404::LR 0.0376923076923 --> Loss 0.00136107226213\n",
      "Epoch 28::Minibatch 405::LR 0.0376923076923 --> Loss 0.00335858225822\n",
      "Epoch 28::Minibatch 406::LR 0.0376923076923 --> Loss 0.00236230671406\n",
      "Epoch 28::Minibatch 407::LR 0.0376923076923 --> Loss 0.00170527319113\n",
      "Epoch 28::Minibatch 408::LR 0.0376923076923 --> Loss 0.0004295497636\n",
      "Epoch 28::Minibatch 409::LR 0.0376923076923 --> Loss 0.0022199567159\n",
      "Epoch 28::Minibatch 410::LR 0.0376923076923 --> Loss 0.00313765704632\n",
      "Epoch 28::Minibatch 411::LR 0.0376923076923 --> Loss 0.0016468094786\n",
      "Epoch 28::Minibatch 412::LR 0.0376923076923 --> Loss 0.000940888524055\n",
      "Epoch 28::Minibatch 413::LR 0.0376923076923 --> Loss 0.00196101268133\n",
      "Epoch 28::Minibatch 414::LR 0.0376923076923 --> Loss 0.00185651679834\n",
      "Epoch 28::Minibatch 415::LR 0.0376923076923 --> Loss 0.00115758687258\n",
      "Epoch 28::Minibatch 416::LR 0.0376923076923 --> Loss 0.000789757072926\n",
      "Epoch 28::Minibatch 417::LR 0.0376923076923 --> Loss 0.00167356014252\n",
      "Epoch 28::Minibatch 418::LR 0.0376923076923 --> Loss 0.00260730981827\n",
      "Epoch 28::Minibatch 419::LR 0.0376923076923 --> Loss 0.000486269146204\n",
      "Epoch 28::Minibatch 420::LR 0.0376923076923 --> Loss 0.00068207030495\n",
      "Epoch 28::Minibatch 421::LR 0.0376923076923 --> Loss 0.00187442322572\n",
      "Epoch 28::Minibatch 422::LR 0.0376923076923 --> Loss 0.00206693987052\n",
      "Epoch 28::Minibatch 423::LR 0.0376923076923 --> Loss 0.000970445970694\n",
      "Epoch 28::Minibatch 424::LR 0.0376923076923 --> Loss 0.00151410033305\n",
      "Epoch 28::Minibatch 425::LR 0.0376923076923 --> Loss 0.00286990602811\n",
      "Epoch 28::Minibatch 426::LR 0.0376923076923 --> Loss 0.0019813623031\n",
      "Epoch 28::Minibatch 427::LR 0.0376923076923 --> Loss 0.000720234761635\n",
      "Epoch 28::Minibatch 428::LR 0.0376923076923 --> Loss 0.000955876211325\n",
      "Epoch 28::Minibatch 429::LR 0.0376923076923 --> Loss 0.00226154386997\n",
      "Epoch 28::Minibatch 430::LR 0.0376923076923 --> Loss 0.00834284146627\n",
      "Epoch 28::Minibatch 431::LR 0.0376923076923 --> Loss 0.00365105191867\n",
      "Epoch 28::Minibatch 432::LR 0.0376923076923 --> Loss 0.00412428418795\n",
      "Epoch 28::Minibatch 433::LR 0.0376923076923 --> Loss 0.00253383715947\n",
      "Epoch 28::Minibatch 434::LR 0.0376923076923 --> Loss 0.00246206084887\n",
      "Epoch 28::Minibatch 435::LR 0.0376923076923 --> Loss 0.00225871165593\n",
      "Epoch 28::Minibatch 436::LR 0.0376923076923 --> Loss 0.00160943776369\n",
      "Epoch 28::Minibatch 437::LR 0.0376923076923 --> Loss 0.00289425651232\n",
      "Epoch 28::Minibatch 438::LR 0.0376923076923 --> Loss 0.00232678373655\n",
      "Epoch 28::Minibatch 439::LR 0.0376923076923 --> Loss 0.00194497128328\n",
      "Epoch 28::Minibatch 440::LR 0.0376923076923 --> Loss 0.00301250259082\n",
      "Epoch 28::Minibatch 441::LR 0.0376923076923 --> Loss 0.00281315386295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 442::LR 0.0376923076923 --> Loss 0.0025298734506\n",
      "Epoch 28::Minibatch 443::LR 0.0376923076923 --> Loss 0.00348975261052\n",
      "Epoch 28::Minibatch 444::LR 0.0376923076923 --> Loss 0.0027022711436\n",
      "Epoch 28::Minibatch 445::LR 0.0376923076923 --> Loss 0.000853782892227\n",
      "Epoch 28::Minibatch 446::LR 0.0376923076923 --> Loss 0.00137603104115\n",
      "Epoch 28::Minibatch 447::LR 0.0376923076923 --> Loss 0.00231205721696\n",
      "Epoch 28::Minibatch 448::LR 0.0376923076923 --> Loss 0.00231951057911\n",
      "Epoch 28::Minibatch 449::LR 0.0376923076923 --> Loss 0.00359133084615\n",
      "Epoch 28::Minibatch 450::LR 0.0376923076923 --> Loss 0.00215389788151\n",
      "Epoch 28::Minibatch 451::LR 0.0376923076923 --> Loss 0.00386056860288\n",
      "Epoch 28::Minibatch 452::LR 0.0376923076923 --> Loss 0.00230414966742\n",
      "Epoch 28::Minibatch 453::LR 0.0376923076923 --> Loss 0.000352133984367\n",
      "Epoch 28::Minibatch 454::LR 0.0376923076923 --> Loss 0.00346794446309\n",
      "Epoch 28::Minibatch 455::LR 0.0376923076923 --> Loss 0.00260371426741\n",
      "Epoch 28::Minibatch 456::LR 0.0376923076923 --> Loss 0.00305070241292\n",
      "Epoch 28::Minibatch 457::LR 0.0376923076923 --> Loss 0.00188241640727\n",
      "Epoch 28::Minibatch 458::LR 0.0376923076923 --> Loss 0.000718268702428\n",
      "Epoch 28::Minibatch 459::LR 0.0376923076923 --> Loss 0.00388493537903\n",
      "Epoch 28::Minibatch 460::LR 0.0376923076923 --> Loss 0.00244802236557\n",
      "Epoch 28::Minibatch 461::LR 0.0376923076923 --> Loss 0.00372233827909\n",
      "Epoch 28::Minibatch 462::LR 0.0376923076923 --> Loss 0.000372105141481\n",
      "Epoch 28::Minibatch 463::LR 0.0376923076923 --> Loss 0.00420541683833\n",
      "Epoch 28::Minibatch 464::LR 0.0376923076923 --> Loss 0.00195826013883\n",
      "Epoch 28::Minibatch 465::LR 0.0376923076923 --> Loss 0.00466094374657\n",
      "Epoch 28::Minibatch 466::LR 0.0376923076923 --> Loss 0.00498863299688\n",
      "Epoch 28::Minibatch 467::LR 0.0376923076923 --> Loss 0.0051794787248\n",
      "Epoch 28::Minibatch 468::LR 0.0376923076923 --> Loss 0.00573081771533\n",
      "Epoch 28::Minibatch 469::LR 0.0376923076923 --> Loss 0.00607695738475\n",
      "Epoch 28::Minibatch 470::LR 0.0376923076923 --> Loss 0.00359796047211\n",
      "Epoch 28::Minibatch 471::LR 0.0376923076923 --> Loss 0.00167229731878\n",
      "Epoch 28::Minibatch 472::LR 0.0376923076923 --> Loss 0.0035539273421\n",
      "Epoch 28::Minibatch 473::LR 0.0376923076923 --> Loss 0.00229676226775\n",
      "Epoch 28::Minibatch 474::LR 0.0376923076923 --> Loss 0.000690813064575\n",
      "Epoch 28::Minibatch 475::LR 0.0376923076923 --> Loss 0.00484479705493\n",
      "Epoch 28::Minibatch 476::LR 0.0376923076923 --> Loss 0.00766446590424\n",
      "Epoch 28::Minibatch 477::LR 0.0376923076923 --> Loss 0.00091709882021\n",
      "Epoch 28::Minibatch 478::LR 0.0376923076923 --> Loss 0.00241862654686\n",
      "Epoch 28::Minibatch 479::LR 0.0376923076923 --> Loss 0.00196187655131\n",
      "Epoch 28::Minibatch 480::LR 0.0376923076923 --> Loss 0.00151756634315\n",
      "Epoch 28::Minibatch 481::LR 0.0376923076923 --> Loss 0.000956941843033\n",
      "Epoch 28::Minibatch 482::LR 0.0376923076923 --> Loss 0.00207195580006\n",
      "Epoch 28::Minibatch 483::LR 0.0376923076923 --> Loss 0.0030463496844\n",
      "Epoch 28::Minibatch 484::LR 0.0376923076923 --> Loss 0.00342234611511\n",
      "Epoch 28::Minibatch 485::LR 0.0376923076923 --> Loss 0.000760976870855\n",
      "Epoch 28::Minibatch 486::LR 0.0376923076923 --> Loss 0.00282234032949\n",
      "Epoch 28::Minibatch 487::LR 0.0376923076923 --> Loss 0.00330444236596\n",
      "Epoch 28::Minibatch 488::LR 0.0376923076923 --> Loss 0.00202451248964\n",
      "Epoch 28::Minibatch 489::LR 0.0376923076923 --> Loss 0.00309356093407\n",
      "Epoch 28::Minibatch 490::LR 0.0376923076923 --> Loss 0.000410636837284\n",
      "Epoch 28::Minibatch 491::LR 0.0376923076923 --> Loss 0.00329677959283\n",
      "Epoch 28::Minibatch 492::LR 0.0376923076923 --> Loss 0.00306285480658\n",
      "Epoch 28::Minibatch 493::LR 0.0376923076923 --> Loss 0.00302453100681\n",
      "Epoch 28::Minibatch 494::LR 0.0376923076923 --> Loss 0.000733560025692\n",
      "Epoch 28::Minibatch 495::LR 0.0376923076923 --> Loss 0.00183701018492\n",
      "Epoch 28::Minibatch 496::LR 0.0376923076923 --> Loss 0.00279439965884\n",
      "Epoch 28::Minibatch 497::LR 0.0376923076923 --> Loss 0.000916547675927\n",
      "Epoch 28::Minibatch 498::LR 0.0376923076923 --> Loss 0.00055138990283\n",
      "Epoch 28::Minibatch 499::LR 0.0376923076923 --> Loss 0.00343860030174\n",
      "Epoch 28::Minibatch 500::LR 0.0376923076923 --> Loss 0.00142838199933\n",
      "Epoch 28::Minibatch 501::LR 0.0376923076923 --> Loss 0.00207246442636\n",
      "Epoch 28::Minibatch 502::LR 0.0376923076923 --> Loss 0.00375136216482\n",
      "Epoch 28::Minibatch 503::LR 0.0376923076923 --> Loss 0.00699377377828\n",
      "Epoch 28::Minibatch 504::LR 0.0376923076923 --> Loss 0.00688625017802\n",
      "Epoch 28::Minibatch 505::LR 0.0376923076923 --> Loss 0.00401588996251\n",
      "Epoch 28::Minibatch 506::LR 0.0376923076923 --> Loss 0.00333735585213\n",
      "Epoch 28::Minibatch 507::LR 0.0376923076923 --> Loss 0.00581147273382\n",
      "Epoch 28::Minibatch 508::LR 0.0376923076923 --> Loss 0.00339247783025\n",
      "Epoch 28::Minibatch 509::LR 0.0376923076923 --> Loss 0.00429967006048\n",
      "Epoch 28::Minibatch 510::LR 0.0376923076923 --> Loss 0.00441750367483\n",
      "Epoch 28::Minibatch 511::LR 0.0376923076923 --> Loss 0.00397418618202\n",
      "Epoch 28::Minibatch 512::LR 0.0376923076923 --> Loss 0.00268081963062\n",
      "Epoch 28::Minibatch 513::LR 0.0376923076923 --> Loss 0.000604394028584\n",
      "Epoch 28::Minibatch 514::LR 0.0376923076923 --> Loss 0.00264612634977\n",
      "Epoch 28::Minibatch 515::LR 0.0376923076923 --> Loss 0.00299431184928\n",
      "Epoch 28::Minibatch 516::LR 0.0376923076923 --> Loss 0.00393814563751\n",
      "Epoch 28::Minibatch 517::LR 0.0376923076923 --> Loss 0.00359381635984\n",
      "Epoch 28::Minibatch 518::LR 0.0376923076923 --> Loss 0.00257746239503\n",
      "Epoch 28::Minibatch 519::LR 0.0376923076923 --> Loss 0.00351831754049\n",
      "Epoch 28::Minibatch 520::LR 0.0376923076923 --> Loss 0.00550485610962\n",
      "Epoch 28::Minibatch 521::LR 0.0376923076923 --> Loss 0.00558015346527\n",
      "Epoch 28::Minibatch 522::LR 0.0376923076923 --> Loss 0.00733573436737\n",
      "Epoch 28::Minibatch 523::LR 0.0376923076923 --> Loss 0.000626101295153\n",
      "Epoch 28::Minibatch 524::LR 0.0376923076923 --> Loss 0.001398118337\n",
      "Epoch 28::Minibatch 525::LR 0.0376923076923 --> Loss 0.00309347331524\n",
      "Epoch 28::Minibatch 526::LR 0.0376923076923 --> Loss 0.00376968224843\n",
      "Epoch 28::Minibatch 527::LR 0.0376923076923 --> Loss 0.00214736660322\n",
      "Epoch 28::Minibatch 528::LR 0.0376923076923 --> Loss 0.000946421921253\n",
      "Epoch 28::Minibatch 529::LR 0.0376923076923 --> Loss 0.00387097001076\n",
      "Epoch 28::Minibatch 530::LR 0.0376923076923 --> Loss 0.00385346134504\n",
      "Epoch 28::Minibatch 531::LR 0.0376923076923 --> Loss 0.00341372330983\n",
      "Epoch 28::Minibatch 532::LR 0.0376923076923 --> Loss 0.00261744419734\n",
      "Epoch 28::Minibatch 533::LR 0.0376923076923 --> Loss 0.00489483435949\n",
      "Epoch 28::Minibatch 534::LR 0.0376923076923 --> Loss 0.0037013510863\n",
      "Epoch 28::Minibatch 535::LR 0.0376923076923 --> Loss 0.00328804234664\n",
      "Epoch 28::Minibatch 536::LR 0.0376923076923 --> Loss 0.00210433224837\n",
      "Epoch 28::Minibatch 537::LR 0.0376923076923 --> Loss 0.000589441607396\n",
      "Epoch 28::Minibatch 538::LR 0.0376923076923 --> Loss 0.00164364079634\n",
      "Epoch 28::Minibatch 539::LR 0.0376923076923 --> Loss 0.00333701093992\n",
      "Epoch 28::Minibatch 540::LR 0.0376923076923 --> Loss 0.00339760502179\n",
      "Epoch 28::Minibatch 541::LR 0.0376923076923 --> Loss 0.00285345772902\n",
      "Epoch 28::Minibatch 542::LR 0.0376923076923 --> Loss 0.00244489947955\n",
      "Epoch 28::Minibatch 543::LR 0.0376923076923 --> Loss 0.00260510226091\n",
      "Epoch 28::Minibatch 544::LR 0.0376923076923 --> Loss 0.00398203730583\n",
      "Epoch 28::Minibatch 545::LR 0.0376923076923 --> Loss 0.00199155608813\n",
      "Epoch 28::Minibatch 546::LR 0.0376923076923 --> Loss 0.0006571487089\n",
      "Epoch 28::Minibatch 547::LR 0.0376923076923 --> Loss 0.00258652925491\n",
      "Epoch 28::Minibatch 548::LR 0.0376923076923 --> Loss 0.00345123171806\n",
      "Epoch 28::Minibatch 549::LR 0.0376923076923 --> Loss 0.00878744761149\n",
      "Epoch 28::Minibatch 550::LR 0.0376923076923 --> Loss 0.00118083208799\n",
      "Epoch 28::Minibatch 551::LR 0.0376923076923 --> Loss 0.0024542794625\n",
      "Epoch 28::Minibatch 552::LR 0.0376923076923 --> Loss 0.00344886859258\n",
      "Epoch 28::Minibatch 553::LR 0.0376923076923 --> Loss 0.00301100552082\n",
      "Epoch 28::Minibatch 554::LR 0.0376923076923 --> Loss 0.00365537087123\n",
      "Epoch 28::Minibatch 555::LR 0.0376923076923 --> Loss 0.000948126614094\n",
      "Epoch 28::Minibatch 556::LR 0.0376923076923 --> Loss 0.00193192005157\n",
      "Epoch 28::Minibatch 557::LR 0.0376923076923 --> Loss 0.00240163664023\n",
      "Epoch 28::Minibatch 558::LR 0.0376923076923 --> Loss 0.00361164808273\n",
      "Epoch 28::Minibatch 559::LR 0.0376923076923 --> Loss 0.00366332729657\n",
      "Epoch 28::Minibatch 560::LR 0.0376923076923 --> Loss 0.00305831074715\n",
      "Epoch 28::Minibatch 561::LR 0.0376923076923 --> Loss 0.00263232032458\n",
      "Epoch 28::Minibatch 562::LR 0.0376923076923 --> Loss 0.00234354436398\n",
      "Epoch 28::Minibatch 563::LR 0.0376923076923 --> Loss 0.0039754196008\n",
      "Epoch 28::Minibatch 564::LR 0.0376923076923 --> Loss 0.00305355687936\n",
      "Epoch 28::Minibatch 565::LR 0.0376923076923 --> Loss 0.00359345038732\n",
      "Epoch 28::Minibatch 566::LR 0.0376923076923 --> Loss 0.00219421744347\n",
      "Epoch 28::Minibatch 567::LR 0.0376923076923 --> Loss 0.00253615876039\n",
      "Epoch 28::Minibatch 568::LR 0.0376923076923 --> Loss 0.00175236860911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 569::LR 0.0376923076923 --> Loss 0.000561081618071\n",
      "Epoch 28::Minibatch 570::LR 0.0376923076923 --> Loss 0.00163703918457\n",
      "Epoch 28::Minibatch 571::LR 0.0376923076923 --> Loss 0.00208987752597\n",
      "Epoch 28::Minibatch 572::LR 0.0376923076923 --> Loss 0.00224493503571\n",
      "Epoch 28::Minibatch 573::LR 0.0376923076923 --> Loss 0.00145210315784\n",
      "Epoch 28::Minibatch 574::LR 0.0376923076923 --> Loss 0.00104454278946\n",
      "Epoch 28::Minibatch 575::LR 0.0376923076923 --> Loss 0.0017293826739\n",
      "Epoch 28::Minibatch 576::LR 0.0376923076923 --> Loss 0.00204299549262\n",
      "Epoch 28::Minibatch 577::LR 0.0376923076923 --> Loss 0.00161707888047\n",
      "Epoch 28::Minibatch 578::LR 0.0376923076923 --> Loss 0.00126792599758\n",
      "Epoch 28::Minibatch 579::LR 0.0376923076923 --> Loss 0.00118477423986\n",
      "Epoch 28::Minibatch 580::LR 0.0376923076923 --> Loss 0.00192268073559\n",
      "Epoch 28::Minibatch 581::LR 0.0376923076923 --> Loss 0.00170676092307\n",
      "Epoch 28::Minibatch 582::LR 0.0376923076923 --> Loss 0.00417194724083\n",
      "Epoch 28::Minibatch 583::LR 0.0376923076923 --> Loss 0.000949822465579\n",
      "Epoch 28::Minibatch 584::LR 0.0376923076923 --> Loss 0.00130800197522\n",
      "Epoch 28::Minibatch 585::LR 0.0376923076923 --> Loss 0.00399893840154\n",
      "Epoch 28::Minibatch 586::LR 0.0376923076923 --> Loss 0.00378021359444\n",
      "Epoch 28::Minibatch 587::LR 0.0376923076923 --> Loss 0.00111589501301\n",
      "Epoch 28::Minibatch 588::LR 0.0376923076923 --> Loss 0.00137798468272\n",
      "Epoch 28::Minibatch 589::LR 0.0376923076923 --> Loss 0.00274606029193\n",
      "Epoch 28::Minibatch 590::LR 0.0376923076923 --> Loss 0.00182656804721\n",
      "Epoch 28::Minibatch 591::LR 0.0376923076923 --> Loss 0.00276571929455\n",
      "Epoch 28::Minibatch 592::LR 0.0376923076923 --> Loss 0.00115522662799\n",
      "Epoch 28::Minibatch 593::LR 0.0376923076923 --> Loss 0.00248982052008\n",
      "Epoch 28::Minibatch 594::LR 0.0376923076923 --> Loss 0.00259911398093\n",
      "Epoch 28::Minibatch 595::LR 0.0376923076923 --> Loss 0.00304134766261\n",
      "Epoch 28::Minibatch 596::LR 0.0376923076923 --> Loss 0.00185963829358\n",
      "Epoch 28::Minibatch 597::LR 0.0376923076923 --> Loss 0.00117240677277\n",
      "Epoch 28::Minibatch 598::LR 0.0376923076923 --> Loss 0.00284108161926\n",
      "Epoch 28::Minibatch 599::LR 0.0376923076923 --> Loss 0.00180230061213\n",
      "Epoch 28::Minibatch 600::LR 0.0376923076923 --> Loss 0.00214297115803\n",
      "Epoch 28::Minibatch 601::LR 0.0376923076923 --> Loss 0.00375991980235\n",
      "Epoch 28::Minibatch 602::LR 0.0376923076923 --> Loss 0.00208936969439\n",
      "Epoch 28::Minibatch 603::LR 0.0376923076923 --> Loss 0.00262068212032\n",
      "Epoch 28::Minibatch 604::LR 0.0376923076923 --> Loss 0.00163378467162\n",
      "Epoch 28::Minibatch 605::LR 0.0376923076923 --> Loss 0.00229742685954\n",
      "Epoch 28::Minibatch 606::LR 0.0376923076923 --> Loss 0.00186774015427\n",
      "Epoch 28::Minibatch 607::LR 0.0376923076923 --> Loss 0.000828686753909\n",
      "Epoch 28::Minibatch 608::LR 0.0376923076923 --> Loss 0.00155853539705\n",
      "Epoch 28::Minibatch 609::LR 0.0376923076923 --> Loss 0.00241443435351\n",
      "Epoch 28::Minibatch 610::LR 0.0376923076923 --> Loss 0.00403093616168\n",
      "Epoch 28::Minibatch 611::LR 0.0376923076923 --> Loss 0.00264767368635\n",
      "Epoch 28::Minibatch 612::LR 0.0376923076923 --> Loss 0.000472198327382\n",
      "Epoch 28::Minibatch 613::LR 0.0376923076923 --> Loss 0.00131019055843\n",
      "Epoch 28::Minibatch 614::LR 0.0376923076923 --> Loss 0.00241220136484\n",
      "Epoch 28::Minibatch 615::LR 0.0376923076923 --> Loss 0.0016589474678\n",
      "Epoch 28::Minibatch 616::LR 0.0376923076923 --> Loss 0.000917898019155\n",
      "Epoch 28::Minibatch 617::LR 0.0376923076923 --> Loss 0.000492774148782\n",
      "Epoch 28::Minibatch 618::LR 0.0376923076923 --> Loss 0.00284416377544\n",
      "Epoch 28::Minibatch 619::LR 0.0376923076923 --> Loss 0.00192686915398\n",
      "Epoch 28::Minibatch 620::LR 0.0376923076923 --> Loss 0.00169578631719\n",
      "Epoch 28::Minibatch 621::LR 0.0376923076923 --> Loss 0.000846822361151\n",
      "Epoch 28::Minibatch 622::LR 0.0376923076923 --> Loss 0.000783072908719\n",
      "Epoch 28::Minibatch 623::LR 0.0376923076923 --> Loss 0.00221840957801\n",
      "Epoch 28::Minibatch 624::LR 0.0376923076923 --> Loss 0.00177715520064\n",
      "Epoch 28::Minibatch 625::LR 0.0376923076923 --> Loss 0.00271240929763\n",
      "Epoch 28::Minibatch 626::LR 0.0376923076923 --> Loss 0.00376282493273\n",
      "Epoch 28::Minibatch 627::LR 0.0376923076923 --> Loss 0.00127722849449\n",
      "Epoch 28::Minibatch 628::LR 0.0376923076923 --> Loss 0.000880283812682\n",
      "Epoch 28::Minibatch 629::LR 0.0376923076923 --> Loss 0.00314398050308\n",
      "Epoch 28::Minibatch 630::LR 0.0376923076923 --> Loss 0.00307355344296\n",
      "Epoch 28::Minibatch 631::LR 0.0376923076923 --> Loss 0.00539401729902\n",
      "Epoch 28::Minibatch 632::LR 0.0376923076923 --> Loss 0.000791693180799\n",
      "Epoch 28::Minibatch 633::LR 0.0376923076923 --> Loss 0.00162500033776\n",
      "Epoch 28::Minibatch 634::LR 0.0376923076923 --> Loss 0.00319842378298\n",
      "Epoch 28::Minibatch 635::LR 0.0376923076923 --> Loss 0.00546877423922\n",
      "Epoch 28::Minibatch 636::LR 0.0376923076923 --> Loss 0.00466771920522\n",
      "Epoch 28::Minibatch 637::LR 0.0376923076923 --> Loss 0.000724146763484\n",
      "Epoch 28::Minibatch 638::LR 0.0376923076923 --> Loss 0.00148492693901\n",
      "Epoch 28::Minibatch 639::LR 0.0376923076923 --> Loss 0.00320434729258\n",
      "Epoch 28::Minibatch 640::LR 0.0376923076923 --> Loss 0.00465639034907\n",
      "Epoch 28::Minibatch 641::LR 0.0376923076923 --> Loss 0.00305825253328\n",
      "Epoch 28::Minibatch 642::LR 0.0376923076923 --> Loss 0.00053293928504\n",
      "Epoch 28::Minibatch 643::LR 0.0376923076923 --> Loss 0.00231520454089\n",
      "Epoch 28::Minibatch 644::LR 0.0376923076923 --> Loss 0.00388618032138\n",
      "Epoch 28::Minibatch 645::LR 0.0376923076923 --> Loss 0.00438527584076\n",
      "Epoch 28::Minibatch 646::LR 0.0376923076923 --> Loss 0.00150123993556\n",
      "Epoch 28::Minibatch 647::LR 0.0376923076923 --> Loss 0.000474723925193\n",
      "Epoch 28::Minibatch 648::LR 0.0376923076923 --> Loss 0.00280726035436\n",
      "Epoch 28::Minibatch 649::LR 0.0376923076923 --> Loss 0.00329108973344\n",
      "Epoch 28::Minibatch 650::LR 0.0376923076923 --> Loss 0.00320283234119\n",
      "Epoch 28::Minibatch 651::LR 0.0376923076923 --> Loss 0.00133970518907\n",
      "Epoch 28::Minibatch 652::LR 0.0376923076923 --> Loss 0.00077987626195\n",
      "Epoch 28::Minibatch 653::LR 0.0376923076923 --> Loss 0.00281350513299\n",
      "Epoch 28::Minibatch 654::LR 0.0376923076923 --> Loss 0.00312647004922\n",
      "Epoch 28::Minibatch 655::LR 0.0376923076923 --> Loss 0.00359519481659\n",
      "Epoch 28::Minibatch 656::LR 0.0376923076923 --> Loss 0.000754563510418\n",
      "Epoch 28::Minibatch 657::LR 0.0376923076923 --> Loss 0.00226520637671\n",
      "Epoch 28::Minibatch 658::LR 0.0376923076923 --> Loss 0.00458764314651\n",
      "Epoch 28::Minibatch 659::LR 0.0376923076923 --> Loss 0.00223395566146\n",
      "Epoch 28::Minibatch 660::LR 0.0376923076923 --> Loss 0.00263109564781\n",
      "Epoch 28::Minibatch 661::LR 0.0376923076923 --> Loss 0.00231942713261\n",
      "Epoch 28::Minibatch 662::LR 0.0376923076923 --> Loss 0.00179771542549\n",
      "Epoch 28::Minibatch 663::LR 0.0376923076923 --> Loss 0.00368505160014\n",
      "Epoch 28::Minibatch 664::LR 0.0376923076923 --> Loss 0.00321733514468\n",
      "Epoch 28::Minibatch 665::LR 0.0376923076923 --> Loss 0.000701374957959\n",
      "Epoch 28::Minibatch 666::LR 0.0376923076923 --> Loss 0.00390548904737\n",
      "Epoch 28::Minibatch 667::LR 0.0376923076923 --> Loss 0.00254166563352\n",
      "Epoch 28::Minibatch 668::LR 0.0376923076923 --> Loss 0.00646533846855\n",
      "Epoch 28::Minibatch 669::LR 0.0376923076923 --> Loss 0.00108674993118\n",
      "Epoch 28::Minibatch 670::LR 0.0376923076923 --> Loss 0.00133340060711\n",
      "Epoch 28::Minibatch 671::LR 0.0376923076923 --> Loss 0.00513778289159\n",
      "Epoch 28::Minibatch 672::LR 0.0376923076923 --> Loss 0.003462160031\n",
      "Epoch 28::Minibatch 673::LR 0.0376923076923 --> Loss 0.00160905291637\n",
      "Epoch 28::Minibatch 674::LR 0.0376923076923 --> Loss 0.000509633819262\n",
      "Epoch 28::Minibatch 675::LR 0.0376923076923 --> Loss 0.00219072699547\n",
      "Epoch 28::Minibatch 676::LR 0.0376923076923 --> Loss 0.00214556157589\n",
      "Epoch 28::Minibatch 677::LR 0.0376923076923 --> Loss 0.00272493640582\n",
      "Epoch 28::Minibatch 678::LR 0.0376923076923 --> Loss 0.00187785506248\n",
      "Epoch 28::Minibatch 679::LR 0.0376923076923 --> Loss 0.00335101127625\n",
      "Epoch 28::Minibatch 680::LR 0.0376923076923 --> Loss 0.00212675750256\n",
      "Epoch 28::Minibatch 681::LR 0.0376923076923 --> Loss 0.00239943444729\n",
      "Epoch 28::Minibatch 682::LR 0.0376923076923 --> Loss 0.000761259595553\n",
      "Epoch 28::Minibatch 683::LR 0.0376923076923 --> Loss 0.00232460041841\n",
      "Epoch 28::Minibatch 684::LR 0.0376923076923 --> Loss 0.00233935077985\n",
      "Epoch 28::Minibatch 685::LR 0.0376923076923 --> Loss 0.00283696631591\n",
      "Epoch 28::Minibatch 686::LR 0.0376923076923 --> Loss 0.0015790494283\n",
      "Epoch 28::Minibatch 687::LR 0.0376923076923 --> Loss 0.000871132314205\n",
      "Epoch 28::Minibatch 688::LR 0.0376923076923 --> Loss 0.00278982420762\n",
      "Epoch 28::Minibatch 689::LR 0.0376923076923 --> Loss 0.00248275617758\n",
      "Epoch 28::Minibatch 690::LR 0.0376923076923 --> Loss 0.00188904702663\n",
      "Epoch 28::Minibatch 691::LR 0.0376923076923 --> Loss 0.000657801230748\n",
      "Epoch 28::Minibatch 692::LR 0.0376923076923 --> Loss 0.00244618594646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 693::LR 0.0376923076923 --> Loss 0.00260242978732\n",
      "Epoch 28::Minibatch 694::LR 0.0376923076923 --> Loss 0.00300087491671\n",
      "Epoch 28::Minibatch 695::LR 0.0376923076923 --> Loss 0.00178184489409\n",
      "Epoch 28::Minibatch 696::LR 0.0376923076923 --> Loss 0.00203664998213\n",
      "Epoch 28::Minibatch 697::LR 0.0376923076923 --> Loss 0.00140107244253\n",
      "Epoch 28::Minibatch 698::LR 0.0376923076923 --> Loss 0.00165632774433\n",
      "Epoch 28::Minibatch 699::LR 0.0376923076923 --> Loss 0.00373671412468\n",
      "Epoch 28::Minibatch 700::LR 0.0376923076923 --> Loss 0.00260169247786\n",
      "Epoch 28::Minibatch 701::LR 0.0376923076923 --> Loss 0.00190883934498\n",
      "Epoch 28::Minibatch 702::LR 0.0376923076923 --> Loss 0.0016649689277\n",
      "Epoch 28::Minibatch 703::LR 0.0376923076923 --> Loss 0.00432351469994\n",
      "Epoch 28::Minibatch 704::LR 0.0376923076923 --> Loss 0.0018031167984\n",
      "Epoch 28::Minibatch 705::LR 0.0376923076923 --> Loss 0.00285095433394\n",
      "Epoch 28::Minibatch 706::LR 0.0376923076923 --> Loss 0.0022159353892\n",
      "Epoch 28::Minibatch 707::LR 0.0376923076923 --> Loss 0.00117972453435\n",
      "Epoch 28::Minibatch 708::LR 0.0376923076923 --> Loss 0.00173105875651\n",
      "Epoch 28::Minibatch 709::LR 0.0376923076923 --> Loss 0.00167309204737\n",
      "Epoch 28::Minibatch 710::LR 0.0376923076923 --> Loss 0.00257199724515\n",
      "Epoch 28::Minibatch 711::LR 0.0376923076923 --> Loss 0.00196176767349\n",
      "Epoch 28::Minibatch 712::LR 0.0376923076923 --> Loss 0.0013520398736\n",
      "Epoch 28::Minibatch 713::LR 0.0376923076923 --> Loss 0.0017862645785\n",
      "Epoch 28::Minibatch 714::LR 0.0376923076923 --> Loss 0.00283706466357\n",
      "Epoch 28::Minibatch 715::LR 0.0376923076923 --> Loss 0.00292854646842\n",
      "Epoch 28::Minibatch 716::LR 0.0376923076923 --> Loss 0.0016510929664\n",
      "Epoch 28::Minibatch 717::LR 0.0376923076923 --> Loss 0.00165521552165\n",
      "Epoch 28::Minibatch 718::LR 0.0376923076923 --> Loss 0.00127206722895\n",
      "Epoch 28::Minibatch 719::LR 0.0376923076923 --> Loss 0.00171130418777\n",
      "Epoch 28::Minibatch 720::LR 0.0376923076923 --> Loss 0.00270661731561\n",
      "Epoch 28::Minibatch 721::LR 0.0376923076923 --> Loss 0.000606319953998\n",
      "Epoch 28::Minibatch 722::LR 0.0376923076923 --> Loss 0.00464058876038\n",
      "Epoch 28::Minibatch 723::LR 0.0376923076923 --> Loss 0.00484718600909\n",
      "Epoch 28::Minibatch 724::LR 0.0376923076923 --> Loss 0.000964718659719\n",
      "Epoch 28::Minibatch 725::LR 0.0376923076923 --> Loss 0.00208308895429\n",
      "Epoch 28::Minibatch 726::LR 0.0376923076923 --> Loss 0.00386474768321\n",
      "Epoch 28::Minibatch 727::LR 0.0376923076923 --> Loss 0.0031292583545\n",
      "Epoch 28::Minibatch 728::LR 0.0376923076923 --> Loss 0.000641200343768\n",
      "Epoch 28::Minibatch 729::LR 0.0376923076923 --> Loss 0.000722826917966\n",
      "Epoch 28::Minibatch 730::LR 0.0376923076923 --> Loss 0.00290603975455\n",
      "Epoch 28::Minibatch 731::LR 0.0376923076923 --> Loss 0.00259385049343\n",
      "Epoch 28::Minibatch 732::LR 0.0376923076923 --> Loss 0.00208150645097\n",
      "Epoch 28::Minibatch 733::LR 0.0376923076923 --> Loss 0.000613012860219\n",
      "Epoch 28::Minibatch 734::LR 0.0376923076923 --> Loss 0.00166124463081\n",
      "Epoch 28::Minibatch 735::LR 0.0376923076923 --> Loss 0.00244209567706\n",
      "Epoch 28::Minibatch 736::LR 0.0376923076923 --> Loss 0.00347448905309\n",
      "Epoch 28::Minibatch 737::LR 0.0376923076923 --> Loss 0.002965751489\n",
      "Epoch 28::Minibatch 738::LR 0.0376923076923 --> Loss 0.00144062966108\n",
      "Epoch 28::Minibatch 739::LR 0.0376923076923 --> Loss 0.00240637898445\n",
      "Epoch 28::Minibatch 740::LR 0.0376923076923 --> Loss 0.00378419280052\n",
      "Epoch 28::Minibatch 741::LR 0.0376923076923 --> Loss 0.00255824704965\n",
      "Epoch 28::Minibatch 742::LR 0.0376923076923 --> Loss 0.00208798189958\n",
      "Epoch 28::Minibatch 743::LR 0.0376923076923 --> Loss 0.00148352523645\n",
      "Epoch 28::Minibatch 744::LR 0.0376923076923 --> Loss 0.00185185213884\n",
      "Epoch 28::Minibatch 745::LR 0.0376923076923 --> Loss 0.00278459946314\n",
      "Epoch 28::Minibatch 746::LR 0.0376923076923 --> Loss 0.00287767489751\n",
      "Epoch 28::Minibatch 747::LR 0.0376923076923 --> Loss 0.00176761130492\n",
      "Epoch 28::Minibatch 748::LR 0.0376923076923 --> Loss 0.000620071490606\n",
      "Epoch 28::Minibatch 749::LR 0.0376923076923 --> Loss 0.00166674276193\n",
      "Epoch 28::Minibatch 750::LR 0.0376923076923 --> Loss 0.00242730240027\n",
      "Epoch 28::Minibatch 751::LR 0.0376923076923 --> Loss 0.00287547767162\n",
      "Epoch 28::Minibatch 752::LR 0.0376923076923 --> Loss 0.00137335429589\n",
      "Epoch 28::Minibatch 753::LR 0.0376923076923 --> Loss 0.00219482421875\n",
      "Epoch 28::Minibatch 754::LR 0.0376923076923 --> Loss 0.00241115748882\n",
      "Epoch 28::Minibatch 755::LR 0.0376923076923 --> Loss 0.00266280432542\n",
      "Epoch 28::Minibatch 756::LR 0.0376923076923 --> Loss 0.00132181783517\n",
      "Epoch 28::Minibatch 757::LR 0.0376923076923 --> Loss 0.000635076562564\n",
      "Epoch 28::Minibatch 758::LR 0.0376923076923 --> Loss 0.00157158732414\n",
      "Epoch 28::Minibatch 759::LR 0.0376923076923 --> Loss 0.00350145419439\n",
      "Epoch 28::Minibatch 760::LR 0.0376923076923 --> Loss 0.00283726155758\n",
      "Epoch 28::Minibatch 761::LR 0.0376923076923 --> Loss 0.00579679052035\n",
      "Epoch 28::Minibatch 762::LR 0.0376923076923 --> Loss 0.00361562927564\n",
      "Epoch 28::Minibatch 763::LR 0.0376923076923 --> Loss 0.00346676071485\n",
      "Epoch 28::Minibatch 764::LR 0.0376923076923 --> Loss 0.00306701203187\n",
      "Epoch 28::Minibatch 765::LR 0.0376923076923 --> Loss 0.001262875398\n",
      "Epoch 28::Minibatch 766::LR 0.0376923076923 --> Loss 0.00229732910792\n",
      "Epoch 28::Minibatch 767::LR 0.0376923076923 --> Loss 0.0048364229997\n",
      "Epoch 28::Minibatch 768::LR 0.0376923076923 --> Loss 0.00365473866463\n",
      "Epoch 28::Minibatch 769::LR 0.0376923076923 --> Loss 0.00184790611267\n",
      "Epoch 28::Minibatch 770::LR 0.0376923076923 --> Loss 0.00149957855543\n",
      "Epoch 28::Minibatch 771::LR 0.0376923076923 --> Loss 0.00347179889679\n",
      "Epoch 28::Minibatch 772::LR 0.0376923076923 --> Loss 0.00356750210126\n",
      "Epoch 28::Minibatch 773::LR 0.0376923076923 --> Loss 0.0031725649039\n",
      "Epoch 28::Minibatch 774::LR 0.0376923076923 --> Loss 0.00186271150907\n",
      "Epoch 28::Minibatch 775::LR 0.0376923076923 --> Loss 0.0033942536513\n",
      "Epoch 28::Minibatch 776::LR 0.0376923076923 --> Loss 0.00371498703957\n",
      "Epoch 28::Minibatch 777::LR 0.0376923076923 --> Loss 0.00637755711873\n",
      "Epoch 28::Minibatch 778::LR 0.0376923076923 --> Loss 0.00773730913798\n",
      "Epoch 28::Minibatch 779::LR 0.0376923076923 --> Loss 0.00246637980143\n",
      "Epoch 28::Minibatch 780::LR 0.0376923076923 --> Loss 0.0015255027016\n",
      "Epoch 28::Minibatch 781::LR 0.0376923076923 --> Loss 0.00346484025319\n",
      "Epoch 28::Minibatch 782::LR 0.0376923076923 --> Loss 0.00380734125773\n",
      "Epoch 28::Minibatch 783::LR 0.0376923076923 --> Loss 0.00227072954178\n",
      "Epoch 28::Minibatch 784::LR 0.0376923076923 --> Loss 0.000706866035859\n",
      "Epoch 28::Minibatch 785::LR 0.0376923076923 --> Loss 0.00326484819253\n",
      "Epoch 28::Minibatch 786::LR 0.0376923076923 --> Loss 0.00344733079274\n",
      "Epoch 28::Minibatch 787::LR 0.0376923076923 --> Loss 0.00258214135965\n",
      "Epoch 28::Minibatch 788::LR 0.0376923076923 --> Loss 0.00236164828142\n",
      "Epoch 28::Minibatch 789::LR 0.0376923076923 --> Loss 0.000726508647203\n",
      "Epoch 28::Minibatch 790::LR 0.0376923076923 --> Loss 0.00312630295753\n",
      "Epoch 28::Minibatch 791::LR 0.0376923076923 --> Loss 0.00333198765914\n",
      "Epoch 28::Minibatch 792::LR 0.0376923076923 --> Loss 0.0029836499691\n",
      "Epoch 28::Minibatch 793::LR 0.0376923076923 --> Loss 0.0016643144687\n",
      "Epoch 28::Minibatch 794::LR 0.0376923076923 --> Loss 0.000986102422078\n",
      "Epoch 28::Minibatch 795::LR 0.0376923076923 --> Loss 0.0027078272899\n",
      "Epoch 28::Minibatch 796::LR 0.0376923076923 --> Loss 0.00500843604406\n",
      "Epoch 28::Minibatch 797::LR 0.0376923076923 --> Loss 0.00601188540459\n",
      "Epoch 28::Minibatch 798::LR 0.0376923076923 --> Loss 0.00305533210437\n",
      "Epoch 28::Minibatch 799::LR 0.0376923076923 --> Loss 0.00226277828217\n",
      "Epoch 28::Minibatch 800::LR 0.0376923076923 --> Loss 0.00200439055761\n",
      "Epoch 28::Minibatch 801::LR 0.0376923076923 --> Loss 0.00396795153618\n",
      "Epoch 28::Minibatch 802::LR 0.0376923076923 --> Loss 0.00122578124205\n",
      "Epoch 28::Minibatch 803::LR 0.0376923076923 --> Loss 0.00292757987976\n",
      "Epoch 28::Minibatch 804::LR 0.0376923076923 --> Loss 0.00209263761838\n",
      "Epoch 28::Minibatch 805::LR 0.0376923076923 --> Loss 0.00219847301642\n",
      "Epoch 28::Minibatch 806::LR 0.0376923076923 --> Loss 0.00339296221733\n",
      "Epoch 28::Minibatch 807::LR 0.0376923076923 --> Loss 0.00306677043438\n",
      "Epoch 28::Minibatch 808::LR 0.0376923076923 --> Loss 0.00277950922648\n",
      "Epoch 28::Minibatch 809::LR 0.0376923076923 --> Loss 0.00320087412993\n",
      "Epoch 28::Minibatch 810::LR 0.0376923076923 --> Loss 0.0044020986557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 811::LR 0.0376923076923 --> Loss 0.00420165816943\n",
      "Epoch 28::Minibatch 812::LR 0.0376923076923 --> Loss 0.00385280330976\n",
      "Epoch 28::Minibatch 813::LR 0.0376923076923 --> Loss 0.003270231088\n",
      "Epoch 28::Minibatch 814::LR 0.0376923076923 --> Loss 0.00155667046706\n",
      "Epoch 28::Minibatch 815::LR 0.0376923076923 --> Loss 0.00355733950933\n",
      "Epoch 28::Minibatch 816::LR 0.0376923076923 --> Loss 0.00399295290311\n",
      "Epoch 28::Minibatch 817::LR 0.0376923076923 --> Loss 0.00508366306623\n",
      "Epoch 28::Minibatch 818::LR 0.0376923076923 --> Loss 0.0012451038758\n",
      "Epoch 28::Minibatch 819::LR 0.0376923076923 --> Loss 0.000713426967462\n",
      "Epoch 28::Minibatch 820::LR 0.0376923076923 --> Loss 0.00513539274534\n",
      "Epoch 28::Minibatch 821::LR 0.0376923076923 --> Loss 0.00306232949098\n",
      "Epoch 28::Minibatch 822::LR 0.0376923076923 --> Loss 0.0036560134093\n",
      "Epoch 28::Minibatch 823::LR 0.0376923076923 --> Loss 0.00126648585002\n",
      "Epoch 28::Minibatch 824::LR 0.0376923076923 --> Loss 0.00136058092117\n",
      "Epoch 28::Minibatch 825::LR 0.0376923076923 --> Loss 0.00367862939835\n",
      "Epoch 28::Minibatch 826::LR 0.0376923076923 --> Loss 0.00423501133919\n",
      "Epoch 28::Minibatch 827::LR 0.0376923076923 --> Loss 0.00205464363098\n",
      "Epoch 28::Minibatch 828::LR 0.0376923076923 --> Loss 0.000491003344456\n",
      "Epoch 28::Minibatch 829::LR 0.0376923076923 --> Loss 0.00227986772855\n",
      "Epoch 28::Minibatch 830::LR 0.0376923076923 --> Loss 0.00408582965533\n",
      "Epoch 28::Minibatch 831::LR 0.0376923076923 --> Loss 0.00243095040321\n",
      "Epoch 28::Minibatch 832::LR 0.0376923076923 --> Loss 0.00213654657205\n",
      "Epoch 28::Minibatch 833::LR 0.0376923076923 --> Loss 0.00182131250699\n",
      "Epoch 28::Minibatch 834::LR 0.0376923076923 --> Loss 0.000782470355431\n",
      "Epoch 28::Minibatch 835::LR 0.0376923076923 --> Loss 0.00375615398089\n",
      "Epoch 28::Minibatch 836::LR 0.0376923076923 --> Loss 0.00358987689018\n",
      "Epoch 28::Minibatch 837::LR 0.0376923076923 --> Loss 0.00221408724785\n",
      "Epoch 28::Minibatch 838::LR 0.0376923076923 --> Loss 0.000637463231881\n",
      "Epoch 28::Minibatch 839::LR 0.0376923076923 --> Loss 0.00240730146567\n",
      "Epoch 28::Minibatch 840::LR 0.0376923076923 --> Loss 0.00284394264221\n",
      "Epoch 28::Minibatch 841::LR 0.0376923076923 --> Loss 0.00275889952977\n",
      "Epoch 28::Minibatch 842::LR 0.0376923076923 --> Loss 0.00208332220713\n",
      "Epoch 28::Minibatch 843::LR 0.0376923076923 --> Loss 0.000982523858547\n",
      "Epoch 28::Minibatch 844::LR 0.0376923076923 --> Loss 0.00146908760071\n",
      "Epoch 28::Minibatch 845::LR 0.0376923076923 --> Loss 0.00408971627553\n",
      "Epoch 28::Minibatch 846::LR 0.0376923076923 --> Loss 0.00166471580664\n",
      "Epoch 28::Minibatch 847::LR 0.0376923076923 --> Loss 0.00232191602389\n",
      "Epoch 28::Minibatch 848::LR 0.0376923076923 --> Loss 0.00107421815395\n",
      "Epoch 28::Minibatch 849::LR 0.0376923076923 --> Loss 0.00178892413775\n",
      "Epoch 28::Minibatch 850::LR 0.0376923076923 --> Loss 0.00314391175906\n",
      "Epoch 28::Minibatch 851::LR 0.0376923076923 --> Loss 0.00255745887756\n",
      "Epoch 28::Minibatch 852::LR 0.0376923076923 --> Loss 0.00110750476519\n",
      "Epoch 28::Minibatch 853::LR 0.0376923076923 --> Loss 0.00130031605562\n",
      "Epoch 28::Minibatch 854::LR 0.0376923076923 --> Loss 0.00253683626652\n",
      "Epoch 28::Minibatch 855::LR 0.0376923076923 --> Loss 0.00212085008621\n",
      "Epoch 28::Minibatch 856::LR 0.0376923076923 --> Loss 0.00178205708663\n",
      "Epoch 28::Minibatch 857::LR 0.0376923076923 --> Loss 0.00120804746946\n",
      "Epoch 28::Minibatch 858::LR 0.0376923076923 --> Loss 0.000595755080382\n",
      "Epoch 28::Minibatch 859::LR 0.0376923076923 --> Loss 0.00194814483325\n",
      "Epoch 28::Minibatch 860::LR 0.0376923076923 --> Loss 0.00128250171741\n",
      "Epoch 28::Minibatch 861::LR 0.0376923076923 --> Loss 0.000940699875355\n",
      "Epoch 28::Minibatch 862::LR 0.0376923076923 --> Loss 0.00368317961693\n",
      "Epoch 28::Minibatch 863::LR 0.0376923076923 --> Loss 0.00337134917577\n",
      "Epoch 28::Minibatch 864::LR 0.0376923076923 --> Loss 0.00265642444293\n",
      "Epoch 28::Minibatch 865::LR 0.0376923076923 --> Loss 0.000476123938958\n",
      "Epoch 28::Minibatch 866::LR 0.0376923076923 --> Loss 0.00209030946096\n",
      "Epoch 28::Minibatch 867::LR 0.0376923076923 --> Loss 0.00288803915183\n",
      "Epoch 28::Minibatch 868::LR 0.0376923076923 --> Loss 0.00240298887094\n",
      "Epoch 28::Minibatch 869::LR 0.0376923076923 --> Loss 0.00211969812711\n",
      "Epoch 28::Minibatch 870::LR 0.0376923076923 --> Loss 0.00333000679811\n",
      "Epoch 28::Minibatch 871::LR 0.0376923076923 --> Loss 0.00158574283123\n",
      "Epoch 28::Minibatch 872::LR 0.0376923076923 --> Loss 0.00216228326162\n",
      "Epoch 28::Minibatch 873::LR 0.0376923076923 --> Loss 0.00245137353738\n",
      "Epoch 28::Minibatch 874::LR 0.0376923076923 --> Loss 0.00546617507935\n",
      "Epoch 28::Minibatch 875::LR 0.0376923076923 --> Loss 0.00058157329758\n",
      "Epoch 28::Minibatch 876::LR 0.0376923076923 --> Loss 0.00284167806307\n",
      "Epoch 28::Minibatch 877::LR 0.0376923076923 --> Loss 0.00495951811473\n",
      "Epoch 28::Minibatch 878::LR 0.0376923076923 --> Loss 0.00304355065028\n",
      "Epoch 28::Minibatch 879::LR 0.0376923076923 --> Loss 0.00394090970357\n",
      "Epoch 28::Minibatch 880::LR 0.0376923076923 --> Loss 0.00484480341276\n",
      "Epoch 28::Minibatch 881::LR 0.0376923076923 --> Loss 0.00424232761065\n",
      "Epoch 28::Minibatch 882::LR 0.0376923076923 --> Loss 0.00192696054777\n",
      "Epoch 28::Minibatch 883::LR 0.0376923076923 --> Loss 0.00354960560799\n",
      "Epoch 28::Minibatch 884::LR 0.0376923076923 --> Loss 0.00276066402594\n",
      "Epoch 28::Minibatch 885::LR 0.0376923076923 --> Loss 0.00257210512956\n",
      "Epoch 28::Minibatch 886::LR 0.0376923076923 --> Loss 0.000442145814498\n",
      "Epoch 28::Minibatch 887::LR 0.0376923076923 --> Loss 0.00535633563995\n",
      "Epoch 28::Minibatch 888::LR 0.0376923076923 --> Loss 0.00248801330725\n",
      "Epoch 28::Minibatch 889::LR 0.0376923076923 --> Loss 0.00257194499175\n",
      "Epoch 28::Minibatch 890::LR 0.0376923076923 --> Loss 0.00373859683673\n",
      "Epoch 28::Minibatch 891::LR 0.0376923076923 --> Loss 0.00174784501394\n",
      "Epoch 28::Minibatch 892::LR 0.0376923076923 --> Loss 0.000806249976158\n",
      "Epoch 28::Minibatch 893::LR 0.0376923076923 --> Loss 0.00230205118656\n",
      "Epoch 28::Minibatch 894::LR 0.0376923076923 --> Loss 0.00202676137288\n",
      "Epoch 28::Minibatch 895::LR 0.0376923076923 --> Loss 0.00229900836945\n",
      "Epoch 28::Minibatch 896::LR 0.0376923076923 --> Loss 0.00123985270659\n",
      "Epoch 28::Minibatch 897::LR 0.0376923076923 --> Loss 0.000678374866645\n",
      "Epoch 28::Minibatch 898::LR 0.0376923076923 --> Loss 0.00202196081479\n",
      "Epoch 28::Minibatch 899::LR 0.0376923076923 --> Loss 0.00245596150557\n",
      "Epoch 28::Minibatch 900::LR 0.0376923076923 --> Loss 0.00310609857241\n",
      "Epoch 28::Minibatch 901::LR 0.0376923076923 --> Loss 0.000583777030309\n",
      "Epoch 28::Minibatch 902::LR 0.0376923076923 --> Loss 0.00139766573906\n",
      "Epoch 28::Minibatch 903::LR 0.0376923076923 --> Loss 0.0025271932284\n",
      "Epoch 28::Minibatch 904::LR 0.0376923076923 --> Loss 0.00181868970394\n",
      "Epoch 28::Minibatch 905::LR 0.0376923076923 --> Loss 0.00140356481075\n",
      "Epoch 28::Minibatch 906::LR 0.0376923076923 --> Loss 0.00103503296773\n",
      "Epoch 28::Minibatch 907::LR 0.0376923076923 --> Loss 0.0015547700723\n",
      "Epoch 28::Minibatch 908::LR 0.0376923076923 --> Loss 0.00208368738492\n",
      "Epoch 28::Minibatch 909::LR 0.0376923076923 --> Loss 0.0019376818339\n",
      "Epoch 28::Minibatch 910::LR 0.0376923076923 --> Loss 0.000837390522162\n",
      "Epoch 28::Minibatch 911::LR 0.0376923076923 --> Loss 0.00125705917676\n",
      "Epoch 28::Minibatch 912::LR 0.0376923076923 --> Loss 0.00202297210693\n",
      "Epoch 28::Minibatch 913::LR 0.0376923076923 --> Loss 0.00222357312838\n",
      "Epoch 28::Minibatch 914::LR 0.0376923076923 --> Loss 0.00120779226224\n",
      "Epoch 28::Minibatch 915::LR 0.0376923076923 --> Loss 0.000514132529497\n",
      "Epoch 28::Minibatch 916::LR 0.0376923076923 --> Loss 0.00210058410962\n",
      "Epoch 28::Minibatch 917::LR 0.0376923076923 --> Loss 0.00340973734856\n",
      "Epoch 28::Minibatch 918::LR 0.0376923076923 --> Loss 0.00526806990306\n",
      "Epoch 28::Minibatch 919::LR 0.0376923076923 --> Loss 0.000533554852009\n",
      "Epoch 28::Minibatch 920::LR 0.0376923076923 --> Loss 0.0125706736247\n",
      "Epoch 28::Minibatch 921::LR 0.0376923076923 --> Loss 0.00290057599545\n",
      "Epoch 28::Minibatch 922::LR 0.0376923076923 --> Loss 0.00294922828674\n",
      "Epoch 28::Minibatch 923::LR 0.0376923076923 --> Loss 0.001250722905\n",
      "Epoch 28::Minibatch 924::LR 0.0376923076923 --> Loss 0.00322625339031\n",
      "Epoch 28::Minibatch 925::LR 0.0376923076923 --> Loss 0.00220043261846\n",
      "Epoch 28::Minibatch 926::LR 0.0376923076923 --> Loss 0.00483474214872\n",
      "Epoch 28::Minibatch 927::LR 0.0376923076923 --> Loss 0.00581855376561\n",
      "Epoch 28::Minibatch 928::LR 0.0376923076923 --> Loss 0.00604409575462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28::Minibatch 929::LR 0.0376923076923 --> Loss 0.00565238952637\n",
      "Epoch 28::Minibatch 930::LR 0.0376923076923 --> Loss 0.00891274054845\n",
      "Epoch 28::Minibatch 931::LR 0.0376923076923 --> Loss 0.00310839076837\n",
      "Epoch 28::Minibatch 932::LR 0.0376923076923 --> Loss 0.00558500250181\n",
      "Epoch 28::Minibatch 933::LR 0.0376923076923 --> Loss 0.00261325399081\n",
      "Epoch 28::Minibatch 934::LR 0.0376923076923 --> Loss 0.00340254108111\n",
      "Epoch 28::Minibatch 935::LR 0.0376923076923 --> Loss 0.00498857537905\n",
      "Epoch 28::Minibatch 936::LR 0.0376923076923 --> Loss 0.00104308843613\n",
      "Epoch 28::Minibatch 937::LR 0.0376923076923 --> Loss 0.00260675787926\n",
      "Epoch 28::Minibatch 938::LR 0.0376923076923 --> Loss 0.00225992341836\n",
      "Epoch 28::Minibatch 939::LR 0.0376923076923 --> Loss 0.0024085611105\n",
      "Epoch 28::Minibatch 940::LR 0.0376923076923 --> Loss 0.000944261749585\n",
      "Epoch 28::Minibatch 941::LR 0.0376923076923 --> Loss 0.000772947818041\n",
      "Epoch 28::Minibatch 942::LR 0.0376923076923 --> Loss 0.0024788437287\n",
      "Epoch 28::Minibatch 943::LR 0.0376923076923 --> Loss 0.00245387852192\n",
      "Epoch 28::Minibatch 944::LR 0.0376923076923 --> Loss 0.00177619616191\n",
      "Epoch 28::Minibatch 945::LR 0.0376923076923 --> Loss 0.00101406753063\n",
      "Epoch 28::Minibatch 946::LR 0.0376923076923 --> Loss 0.00257207830747\n",
      "Epoch 28::Minibatch 947::LR 0.0376923076923 --> Loss 0.00235351204872\n",
      "Epoch 28::Minibatch 948::LR 0.0376923076923 --> Loss 0.00433341940244\n",
      "Epoch 28::Minibatch 949::LR 0.0376923076923 --> Loss 0.00175065616767\n",
      "Epoch 28::Minibatch 950::LR 0.0376923076923 --> Loss 0.000711439947287\n",
      "Epoch 28::Minibatch 951::LR 0.0376923076923 --> Loss 0.00336267232895\n",
      "Epoch 28::Minibatch 952::LR 0.0376923076923 --> Loss 0.00235370000203\n",
      "Epoch 28::Minibatch 953::LR 0.0376923076923 --> Loss 0.00140544474125\n",
      "Epoch 28::Minibatch 954::LR 0.0376923076923 --> Loss 0.000946699182192\n",
      "Epoch 28::Minibatch 955::LR 0.0376923076923 --> Loss 0.00253522177537\n",
      "Epoch 28::Minibatch 956::LR 0.0376923076923 --> Loss 0.00323705355326\n",
      "Epoch 28::Minibatch 957::LR 0.0376923076923 --> Loss 0.00182671964169\n",
      "Epoch 28::Minibatch 958::LR 0.0376923076923 --> Loss 0.00218995928764\n",
      "Epoch 28::Minibatch 959::LR 0.0376923076923 --> Loss 0.00259936153889\n",
      "Epoch 28::Minibatch 960::LR 0.0376923076923 --> Loss 0.00557839711507\n",
      "Epoch 28::Minibatch 961::LR 0.0376923076923 --> Loss 0.00307592888673\n",
      "Epoch 28::Minibatch 962::LR 0.0376923076923 --> Loss 0.00250868022442\n",
      "Epoch 28::Minibatch 963::LR 0.0376923076923 --> Loss 0.001045738856\n",
      "Epoch 28::Minibatch 964::LR 0.0376923076923 --> Loss 0.00234428346157\n",
      "Epoch 28::Minibatch 965::LR 0.0376923076923 --> Loss 0.00653163075447\n",
      "Epoch 28::Minibatch 966::LR 0.0376923076923 --> Loss 0.00491141796112\n",
      "Epoch 28::Minibatch 967::LR 0.0376923076923 --> Loss 0.00131403197845\n",
      "Epoch 28::Minibatch 968::LR 0.0376923076923 --> Loss 0.00111593902111\n",
      "Epoch 28::Minibatch 969::LR 0.0376923076923 --> Loss 0.00504155913989\n",
      "Epoch 28::Minibatch 970::LR 0.0376923076923 --> Loss 0.00482989549637\n",
      "Epoch 28::Minibatch 971::LR 0.0376923076923 --> Loss 0.00336861570676\n",
      "Epoch 28::Minibatch 972::LR 0.0376923076923 --> Loss 0.00886856714884\n",
      "Epoch 28::Minibatch 973::LR 0.0376923076923 --> Loss 0.0091265352567\n",
      "Epoch 28::Minibatch 974::LR 0.0376923076923 --> Loss 0.0082418847084\n",
      "Epoch 28::Minibatch 975::LR 0.0376923076923 --> Loss 0.00439033508301\n",
      "Epoch 28::Minibatch 976::LR 0.0376923076923 --> Loss 0.00373929182688\n",
      "Epoch 28::Minibatch 977::LR 0.0376923076923 --> Loss 0.00355945865313\n",
      "Epoch 28::Minibatch 978::LR 0.0376923076923 --> Loss 0.00350609064102\n",
      "Epoch 28::Minibatch 979::LR 0.0376923076923 --> Loss 0.00331480423609\n",
      "Epoch 28::Minibatch 980::LR 0.0376923076923 --> Loss 0.00360483447711\n",
      "Epoch 28::Minibatch 981::LR 0.0376923076923 --> Loss 0.00457361221313\n",
      "Epoch 28::Minibatch 982::LR 0.0376923076923 --> Loss 0.00495104988416\n",
      "Epoch 28::Minibatch 983::LR 0.0376923076923 --> Loss 0.00267152468363\n",
      "Epoch 28::Minibatch 984::LR 0.0376923076923 --> Loss 0.00196230749289\n",
      "Epoch 28::Minibatch 985::LR 0.0376923076923 --> Loss 0.00362232804298\n",
      "Epoch 28::Minibatch 986::LR 0.0376923076923 --> Loss 0.00330793321133\n",
      "Epoch 28::Minibatch 987::LR 0.0376923076923 --> Loss 0.00359428048134\n",
      "Epoch 28::Minibatch 988::LR 0.0376923076923 --> Loss 0.00287298440933\n",
      "Epoch 28::Minibatch 989::LR 0.0376923076923 --> Loss 0.00311645249526\n",
      "Epoch 28::Minibatch 990::LR 0.0376923076923 --> Loss 0.00287597974141\n",
      "Epoch 28::Minibatch 991::LR 0.0376923076923 --> Loss 0.00148900051912\n",
      "Epoch 28::Minibatch 992::LR 0.0376923076923 --> Loss 0.00169126152992\n",
      "Epoch 28::Minibatch 993::LR 0.0376923076923 --> Loss 0.00313780327638\n",
      "Epoch 28::Minibatch 994::LR 0.0376923076923 --> Loss 0.00203617632389\n",
      "Epoch 28::Minibatch 995::LR 0.0376923076923 --> Loss 0.000823045422633\n",
      "Epoch 28::Minibatch 996::LR 0.0376923076923 --> Loss 0.00277196149031\n",
      "Epoch 28::Minibatch 997::LR 0.0376923076923 --> Loss 0.0022095712026\n",
      "Epoch 28::Minibatch 998::LR 0.0376923076923 --> Loss 0.00251315514247\n",
      "Epoch 28::Minibatch 999::LR 0.0376923076923 --> Loss 0.00213171064854\n",
      "Epoch 28::Minibatch 1000::LR 0.0376923076923 --> Loss 0.00254484375318\n",
      "Epoch 28::Minibatch 1001::LR 0.0376923076923 --> Loss 0.00202641248703\n",
      "Epoch 28::Minibatch 1002::LR 0.0376923076923 --> Loss 0.00171673854192\n",
      "Epoch 28::Minibatch 1003::LR 0.0376923076923 --> Loss 0.00272966464361\n",
      "Epoch 28::Minibatch 1004::LR 0.0376923076923 --> Loss 0.00106982350349\n",
      "Epoch 28::Minibatch 1005::LR 0.0376923076923 --> Loss 0.00272355059783\n",
      "Epoch 28::Minibatch 1006::LR 0.0376923076923 --> Loss 0.00145130872726\n",
      "Epoch 28::Minibatch 1007::LR 0.0376923076923 --> Loss 0.00188379744689\n",
      "Epoch 28::Minibatch 1008::LR 0.0376923076923 --> Loss 0.000932349463304\n",
      "Epoch 28::Minibatch 1009::LR 0.0376923076923 --> Loss 0.00125725736221\n",
      "Epoch 28::Minibatch 1010::LR 0.0376923076923 --> Loss 0.00115137716134\n",
      "Epoch 28::Minibatch 1011::LR 0.0376923076923 --> Loss 0.00185214817524\n",
      "Epoch 28::Minibatch 1012::LR 0.0376923076923 --> Loss 0.0014408437411\n",
      "Epoch 28::Minibatch 1013::LR 0.0376923076923 --> Loss 0.00366264343262\n",
      "Epoch 28::Minibatch 1014::LR 0.0376923076923 --> Loss 0.00342686971029\n",
      "Epoch 28::Minibatch 1015::LR 0.0376923076923 --> Loss 0.00155575573444\n",
      "Epoch 28::Minibatch 1016::LR 0.0376923076923 --> Loss 0.00458250323931\n",
      "Epoch 28::Minibatch 1017::LR 0.0376923076923 --> Loss 0.00310420076052\n",
      "Epoch 28::Minibatch 1018::LR 0.0376923076923 --> Loss 0.00259161353111\n",
      "Epoch 28::Minibatch 1019::LR 0.0376923076923 --> Loss 0.00166240473588\n",
      "Epoch 28::Minibatch 1020::LR 0.0376923076923 --> Loss 0.0017598537604\n",
      "Epoch 28::Minibatch 1021::LR 0.0376923076923 --> Loss 0.00186614235242\n",
      "Epoch 28::Minibatch 1022::LR 0.0376923076923 --> Loss 0.00138462771972\n",
      "Epoch 28::Minibatch 1023::LR 0.0376923076923 --> Loss 0.00104396273692\n",
      "Epoch 28::Minibatch 1024::LR 0.0376923076923 --> Loss 0.00103532075882\n",
      "Epoch 28::Minibatch 1025::LR 0.0376923076923 --> Loss 0.00137514531612\n",
      "Epoch 28::Minibatch 1026::LR 0.0376923076923 --> Loss 0.000723768273989\n",
      "Epoch 28::Minibatch 1027::LR 0.0376923076923 --> Loss 0.000985461473465\n",
      "Epoch 28::Minibatch 1028::LR 0.0376923076923 --> Loss 0.000745339890321\n",
      "Epoch 28::Minibatch 1029::LR 0.0376923076923 --> Loss 0.000747979730368\n",
      "Epoch 28::Minibatch 1030::LR 0.0376923076923 --> Loss 0.000918863316377\n",
      "Epoch 28::Minibatch 1031::LR 0.0376923076923 --> Loss 0.000708051919937\n",
      "Epoch 28::Minibatch 1032::LR 0.0376923076923 --> Loss 0.000778140326341\n",
      "Epoch 28::Minibatch 1033::LR 0.0376923076923 --> Loss 0.000661350737015\n",
      "Epoch 28::Minibatch 1034::LR 0.0376923076923 --> Loss 0.000629647026459\n",
      "Epoch 28::Minibatch 1035::LR 0.0376923076923 --> Loss 0.000417388826609\n",
      "Epoch 28::Minibatch 1036::LR 0.0376923076923 --> Loss 0.000334419583281\n",
      "Epoch 28::Minibatch 1037::LR 0.0376923076923 --> Loss 0.00059709807237\n",
      "Epoch 28::Minibatch 1038::LR 0.0376923076923 --> Loss 0.00113602558772\n",
      "Epoch 28::Minibatch 1039::LR 0.0376923076923 --> Loss 0.000895804166794\n",
      "Epoch 28::Minibatch 1040::LR 0.0376923076923 --> Loss 0.000354701454441\n",
      "Epoch 28::Minibatch 1041::LR 0.0376923076923 --> Loss 0.000511342783769\n",
      "Epoch 29::Minibatch 1::LR 0.0353846153846 --> Loss 0.00793187777201\n",
      "Epoch 29::Minibatch 2::LR 0.0353846153846 --> Loss 0.00488022963206\n",
      "Epoch 29::Minibatch 3::LR 0.0353846153846 --> Loss 0.0032024838527\n",
      "Epoch 29::Minibatch 4::LR 0.0353846153846 --> Loss 0.00388825376829\n",
      "Epoch 29::Minibatch 5::LR 0.0353846153846 --> Loss 0.00444505572319\n",
      "Epoch 29::Minibatch 6::LR 0.0353846153846 --> Loss 0.00213343421618\n",
      "Epoch 29::Minibatch 7::LR 0.0353846153846 --> Loss 0.00724783102671\n",
      "Epoch 29::Minibatch 8::LR 0.0353846153846 --> Loss 0.0067543721199\n",
      "Epoch 29::Minibatch 9::LR 0.0353846153846 --> Loss 0.00519807537397\n",
      "Epoch 29::Minibatch 10::LR 0.0353846153846 --> Loss 0.00243531048298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 11::LR 0.0353846153846 --> Loss 0.00226049145063\n",
      "Epoch 29::Minibatch 12::LR 0.0353846153846 --> Loss 0.00337104439735\n",
      "Epoch 29::Minibatch 13::LR 0.0353846153846 --> Loss 0.00527575651805\n",
      "Epoch 29::Minibatch 14::LR 0.0353846153846 --> Loss 0.00526905020078\n",
      "Epoch 29::Minibatch 15::LR 0.0353846153846 --> Loss 0.0045413839817\n",
      "Epoch 29::Minibatch 16::LR 0.0353846153846 --> Loss 0.000740159650644\n",
      "Epoch 29::Minibatch 17::LR 0.0353846153846 --> Loss 0.00316707392534\n",
      "Epoch 29::Minibatch 18::LR 0.0353846153846 --> Loss 0.00261678218842\n",
      "Epoch 29::Minibatch 19::LR 0.0353846153846 --> Loss 0.00153437236945\n",
      "Epoch 29::Minibatch 20::LR 0.0353846153846 --> Loss 0.00205175777276\n",
      "Epoch 29::Minibatch 21::LR 0.0353846153846 --> Loss 0.003351739645\n",
      "Epoch 29::Minibatch 22::LR 0.0353846153846 --> Loss 0.00222742597262\n",
      "Epoch 29::Minibatch 23::LR 0.0353846153846 --> Loss 0.000876961449782\n",
      "Epoch 29::Minibatch 24::LR 0.0353846153846 --> Loss 0.000472269554933\n",
      "Epoch 29::Minibatch 25::LR 0.0353846153846 --> Loss 0.00128965914249\n",
      "Epoch 29::Minibatch 26::LR 0.0353846153846 --> Loss 0.00148748536905\n",
      "Epoch 29::Minibatch 27::LR 0.0353846153846 --> Loss 0.00108960658312\n",
      "Epoch 29::Minibatch 28::LR 0.0353846153846 --> Loss 0.000475648442904\n",
      "Epoch 29::Minibatch 29::LR 0.0353846153846 --> Loss 0.00055313795805\n",
      "Epoch 29::Minibatch 30::LR 0.0353846153846 --> Loss 0.00103934437037\n",
      "Epoch 29::Minibatch 31::LR 0.0353846153846 --> Loss 0.00152671158314\n",
      "Epoch 29::Minibatch 32::LR 0.0353846153846 --> Loss 0.00136225998402\n",
      "Epoch 29::Minibatch 33::LR 0.0353846153846 --> Loss 0.00079827055335\n",
      "Epoch 29::Minibatch 34::LR 0.0353846153846 --> Loss 0.00206015090148\n",
      "Epoch 29::Minibatch 35::LR 0.0353846153846 --> Loss 0.00316274007161\n",
      "Epoch 29::Minibatch 36::LR 0.0353846153846 --> Loss 0.00226834317048\n",
      "Epoch 29::Minibatch 37::LR 0.0353846153846 --> Loss 0.00069857776165\n",
      "Epoch 29::Minibatch 38::LR 0.0353846153846 --> Loss 0.000724127988021\n",
      "Epoch 29::Minibatch 39::LR 0.0353846153846 --> Loss 0.00218496243159\n",
      "Epoch 29::Minibatch 40::LR 0.0353846153846 --> Loss 0.00310721635818\n",
      "Epoch 29::Minibatch 41::LR 0.0353846153846 --> Loss 0.00248581051826\n",
      "Epoch 29::Minibatch 42::LR 0.0353846153846 --> Loss 0.00484242598216\n",
      "Epoch 29::Minibatch 43::LR 0.0353846153846 --> Loss 0.00198250293732\n",
      "Epoch 29::Minibatch 44::LR 0.0353846153846 --> Loss 0.00324183722337\n",
      "Epoch 29::Minibatch 45::LR 0.0353846153846 --> Loss 0.00239459355672\n",
      "Epoch 29::Minibatch 46::LR 0.0353846153846 --> Loss 0.00311335285505\n",
      "Epoch 29::Minibatch 47::LR 0.0353846153846 --> Loss 0.00348622401555\n",
      "Epoch 29::Minibatch 48::LR 0.0353846153846 --> Loss 0.00500947872798\n",
      "Epoch 29::Minibatch 49::LR 0.0353846153846 --> Loss 0.00561388492584\n",
      "Epoch 29::Minibatch 50::LR 0.0353846153846 --> Loss 0.00602552175522\n",
      "Epoch 29::Minibatch 51::LR 0.0353846153846 --> Loss 0.0046709382534\n",
      "Epoch 29::Minibatch 52::LR 0.0353846153846 --> Loss 0.00342524449031\n",
      "Epoch 29::Minibatch 53::LR 0.0353846153846 --> Loss 0.00338366349538\n",
      "Epoch 29::Minibatch 54::LR 0.0353846153846 --> Loss 0.00399751464526\n",
      "Epoch 29::Minibatch 55::LR 0.0353846153846 --> Loss 0.000990727245808\n",
      "Epoch 29::Minibatch 56::LR 0.0353846153846 --> Loss 0.00272481620312\n",
      "Epoch 29::Minibatch 57::LR 0.0353846153846 --> Loss 0.00471964319547\n",
      "Epoch 29::Minibatch 58::LR 0.0353846153846 --> Loss 0.00321844220161\n",
      "Epoch 29::Minibatch 59::LR 0.0353846153846 --> Loss 0.00243408580621\n",
      "Epoch 29::Minibatch 60::LR 0.0353846153846 --> Loss 0.00245898346106\n",
      "Epoch 29::Minibatch 61::LR 0.0353846153846 --> Loss 0.000737638970216\n",
      "Epoch 29::Minibatch 62::LR 0.0353846153846 --> Loss 0.00259936988354\n",
      "Epoch 29::Minibatch 63::LR 0.0353846153846 --> Loss 0.00201520562172\n",
      "Epoch 29::Minibatch 64::LR 0.0353846153846 --> Loss 0.000827002127965\n",
      "Epoch 29::Minibatch 65::LR 0.0353846153846 --> Loss 0.00216490924358\n",
      "Epoch 29::Minibatch 66::LR 0.0353846153846 --> Loss 0.00273161451022\n",
      "Epoch 29::Minibatch 67::LR 0.0353846153846 --> Loss 0.00254665652911\n",
      "Epoch 29::Minibatch 68::LR 0.0353846153846 --> Loss 0.00184708833694\n",
      "Epoch 29::Minibatch 69::LR 0.0353846153846 --> Loss 0.00366096615791\n",
      "Epoch 29::Minibatch 70::LR 0.0353846153846 --> Loss 0.00323519468307\n",
      "Epoch 29::Minibatch 71::LR 0.0353846153846 --> Loss 0.00224957108498\n",
      "Epoch 29::Minibatch 72::LR 0.0353846153846 --> Loss 0.000544165074825\n",
      "Epoch 29::Minibatch 73::LR 0.0353846153846 --> Loss 0.00371553262075\n",
      "Epoch 29::Minibatch 74::LR 0.0353846153846 --> Loss 0.0040068646272\n",
      "Epoch 29::Minibatch 75::LR 0.0353846153846 --> Loss 0.00213157097499\n",
      "Epoch 29::Minibatch 76::LR 0.0353846153846 --> Loss 0.000524703860283\n",
      "Epoch 29::Minibatch 77::LR 0.0353846153846 --> Loss 0.00336791316668\n",
      "Epoch 29::Minibatch 78::LR 0.0353846153846 --> Loss 0.00389954129855\n",
      "Epoch 29::Minibatch 79::LR 0.0353846153846 --> Loss 0.00174211541812\n",
      "Epoch 29::Minibatch 80::LR 0.0353846153846 --> Loss 0.00288718144099\n",
      "Epoch 29::Minibatch 81::LR 0.0353846153846 --> Loss 0.00254660805066\n",
      "Epoch 29::Minibatch 82::LR 0.0353846153846 --> Loss 0.00185819804668\n",
      "Epoch 29::Minibatch 83::LR 0.0353846153846 --> Loss 0.00397241711617\n",
      "Epoch 29::Minibatch 84::LR 0.0353846153846 --> Loss 0.00187240242958\n",
      "Epoch 29::Minibatch 85::LR 0.0353846153846 --> Loss 0.0025583144029\n",
      "Epoch 29::Minibatch 86::LR 0.0353846153846 --> Loss 0.00209995706876\n",
      "Epoch 29::Minibatch 87::LR 0.0353846153846 --> Loss 0.00224062780539\n",
      "Epoch 29::Minibatch 88::LR 0.0353846153846 --> Loss 0.00167691230774\n",
      "Epoch 29::Minibatch 89::LR 0.0353846153846 --> Loss 0.00220488031705\n",
      "Epoch 29::Minibatch 90::LR 0.0353846153846 --> Loss 0.00104748636484\n",
      "Epoch 29::Minibatch 91::LR 0.0353846153846 --> Loss 0.00086800634861\n",
      "Epoch 29::Minibatch 92::LR 0.0353846153846 --> Loss 0.00256889561812\n",
      "Epoch 29::Minibatch 93::LR 0.0353846153846 --> Loss 0.00170227269332\n",
      "Epoch 29::Minibatch 94::LR 0.0353846153846 --> Loss 0.00173766553402\n",
      "Epoch 29::Minibatch 95::LR 0.0353846153846 --> Loss 0.00188492655754\n",
      "Epoch 29::Minibatch 96::LR 0.0353846153846 --> Loss 0.00490558624268\n",
      "Epoch 29::Minibatch 97::LR 0.0353846153846 --> Loss 0.00303209940592\n",
      "Epoch 29::Minibatch 98::LR 0.0353846153846 --> Loss 0.00106122503678\n",
      "Epoch 29::Minibatch 99::LR 0.0353846153846 --> Loss 0.00138416777054\n",
      "Epoch 29::Minibatch 100::LR 0.0353846153846 --> Loss 0.00434735059738\n",
      "Epoch 29::Minibatch 101::LR 0.0353846153846 --> Loss 0.000898891488711\n",
      "Epoch 29::Minibatch 102::LR 0.0353846153846 --> Loss 0.00387628316879\n",
      "Epoch 29::Minibatch 103::LR 0.0353846153846 --> Loss 0.00391055703163\n",
      "Epoch 29::Minibatch 104::LR 0.0353846153846 --> Loss 0.00266770144304\n",
      "Epoch 29::Minibatch 105::LR 0.0353846153846 --> Loss 0.00216890315215\n",
      "Epoch 29::Minibatch 106::LR 0.0353846153846 --> Loss 0.0144014644623\n",
      "Epoch 29::Minibatch 107::LR 0.0353846153846 --> Loss 0.0047755920887\n",
      "Epoch 29::Minibatch 108::LR 0.0353846153846 --> Loss 0.000939943989118\n",
      "Epoch 29::Minibatch 109::LR 0.0353846153846 --> Loss 0.00429548462232\n",
      "Epoch 29::Minibatch 110::LR 0.0353846153846 --> Loss 0.00222560564677\n",
      "Epoch 29::Minibatch 111::LR 0.0353846153846 --> Loss 0.000829077363014\n",
      "Epoch 29::Minibatch 112::LR 0.0353846153846 --> Loss 0.00330071091652\n",
      "Epoch 29::Minibatch 113::LR 0.0353846153846 --> Loss 0.00241063396136\n",
      "Epoch 29::Minibatch 114::LR 0.0353846153846 --> Loss 0.00134532848994\n",
      "Epoch 29::Minibatch 115::LR 0.0353846153846 --> Loss 0.00115511963765\n",
      "Epoch 29::Minibatch 116::LR 0.0353846153846 --> Loss 0.00262861073017\n",
      "Epoch 29::Minibatch 117::LR 0.0353846153846 --> Loss 0.00401633024216\n",
      "Epoch 29::Minibatch 118::LR 0.0353846153846 --> Loss 0.0066030005614\n",
      "Epoch 29::Minibatch 119::LR 0.0353846153846 --> Loss 0.000514936844508\n",
      "Epoch 29::Minibatch 120::LR 0.0353846153846 --> Loss 0.00162855972846\n",
      "Epoch 29::Minibatch 121::LR 0.0353846153846 --> Loss 0.00238697767258\n",
      "Epoch 29::Minibatch 122::LR 0.0353846153846 --> Loss 0.00379999279976\n",
      "Epoch 29::Minibatch 123::LR 0.0353846153846 --> Loss 0.000724135637283\n",
      "Epoch 29::Minibatch 124::LR 0.0353846153846 --> Loss 0.00260254303614\n",
      "Epoch 29::Minibatch 125::LR 0.0353846153846 --> Loss 0.00443084994952\n",
      "Epoch 29::Minibatch 126::LR 0.0353846153846 --> Loss 0.00248480796814\n",
      "Epoch 29::Minibatch 127::LR 0.0353846153846 --> Loss 0.00471449335416\n",
      "Epoch 29::Minibatch 128::LR 0.0353846153846 --> Loss 0.00352326631546\n",
      "Epoch 29::Minibatch 129::LR 0.0353846153846 --> Loss 0.00244290391604\n",
      "Epoch 29::Minibatch 130::LR 0.0353846153846 --> Loss 0.00432031750679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 131::LR 0.0353846153846 --> Loss 0.00171978433927\n",
      "Epoch 29::Minibatch 132::LR 0.0353846153846 --> Loss 0.00286133249601\n",
      "Epoch 29::Minibatch 133::LR 0.0353846153846 --> Loss 0.00274566888809\n",
      "Epoch 29::Minibatch 134::LR 0.0353846153846 --> Loss 0.00214725752672\n",
      "Epoch 29::Minibatch 135::LR 0.0353846153846 --> Loss 0.0013275423646\n",
      "Epoch 29::Minibatch 136::LR 0.0353846153846 --> Loss 0.00247404833635\n",
      "Epoch 29::Minibatch 137::LR 0.0353846153846 --> Loss 0.00343577941259\n",
      "Epoch 29::Minibatch 138::LR 0.0353846153846 --> Loss 0.00122828791539\n",
      "Epoch 29::Minibatch 139::LR 0.0353846153846 --> Loss 0.00188034613927\n",
      "Epoch 29::Minibatch 140::LR 0.0353846153846 --> Loss 0.00239864647388\n",
      "Epoch 29::Minibatch 141::LR 0.0353846153846 --> Loss 0.00290575345357\n",
      "Epoch 29::Minibatch 142::LR 0.0353846153846 --> Loss 0.00271078606447\n",
      "Epoch 29::Minibatch 143::LR 0.0353846153846 --> Loss 0.000550600091616\n",
      "Epoch 29::Minibatch 144::LR 0.0353846153846 --> Loss 0.00333030839761\n",
      "Epoch 29::Minibatch 145::LR 0.0353846153846 --> Loss 0.00415003379186\n",
      "Epoch 29::Minibatch 146::LR 0.0353846153846 --> Loss 0.00250735163689\n",
      "Epoch 29::Minibatch 147::LR 0.0353846153846 --> Loss 0.00178974966208\n",
      "Epoch 29::Minibatch 148::LR 0.0353846153846 --> Loss 0.000978997548421\n",
      "Epoch 29::Minibatch 149::LR 0.0353846153846 --> Loss 0.00284853557746\n",
      "Epoch 29::Minibatch 150::LR 0.0353846153846 --> Loss 0.00266865332921\n",
      "Epoch 29::Minibatch 151::LR 0.0353846153846 --> Loss 0.0042665930589\n",
      "Epoch 29::Minibatch 152::LR 0.0353846153846 --> Loss 0.000905864636103\n",
      "Epoch 29::Minibatch 153::LR 0.0353846153846 --> Loss 0.00167072912057\n",
      "Epoch 29::Minibatch 154::LR 0.0353846153846 --> Loss 0.00201884826024\n",
      "Epoch 29::Minibatch 155::LR 0.0353846153846 --> Loss 0.00413882017136\n",
      "Epoch 29::Minibatch 156::LR 0.0353846153846 --> Loss 0.00235816299915\n",
      "Epoch 29::Minibatch 157::LR 0.0353846153846 --> Loss 0.000688949525356\n",
      "Epoch 29::Minibatch 158::LR 0.0353846153846 --> Loss 0.00313344736894\n",
      "Epoch 29::Minibatch 159::LR 0.0353846153846 --> Loss 0.00272753973802\n",
      "Epoch 29::Minibatch 160::LR 0.0353846153846 --> Loss 0.00263963182767\n",
      "Epoch 29::Minibatch 161::LR 0.0353846153846 --> Loss 0.00100532452265\n",
      "Epoch 29::Minibatch 162::LR 0.0353846153846 --> Loss 0.00389608780543\n",
      "Epoch 29::Minibatch 163::LR 0.0353846153846 --> Loss 0.00239387214184\n",
      "Epoch 29::Minibatch 164::LR 0.0353846153846 --> Loss 0.00251782695452\n",
      "Epoch 29::Minibatch 165::LR 0.0353846153846 --> Loss 0.000504844039679\n",
      "Epoch 29::Minibatch 166::LR 0.0353846153846 --> Loss 0.00172330041726\n",
      "Epoch 29::Minibatch 167::LR 0.0353846153846 --> Loss 0.00246734023094\n",
      "Epoch 29::Minibatch 168::LR 0.0353846153846 --> Loss 0.00214877486229\n",
      "Epoch 29::Minibatch 169::LR 0.0353846153846 --> Loss 0.000996384421984\n",
      "Epoch 29::Minibatch 170::LR 0.0353846153846 --> Loss 0.000962939659754\n",
      "Epoch 29::Minibatch 171::LR 0.0353846153846 --> Loss 0.00250187516212\n",
      "Epoch 29::Minibatch 172::LR 0.0353846153846 --> Loss 0.0042578736941\n",
      "Epoch 29::Minibatch 173::LR 0.0353846153846 --> Loss 0.00197537382444\n",
      "Epoch 29::Minibatch 174::LR 0.0353846153846 --> Loss 0.000977494716644\n",
      "Epoch 29::Minibatch 175::LR 0.0353846153846 --> Loss 0.00233981013298\n",
      "Epoch 29::Minibatch 176::LR 0.0353846153846 --> Loss 0.00315168718497\n",
      "Epoch 29::Minibatch 177::LR 0.0353846153846 --> Loss 0.00432887832324\n",
      "Epoch 29::Minibatch 178::LR 0.0353846153846 --> Loss 0.00153468887011\n",
      "Epoch 29::Minibatch 179::LR 0.0353846153846 --> Loss 0.00124104032914\n",
      "Epoch 29::Minibatch 180::LR 0.0353846153846 --> Loss 0.00343671162923\n",
      "Epoch 29::Minibatch 181::LR 0.0353846153846 --> Loss 0.00309781610966\n",
      "Epoch 29::Minibatch 182::LR 0.0353846153846 --> Loss 0.000722380280495\n",
      "Epoch 29::Minibatch 183::LR 0.0353846153846 --> Loss 0.00159462600946\n",
      "Epoch 29::Minibatch 184::LR 0.0353846153846 --> Loss 0.00341527024905\n",
      "Epoch 29::Minibatch 185::LR 0.0353846153846 --> Loss 0.00271907091141\n",
      "Epoch 29::Minibatch 186::LR 0.0353846153846 --> Loss 0.00094213138024\n",
      "Epoch 29::Minibatch 187::LR 0.0353846153846 --> Loss 0.00127658714851\n",
      "Epoch 29::Minibatch 188::LR 0.0353846153846 --> Loss 0.00409319321314\n",
      "Epoch 29::Minibatch 189::LR 0.0353846153846 --> Loss 0.00419930378596\n",
      "Epoch 29::Minibatch 190::LR 0.0353846153846 --> Loss 0.00232092281183\n",
      "Epoch 29::Minibatch 191::LR 0.0353846153846 --> Loss 0.00045687849323\n",
      "Epoch 29::Minibatch 192::LR 0.0353846153846 --> Loss 0.00276259799798\n",
      "Epoch 29::Minibatch 193::LR 0.0353846153846 --> Loss 0.00266095777353\n",
      "Epoch 29::Minibatch 194::LR 0.0353846153846 --> Loss 0.00174992521604\n",
      "Epoch 29::Minibatch 195::LR 0.0353846153846 --> Loss 0.000378007665277\n",
      "Epoch 29::Minibatch 196::LR 0.0353846153846 --> Loss 0.0013208826383\n",
      "Epoch 29::Minibatch 197::LR 0.0353846153846 --> Loss 0.00293870985508\n",
      "Epoch 29::Minibatch 198::LR 0.0353846153846 --> Loss 0.00228245337804\n",
      "Epoch 29::Minibatch 199::LR 0.0353846153846 --> Loss 0.000289534231027\n",
      "Epoch 29::Minibatch 200::LR 0.0353846153846 --> Loss 0.00204106152058\n",
      "Epoch 29::Minibatch 201::LR 0.0353846153846 --> Loss 0.00193541069825\n",
      "Epoch 29::Minibatch 202::LR 0.0353846153846 --> Loss 0.0018280963103\n",
      "Epoch 29::Minibatch 203::LR 0.0353846153846 --> Loss 0.00174897114436\n",
      "Epoch 29::Minibatch 204::LR 0.0353846153846 --> Loss 0.00141995420059\n",
      "Epoch 29::Minibatch 205::LR 0.0353846153846 --> Loss 0.00220441023509\n",
      "Epoch 29::Minibatch 206::LR 0.0353846153846 --> Loss 0.00572284142176\n",
      "Epoch 29::Minibatch 207::LR 0.0353846153846 --> Loss 0.00139784346024\n",
      "Epoch 29::Minibatch 208::LR 0.0353846153846 --> Loss 0.00110791583856\n",
      "Epoch 29::Minibatch 209::LR 0.0353846153846 --> Loss 0.00241270105044\n",
      "Epoch 29::Minibatch 210::LR 0.0353846153846 --> Loss 0.0022831906875\n",
      "Epoch 29::Minibatch 211::LR 0.0353846153846 --> Loss 0.0025722916921\n",
      "Epoch 29::Minibatch 212::LR 0.0353846153846 --> Loss 0.00381027062734\n",
      "Epoch 29::Minibatch 213::LR 0.0353846153846 --> Loss 0.0054964919885\n",
      "Epoch 29::Minibatch 214::LR 0.0353846153846 --> Loss 0.00759978532791\n",
      "Epoch 29::Minibatch 215::LR 0.0353846153846 --> Loss 0.00135986675819\n",
      "Epoch 29::Minibatch 216::LR 0.0353846153846 --> Loss 0.00534026106199\n",
      "Epoch 29::Minibatch 217::LR 0.0353846153846 --> Loss 0.00592665513357\n",
      "Epoch 29::Minibatch 218::LR 0.0353846153846 --> Loss 0.00390126506488\n",
      "Epoch 29::Minibatch 219::LR 0.0353846153846 --> Loss 0.00434383591016\n",
      "Epoch 29::Minibatch 220::LR 0.0353846153846 --> Loss 0.00438356876373\n",
      "Epoch 29::Minibatch 221::LR 0.0353846153846 --> Loss 0.00423915982246\n",
      "Epoch 29::Minibatch 222::LR 0.0353846153846 --> Loss 0.0031771504879\n",
      "Epoch 29::Minibatch 223::LR 0.0353846153846 --> Loss 0.00138979971409\n",
      "Epoch 29::Minibatch 224::LR 0.0353846153846 --> Loss 0.00162681261698\n",
      "Epoch 29::Minibatch 225::LR 0.0353846153846 --> Loss 0.0076681192716\n",
      "Epoch 29::Minibatch 226::LR 0.0353846153846 --> Loss 0.00369236548742\n",
      "Epoch 29::Minibatch 227::LR 0.0353846153846 --> Loss 0.00167973836263\n",
      "Epoch 29::Minibatch 228::LR 0.0353846153846 --> Loss 0.00067212253809\n",
      "Epoch 29::Minibatch 229::LR 0.0353846153846 --> Loss 0.00471111615499\n",
      "Epoch 29::Minibatch 230::LR 0.0353846153846 --> Loss 0.00374675273895\n",
      "Epoch 29::Minibatch 231::LR 0.0353846153846 --> Loss 0.00265791495641\n",
      "Epoch 29::Minibatch 232::LR 0.0353846153846 --> Loss 0.00117433289687\n",
      "Epoch 29::Minibatch 233::LR 0.0353846153846 --> Loss 0.00245180666447\n",
      "Epoch 29::Minibatch 234::LR 0.0353846153846 --> Loss 0.00722405751546\n",
      "Epoch 29::Minibatch 235::LR 0.0353846153846 --> Loss 0.00457095702489\n",
      "Epoch 29::Minibatch 236::LR 0.0353846153846 --> Loss 0.00169454832872\n",
      "Epoch 29::Minibatch 237::LR 0.0353846153846 --> Loss 0.000611736426751\n",
      "Epoch 29::Minibatch 238::LR 0.0353846153846 --> Loss 0.00342183550199\n",
      "Epoch 29::Minibatch 239::LR 0.0353846153846 --> Loss 0.00295774797599\n",
      "Epoch 29::Minibatch 240::LR 0.0353846153846 --> Loss 0.00324196537336\n",
      "Epoch 29::Minibatch 241::LR 0.0353846153846 --> Loss 0.000745207220316\n",
      "Epoch 29::Minibatch 242::LR 0.0353846153846 --> Loss 0.0067829767863\n",
      "Epoch 29::Minibatch 243::LR 0.0353846153846 --> Loss 0.00331999937693\n",
      "Epoch 29::Minibatch 244::LR 0.0353846153846 --> Loss 0.00278538326422\n",
      "Epoch 29::Minibatch 245::LR 0.0353846153846 --> Loss 0.000440732041995\n",
      "Epoch 29::Minibatch 246::LR 0.0353846153846 --> Loss 0.0019486006101\n",
      "Epoch 29::Minibatch 247::LR 0.0353846153846 --> Loss 0.011129749616\n",
      "Epoch 29::Minibatch 248::LR 0.0353846153846 --> Loss 0.00436932603518\n",
      "Epoch 29::Minibatch 249::LR 0.0353846153846 --> Loss 0.00246769805749\n",
      "Epoch 29::Minibatch 250::LR 0.0353846153846 --> Loss 0.00238670667013\n",
      "Epoch 29::Minibatch 251::LR 0.0353846153846 --> Loss 0.00236721694469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 252::LR 0.0353846153846 --> Loss 0.00164826263984\n",
      "Epoch 29::Minibatch 253::LR 0.0353846153846 --> Loss 0.0028674441576\n",
      "Epoch 29::Minibatch 254::LR 0.0353846153846 --> Loss 0.00489719390869\n",
      "Epoch 29::Minibatch 255::LR 0.0353846153846 --> Loss 0.0038241203626\n",
      "Epoch 29::Minibatch 256::LR 0.0353846153846 --> Loss 0.00145348330339\n",
      "Epoch 29::Minibatch 257::LR 0.0353846153846 --> Loss 0.00115389446417\n",
      "Epoch 29::Minibatch 258::LR 0.0353846153846 --> Loss 0.00364434361458\n",
      "Epoch 29::Minibatch 259::LR 0.0353846153846 --> Loss 0.00164008190235\n",
      "Epoch 29::Minibatch 260::LR 0.0353846153846 --> Loss 0.00185089071592\n",
      "Epoch 29::Minibatch 261::LR 0.0353846153846 --> Loss 0.00269315779209\n",
      "Epoch 29::Minibatch 262::LR 0.0353846153846 --> Loss 0.0018376660347\n",
      "Epoch 29::Minibatch 263::LR 0.0353846153846 --> Loss 0.00230593125025\n",
      "Epoch 29::Minibatch 264::LR 0.0353846153846 --> Loss 0.00357261737188\n",
      "Epoch 29::Minibatch 265::LR 0.0353846153846 --> Loss 0.00994485855103\n",
      "Epoch 29::Minibatch 266::LR 0.0353846153846 --> Loss 0.000915838479996\n",
      "Epoch 29::Minibatch 267::LR 0.0353846153846 --> Loss 0.0093026971817\n",
      "Epoch 29::Minibatch 268::LR 0.0353846153846 --> Loss 0.00107245951891\n",
      "Epoch 29::Minibatch 269::LR 0.0353846153846 --> Loss 0.00347911596298\n",
      "Epoch 29::Minibatch 270::LR 0.0353846153846 --> Loss 0.00711738745372\n",
      "Epoch 29::Minibatch 271::LR 0.0353846153846 --> Loss 0.00249356110891\n",
      "Epoch 29::Minibatch 272::LR 0.0353846153846 --> Loss 0.00434377948443\n",
      "Epoch 29::Minibatch 273::LR 0.0353846153846 --> Loss 0.00145097523928\n",
      "Epoch 29::Minibatch 274::LR 0.0353846153846 --> Loss 0.00177795251211\n",
      "Epoch 29::Minibatch 275::LR 0.0353846153846 --> Loss 0.00251074115435\n",
      "Epoch 29::Minibatch 276::LR 0.0353846153846 --> Loss 0.00338461478551\n",
      "Epoch 29::Minibatch 277::LR 0.0353846153846 --> Loss 0.000901355743408\n",
      "Epoch 29::Minibatch 278::LR 0.0353846153846 --> Loss 0.00256402552128\n",
      "Epoch 29::Minibatch 279::LR 0.0353846153846 --> Loss 0.00209437390169\n",
      "Epoch 29::Minibatch 280::LR 0.0353846153846 --> Loss 0.00184538523356\n",
      "Epoch 29::Minibatch 281::LR 0.0353846153846 --> Loss 0.00117009460926\n",
      "Epoch 29::Minibatch 282::LR 0.0353846153846 --> Loss 0.00207358896732\n",
      "Epoch 29::Minibatch 283::LR 0.0353846153846 --> Loss 0.00198655426502\n",
      "Epoch 29::Minibatch 284::LR 0.0353846153846 --> Loss 0.00161370615164\n",
      "Epoch 29::Minibatch 285::LR 0.0353846153846 --> Loss 0.00115260432164\n",
      "Epoch 29::Minibatch 286::LR 0.0353846153846 --> Loss 0.00201193233331\n",
      "Epoch 29::Minibatch 287::LR 0.0353846153846 --> Loss 0.0019818709294\n",
      "Epoch 29::Minibatch 288::LR 0.0353846153846 --> Loss 0.00107810735703\n",
      "Epoch 29::Minibatch 289::LR 0.0353846153846 --> Loss 0.0015792859594\n",
      "Epoch 29::Minibatch 290::LR 0.0353846153846 --> Loss 0.00187878588835\n",
      "Epoch 29::Minibatch 291::LR 0.0353846153846 --> Loss 0.0016837455829\n",
      "Epoch 29::Minibatch 292::LR 0.0353846153846 --> Loss 0.000594718257586\n",
      "Epoch 29::Minibatch 293::LR 0.0353846153846 --> Loss 0.00150004088879\n",
      "Epoch 29::Minibatch 294::LR 0.0353846153846 --> Loss 0.00160925557216\n",
      "Epoch 29::Minibatch 295::LR 0.0353846153846 --> Loss 0.0018845363458\n",
      "Epoch 29::Minibatch 296::LR 0.0353846153846 --> Loss 0.00163167734941\n",
      "Epoch 29::Minibatch 297::LR 0.0353846153846 --> Loss 0.00142293900251\n",
      "Epoch 29::Minibatch 298::LR 0.0353846153846 --> Loss 0.00142260283232\n",
      "Epoch 29::Minibatch 299::LR 0.0353846153846 --> Loss 0.000813682029645\n",
      "Epoch 29::Minibatch 300::LR 0.0353846153846 --> Loss 0.00271337290605\n",
      "Epoch 29::Minibatch 301::LR 0.0353846153846 --> Loss 0.00262429674466\n",
      "Epoch 29::Minibatch 302::LR 0.0353846153846 --> Loss 0.00240533828735\n",
      "Epoch 29::Minibatch 303::LR 0.0353846153846 --> Loss 0.000840134123961\n",
      "Epoch 29::Minibatch 304::LR 0.0353846153846 --> Loss 0.00297384560108\n",
      "Epoch 29::Minibatch 305::LR 0.0353846153846 --> Loss 0.00171100854874\n",
      "Epoch 29::Minibatch 306::LR 0.0353846153846 --> Loss 0.000940075814724\n",
      "Epoch 29::Minibatch 307::LR 0.0353846153846 --> Loss 0.00241212228934\n",
      "Epoch 29::Minibatch 308::LR 0.0353846153846 --> Loss 0.00202103018761\n",
      "Epoch 29::Minibatch 309::LR 0.0353846153846 --> Loss 0.00103945116202\n",
      "Epoch 29::Minibatch 310::LR 0.0353846153846 --> Loss 0.0011852055788\n",
      "Epoch 29::Minibatch 311::LR 0.0353846153846 --> Loss 0.00178787648678\n",
      "Epoch 29::Minibatch 312::LR 0.0353846153846 --> Loss 0.00286696453889\n",
      "Epoch 29::Minibatch 313::LR 0.0353846153846 --> Loss 0.0023519239823\n",
      "Epoch 29::Minibatch 314::LR 0.0353846153846 --> Loss 0.00192384660244\n",
      "Epoch 29::Minibatch 315::LR 0.0353846153846 --> Loss 0.00104118973017\n",
      "Epoch 29::Minibatch 316::LR 0.0353846153846 --> Loss 0.0023430343469\n",
      "Epoch 29::Minibatch 317::LR 0.0353846153846 --> Loss 0.00156200687091\n",
      "Epoch 29::Minibatch 318::LR 0.0353846153846 --> Loss 0.0012963878115\n",
      "Epoch 29::Minibatch 319::LR 0.0353846153846 --> Loss 0.00230788906415\n",
      "Epoch 29::Minibatch 320::LR 0.0353846153846 --> Loss 0.00306456287702\n",
      "Epoch 29::Minibatch 321::LR 0.0353846153846 --> Loss 0.000841687520345\n",
      "Epoch 29::Minibatch 322::LR 0.0353846153846 --> Loss 0.00349699338277\n",
      "Epoch 29::Minibatch 323::LR 0.0353846153846 --> Loss 0.00343575000763\n",
      "Epoch 29::Minibatch 324::LR 0.0353846153846 --> Loss 0.00264716943105\n",
      "Epoch 29::Minibatch 325::LR 0.0353846153846 --> Loss 0.00237521588802\n",
      "Epoch 29::Minibatch 326::LR 0.0353846153846 --> Loss 0.00534086664518\n",
      "Epoch 29::Minibatch 327::LR 0.0353846153846 --> Loss 0.00223767280579\n",
      "Epoch 29::Minibatch 328::LR 0.0353846153846 --> Loss 0.00300594826539\n",
      "Epoch 29::Minibatch 329::LR 0.0353846153846 --> Loss 0.00119739154975\n",
      "Epoch 29::Minibatch 330::LR 0.0353846153846 --> Loss 0.0015898189942\n",
      "Epoch 29::Minibatch 331::LR 0.0353846153846 --> Loss 0.00253415425618\n",
      "Epoch 29::Minibatch 332::LR 0.0353846153846 --> Loss 0.0024639193217\n",
      "Epoch 29::Minibatch 333::LR 0.0353846153846 --> Loss 0.00146408061186\n",
      "Epoch 29::Minibatch 334::LR 0.0353846153846 --> Loss 0.00441768964132\n",
      "Epoch 29::Minibatch 335::LR 0.0353846153846 --> Loss 0.00189586341381\n",
      "Epoch 29::Minibatch 336::LR 0.0353846153846 --> Loss 0.0022456719478\n",
      "Epoch 29::Minibatch 337::LR 0.0353846153846 --> Loss 0.00368172287941\n",
      "Epoch 29::Minibatch 338::LR 0.0353846153846 --> Loss 0.000548784583807\n",
      "Epoch 29::Minibatch 339::LR 0.0353846153846 --> Loss 0.0032674608628\n",
      "Epoch 29::Minibatch 340::LR 0.0353846153846 --> Loss 0.0037394742171\n",
      "Epoch 29::Minibatch 341::LR 0.0353846153846 --> Loss 0.0043942797184\n",
      "Epoch 29::Minibatch 342::LR 0.0353846153846 --> Loss 0.00306683619817\n",
      "Epoch 29::Minibatch 343::LR 0.0353846153846 --> Loss 0.00164241224527\n",
      "Epoch 29::Minibatch 344::LR 0.0353846153846 --> Loss 0.00316017727057\n",
      "Epoch 29::Minibatch 345::LR 0.0353846153846 --> Loss 0.00411892731984\n",
      "Epoch 29::Minibatch 346::LR 0.0353846153846 --> Loss 0.00543445825577\n",
      "Epoch 29::Minibatch 347::LR 0.0353846153846 --> Loss 0.000818652709325\n",
      "Epoch 29::Minibatch 348::LR 0.0353846153846 --> Loss 0.00306895275911\n",
      "Epoch 29::Minibatch 349::LR 0.0353846153846 --> Loss 0.0033969505628\n",
      "Epoch 29::Minibatch 350::LR 0.0353846153846 --> Loss 0.00165959447622\n",
      "Epoch 29::Minibatch 351::LR 0.0353846153846 --> Loss 0.00343999306361\n",
      "Epoch 29::Minibatch 352::LR 0.0353846153846 --> Loss 0.0049202978611\n",
      "Epoch 29::Minibatch 353::LR 0.0353846153846 --> Loss 0.00351607879003\n",
      "Epoch 29::Minibatch 354::LR 0.0353846153846 --> Loss 0.00294323861599\n",
      "Epoch 29::Minibatch 355::LR 0.0353846153846 --> Loss 0.00622060775757\n",
      "Epoch 29::Minibatch 356::LR 0.0353846153846 --> Loss 0.00314251820246\n",
      "Epoch 29::Minibatch 357::LR 0.0353846153846 --> Loss 0.00115313400825\n",
      "Epoch 29::Minibatch 358::LR 0.0353846153846 --> Loss 0.00198235412439\n",
      "Epoch 29::Minibatch 359::LR 0.0353846153846 --> Loss 0.00268235286077\n",
      "Epoch 29::Minibatch 360::LR 0.0353846153846 --> Loss 0.00232088605563\n",
      "Epoch 29::Minibatch 361::LR 0.0353846153846 --> Loss 0.00229453682899\n",
      "Epoch 29::Minibatch 362::LR 0.0353846153846 --> Loss 0.00227753818035\n",
      "Epoch 29::Minibatch 363::LR 0.0353846153846 --> Loss 0.00063953007261\n",
      "Epoch 29::Minibatch 364::LR 0.0353846153846 --> Loss 0.00197616954645\n",
      "Epoch 29::Minibatch 365::LR 0.0353846153846 --> Loss 0.00202071328958\n",
      "Epoch 29::Minibatch 366::LR 0.0353846153846 --> Loss 0.00214360495408\n",
      "Epoch 29::Minibatch 367::LR 0.0353846153846 --> Loss 0.00101084719102\n",
      "Epoch 29::Minibatch 368::LR 0.0353846153846 --> Loss 0.000974219441414\n",
      "Epoch 29::Minibatch 369::LR 0.0353846153846 --> Loss 0.00278847475847\n",
      "Epoch 29::Minibatch 370::LR 0.0353846153846 --> Loss 0.00222193260988\n",
      "Epoch 29::Minibatch 371::LR 0.0353846153846 --> Loss 0.00185497244199\n",
      "Epoch 29::Minibatch 372::LR 0.0353846153846 --> Loss 0.000429260532061\n",
      "Epoch 29::Minibatch 373::LR 0.0353846153846 --> Loss 0.00179940879345\n",
      "Epoch 29::Minibatch 374::LR 0.0353846153846 --> Loss 0.0022433368365\n",
      "Epoch 29::Minibatch 375::LR 0.0353846153846 --> Loss 0.00187864383062\n",
      "Epoch 29::Minibatch 376::LR 0.0353846153846 --> Loss 0.00121649612983\n",
      "Epoch 29::Minibatch 377::LR 0.0353846153846 --> Loss 0.00191560049852\n",
      "Epoch 29::Minibatch 378::LR 0.0353846153846 --> Loss 0.00210078239441\n",
      "Epoch 29::Minibatch 379::LR 0.0353846153846 --> Loss 0.00233239789804\n",
      "Epoch 29::Minibatch 380::LR 0.0353846153846 --> Loss 0.00156902949015\n",
      "Epoch 29::Minibatch 381::LR 0.0353846153846 --> Loss 0.000990342994531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 382::LR 0.0353846153846 --> Loss 0.00202910224597\n",
      "Epoch 29::Minibatch 383::LR 0.0353846153846 --> Loss 0.00198245505492\n",
      "Epoch 29::Minibatch 384::LR 0.0353846153846 --> Loss 0.0011032479008\n",
      "Epoch 29::Minibatch 385::LR 0.0353846153846 --> Loss 0.00105104257663\n",
      "Epoch 29::Minibatch 386::LR 0.0353846153846 --> Loss 0.00222768187523\n",
      "Epoch 29::Minibatch 387::LR 0.0353846153846 --> Loss 0.0023595482111\n",
      "Epoch 29::Minibatch 388::LR 0.0353846153846 --> Loss 0.00120014746984\n",
      "Epoch 29::Minibatch 389::LR 0.0353846153846 --> Loss 0.00178439756234\n",
      "Epoch 29::Minibatch 390::LR 0.0353846153846 --> Loss 0.00331739584605\n",
      "Epoch 29::Minibatch 391::LR 0.0353846153846 --> Loss 0.00257320066293\n",
      "Epoch 29::Minibatch 392::LR 0.0353846153846 --> Loss 0.00256683250268\n",
      "Epoch 29::Minibatch 393::LR 0.0353846153846 --> Loss 0.00273511012395\n",
      "Epoch 29::Minibatch 394::LR 0.0353846153846 --> Loss 0.00201558073362\n",
      "Epoch 29::Minibatch 395::LR 0.0353846153846 --> Loss 0.00206526021163\n",
      "Epoch 29::Minibatch 396::LR 0.0353846153846 --> Loss 0.00193411191305\n",
      "Epoch 29::Minibatch 397::LR 0.0353846153846 --> Loss 0.00206975162029\n",
      "Epoch 29::Minibatch 398::LR 0.0353846153846 --> Loss 0.00205801963806\n",
      "Epoch 29::Minibatch 399::LR 0.0353846153846 --> Loss 0.00236658831437\n",
      "Epoch 29::Minibatch 400::LR 0.0353846153846 --> Loss 0.00200386921565\n",
      "Epoch 29::Minibatch 401::LR 0.0353846153846 --> Loss 0.00341371973356\n",
      "Epoch 29::Minibatch 402::LR 0.0353846153846 --> Loss 0.001723468105\n",
      "Epoch 29::Minibatch 403::LR 0.0353846153846 --> Loss 0.00142427225908\n",
      "Epoch 29::Minibatch 404::LR 0.0353846153846 --> Loss 0.00135496834914\n",
      "Epoch 29::Minibatch 405::LR 0.0353846153846 --> Loss 0.00335145394007\n",
      "Epoch 29::Minibatch 406::LR 0.0353846153846 --> Loss 0.00235275646051\n",
      "Epoch 29::Minibatch 407::LR 0.0353846153846 --> Loss 0.00170317808787\n",
      "Epoch 29::Minibatch 408::LR 0.0353846153846 --> Loss 0.000430604418119\n",
      "Epoch 29::Minibatch 409::LR 0.0353846153846 --> Loss 0.00222200532754\n",
      "Epoch 29::Minibatch 410::LR 0.0353846153846 --> Loss 0.00313480257988\n",
      "Epoch 29::Minibatch 411::LR 0.0353846153846 --> Loss 0.00164886504412\n",
      "Epoch 29::Minibatch 412::LR 0.0353846153846 --> Loss 0.000939887960752\n",
      "Epoch 29::Minibatch 413::LR 0.0353846153846 --> Loss 0.00196254054705\n",
      "Epoch 29::Minibatch 414::LR 0.0353846153846 --> Loss 0.00185887118181\n",
      "Epoch 29::Minibatch 415::LR 0.0353846153846 --> Loss 0.00115909457207\n",
      "Epoch 29::Minibatch 416::LR 0.0353846153846 --> Loss 0.000789104253054\n",
      "Epoch 29::Minibatch 417::LR 0.0353846153846 --> Loss 0.00167305767536\n",
      "Epoch 29::Minibatch 418::LR 0.0353846153846 --> Loss 0.00260162254175\n",
      "Epoch 29::Minibatch 419::LR 0.0353846153846 --> Loss 0.000487592667341\n",
      "Epoch 29::Minibatch 420::LR 0.0353846153846 --> Loss 0.000684442768494\n",
      "Epoch 29::Minibatch 421::LR 0.0353846153846 --> Loss 0.00187318503857\n",
      "Epoch 29::Minibatch 422::LR 0.0353846153846 --> Loss 0.00206463873386\n",
      "Epoch 29::Minibatch 423::LR 0.0353846153846 --> Loss 0.000973599851131\n",
      "Epoch 29::Minibatch 424::LR 0.0353846153846 --> Loss 0.00151457607746\n",
      "Epoch 29::Minibatch 425::LR 0.0353846153846 --> Loss 0.00286818742752\n",
      "Epoch 29::Minibatch 426::LR 0.0353846153846 --> Loss 0.00198279658953\n",
      "Epoch 29::Minibatch 427::LR 0.0353846153846 --> Loss 0.000723513116439\n",
      "Epoch 29::Minibatch 428::LR 0.0353846153846 --> Loss 0.000950724879901\n",
      "Epoch 29::Minibatch 429::LR 0.0353846153846 --> Loss 0.00225541333357\n",
      "Epoch 29::Minibatch 430::LR 0.0353846153846 --> Loss 0.00823616663615\n",
      "Epoch 29::Minibatch 431::LR 0.0353846153846 --> Loss 0.00363268097242\n",
      "Epoch 29::Minibatch 432::LR 0.0353846153846 --> Loss 0.00409657994906\n",
      "Epoch 29::Minibatch 433::LR 0.0353846153846 --> Loss 0.0025315930446\n",
      "Epoch 29::Minibatch 434::LR 0.0353846153846 --> Loss 0.00245577077071\n",
      "Epoch 29::Minibatch 435::LR 0.0353846153846 --> Loss 0.00225494106611\n",
      "Epoch 29::Minibatch 436::LR 0.0353846153846 --> Loss 0.00160512834787\n",
      "Epoch 29::Minibatch 437::LR 0.0353846153846 --> Loss 0.00287259399891\n",
      "Epoch 29::Minibatch 438::LR 0.0353846153846 --> Loss 0.00230945984523\n",
      "Epoch 29::Minibatch 439::LR 0.0353846153846 --> Loss 0.00193721572558\n",
      "Epoch 29::Minibatch 440::LR 0.0353846153846 --> Loss 0.00299832284451\n",
      "Epoch 29::Minibatch 441::LR 0.0353846153846 --> Loss 0.00280049522718\n",
      "Epoch 29::Minibatch 442::LR 0.0353846153846 --> Loss 0.00251509785652\n",
      "Epoch 29::Minibatch 443::LR 0.0353846153846 --> Loss 0.003478799661\n",
      "Epoch 29::Minibatch 444::LR 0.0353846153846 --> Loss 0.00269135951996\n",
      "Epoch 29::Minibatch 445::LR 0.0353846153846 --> Loss 0.000851518015067\n",
      "Epoch 29::Minibatch 446::LR 0.0353846153846 --> Loss 0.00137148062388\n",
      "Epoch 29::Minibatch 447::LR 0.0353846153846 --> Loss 0.00230372528235\n",
      "Epoch 29::Minibatch 448::LR 0.0353846153846 --> Loss 0.00231503208478\n",
      "Epoch 29::Minibatch 449::LR 0.0353846153846 --> Loss 0.00358268896739\n",
      "Epoch 29::Minibatch 450::LR 0.0353846153846 --> Loss 0.00214511712392\n",
      "Epoch 29::Minibatch 451::LR 0.0353846153846 --> Loss 0.00384904503822\n",
      "Epoch 29::Minibatch 452::LR 0.0353846153846 --> Loss 0.00229939798514\n",
      "Epoch 29::Minibatch 453::LR 0.0353846153846 --> Loss 0.000351091697812\n",
      "Epoch 29::Minibatch 454::LR 0.0353846153846 --> Loss 0.00345537344615\n",
      "Epoch 29::Minibatch 455::LR 0.0353846153846 --> Loss 0.00259658058484\n",
      "Epoch 29::Minibatch 456::LR 0.0353846153846 --> Loss 0.00304749906063\n",
      "Epoch 29::Minibatch 457::LR 0.0353846153846 --> Loss 0.00187843064467\n",
      "Epoch 29::Minibatch 458::LR 0.0353846153846 --> Loss 0.00071687027812\n",
      "Epoch 29::Minibatch 459::LR 0.0353846153846 --> Loss 0.00387073477109\n",
      "Epoch 29::Minibatch 460::LR 0.0353846153846 --> Loss 0.00244047721227\n",
      "Epoch 29::Minibatch 461::LR 0.0353846153846 --> Loss 0.00370939612389\n",
      "Epoch 29::Minibatch 462::LR 0.0353846153846 --> Loss 0.000371178289255\n",
      "Epoch 29::Minibatch 463::LR 0.0353846153846 --> Loss 0.00417764306068\n",
      "Epoch 29::Minibatch 464::LR 0.0353846153846 --> Loss 0.00195336699486\n",
      "Epoch 29::Minibatch 465::LR 0.0353846153846 --> Loss 0.00461868564288\n",
      "Epoch 29::Minibatch 466::LR 0.0353846153846 --> Loss 0.0049757373333\n",
      "Epoch 29::Minibatch 467::LR 0.0353846153846 --> Loss 0.00514540553093\n",
      "Epoch 29::Minibatch 468::LR 0.0353846153846 --> Loss 0.00570558508237\n",
      "Epoch 29::Minibatch 469::LR 0.0353846153846 --> Loss 0.00605461200078\n",
      "Epoch 29::Minibatch 470::LR 0.0353846153846 --> Loss 0.0035881225268\n",
      "Epoch 29::Minibatch 471::LR 0.0353846153846 --> Loss 0.0016682412227\n",
      "Epoch 29::Minibatch 472::LR 0.0353846153846 --> Loss 0.00355390429497\n",
      "Epoch 29::Minibatch 473::LR 0.0353846153846 --> Loss 0.00229912519455\n",
      "Epoch 29::Minibatch 474::LR 0.0353846153846 --> Loss 0.000690136998892\n",
      "Epoch 29::Minibatch 475::LR 0.0353846153846 --> Loss 0.00482221881549\n",
      "Epoch 29::Minibatch 476::LR 0.0353846153846 --> Loss 0.00764743725459\n",
      "Epoch 29::Minibatch 477::LR 0.0353846153846 --> Loss 0.000916327436765\n",
      "Epoch 29::Minibatch 478::LR 0.0353846153846 --> Loss 0.0024145668745\n",
      "Epoch 29::Minibatch 479::LR 0.0353846153846 --> Loss 0.00196035643419\n",
      "Epoch 29::Minibatch 480::LR 0.0353846153846 --> Loss 0.00151584645112\n",
      "Epoch 29::Minibatch 481::LR 0.0353846153846 --> Loss 0.000957264900208\n",
      "Epoch 29::Minibatch 482::LR 0.0353846153846 --> Loss 0.00207016090552\n",
      "Epoch 29::Minibatch 483::LR 0.0353846153846 --> Loss 0.00303807139397\n",
      "Epoch 29::Minibatch 484::LR 0.0353846153846 --> Loss 0.00341210405032\n",
      "Epoch 29::Minibatch 485::LR 0.0353846153846 --> Loss 0.000760412762562\n",
      "Epoch 29::Minibatch 486::LR 0.0353846153846 --> Loss 0.00281728903453\n",
      "Epoch 29::Minibatch 487::LR 0.0353846153846 --> Loss 0.00330110132694\n",
      "Epoch 29::Minibatch 488::LR 0.0353846153846 --> Loss 0.00202243010203\n",
      "Epoch 29::Minibatch 489::LR 0.0353846153846 --> Loss 0.00308627645175\n",
      "Epoch 29::Minibatch 490::LR 0.0353846153846 --> Loss 0.000411104684075\n",
      "Epoch 29::Minibatch 491::LR 0.0353846153846 --> Loss 0.00326921721299\n",
      "Epoch 29::Minibatch 492::LR 0.0353846153846 --> Loss 0.00306309998035\n",
      "Epoch 29::Minibatch 493::LR 0.0353846153846 --> Loss 0.00302211225033\n",
      "Epoch 29::Minibatch 494::LR 0.0353846153846 --> Loss 0.000733424524466\n",
      "Epoch 29::Minibatch 495::LR 0.0353846153846 --> Loss 0.00183413227399\n",
      "Epoch 29::Minibatch 496::LR 0.0353846153846 --> Loss 0.00278964519501\n",
      "Epoch 29::Minibatch 497::LR 0.0353846153846 --> Loss 0.000915234684944\n",
      "Epoch 29::Minibatch 498::LR 0.0353846153846 --> Loss 0.000550747861465\n",
      "Epoch 29::Minibatch 499::LR 0.0353846153846 --> Loss 0.00342834711075\n",
      "Epoch 29::Minibatch 500::LR 0.0353846153846 --> Loss 0.00142710715532\n",
      "Epoch 29::Minibatch 501::LR 0.0353846153846 --> Loss 0.00206226448218\n",
      "Epoch 29::Minibatch 502::LR 0.0353846153846 --> Loss 0.00374659220378\n",
      "Epoch 29::Minibatch 503::LR 0.0353846153846 --> Loss 0.00692814191182\n",
      "Epoch 29::Minibatch 504::LR 0.0353846153846 --> Loss 0.00683191299438\n",
      "Epoch 29::Minibatch 505::LR 0.0353846153846 --> Loss 0.00399543523788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 506::LR 0.0353846153846 --> Loss 0.00332828362783\n",
      "Epoch 29::Minibatch 507::LR 0.0353846153846 --> Loss 0.00579212903976\n",
      "Epoch 29::Minibatch 508::LR 0.0353846153846 --> Loss 0.00339023828506\n",
      "Epoch 29::Minibatch 509::LR 0.0353846153846 --> Loss 0.00428149819374\n",
      "Epoch 29::Minibatch 510::LR 0.0353846153846 --> Loss 0.00440668185552\n",
      "Epoch 29::Minibatch 511::LR 0.0353846153846 --> Loss 0.00397955497106\n",
      "Epoch 29::Minibatch 512::LR 0.0353846153846 --> Loss 0.00268076221148\n",
      "Epoch 29::Minibatch 513::LR 0.0353846153846 --> Loss 0.000602251191934\n",
      "Epoch 29::Minibatch 514::LR 0.0353846153846 --> Loss 0.00264236807823\n",
      "Epoch 29::Minibatch 515::LR 0.0353846153846 --> Loss 0.00299325784047\n",
      "Epoch 29::Minibatch 516::LR 0.0353846153846 --> Loss 0.00392897327741\n",
      "Epoch 29::Minibatch 517::LR 0.0353846153846 --> Loss 0.00360093394915\n",
      "Epoch 29::Minibatch 518::LR 0.0353846153846 --> Loss 0.00257695039113\n",
      "Epoch 29::Minibatch 519::LR 0.0353846153846 --> Loss 0.00352425177892\n",
      "Epoch 29::Minibatch 520::LR 0.0353846153846 --> Loss 0.00552072326342\n",
      "Epoch 29::Minibatch 521::LR 0.0353846153846 --> Loss 0.00559779763222\n",
      "Epoch 29::Minibatch 522::LR 0.0353846153846 --> Loss 0.00728820006053\n",
      "Epoch 29::Minibatch 523::LR 0.0353846153846 --> Loss 0.000624821782112\n",
      "Epoch 29::Minibatch 524::LR 0.0353846153846 --> Loss 0.00139576961597\n",
      "Epoch 29::Minibatch 525::LR 0.0353846153846 --> Loss 0.00308199246724\n",
      "Epoch 29::Minibatch 526::LR 0.0353846153846 --> Loss 0.00375054995219\n",
      "Epoch 29::Minibatch 527::LR 0.0353846153846 --> Loss 0.00214092055957\n",
      "Epoch 29::Minibatch 528::LR 0.0353846153846 --> Loss 0.000940620501836\n",
      "Epoch 29::Minibatch 529::LR 0.0353846153846 --> Loss 0.00385854403178\n",
      "Epoch 29::Minibatch 530::LR 0.0353846153846 --> Loss 0.00385241866112\n",
      "Epoch 29::Minibatch 531::LR 0.0353846153846 --> Loss 0.00342671116193\n",
      "Epoch 29::Minibatch 532::LR 0.0353846153846 --> Loss 0.00261566122373\n",
      "Epoch 29::Minibatch 533::LR 0.0353846153846 --> Loss 0.00491384665171\n",
      "Epoch 29::Minibatch 534::LR 0.0353846153846 --> Loss 0.00370075265567\n",
      "Epoch 29::Minibatch 535::LR 0.0353846153846 --> Loss 0.00330590466658\n",
      "Epoch 29::Minibatch 536::LR 0.0353846153846 --> Loss 0.00210433463256\n",
      "Epoch 29::Minibatch 537::LR 0.0353846153846 --> Loss 0.000587927202384\n",
      "Epoch 29::Minibatch 538::LR 0.0353846153846 --> Loss 0.00164012014866\n",
      "Epoch 29::Minibatch 539::LR 0.0353846153846 --> Loss 0.00332904378573\n",
      "Epoch 29::Minibatch 540::LR 0.0353846153846 --> Loss 0.00339346170425\n",
      "Epoch 29::Minibatch 541::LR 0.0353846153846 --> Loss 0.00284965197245\n",
      "Epoch 29::Minibatch 542::LR 0.0353846153846 --> Loss 0.00244707326094\n",
      "Epoch 29::Minibatch 543::LR 0.0353846153846 --> Loss 0.00259501894315\n",
      "Epoch 29::Minibatch 544::LR 0.0353846153846 --> Loss 0.00399368643761\n",
      "Epoch 29::Minibatch 545::LR 0.0353846153846 --> Loss 0.00198609332244\n",
      "Epoch 29::Minibatch 546::LR 0.0353846153846 --> Loss 0.000657649536928\n",
      "Epoch 29::Minibatch 547::LR 0.0353846153846 --> Loss 0.00258416970571\n",
      "Epoch 29::Minibatch 548::LR 0.0353846153846 --> Loss 0.00343659679095\n",
      "Epoch 29::Minibatch 549::LR 0.0353846153846 --> Loss 0.00880170981089\n",
      "Epoch 29::Minibatch 550::LR 0.0353846153846 --> Loss 0.00118159641822\n",
      "Epoch 29::Minibatch 551::LR 0.0353846153846 --> Loss 0.00245537201564\n",
      "Epoch 29::Minibatch 552::LR 0.0353846153846 --> Loss 0.00344271858533\n",
      "Epoch 29::Minibatch 553::LR 0.0353846153846 --> Loss 0.00299653530121\n",
      "Epoch 29::Minibatch 554::LR 0.0353846153846 --> Loss 0.0036467174689\n",
      "Epoch 29::Minibatch 555::LR 0.0353846153846 --> Loss 0.000945732792219\n",
      "Epoch 29::Minibatch 556::LR 0.0353846153846 --> Loss 0.00192731738091\n",
      "Epoch 29::Minibatch 557::LR 0.0353846153846 --> Loss 0.00240900158882\n",
      "Epoch 29::Minibatch 558::LR 0.0353846153846 --> Loss 0.00360487302144\n",
      "Epoch 29::Minibatch 559::LR 0.0353846153846 --> Loss 0.00365982691447\n",
      "Epoch 29::Minibatch 560::LR 0.0353846153846 --> Loss 0.00305643479029\n",
      "Epoch 29::Minibatch 561::LR 0.0353846153846 --> Loss 0.00262874742349\n",
      "Epoch 29::Minibatch 562::LR 0.0353846153846 --> Loss 0.00234285573165\n",
      "Epoch 29::Minibatch 563::LR 0.0353846153846 --> Loss 0.00397240956624\n",
      "Epoch 29::Minibatch 564::LR 0.0353846153846 --> Loss 0.00304989476999\n",
      "Epoch 29::Minibatch 565::LR 0.0353846153846 --> Loss 0.00358633359273\n",
      "Epoch 29::Minibatch 566::LR 0.0353846153846 --> Loss 0.00218784570694\n",
      "Epoch 29::Minibatch 567::LR 0.0353846153846 --> Loss 0.00253499070803\n",
      "Epoch 29::Minibatch 568::LR 0.0353846153846 --> Loss 0.00174684723218\n",
      "Epoch 29::Minibatch 569::LR 0.0353846153846 --> Loss 0.000560774902503\n",
      "Epoch 29::Minibatch 570::LR 0.0353846153846 --> Loss 0.00163124233484\n",
      "Epoch 29::Minibatch 571::LR 0.0353846153846 --> Loss 0.00207778731982\n",
      "Epoch 29::Minibatch 572::LR 0.0353846153846 --> Loss 0.00223320623239\n",
      "Epoch 29::Minibatch 573::LR 0.0353846153846 --> Loss 0.00144646177689\n",
      "Epoch 29::Minibatch 574::LR 0.0353846153846 --> Loss 0.00104409525792\n",
      "Epoch 29::Minibatch 575::LR 0.0353846153846 --> Loss 0.00172389268875\n",
      "Epoch 29::Minibatch 576::LR 0.0353846153846 --> Loss 0.00203757921855\n",
      "Epoch 29::Minibatch 577::LR 0.0353846153846 --> Loss 0.00161252597968\n",
      "Epoch 29::Minibatch 578::LR 0.0353846153846 --> Loss 0.00126536935568\n",
      "Epoch 29::Minibatch 579::LR 0.0353846153846 --> Loss 0.00118340690931\n",
      "Epoch 29::Minibatch 580::LR 0.0353846153846 --> Loss 0.00192013680935\n",
      "Epoch 29::Minibatch 581::LR 0.0353846153846 --> Loss 0.00170540670554\n",
      "Epoch 29::Minibatch 582::LR 0.0353846153846 --> Loss 0.00417513291041\n",
      "Epoch 29::Minibatch 583::LR 0.0353846153846 --> Loss 0.000950592160225\n",
      "Epoch 29::Minibatch 584::LR 0.0353846153846 --> Loss 0.00130817830563\n",
      "Epoch 29::Minibatch 585::LR 0.0353846153846 --> Loss 0.00397594491641\n",
      "Epoch 29::Minibatch 586::LR 0.0353846153846 --> Loss 0.00376502315203\n",
      "Epoch 29::Minibatch 587::LR 0.0353846153846 --> Loss 0.00111422926188\n",
      "Epoch 29::Minibatch 588::LR 0.0353846153846 --> Loss 0.00137518852949\n",
      "Epoch 29::Minibatch 589::LR 0.0353846153846 --> Loss 0.00274238665899\n",
      "Epoch 29::Minibatch 590::LR 0.0353846153846 --> Loss 0.00181721925735\n",
      "Epoch 29::Minibatch 591::LR 0.0353846153846 --> Loss 0.0027441829443\n",
      "Epoch 29::Minibatch 592::LR 0.0353846153846 --> Loss 0.00115336587032\n",
      "Epoch 29::Minibatch 593::LR 0.0353846153846 --> Loss 0.00248067537944\n",
      "Epoch 29::Minibatch 594::LR 0.0353846153846 --> Loss 0.00258564134439\n",
      "Epoch 29::Minibatch 595::LR 0.0353846153846 --> Loss 0.00304036239783\n",
      "Epoch 29::Minibatch 596::LR 0.0353846153846 --> Loss 0.00185304780801\n",
      "Epoch 29::Minibatch 597::LR 0.0353846153846 --> Loss 0.00117038071156\n",
      "Epoch 29::Minibatch 598::LR 0.0353846153846 --> Loss 0.00282820065816\n",
      "Epoch 29::Minibatch 599::LR 0.0353846153846 --> Loss 0.00179819583893\n",
      "Epoch 29::Minibatch 600::LR 0.0353846153846 --> Loss 0.00213638246059\n",
      "Epoch 29::Minibatch 601::LR 0.0353846153846 --> Loss 0.00374866684278\n",
      "Epoch 29::Minibatch 602::LR 0.0353846153846 --> Loss 0.00208669523398\n",
      "Epoch 29::Minibatch 603::LR 0.0353846153846 --> Loss 0.00261834998926\n",
      "Epoch 29::Minibatch 604::LR 0.0353846153846 --> Loss 0.00163182556629\n",
      "Epoch 29::Minibatch 605::LR 0.0353846153846 --> Loss 0.00229051152865\n",
      "Epoch 29::Minibatch 606::LR 0.0353846153846 --> Loss 0.00186234434446\n",
      "Epoch 29::Minibatch 607::LR 0.0353846153846 --> Loss 0.000827569862207\n",
      "Epoch 29::Minibatch 608::LR 0.0353846153846 --> Loss 0.0015558586518\n",
      "Epoch 29::Minibatch 609::LR 0.0353846153846 --> Loss 0.00241593241692\n",
      "Epoch 29::Minibatch 610::LR 0.0353846153846 --> Loss 0.00403233210246\n",
      "Epoch 29::Minibatch 611::LR 0.0353846153846 --> Loss 0.00265240192413\n",
      "Epoch 29::Minibatch 612::LR 0.0353846153846 --> Loss 0.000471714834372\n",
      "Epoch 29::Minibatch 613::LR 0.0353846153846 --> Loss 0.00131037125985\n",
      "Epoch 29::Minibatch 614::LR 0.0353846153846 --> Loss 0.00240886549155\n",
      "Epoch 29::Minibatch 615::LR 0.0353846153846 --> Loss 0.00165639261405\n",
      "Epoch 29::Minibatch 616::LR 0.0353846153846 --> Loss 0.000917089978854\n",
      "Epoch 29::Minibatch 617::LR 0.0353846153846 --> Loss 0.000492475728194\n",
      "Epoch 29::Minibatch 618::LR 0.0353846153846 --> Loss 0.00285450875759\n",
      "Epoch 29::Minibatch 619::LR 0.0353846153846 --> Loss 0.00192723989487\n",
      "Epoch 29::Minibatch 620::LR 0.0353846153846 --> Loss 0.00169255574544\n",
      "Epoch 29::Minibatch 621::LR 0.0353846153846 --> Loss 0.000845848917961\n",
      "Epoch 29::Minibatch 622::LR 0.0353846153846 --> Loss 0.000781924674908\n",
      "Epoch 29::Minibatch 623::LR 0.0353846153846 --> Loss 0.00221793472767\n",
      "Epoch 29::Minibatch 624::LR 0.0353846153846 --> Loss 0.001774533391\n",
      "Epoch 29::Minibatch 625::LR 0.0353846153846 --> Loss 0.00269561668237\n",
      "Epoch 29::Minibatch 626::LR 0.0353846153846 --> Loss 0.00371311624845\n",
      "Epoch 29::Minibatch 627::LR 0.0353846153846 --> Loss 0.00127388576667\n",
      "Epoch 29::Minibatch 628::LR 0.0353846153846 --> Loss 0.000878969033559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 629::LR 0.0353846153846 --> Loss 0.00312199970086\n",
      "Epoch 29::Minibatch 630::LR 0.0353846153846 --> Loss 0.00305311938127\n",
      "Epoch 29::Minibatch 631::LR 0.0353846153846 --> Loss 0.00532272617022\n",
      "Epoch 29::Minibatch 632::LR 0.0353846153846 --> Loss 0.000791993836562\n",
      "Epoch 29::Minibatch 633::LR 0.0353846153846 --> Loss 0.00162236889203\n",
      "Epoch 29::Minibatch 634::LR 0.0353846153846 --> Loss 0.00319306472937\n",
      "Epoch 29::Minibatch 635::LR 0.0353846153846 --> Loss 0.00545789718628\n",
      "Epoch 29::Minibatch 636::LR 0.0353846153846 --> Loss 0.00463799754779\n",
      "Epoch 29::Minibatch 637::LR 0.0353846153846 --> Loss 0.000720422714949\n",
      "Epoch 29::Minibatch 638::LR 0.0353846153846 --> Loss 0.00148432672024\n",
      "Epoch 29::Minibatch 639::LR 0.0353846153846 --> Loss 0.00319618006547\n",
      "Epoch 29::Minibatch 640::LR 0.0353846153846 --> Loss 0.00462445934614\n",
      "Epoch 29::Minibatch 641::LR 0.0353846153846 --> Loss 0.00305032273134\n",
      "Epoch 29::Minibatch 642::LR 0.0353846153846 --> Loss 0.000532455195983\n",
      "Epoch 29::Minibatch 643::LR 0.0353846153846 --> Loss 0.002312814792\n",
      "Epoch 29::Minibatch 644::LR 0.0353846153846 --> Loss 0.00387767672539\n",
      "Epoch 29::Minibatch 645::LR 0.0353846153846 --> Loss 0.00440473834674\n",
      "Epoch 29::Minibatch 646::LR 0.0353846153846 --> Loss 0.00150151371956\n",
      "Epoch 29::Minibatch 647::LR 0.0353846153846 --> Loss 0.0004718884329\n",
      "Epoch 29::Minibatch 648::LR 0.0353846153846 --> Loss 0.00279231548309\n",
      "Epoch 29::Minibatch 649::LR 0.0353846153846 --> Loss 0.00326629678408\n",
      "Epoch 29::Minibatch 650::LR 0.0353846153846 --> Loss 0.00318908015887\n",
      "Epoch 29::Minibatch 651::LR 0.0353846153846 --> Loss 0.00133564194043\n",
      "Epoch 29::Minibatch 652::LR 0.0353846153846 --> Loss 0.000778924922148\n",
      "Epoch 29::Minibatch 653::LR 0.0353846153846 --> Loss 0.00280928949515\n",
      "Epoch 29::Minibatch 654::LR 0.0353846153846 --> Loss 0.00312491297722\n",
      "Epoch 29::Minibatch 655::LR 0.0353846153846 --> Loss 0.00360465566317\n",
      "Epoch 29::Minibatch 656::LR 0.0353846153846 --> Loss 0.000754556159178\n",
      "Epoch 29::Minibatch 657::LR 0.0353846153846 --> Loss 0.00226591408253\n",
      "Epoch 29::Minibatch 658::LR 0.0353846153846 --> Loss 0.00456022500992\n",
      "Epoch 29::Minibatch 659::LR 0.0353846153846 --> Loss 0.00222804625829\n",
      "Epoch 29::Minibatch 660::LR 0.0353846153846 --> Loss 0.00263550360998\n",
      "Epoch 29::Minibatch 661::LR 0.0353846153846 --> Loss 0.00230363070965\n",
      "Epoch 29::Minibatch 662::LR 0.0353846153846 --> Loss 0.00179540356\n",
      "Epoch 29::Minibatch 663::LR 0.0353846153846 --> Loss 0.00367991169294\n",
      "Epoch 29::Minibatch 664::LR 0.0353846153846 --> Loss 0.00320079366366\n",
      "Epoch 29::Minibatch 665::LR 0.0353846153846 --> Loss 0.000699654569228\n",
      "Epoch 29::Minibatch 666::LR 0.0353846153846 --> Loss 0.0039049633344\n",
      "Epoch 29::Minibatch 667::LR 0.0353846153846 --> Loss 0.00254122575124\n",
      "Epoch 29::Minibatch 668::LR 0.0353846153846 --> Loss 0.00642199317614\n",
      "Epoch 29::Minibatch 669::LR 0.0353846153846 --> Loss 0.00108581155539\n",
      "Epoch 29::Minibatch 670::LR 0.0353846153846 --> Loss 0.00133154173692\n",
      "Epoch 29::Minibatch 671::LR 0.0353846153846 --> Loss 0.00511999487877\n",
      "Epoch 29::Minibatch 672::LR 0.0353846153846 --> Loss 0.00343949635824\n",
      "Epoch 29::Minibatch 673::LR 0.0353846153846 --> Loss 0.00160725007455\n",
      "Epoch 29::Minibatch 674::LR 0.0353846153846 --> Loss 0.000509738673766\n",
      "Epoch 29::Minibatch 675::LR 0.0353846153846 --> Loss 0.00219215770562\n",
      "Epoch 29::Minibatch 676::LR 0.0353846153846 --> Loss 0.00214869817098\n",
      "Epoch 29::Minibatch 677::LR 0.0353846153846 --> Loss 0.00271869719028\n",
      "Epoch 29::Minibatch 678::LR 0.0353846153846 --> Loss 0.00187381426493\n",
      "Epoch 29::Minibatch 679::LR 0.0353846153846 --> Loss 0.00333874344826\n",
      "Epoch 29::Minibatch 680::LR 0.0353846153846 --> Loss 0.00212548971176\n",
      "Epoch 29::Minibatch 681::LR 0.0353846153846 --> Loss 0.00239482720693\n",
      "Epoch 29::Minibatch 682::LR 0.0353846153846 --> Loss 0.00076160500447\n",
      "Epoch 29::Minibatch 683::LR 0.0353846153846 --> Loss 0.00231957455476\n",
      "Epoch 29::Minibatch 684::LR 0.0353846153846 --> Loss 0.00233903328578\n",
      "Epoch 29::Minibatch 685::LR 0.0353846153846 --> Loss 0.00283116539319\n",
      "Epoch 29::Minibatch 686::LR 0.0353846153846 --> Loss 0.0015803989768\n",
      "Epoch 29::Minibatch 687::LR 0.0353846153846 --> Loss 0.000873215993245\n",
      "Epoch 29::Minibatch 688::LR 0.0353846153846 --> Loss 0.00279316723347\n",
      "Epoch 29::Minibatch 689::LR 0.0353846153846 --> Loss 0.00247850994269\n",
      "Epoch 29::Minibatch 690::LR 0.0353846153846 --> Loss 0.00188555280368\n",
      "Epoch 29::Minibatch 691::LR 0.0353846153846 --> Loss 0.000657896747192\n",
      "Epoch 29::Minibatch 692::LR 0.0353846153846 --> Loss 0.00244482477506\n",
      "Epoch 29::Minibatch 693::LR 0.0353846153846 --> Loss 0.0026052202781\n",
      "Epoch 29::Minibatch 694::LR 0.0353846153846 --> Loss 0.00299876232942\n",
      "Epoch 29::Minibatch 695::LR 0.0353846153846 --> Loss 0.00178593993187\n",
      "Epoch 29::Minibatch 696::LR 0.0353846153846 --> Loss 0.00203497131666\n",
      "Epoch 29::Minibatch 697::LR 0.0353846153846 --> Loss 0.00140051593383\n",
      "Epoch 29::Minibatch 698::LR 0.0353846153846 --> Loss 0.00165798624357\n",
      "Epoch 29::Minibatch 699::LR 0.0353846153846 --> Loss 0.00372567653656\n",
      "Epoch 29::Minibatch 700::LR 0.0353846153846 --> Loss 0.00259367565314\n",
      "Epoch 29::Minibatch 701::LR 0.0353846153846 --> Loss 0.00190236508846\n",
      "Epoch 29::Minibatch 702::LR 0.0353846153846 --> Loss 0.00166554649671\n",
      "Epoch 29::Minibatch 703::LR 0.0353846153846 --> Loss 0.00431954860687\n",
      "Epoch 29::Minibatch 704::LR 0.0353846153846 --> Loss 0.00180342892806\n",
      "Epoch 29::Minibatch 705::LR 0.0353846153846 --> Loss 0.00284757971764\n",
      "Epoch 29::Minibatch 706::LR 0.0353846153846 --> Loss 0.00221198240916\n",
      "Epoch 29::Minibatch 707::LR 0.0353846153846 --> Loss 0.00117901901404\n",
      "Epoch 29::Minibatch 708::LR 0.0353846153846 --> Loss 0.001730859677\n",
      "Epoch 29::Minibatch 709::LR 0.0353846153846 --> Loss 0.00167213082314\n",
      "Epoch 29::Minibatch 710::LR 0.0353846153846 --> Loss 0.00257525861263\n",
      "Epoch 29::Minibatch 711::LR 0.0353846153846 --> Loss 0.00196551163991\n",
      "Epoch 29::Minibatch 712::LR 0.0353846153846 --> Loss 0.00135468055805\n",
      "Epoch 29::Minibatch 713::LR 0.0353846153846 --> Loss 0.00178917785486\n",
      "Epoch 29::Minibatch 714::LR 0.0353846153846 --> Loss 0.00284451067448\n",
      "Epoch 29::Minibatch 715::LR 0.0353846153846 --> Loss 0.00292770226796\n",
      "Epoch 29::Minibatch 716::LR 0.0353846153846 --> Loss 0.0016545822223\n",
      "Epoch 29::Minibatch 717::LR 0.0353846153846 --> Loss 0.00165912399689\n",
      "Epoch 29::Minibatch 718::LR 0.0353846153846 --> Loss 0.00127455731233\n",
      "Epoch 29::Minibatch 719::LR 0.0353846153846 --> Loss 0.0017154020071\n",
      "Epoch 29::Minibatch 720::LR 0.0353846153846 --> Loss 0.00272134502729\n",
      "Epoch 29::Minibatch 721::LR 0.0353846153846 --> Loss 0.000605870733658\n",
      "Epoch 29::Minibatch 722::LR 0.0353846153846 --> Loss 0.00462816476822\n",
      "Epoch 29::Minibatch 723::LR 0.0353846153846 --> Loss 0.00484086235364\n",
      "Epoch 29::Minibatch 724::LR 0.0353846153846 --> Loss 0.000964902043343\n",
      "Epoch 29::Minibatch 725::LR 0.0353846153846 --> Loss 0.00207579453786\n",
      "Epoch 29::Minibatch 726::LR 0.0353846153846 --> Loss 0.00380574067434\n",
      "Epoch 29::Minibatch 727::LR 0.0353846153846 --> Loss 0.00311092913151\n",
      "Epoch 29::Minibatch 728::LR 0.0353846153846 --> Loss 0.000641249616941\n",
      "Epoch 29::Minibatch 729::LR 0.0353846153846 --> Loss 0.000721301833789\n",
      "Epoch 29::Minibatch 730::LR 0.0353846153846 --> Loss 0.00290921370188\n",
      "Epoch 29::Minibatch 731::LR 0.0353846153846 --> Loss 0.0026013537248\n",
      "Epoch 29::Minibatch 732::LR 0.0353846153846 --> Loss 0.00206965923309\n",
      "Epoch 29::Minibatch 733::LR 0.0353846153846 --> Loss 0.000608115295569\n",
      "Epoch 29::Minibatch 734::LR 0.0353846153846 --> Loss 0.00165574302276\n",
      "Epoch 29::Minibatch 735::LR 0.0353846153846 --> Loss 0.00245144208272\n",
      "Epoch 29::Minibatch 736::LR 0.0353846153846 --> Loss 0.00347521106402\n",
      "Epoch 29::Minibatch 737::LR 0.0353846153846 --> Loss 0.00295449177424\n",
      "Epoch 29::Minibatch 738::LR 0.0353846153846 --> Loss 0.00142789085706\n",
      "Epoch 29::Minibatch 739::LR 0.0353846153846 --> Loss 0.00239973068237\n",
      "Epoch 29::Minibatch 740::LR 0.0353846153846 --> Loss 0.00377750277519\n",
      "Epoch 29::Minibatch 741::LR 0.0353846153846 --> Loss 0.00254894177119\n",
      "Epoch 29::Minibatch 742::LR 0.0353846153846 --> Loss 0.00208471695582\n",
      "Epoch 29::Minibatch 743::LR 0.0353846153846 --> Loss 0.00149061828852\n",
      "Epoch 29::Minibatch 744::LR 0.0353846153846 --> Loss 0.00185764789581\n",
      "Epoch 29::Minibatch 745::LR 0.0353846153846 --> Loss 0.00278017938137\n",
      "Epoch 29::Minibatch 746::LR 0.0353846153846 --> Loss 0.00286815245946\n",
      "Epoch 29::Minibatch 747::LR 0.0353846153846 --> Loss 0.00176453769207\n",
      "Epoch 29::Minibatch 748::LR 0.0353846153846 --> Loss 0.000620150019725\n",
      "Epoch 29::Minibatch 749::LR 0.0353846153846 --> Loss 0.00166850845019\n",
      "Epoch 29::Minibatch 750::LR 0.0353846153846 --> Loss 0.00242409904798\n",
      "Epoch 29::Minibatch 751::LR 0.0353846153846 --> Loss 0.00288787961006\n",
      "Epoch 29::Minibatch 752::LR 0.0353846153846 --> Loss 0.00139098395904\n",
      "Epoch 29::Minibatch 753::LR 0.0353846153846 --> Loss 0.00219391942024\n",
      "Epoch 29::Minibatch 754::LR 0.0353846153846 --> Loss 0.00241271734238\n",
      "Epoch 29::Minibatch 755::LR 0.0353846153846 --> Loss 0.0026621290048\n",
      "Epoch 29::Minibatch 756::LR 0.0353846153846 --> Loss 0.00131697515647\n",
      "Epoch 29::Minibatch 757::LR 0.0353846153846 --> Loss 0.00062473187844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 758::LR 0.0353846153846 --> Loss 0.00156888405482\n",
      "Epoch 29::Minibatch 759::LR 0.0353846153846 --> Loss 0.00347536126773\n",
      "Epoch 29::Minibatch 760::LR 0.0353846153846 --> Loss 0.00282888611158\n",
      "Epoch 29::Minibatch 761::LR 0.0353846153846 --> Loss 0.00574913620949\n",
      "Epoch 29::Minibatch 762::LR 0.0353846153846 --> Loss 0.00359889308612\n",
      "Epoch 29::Minibatch 763::LR 0.0353846153846 --> Loss 0.00345824400584\n",
      "Epoch 29::Minibatch 764::LR 0.0353846153846 --> Loss 0.00305031299591\n",
      "Epoch 29::Minibatch 765::LR 0.0353846153846 --> Loss 0.00125838647286\n",
      "Epoch 29::Minibatch 766::LR 0.0353846153846 --> Loss 0.0022994440794\n",
      "Epoch 29::Minibatch 767::LR 0.0353846153846 --> Loss 0.00482296347618\n",
      "Epoch 29::Minibatch 768::LR 0.0353846153846 --> Loss 0.00365245381991\n",
      "Epoch 29::Minibatch 769::LR 0.0353846153846 --> Loss 0.00184340596199\n",
      "Epoch 29::Minibatch 770::LR 0.0353846153846 --> Loss 0.0015028778712\n",
      "Epoch 29::Minibatch 771::LR 0.0353846153846 --> Loss 0.0034546593825\n",
      "Epoch 29::Minibatch 772::LR 0.0353846153846 --> Loss 0.0035836271445\n",
      "Epoch 29::Minibatch 773::LR 0.0353846153846 --> Loss 0.0031771582365\n",
      "Epoch 29::Minibatch 774::LR 0.0353846153846 --> Loss 0.00186987559001\n",
      "Epoch 29::Minibatch 775::LR 0.0353846153846 --> Loss 0.00336545626322\n",
      "Epoch 29::Minibatch 776::LR 0.0353846153846 --> Loss 0.00373391230901\n",
      "Epoch 29::Minibatch 777::LR 0.0353846153846 --> Loss 0.0062978219986\n",
      "Epoch 29::Minibatch 778::LR 0.0353846153846 --> Loss 0.00760630846024\n",
      "Epoch 29::Minibatch 779::LR 0.0353846153846 --> Loss 0.00247494757175\n",
      "Epoch 29::Minibatch 780::LR 0.0353846153846 --> Loss 0.00151991665363\n",
      "Epoch 29::Minibatch 781::LR 0.0353846153846 --> Loss 0.00346907416979\n",
      "Epoch 29::Minibatch 782::LR 0.0353846153846 --> Loss 0.00380336403847\n",
      "Epoch 29::Minibatch 783::LR 0.0353846153846 --> Loss 0.00226888934771\n",
      "Epoch 29::Minibatch 784::LR 0.0353846153846 --> Loss 0.000707445492347\n",
      "Epoch 29::Minibatch 785::LR 0.0353846153846 --> Loss 0.003279124101\n",
      "Epoch 29::Minibatch 786::LR 0.0353846153846 --> Loss 0.00346354047457\n",
      "Epoch 29::Minibatch 787::LR 0.0353846153846 --> Loss 0.00257789194584\n",
      "Epoch 29::Minibatch 788::LR 0.0353846153846 --> Loss 0.00236711521943\n",
      "Epoch 29::Minibatch 789::LR 0.0353846153846 --> Loss 0.000726002156734\n",
      "Epoch 29::Minibatch 790::LR 0.0353846153846 --> Loss 0.00312811811765\n",
      "Epoch 29::Minibatch 791::LR 0.0353846153846 --> Loss 0.00331344207128\n",
      "Epoch 29::Minibatch 792::LR 0.0353846153846 --> Loss 0.00298012753328\n",
      "Epoch 29::Minibatch 793::LR 0.0353846153846 --> Loss 0.00165831118822\n",
      "Epoch 29::Minibatch 794::LR 0.0353846153846 --> Loss 0.000985098481178\n",
      "Epoch 29::Minibatch 795::LR 0.0353846153846 --> Loss 0.00269148131212\n",
      "Epoch 29::Minibatch 796::LR 0.0353846153846 --> Loss 0.0049662621816\n",
      "Epoch 29::Minibatch 797::LR 0.0353846153846 --> Loss 0.0059399998188\n",
      "Epoch 29::Minibatch 798::LR 0.0353846153846 --> Loss 0.00303927878539\n",
      "Epoch 29::Minibatch 799::LR 0.0353846153846 --> Loss 0.00225822945436\n",
      "Epoch 29::Minibatch 800::LR 0.0353846153846 --> Loss 0.00200342953205\n",
      "Epoch 29::Minibatch 801::LR 0.0353846153846 --> Loss 0.00394412636757\n",
      "Epoch 29::Minibatch 802::LR 0.0353846153846 --> Loss 0.00122003883123\n",
      "Epoch 29::Minibatch 803::LR 0.0353846153846 --> Loss 0.00293233911196\n",
      "Epoch 29::Minibatch 804::LR 0.0353846153846 --> Loss 0.00208751658599\n",
      "Epoch 29::Minibatch 805::LR 0.0353846153846 --> Loss 0.00219399929047\n",
      "Epoch 29::Minibatch 806::LR 0.0353846153846 --> Loss 0.00338928063711\n",
      "Epoch 29::Minibatch 807::LR 0.0353846153846 --> Loss 0.00306853830814\n",
      "Epoch 29::Minibatch 808::LR 0.0353846153846 --> Loss 0.0027955977122\n",
      "Epoch 29::Minibatch 809::LR 0.0353846153846 --> Loss 0.0031683754921\n",
      "Epoch 29::Minibatch 810::LR 0.0353846153846 --> Loss 0.00435489296913\n",
      "Epoch 29::Minibatch 811::LR 0.0353846153846 --> Loss 0.00416151046753\n",
      "Epoch 29::Minibatch 812::LR 0.0353846153846 --> Loss 0.00381773352623\n",
      "Epoch 29::Minibatch 813::LR 0.0353846153846 --> Loss 0.00322557846705\n",
      "Epoch 29::Minibatch 814::LR 0.0353846153846 --> Loss 0.00154861152172\n",
      "Epoch 29::Minibatch 815::LR 0.0353846153846 --> Loss 0.0035412867864\n",
      "Epoch 29::Minibatch 816::LR 0.0353846153846 --> Loss 0.00397977590561\n",
      "Epoch 29::Minibatch 817::LR 0.0353846153846 --> Loss 0.00502337773641\n",
      "Epoch 29::Minibatch 818::LR 0.0353846153846 --> Loss 0.00124342113733\n",
      "Epoch 29::Minibatch 819::LR 0.0353846153846 --> Loss 0.000715386271477\n",
      "Epoch 29::Minibatch 820::LR 0.0353846153846 --> Loss 0.00511884649595\n",
      "Epoch 29::Minibatch 821::LR 0.0353846153846 --> Loss 0.00306002656619\n",
      "Epoch 29::Minibatch 822::LR 0.0353846153846 --> Loss 0.00365541537603\n",
      "Epoch 29::Minibatch 823::LR 0.0353846153846 --> Loss 0.00126472045978\n",
      "Epoch 29::Minibatch 824::LR 0.0353846153846 --> Loss 0.0013607169191\n",
      "Epoch 29::Minibatch 825::LR 0.0353846153846 --> Loss 0.00368605891864\n",
      "Epoch 29::Minibatch 826::LR 0.0353846153846 --> Loss 0.00426646987597\n",
      "Epoch 29::Minibatch 827::LR 0.0353846153846 --> Loss 0.00205445190271\n",
      "Epoch 29::Minibatch 828::LR 0.0353846153846 --> Loss 0.000489979734023\n",
      "Epoch 29::Minibatch 829::LR 0.0353846153846 --> Loss 0.00227493087451\n",
      "Epoch 29::Minibatch 830::LR 0.0353846153846 --> Loss 0.00406431635221\n",
      "Epoch 29::Minibatch 831::LR 0.0353846153846 --> Loss 0.0024202978611\n",
      "Epoch 29::Minibatch 832::LR 0.0353846153846 --> Loss 0.00212819973628\n",
      "Epoch 29::Minibatch 833::LR 0.0353846153846 --> Loss 0.00182012061278\n",
      "Epoch 29::Minibatch 834::LR 0.0353846153846 --> Loss 0.000783731043339\n",
      "Epoch 29::Minibatch 835::LR 0.0353846153846 --> Loss 0.00375905394554\n",
      "Epoch 29::Minibatch 836::LR 0.0353846153846 --> Loss 0.00358366330465\n",
      "Epoch 29::Minibatch 837::LR 0.0353846153846 --> Loss 0.00221920172373\n",
      "Epoch 29::Minibatch 838::LR 0.0353846153846 --> Loss 0.000638965219259\n",
      "Epoch 29::Minibatch 839::LR 0.0353846153846 --> Loss 0.00240120768547\n",
      "Epoch 29::Minibatch 840::LR 0.0353846153846 --> Loss 0.00284178376198\n",
      "Epoch 29::Minibatch 841::LR 0.0353846153846 --> Loss 0.00275570670764\n",
      "Epoch 29::Minibatch 842::LR 0.0353846153846 --> Loss 0.00208524604638\n",
      "Epoch 29::Minibatch 843::LR 0.0353846153846 --> Loss 0.000980688730876\n",
      "Epoch 29::Minibatch 844::LR 0.0353846153846 --> Loss 0.00146792769432\n",
      "Epoch 29::Minibatch 845::LR 0.0353846153846 --> Loss 0.00407150268555\n",
      "Epoch 29::Minibatch 846::LR 0.0353846153846 --> Loss 0.00166480898857\n",
      "Epoch 29::Minibatch 847::LR 0.0353846153846 --> Loss 0.0023276356856\n",
      "Epoch 29::Minibatch 848::LR 0.0353846153846 --> Loss 0.00108199765285\n",
      "Epoch 29::Minibatch 849::LR 0.0353846153846 --> Loss 0.00178708751996\n",
      "Epoch 29::Minibatch 850::LR 0.0353846153846 --> Loss 0.00314341406027\n",
      "Epoch 29::Minibatch 851::LR 0.0353846153846 --> Loss 0.0025521761179\n",
      "Epoch 29::Minibatch 852::LR 0.0353846153846 --> Loss 0.00111147681872\n",
      "Epoch 29::Minibatch 853::LR 0.0353846153846 --> Loss 0.00130074739456\n",
      "Epoch 29::Minibatch 854::LR 0.0353846153846 --> Loss 0.00253374318282\n",
      "Epoch 29::Minibatch 855::LR 0.0353846153846 --> Loss 0.00211730996768\n",
      "Epoch 29::Minibatch 856::LR 0.0353846153846 --> Loss 0.00178075015545\n",
      "Epoch 29::Minibatch 857::LR 0.0353846153846 --> Loss 0.00120750923951\n",
      "Epoch 29::Minibatch 858::LR 0.0353846153846 --> Loss 0.000596440533797\n",
      "Epoch 29::Minibatch 859::LR 0.0353846153846 --> Loss 0.00195276677608\n",
      "Epoch 29::Minibatch 860::LR 0.0353846153846 --> Loss 0.00128530750672\n",
      "Epoch 29::Minibatch 861::LR 0.0353846153846 --> Loss 0.000941543281078\n",
      "Epoch 29::Minibatch 862::LR 0.0353846153846 --> Loss 0.00368814746539\n",
      "Epoch 29::Minibatch 863::LR 0.0353846153846 --> Loss 0.0033667520682\n",
      "Epoch 29::Minibatch 864::LR 0.0353846153846 --> Loss 0.00264236013095\n",
      "Epoch 29::Minibatch 865::LR 0.0353846153846 --> Loss 0.000481977661451\n",
      "Epoch 29::Minibatch 866::LR 0.0353846153846 --> Loss 0.00208603878816\n",
      "Epoch 29::Minibatch 867::LR 0.0353846153846 --> Loss 0.00288223783175\n",
      "Epoch 29::Minibatch 868::LR 0.0353846153846 --> Loss 0.00240444262822\n",
      "Epoch 29::Minibatch 869::LR 0.0353846153846 --> Loss 0.00212140480677\n",
      "Epoch 29::Minibatch 870::LR 0.0353846153846 --> Loss 0.0033125291268\n",
      "Epoch 29::Minibatch 871::LR 0.0353846153846 --> Loss 0.00159157991409\n",
      "Epoch 29::Minibatch 872::LR 0.0353846153846 --> Loss 0.00215301831563\n",
      "Epoch 29::Minibatch 873::LR 0.0353846153846 --> Loss 0.00245074788729\n",
      "Epoch 29::Minibatch 874::LR 0.0353846153846 --> Loss 0.005402084589\n",
      "Epoch 29::Minibatch 875::LR 0.0353846153846 --> Loss 0.000589377383391\n",
      "Epoch 29::Minibatch 876::LR 0.0353846153846 --> Loss 0.00281840980053\n",
      "Epoch 29::Minibatch 877::LR 0.0353846153846 --> Loss 0.00488424420357\n",
      "Epoch 29::Minibatch 878::LR 0.0353846153846 --> Loss 0.00302505354087\n",
      "Epoch 29::Minibatch 879::LR 0.0353846153846 --> Loss 0.00393419226011\n",
      "Epoch 29::Minibatch 880::LR 0.0353846153846 --> Loss 0.00484812180201\n",
      "Epoch 29::Minibatch 881::LR 0.0353846153846 --> Loss 0.00423575560252\n",
      "Epoch 29::Minibatch 882::LR 0.0353846153846 --> Loss 0.00192323744297\n",
      "Epoch 29::Minibatch 883::LR 0.0353846153846 --> Loss 0.00356252113978\n",
      "Epoch 29::Minibatch 884::LR 0.0353846153846 --> Loss 0.00276658455531\n",
      "Epoch 29::Minibatch 885::LR 0.0353846153846 --> Loss 0.00257491707802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 886::LR 0.0353846153846 --> Loss 0.000440182834864\n",
      "Epoch 29::Minibatch 887::LR 0.0353846153846 --> Loss 0.00537794987361\n",
      "Epoch 29::Minibatch 888::LR 0.0353846153846 --> Loss 0.00247759421666\n",
      "Epoch 29::Minibatch 889::LR 0.0353846153846 --> Loss 0.00255469977856\n",
      "Epoch 29::Minibatch 890::LR 0.0353846153846 --> Loss 0.0037077220281\n",
      "Epoch 29::Minibatch 891::LR 0.0353846153846 --> Loss 0.00174020071824\n",
      "Epoch 29::Minibatch 892::LR 0.0353846153846 --> Loss 0.000802805225054\n",
      "Epoch 29::Minibatch 893::LR 0.0353846153846 --> Loss 0.00229177812735\n",
      "Epoch 29::Minibatch 894::LR 0.0353846153846 --> Loss 0.00201689680417\n",
      "Epoch 29::Minibatch 895::LR 0.0353846153846 --> Loss 0.00229153295358\n",
      "Epoch 29::Minibatch 896::LR 0.0353846153846 --> Loss 0.00124027997255\n",
      "Epoch 29::Minibatch 897::LR 0.0353846153846 --> Loss 0.000676359285911\n",
      "Epoch 29::Minibatch 898::LR 0.0353846153846 --> Loss 0.00201087494691\n",
      "Epoch 29::Minibatch 899::LR 0.0353846153846 --> Loss 0.00245403925578\n",
      "Epoch 29::Minibatch 900::LR 0.0353846153846 --> Loss 0.00309505840143\n",
      "Epoch 29::Minibatch 901::LR 0.0353846153846 --> Loss 0.000583581626415\n",
      "Epoch 29::Minibatch 902::LR 0.0353846153846 --> Loss 0.00139635205269\n",
      "Epoch 29::Minibatch 903::LR 0.0353846153846 --> Loss 0.00252665996552\n",
      "Epoch 29::Minibatch 904::LR 0.0353846153846 --> Loss 0.00181300203005\n",
      "Epoch 29::Minibatch 905::LR 0.0353846153846 --> Loss 0.00140106479327\n",
      "Epoch 29::Minibatch 906::LR 0.0353846153846 --> Loss 0.00103204349677\n",
      "Epoch 29::Minibatch 907::LR 0.0353846153846 --> Loss 0.00155221035083\n",
      "Epoch 29::Minibatch 908::LR 0.0353846153846 --> Loss 0.00207852065563\n",
      "Epoch 29::Minibatch 909::LR 0.0353846153846 --> Loss 0.00193410774072\n",
      "Epoch 29::Minibatch 910::LR 0.0353846153846 --> Loss 0.00083869467179\n",
      "Epoch 29::Minibatch 911::LR 0.0353846153846 --> Loss 0.00125942279895\n",
      "Epoch 29::Minibatch 912::LR 0.0353846153846 --> Loss 0.00202770531178\n",
      "Epoch 29::Minibatch 913::LR 0.0353846153846 --> Loss 0.00223115960757\n",
      "Epoch 29::Minibatch 914::LR 0.0353846153846 --> Loss 0.00121314883232\n",
      "Epoch 29::Minibatch 915::LR 0.0353846153846 --> Loss 0.000516960521539\n",
      "Epoch 29::Minibatch 916::LR 0.0353846153846 --> Loss 0.00208592335383\n",
      "Epoch 29::Minibatch 917::LR 0.0353846153846 --> Loss 0.00336792588234\n",
      "Epoch 29::Minibatch 918::LR 0.0353846153846 --> Loss 0.00519545912743\n",
      "Epoch 29::Minibatch 919::LR 0.0353846153846 --> Loss 0.000533604174852\n",
      "Epoch 29::Minibatch 920::LR 0.0353846153846 --> Loss 0.0125610891978\n",
      "Epoch 29::Minibatch 921::LR 0.0353846153846 --> Loss 0.00291089495023\n",
      "Epoch 29::Minibatch 922::LR 0.0353846153846 --> Loss 0.00295408626397\n",
      "Epoch 29::Minibatch 923::LR 0.0353846153846 --> Loss 0.00123155325651\n",
      "Epoch 29::Minibatch 924::LR 0.0353846153846 --> Loss 0.00320534408092\n",
      "Epoch 29::Minibatch 925::LR 0.0353846153846 --> Loss 0.00219443619251\n",
      "Epoch 29::Minibatch 926::LR 0.0353846153846 --> Loss 0.00478612740835\n",
      "Epoch 29::Minibatch 927::LR 0.0353846153846 --> Loss 0.00567414522171\n",
      "Epoch 29::Minibatch 928::LR 0.0353846153846 --> Loss 0.00601607322693\n",
      "Epoch 29::Minibatch 929::LR 0.0353846153846 --> Loss 0.00557258486748\n",
      "Epoch 29::Minibatch 930::LR 0.0353846153846 --> Loss 0.00894538561503\n",
      "Epoch 29::Minibatch 931::LR 0.0353846153846 --> Loss 0.00308498104413\n",
      "Epoch 29::Minibatch 932::LR 0.0353846153846 --> Loss 0.00550033807755\n",
      "Epoch 29::Minibatch 933::LR 0.0353846153846 --> Loss 0.00255806565285\n",
      "Epoch 29::Minibatch 934::LR 0.0353846153846 --> Loss 0.00332070887089\n",
      "Epoch 29::Minibatch 935::LR 0.0353846153846 --> Loss 0.00488796949387\n",
      "Epoch 29::Minibatch 936::LR 0.0353846153846 --> Loss 0.00101065884034\n",
      "Epoch 29::Minibatch 937::LR 0.0353846153846 --> Loss 0.00255647440751\n",
      "Epoch 29::Minibatch 938::LR 0.0353846153846 --> Loss 0.00220833400885\n",
      "Epoch 29::Minibatch 939::LR 0.0353846153846 --> Loss 0.00236414651076\n",
      "Epoch 29::Minibatch 940::LR 0.0353846153846 --> Loss 0.000938670039177\n",
      "Epoch 29::Minibatch 941::LR 0.0353846153846 --> Loss 0.000767568349838\n",
      "Epoch 29::Minibatch 942::LR 0.0353846153846 --> Loss 0.00248465359211\n",
      "Epoch 29::Minibatch 943::LR 0.0353846153846 --> Loss 0.00242671430111\n",
      "Epoch 29::Minibatch 944::LR 0.0353846153846 --> Loss 0.00175549209118\n",
      "Epoch 29::Minibatch 945::LR 0.0353846153846 --> Loss 0.000998964210351\n",
      "Epoch 29::Minibatch 946::LR 0.0353846153846 --> Loss 0.00253557085991\n",
      "Epoch 29::Minibatch 947::LR 0.0353846153846 --> Loss 0.00232671280702\n",
      "Epoch 29::Minibatch 948::LR 0.0353846153846 --> Loss 0.00426821390788\n",
      "Epoch 29::Minibatch 949::LR 0.0353846153846 --> Loss 0.00174165387948\n",
      "Epoch 29::Minibatch 950::LR 0.0353846153846 --> Loss 0.000707899183035\n",
      "Epoch 29::Minibatch 951::LR 0.0353846153846 --> Loss 0.0033596154054\n",
      "Epoch 29::Minibatch 952::LR 0.0353846153846 --> Loss 0.00234987894694\n",
      "Epoch 29::Minibatch 953::LR 0.0353846153846 --> Loss 0.00140713681777\n",
      "Epoch 29::Minibatch 954::LR 0.0353846153846 --> Loss 0.000944419701894\n",
      "Epoch 29::Minibatch 955::LR 0.0353846153846 --> Loss 0.00253769159317\n",
      "Epoch 29::Minibatch 956::LR 0.0353846153846 --> Loss 0.00320351541042\n",
      "Epoch 29::Minibatch 957::LR 0.0353846153846 --> Loss 0.00182516296705\n",
      "Epoch 29::Minibatch 958::LR 0.0353846153846 --> Loss 0.00218734045823\n",
      "Epoch 29::Minibatch 959::LR 0.0353846153846 --> Loss 0.00258353948593\n",
      "Epoch 29::Minibatch 960::LR 0.0353846153846 --> Loss 0.00552507797877\n",
      "Epoch 29::Minibatch 961::LR 0.0353846153846 --> Loss 0.00305408338706\n",
      "Epoch 29::Minibatch 962::LR 0.0353846153846 --> Loss 0.00247513771057\n",
      "Epoch 29::Minibatch 963::LR 0.0353846153846 --> Loss 0.00104595114787\n",
      "Epoch 29::Minibatch 964::LR 0.0353846153846 --> Loss 0.00234154661496\n",
      "Epoch 29::Minibatch 965::LR 0.0353846153846 --> Loss 0.00646281282107\n",
      "Epoch 29::Minibatch 966::LR 0.0353846153846 --> Loss 0.0048936009407\n",
      "Epoch 29::Minibatch 967::LR 0.0353846153846 --> Loss 0.00129971534014\n",
      "Epoch 29::Minibatch 968::LR 0.0353846153846 --> Loss 0.00109630654256\n",
      "Epoch 29::Minibatch 969::LR 0.0353846153846 --> Loss 0.00493694265683\n",
      "Epoch 29::Minibatch 970::LR 0.0353846153846 --> Loss 0.00474303483963\n",
      "Epoch 29::Minibatch 971::LR 0.0353846153846 --> Loss 0.00335766951243\n",
      "Epoch 29::Minibatch 972::LR 0.0353846153846 --> Loss 0.00870190064112\n",
      "Epoch 29::Minibatch 973::LR 0.0353846153846 --> Loss 0.00916742324829\n",
      "Epoch 29::Minibatch 974::LR 0.0353846153846 --> Loss 0.00825299421946\n",
      "Epoch 29::Minibatch 975::LR 0.0353846153846 --> Loss 0.00440214753151\n",
      "Epoch 29::Minibatch 976::LR 0.0353846153846 --> Loss 0.0037050151825\n",
      "Epoch 29::Minibatch 977::LR 0.0353846153846 --> Loss 0.00350133140882\n",
      "Epoch 29::Minibatch 978::LR 0.0353846153846 --> Loss 0.00344303647677\n",
      "Epoch 29::Minibatch 979::LR 0.0353846153846 --> Loss 0.00323749562105\n",
      "Epoch 29::Minibatch 980::LR 0.0353846153846 --> Loss 0.00355621695518\n",
      "Epoch 29::Minibatch 981::LR 0.0353846153846 --> Loss 0.00449094971021\n",
      "Epoch 29::Minibatch 982::LR 0.0353846153846 --> Loss 0.00478013277054\n",
      "Epoch 29::Minibatch 983::LR 0.0353846153846 --> Loss 0.00262900511424\n",
      "Epoch 29::Minibatch 984::LR 0.0353846153846 --> Loss 0.00190439621607\n",
      "Epoch 29::Minibatch 985::LR 0.0353846153846 --> Loss 0.00353810787201\n",
      "Epoch 29::Minibatch 986::LR 0.0353846153846 --> Loss 0.00322653055191\n",
      "Epoch 29::Minibatch 987::LR 0.0353846153846 --> Loss 0.00351816177368\n",
      "Epoch 29::Minibatch 988::LR 0.0353846153846 --> Loss 0.00281091888746\n",
      "Epoch 29::Minibatch 989::LR 0.0353846153846 --> Loss 0.00306637088458\n",
      "Epoch 29::Minibatch 990::LR 0.0353846153846 --> Loss 0.00284020940463\n",
      "Epoch 29::Minibatch 991::LR 0.0353846153846 --> Loss 0.00145801285903\n",
      "Epoch 29::Minibatch 992::LR 0.0353846153846 --> Loss 0.00166890561581\n",
      "Epoch 29::Minibatch 993::LR 0.0353846153846 --> Loss 0.00309894184271\n",
      "Epoch 29::Minibatch 994::LR 0.0353846153846 --> Loss 0.00201910078526\n",
      "Epoch 29::Minibatch 995::LR 0.0353846153846 --> Loss 0.000815342466036\n",
      "Epoch 29::Minibatch 996::LR 0.0353846153846 --> Loss 0.00274230142434\n",
      "Epoch 29::Minibatch 997::LR 0.0353846153846 --> Loss 0.00220383723577\n",
      "Epoch 29::Minibatch 998::LR 0.0353846153846 --> Loss 0.00250824689865\n",
      "Epoch 29::Minibatch 999::LR 0.0353846153846 --> Loss 0.00213173568249\n",
      "Epoch 29::Minibatch 1000::LR 0.0353846153846 --> Loss 0.00255144079526\n",
      "Epoch 29::Minibatch 1001::LR 0.0353846153846 --> Loss 0.00202946543694\n",
      "Epoch 29::Minibatch 1002::LR 0.0353846153846 --> Loss 0.0016696814696\n",
      "Epoch 29::Minibatch 1003::LR 0.0353846153846 --> Loss 0.00268080373605\n",
      "Epoch 29::Minibatch 1004::LR 0.0353846153846 --> Loss 0.00106976459424\n",
      "Epoch 29::Minibatch 1005::LR 0.0353846153846 --> Loss 0.00267322719097\n",
      "Epoch 29::Minibatch 1006::LR 0.0353846153846 --> Loss 0.00142283608516\n",
      "Epoch 29::Minibatch 1007::LR 0.0353846153846 --> Loss 0.00185167590777\n",
      "Epoch 29::Minibatch 1008::LR 0.0353846153846 --> Loss 0.000930137534936\n",
      "Epoch 29::Minibatch 1009::LR 0.0353846153846 --> Loss 0.00124695579211\n",
      "Epoch 29::Minibatch 1010::LR 0.0353846153846 --> Loss 0.001147159338\n",
      "Epoch 29::Minibatch 1011::LR 0.0353846153846 --> Loss 0.00179427425067\n",
      "Epoch 29::Minibatch 1012::LR 0.0353846153846 --> Loss 0.00143547644218\n",
      "Epoch 29::Minibatch 1013::LR 0.0353846153846 --> Loss 0.00361619869868\n",
      "Epoch 29::Minibatch 1014::LR 0.0353846153846 --> Loss 0.00337956110636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29::Minibatch 1015::LR 0.0353846153846 --> Loss 0.00154908319314\n",
      "Epoch 29::Minibatch 1016::LR 0.0353846153846 --> Loss 0.00455376982689\n",
      "Epoch 29::Minibatch 1017::LR 0.0353846153846 --> Loss 0.0031053541104\n",
      "Epoch 29::Minibatch 1018::LR 0.0353846153846 --> Loss 0.00256632864475\n",
      "Epoch 29::Minibatch 1019::LR 0.0353846153846 --> Loss 0.00163714587688\n",
      "Epoch 29::Minibatch 1020::LR 0.0353846153846 --> Loss 0.00174137949944\n",
      "Epoch 29::Minibatch 1021::LR 0.0353846153846 --> Loss 0.00185343881448\n",
      "Epoch 29::Minibatch 1022::LR 0.0353846153846 --> Loss 0.0013714119792\n",
      "Epoch 29::Minibatch 1023::LR 0.0353846153846 --> Loss 0.00103272805611\n",
      "Epoch 29::Minibatch 1024::LR 0.0353846153846 --> Loss 0.00102599273125\n",
      "Epoch 29::Minibatch 1025::LR 0.0353846153846 --> Loss 0.00137168725332\n",
      "Epoch 29::Minibatch 1026::LR 0.0353846153846 --> Loss 0.000716675122579\n",
      "Epoch 29::Minibatch 1027::LR 0.0353846153846 --> Loss 0.000981810291608\n",
      "Epoch 29::Minibatch 1028::LR 0.0353846153846 --> Loss 0.000740259935459\n",
      "Epoch 29::Minibatch 1029::LR 0.0353846153846 --> Loss 0.000746192634106\n",
      "Epoch 29::Minibatch 1030::LR 0.0353846153846 --> Loss 0.000915035009384\n",
      "Epoch 29::Minibatch 1031::LR 0.0353846153846 --> Loss 0.000703734258811\n",
      "Epoch 29::Minibatch 1032::LR 0.0353846153846 --> Loss 0.000777424474557\n",
      "Epoch 29::Minibatch 1033::LR 0.0353846153846 --> Loss 0.000660976022482\n",
      "Epoch 29::Minibatch 1034::LR 0.0353846153846 --> Loss 0.000628547320763\n",
      "Epoch 29::Minibatch 1035::LR 0.0353846153846 --> Loss 0.000415283938249\n",
      "Epoch 29::Minibatch 1036::LR 0.0353846153846 --> Loss 0.000332495371501\n",
      "Epoch 29::Minibatch 1037::LR 0.0353846153846 --> Loss 0.000599339554707\n",
      "Epoch 29::Minibatch 1038::LR 0.0353846153846 --> Loss 0.001118410031\n",
      "Epoch 29::Minibatch 1039::LR 0.0353846153846 --> Loss 0.000889312624931\n",
      "Epoch 29::Minibatch 1040::LR 0.0353846153846 --> Loss 0.000351221809785\n",
      "Epoch 29::Minibatch 1041::LR 0.0353846153846 --> Loss 0.000506039659182\n",
      "Epoch 30::Minibatch 1::LR 0.0330769230769 --> Loss 0.00782542626063\n",
      "Epoch 30::Minibatch 2::LR 0.0330769230769 --> Loss 0.00495833754539\n",
      "Epoch 30::Minibatch 3::LR 0.0330769230769 --> Loss 0.0031573053201\n",
      "Epoch 30::Minibatch 4::LR 0.0330769230769 --> Loss 0.00387373129527\n",
      "Epoch 30::Minibatch 5::LR 0.0330769230769 --> Loss 0.00442677021027\n",
      "Epoch 30::Minibatch 6::LR 0.0330769230769 --> Loss 0.00211552858353\n",
      "Epoch 30::Minibatch 7::LR 0.0330769230769 --> Loss 0.00722128868103\n",
      "Epoch 30::Minibatch 8::LR 0.0330769230769 --> Loss 0.00673676013947\n",
      "Epoch 30::Minibatch 9::LR 0.0330769230769 --> Loss 0.00520233313243\n",
      "Epoch 30::Minibatch 10::LR 0.0330769230769 --> Loss 0.00241884946823\n",
      "Epoch 30::Minibatch 11::LR 0.0330769230769 --> Loss 0.00224739332994\n",
      "Epoch 30::Minibatch 12::LR 0.0330769230769 --> Loss 0.00337795098623\n",
      "Epoch 30::Minibatch 13::LR 0.0330769230769 --> Loss 0.00530923803647\n",
      "Epoch 30::Minibatch 14::LR 0.0330769230769 --> Loss 0.00528483311335\n",
      "Epoch 30::Minibatch 15::LR 0.0330769230769 --> Loss 0.0045539855957\n",
      "Epoch 30::Minibatch 16::LR 0.0330769230769 --> Loss 0.000733175079028\n",
      "Epoch 30::Minibatch 17::LR 0.0330769230769 --> Loss 0.00318370600541\n",
      "Epoch 30::Minibatch 18::LR 0.0330769230769 --> Loss 0.00262929280599\n",
      "Epoch 30::Minibatch 19::LR 0.0330769230769 --> Loss 0.0015520949165\n",
      "Epoch 30::Minibatch 20::LR 0.0330769230769 --> Loss 0.00207649469376\n",
      "Epoch 30::Minibatch 21::LR 0.0330769230769 --> Loss 0.0033655043443\n",
      "Epoch 30::Minibatch 22::LR 0.0330769230769 --> Loss 0.00222824752331\n",
      "Epoch 30::Minibatch 23::LR 0.0330769230769 --> Loss 0.000893222292264\n",
      "Epoch 30::Minibatch 24::LR 0.0330769230769 --> Loss 0.000483333418767\n",
      "Epoch 30::Minibatch 25::LR 0.0330769230769 --> Loss 0.00131130884091\n",
      "Epoch 30::Minibatch 26::LR 0.0330769230769 --> Loss 0.00150861680508\n",
      "Epoch 30::Minibatch 27::LR 0.0330769230769 --> Loss 0.00111568291982\n",
      "Epoch 30::Minibatch 28::LR 0.0330769230769 --> Loss 0.000487307161093\n",
      "Epoch 30::Minibatch 29::LR 0.0330769230769 --> Loss 0.000572989781698\n",
      "Epoch 30::Minibatch 30::LR 0.0330769230769 --> Loss 0.00106420367956\n",
      "Epoch 30::Minibatch 31::LR 0.0330769230769 --> Loss 0.00155123184125\n",
      "Epoch 30::Minibatch 32::LR 0.0330769230769 --> Loss 0.00138033260902\n",
      "Epoch 30::Minibatch 33::LR 0.0330769230769 --> Loss 0.000803123066823\n",
      "Epoch 30::Minibatch 34::LR 0.0330769230769 --> Loss 0.00205892781417\n",
      "Epoch 30::Minibatch 35::LR 0.0330769230769 --> Loss 0.00304774026076\n",
      "Epoch 30::Minibatch 36::LR 0.0330769230769 --> Loss 0.00224610904853\n",
      "Epoch 30::Minibatch 37::LR 0.0330769230769 --> Loss 0.000702005972465\n",
      "Epoch 30::Minibatch 38::LR 0.0330769230769 --> Loss 0.000726691881816\n",
      "Epoch 30::Minibatch 39::LR 0.0330769230769 --> Loss 0.00216596027215\n",
      "Epoch 30::Minibatch 40::LR 0.0330769230769 --> Loss 0.00309037824472\n",
      "Epoch 30::Minibatch 41::LR 0.0330769230769 --> Loss 0.00247003297011\n",
      "Epoch 30::Minibatch 42::LR 0.0330769230769 --> Loss 0.00471935431163\n",
      "Epoch 30::Minibatch 43::LR 0.0330769230769 --> Loss 0.0019980909427\n",
      "Epoch 30::Minibatch 44::LR 0.0330769230769 --> Loss 0.00327231287956\n",
      "Epoch 30::Minibatch 45::LR 0.0330769230769 --> Loss 0.00240053693453\n",
      "Epoch 30::Minibatch 46::LR 0.0330769230769 --> Loss 0.00309100210667\n",
      "Epoch 30::Minibatch 47::LR 0.0330769230769 --> Loss 0.00341328660647\n",
      "Epoch 30::Minibatch 48::LR 0.0330769230769 --> Loss 0.0049292298158\n",
      "Epoch 30::Minibatch 49::LR 0.0330769230769 --> Loss 0.00554984609286\n",
      "Epoch 30::Minibatch 50::LR 0.0330769230769 --> Loss 0.00600812315941\n",
      "Epoch 30::Minibatch 51::LR 0.0330769230769 --> Loss 0.00453474919001\n",
      "Epoch 30::Minibatch 52::LR 0.0330769230769 --> Loss 0.00341750383377\n",
      "Epoch 30::Minibatch 53::LR 0.0330769230769 --> Loss 0.00337789138158\n",
      "Epoch 30::Minibatch 54::LR 0.0330769230769 --> Loss 0.00399085680644\n",
      "Epoch 30::Minibatch 55::LR 0.0330769230769 --> Loss 0.000991141001383\n",
      "Epoch 30::Minibatch 56::LR 0.0330769230769 --> Loss 0.00273007134597\n",
      "Epoch 30::Minibatch 57::LR 0.0330769230769 --> Loss 0.00466241876284\n",
      "Epoch 30::Minibatch 58::LR 0.0330769230769 --> Loss 0.00321022709211\n",
      "Epoch 30::Minibatch 59::LR 0.0330769230769 --> Loss 0.00243823448817\n",
      "Epoch 30::Minibatch 60::LR 0.0330769230769 --> Loss 0.00247123340766\n",
      "Epoch 30::Minibatch 61::LR 0.0330769230769 --> Loss 0.000729934771856\n",
      "Epoch 30::Minibatch 62::LR 0.0330769230769 --> Loss 0.00256550093492\n",
      "Epoch 30::Minibatch 63::LR 0.0330769230769 --> Loss 0.00201960305373\n",
      "Epoch 30::Minibatch 64::LR 0.0330769230769 --> Loss 0.000822196106116\n",
      "Epoch 30::Minibatch 65::LR 0.0330769230769 --> Loss 0.00215061128139\n",
      "Epoch 30::Minibatch 66::LR 0.0330769230769 --> Loss 0.00273952523867\n",
      "Epoch 30::Minibatch 67::LR 0.0330769230769 --> Loss 0.00252826233705\n",
      "Epoch 30::Minibatch 68::LR 0.0330769230769 --> Loss 0.00183723767598\n",
      "Epoch 30::Minibatch 69::LR 0.0330769230769 --> Loss 0.00363692045212\n",
      "Epoch 30::Minibatch 70::LR 0.0330769230769 --> Loss 0.00322555085023\n",
      "Epoch 30::Minibatch 71::LR 0.0330769230769 --> Loss 0.00224389354388\n",
      "Epoch 30::Minibatch 72::LR 0.0330769230769 --> Loss 0.000542757362127\n",
      "Epoch 30::Minibatch 73::LR 0.0330769230769 --> Loss 0.00369861602783\n",
      "Epoch 30::Minibatch 74::LR 0.0330769230769 --> Loss 0.00399174213409\n",
      "Epoch 30::Minibatch 75::LR 0.0330769230769 --> Loss 0.00210782170296\n",
      "Epoch 30::Minibatch 76::LR 0.0330769230769 --> Loss 0.000522794326146\n",
      "Epoch 30::Minibatch 77::LR 0.0330769230769 --> Loss 0.00333857178688\n",
      "Epoch 30::Minibatch 78::LR 0.0330769230769 --> Loss 0.00391385992368\n",
      "Epoch 30::Minibatch 79::LR 0.0330769230769 --> Loss 0.0017255338033\n",
      "Epoch 30::Minibatch 80::LR 0.0330769230769 --> Loss 0.00285797198613\n",
      "Epoch 30::Minibatch 81::LR 0.0330769230769 --> Loss 0.00252812246482\n",
      "Epoch 30::Minibatch 82::LR 0.0330769230769 --> Loss 0.00184260606766\n",
      "Epoch 30::Minibatch 83::LR 0.0330769230769 --> Loss 0.00392143527667\n",
      "Epoch 30::Minibatch 84::LR 0.0330769230769 --> Loss 0.00186086058617\n",
      "Epoch 30::Minibatch 85::LR 0.0330769230769 --> Loss 0.00253872553507\n",
      "Epoch 30::Minibatch 86::LR 0.0330769230769 --> Loss 0.00209109842777\n",
      "Epoch 30::Minibatch 87::LR 0.0330769230769 --> Loss 0.00222185353438\n",
      "Epoch 30::Minibatch 88::LR 0.0330769230769 --> Loss 0.00166776319345\n",
      "Epoch 30::Minibatch 89::LR 0.0330769230769 --> Loss 0.00219507495562\n",
      "Epoch 30::Minibatch 90::LR 0.0330769230769 --> Loss 0.00104613075654\n",
      "Epoch 30::Minibatch 91::LR 0.0330769230769 --> Loss 0.000869036118189\n",
      "Epoch 30::Minibatch 92::LR 0.0330769230769 --> Loss 0.00255693455537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 93::LR 0.0330769230769 --> Loss 0.00169649600983\n",
      "Epoch 30::Minibatch 94::LR 0.0330769230769 --> Loss 0.00173775653044\n",
      "Epoch 30::Minibatch 95::LR 0.0330769230769 --> Loss 0.00188978234927\n",
      "Epoch 30::Minibatch 96::LR 0.0330769230769 --> Loss 0.00482916911443\n",
      "Epoch 30::Minibatch 97::LR 0.0330769230769 --> Loss 0.00302352567514\n",
      "Epoch 30::Minibatch 98::LR 0.0330769230769 --> Loss 0.00106811136007\n",
      "Epoch 30::Minibatch 99::LR 0.0330769230769 --> Loss 0.00139148255189\n",
      "Epoch 30::Minibatch 100::LR 0.0330769230769 --> Loss 0.00427936196327\n",
      "Epoch 30::Minibatch 101::LR 0.0330769230769 --> Loss 0.0008975020051\n",
      "Epoch 30::Minibatch 102::LR 0.0330769230769 --> Loss 0.00386979897817\n",
      "Epoch 30::Minibatch 103::LR 0.0330769230769 --> Loss 0.00389476617177\n",
      "Epoch 30::Minibatch 104::LR 0.0330769230769 --> Loss 0.00265876690547\n",
      "Epoch 30::Minibatch 105::LR 0.0330769230769 --> Loss 0.00213643908501\n",
      "Epoch 30::Minibatch 106::LR 0.0330769230769 --> Loss 0.0140746514002\n",
      "Epoch 30::Minibatch 107::LR 0.0330769230769 --> Loss 0.00476513465246\n",
      "Epoch 30::Minibatch 108::LR 0.0330769230769 --> Loss 0.000931802392006\n",
      "Epoch 30::Minibatch 109::LR 0.0330769230769 --> Loss 0.00429564317067\n",
      "Epoch 30::Minibatch 110::LR 0.0330769230769 --> Loss 0.00221660494804\n",
      "Epoch 30::Minibatch 111::LR 0.0330769230769 --> Loss 0.000821864555279\n",
      "Epoch 30::Minibatch 112::LR 0.0330769230769 --> Loss 0.00328417340914\n",
      "Epoch 30::Minibatch 113::LR 0.0330769230769 --> Loss 0.00239238341649\n",
      "Epoch 30::Minibatch 114::LR 0.0330769230769 --> Loss 0.00133724739154\n",
      "Epoch 30::Minibatch 115::LR 0.0330769230769 --> Loss 0.00114096214374\n",
      "Epoch 30::Minibatch 116::LR 0.0330769230769 --> Loss 0.00262442588806\n",
      "Epoch 30::Minibatch 117::LR 0.0330769230769 --> Loss 0.00403679807981\n",
      "Epoch 30::Minibatch 118::LR 0.0330769230769 --> Loss 0.00657279531161\n",
      "Epoch 30::Minibatch 119::LR 0.0330769230769 --> Loss 0.000505080322425\n",
      "Epoch 30::Minibatch 120::LR 0.0330769230769 --> Loss 0.00162456085285\n",
      "Epoch 30::Minibatch 121::LR 0.0330769230769 --> Loss 0.00236743708452\n",
      "Epoch 30::Minibatch 122::LR 0.0330769230769 --> Loss 0.00381601730982\n",
      "Epoch 30::Minibatch 123::LR 0.0330769230769 --> Loss 0.000702642599742\n",
      "Epoch 30::Minibatch 124::LR 0.0330769230769 --> Loss 0.00259632031123\n",
      "Epoch 30::Minibatch 125::LR 0.0330769230769 --> Loss 0.00441610813141\n",
      "Epoch 30::Minibatch 126::LR 0.0330769230769 --> Loss 0.00246212422848\n",
      "Epoch 30::Minibatch 127::LR 0.0330769230769 --> Loss 0.00475935578346\n",
      "Epoch 30::Minibatch 128::LR 0.0330769230769 --> Loss 0.00351440827052\n",
      "Epoch 30::Minibatch 129::LR 0.0330769230769 --> Loss 0.00241803050041\n",
      "Epoch 30::Minibatch 130::LR 0.0330769230769 --> Loss 0.00431765755018\n",
      "Epoch 30::Minibatch 131::LR 0.0330769230769 --> Loss 0.00171302497387\n",
      "Epoch 30::Minibatch 132::LR 0.0330769230769 --> Loss 0.00284186899662\n",
      "Epoch 30::Minibatch 133::LR 0.0330769230769 --> Loss 0.00273449758689\n",
      "Epoch 30::Minibatch 134::LR 0.0330769230769 --> Loss 0.00213215947151\n",
      "Epoch 30::Minibatch 135::LR 0.0330769230769 --> Loss 0.00130679140488\n",
      "Epoch 30::Minibatch 136::LR 0.0330769230769 --> Loss 0.00245296855768\n",
      "Epoch 30::Minibatch 137::LR 0.0330769230769 --> Loss 0.00341152111689\n",
      "Epoch 30::Minibatch 138::LR 0.0330769230769 --> Loss 0.0012207236886\n",
      "Epoch 30::Minibatch 139::LR 0.0330769230769 --> Loss 0.00187495251497\n",
      "Epoch 30::Minibatch 140::LR 0.0330769230769 --> Loss 0.00238921562831\n",
      "Epoch 30::Minibatch 141::LR 0.0330769230769 --> Loss 0.00289758880933\n",
      "Epoch 30::Minibatch 142::LR 0.0330769230769 --> Loss 0.00270365158717\n",
      "Epoch 30::Minibatch 143::LR 0.0330769230769 --> Loss 0.000545032223066\n",
      "Epoch 30::Minibatch 144::LR 0.0330769230769 --> Loss 0.00333980441093\n",
      "Epoch 30::Minibatch 145::LR 0.0330769230769 --> Loss 0.00413584629695\n",
      "Epoch 30::Minibatch 146::LR 0.0330769230769 --> Loss 0.00250100692113\n",
      "Epoch 30::Minibatch 147::LR 0.0330769230769 --> Loss 0.00178756097953\n",
      "Epoch 30::Minibatch 148::LR 0.0330769230769 --> Loss 0.000974907080332\n",
      "Epoch 30::Minibatch 149::LR 0.0330769230769 --> Loss 0.00285034338633\n",
      "Epoch 30::Minibatch 150::LR 0.0330769230769 --> Loss 0.00266339202722\n",
      "Epoch 30::Minibatch 151::LR 0.0330769230769 --> Loss 0.00426997343699\n",
      "Epoch 30::Minibatch 152::LR 0.0330769230769 --> Loss 0.000904070734978\n",
      "Epoch 30::Minibatch 153::LR 0.0330769230769 --> Loss 0.00165578077237\n",
      "Epoch 30::Minibatch 154::LR 0.0330769230769 --> Loss 0.00201413055261\n",
      "Epoch 30::Minibatch 155::LR 0.0330769230769 --> Loss 0.00412023186684\n",
      "Epoch 30::Minibatch 156::LR 0.0330769230769 --> Loss 0.00235500494639\n",
      "Epoch 30::Minibatch 157::LR 0.0330769230769 --> Loss 0.000687085191409\n",
      "Epoch 30::Minibatch 158::LR 0.0330769230769 --> Loss 0.00314076642195\n",
      "Epoch 30::Minibatch 159::LR 0.0330769230769 --> Loss 0.0027246928215\n",
      "Epoch 30::Minibatch 160::LR 0.0330769230769 --> Loss 0.0026421525081\n",
      "Epoch 30::Minibatch 161::LR 0.0330769230769 --> Loss 0.00100333799918\n",
      "Epoch 30::Minibatch 162::LR 0.0330769230769 --> Loss 0.0039090081056\n",
      "Epoch 30::Minibatch 163::LR 0.0330769230769 --> Loss 0.00239466428757\n",
      "Epoch 30::Minibatch 164::LR 0.0330769230769 --> Loss 0.00252104242643\n",
      "Epoch 30::Minibatch 165::LR 0.0330769230769 --> Loss 0.000501823524634\n",
      "Epoch 30::Minibatch 166::LR 0.0330769230769 --> Loss 0.00171680688858\n",
      "Epoch 30::Minibatch 167::LR 0.0330769230769 --> Loss 0.00246811052163\n",
      "Epoch 30::Minibatch 168::LR 0.0330769230769 --> Loss 0.00214497705301\n",
      "Epoch 30::Minibatch 169::LR 0.0330769230769 --> Loss 0.000993438363075\n",
      "Epoch 30::Minibatch 170::LR 0.0330769230769 --> Loss 0.0009596418341\n",
      "Epoch 30::Minibatch 171::LR 0.0330769230769 --> Loss 0.00250392039617\n",
      "Epoch 30::Minibatch 172::LR 0.0330769230769 --> Loss 0.00425338387489\n",
      "Epoch 30::Minibatch 173::LR 0.0330769230769 --> Loss 0.00198255161444\n",
      "Epoch 30::Minibatch 174::LR 0.0330769230769 --> Loss 0.000971287389596\n",
      "Epoch 30::Minibatch 175::LR 0.0330769230769 --> Loss 0.00234432578087\n",
      "Epoch 30::Minibatch 176::LR 0.0330769230769 --> Loss 0.00314470589161\n",
      "Epoch 30::Minibatch 177::LR 0.0330769230769 --> Loss 0.00430869897207\n",
      "Epoch 30::Minibatch 178::LR 0.0330769230769 --> Loss 0.00152665376663\n",
      "Epoch 30::Minibatch 179::LR 0.0330769230769 --> Loss 0.00123500198126\n",
      "Epoch 30::Minibatch 180::LR 0.0330769230769 --> Loss 0.00343263506889\n",
      "Epoch 30::Minibatch 181::LR 0.0330769230769 --> Loss 0.00308416247368\n",
      "Epoch 30::Minibatch 182::LR 0.0330769230769 --> Loss 0.000718359748522\n",
      "Epoch 30::Minibatch 183::LR 0.0330769230769 --> Loss 0.00158692290386\n",
      "Epoch 30::Minibatch 184::LR 0.0330769230769 --> Loss 0.00340950528781\n",
      "Epoch 30::Minibatch 185::LR 0.0330769230769 --> Loss 0.00271312594414\n",
      "Epoch 30::Minibatch 186::LR 0.0330769230769 --> Loss 0.000938240091006\n",
      "Epoch 30::Minibatch 187::LR 0.0330769230769 --> Loss 0.00127648681402\n",
      "Epoch 30::Minibatch 188::LR 0.0330769230769 --> Loss 0.00408478061358\n",
      "Epoch 30::Minibatch 189::LR 0.0330769230769 --> Loss 0.0041817522049\n",
      "Epoch 30::Minibatch 190::LR 0.0330769230769 --> Loss 0.00231917123\n",
      "Epoch 30::Minibatch 191::LR 0.0330769230769 --> Loss 0.000455136497815\n",
      "Epoch 30::Minibatch 192::LR 0.0330769230769 --> Loss 0.0027675229311\n",
      "Epoch 30::Minibatch 193::LR 0.0330769230769 --> Loss 0.00267064273357\n",
      "Epoch 30::Minibatch 194::LR 0.0330769230769 --> Loss 0.00174597839514\n",
      "Epoch 30::Minibatch 195::LR 0.0330769230769 --> Loss 0.00037800612549\n",
      "Epoch 30::Minibatch 196::LR 0.0330769230769 --> Loss 0.00133348872264\n",
      "Epoch 30::Minibatch 197::LR 0.0330769230769 --> Loss 0.00294693013032\n",
      "Epoch 30::Minibatch 198::LR 0.0330769230769 --> Loss 0.00229110399882\n",
      "Epoch 30::Minibatch 199::LR 0.0330769230769 --> Loss 0.000290383547544\n",
      "Epoch 30::Minibatch 200::LR 0.0330769230769 --> Loss 0.00203965544701\n",
      "Epoch 30::Minibatch 201::LR 0.0330769230769 --> Loss 0.00193392813206\n",
      "Epoch 30::Minibatch 202::LR 0.0330769230769 --> Loss 0.0018242418766\n",
      "Epoch 30::Minibatch 203::LR 0.0330769230769 --> Loss 0.00175076285998\n",
      "Epoch 30::Minibatch 204::LR 0.0330769230769 --> Loss 0.00141910284758\n",
      "Epoch 30::Minibatch 205::LR 0.0330769230769 --> Loss 0.00220590531826\n",
      "Epoch 30::Minibatch 206::LR 0.0330769230769 --> Loss 0.0056550359726\n",
      "Epoch 30::Minibatch 207::LR 0.0330769230769 --> Loss 0.00139805823565\n",
      "Epoch 30::Minibatch 208::LR 0.0330769230769 --> Loss 0.00110709617535\n",
      "Epoch 30::Minibatch 209::LR 0.0330769230769 --> Loss 0.00243250707785\n",
      "Epoch 30::Minibatch 210::LR 0.0330769230769 --> Loss 0.00229857067267\n",
      "Epoch 30::Minibatch 211::LR 0.0330769230769 --> Loss 0.00259809831778\n",
      "Epoch 30::Minibatch 212::LR 0.0330769230769 --> Loss 0.00379608750343\n",
      "Epoch 30::Minibatch 213::LR 0.0330769230769 --> Loss 0.00546751141548\n",
      "Epoch 30::Minibatch 214::LR 0.0330769230769 --> Loss 0.0074685939153\n",
      "Epoch 30::Minibatch 215::LR 0.0330769230769 --> Loss 0.00136097540458\n",
      "Epoch 30::Minibatch 216::LR 0.0330769230769 --> Loss 0.00532851537069\n",
      "Epoch 30::Minibatch 217::LR 0.0330769230769 --> Loss 0.00590191443761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 218::LR 0.0330769230769 --> Loss 0.00389780521393\n",
      "Epoch 30::Minibatch 219::LR 0.0330769230769 --> Loss 0.00436258236567\n",
      "Epoch 30::Minibatch 220::LR 0.0330769230769 --> Loss 0.00437581499418\n",
      "Epoch 30::Minibatch 221::LR 0.0330769230769 --> Loss 0.00424264431\n",
      "Epoch 30::Minibatch 222::LR 0.0330769230769 --> Loss 0.0031720773379\n",
      "Epoch 30::Minibatch 223::LR 0.0330769230769 --> Loss 0.001387360394\n",
      "Epoch 30::Minibatch 224::LR 0.0330769230769 --> Loss 0.0016177680095\n",
      "Epoch 30::Minibatch 225::LR 0.0330769230769 --> Loss 0.00770494302114\n",
      "Epoch 30::Minibatch 226::LR 0.0330769230769 --> Loss 0.00368129412333\n",
      "Epoch 30::Minibatch 227::LR 0.0330769230769 --> Loss 0.00167907039324\n",
      "Epoch 30::Minibatch 228::LR 0.0330769230769 --> Loss 0.000666424036026\n",
      "Epoch 30::Minibatch 229::LR 0.0330769230769 --> Loss 0.00471216479937\n",
      "Epoch 30::Minibatch 230::LR 0.0330769230769 --> Loss 0.00372684121132\n",
      "Epoch 30::Minibatch 231::LR 0.0330769230769 --> Loss 0.00265775978565\n",
      "Epoch 30::Minibatch 232::LR 0.0330769230769 --> Loss 0.00117122173309\n",
      "Epoch 30::Minibatch 233::LR 0.0330769230769 --> Loss 0.00245488087336\n",
      "Epoch 30::Minibatch 234::LR 0.0330769230769 --> Loss 0.00725484132767\n",
      "Epoch 30::Minibatch 235::LR 0.0330769230769 --> Loss 0.00456681569417\n",
      "Epoch 30::Minibatch 236::LR 0.0330769230769 --> Loss 0.0016885338227\n",
      "Epoch 30::Minibatch 237::LR 0.0330769230769 --> Loss 0.000604982425769\n",
      "Epoch 30::Minibatch 238::LR 0.0330769230769 --> Loss 0.00342523097992\n",
      "Epoch 30::Minibatch 239::LR 0.0330769230769 --> Loss 0.0029573349158\n",
      "Epoch 30::Minibatch 240::LR 0.0330769230769 --> Loss 0.00324346363544\n",
      "Epoch 30::Minibatch 241::LR 0.0330769230769 --> Loss 0.000744593391816\n",
      "Epoch 30::Minibatch 242::LR 0.0330769230769 --> Loss 0.00676271677017\n",
      "Epoch 30::Minibatch 243::LR 0.0330769230769 --> Loss 0.0033071710666\n",
      "Epoch 30::Minibatch 244::LR 0.0330769230769 --> Loss 0.00277294337749\n",
      "Epoch 30::Minibatch 245::LR 0.0330769230769 --> Loss 0.000436939448118\n",
      "Epoch 30::Minibatch 246::LR 0.0330769230769 --> Loss 0.00193689664205\n",
      "Epoch 30::Minibatch 247::LR 0.0330769230769 --> Loss 0.0109646836917\n",
      "Epoch 30::Minibatch 248::LR 0.0330769230769 --> Loss 0.00436052481333\n",
      "Epoch 30::Minibatch 249::LR 0.0330769230769 --> Loss 0.00245020786921\n",
      "Epoch 30::Minibatch 250::LR 0.0330769230769 --> Loss 0.00237468004227\n",
      "Epoch 30::Minibatch 251::LR 0.0330769230769 --> Loss 0.0023579476277\n",
      "Epoch 30::Minibatch 252::LR 0.0330769230769 --> Loss 0.00163854420185\n",
      "Epoch 30::Minibatch 253::LR 0.0330769230769 --> Loss 0.0028480219841\n",
      "Epoch 30::Minibatch 254::LR 0.0330769230769 --> Loss 0.0048752228419\n",
      "Epoch 30::Minibatch 255::LR 0.0330769230769 --> Loss 0.0038362411658\n",
      "Epoch 30::Minibatch 256::LR 0.0330769230769 --> Loss 0.00143756647905\n",
      "Epoch 30::Minibatch 257::LR 0.0330769230769 --> Loss 0.00114947319031\n",
      "Epoch 30::Minibatch 258::LR 0.0330769230769 --> Loss 0.00364635984103\n",
      "Epoch 30::Minibatch 259::LR 0.0330769230769 --> Loss 0.00162657260895\n",
      "Epoch 30::Minibatch 260::LR 0.0330769230769 --> Loss 0.00185036838055\n",
      "Epoch 30::Minibatch 261::LR 0.0330769230769 --> Loss 0.00269066949685\n",
      "Epoch 30::Minibatch 262::LR 0.0330769230769 --> Loss 0.001831381917\n",
      "Epoch 30::Minibatch 263::LR 0.0330769230769 --> Loss 0.00229891041915\n",
      "Epoch 30::Minibatch 264::LR 0.0330769230769 --> Loss 0.00356707811356\n",
      "Epoch 30::Minibatch 265::LR 0.0330769230769 --> Loss 0.00993567943573\n",
      "Epoch 30::Minibatch 266::LR 0.0330769230769 --> Loss 0.000906915863355\n",
      "Epoch 30::Minibatch 267::LR 0.0330769230769 --> Loss 0.00924402475357\n",
      "Epoch 30::Minibatch 268::LR 0.0330769230769 --> Loss 0.00106298267841\n",
      "Epoch 30::Minibatch 269::LR 0.0330769230769 --> Loss 0.00346463481585\n",
      "Epoch 30::Minibatch 270::LR 0.0330769230769 --> Loss 0.00716760238012\n",
      "Epoch 30::Minibatch 271::LR 0.0330769230769 --> Loss 0.00247544785341\n",
      "Epoch 30::Minibatch 272::LR 0.0330769230769 --> Loss 0.00435624837875\n",
      "Epoch 30::Minibatch 273::LR 0.0330769230769 --> Loss 0.00143269191186\n",
      "Epoch 30::Minibatch 274::LR 0.0330769230769 --> Loss 0.00177655378977\n",
      "Epoch 30::Minibatch 275::LR 0.0330769230769 --> Loss 0.00249898135662\n",
      "Epoch 30::Minibatch 276::LR 0.0330769230769 --> Loss 0.00337648948034\n",
      "Epoch 30::Minibatch 277::LR 0.0330769230769 --> Loss 0.000892641445001\n",
      "Epoch 30::Minibatch 278::LR 0.0330769230769 --> Loss 0.00255718648434\n",
      "Epoch 30::Minibatch 279::LR 0.0330769230769 --> Loss 0.00206896444162\n",
      "Epoch 30::Minibatch 280::LR 0.0330769230769 --> Loss 0.00182560880979\n",
      "Epoch 30::Minibatch 281::LR 0.0330769230769 --> Loss 0.00115717321634\n",
      "Epoch 30::Minibatch 282::LR 0.0330769230769 --> Loss 0.00205782949924\n",
      "Epoch 30::Minibatch 283::LR 0.0330769230769 --> Loss 0.00196764032046\n",
      "Epoch 30::Minibatch 284::LR 0.0330769230769 --> Loss 0.00160142074029\n",
      "Epoch 30::Minibatch 285::LR 0.0330769230769 --> Loss 0.00114520837863\n",
      "Epoch 30::Minibatch 286::LR 0.0330769230769 --> Loss 0.00199794391791\n",
      "Epoch 30::Minibatch 287::LR 0.0330769230769 --> Loss 0.00197146693865\n",
      "Epoch 30::Minibatch 288::LR 0.0330769230769 --> Loss 0.00107262482246\n",
      "Epoch 30::Minibatch 289::LR 0.0330769230769 --> Loss 0.00157321333885\n",
      "Epoch 30::Minibatch 290::LR 0.0330769230769 --> Loss 0.0018704110384\n",
      "Epoch 30::Minibatch 291::LR 0.0330769230769 --> Loss 0.00167790174484\n",
      "Epoch 30::Minibatch 292::LR 0.0330769230769 --> Loss 0.000592788308859\n",
      "Epoch 30::Minibatch 293::LR 0.0330769230769 --> Loss 0.00149806290865\n",
      "Epoch 30::Minibatch 294::LR 0.0330769230769 --> Loss 0.00161170234283\n",
      "Epoch 30::Minibatch 295::LR 0.0330769230769 --> Loss 0.00188422977924\n",
      "Epoch 30::Minibatch 296::LR 0.0330769230769 --> Loss 0.0016305522124\n",
      "Epoch 30::Minibatch 297::LR 0.0330769230769 --> Loss 0.00142310470343\n",
      "Epoch 30::Minibatch 298::LR 0.0330769230769 --> Loss 0.0014242759347\n",
      "Epoch 30::Minibatch 299::LR 0.0330769230769 --> Loss 0.000814439356327\n",
      "Epoch 30::Minibatch 300::LR 0.0330769230769 --> Loss 0.00270441492399\n",
      "Epoch 30::Minibatch 301::LR 0.0330769230769 --> Loss 0.00261494576931\n",
      "Epoch 30::Minibatch 302::LR 0.0330769230769 --> Loss 0.00239889045556\n",
      "Epoch 30::Minibatch 303::LR 0.0330769230769 --> Loss 0.000836938222249\n",
      "Epoch 30::Minibatch 304::LR 0.0330769230769 --> Loss 0.00296122451623\n",
      "Epoch 30::Minibatch 305::LR 0.0330769230769 --> Loss 0.00171183685462\n",
      "Epoch 30::Minibatch 306::LR 0.0330769230769 --> Loss 0.000939358671506\n",
      "Epoch 30::Minibatch 307::LR 0.0330769230769 --> Loss 0.00240709761779\n",
      "Epoch 30::Minibatch 308::LR 0.0330769230769 --> Loss 0.00202137847741\n",
      "Epoch 30::Minibatch 309::LR 0.0330769230769 --> Loss 0.00104153235753\n",
      "Epoch 30::Minibatch 310::LR 0.0330769230769 --> Loss 0.00118876735369\n",
      "Epoch 30::Minibatch 311::LR 0.0330769230769 --> Loss 0.00179088016351\n",
      "Epoch 30::Minibatch 312::LR 0.0330769230769 --> Loss 0.00286227325598\n",
      "Epoch 30::Minibatch 313::LR 0.0330769230769 --> Loss 0.00234709938367\n",
      "Epoch 30::Minibatch 314::LR 0.0330769230769 --> Loss 0.00192408879598\n",
      "Epoch 30::Minibatch 315::LR 0.0330769230769 --> Loss 0.00104331384103\n",
      "Epoch 30::Minibatch 316::LR 0.0330769230769 --> Loss 0.00234385152658\n",
      "Epoch 30::Minibatch 317::LR 0.0330769230769 --> Loss 0.00156252831221\n",
      "Epoch 30::Minibatch 318::LR 0.0330769230769 --> Loss 0.00130035827557\n",
      "Epoch 30::Minibatch 319::LR 0.0330769230769 --> Loss 0.00230850040913\n",
      "Epoch 30::Minibatch 320::LR 0.0330769230769 --> Loss 0.00305457830429\n",
      "Epoch 30::Minibatch 321::LR 0.0330769230769 --> Loss 0.000842315157255\n",
      "Epoch 30::Minibatch 322::LR 0.0330769230769 --> Loss 0.00348141392072\n",
      "Epoch 30::Minibatch 323::LR 0.0330769230769 --> Loss 0.00343007246653\n",
      "Epoch 30::Minibatch 324::LR 0.0330769230769 --> Loss 0.0026474404335\n",
      "Epoch 30::Minibatch 325::LR 0.0330769230769 --> Loss 0.00237428486347\n",
      "Epoch 30::Minibatch 326::LR 0.0330769230769 --> Loss 0.00532108346621\n",
      "Epoch 30::Minibatch 327::LR 0.0330769230769 --> Loss 0.00223448614279\n",
      "Epoch 30::Minibatch 328::LR 0.0330769230769 --> Loss 0.00298515299956\n",
      "Epoch 30::Minibatch 329::LR 0.0330769230769 --> Loss 0.00119644691547\n",
      "Epoch 30::Minibatch 330::LR 0.0330769230769 --> Loss 0.00158917446931\n",
      "Epoch 30::Minibatch 331::LR 0.0330769230769 --> Loss 0.0025341997544\n",
      "Epoch 30::Minibatch 332::LR 0.0330769230769 --> Loss 0.0024596653382\n",
      "Epoch 30::Minibatch 333::LR 0.0330769230769 --> Loss 0.00146632154783\n",
      "Epoch 30::Minibatch 334::LR 0.0330769230769 --> Loss 0.00441500544548\n",
      "Epoch 30::Minibatch 335::LR 0.0330769230769 --> Loss 0.00189777414004\n",
      "Epoch 30::Minibatch 336::LR 0.0330769230769 --> Loss 0.00225100417932\n",
      "Epoch 30::Minibatch 337::LR 0.0330769230769 --> Loss 0.00370080033938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 338::LR 0.0330769230769 --> Loss 0.00055029074351\n",
      "Epoch 30::Minibatch 339::LR 0.0330769230769 --> Loss 0.00326039552689\n",
      "Epoch 30::Minibatch 340::LR 0.0330769230769 --> Loss 0.00371909777323\n",
      "Epoch 30::Minibatch 341::LR 0.0330769230769 --> Loss 0.00436321695646\n",
      "Epoch 30::Minibatch 342::LR 0.0330769230769 --> Loss 0.0030635646979\n",
      "Epoch 30::Minibatch 343::LR 0.0330769230769 --> Loss 0.00164111117522\n",
      "Epoch 30::Minibatch 344::LR 0.0330769230769 --> Loss 0.0031607401371\n",
      "Epoch 30::Minibatch 345::LR 0.0330769230769 --> Loss 0.00410617470741\n",
      "Epoch 30::Minibatch 346::LR 0.0330769230769 --> Loss 0.0054124045372\n",
      "Epoch 30::Minibatch 347::LR 0.0330769230769 --> Loss 0.000821556150913\n",
      "Epoch 30::Minibatch 348::LR 0.0330769230769 --> Loss 0.00304479738077\n",
      "Epoch 30::Minibatch 349::LR 0.0330769230769 --> Loss 0.0033897793293\n",
      "Epoch 30::Minibatch 350::LR 0.0330769230769 --> Loss 0.00166069865227\n",
      "Epoch 30::Minibatch 351::LR 0.0330769230769 --> Loss 0.00344269156456\n",
      "Epoch 30::Minibatch 352::LR 0.0330769230769 --> Loss 0.0049138379097\n",
      "Epoch 30::Minibatch 353::LR 0.0330769230769 --> Loss 0.00351221760114\n",
      "Epoch 30::Minibatch 354::LR 0.0330769230769 --> Loss 0.00294037183126\n",
      "Epoch 30::Minibatch 355::LR 0.0330769230769 --> Loss 0.00623086770376\n",
      "Epoch 30::Minibatch 356::LR 0.0330769230769 --> Loss 0.00314694821835\n",
      "Epoch 30::Minibatch 357::LR 0.0330769230769 --> Loss 0.00116406003634\n",
      "Epoch 30::Minibatch 358::LR 0.0330769230769 --> Loss 0.00197115977605\n",
      "Epoch 30::Minibatch 359::LR 0.0330769230769 --> Loss 0.00267913540204\n",
      "Epoch 30::Minibatch 360::LR 0.0330769230769 --> Loss 0.00231225053469\n",
      "Epoch 30::Minibatch 361::LR 0.0330769230769 --> Loss 0.0022832685709\n",
      "Epoch 30::Minibatch 362::LR 0.0330769230769 --> Loss 0.00226918657621\n",
      "Epoch 30::Minibatch 363::LR 0.0330769230769 --> Loss 0.000637968083223\n",
      "Epoch 30::Minibatch 364::LR 0.0330769230769 --> Loss 0.00197386026382\n",
      "Epoch 30::Minibatch 365::LR 0.0330769230769 --> Loss 0.00201432724794\n",
      "Epoch 30::Minibatch 366::LR 0.0330769230769 --> Loss 0.0021363979578\n",
      "Epoch 30::Minibatch 367::LR 0.0330769230769 --> Loss 0.00100535313288\n",
      "Epoch 30::Minibatch 368::LR 0.0330769230769 --> Loss 0.000973372260729\n",
      "Epoch 30::Minibatch 369::LR 0.0330769230769 --> Loss 0.00277914543947\n",
      "Epoch 30::Minibatch 370::LR 0.0330769230769 --> Loss 0.00221719563007\n",
      "Epoch 30::Minibatch 371::LR 0.0330769230769 --> Loss 0.00185241202513\n",
      "Epoch 30::Minibatch 372::LR 0.0330769230769 --> Loss 0.000428811758757\n",
      "Epoch 30::Minibatch 373::LR 0.0330769230769 --> Loss 0.00180120746295\n",
      "Epoch 30::Minibatch 374::LR 0.0330769230769 --> Loss 0.00224635044734\n",
      "Epoch 30::Minibatch 375::LR 0.0330769230769 --> Loss 0.00188219825427\n",
      "Epoch 30::Minibatch 376::LR 0.0330769230769 --> Loss 0.00121341069539\n",
      "Epoch 30::Minibatch 377::LR 0.0330769230769 --> Loss 0.00191337505976\n",
      "Epoch 30::Minibatch 378::LR 0.0330769230769 --> Loss 0.00209758957227\n",
      "Epoch 30::Minibatch 379::LR 0.0330769230769 --> Loss 0.00232799768448\n",
      "Epoch 30::Minibatch 380::LR 0.0330769230769 --> Loss 0.00156693359216\n",
      "Epoch 30::Minibatch 381::LR 0.0330769230769 --> Loss 0.000991123318672\n",
      "Epoch 30::Minibatch 382::LR 0.0330769230769 --> Loss 0.00203097542127\n",
      "Epoch 30::Minibatch 383::LR 0.0330769230769 --> Loss 0.00198448757331\n",
      "Epoch 30::Minibatch 384::LR 0.0330769230769 --> Loss 0.00110870103041\n",
      "Epoch 30::Minibatch 385::LR 0.0330769230769 --> Loss 0.00105262170235\n",
      "Epoch 30::Minibatch 386::LR 0.0330769230769 --> Loss 0.00223349372546\n",
      "Epoch 30::Minibatch 387::LR 0.0330769230769 --> Loss 0.00236023664474\n",
      "Epoch 30::Minibatch 388::LR 0.0330769230769 --> Loss 0.00120435297489\n",
      "Epoch 30::Minibatch 389::LR 0.0330769230769 --> Loss 0.00178378760815\n",
      "Epoch 30::Minibatch 390::LR 0.0330769230769 --> Loss 0.00330078164736\n",
      "Epoch 30::Minibatch 391::LR 0.0330769230769 --> Loss 0.0025666598479\n",
      "Epoch 30::Minibatch 392::LR 0.0330769230769 --> Loss 0.00256416042646\n",
      "Epoch 30::Minibatch 393::LR 0.0330769230769 --> Loss 0.00273312409719\n",
      "Epoch 30::Minibatch 394::LR 0.0330769230769 --> Loss 0.00201206922531\n",
      "Epoch 30::Minibatch 395::LR 0.0330769230769 --> Loss 0.00206700662772\n",
      "Epoch 30::Minibatch 396::LR 0.0330769230769 --> Loss 0.0019353979826\n",
      "Epoch 30::Minibatch 397::LR 0.0330769230769 --> Loss 0.00207114577293\n",
      "Epoch 30::Minibatch 398::LR 0.0330769230769 --> Loss 0.00205958485603\n",
      "Epoch 30::Minibatch 399::LR 0.0330769230769 --> Loss 0.00236739575863\n",
      "Epoch 30::Minibatch 400::LR 0.0330769230769 --> Loss 0.00200477639834\n",
      "Epoch 30::Minibatch 401::LR 0.0330769230769 --> Loss 0.00341396888097\n",
      "Epoch 30::Minibatch 402::LR 0.0330769230769 --> Loss 0.00172417898973\n",
      "Epoch 30::Minibatch 403::LR 0.0330769230769 --> Loss 0.00142642229795\n",
      "Epoch 30::Minibatch 404::LR 0.0330769230769 --> Loss 0.00134810060263\n",
      "Epoch 30::Minibatch 405::LR 0.0330769230769 --> Loss 0.00334389805794\n",
      "Epoch 30::Minibatch 406::LR 0.0330769230769 --> Loss 0.00234970490138\n",
      "Epoch 30::Minibatch 407::LR 0.0330769230769 --> Loss 0.00170370062192\n",
      "Epoch 30::Minibatch 408::LR 0.0330769230769 --> Loss 0.000430509249369\n",
      "Epoch 30::Minibatch 409::LR 0.0330769230769 --> Loss 0.00221337457498\n",
      "Epoch 30::Minibatch 410::LR 0.0330769230769 --> Loss 0.00313372075558\n",
      "Epoch 30::Minibatch 411::LR 0.0330769230769 --> Loss 0.00165262977282\n",
      "Epoch 30::Minibatch 412::LR 0.0330769230769 --> Loss 0.00094071974357\n",
      "Epoch 30::Minibatch 413::LR 0.0330769230769 --> Loss 0.00196526924769\n",
      "Epoch 30::Minibatch 414::LR 0.0330769230769 --> Loss 0.00186336914698\n",
      "Epoch 30::Minibatch 415::LR 0.0330769230769 --> Loss 0.00116326500972\n",
      "Epoch 30::Minibatch 416::LR 0.0330769230769 --> Loss 0.00078928788503\n",
      "Epoch 30::Minibatch 417::LR 0.0330769230769 --> Loss 0.0016736181577\n",
      "Epoch 30::Minibatch 418::LR 0.0330769230769 --> Loss 0.00259500046571\n",
      "Epoch 30::Minibatch 419::LR 0.0330769230769 --> Loss 0.000487426618735\n",
      "Epoch 30::Minibatch 420::LR 0.0330769230769 --> Loss 0.000684457023938\n",
      "Epoch 30::Minibatch 421::LR 0.0330769230769 --> Loss 0.00187025864919\n",
      "Epoch 30::Minibatch 422::LR 0.0330769230769 --> Loss 0.00206106921037\n",
      "Epoch 30::Minibatch 423::LR 0.0330769230769 --> Loss 0.00097540418307\n",
      "Epoch 30::Minibatch 424::LR 0.0330769230769 --> Loss 0.00151407291492\n",
      "Epoch 30::Minibatch 425::LR 0.0330769230769 --> Loss 0.00286510705948\n",
      "Epoch 30::Minibatch 426::LR 0.0330769230769 --> Loss 0.0019834446907\n",
      "Epoch 30::Minibatch 427::LR 0.0330769230769 --> Loss 0.000725996295611\n",
      "Epoch 30::Minibatch 428::LR 0.0330769230769 --> Loss 0.000944067537785\n",
      "Epoch 30::Minibatch 429::LR 0.0330769230769 --> Loss 0.00224865118663\n",
      "Epoch 30::Minibatch 430::LR 0.0330769230769 --> Loss 0.00812729358673\n",
      "Epoch 30::Minibatch 431::LR 0.0330769230769 --> Loss 0.00361307660739\n",
      "Epoch 30::Minibatch 432::LR 0.0330769230769 --> Loss 0.00406799872716\n",
      "Epoch 30::Minibatch 433::LR 0.0330769230769 --> Loss 0.00253118197123\n",
      "Epoch 30::Minibatch 434::LR 0.0330769230769 --> Loss 0.00244992931684\n",
      "Epoch 30::Minibatch 435::LR 0.0330769230769 --> Loss 0.00225236992041\n",
      "Epoch 30::Minibatch 436::LR 0.0330769230769 --> Loss 0.00160114328067\n",
      "Epoch 30::Minibatch 437::LR 0.0330769230769 --> Loss 0.00285237232844\n",
      "Epoch 30::Minibatch 438::LR 0.0330769230769 --> Loss 0.00229308525721\n",
      "Epoch 30::Minibatch 439::LR 0.0330769230769 --> Loss 0.00192988316218\n",
      "Epoch 30::Minibatch 440::LR 0.0330769230769 --> Loss 0.00298508425554\n",
      "Epoch 30::Minibatch 441::LR 0.0330769230769 --> Loss 0.00278879443804\n",
      "Epoch 30::Minibatch 442::LR 0.0330769230769 --> Loss 0.00250108778477\n",
      "Epoch 30::Minibatch 443::LR 0.0330769230769 --> Loss 0.00346868634224\n",
      "Epoch 30::Minibatch 444::LR 0.0330769230769 --> Loss 0.00268124262492\n",
      "Epoch 30::Minibatch 445::LR 0.0330769230769 --> Loss 0.00084933578968\n",
      "Epoch 30::Minibatch 446::LR 0.0330769230769 --> Loss 0.00136713624001\n",
      "Epoch 30::Minibatch 447::LR 0.0330769230769 --> Loss 0.00229592720668\n",
      "Epoch 30::Minibatch 448::LR 0.0330769230769 --> Loss 0.00231115937233\n",
      "Epoch 30::Minibatch 449::LR 0.0330769230769 --> Loss 0.00357357899348\n",
      "Epoch 30::Minibatch 450::LR 0.0330769230769 --> Loss 0.00213712513447\n",
      "Epoch 30::Minibatch 451::LR 0.0330769230769 --> Loss 0.00383813222249\n",
      "Epoch 30::Minibatch 452::LR 0.0330769230769 --> Loss 0.00229491174221\n",
      "Epoch 30::Minibatch 453::LR 0.0330769230769 --> Loss 0.00035004136463\n",
      "Epoch 30::Minibatch 454::LR 0.0330769230769 --> Loss 0.00344285130501\n",
      "Epoch 30::Minibatch 455::LR 0.0330769230769 --> Loss 0.00258983850479\n",
      "Epoch 30::Minibatch 456::LR 0.0330769230769 --> Loss 0.00304464280605\n",
      "Epoch 30::Minibatch 457::LR 0.0330769230769 --> Loss 0.00187503218651\n",
      "Epoch 30::Minibatch 458::LR 0.0330769230769 --> Loss 0.000715580334266\n",
      "Epoch 30::Minibatch 459::LR 0.0330769230769 --> Loss 0.00385716080666\n",
      "Epoch 30::Minibatch 460::LR 0.0330769230769 --> Loss 0.00243372360865\n",
      "Epoch 30::Minibatch 461::LR 0.0330769230769 --> Loss 0.003696915706\n",
      "Epoch 30::Minibatch 462::LR 0.0330769230769 --> Loss 0.000370241378744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 463::LR 0.0330769230769 --> Loss 0.00414995908737\n",
      "Epoch 30::Minibatch 464::LR 0.0330769230769 --> Loss 0.00194892863433\n",
      "Epoch 30::Minibatch 465::LR 0.0330769230769 --> Loss 0.00457865357399\n",
      "Epoch 30::Minibatch 466::LR 0.0330769230769 --> Loss 0.00496630509694\n",
      "Epoch 30::Minibatch 467::LR 0.0330769230769 --> Loss 0.00511487205823\n",
      "Epoch 30::Minibatch 468::LR 0.0330769230769 --> Loss 0.00568118413289\n",
      "Epoch 30::Minibatch 469::LR 0.0330769230769 --> Loss 0.00602158824603\n",
      "Epoch 30::Minibatch 470::LR 0.0330769230769 --> Loss 0.00358082016309\n",
      "Epoch 30::Minibatch 471::LR 0.0330769230769 --> Loss 0.00166583369176\n",
      "Epoch 30::Minibatch 472::LR 0.0330769230769 --> Loss 0.00355627497037\n",
      "Epoch 30::Minibatch 473::LR 0.0330769230769 --> Loss 0.00230243047078\n",
      "Epoch 30::Minibatch 474::LR 0.0330769230769 --> Loss 0.000690075407426\n",
      "Epoch 30::Minibatch 475::LR 0.0330769230769 --> Loss 0.0048052974542\n",
      "Epoch 30::Minibatch 476::LR 0.0330769230769 --> Loss 0.0076387945811\n",
      "Epoch 30::Minibatch 477::LR 0.0330769230769 --> Loss 0.000916450917721\n",
      "Epoch 30::Minibatch 478::LR 0.0330769230769 --> Loss 0.00241208990415\n",
      "Epoch 30::Minibatch 479::LR 0.0330769230769 --> Loss 0.00196098764737\n",
      "Epoch 30::Minibatch 480::LR 0.0330769230769 --> Loss 0.00151507824659\n",
      "Epoch 30::Minibatch 481::LR 0.0330769230769 --> Loss 0.000957476894061\n",
      "Epoch 30::Minibatch 482::LR 0.0330769230769 --> Loss 0.00206889232\n",
      "Epoch 30::Minibatch 483::LR 0.0330769230769 --> Loss 0.00303032795588\n",
      "Epoch 30::Minibatch 484::LR 0.0330769230769 --> Loss 0.003403292497\n",
      "Epoch 30::Minibatch 485::LR 0.0330769230769 --> Loss 0.000761451174815\n",
      "Epoch 30::Minibatch 486::LR 0.0330769230769 --> Loss 0.00281370838483\n",
      "Epoch 30::Minibatch 487::LR 0.0330769230769 --> Loss 0.00329777677854\n",
      "Epoch 30::Minibatch 488::LR 0.0330769230769 --> Loss 0.00202125271161\n",
      "Epoch 30::Minibatch 489::LR 0.0330769230769 --> Loss 0.00307964106401\n",
      "Epoch 30::Minibatch 490::LR 0.0330769230769 --> Loss 0.000411341637373\n",
      "Epoch 30::Minibatch 491::LR 0.0330769230769 --> Loss 0.00324295004209\n",
      "Epoch 30::Minibatch 492::LR 0.0330769230769 --> Loss 0.00306336859862\n",
      "Epoch 30::Minibatch 493::LR 0.0330769230769 --> Loss 0.00302106002967\n",
      "Epoch 30::Minibatch 494::LR 0.0330769230769 --> Loss 0.000733079661926\n",
      "Epoch 30::Minibatch 495::LR 0.0330769230769 --> Loss 0.00183099448681\n",
      "Epoch 30::Minibatch 496::LR 0.0330769230769 --> Loss 0.00278610885143\n",
      "Epoch 30::Minibatch 497::LR 0.0330769230769 --> Loss 0.000915537575881\n",
      "Epoch 30::Minibatch 498::LR 0.0330769230769 --> Loss 0.000550528665384\n",
      "Epoch 30::Minibatch 499::LR 0.0330769230769 --> Loss 0.00341788490613\n",
      "Epoch 30::Minibatch 500::LR 0.0330769230769 --> Loss 0.00142650494973\n",
      "Epoch 30::Minibatch 501::LR 0.0330769230769 --> Loss 0.00205027282238\n",
      "Epoch 30::Minibatch 502::LR 0.0330769230769 --> Loss 0.00374238053958\n",
      "Epoch 30::Minibatch 503::LR 0.0330769230769 --> Loss 0.00686797618866\n",
      "Epoch 30::Minibatch 504::LR 0.0330769230769 --> Loss 0.00677972316742\n",
      "Epoch 30::Minibatch 505::LR 0.0330769230769 --> Loss 0.00397558291753\n",
      "Epoch 30::Minibatch 506::LR 0.0330769230769 --> Loss 0.00331977427006\n",
      "Epoch 30::Minibatch 507::LR 0.0330769230769 --> Loss 0.00577357172966\n",
      "Epoch 30::Minibatch 508::LR 0.0330769230769 --> Loss 0.00338845809301\n",
      "Epoch 30::Minibatch 509::LR 0.0330769230769 --> Loss 0.00426448305448\n",
      "Epoch 30::Minibatch 510::LR 0.0330769230769 --> Loss 0.00439683755239\n",
      "Epoch 30::Minibatch 511::LR 0.0330769230769 --> Loss 0.0039855714639\n",
      "Epoch 30::Minibatch 512::LR 0.0330769230769 --> Loss 0.0026805583636\n",
      "Epoch 30::Minibatch 513::LR 0.0330769230769 --> Loss 0.000600044329961\n",
      "Epoch 30::Minibatch 514::LR 0.0330769230769 --> Loss 0.00263722936312\n",
      "Epoch 30::Minibatch 515::LR 0.0330769230769 --> Loss 0.00299211978912\n",
      "Epoch 30::Minibatch 516::LR 0.0330769230769 --> Loss 0.00392137130102\n",
      "Epoch 30::Minibatch 517::LR 0.0330769230769 --> Loss 0.00360821048419\n",
      "Epoch 30::Minibatch 518::LR 0.0330769230769 --> Loss 0.00257619241873\n",
      "Epoch 30::Minibatch 519::LR 0.0330769230769 --> Loss 0.00353201945623\n",
      "Epoch 30::Minibatch 520::LR 0.0330769230769 --> Loss 0.00553760608037\n",
      "Epoch 30::Minibatch 521::LR 0.0330769230769 --> Loss 0.00560243964195\n",
      "Epoch 30::Minibatch 522::LR 0.0330769230769 --> Loss 0.00722699006399\n",
      "Epoch 30::Minibatch 523::LR 0.0330769230769 --> Loss 0.000624279727538\n",
      "Epoch 30::Minibatch 524::LR 0.0330769230769 --> Loss 0.00139404396216\n",
      "Epoch 30::Minibatch 525::LR 0.0330769230769 --> Loss 0.00307067493598\n",
      "Epoch 30::Minibatch 526::LR 0.0330769230769 --> Loss 0.00373380382856\n",
      "Epoch 30::Minibatch 527::LR 0.0330769230769 --> Loss 0.00213478942712\n",
      "Epoch 30::Minibatch 528::LR 0.0330769230769 --> Loss 0.000934675931931\n",
      "Epoch 30::Minibatch 529::LR 0.0330769230769 --> Loss 0.00383792042732\n",
      "Epoch 30::Minibatch 530::LR 0.0330769230769 --> Loss 0.00381433963776\n",
      "Epoch 30::Minibatch 531::LR 0.0330769230769 --> Loss 0.00338506658872\n",
      "Epoch 30::Minibatch 532::LR 0.0330769230769 --> Loss 0.00260420064131\n",
      "Epoch 30::Minibatch 533::LR 0.0330769230769 --> Loss 0.00488542278608\n",
      "Epoch 30::Minibatch 534::LR 0.0330769230769 --> Loss 0.00368825395902\n",
      "Epoch 30::Minibatch 535::LR 0.0330769230769 --> Loss 0.00330099523067\n",
      "Epoch 30::Minibatch 536::LR 0.0330769230769 --> Loss 0.00210452497005\n",
      "Epoch 30::Minibatch 537::LR 0.0330769230769 --> Loss 0.000586137721936\n",
      "Epoch 30::Minibatch 538::LR 0.0330769230769 --> Loss 0.00163733889659\n",
      "Epoch 30::Minibatch 539::LR 0.0330769230769 --> Loss 0.00332338313262\n",
      "Epoch 30::Minibatch 540::LR 0.0330769230769 --> Loss 0.00339150587718\n",
      "Epoch 30::Minibatch 541::LR 0.0330769230769 --> Loss 0.00284546017647\n",
      "Epoch 30::Minibatch 542::LR 0.0330769230769 --> Loss 0.0024370743831\n",
      "Epoch 30::Minibatch 543::LR 0.0330769230769 --> Loss 0.00258542577426\n",
      "Epoch 30::Minibatch 544::LR 0.0330769230769 --> Loss 0.00400529464086\n",
      "Epoch 30::Minibatch 545::LR 0.0330769230769 --> Loss 0.00198167483012\n",
      "Epoch 30::Minibatch 546::LR 0.0330769230769 --> Loss 0.000658756544193\n",
      "Epoch 30::Minibatch 547::LR 0.0330769230769 --> Loss 0.0025815842549\n",
      "Epoch 30::Minibatch 548::LR 0.0330769230769 --> Loss 0.00342124183973\n",
      "Epoch 30::Minibatch 549::LR 0.0330769230769 --> Loss 0.00882001479467\n",
      "Epoch 30::Minibatch 550::LR 0.0330769230769 --> Loss 0.0011832733949\n",
      "Epoch 30::Minibatch 551::LR 0.0330769230769 --> Loss 0.00245669921239\n",
      "Epoch 30::Minibatch 552::LR 0.0330769230769 --> Loss 0.00343787789345\n",
      "Epoch 30::Minibatch 553::LR 0.0330769230769 --> Loss 0.00298191487789\n",
      "Epoch 30::Minibatch 554::LR 0.0330769230769 --> Loss 0.00363850394885\n",
      "Epoch 30::Minibatch 555::LR 0.0330769230769 --> Loss 0.00094389239947\n",
      "Epoch 30::Minibatch 556::LR 0.0330769230769 --> Loss 0.00192393362522\n",
      "Epoch 30::Minibatch 557::LR 0.0330769230769 --> Loss 0.00240261435509\n",
      "Epoch 30::Minibatch 558::LR 0.0330769230769 --> Loss 0.00359564701716\n",
      "Epoch 30::Minibatch 559::LR 0.0330769230769 --> Loss 0.003655889829\n",
      "Epoch 30::Minibatch 560::LR 0.0330769230769 --> Loss 0.0030549732844\n",
      "Epoch 30::Minibatch 561::LR 0.0330769230769 --> Loss 0.00262503445148\n",
      "Epoch 30::Minibatch 562::LR 0.0330769230769 --> Loss 0.00234005947908\n",
      "Epoch 30::Minibatch 563::LR 0.0330769230769 --> Loss 0.00396875421206\n",
      "Epoch 30::Minibatch 564::LR 0.0330769230769 --> Loss 0.00304511845112\n",
      "Epoch 30::Minibatch 565::LR 0.0330769230769 --> Loss 0.00358266472816\n",
      "Epoch 30::Minibatch 566::LR 0.0330769230769 --> Loss 0.00218258619308\n",
      "Epoch 30::Minibatch 567::LR 0.0330769230769 --> Loss 0.00253602584203\n",
      "Epoch 30::Minibatch 568::LR 0.0330769230769 --> Loss 0.00174249390761\n",
      "Epoch 30::Minibatch 569::LR 0.0330769230769 --> Loss 0.000560681720575\n",
      "Epoch 30::Minibatch 570::LR 0.0330769230769 --> Loss 0.00162674476703\n",
      "Epoch 30::Minibatch 571::LR 0.0330769230769 --> Loss 0.00206785261631\n",
      "Epoch 30::Minibatch 572::LR 0.0330769230769 --> Loss 0.00222419003646\n",
      "Epoch 30::Minibatch 573::LR 0.0330769230769 --> Loss 0.0014426886042\n",
      "Epoch 30::Minibatch 574::LR 0.0330769230769 --> Loss 0.00104386965434\n",
      "Epoch 30::Minibatch 575::LR 0.0330769230769 --> Loss 0.00172015289466\n",
      "Epoch 30::Minibatch 576::LR 0.0330769230769 --> Loss 0.0020330174764\n",
      "Epoch 30::Minibatch 577::LR 0.0330769230769 --> Loss 0.00160979459683\n",
      "Epoch 30::Minibatch 578::LR 0.0330769230769 --> Loss 0.00126428365707\n",
      "Epoch 30::Minibatch 579::LR 0.0330769230769 --> Loss 0.00118229399125\n",
      "Epoch 30::Minibatch 580::LR 0.0330769230769 --> Loss 0.00191964844863\n",
      "Epoch 30::Minibatch 581::LR 0.0330769230769 --> Loss 0.00170485834281\n",
      "Epoch 30::Minibatch 582::LR 0.0330769230769 --> Loss 0.00418038050334\n",
      "Epoch 30::Minibatch 583::LR 0.0330769230769 --> Loss 0.00095139314731\n",
      "Epoch 30::Minibatch 584::LR 0.0330769230769 --> Loss 0.00130844970544\n",
      "Epoch 30::Minibatch 585::LR 0.0330769230769 --> Loss 0.00395437200864\n",
      "Epoch 30::Minibatch 586::LR 0.0330769230769 --> Loss 0.00375096360842\n",
      "Epoch 30::Minibatch 587::LR 0.0330769230769 --> Loss 0.00111368139585\n",
      "Epoch 30::Minibatch 588::LR 0.0330769230769 --> Loss 0.00137278079987\n",
      "Epoch 30::Minibatch 589::LR 0.0330769230769 --> Loss 0.00273845394452\n",
      "Epoch 30::Minibatch 590::LR 0.0330769230769 --> Loss 0.00180841406186\n",
      "Epoch 30::Minibatch 591::LR 0.0330769230769 --> Loss 0.00272375643253\n",
      "Epoch 30::Minibatch 592::LR 0.0330769230769 --> Loss 0.00115122079849\n",
      "Epoch 30::Minibatch 593::LR 0.0330769230769 --> Loss 0.00247151911259\n",
      "Epoch 30::Minibatch 594::LR 0.0330769230769 --> Loss 0.00257241070271\n",
      "Epoch 30::Minibatch 595::LR 0.0330769230769 --> Loss 0.00303974866867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 596::LR 0.0330769230769 --> Loss 0.00184616565704\n",
      "Epoch 30::Minibatch 597::LR 0.0330769230769 --> Loss 0.00116799424092\n",
      "Epoch 30::Minibatch 598::LR 0.0330769230769 --> Loss 0.00281551361084\n",
      "Epoch 30::Minibatch 599::LR 0.0330769230769 --> Loss 0.00179328302542\n",
      "Epoch 30::Minibatch 600::LR 0.0330769230769 --> Loss 0.00212949236234\n",
      "Epoch 30::Minibatch 601::LR 0.0330769230769 --> Loss 0.00373867909114\n",
      "Epoch 30::Minibatch 602::LR 0.0330769230769 --> Loss 0.00208432177703\n",
      "Epoch 30::Minibatch 603::LR 0.0330769230769 --> Loss 0.00261651833852\n",
      "Epoch 30::Minibatch 604::LR 0.0330769230769 --> Loss 0.00162887503703\n",
      "Epoch 30::Minibatch 605::LR 0.0330769230769 --> Loss 0.00228378196557\n",
      "Epoch 30::Minibatch 606::LR 0.0330769230769 --> Loss 0.00185683786869\n",
      "Epoch 30::Minibatch 607::LR 0.0330769230769 --> Loss 0.00082592929403\n",
      "Epoch 30::Minibatch 608::LR 0.0330769230769 --> Loss 0.0015529208382\n",
      "Epoch 30::Minibatch 609::LR 0.0330769230769 --> Loss 0.00241678814093\n",
      "Epoch 30::Minibatch 610::LR 0.0330769230769 --> Loss 0.00403387784958\n",
      "Epoch 30::Minibatch 611::LR 0.0330769230769 --> Loss 0.00265749375025\n",
      "Epoch 30::Minibatch 612::LR 0.0330769230769 --> Loss 0.000470860103766\n",
      "Epoch 30::Minibatch 613::LR 0.0330769230769 --> Loss 0.00131024340789\n",
      "Epoch 30::Minibatch 614::LR 0.0330769230769 --> Loss 0.00240527451038\n",
      "Epoch 30::Minibatch 615::LR 0.0330769230769 --> Loss 0.00165375957886\n",
      "Epoch 30::Minibatch 616::LR 0.0330769230769 --> Loss 0.00091612358888\n",
      "Epoch 30::Minibatch 617::LR 0.0330769230769 --> Loss 0.000491812030474\n",
      "Epoch 30::Minibatch 618::LR 0.0330769230769 --> Loss 0.00286511421204\n",
      "Epoch 30::Minibatch 619::LR 0.0330769230769 --> Loss 0.00192698995272\n",
      "Epoch 30::Minibatch 620::LR 0.0330769230769 --> Loss 0.00169085363547\n",
      "Epoch 30::Minibatch 621::LR 0.0330769230769 --> Loss 0.000845659077168\n",
      "Epoch 30::Minibatch 622::LR 0.0330769230769 --> Loss 0.000780890633663\n",
      "Epoch 30::Minibatch 623::LR 0.0330769230769 --> Loss 0.00221682012081\n",
      "Epoch 30::Minibatch 624::LR 0.0330769230769 --> Loss 0.00177120566368\n",
      "Epoch 30::Minibatch 625::LR 0.0330769230769 --> Loss 0.00267982860406\n",
      "Epoch 30::Minibatch 626::LR 0.0330769230769 --> Loss 0.0036651468277\n",
      "Epoch 30::Minibatch 627::LR 0.0330769230769 --> Loss 0.00127151052157\n",
      "Epoch 30::Minibatch 628::LR 0.0330769230769 --> Loss 0.000877925356229\n",
      "Epoch 30::Minibatch 629::LR 0.0330769230769 --> Loss 0.00309989651044\n",
      "Epoch 30::Minibatch 630::LR 0.0330769230769 --> Loss 0.0030326239268\n",
      "Epoch 30::Minibatch 631::LR 0.0330769230769 --> Loss 0.00525368928909\n",
      "Epoch 30::Minibatch 632::LR 0.0330769230769 --> Loss 0.000792522082726\n",
      "Epoch 30::Minibatch 633::LR 0.0330769230769 --> Loss 0.00161919295788\n",
      "Epoch 30::Minibatch 634::LR 0.0330769230769 --> Loss 0.00318740129471\n",
      "Epoch 30::Minibatch 635::LR 0.0330769230769 --> Loss 0.00544344584147\n",
      "Epoch 30::Minibatch 636::LR 0.0330769230769 --> Loss 0.00460943261782\n",
      "Epoch 30::Minibatch 637::LR 0.0330769230769 --> Loss 0.000717024455468\n",
      "Epoch 30::Minibatch 638::LR 0.0330769230769 --> Loss 0.0014836537838\n",
      "Epoch 30::Minibatch 639::LR 0.0330769230769 --> Loss 0.00318878312906\n",
      "Epoch 30::Minibatch 640::LR 0.0330769230769 --> Loss 0.00459455768267\n",
      "Epoch 30::Minibatch 641::LR 0.0330769230769 --> Loss 0.00304371078809\n",
      "Epoch 30::Minibatch 642::LR 0.0330769230769 --> Loss 0.000532314827045\n",
      "Epoch 30::Minibatch 643::LR 0.0330769230769 --> Loss 0.00231057127317\n",
      "Epoch 30::Minibatch 644::LR 0.0330769230769 --> Loss 0.00387009700139\n",
      "Epoch 30::Minibatch 645::LR 0.0330769230769 --> Loss 0.00442441781362\n",
      "Epoch 30::Minibatch 646::LR 0.0330769230769 --> Loss 0.00150255719821\n",
      "Epoch 30::Minibatch 647::LR 0.0330769230769 --> Loss 0.000469065904617\n",
      "Epoch 30::Minibatch 648::LR 0.0330769230769 --> Loss 0.00277710258961\n",
      "Epoch 30::Minibatch 649::LR 0.0330769230769 --> Loss 0.00324069321156\n",
      "Epoch 30::Minibatch 650::LR 0.0330769230769 --> Loss 0.00317514836788\n",
      "Epoch 30::Minibatch 651::LR 0.0330769230769 --> Loss 0.00133201599121\n",
      "Epoch 30::Minibatch 652::LR 0.0330769230769 --> Loss 0.00077795167764\n",
      "Epoch 30::Minibatch 653::LR 0.0330769230769 --> Loss 0.0028046554327\n",
      "Epoch 30::Minibatch 654::LR 0.0330769230769 --> Loss 0.00312334756056\n",
      "Epoch 30::Minibatch 655::LR 0.0330769230769 --> Loss 0.00361484328906\n",
      "Epoch 30::Minibatch 656::LR 0.0330769230769 --> Loss 0.000754940162102\n",
      "Epoch 30::Minibatch 657::LR 0.0330769230769 --> Loss 0.00226598660151\n",
      "Epoch 30::Minibatch 658::LR 0.0330769230769 --> Loss 0.00453349669774\n",
      "Epoch 30::Minibatch 659::LR 0.0330769230769 --> Loss 0.00222024063269\n",
      "Epoch 30::Minibatch 660::LR 0.0330769230769 --> Loss 0.00263619720936\n",
      "Epoch 30::Minibatch 661::LR 0.0330769230769 --> Loss 0.00228982051214\n",
      "Epoch 30::Minibatch 662::LR 0.0330769230769 --> Loss 0.00179483850797\n",
      "Epoch 30::Minibatch 663::LR 0.0330769230769 --> Loss 0.00367420593898\n",
      "Epoch 30::Minibatch 664::LR 0.0330769230769 --> Loss 0.00318053166072\n",
      "Epoch 30::Minibatch 665::LR 0.0330769230769 --> Loss 0.000697915256023\n",
      "Epoch 30::Minibatch 666::LR 0.0330769230769 --> Loss 0.00390456795692\n",
      "Epoch 30::Minibatch 667::LR 0.0330769230769 --> Loss 0.00254094660282\n",
      "Epoch 30::Minibatch 668::LR 0.0330769230769 --> Loss 0.00637937784195\n",
      "Epoch 30::Minibatch 669::LR 0.0330769230769 --> Loss 0.00108460813761\n",
      "Epoch 30::Minibatch 670::LR 0.0330769230769 --> Loss 0.00133040746053\n",
      "Epoch 30::Minibatch 671::LR 0.0330769230769 --> Loss 0.00510230382284\n",
      "Epoch 30::Minibatch 672::LR 0.0330769230769 --> Loss 0.00341724077861\n",
      "Epoch 30::Minibatch 673::LR 0.0330769230769 --> Loss 0.00160535524289\n",
      "Epoch 30::Minibatch 674::LR 0.0330769230769 --> Loss 0.000509625871976\n",
      "Epoch 30::Minibatch 675::LR 0.0330769230769 --> Loss 0.00219331125418\n",
      "Epoch 30::Minibatch 676::LR 0.0330769230769 --> Loss 0.00215135435263\n",
      "Epoch 30::Minibatch 677::LR 0.0330769230769 --> Loss 0.00271210551262\n",
      "Epoch 30::Minibatch 678::LR 0.0330769230769 --> Loss 0.00186987598737\n",
      "Epoch 30::Minibatch 679::LR 0.0330769230769 --> Loss 0.0033277930816\n",
      "Epoch 30::Minibatch 680::LR 0.0330769230769 --> Loss 0.0021236628294\n",
      "Epoch 30::Minibatch 681::LR 0.0330769230769 --> Loss 0.00238977392515\n",
      "Epoch 30::Minibatch 682::LR 0.0330769230769 --> Loss 0.000761578579744\n",
      "Epoch 30::Minibatch 683::LR 0.0330769230769 --> Loss 0.00231368243694\n",
      "Epoch 30::Minibatch 684::LR 0.0330769230769 --> Loss 0.00233890453974\n",
      "Epoch 30::Minibatch 685::LR 0.0330769230769 --> Loss 0.00282579799493\n",
      "Epoch 30::Minibatch 686::LR 0.0330769230769 --> Loss 0.00158170054356\n",
      "Epoch 30::Minibatch 687::LR 0.0330769230769 --> Loss 0.000874903202057\n",
      "Epoch 30::Minibatch 688::LR 0.0330769230769 --> Loss 0.00279612223307\n",
      "Epoch 30::Minibatch 689::LR 0.0330769230769 --> Loss 0.00247415781021\n",
      "Epoch 30::Minibatch 690::LR 0.0330769230769 --> Loss 0.0018824082613\n",
      "Epoch 30::Minibatch 691::LR 0.0330769230769 --> Loss 0.000657750715812\n",
      "Epoch 30::Minibatch 692::LR 0.0330769230769 --> Loss 0.00244379222393\n",
      "Epoch 30::Minibatch 693::LR 0.0330769230769 --> Loss 0.00260822296143\n",
      "Epoch 30::Minibatch 694::LR 0.0330769230769 --> Loss 0.00299568911393\n",
      "Epoch 30::Minibatch 695::LR 0.0330769230769 --> Loss 0.00178909142812\n",
      "Epoch 30::Minibatch 696::LR 0.0330769230769 --> Loss 0.00203307191531\n",
      "Epoch 30::Minibatch 697::LR 0.0330769230769 --> Loss 0.00139999767145\n",
      "Epoch 30::Minibatch 698::LR 0.0330769230769 --> Loss 0.0016596147418\n",
      "Epoch 30::Minibatch 699::LR 0.0330769230769 --> Loss 0.0037161942323\n",
      "Epoch 30::Minibatch 700::LR 0.0330769230769 --> Loss 0.00258657415708\n",
      "Epoch 30::Minibatch 701::LR 0.0330769230769 --> Loss 0.00189598401388\n",
      "Epoch 30::Minibatch 702::LR 0.0330769230769 --> Loss 0.0016657953461\n",
      "Epoch 30::Minibatch 703::LR 0.0330769230769 --> Loss 0.00431467692057\n",
      "Epoch 30::Minibatch 704::LR 0.0330769230769 --> Loss 0.0018031078577\n",
      "Epoch 30::Minibatch 705::LR 0.0330769230769 --> Loss 0.00284397006035\n",
      "Epoch 30::Minibatch 706::LR 0.0330769230769 --> Loss 0.00220881183942\n",
      "Epoch 30::Minibatch 707::LR 0.0330769230769 --> Loss 0.00117945224047\n",
      "Epoch 30::Minibatch 708::LR 0.0330769230769 --> Loss 0.0017306625843\n",
      "Epoch 30::Minibatch 709::LR 0.0330769230769 --> Loss 0.00167128702005\n",
      "Epoch 30::Minibatch 710::LR 0.0330769230769 --> Loss 0.00257896502813\n",
      "Epoch 30::Minibatch 711::LR 0.0330769230769 --> Loss 0.0019691212972\n",
      "Epoch 30::Minibatch 712::LR 0.0330769230769 --> Loss 0.0013569594423\n",
      "Epoch 30::Minibatch 713::LR 0.0330769230769 --> Loss 0.0017913210392\n",
      "Epoch 30::Minibatch 714::LR 0.0330769230769 --> Loss 0.00285135030746\n",
      "Epoch 30::Minibatch 715::LR 0.0330769230769 --> Loss 0.0029265832901\n",
      "Epoch 30::Minibatch 716::LR 0.0330769230769 --> Loss 0.00165770401557\n",
      "Epoch 30::Minibatch 717::LR 0.0330769230769 --> Loss 0.00166217605273\n",
      "Epoch 30::Minibatch 718::LR 0.0330769230769 --> Loss 0.00127617299557\n",
      "Epoch 30::Minibatch 719::LR 0.0330769230769 --> Loss 0.00171933551629\n",
      "Epoch 30::Minibatch 720::LR 0.0330769230769 --> Loss 0.00273630440235\n",
      "Epoch 30::Minibatch 721::LR 0.0330769230769 --> Loss 0.000605186919371\n",
      "Epoch 30::Minibatch 722::LR 0.0330769230769 --> Loss 0.00461523373922\n",
      "Epoch 30::Minibatch 723::LR 0.0330769230769 --> Loss 0.00483321785927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 724::LR 0.0330769230769 --> Loss 0.000964576601982\n",
      "Epoch 30::Minibatch 725::LR 0.0330769230769 --> Loss 0.00206797043482\n",
      "Epoch 30::Minibatch 726::LR 0.0330769230769 --> Loss 0.0037469236056\n",
      "Epoch 30::Minibatch 727::LR 0.0330769230769 --> Loss 0.00309116303921\n",
      "Epoch 30::Minibatch 728::LR 0.0330769230769 --> Loss 0.000641036182642\n",
      "Epoch 30::Minibatch 729::LR 0.0330769230769 --> Loss 0.000719636380672\n",
      "Epoch 30::Minibatch 730::LR 0.0330769230769 --> Loss 0.00291059931119\n",
      "Epoch 30::Minibatch 731::LR 0.0330769230769 --> Loss 0.00260747790337\n",
      "Epoch 30::Minibatch 732::LR 0.0330769230769 --> Loss 0.00205770949523\n",
      "Epoch 30::Minibatch 733::LR 0.0330769230769 --> Loss 0.000603189369043\n",
      "Epoch 30::Minibatch 734::LR 0.0330769230769 --> Loss 0.00164996355772\n",
      "Epoch 30::Minibatch 735::LR 0.0330769230769 --> Loss 0.00246063947678\n",
      "Epoch 30::Minibatch 736::LR 0.0330769230769 --> Loss 0.0034750576814\n",
      "Epoch 30::Minibatch 737::LR 0.0330769230769 --> Loss 0.00294268965721\n",
      "Epoch 30::Minibatch 738::LR 0.0330769230769 --> Loss 0.00141461362441\n",
      "Epoch 30::Minibatch 739::LR 0.0330769230769 --> Loss 0.0023922620217\n",
      "Epoch 30::Minibatch 740::LR 0.0330769230769 --> Loss 0.00377092639605\n",
      "Epoch 30::Minibatch 741::LR 0.0330769230769 --> Loss 0.0025397503376\n",
      "Epoch 30::Minibatch 742::LR 0.0330769230769 --> Loss 0.00208136618137\n",
      "Epoch 30::Minibatch 743::LR 0.0330769230769 --> Loss 0.00149704386791\n",
      "Epoch 30::Minibatch 744::LR 0.0330769230769 --> Loss 0.00186321417491\n",
      "Epoch 30::Minibatch 745::LR 0.0330769230769 --> Loss 0.00277586062749\n",
      "Epoch 30::Minibatch 746::LR 0.0330769230769 --> Loss 0.00285978595416\n",
      "Epoch 30::Minibatch 747::LR 0.0330769230769 --> Loss 0.00176195979118\n",
      "Epoch 30::Minibatch 748::LR 0.0330769230769 --> Loss 0.000620377113422\n",
      "Epoch 30::Minibatch 749::LR 0.0330769230769 --> Loss 0.00167097091675\n",
      "Epoch 30::Minibatch 750::LR 0.0330769230769 --> Loss 0.00242127478123\n",
      "Epoch 30::Minibatch 751::LR 0.0330769230769 --> Loss 0.00290065844854\n",
      "Epoch 30::Minibatch 752::LR 0.0330769230769 --> Loss 0.00140856782595\n",
      "Epoch 30::Minibatch 753::LR 0.0330769230769 --> Loss 0.00219287753105\n",
      "Epoch 30::Minibatch 754::LR 0.0330769230769 --> Loss 0.00241407891115\n",
      "Epoch 30::Minibatch 755::LR 0.0330769230769 --> Loss 0.00266127785047\n",
      "Epoch 30::Minibatch 756::LR 0.0330769230769 --> Loss 0.00131214420001\n",
      "Epoch 30::Minibatch 757::LR 0.0330769230769 --> Loss 0.00061464086175\n",
      "Epoch 30::Minibatch 758::LR 0.0330769230769 --> Loss 0.00156626025836\n",
      "Epoch 30::Minibatch 759::LR 0.0330769230769 --> Loss 0.00345307548841\n",
      "Epoch 30::Minibatch 760::LR 0.0330769230769 --> Loss 0.00281321307023\n",
      "Epoch 30::Minibatch 761::LR 0.0330769230769 --> Loss 0.00569968779882\n",
      "Epoch 30::Minibatch 762::LR 0.0330769230769 --> Loss 0.00358499129613\n",
      "Epoch 30::Minibatch 763::LR 0.0330769230769 --> Loss 0.0034500837326\n",
      "Epoch 30::Minibatch 764::LR 0.0330769230769 --> Loss 0.00304463704427\n",
      "Epoch 30::Minibatch 765::LR 0.0330769230769 --> Loss 0.00125469654799\n",
      "Epoch 30::Minibatch 766::LR 0.0330769230769 --> Loss 0.00229953328768\n",
      "Epoch 30::Minibatch 767::LR 0.0330769230769 --> Loss 0.0048087600867\n",
      "Epoch 30::Minibatch 768::LR 0.0330769230769 --> Loss 0.00364972432454\n",
      "Epoch 30::Minibatch 769::LR 0.0330769230769 --> Loss 0.00184019784133\n",
      "Epoch 30::Minibatch 770::LR 0.0330769230769 --> Loss 0.00150586922963\n",
      "Epoch 30::Minibatch 771::LR 0.0330769230769 --> Loss 0.00343665957451\n",
      "Epoch 30::Minibatch 772::LR 0.0330769230769 --> Loss 0.00359718243281\n",
      "Epoch 30::Minibatch 773::LR 0.0330769230769 --> Loss 0.0031814823548\n",
      "Epoch 30::Minibatch 774::LR 0.0330769230769 --> Loss 0.00187653640906\n",
      "Epoch 30::Minibatch 775::LR 0.0330769230769 --> Loss 0.0033371078968\n",
      "Epoch 30::Minibatch 776::LR 0.0330769230769 --> Loss 0.00375356237094\n",
      "Epoch 30::Minibatch 777::LR 0.0330769230769 --> Loss 0.00622033238411\n",
      "Epoch 30::Minibatch 778::LR 0.0330769230769 --> Loss 0.00747789621353\n",
      "Epoch 30::Minibatch 779::LR 0.0330769230769 --> Loss 0.00248237729073\n",
      "Epoch 30::Minibatch 780::LR 0.0330769230769 --> Loss 0.00151436060667\n",
      "Epoch 30::Minibatch 781::LR 0.0330769230769 --> Loss 0.0034769030412\n",
      "Epoch 30::Minibatch 782::LR 0.0330769230769 --> Loss 0.00380144357681\n",
      "Epoch 30::Minibatch 783::LR 0.0330769230769 --> Loss 0.00226720750332\n",
      "Epoch 30::Minibatch 784::LR 0.0330769230769 --> Loss 0.000707871417205\n",
      "Epoch 30::Minibatch 785::LR 0.0330769230769 --> Loss 0.00329736808936\n",
      "Epoch 30::Minibatch 786::LR 0.0330769230769 --> Loss 0.00348190029462\n",
      "Epoch 30::Minibatch 787::LR 0.0330769230769 --> Loss 0.00257372021675\n",
      "Epoch 30::Minibatch 788::LR 0.0330769230769 --> Loss 0.00237410604954\n",
      "Epoch 30::Minibatch 789::LR 0.0330769230769 --> Loss 0.000725531627735\n",
      "Epoch 30::Minibatch 790::LR 0.0330769230769 --> Loss 0.00313036719958\n",
      "Epoch 30::Minibatch 791::LR 0.0330769230769 --> Loss 0.00330107490222\n",
      "Epoch 30::Minibatch 792::LR 0.0330769230769 --> Loss 0.00297823548317\n",
      "Epoch 30::Minibatch 793::LR 0.0330769230769 --> Loss 0.00165276457866\n",
      "Epoch 30::Minibatch 794::LR 0.0330769230769 --> Loss 0.000983794828256\n",
      "Epoch 30::Minibatch 795::LR 0.0330769230769 --> Loss 0.00267546912034\n",
      "Epoch 30::Minibatch 796::LR 0.0330769230769 --> Loss 0.00492470860481\n",
      "Epoch 30::Minibatch 797::LR 0.0330769230769 --> Loss 0.00587054729462\n",
      "Epoch 30::Minibatch 798::LR 0.0330769230769 --> Loss 0.00302357037862\n",
      "Epoch 30::Minibatch 799::LR 0.0330769230769 --> Loss 0.00225404063861\n",
      "Epoch 30::Minibatch 800::LR 0.0330769230769 --> Loss 0.00200297514598\n",
      "Epoch 30::Minibatch 801::LR 0.0330769230769 --> Loss 0.00392033656438\n",
      "Epoch 30::Minibatch 802::LR 0.0330769230769 --> Loss 0.00121494253476\n",
      "Epoch 30::Minibatch 803::LR 0.0330769230769 --> Loss 0.00293679237366\n",
      "Epoch 30::Minibatch 804::LR 0.0330769230769 --> Loss 0.00208290894826\n",
      "Epoch 30::Minibatch 805::LR 0.0330769230769 --> Loss 0.00219079514345\n",
      "Epoch 30::Minibatch 806::LR 0.0330769230769 --> Loss 0.00338345487912\n",
      "Epoch 30::Minibatch 807::LR 0.0330769230769 --> Loss 0.00307089646657\n",
      "Epoch 30::Minibatch 808::LR 0.0330769230769 --> Loss 0.00281169573466\n",
      "Epoch 30::Minibatch 809::LR 0.0330769230769 --> Loss 0.00313723345598\n",
      "Epoch 30::Minibatch 810::LR 0.0330769230769 --> Loss 0.0043080453078\n",
      "Epoch 30::Minibatch 811::LR 0.0330769230769 --> Loss 0.00412157297134\n",
      "Epoch 30::Minibatch 812::LR 0.0330769230769 --> Loss 0.00378281950951\n",
      "Epoch 30::Minibatch 813::LR 0.0330769230769 --> Loss 0.00318287372589\n",
      "Epoch 30::Minibatch 814::LR 0.0330769230769 --> Loss 0.00154101004203\n",
      "Epoch 30::Minibatch 815::LR 0.0330769230769 --> Loss 0.00352870901426\n",
      "Epoch 30::Minibatch 816::LR 0.0330769230769 --> Loss 0.00396812677383\n",
      "Epoch 30::Minibatch 817::LR 0.0330769230769 --> Loss 0.00496177991231\n",
      "Epoch 30::Minibatch 818::LR 0.0330769230769 --> Loss 0.00124174127976\n",
      "Epoch 30::Minibatch 819::LR 0.0330769230769 --> Loss 0.000717115104198\n",
      "Epoch 30::Minibatch 820::LR 0.0330769230769 --> Loss 0.00510173201561\n",
      "Epoch 30::Minibatch 821::LR 0.0330769230769 --> Loss 0.0030577536424\n",
      "Epoch 30::Minibatch 822::LR 0.0330769230769 --> Loss 0.0036558787028\n",
      "Epoch 30::Minibatch 823::LR 0.0330769230769 --> Loss 0.00126265148322\n",
      "Epoch 30::Minibatch 824::LR 0.0330769230769 --> Loss 0.00136096328497\n",
      "Epoch 30::Minibatch 825::LR 0.0330769230769 --> Loss 0.0036945048968\n",
      "Epoch 30::Minibatch 826::LR 0.0330769230769 --> Loss 0.00429766178131\n",
      "Epoch 30::Minibatch 827::LR 0.0330769230769 --> Loss 0.0020543807745\n",
      "Epoch 30::Minibatch 828::LR 0.0330769230769 --> Loss 0.000489020397266\n",
      "Epoch 30::Minibatch 829::LR 0.0330769230769 --> Loss 0.00227039178212\n",
      "Epoch 30::Minibatch 830::LR 0.0330769230769 --> Loss 0.00404285311699\n",
      "Epoch 30::Minibatch 831::LR 0.0330769230769 --> Loss 0.00240973591805\n",
      "Epoch 30::Minibatch 832::LR 0.0330769230769 --> Loss 0.00212010204792\n",
      "Epoch 30::Minibatch 833::LR 0.0330769230769 --> Loss 0.00181751310825\n",
      "Epoch 30::Minibatch 834::LR 0.0330769230769 --> Loss 0.000784899294376\n",
      "Epoch 30::Minibatch 835::LR 0.0330769230769 --> Loss 0.00376239339511\n",
      "Epoch 30::Minibatch 836::LR 0.0330769230769 --> Loss 0.00357781529427\n",
      "Epoch 30::Minibatch 837::LR 0.0330769230769 --> Loss 0.00222460409005\n",
      "Epoch 30::Minibatch 838::LR 0.0330769230769 --> Loss 0.000640154580275\n",
      "Epoch 30::Minibatch 839::LR 0.0330769230769 --> Loss 0.0023945560058\n",
      "Epoch 30::Minibatch 840::LR 0.0330769230769 --> Loss 0.00283935189247\n",
      "Epoch 30::Minibatch 841::LR 0.0330769230769 --> Loss 0.00275278329849\n",
      "Epoch 30::Minibatch 842::LR 0.0330769230769 --> Loss 0.00208788851897\n",
      "Epoch 30::Minibatch 843::LR 0.0330769230769 --> Loss 0.000978808204333\n",
      "Epoch 30::Minibatch 844::LR 0.0330769230769 --> Loss 0.00146687308947\n",
      "Epoch 30::Minibatch 845::LR 0.0330769230769 --> Loss 0.00405337731043\n",
      "Epoch 30::Minibatch 846::LR 0.0330769230769 --> Loss 0.00166513234377\n",
      "Epoch 30::Minibatch 847::LR 0.0330769230769 --> Loss 0.00233380357424\n",
      "Epoch 30::Minibatch 848::LR 0.0330769230769 --> Loss 0.00108967403571\n",
      "Epoch 30::Minibatch 849::LR 0.0330769230769 --> Loss 0.00178534011046\n",
      "Epoch 30::Minibatch 850::LR 0.0330769230769 --> Loss 0.003142978549\n",
      "Epoch 30::Minibatch 851::LR 0.0330769230769 --> Loss 0.00254688620567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 852::LR 0.0330769230769 --> Loss 0.00111523558696\n",
      "Epoch 30::Minibatch 853::LR 0.0330769230769 --> Loss 0.00130108684301\n",
      "Epoch 30::Minibatch 854::LR 0.0330769230769 --> Loss 0.00253081361453\n",
      "Epoch 30::Minibatch 855::LR 0.0330769230769 --> Loss 0.00211395164331\n",
      "Epoch 30::Minibatch 856::LR 0.0330769230769 --> Loss 0.00177982966105\n",
      "Epoch 30::Minibatch 857::LR 0.0330769230769 --> Loss 0.00120747148991\n",
      "Epoch 30::Minibatch 858::LR 0.0330769230769 --> Loss 0.000597148438295\n",
      "Epoch 30::Minibatch 859::LR 0.0330769230769 --> Loss 0.00195772031943\n",
      "Epoch 30::Minibatch 860::LR 0.0330769230769 --> Loss 0.0012884119153\n",
      "Epoch 30::Minibatch 861::LR 0.0330769230769 --> Loss 0.000942354102929\n",
      "Epoch 30::Minibatch 862::LR 0.0330769230769 --> Loss 0.00369308710098\n",
      "Epoch 30::Minibatch 863::LR 0.0330769230769 --> Loss 0.00336542407672\n",
      "Epoch 30::Minibatch 864::LR 0.0330769230769 --> Loss 0.00262937863668\n",
      "Epoch 30::Minibatch 865::LR 0.0330769230769 --> Loss 0.00048800850908\n",
      "Epoch 30::Minibatch 866::LR 0.0330769230769 --> Loss 0.00208333651225\n",
      "Epoch 30::Minibatch 867::LR 0.0330769230769 --> Loss 0.00287863075733\n",
      "Epoch 30::Minibatch 868::LR 0.0330769230769 --> Loss 0.00240677297115\n",
      "Epoch 30::Minibatch 869::LR 0.0330769230769 --> Loss 0.00212327122688\n",
      "Epoch 30::Minibatch 870::LR 0.0330769230769 --> Loss 0.00329517801603\n",
      "Epoch 30::Minibatch 871::LR 0.0330769230769 --> Loss 0.00159779240688\n",
      "Epoch 30::Minibatch 872::LR 0.0330769230769 --> Loss 0.00214323123296\n",
      "Epoch 30::Minibatch 873::LR 0.0330769230769 --> Loss 0.00244994739691\n",
      "Epoch 30::Minibatch 874::LR 0.0330769230769 --> Loss 0.00533675869306\n",
      "Epoch 30::Minibatch 875::LR 0.0330769230769 --> Loss 0.000597437620163\n",
      "Epoch 30::Minibatch 876::LR 0.0330769230769 --> Loss 0.00279503504435\n",
      "Epoch 30::Minibatch 877::LR 0.0330769230769 --> Loss 0.0048057115078\n",
      "Epoch 30::Minibatch 878::LR 0.0330769230769 --> Loss 0.00300549089909\n",
      "Epoch 30::Minibatch 879::LR 0.0330769230769 --> Loss 0.00392623225848\n",
      "Epoch 30::Minibatch 880::LR 0.0330769230769 --> Loss 0.00485058307648\n",
      "Epoch 30::Minibatch 881::LR 0.0330769230769 --> Loss 0.00422827283541\n",
      "Epoch 30::Minibatch 882::LR 0.0330769230769 --> Loss 0.00191911816597\n",
      "Epoch 30::Minibatch 883::LR 0.0330769230769 --> Loss 0.00357509454091\n",
      "Epoch 30::Minibatch 884::LR 0.0330769230769 --> Loss 0.00277214626471\n",
      "Epoch 30::Minibatch 885::LR 0.0330769230769 --> Loss 0.00257731080055\n",
      "Epoch 30::Minibatch 886::LR 0.0330769230769 --> Loss 0.000438349892696\n",
      "Epoch 30::Minibatch 887::LR 0.0330769230769 --> Loss 0.00540166576703\n",
      "Epoch 30::Minibatch 888::LR 0.0330769230769 --> Loss 0.00246774554253\n",
      "Epoch 30::Minibatch 889::LR 0.0330769230769 --> Loss 0.00253982086976\n",
      "Epoch 30::Minibatch 890::LR 0.0330769230769 --> Loss 0.00367900013924\n",
      "Epoch 30::Minibatch 891::LR 0.0330769230769 --> Loss 0.00173272788525\n",
      "Epoch 30::Minibatch 892::LR 0.0330769230769 --> Loss 0.000799337824186\n",
      "Epoch 30::Minibatch 893::LR 0.0330769230769 --> Loss 0.00228120187918\n",
      "Epoch 30::Minibatch 894::LR 0.0330769230769 --> Loss 0.00200676699479\n",
      "Epoch 30::Minibatch 895::LR 0.0330769230769 --> Loss 0.00228432238102\n",
      "Epoch 30::Minibatch 896::LR 0.0330769230769 --> Loss 0.00124099711577\n",
      "Epoch 30::Minibatch 897::LR 0.0330769230769 --> Loss 0.000674258669217\n",
      "Epoch 30::Minibatch 898::LR 0.0330769230769 --> Loss 0.00200207750003\n",
      "Epoch 30::Minibatch 899::LR 0.0330769230769 --> Loss 0.00245206038157\n",
      "Epoch 30::Minibatch 900::LR 0.0330769230769 --> Loss 0.00308410167694\n",
      "Epoch 30::Minibatch 901::LR 0.0330769230769 --> Loss 0.000583395560582\n",
      "Epoch 30::Minibatch 902::LR 0.0330769230769 --> Loss 0.00139492164056\n",
      "Epoch 30::Minibatch 903::LR 0.0330769230769 --> Loss 0.00252774655819\n",
      "Epoch 30::Minibatch 904::LR 0.0330769230769 --> Loss 0.00180785953999\n",
      "Epoch 30::Minibatch 905::LR 0.0330769230769 --> Loss 0.0013987749815\n",
      "Epoch 30::Minibatch 906::LR 0.0330769230769 --> Loss 0.0010290068388\n",
      "Epoch 30::Minibatch 907::LR 0.0330769230769 --> Loss 0.00154950529337\n",
      "Epoch 30::Minibatch 908::LR 0.0330769230769 --> Loss 0.00207325537999\n",
      "Epoch 30::Minibatch 909::LR 0.0330769230769 --> Loss 0.0019309335947\n",
      "Epoch 30::Minibatch 910::LR 0.0330769230769 --> Loss 0.000838490823905\n",
      "Epoch 30::Minibatch 911::LR 0.0330769230769 --> Loss 0.00126179804405\n",
      "Epoch 30::Minibatch 912::LR 0.0330769230769 --> Loss 0.00203250984351\n",
      "Epoch 30::Minibatch 913::LR 0.0330769230769 --> Loss 0.00223950882753\n",
      "Epoch 30::Minibatch 914::LR 0.0330769230769 --> Loss 0.00121918012698\n",
      "Epoch 30::Minibatch 915::LR 0.0330769230769 --> Loss 0.000519827902317\n",
      "Epoch 30::Minibatch 916::LR 0.0330769230769 --> Loss 0.00207179645697\n",
      "Epoch 30::Minibatch 917::LR 0.0330769230769 --> Loss 0.0033426507314\n",
      "Epoch 30::Minibatch 918::LR 0.0330769230769 --> Loss 0.00511216719945\n",
      "Epoch 30::Minibatch 919::LR 0.0330769230769 --> Loss 0.00053385724624\n",
      "Epoch 30::Minibatch 920::LR 0.0330769230769 --> Loss 0.0125317597389\n",
      "Epoch 30::Minibatch 921::LR 0.0330769230769 --> Loss 0.00293073018392\n",
      "Epoch 30::Minibatch 922::LR 0.0330769230769 --> Loss 0.00295859833558\n",
      "Epoch 30::Minibatch 923::LR 0.0330769230769 --> Loss 0.00121216555436\n",
      "Epoch 30::Minibatch 924::LR 0.0330769230769 --> Loss 0.00318620761236\n",
      "Epoch 30::Minibatch 925::LR 0.0330769230769 --> Loss 0.00219267964363\n",
      "Epoch 30::Minibatch 926::LR 0.0330769230769 --> Loss 0.00473523020744\n",
      "Epoch 30::Minibatch 927::LR 0.0330769230769 --> Loss 0.0055312037468\n",
      "Epoch 30::Minibatch 928::LR 0.0330769230769 --> Loss 0.00598902026812\n",
      "Epoch 30::Minibatch 929::LR 0.0330769230769 --> Loss 0.00549233396848\n",
      "Epoch 30::Minibatch 930::LR 0.0330769230769 --> Loss 0.00898956537247\n",
      "Epoch 30::Minibatch 931::LR 0.0330769230769 --> Loss 0.00306221067905\n",
      "Epoch 30::Minibatch 932::LR 0.0330769230769 --> Loss 0.0054215657711\n",
      "Epoch 30::Minibatch 933::LR 0.0330769230769 --> Loss 0.00250642200311\n",
      "Epoch 30::Minibatch 934::LR 0.0330769230769 --> Loss 0.00324111739794\n",
      "Epoch 30::Minibatch 935::LR 0.0330769230769 --> Loss 0.00479054689407\n",
      "Epoch 30::Minibatch 936::LR 0.0330769230769 --> Loss 0.000977654059728\n",
      "Epoch 30::Minibatch 937::LR 0.0330769230769 --> Loss 0.00250639557838\n",
      "Epoch 30::Minibatch 938::LR 0.0330769230769 --> Loss 0.00215731998285\n",
      "Epoch 30::Minibatch 939::LR 0.0330769230769 --> Loss 0.00232046584288\n",
      "Epoch 30::Minibatch 940::LR 0.0330769230769 --> Loss 0.000933584372203\n",
      "Epoch 30::Minibatch 941::LR 0.0330769230769 --> Loss 0.000761978874604\n",
      "Epoch 30::Minibatch 942::LR 0.0330769230769 --> Loss 0.00249129354954\n",
      "Epoch 30::Minibatch 943::LR 0.0330769230769 --> Loss 0.00240020831426\n",
      "Epoch 30::Minibatch 944::LR 0.0330769230769 --> Loss 0.00173484941324\n",
      "Epoch 30::Minibatch 945::LR 0.0330769230769 --> Loss 0.000982937415441\n",
      "Epoch 30::Minibatch 946::LR 0.0330769230769 --> Loss 0.0024993433555\n",
      "Epoch 30::Minibatch 947::LR 0.0330769230769 --> Loss 0.0023003834486\n",
      "Epoch 30::Minibatch 948::LR 0.0330769230769 --> Loss 0.00420341014862\n",
      "Epoch 30::Minibatch 949::LR 0.0330769230769 --> Loss 0.00173318266869\n",
      "Epoch 30::Minibatch 950::LR 0.0330769230769 --> Loss 0.000704043060541\n",
      "Epoch 30::Minibatch 951::LR 0.0330769230769 --> Loss 0.0033561638991\n",
      "Epoch 30::Minibatch 952::LR 0.0330769230769 --> Loss 0.00234561443329\n",
      "Epoch 30::Minibatch 953::LR 0.0330769230769 --> Loss 0.00140857160091\n",
      "Epoch 30::Minibatch 954::LR 0.0330769230769 --> Loss 0.000941816866398\n",
      "Epoch 30::Minibatch 955::LR 0.0330769230769 --> Loss 0.00254018982251\n",
      "Epoch 30::Minibatch 956::LR 0.0330769230769 --> Loss 0.00317135870457\n",
      "Epoch 30::Minibatch 957::LR 0.0330769230769 --> Loss 0.00182436307271\n",
      "Epoch 30::Minibatch 958::LR 0.0330769230769 --> Loss 0.00218542059263\n",
      "Epoch 30::Minibatch 959::LR 0.0330769230769 --> Loss 0.00256751974424\n",
      "Epoch 30::Minibatch 960::LR 0.0330769230769 --> Loss 0.00547466516495\n",
      "Epoch 30::Minibatch 961::LR 0.0330769230769 --> Loss 0.00303227921327\n",
      "Epoch 30::Minibatch 962::LR 0.0330769230769 --> Loss 0.00244231581688\n",
      "Epoch 30::Minibatch 963::LR 0.0330769230769 --> Loss 0.00104508092006\n",
      "Epoch 30::Minibatch 964::LR 0.0330769230769 --> Loss 0.00233819345633\n",
      "Epoch 30::Minibatch 965::LR 0.0330769230769 --> Loss 0.00639963229497\n",
      "Epoch 30::Minibatch 966::LR 0.0330769230769 --> Loss 0.0048772641023\n",
      "Epoch 30::Minibatch 967::LR 0.0330769230769 --> Loss 0.001286701262\n",
      "Epoch 30::Minibatch 968::LR 0.0330769230769 --> Loss 0.00107693781455\n",
      "Epoch 30::Minibatch 969::LR 0.0330769230769 --> Loss 0.00483345508575\n",
      "Epoch 30::Minibatch 970::LR 0.0330769230769 --> Loss 0.00465219974518\n",
      "Epoch 30::Minibatch 971::LR 0.0330769230769 --> Loss 0.00334288597107\n",
      "Epoch 30::Minibatch 972::LR 0.0330769230769 --> Loss 0.00852458238602\n",
      "Epoch 30::Minibatch 973::LR 0.0330769230769 --> Loss 0.00921078443527\n",
      "Epoch 30::Minibatch 974::LR 0.0330769230769 --> Loss 0.0082302792867\n",
      "Epoch 30::Minibatch 975::LR 0.0330769230769 --> Loss 0.00443067153295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30::Minibatch 976::LR 0.0330769230769 --> Loss 0.00367303768794\n",
      "Epoch 30::Minibatch 977::LR 0.0330769230769 --> Loss 0.00344574491183\n",
      "Epoch 30::Minibatch 978::LR 0.0330769230769 --> Loss 0.00337932904561\n",
      "Epoch 30::Minibatch 979::LR 0.0330769230769 --> Loss 0.00316039562225\n",
      "Epoch 30::Minibatch 980::LR 0.0330769230769 --> Loss 0.00350698033969\n",
      "Epoch 30::Minibatch 981::LR 0.0330769230769 --> Loss 0.00440431197484\n",
      "Epoch 30::Minibatch 982::LR 0.0330769230769 --> Loss 0.00460831006368\n",
      "Epoch 30::Minibatch 983::LR 0.0330769230769 --> Loss 0.00258577167988\n",
      "Epoch 30::Minibatch 984::LR 0.0330769230769 --> Loss 0.00184479733308\n",
      "Epoch 30::Minibatch 985::LR 0.0330769230769 --> Loss 0.00345090230306\n",
      "Epoch 30::Minibatch 986::LR 0.0330769230769 --> Loss 0.0031415772438\n",
      "Epoch 30::Minibatch 987::LR 0.0330769230769 --> Loss 0.00344076434771\n",
      "Epoch 30::Minibatch 988::LR 0.0330769230769 --> Loss 0.00274468362331\n",
      "Epoch 30::Minibatch 989::LR 0.0330769230769 --> Loss 0.00301284372807\n",
      "Epoch 30::Minibatch 990::LR 0.0330769230769 --> Loss 0.00280275861422\n",
      "Epoch 30::Minibatch 991::LR 0.0330769230769 --> Loss 0.00142570614815\n",
      "Epoch 30::Minibatch 992::LR 0.0330769230769 --> Loss 0.00164563635985\n",
      "Epoch 30::Minibatch 993::LR 0.0330769230769 --> Loss 0.00305647472541\n",
      "Epoch 30::Minibatch 994::LR 0.0330769230769 --> Loss 0.00199964761734\n",
      "Epoch 30::Minibatch 995::LR 0.0330769230769 --> Loss 0.000806796203057\n",
      "Epoch 30::Minibatch 996::LR 0.0330769230769 --> Loss 0.00271110534668\n",
      "Epoch 30::Minibatch 997::LR 0.0330769230769 --> Loss 0.00219591140747\n",
      "Epoch 30::Minibatch 998::LR 0.0330769230769 --> Loss 0.00250029126803\n",
      "Epoch 30::Minibatch 999::LR 0.0330769230769 --> Loss 0.00212899883588\n",
      "Epoch 30::Minibatch 1000::LR 0.0330769230769 --> Loss 0.00255581041177\n",
      "Epoch 30::Minibatch 1001::LR 0.0330769230769 --> Loss 0.0020296082894\n",
      "Epoch 30::Minibatch 1002::LR 0.0330769230769 --> Loss 0.00162279993296\n",
      "Epoch 30::Minibatch 1003::LR 0.0330769230769 --> Loss 0.00262824773788\n",
      "Epoch 30::Minibatch 1004::LR 0.0330769230769 --> Loss 0.00106802294652\n",
      "Epoch 30::Minibatch 1005::LR 0.0330769230769 --> Loss 0.0026276721557\n",
      "Epoch 30::Minibatch 1006::LR 0.0330769230769 --> Loss 0.00139499386152\n",
      "Epoch 30::Minibatch 1007::LR 0.0330769230769 --> Loss 0.00182060082753\n",
      "Epoch 30::Minibatch 1008::LR 0.0330769230769 --> Loss 0.000926694770654\n",
      "Epoch 30::Minibatch 1009::LR 0.0330769230769 --> Loss 0.00123734335105\n",
      "Epoch 30::Minibatch 1010::LR 0.0330769230769 --> Loss 0.00114445885022\n",
      "Epoch 30::Minibatch 1011::LR 0.0330769230769 --> Loss 0.00173885623614\n",
      "Epoch 30::Minibatch 1012::LR 0.0330769230769 --> Loss 0.00142839541038\n",
      "Epoch 30::Minibatch 1013::LR 0.0330769230769 --> Loss 0.00356913685799\n",
      "Epoch 30::Minibatch 1014::LR 0.0330769230769 --> Loss 0.00333071291447\n",
      "Epoch 30::Minibatch 1015::LR 0.0330769230769 --> Loss 0.00154050032298\n",
      "Epoch 30::Minibatch 1016::LR 0.0330769230769 --> Loss 0.00452276070913\n",
      "Epoch 30::Minibatch 1017::LR 0.0330769230769 --> Loss 0.00311694045862\n",
      "Epoch 30::Minibatch 1018::LR 0.0330769230769 --> Loss 0.00254083156586\n",
      "Epoch 30::Minibatch 1019::LR 0.0330769230769 --> Loss 0.0016123042504\n",
      "Epoch 30::Minibatch 1020::LR 0.0330769230769 --> Loss 0.00172344366709\n",
      "Epoch 30::Minibatch 1021::LR 0.0330769230769 --> Loss 0.0018406689167\n",
      "Epoch 30::Minibatch 1022::LR 0.0330769230769 --> Loss 0.00135809818904\n",
      "Epoch 30::Minibatch 1023::LR 0.0330769230769 --> Loss 0.00102174421151\n",
      "Epoch 30::Minibatch 1024::LR 0.0330769230769 --> Loss 0.0010169133544\n",
      "Epoch 30::Minibatch 1025::LR 0.0330769230769 --> Loss 0.00136821101109\n",
      "Epoch 30::Minibatch 1026::LR 0.0330769230769 --> Loss 0.000709894001484\n",
      "Epoch 30::Minibatch 1027::LR 0.0330769230769 --> Loss 0.000978338718414\n",
      "Epoch 30::Minibatch 1028::LR 0.0330769230769 --> Loss 0.000735131899516\n",
      "Epoch 30::Minibatch 1029::LR 0.0330769230769 --> Loss 0.000744568953911\n",
      "Epoch 30::Minibatch 1030::LR 0.0330769230769 --> Loss 0.000911153356234\n",
      "Epoch 30::Minibatch 1031::LR 0.0330769230769 --> Loss 0.000699284076691\n",
      "Epoch 30::Minibatch 1032::LR 0.0330769230769 --> Loss 0.000776588370403\n",
      "Epoch 30::Minibatch 1033::LR 0.0330769230769 --> Loss 0.000660504698753\n",
      "Epoch 30::Minibatch 1034::LR 0.0330769230769 --> Loss 0.000627533992132\n",
      "Epoch 30::Minibatch 1035::LR 0.0330769230769 --> Loss 0.00041331085066\n",
      "Epoch 30::Minibatch 1036::LR 0.0330769230769 --> Loss 0.000330638363957\n",
      "Epoch 30::Minibatch 1037::LR 0.0330769230769 --> Loss 0.000601692895095\n",
      "Epoch 30::Minibatch 1038::LR 0.0330769230769 --> Loss 0.00110030780236\n",
      "Epoch 30::Minibatch 1039::LR 0.0330769230769 --> Loss 0.000883279542128\n",
      "Epoch 30::Minibatch 1040::LR 0.0330769230769 --> Loss 0.000347979838649\n",
      "Epoch 30::Minibatch 1041::LR 0.0330769230769 --> Loss 0.00050099487106\n",
      "Epoch 31::Minibatch 1::LR 0.0307692307692 --> Loss 0.00772115945816\n",
      "Epoch 31::Minibatch 2::LR 0.0307692307692 --> Loss 0.00477488160133\n",
      "Epoch 31::Minibatch 3::LR 0.0307692307692 --> Loss 0.0030912599961\n",
      "Epoch 31::Minibatch 4::LR 0.0307692307692 --> Loss 0.00382839997609\n",
      "Epoch 31::Minibatch 5::LR 0.0307692307692 --> Loss 0.00439956347148\n",
      "Epoch 31::Minibatch 6::LR 0.0307692307692 --> Loss 0.00209338029226\n",
      "Epoch 31::Minibatch 7::LR 0.0307692307692 --> Loss 0.00715989033381\n",
      "Epoch 31::Minibatch 8::LR 0.0307692307692 --> Loss 0.0066629354159\n",
      "Epoch 31::Minibatch 9::LR 0.0307692307692 --> Loss 0.0051621667544\n",
      "Epoch 31::Minibatch 10::LR 0.0307692307692 --> Loss 0.00238283058008\n",
      "Epoch 31::Minibatch 11::LR 0.0307692307692 --> Loss 0.00222621579965\n",
      "Epoch 31::Minibatch 12::LR 0.0307692307692 --> Loss 0.00335180600484\n",
      "Epoch 31::Minibatch 13::LR 0.0307692307692 --> Loss 0.00528396606445\n",
      "Epoch 31::Minibatch 14::LR 0.0307692307692 --> Loss 0.00526985168457\n",
      "Epoch 31::Minibatch 15::LR 0.0307692307692 --> Loss 0.00455393751462\n",
      "Epoch 31::Minibatch 16::LR 0.0307692307692 --> Loss 0.000724227180084\n",
      "Epoch 31::Minibatch 17::LR 0.0307692307692 --> Loss 0.00318363865217\n",
      "Epoch 31::Minibatch 18::LR 0.0307692307692 --> Loss 0.00263921201229\n",
      "Epoch 31::Minibatch 19::LR 0.0307692307692 --> Loss 0.00157458871603\n",
      "Epoch 31::Minibatch 20::LR 0.0307692307692 --> Loss 0.00209956069787\n",
      "Epoch 31::Minibatch 21::LR 0.0307692307692 --> Loss 0.00337656855583\n",
      "Epoch 31::Minibatch 22::LR 0.0307692307692 --> Loss 0.00222675323486\n",
      "Epoch 31::Minibatch 23::LR 0.0307692307692 --> Loss 0.000902861555417\n",
      "Epoch 31::Minibatch 24::LR 0.0307692307692 --> Loss 0.000494795838992\n",
      "Epoch 31::Minibatch 25::LR 0.0307692307692 --> Loss 0.00133134563764\n",
      "Epoch 31::Minibatch 26::LR 0.0307692307692 --> Loss 0.00152757386367\n",
      "Epoch 31::Minibatch 27::LR 0.0307692307692 --> Loss 0.00113643735647\n",
      "Epoch 31::Minibatch 28::LR 0.0307692307692 --> Loss 0.000497472335895\n",
      "Epoch 31::Minibatch 29::LR 0.0307692307692 --> Loss 0.000593530784051\n",
      "Epoch 31::Minibatch 30::LR 0.0307692307692 --> Loss 0.00108887970448\n",
      "Epoch 31::Minibatch 31::LR 0.0307692307692 --> Loss 0.00157300422589\n",
      "Epoch 31::Minibatch 32::LR 0.0307692307692 --> Loss 0.001393853724\n",
      "Epoch 31::Minibatch 33::LR 0.0307692307692 --> Loss 0.000808582752943\n",
      "Epoch 31::Minibatch 34::LR 0.0307692307692 --> Loss 0.0020419661204\n",
      "Epoch 31::Minibatch 35::LR 0.0307692307692 --> Loss 0.00299721459548\n",
      "Epoch 31::Minibatch 36::LR 0.0307692307692 --> Loss 0.00226071635882\n",
      "Epoch 31::Minibatch 37::LR 0.0307692307692 --> Loss 0.000714657654365\n",
      "Epoch 31::Minibatch 38::LR 0.0307692307692 --> Loss 0.000732974509398\n",
      "Epoch 31::Minibatch 39::LR 0.0307692307692 --> Loss 0.00214880625407\n",
      "Epoch 31::Minibatch 40::LR 0.0307692307692 --> Loss 0.0030833431085\n",
      "Epoch 31::Minibatch 41::LR 0.0307692307692 --> Loss 0.00245698730151\n",
      "Epoch 31::Minibatch 42::LR 0.0307692307692 --> Loss 0.00460228562355\n",
      "Epoch 31::Minibatch 43::LR 0.0307692307692 --> Loss 0.00201124429703\n",
      "Epoch 31::Minibatch 44::LR 0.0307692307692 --> Loss 0.00330721199512\n",
      "Epoch 31::Minibatch 45::LR 0.0307692307692 --> Loss 0.00240653793017\n",
      "Epoch 31::Minibatch 46::LR 0.0307692307692 --> Loss 0.00306944608688\n",
      "Epoch 31::Minibatch 47::LR 0.0307692307692 --> Loss 0.00334275325139\n",
      "Epoch 31::Minibatch 48::LR 0.0307692307692 --> Loss 0.00484716773033\n",
      "Epoch 31::Minibatch 49::LR 0.0307692307692 --> Loss 0.00547995487849\n",
      "Epoch 31::Minibatch 50::LR 0.0307692307692 --> Loss 0.00598456978798\n",
      "Epoch 31::Minibatch 51::LR 0.0307692307692 --> Loss 0.00440018892288\n",
      "Epoch 31::Minibatch 52::LR 0.0307692307692 --> Loss 0.00341146111488\n",
      "Epoch 31::Minibatch 53::LR 0.0307692307692 --> Loss 0.00337966879209\n",
      "Epoch 31::Minibatch 54::LR 0.0307692307692 --> Loss 0.00398805101713\n",
      "Epoch 31::Minibatch 55::LR 0.0307692307692 --> Loss 0.000992727478345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 56::LR 0.0307692307692 --> Loss 0.0027387847503\n",
      "Epoch 31::Minibatch 57::LR 0.0307692307692 --> Loss 0.00460854927699\n",
      "Epoch 31::Minibatch 58::LR 0.0307692307692 --> Loss 0.00320189853509\n",
      "Epoch 31::Minibatch 59::LR 0.0307692307692 --> Loss 0.0024395519495\n",
      "Epoch 31::Minibatch 60::LR 0.0307692307692 --> Loss 0.00248180131118\n",
      "Epoch 31::Minibatch 61::LR 0.0307692307692 --> Loss 0.000722561329603\n",
      "Epoch 31::Minibatch 62::LR 0.0307692307692 --> Loss 0.00253200888634\n",
      "Epoch 31::Minibatch 63::LR 0.0307692307692 --> Loss 0.00202523390452\n",
      "Epoch 31::Minibatch 64::LR 0.0307692307692 --> Loss 0.000818979392449\n",
      "Epoch 31::Minibatch 65::LR 0.0307692307692 --> Loss 0.00213952104251\n",
      "Epoch 31::Minibatch 66::LR 0.0307692307692 --> Loss 0.00275206287702\n",
      "Epoch 31::Minibatch 67::LR 0.0307692307692 --> Loss 0.00250878910224\n",
      "Epoch 31::Minibatch 68::LR 0.0307692307692 --> Loss 0.00183000405629\n",
      "Epoch 31::Minibatch 69::LR 0.0307692307692 --> Loss 0.00361291368802\n",
      "Epoch 31::Minibatch 70::LR 0.0307692307692 --> Loss 0.0032063494126\n",
      "Epoch 31::Minibatch 71::LR 0.0307692307692 --> Loss 0.00223780711492\n",
      "Epoch 31::Minibatch 72::LR 0.0307692307692 --> Loss 0.000545523265998\n",
      "Epoch 31::Minibatch 73::LR 0.0307692307692 --> Loss 0.00367909113566\n",
      "Epoch 31::Minibatch 74::LR 0.0307692307692 --> Loss 0.0039803703626\n",
      "Epoch 31::Minibatch 75::LR 0.0307692307692 --> Loss 0.0020821950833\n",
      "Epoch 31::Minibatch 76::LR 0.0307692307692 --> Loss 0.000520485242208\n",
      "Epoch 31::Minibatch 77::LR 0.0307692307692 --> Loss 0.00330885271231\n",
      "Epoch 31::Minibatch 78::LR 0.0307692307692 --> Loss 0.00392990469933\n",
      "Epoch 31::Minibatch 79::LR 0.0307692307692 --> Loss 0.00170696556568\n",
      "Epoch 31::Minibatch 80::LR 0.0307692307692 --> Loss 0.00282943844795\n",
      "Epoch 31::Minibatch 81::LR 0.0307692307692 --> Loss 0.00251032272975\n",
      "Epoch 31::Minibatch 82::LR 0.0307692307692 --> Loss 0.00182895044486\n",
      "Epoch 31::Minibatch 83::LR 0.0307692307692 --> Loss 0.00387390295664\n",
      "Epoch 31::Minibatch 84::LR 0.0307692307692 --> Loss 0.00185052414735\n",
      "Epoch 31::Minibatch 85::LR 0.0307692307692 --> Loss 0.00251873711745\n",
      "Epoch 31::Minibatch 86::LR 0.0307692307692 --> Loss 0.00208196957906\n",
      "Epoch 31::Minibatch 87::LR 0.0307692307692 --> Loss 0.00220483044783\n",
      "Epoch 31::Minibatch 88::LR 0.0307692307692 --> Loss 0.00166001478831\n",
      "Epoch 31::Minibatch 89::LR 0.0307692307692 --> Loss 0.00218560636044\n",
      "Epoch 31::Minibatch 90::LR 0.0307692307692 --> Loss 0.00104420810938\n",
      "Epoch 31::Minibatch 91::LR 0.0307692307692 --> Loss 0.000870263576508\n",
      "Epoch 31::Minibatch 92::LR 0.0307692307692 --> Loss 0.0025463227431\n",
      "Epoch 31::Minibatch 93::LR 0.0307692307692 --> Loss 0.00169208089511\n",
      "Epoch 31::Minibatch 94::LR 0.0307692307692 --> Loss 0.00173571368059\n",
      "Epoch 31::Minibatch 95::LR 0.0307692307692 --> Loss 0.00189707497756\n",
      "Epoch 31::Minibatch 96::LR 0.0307692307692 --> Loss 0.0047535208861\n",
      "Epoch 31::Minibatch 97::LR 0.0307692307692 --> Loss 0.00301586945852\n",
      "Epoch 31::Minibatch 98::LR 0.0307692307692 --> Loss 0.00107666174571\n",
      "Epoch 31::Minibatch 99::LR 0.0307692307692 --> Loss 0.00140091796716\n",
      "Epoch 31::Minibatch 100::LR 0.0307692307692 --> Loss 0.0042143646876\n",
      "Epoch 31::Minibatch 101::LR 0.0307692307692 --> Loss 0.000897152721882\n",
      "Epoch 31::Minibatch 102::LR 0.0307692307692 --> Loss 0.00386385242144\n",
      "Epoch 31::Minibatch 103::LR 0.0307692307692 --> Loss 0.00387981414795\n",
      "Epoch 31::Minibatch 104::LR 0.0307692307692 --> Loss 0.00265188336372\n",
      "Epoch 31::Minibatch 105::LR 0.0307692307692 --> Loss 0.00209509472052\n",
      "Epoch 31::Minibatch 106::LR 0.0307692307692 --> Loss 0.0137401676178\n",
      "Epoch 31::Minibatch 107::LR 0.0307692307692 --> Loss 0.00475410461426\n",
      "Epoch 31::Minibatch 108::LR 0.0307692307692 --> Loss 0.00092585682869\n",
      "Epoch 31::Minibatch 109::LR 0.0307692307692 --> Loss 0.0042976852258\n",
      "Epoch 31::Minibatch 110::LR 0.0307692307692 --> Loss 0.00220868150393\n",
      "Epoch 31::Minibatch 111::LR 0.0307692307692 --> Loss 0.000814305196206\n",
      "Epoch 31::Minibatch 112::LR 0.0307692307692 --> Loss 0.00326941013336\n",
      "Epoch 31::Minibatch 113::LR 0.0307692307692 --> Loss 0.00237696190675\n",
      "Epoch 31::Minibatch 114::LR 0.0307692307692 --> Loss 0.00133066038291\n",
      "Epoch 31::Minibatch 115::LR 0.0307692307692 --> Loss 0.00112875372171\n",
      "Epoch 31::Minibatch 116::LR 0.0307692307692 --> Loss 0.00261829872926\n",
      "Epoch 31::Minibatch 117::LR 0.0307692307692 --> Loss 0.00405910929044\n",
      "Epoch 31::Minibatch 118::LR 0.0307692307692 --> Loss 0.00654101769129\n",
      "Epoch 31::Minibatch 119::LR 0.0307692307692 --> Loss 0.000496573050817\n",
      "Epoch 31::Minibatch 120::LR 0.0307692307692 --> Loss 0.00162377526363\n",
      "Epoch 31::Minibatch 121::LR 0.0307692307692 --> Loss 0.00234967470169\n",
      "Epoch 31::Minibatch 122::LR 0.0307692307692 --> Loss 0.00383303244909\n",
      "Epoch 31::Minibatch 123::LR 0.0307692307692 --> Loss 0.000681516478459\n",
      "Epoch 31::Minibatch 124::LR 0.0307692307692 --> Loss 0.00259433984756\n",
      "Epoch 31::Minibatch 125::LR 0.0307692307692 --> Loss 0.00440295894941\n",
      "Epoch 31::Minibatch 126::LR 0.0307692307692 --> Loss 0.00244230608145\n",
      "Epoch 31::Minibatch 127::LR 0.0307692307692 --> Loss 0.00480725248655\n",
      "Epoch 31::Minibatch 128::LR 0.0307692307692 --> Loss 0.00350559433301\n",
      "Epoch 31::Minibatch 129::LR 0.0307692307692 --> Loss 0.00239537616571\n",
      "Epoch 31::Minibatch 130::LR 0.0307692307692 --> Loss 0.00431296745936\n",
      "Epoch 31::Minibatch 131::LR 0.0307692307692 --> Loss 0.00170720875263\n",
      "Epoch 31::Minibatch 132::LR 0.0307692307692 --> Loss 0.00282161096732\n",
      "Epoch 31::Minibatch 133::LR 0.0307692307692 --> Loss 0.00272049307823\n",
      "Epoch 31::Minibatch 134::LR 0.0307692307692 --> Loss 0.00211549560229\n",
      "Epoch 31::Minibatch 135::LR 0.0307692307692 --> Loss 0.00128640820583\n",
      "Epoch 31::Minibatch 136::LR 0.0307692307692 --> Loss 0.00242975175381\n",
      "Epoch 31::Minibatch 137::LR 0.0307692307692 --> Loss 0.00338541309039\n",
      "Epoch 31::Minibatch 138::LR 0.0307692307692 --> Loss 0.00121450682481\n",
      "Epoch 31::Minibatch 139::LR 0.0307692307692 --> Loss 0.00187006572882\n",
      "Epoch 31::Minibatch 140::LR 0.0307692307692 --> Loss 0.00238116959731\n",
      "Epoch 31::Minibatch 141::LR 0.0307692307692 --> Loss 0.00288796404998\n",
      "Epoch 31::Minibatch 142::LR 0.0307692307692 --> Loss 0.00269673983256\n",
      "Epoch 31::Minibatch 143::LR 0.0307692307692 --> Loss 0.000541106710831\n",
      "Epoch 31::Minibatch 144::LR 0.0307692307692 --> Loss 0.00335145831108\n",
      "Epoch 31::Minibatch 145::LR 0.0307692307692 --> Loss 0.0041241033872\n",
      "Epoch 31::Minibatch 146::LR 0.0307692307692 --> Loss 0.00249621609847\n",
      "Epoch 31::Minibatch 147::LR 0.0307692307692 --> Loss 0.00178668002288\n",
      "Epoch 31::Minibatch 148::LR 0.0307692307692 --> Loss 0.000971314013004\n",
      "Epoch 31::Minibatch 149::LR 0.0307692307692 --> Loss 0.00285428007444\n",
      "Epoch 31::Minibatch 150::LR 0.0307692307692 --> Loss 0.00266077935696\n",
      "Epoch 31::Minibatch 151::LR 0.0307692307692 --> Loss 0.00427522222201\n",
      "Epoch 31::Minibatch 152::LR 0.0307692307692 --> Loss 0.00090314279\n",
      "Epoch 31::Minibatch 153::LR 0.0307692307692 --> Loss 0.00164363364379\n",
      "Epoch 31::Minibatch 154::LR 0.0307692307692 --> Loss 0.00201158324877\n",
      "Epoch 31::Minibatch 155::LR 0.0307692307692 --> Loss 0.00409003973007\n",
      "Epoch 31::Minibatch 156::LR 0.0307692307692 --> Loss 0.00235259672006\n",
      "Epoch 31::Minibatch 157::LR 0.0307692307692 --> Loss 0.000686354736487\n",
      "Epoch 31::Minibatch 158::LR 0.0307692307692 --> Loss 0.00315081675847\n",
      "Epoch 31::Minibatch 159::LR 0.0307692307692 --> Loss 0.00272371649742\n",
      "Epoch 31::Minibatch 160::LR 0.0307692307692 --> Loss 0.00264615277449\n",
      "Epoch 31::Minibatch 161::LR 0.0307692307692 --> Loss 0.00100178390741\n",
      "Epoch 31::Minibatch 162::LR 0.0307692307692 --> Loss 0.00392555038134\n",
      "Epoch 31::Minibatch 163::LR 0.0307692307692 --> Loss 0.00239713172118\n",
      "Epoch 31::Minibatch 164::LR 0.0307692307692 --> Loss 0.00252612054348\n",
      "Epoch 31::Minibatch 165::LR 0.0307692307692 --> Loss 0.000499888658524\n",
      "Epoch 31::Minibatch 166::LR 0.0307692307692 --> Loss 0.00171239753564\n",
      "Epoch 31::Minibatch 167::LR 0.0307692307692 --> Loss 0.00247183203697\n",
      "Epoch 31::Minibatch 168::LR 0.0307692307692 --> Loss 0.00214317242304\n",
      "Epoch 31::Minibatch 169::LR 0.0307692307692 --> Loss 0.000991801321507\n",
      "Epoch 31::Minibatch 170::LR 0.0307692307692 --> Loss 0.000956765115261\n",
      "Epoch 31::Minibatch 171::LR 0.0307692307692 --> Loss 0.00250554005305\n",
      "Epoch 31::Minibatch 172::LR 0.0307692307692 --> Loss 0.00424980600675\n",
      "Epoch 31::Minibatch 173::LR 0.0307692307692 --> Loss 0.00198972642422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 174::LR 0.0307692307692 --> Loss 0.000966333647569\n",
      "Epoch 31::Minibatch 175::LR 0.0307692307692 --> Loss 0.00235121647517\n",
      "Epoch 31::Minibatch 176::LR 0.0307692307692 --> Loss 0.00312971611818\n",
      "Epoch 31::Minibatch 177::LR 0.0307692307692 --> Loss 0.00429189046224\n",
      "Epoch 31::Minibatch 178::LR 0.0307692307692 --> Loss 0.00151510049899\n",
      "Epoch 31::Minibatch 179::LR 0.0307692307692 --> Loss 0.00121727456649\n",
      "Epoch 31::Minibatch 180::LR 0.0307692307692 --> Loss 0.00340599417686\n",
      "Epoch 31::Minibatch 181::LR 0.0307692307692 --> Loss 0.00306917885939\n",
      "Epoch 31::Minibatch 182::LR 0.0307692307692 --> Loss 0.000712626924117\n",
      "Epoch 31::Minibatch 183::LR 0.0307692307692 --> Loss 0.00157592097918\n",
      "Epoch 31::Minibatch 184::LR 0.0307692307692 --> Loss 0.00340606331825\n",
      "Epoch 31::Minibatch 185::LR 0.0307692307692 --> Loss 0.00268958071868\n",
      "Epoch 31::Minibatch 186::LR 0.0307692307692 --> Loss 0.000934080282847\n",
      "Epoch 31::Minibatch 187::LR 0.0307692307692 --> Loss 0.00127466430267\n",
      "Epoch 31::Minibatch 188::LR 0.0307692307692 --> Loss 0.00406370997429\n",
      "Epoch 31::Minibatch 189::LR 0.0307692307692 --> Loss 0.00415544629097\n",
      "Epoch 31::Minibatch 190::LR 0.0307692307692 --> Loss 0.00231513977051\n",
      "Epoch 31::Minibatch 191::LR 0.0307692307692 --> Loss 0.000452742129564\n",
      "Epoch 31::Minibatch 192::LR 0.0307692307692 --> Loss 0.00276923616727\n",
      "Epoch 31::Minibatch 193::LR 0.0307692307692 --> Loss 0.00267569422722\n",
      "Epoch 31::Minibatch 194::LR 0.0307692307692 --> Loss 0.00174200952053\n",
      "Epoch 31::Minibatch 195::LR 0.0307692307692 --> Loss 0.000376600871483\n",
      "Epoch 31::Minibatch 196::LR 0.0307692307692 --> Loss 0.00133865614732\n",
      "Epoch 31::Minibatch 197::LR 0.0307692307692 --> Loss 0.00294904390971\n",
      "Epoch 31::Minibatch 198::LR 0.0307692307692 --> Loss 0.00229694267114\n",
      "Epoch 31::Minibatch 199::LR 0.0307692307692 --> Loss 0.000289996688565\n",
      "Epoch 31::Minibatch 200::LR 0.0307692307692 --> Loss 0.00203887164593\n",
      "Epoch 31::Minibatch 201::LR 0.0307692307692 --> Loss 0.0019327344497\n",
      "Epoch 31::Minibatch 202::LR 0.0307692307692 --> Loss 0.00182163874308\n",
      "Epoch 31::Minibatch 203::LR 0.0307692307692 --> Loss 0.00174994746844\n",
      "Epoch 31::Minibatch 204::LR 0.0307692307692 --> Loss 0.00141740938028\n",
      "Epoch 31::Minibatch 205::LR 0.0307692307692 --> Loss 0.00220806499322\n",
      "Epoch 31::Minibatch 206::LR 0.0307692307692 --> Loss 0.00558686216672\n",
      "Epoch 31::Minibatch 207::LR 0.0307692307692 --> Loss 0.00139814903339\n",
      "Epoch 31::Minibatch 208::LR 0.0307692307692 --> Loss 0.00110603233178\n",
      "Epoch 31::Minibatch 209::LR 0.0307692307692 --> Loss 0.00245243728161\n",
      "Epoch 31::Minibatch 210::LR 0.0307692307692 --> Loss 0.0023138097922\n",
      "Epoch 31::Minibatch 211::LR 0.0307692307692 --> Loss 0.00262325962385\n",
      "Epoch 31::Minibatch 212::LR 0.0307692307692 --> Loss 0.00378326654434\n",
      "Epoch 31::Minibatch 213::LR 0.0307692307692 --> Loss 0.00544098377228\n",
      "Epoch 31::Minibatch 214::LR 0.0307692307692 --> Loss 0.00733868439992\n",
      "Epoch 31::Minibatch 215::LR 0.0307692307692 --> Loss 0.00135887463888\n",
      "Epoch 31::Minibatch 216::LR 0.0307692307692 --> Loss 0.00531131108602\n",
      "Epoch 31::Minibatch 217::LR 0.0307692307692 --> Loss 0.00587472200394\n",
      "Epoch 31::Minibatch 218::LR 0.0307692307692 --> Loss 0.00389721632004\n",
      "Epoch 31::Minibatch 219::LR 0.0307692307692 --> Loss 0.00437543153763\n",
      "Epoch 31::Minibatch 220::LR 0.0307692307692 --> Loss 0.00436449686686\n",
      "Epoch 31::Minibatch 221::LR 0.0307692307692 --> Loss 0.00424367070198\n",
      "Epoch 31::Minibatch 222::LR 0.0307692307692 --> Loss 0.0031673314174\n",
      "Epoch 31::Minibatch 223::LR 0.0307692307692 --> Loss 0.00138565897942\n",
      "Epoch 31::Minibatch 224::LR 0.0307692307692 --> Loss 0.00160858372847\n",
      "Epoch 31::Minibatch 225::LR 0.0307692307692 --> Loss 0.00774172385534\n",
      "Epoch 31::Minibatch 226::LR 0.0307692307692 --> Loss 0.00366945068041\n",
      "Epoch 31::Minibatch 227::LR 0.0307692307692 --> Loss 0.00167863607407\n",
      "Epoch 31::Minibatch 228::LR 0.0307692307692 --> Loss 0.000661902576685\n",
      "Epoch 31::Minibatch 229::LR 0.0307692307692 --> Loss 0.00471040288607\n",
      "Epoch 31::Minibatch 230::LR 0.0307692307692 --> Loss 0.00370742996534\n",
      "Epoch 31::Minibatch 231::LR 0.0307692307692 --> Loss 0.00266021728516\n",
      "Epoch 31::Minibatch 232::LR 0.0307692307692 --> Loss 0.00116842836142\n",
      "Epoch 31::Minibatch 233::LR 0.0307692307692 --> Loss 0.00245735685031\n",
      "Epoch 31::Minibatch 234::LR 0.0307692307692 --> Loss 0.00728671153386\n",
      "Epoch 31::Minibatch 235::LR 0.0307692307692 --> Loss 0.00456501444181\n",
      "Epoch 31::Minibatch 236::LR 0.0307692307692 --> Loss 0.00168306410313\n",
      "Epoch 31::Minibatch 237::LR 0.0307692307692 --> Loss 0.000599443763494\n",
      "Epoch 31::Minibatch 238::LR 0.0307692307692 --> Loss 0.00343055764834\n",
      "Epoch 31::Minibatch 239::LR 0.0307692307692 --> Loss 0.00295727749666\n",
      "Epoch 31::Minibatch 240::LR 0.0307692307692 --> Loss 0.0032459328572\n",
      "Epoch 31::Minibatch 241::LR 0.0307692307692 --> Loss 0.000744156787793\n",
      "Epoch 31::Minibatch 242::LR 0.0307692307692 --> Loss 0.00674469788869\n",
      "Epoch 31::Minibatch 243::LR 0.0307692307692 --> Loss 0.00328854262829\n",
      "Epoch 31::Minibatch 244::LR 0.0307692307692 --> Loss 0.0027585564057\n",
      "Epoch 31::Minibatch 245::LR 0.0307692307692 --> Loss 0.000434410174688\n",
      "Epoch 31::Minibatch 246::LR 0.0307692307692 --> Loss 0.00192647735278\n",
      "Epoch 31::Minibatch 247::LR 0.0307692307692 --> Loss 0.0108004085223\n",
      "Epoch 31::Minibatch 248::LR 0.0307692307692 --> Loss 0.00435282905897\n",
      "Epoch 31::Minibatch 249::LR 0.0307692307692 --> Loss 0.00243365029494\n",
      "Epoch 31::Minibatch 250::LR 0.0307692307692 --> Loss 0.00236205101013\n",
      "Epoch 31::Minibatch 251::LR 0.0307692307692 --> Loss 0.00234793643157\n",
      "Epoch 31::Minibatch 252::LR 0.0307692307692 --> Loss 0.00162786275148\n",
      "Epoch 31::Minibatch 253::LR 0.0307692307692 --> Loss 0.00282715996106\n",
      "Epoch 31::Minibatch 254::LR 0.0307692307692 --> Loss 0.00485977530479\n",
      "Epoch 31::Minibatch 255::LR 0.0307692307692 --> Loss 0.0038313694795\n",
      "Epoch 31::Minibatch 256::LR 0.0307692307692 --> Loss 0.00142288605372\n",
      "Epoch 31::Minibatch 257::LR 0.0307692307692 --> Loss 0.00114457746347\n",
      "Epoch 31::Minibatch 258::LR 0.0307692307692 --> Loss 0.00364999731382\n",
      "Epoch 31::Minibatch 259::LR 0.0307692307692 --> Loss 0.00161361157894\n",
      "Epoch 31::Minibatch 260::LR 0.0307692307692 --> Loss 0.00184649308523\n",
      "Epoch 31::Minibatch 261::LR 0.0307692307692 --> Loss 0.00267089108626\n",
      "Epoch 31::Minibatch 262::LR 0.0307692307692 --> Loss 0.00182366152604\n",
      "Epoch 31::Minibatch 263::LR 0.0307692307692 --> Loss 0.00229332149029\n",
      "Epoch 31::Minibatch 264::LR 0.0307692307692 --> Loss 0.00356103459994\n",
      "Epoch 31::Minibatch 265::LR 0.0307692307692 --> Loss 0.00992578903834\n",
      "Epoch 31::Minibatch 266::LR 0.0307692307692 --> Loss 0.000896797974904\n",
      "Epoch 31::Minibatch 267::LR 0.0307692307692 --> Loss 0.00918368180593\n",
      "Epoch 31::Minibatch 268::LR 0.0307692307692 --> Loss 0.0010519639651\n",
      "Epoch 31::Minibatch 269::LR 0.0307692307692 --> Loss 0.00347061872482\n",
      "Epoch 31::Minibatch 270::LR 0.0307692307692 --> Loss 0.0072178252538\n",
      "Epoch 31::Minibatch 271::LR 0.0307692307692 --> Loss 0.00245386123657\n",
      "Epoch 31::Minibatch 272::LR 0.0307692307692 --> Loss 0.00438357154528\n",
      "Epoch 31::Minibatch 273::LR 0.0307692307692 --> Loss 0.00141082207362\n",
      "Epoch 31::Minibatch 274::LR 0.0307692307692 --> Loss 0.00177374025186\n",
      "Epoch 31::Minibatch 275::LR 0.0307692307692 --> Loss 0.00248446424802\n",
      "Epoch 31::Minibatch 276::LR 0.0307692307692 --> Loss 0.00336466789246\n",
      "Epoch 31::Minibatch 277::LR 0.0307692307692 --> Loss 0.000882671674093\n",
      "Epoch 31::Minibatch 278::LR 0.0307692307692 --> Loss 0.00254750271638\n",
      "Epoch 31::Minibatch 279::LR 0.0307692307692 --> Loss 0.00204076945782\n",
      "Epoch 31::Minibatch 280::LR 0.0307692307692 --> Loss 0.00180226822694\n",
      "Epoch 31::Minibatch 281::LR 0.0307692307692 --> Loss 0.00114304711421\n",
      "Epoch 31::Minibatch 282::LR 0.0307692307692 --> Loss 0.00203863521417\n",
      "Epoch 31::Minibatch 283::LR 0.0307692307692 --> Loss 0.00194601158301\n",
      "Epoch 31::Minibatch 284::LR 0.0307692307692 --> Loss 0.00158570379019\n",
      "Epoch 31::Minibatch 285::LR 0.0307692307692 --> Loss 0.00113666007916\n",
      "Epoch 31::Minibatch 286::LR 0.0307692307692 --> Loss 0.00198119541009\n",
      "Epoch 31::Minibatch 287::LR 0.0307692307692 --> Loss 0.00195664763451\n",
      "Epoch 31::Minibatch 288::LR 0.0307692307692 --> Loss 0.0010654665033\n",
      "Epoch 31::Minibatch 289::LR 0.0307692307692 --> Loss 0.00156540989876\n",
      "Epoch 31::Minibatch 290::LR 0.0307692307692 --> Loss 0.0018593676885\n",
      "Epoch 31::Minibatch 291::LR 0.0307692307692 --> Loss 0.00166919986407\n",
      "Epoch 31::Minibatch 292::LR 0.0307692307692 --> Loss 0.000590135653814\n",
      "Epoch 31::Minibatch 293::LR 0.0307692307692 --> Loss 0.00149318714937\n",
      "Epoch 31::Minibatch 294::LR 0.0307692307692 --> Loss 0.00161314288775\n",
      "Epoch 31::Minibatch 295::LR 0.0307692307692 --> Loss 0.00188140014807\n",
      "Epoch 31::Minibatch 296::LR 0.0307692307692 --> Loss 0.00162624508142\n",
      "Epoch 31::Minibatch 297::LR 0.0307692307692 --> Loss 0.00142107158899\n",
      "Epoch 31::Minibatch 298::LR 0.0307692307692 --> Loss 0.00142307311296\n",
      "Epoch 31::Minibatch 299::LR 0.0307692307692 --> Loss 0.000814548929532\n",
      "Epoch 31::Minibatch 300::LR 0.0307692307692 --> Loss 0.00269527216752\n",
      "Epoch 31::Minibatch 301::LR 0.0307692307692 --> Loss 0.00260638852914\n",
      "Epoch 31::Minibatch 302::LR 0.0307692307692 --> Loss 0.00239151299\n",
      "Epoch 31::Minibatch 303::LR 0.0307692307692 --> Loss 0.000834844013055\n",
      "Epoch 31::Minibatch 304::LR 0.0307692307692 --> Loss 0.00294967492421\n",
      "Epoch 31::Minibatch 305::LR 0.0307692307692 --> Loss 0.00171288847923\n",
      "Epoch 31::Minibatch 306::LR 0.0307692307692 --> Loss 0.000939421157042\n",
      "Epoch 31::Minibatch 307::LR 0.0307692307692 --> Loss 0.00240413665771\n",
      "Epoch 31::Minibatch 308::LR 0.0307692307692 --> Loss 0.00202116429806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 309::LR 0.0307692307692 --> Loss 0.00104321966569\n",
      "Epoch 31::Minibatch 310::LR 0.0307692307692 --> Loss 0.00119189123313\n",
      "Epoch 31::Minibatch 311::LR 0.0307692307692 --> Loss 0.00179401814938\n",
      "Epoch 31::Minibatch 312::LR 0.0307692307692 --> Loss 0.0028574081262\n",
      "Epoch 31::Minibatch 313::LR 0.0307692307692 --> Loss 0.00234295169512\n",
      "Epoch 31::Minibatch 314::LR 0.0307692307692 --> Loss 0.00192401687304\n",
      "Epoch 31::Minibatch 315::LR 0.0307692307692 --> Loss 0.00104648470879\n",
      "Epoch 31::Minibatch 316::LR 0.0307692307692 --> Loss 0.00234480698903\n",
      "Epoch 31::Minibatch 317::LR 0.0307692307692 --> Loss 0.00156401773294\n",
      "Epoch 31::Minibatch 318::LR 0.0307692307692 --> Loss 0.00130494107803\n",
      "Epoch 31::Minibatch 319::LR 0.0307692307692 --> Loss 0.00230902552605\n",
      "Epoch 31::Minibatch 320::LR 0.0307692307692 --> Loss 0.00304405053457\n",
      "Epoch 31::Minibatch 321::LR 0.0307692307692 --> Loss 0.000842185119788\n",
      "Epoch 31::Minibatch 322::LR 0.0307692307692 --> Loss 0.00346505840619\n",
      "Epoch 31::Minibatch 323::LR 0.0307692307692 --> Loss 0.00342329541842\n",
      "Epoch 31::Minibatch 324::LR 0.0307692307692 --> Loss 0.00264935771624\n",
      "Epoch 31::Minibatch 325::LR 0.0307692307692 --> Loss 0.00237244427204\n",
      "Epoch 31::Minibatch 326::LR 0.0307692307692 --> Loss 0.00529943625132\n",
      "Epoch 31::Minibatch 327::LR 0.0307692307692 --> Loss 0.00223242998123\n",
      "Epoch 31::Minibatch 328::LR 0.0307692307692 --> Loss 0.00296591838201\n",
      "Epoch 31::Minibatch 329::LR 0.0307692307692 --> Loss 0.00119382242362\n",
      "Epoch 31::Minibatch 330::LR 0.0307692307692 --> Loss 0.00158916175365\n",
      "Epoch 31::Minibatch 331::LR 0.0307692307692 --> Loss 0.00253397067388\n",
      "Epoch 31::Minibatch 332::LR 0.0307692307692 --> Loss 0.0024562917153\n",
      "Epoch 31::Minibatch 333::LR 0.0307692307692 --> Loss 0.00146794478099\n",
      "Epoch 31::Minibatch 334::LR 0.0307692307692 --> Loss 0.00441260298093\n",
      "Epoch 31::Minibatch 335::LR 0.0307692307692 --> Loss 0.00189897358418\n",
      "Epoch 31::Minibatch 336::LR 0.0307692307692 --> Loss 0.00225530207157\n",
      "Epoch 31::Minibatch 337::LR 0.0307692307692 --> Loss 0.00371978640556\n",
      "Epoch 31::Minibatch 338::LR 0.0307692307692 --> Loss 0.000552881260713\n",
      "Epoch 31::Minibatch 339::LR 0.0307692307692 --> Loss 0.00325347761313\n",
      "Epoch 31::Minibatch 340::LR 0.0307692307692 --> Loss 0.00369896014531\n",
      "Epoch 31::Minibatch 341::LR 0.0307692307692 --> Loss 0.00433375875155\n",
      "Epoch 31::Minibatch 342::LR 0.0307692307692 --> Loss 0.00306098997593\n",
      "Epoch 31::Minibatch 343::LR 0.0307692307692 --> Loss 0.00164009253184\n",
      "Epoch 31::Minibatch 344::LR 0.0307692307692 --> Loss 0.00316105524699\n",
      "Epoch 31::Minibatch 345::LR 0.0307692307692 --> Loss 0.00409450252851\n",
      "Epoch 31::Minibatch 346::LR 0.0307692307692 --> Loss 0.00539004484812\n",
      "Epoch 31::Minibatch 347::LR 0.0307692307692 --> Loss 0.000817740956942\n",
      "Epoch 31::Minibatch 348::LR 0.0307692307692 --> Loss 0.00301955461502\n",
      "Epoch 31::Minibatch 349::LR 0.0307692307692 --> Loss 0.00337550083796\n",
      "Epoch 31::Minibatch 350::LR 0.0307692307692 --> Loss 0.00165140757958\n",
      "Epoch 31::Minibatch 351::LR 0.0307692307692 --> Loss 0.00343185663223\n",
      "Epoch 31::Minibatch 352::LR 0.0307692307692 --> Loss 0.00490837097168\n",
      "Epoch 31::Minibatch 353::LR 0.0307692307692 --> Loss 0.00350781003634\n",
      "Epoch 31::Minibatch 354::LR 0.0307692307692 --> Loss 0.00294246633848\n",
      "Epoch 31::Minibatch 355::LR 0.0307692307692 --> Loss 0.0062438984712\n",
      "Epoch 31::Minibatch 356::LR 0.0307692307692 --> Loss 0.00314939836661\n",
      "Epoch 31::Minibatch 357::LR 0.0307692307692 --> Loss 0.00116373479366\n",
      "Epoch 31::Minibatch 358::LR 0.0307692307692 --> Loss 0.00196160336336\n",
      "Epoch 31::Minibatch 359::LR 0.0307692307692 --> Loss 0.00267654299736\n",
      "Epoch 31::Minibatch 360::LR 0.0307692307692 --> Loss 0.00230385601521\n",
      "Epoch 31::Minibatch 361::LR 0.0307692307692 --> Loss 0.00227436920007\n",
      "Epoch 31::Minibatch 362::LR 0.0307692307692 --> Loss 0.00226077377796\n",
      "Epoch 31::Minibatch 363::LR 0.0307692307692 --> Loss 0.000637410332759\n",
      "Epoch 31::Minibatch 364::LR 0.0307692307692 --> Loss 0.00197258114815\n",
      "Epoch 31::Minibatch 365::LR 0.0307692307692 --> Loss 0.00200974245866\n",
      "Epoch 31::Minibatch 366::LR 0.0307692307692 --> Loss 0.0021296731631\n",
      "Epoch 31::Minibatch 367::LR 0.0307692307692 --> Loss 0.00100063959757\n",
      "Epoch 31::Minibatch 368::LR 0.0307692307692 --> Loss 0.000973830719789\n",
      "Epoch 31::Minibatch 369::LR 0.0307692307692 --> Loss 0.00277019321918\n",
      "Epoch 31::Minibatch 370::LR 0.0307692307692 --> Loss 0.00221330920855\n",
      "Epoch 31::Minibatch 371::LR 0.0307692307692 --> Loss 0.00184955100218\n",
      "Epoch 31::Minibatch 372::LR 0.0307692307692 --> Loss 0.000429072926442\n",
      "Epoch 31::Minibatch 373::LR 0.0307692307692 --> Loss 0.00180405437946\n",
      "Epoch 31::Minibatch 374::LR 0.0307692307692 --> Loss 0.0022498613596\n",
      "Epoch 31::Minibatch 375::LR 0.0307692307692 --> Loss 0.00188598752022\n",
      "Epoch 31::Minibatch 376::LR 0.0307692307692 --> Loss 0.00121066381534\n",
      "Epoch 31::Minibatch 377::LR 0.0307692307692 --> Loss 0.00191191871961\n",
      "Epoch 31::Minibatch 378::LR 0.0307692307692 --> Loss 0.00209581832091\n",
      "Epoch 31::Minibatch 379::LR 0.0307692307692 --> Loss 0.00232519169648\n",
      "Epoch 31::Minibatch 380::LR 0.0307692307692 --> Loss 0.00156574040651\n",
      "Epoch 31::Minibatch 381::LR 0.0307692307692 --> Loss 0.000992678701878\n",
      "Epoch 31::Minibatch 382::LR 0.0307692307692 --> Loss 0.00203372557958\n",
      "Epoch 31::Minibatch 383::LR 0.0307692307692 --> Loss 0.00198726197084\n",
      "Epoch 31::Minibatch 384::LR 0.0307692307692 --> Loss 0.00111415157715\n",
      "Epoch 31::Minibatch 385::LR 0.0307692307692 --> Loss 0.00105484296878\n",
      "Epoch 31::Minibatch 386::LR 0.0307692307692 --> Loss 0.00223964730899\n",
      "Epoch 31::Minibatch 387::LR 0.0307692307692 --> Loss 0.00236231009165\n",
      "Epoch 31::Minibatch 388::LR 0.0307692307692 --> Loss 0.00120920826991\n",
      "Epoch 31::Minibatch 389::LR 0.0307692307692 --> Loss 0.00178399980068\n",
      "Epoch 31::Minibatch 390::LR 0.0307692307692 --> Loss 0.00328457752864\n",
      "Epoch 31::Minibatch 391::LR 0.0307692307692 --> Loss 0.00256064971288\n",
      "Epoch 31::Minibatch 392::LR 0.0307692307692 --> Loss 0.00256128768126\n",
      "Epoch 31::Minibatch 393::LR 0.0307692307692 --> Loss 0.0027317327261\n",
      "Epoch 31::Minibatch 394::LR 0.0307692307692 --> Loss 0.00200983802478\n",
      "Epoch 31::Minibatch 395::LR 0.0307692307692 --> Loss 0.00206925312678\n",
      "Epoch 31::Minibatch 396::LR 0.0307692307692 --> Loss 0.00193707009157\n",
      "Epoch 31::Minibatch 397::LR 0.0307692307692 --> Loss 0.00207302431266\n",
      "Epoch 31::Minibatch 398::LR 0.0307692307692 --> Loss 0.00206181863944\n",
      "Epoch 31::Minibatch 399::LR 0.0307692307692 --> Loss 0.00236898779869\n",
      "Epoch 31::Minibatch 400::LR 0.0307692307692 --> Loss 0.00200613001982\n",
      "Epoch 31::Minibatch 401::LR 0.0307692307692 --> Loss 0.00340903043747\n",
      "Epoch 31::Minibatch 402::LR 0.0307692307692 --> Loss 0.00171869635582\n",
      "Epoch 31::Minibatch 403::LR 0.0307692307692 --> Loss 0.00142437299093\n",
      "Epoch 31::Minibatch 404::LR 0.0307692307692 --> Loss 0.00134253760179\n",
      "Epoch 31::Minibatch 405::LR 0.0307692307692 --> Loss 0.00333781798681\n",
      "Epoch 31::Minibatch 406::LR 0.0307692307692 --> Loss 0.00234193960826\n",
      "Epoch 31::Minibatch 407::LR 0.0307692307692 --> Loss 0.00170264879862\n",
      "Epoch 31::Minibatch 408::LR 0.0307692307692 --> Loss 0.000431601355473\n",
      "Epoch 31::Minibatch 409::LR 0.0307692307692 --> Loss 0.00221381862958\n",
      "Epoch 31::Minibatch 410::LR 0.0307692307692 --> Loss 0.00313192208608\n",
      "Epoch 31::Minibatch 411::LR 0.0307692307692 --> Loss 0.00165528386831\n",
      "Epoch 31::Minibatch 412::LR 0.0307692307692 --> Loss 0.000940342744191\n",
      "Epoch 31::Minibatch 413::LR 0.0307692307692 --> Loss 0.00196739097436\n",
      "Epoch 31::Minibatch 414::LR 0.0307692307692 --> Loss 0.00186630348365\n",
      "Epoch 31::Minibatch 415::LR 0.0307692307692 --> Loss 0.00116555879513\n",
      "Epoch 31::Minibatch 416::LR 0.0307692307692 --> Loss 0.000788993239403\n",
      "Epoch 31::Minibatch 417::LR 0.0307692307692 --> Loss 0.00167366226514\n",
      "Epoch 31::Minibatch 418::LR 0.0307692307692 --> Loss 0.00259008924166\n",
      "Epoch 31::Minibatch 419::LR 0.0307692307692 --> Loss 0.000488680203756\n",
      "Epoch 31::Minibatch 420::LR 0.0307692307692 --> Loss 0.000686761538188\n",
      "Epoch 31::Minibatch 421::LR 0.0307692307692 --> Loss 0.00186925292015\n",
      "Epoch 31::Minibatch 422::LR 0.0307692307692 --> Loss 0.00205902119478\n",
      "Epoch 31::Minibatch 423::LR 0.0307692307692 --> Loss 0.000978689392408\n",
      "Epoch 31::Minibatch 424::LR 0.0307692307692 --> Loss 0.00151501268148\n",
      "Epoch 31::Minibatch 425::LR 0.0307692307692 --> Loss 0.00286331117153\n",
      "Epoch 31::Minibatch 426::LR 0.0307692307692 --> Loss 0.00198512514432\n",
      "Epoch 31::Minibatch 427::LR 0.0307692307692 --> Loss 0.000729570239782\n",
      "Epoch 31::Minibatch 428::LR 0.0307692307692 --> Loss 0.000938493311405\n",
      "Epoch 31::Minibatch 429::LR 0.0307692307692 --> Loss 0.00224318146706\n",
      "Epoch 31::Minibatch 430::LR 0.0307692307692 --> Loss 0.00801541805267\n",
      "Epoch 31::Minibatch 431::LR 0.0307692307692 --> Loss 0.00359365304311\n",
      "Epoch 31::Minibatch 432::LR 0.0307692307692 --> Loss 0.00403894066811\n",
      "Epoch 31::Minibatch 433::LR 0.0307692307692 --> Loss 0.0025301194191\n",
      "Epoch 31::Minibatch 434::LR 0.0307692307692 --> Loss 0.00244390090307\n",
      "Epoch 31::Minibatch 435::LR 0.0307692307692 --> Loss 0.00224972565969\n",
      "Epoch 31::Minibatch 436::LR 0.0307692307692 --> Loss 0.00159726997217\n",
      "Epoch 31::Minibatch 437::LR 0.0307692307692 --> Loss 0.00283288061619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 438::LR 0.0307692307692 --> Loss 0.00227723558744\n",
      "Epoch 31::Minibatch 439::LR 0.0307692307692 --> Loss 0.0019228108724\n",
      "Epoch 31::Minibatch 440::LR 0.0307692307692 --> Loss 0.00297216494878\n",
      "Epoch 31::Minibatch 441::LR 0.0307692307692 --> Loss 0.00277745405833\n",
      "Epoch 31::Minibatch 442::LR 0.0307692307692 --> Loss 0.0024876032273\n",
      "Epoch 31::Minibatch 443::LR 0.0307692307692 --> Loss 0.00345906098684\n",
      "Epoch 31::Minibatch 444::LR 0.0307692307692 --> Loss 0.00267155031363\n",
      "Epoch 31::Minibatch 445::LR 0.0307692307692 --> Loss 0.000847324430943\n",
      "Epoch 31::Minibatch 446::LR 0.0307692307692 --> Loss 0.00136304001013\n",
      "Epoch 31::Minibatch 447::LR 0.0307692307692 --> Loss 0.0022883049647\n",
      "Epoch 31::Minibatch 448::LR 0.0307692307692 --> Loss 0.0023075824976\n",
      "Epoch 31::Minibatch 449::LR 0.0307692307692 --> Loss 0.00356580893199\n",
      "Epoch 31::Minibatch 450::LR 0.0307692307692 --> Loss 0.00212963064512\n",
      "Epoch 31::Minibatch 451::LR 0.0307692307692 --> Loss 0.00382748126984\n",
      "Epoch 31::Minibatch 452::LR 0.0307692307692 --> Loss 0.00229057073593\n",
      "Epoch 31::Minibatch 453::LR 0.0307692307692 --> Loss 0.000349114537239\n",
      "Epoch 31::Minibatch 454::LR 0.0307692307692 --> Loss 0.00343017776807\n",
      "Epoch 31::Minibatch 455::LR 0.0307692307692 --> Loss 0.00258311390877\n",
      "Epoch 31::Minibatch 456::LR 0.0307692307692 --> Loss 0.00304245014985\n",
      "Epoch 31::Minibatch 457::LR 0.0307692307692 --> Loss 0.001872001489\n",
      "Epoch 31::Minibatch 458::LR 0.0307692307692 --> Loss 0.000714503477017\n",
      "Epoch 31::Minibatch 459::LR 0.0307692307692 --> Loss 0.00384316364924\n",
      "Epoch 31::Minibatch 460::LR 0.0307692307692 --> Loss 0.00242730617523\n",
      "Epoch 31::Minibatch 461::LR 0.0307692307692 --> Loss 0.00368466774623\n",
      "Epoch 31::Minibatch 462::LR 0.0307692307692 --> Loss 0.00036940480272\n",
      "Epoch 31::Minibatch 463::LR 0.0307692307692 --> Loss 0.00412228186925\n",
      "Epoch 31::Minibatch 464::LR 0.0307692307692 --> Loss 0.00194467882315\n",
      "Epoch 31::Minibatch 465::LR 0.0307692307692 --> Loss 0.00453834891319\n",
      "Epoch 31::Minibatch 466::LR 0.0307692307692 --> Loss 0.00495478630066\n",
      "Epoch 31::Minibatch 467::LR 0.0307692307692 --> Loss 0.00508480151494\n",
      "Epoch 31::Minibatch 468::LR 0.0307692307692 --> Loss 0.00565677762032\n",
      "Epoch 31::Minibatch 469::LR 0.0307692307692 --> Loss 0.00599115808805\n",
      "Epoch 31::Minibatch 470::LR 0.0307692307692 --> Loss 0.00357240517934\n",
      "Epoch 31::Minibatch 471::LR 0.0307692307692 --> Loss 0.00166246493657\n",
      "Epoch 31::Minibatch 472::LR 0.0307692307692 --> Loss 0.0035566953818\n",
      "Epoch 31::Minibatch 473::LR 0.0307692307692 --> Loss 0.00230453888575\n",
      "Epoch 31::Minibatch 474::LR 0.0307692307692 --> Loss 0.000689418862263\n",
      "Epoch 31::Minibatch 475::LR 0.0307692307692 --> Loss 0.00478410204252\n",
      "Epoch 31::Minibatch 476::LR 0.0307692307692 --> Loss 0.00762438138326\n",
      "Epoch 31::Minibatch 477::LR 0.0307692307692 --> Loss 0.000915834903717\n",
      "Epoch 31::Minibatch 478::LR 0.0307692307692 --> Loss 0.00240825037162\n",
      "Epoch 31::Minibatch 479::LR 0.0307692307692 --> Loss 0.00195950130622\n",
      "Epoch 31::Minibatch 480::LR 0.0307692307692 --> Loss 0.00151338398457\n",
      "Epoch 31::Minibatch 481::LR 0.0307692307692 --> Loss 0.000957733988762\n",
      "Epoch 31::Minibatch 482::LR 0.0307692307692 --> Loss 0.00206727763017\n",
      "Epoch 31::Minibatch 483::LR 0.0307692307692 --> Loss 0.00302262862523\n",
      "Epoch 31::Minibatch 484::LR 0.0307692307692 --> Loss 0.003393526872\n",
      "Epoch 31::Minibatch 485::LR 0.0307692307692 --> Loss 0.000761040151119\n",
      "Epoch 31::Minibatch 486::LR 0.0307692307692 --> Loss 0.00281103273233\n",
      "Epoch 31::Minibatch 487::LR 0.0307692307692 --> Loss 0.00329466323058\n",
      "Epoch 31::Minibatch 488::LR 0.0307692307692 --> Loss 0.00201924403509\n",
      "Epoch 31::Minibatch 489::LR 0.0307692307692 --> Loss 0.00307359238466\n",
      "Epoch 31::Minibatch 490::LR 0.0307692307692 --> Loss 0.000411731575926\n",
      "Epoch 31::Minibatch 491::LR 0.0307692307692 --> Loss 0.00321684598923\n",
      "Epoch 31::Minibatch 492::LR 0.0307692307692 --> Loss 0.00306342204412\n",
      "Epoch 31::Minibatch 493::LR 0.0307692307692 --> Loss 0.00301873068015\n",
      "Epoch 31::Minibatch 494::LR 0.0307692307692 --> Loss 0.00073283140858\n",
      "Epoch 31::Minibatch 495::LR 0.0307692307692 --> Loss 0.0018282443285\n",
      "Epoch 31::Minibatch 496::LR 0.0307692307692 --> Loss 0.00278258959452\n",
      "Epoch 31::Minibatch 497::LR 0.0307692307692 --> Loss 0.000914517045021\n",
      "Epoch 31::Minibatch 498::LR 0.0307692307692 --> Loss 0.000549954821666\n",
      "Epoch 31::Minibatch 499::LR 0.0307692307692 --> Loss 0.0034087340037\n",
      "Epoch 31::Minibatch 500::LR 0.0307692307692 --> Loss 0.00142537673314\n",
      "Epoch 31::Minibatch 501::LR 0.0307692307692 --> Loss 0.00203957994779\n",
      "Epoch 31::Minibatch 502::LR 0.0307692307692 --> Loss 0.00373790105184\n",
      "Epoch 31::Minibatch 503::LR 0.0307692307692 --> Loss 0.00681193033854\n",
      "Epoch 31::Minibatch 504::LR 0.0307692307692 --> Loss 0.00672937870026\n",
      "Epoch 31::Minibatch 505::LR 0.0307692307692 --> Loss 0.0039557603995\n",
      "Epoch 31::Minibatch 506::LR 0.0307692307692 --> Loss 0.003310983181\n",
      "Epoch 31::Minibatch 507::LR 0.0307692307692 --> Loss 0.00575434843699\n",
      "Epoch 31::Minibatch 508::LR 0.0307692307692 --> Loss 0.00338632464409\n",
      "Epoch 31::Minibatch 509::LR 0.0307692307692 --> Loss 0.00424857735634\n",
      "Epoch 31::Minibatch 510::LR 0.0307692307692 --> Loss 0.00438737193743\n",
      "Epoch 31::Minibatch 511::LR 0.0307692307692 --> Loss 0.00399159789085\n",
      "Epoch 31::Minibatch 512::LR 0.0307692307692 --> Loss 0.00268070538839\n",
      "Epoch 31::Minibatch 513::LR 0.0307692307692 --> Loss 0.000598106235266\n",
      "Epoch 31::Minibatch 514::LR 0.0307692307692 --> Loss 0.00263091961543\n",
      "Epoch 31::Minibatch 515::LR 0.0307692307692 --> Loss 0.00299113353093\n",
      "Epoch 31::Minibatch 516::LR 0.0307692307692 --> Loss 0.00391421477\n",
      "Epoch 31::Minibatch 517::LR 0.0307692307692 --> Loss 0.00361521760623\n",
      "Epoch 31::Minibatch 518::LR 0.0307692307692 --> Loss 0.0025754237175\n",
      "Epoch 31::Minibatch 519::LR 0.0307692307692 --> Loss 0.00353977203369\n",
      "Epoch 31::Minibatch 520::LR 0.0307692307692 --> Loss 0.00555552522341\n",
      "Epoch 31::Minibatch 521::LR 0.0307692307692 --> Loss 0.00562011043231\n",
      "Epoch 31::Minibatch 522::LR 0.0307692307692 --> Loss 0.00717686891556\n",
      "Epoch 31::Minibatch 523::LR 0.0307692307692 --> Loss 0.000623276084661\n",
      "Epoch 31::Minibatch 524::LR 0.0307692307692 --> Loss 0.00139174272617\n",
      "Epoch 31::Minibatch 525::LR 0.0307692307692 --> Loss 0.00305946826935\n",
      "Epoch 31::Minibatch 526::LR 0.0307692307692 --> Loss 0.00371604601542\n",
      "Epoch 31::Minibatch 527::LR 0.0307692307692 --> Loss 0.00212946573893\n",
      "Epoch 31::Minibatch 528::LR 0.0307692307692 --> Loss 0.000929543276628\n",
      "Epoch 31::Minibatch 529::LR 0.0307692307692 --> Loss 0.00382361491521\n",
      "Epoch 31::Minibatch 530::LR 0.0307692307692 --> Loss 0.00380674242973\n",
      "Epoch 31::Minibatch 531::LR 0.0307692307692 --> Loss 0.00338619748751\n",
      "Epoch 31::Minibatch 532::LR 0.0307692307692 --> Loss 0.00260047813257\n",
      "Epoch 31::Minibatch 533::LR 0.0307692307692 --> Loss 0.00489443500837\n",
      "Epoch 31::Minibatch 534::LR 0.0307692307692 --> Loss 0.00368661085765\n",
      "Epoch 31::Minibatch 535::LR 0.0307692307692 --> Loss 0.00331496695677\n",
      "Epoch 31::Minibatch 536::LR 0.0307692307692 --> Loss 0.00210487882296\n",
      "Epoch 31::Minibatch 537::LR 0.0307692307692 --> Loss 0.000584814200799\n",
      "Epoch 31::Minibatch 538::LR 0.0307692307692 --> Loss 0.00163401563962\n",
      "Epoch 31::Minibatch 539::LR 0.0307692307692 --> Loss 0.00331612706184\n",
      "Epoch 31::Minibatch 540::LR 0.0307692307692 --> Loss 0.00338747223218\n",
      "Epoch 31::Minibatch 541::LR 0.0307692307692 --> Loss 0.00284171481927\n",
      "Epoch 31::Minibatch 542::LR 0.0307692307692 --> Loss 0.00243756274382\n",
      "Epoch 31::Minibatch 543::LR 0.0307692307692 --> Loss 0.00257586518923\n",
      "Epoch 31::Minibatch 544::LR 0.0307692307692 --> Loss 0.00401809374491\n",
      "Epoch 31::Minibatch 545::LR 0.0307692307692 --> Loss 0.00197600622972\n",
      "Epoch 31::Minibatch 546::LR 0.0307692307692 --> Loss 0.000659334162871\n",
      "Epoch 31::Minibatch 547::LR 0.0307692307692 --> Loss 0.00257925848166\n",
      "Epoch 31::Minibatch 548::LR 0.0307692307692 --> Loss 0.00340753237406\n",
      "Epoch 31::Minibatch 549::LR 0.0307692307692 --> Loss 0.0088397248586\n",
      "Epoch 31::Minibatch 550::LR 0.0307692307692 --> Loss 0.00118411471446\n",
      "Epoch 31::Minibatch 551::LR 0.0307692307692 --> Loss 0.00245789845785\n",
      "Epoch 31::Minibatch 552::LR 0.0307692307692 --> Loss 0.00343292713165\n",
      "Epoch 31::Minibatch 553::LR 0.0307692307692 --> Loss 0.00296786904335\n",
      "Epoch 31::Minibatch 554::LR 0.0307692307692 --> Loss 0.00362897674243\n",
      "Epoch 31::Minibatch 555::LR 0.0307692307692 --> Loss 0.000941613813241\n",
      "Epoch 31::Minibatch 556::LR 0.0307692307692 --> Loss 0.00191960434119\n",
      "Epoch 31::Minibatch 557::LR 0.0307692307692 --> Loss 0.00240783452988\n",
      "Epoch 31::Minibatch 558::LR 0.0307692307692 --> Loss 0.00358900348345\n",
      "Epoch 31::Minibatch 559::LR 0.0307692307692 --> Loss 0.00365296959877\n",
      "Epoch 31::Minibatch 560::LR 0.0307692307692 --> Loss 0.00305351257324\n",
      "Epoch 31::Minibatch 561::LR 0.0307692307692 --> Loss 0.00262192130089\n",
      "Epoch 31::Minibatch 562::LR 0.0307692307692 --> Loss 0.00233912169933\n",
      "Epoch 31::Minibatch 563::LR 0.0307692307692 --> Loss 0.00396584788958\n",
      "Epoch 31::Minibatch 564::LR 0.0307692307692 --> Loss 0.00304155051708\n",
      "Epoch 31::Minibatch 565::LR 0.0307692307692 --> Loss 0.00357749025027\n",
      "Epoch 31::Minibatch 566::LR 0.0307692307692 --> Loss 0.00217670838038\n",
      "Epoch 31::Minibatch 567::LR 0.0307692307692 --> Loss 0.00253589471181\n",
      "Epoch 31::Minibatch 568::LR 0.0307692307692 --> Loss 0.00173723598321\n",
      "Epoch 31::Minibatch 569::LR 0.0307692307692 --> Loss 0.000560323596001\n",
      "Epoch 31::Minibatch 570::LR 0.0307692307692 --> Loss 0.00162123262882\n",
      "Epoch 31::Minibatch 571::LR 0.0307692307692 --> Loss 0.00205627481143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 572::LR 0.0307692307692 --> Loss 0.00221297880014\n",
      "Epoch 31::Minibatch 573::LR 0.0307692307692 --> Loss 0.00143733024597\n",
      "Epoch 31::Minibatch 574::LR 0.0307692307692 --> Loss 0.00104338824749\n",
      "Epoch 31::Minibatch 575::LR 0.0307692307692 --> Loss 0.001714955767\n",
      "Epoch 31::Minibatch 576::LR 0.0307692307692 --> Loss 0.00202793816725\n",
      "Epoch 31::Minibatch 577::LR 0.0307692307692 --> Loss 0.00160548885663\n",
      "Epoch 31::Minibatch 578::LR 0.0307692307692 --> Loss 0.00126188705365\n",
      "Epoch 31::Minibatch 579::LR 0.0307692307692 --> Loss 0.00118090917667\n",
      "Epoch 31::Minibatch 580::LR 0.0307692307692 --> Loss 0.00191753923893\n",
      "Epoch 31::Minibatch 581::LR 0.0307692307692 --> Loss 0.00170354088147\n",
      "Epoch 31::Minibatch 582::LR 0.0307692307692 --> Loss 0.00418413996696\n",
      "Epoch 31::Minibatch 583::LR 0.0307692307692 --> Loss 0.000952068169912\n",
      "Epoch 31::Minibatch 584::LR 0.0307692307692 --> Loss 0.0013086438179\n",
      "Epoch 31::Minibatch 585::LR 0.0307692307692 --> Loss 0.00393343011538\n",
      "Epoch 31::Minibatch 586::LR 0.0307692307692 --> Loss 0.00373677213987\n",
      "Epoch 31::Minibatch 587::LR 0.0307692307692 --> Loss 0.00111216644446\n",
      "Epoch 31::Minibatch 588::LR 0.0307692307692 --> Loss 0.00137001881997\n",
      "Epoch 31::Minibatch 589::LR 0.0307692307692 --> Loss 0.00273394505183\n",
      "Epoch 31::Minibatch 590::LR 0.0307692307692 --> Loss 0.00179939548175\n",
      "Epoch 31::Minibatch 591::LR 0.0307692307692 --> Loss 0.00270331044992\n",
      "Epoch 31::Minibatch 592::LR 0.0307692307692 --> Loss 0.00114929993947\n",
      "Epoch 31::Minibatch 593::LR 0.0307692307692 --> Loss 0.00246289730072\n",
      "Epoch 31::Minibatch 594::LR 0.0307692307692 --> Loss 0.00255896290143\n",
      "Epoch 31::Minibatch 595::LR 0.0307692307692 --> Loss 0.00303865333398\n",
      "Epoch 31::Minibatch 596::LR 0.0307692307692 --> Loss 0.00183954358101\n",
      "Epoch 31::Minibatch 597::LR 0.0307692307692 --> Loss 0.00116573244333\n",
      "Epoch 31::Minibatch 598::LR 0.0307692307692 --> Loss 0.0028031339248\n",
      "Epoch 31::Minibatch 599::LR 0.0307692307692 --> Loss 0.00178915023804\n",
      "Epoch 31::Minibatch 600::LR 0.0307692307692 --> Loss 0.00212289532026\n",
      "Epoch 31::Minibatch 601::LR 0.0307692307692 --> Loss 0.00372808376948\n",
      "Epoch 31::Minibatch 602::LR 0.0307692307692 --> Loss 0.00208173394203\n",
      "Epoch 31::Minibatch 603::LR 0.0307692307692 --> Loss 0.00261447827021\n",
      "Epoch 31::Minibatch 604::LR 0.0307692307692 --> Loss 0.00162665049235\n",
      "Epoch 31::Minibatch 605::LR 0.0307692307692 --> Loss 0.00227708339691\n",
      "Epoch 31::Minibatch 606::LR 0.0307692307692 --> Loss 0.00185139318307\n",
      "Epoch 31::Minibatch 607::LR 0.0307692307692 --> Loss 0.000824655294418\n",
      "Epoch 31::Minibatch 608::LR 0.0307692307692 --> Loss 0.00155007859071\n",
      "Epoch 31::Minibatch 609::LR 0.0307692307692 --> Loss 0.00241795996825\n",
      "Epoch 31::Minibatch 610::LR 0.0307692307692 --> Loss 0.00403612335523\n",
      "Epoch 31::Minibatch 611::LR 0.0307692307692 --> Loss 0.0026636081934\n",
      "Epoch 31::Minibatch 612::LR 0.0307692307692 --> Loss 0.000470387836297\n",
      "Epoch 31::Minibatch 613::LR 0.0307692307692 --> Loss 0.00131045420965\n",
      "Epoch 31::Minibatch 614::LR 0.0307692307692 --> Loss 0.00240196406841\n",
      "Epoch 31::Minibatch 615::LR 0.0307692307692 --> Loss 0.00165115316709\n",
      "Epoch 31::Minibatch 616::LR 0.0307692307692 --> Loss 0.000915262798468\n",
      "Epoch 31::Minibatch 617::LR 0.0307692307692 --> Loss 0.000491505265236\n",
      "Epoch 31::Minibatch 618::LR 0.0307692307692 --> Loss 0.00287730256716\n",
      "Epoch 31::Minibatch 619::LR 0.0307692307692 --> Loss 0.0019271761179\n",
      "Epoch 31::Minibatch 620::LR 0.0307692307692 --> Loss 0.00168779353301\n",
      "Epoch 31::Minibatch 621::LR 0.0307692307692 --> Loss 0.000844770371914\n",
      "Epoch 31::Minibatch 622::LR 0.0307692307692 --> Loss 0.000779812435309\n",
      "Epoch 31::Minibatch 623::LR 0.0307692307692 --> Loss 0.00221615294615\n",
      "Epoch 31::Minibatch 624::LR 0.0307692307692 --> Loss 0.00176858067513\n",
      "Epoch 31::Minibatch 625::LR 0.0307692307692 --> Loss 0.00266453246276\n",
      "Epoch 31::Minibatch 626::LR 0.0307692307692 --> Loss 0.0036181807518\n",
      "Epoch 31::Minibatch 627::LR 0.0307692307692 --> Loss 0.00126865635316\n",
      "Epoch 31::Minibatch 628::LR 0.0307692307692 --> Loss 0.000876787006855\n",
      "Epoch 31::Minibatch 629::LR 0.0307692307692 --> Loss 0.00307792544365\n",
      "Epoch 31::Minibatch 630::LR 0.0307692307692 --> Loss 0.00301240722338\n",
      "Epoch 31::Minibatch 631::LR 0.0307692307692 --> Loss 0.0051856970787\n",
      "Epoch 31::Minibatch 632::LR 0.0307692307692 --> Loss 0.000793007711569\n",
      "Epoch 31::Minibatch 633::LR 0.0307692307692 --> Loss 0.00161630024513\n",
      "Epoch 31::Minibatch 634::LR 0.0307692307692 --> Loss 0.00318152983983\n",
      "Epoch 31::Minibatch 635::LR 0.0307692307692 --> Loss 0.00542636712392\n",
      "Epoch 31::Minibatch 636::LR 0.0307692307692 --> Loss 0.0045818622907\n",
      "Epoch 31::Minibatch 637::LR 0.0307692307692 --> Loss 0.000713778585196\n",
      "Epoch 31::Minibatch 638::LR 0.0307692307692 --> Loss 0.00148367583752\n",
      "Epoch 31::Minibatch 639::LR 0.0307692307692 --> Loss 0.00318130493164\n",
      "Epoch 31::Minibatch 640::LR 0.0307692307692 --> Loss 0.00456311186155\n",
      "Epoch 31::Minibatch 641::LR 0.0307692307692 --> Loss 0.00303586562475\n",
      "Epoch 31::Minibatch 642::LR 0.0307692307692 --> Loss 0.000532091160615\n",
      "Epoch 31::Minibatch 643::LR 0.0307692307692 --> Loss 0.00230828563372\n",
      "Epoch 31::Minibatch 644::LR 0.0307692307692 --> Loss 0.0038620865345\n",
      "Epoch 31::Minibatch 645::LR 0.0307692307692 --> Loss 0.00444421688716\n",
      "Epoch 31::Minibatch 646::LR 0.0307692307692 --> Loss 0.00150364051263\n",
      "Epoch 31::Minibatch 647::LR 0.0307692307692 --> Loss 0.00046672090888\n",
      "Epoch 31::Minibatch 648::LR 0.0307692307692 --> Loss 0.00276200671991\n",
      "Epoch 31::Minibatch 649::LR 0.0307692307692 --> Loss 0.00321478704611\n",
      "Epoch 31::Minibatch 650::LR 0.0307692307692 --> Loss 0.00316006978353\n",
      "Epoch 31::Minibatch 651::LR 0.0307692307692 --> Loss 0.00132808188597\n",
      "Epoch 31::Minibatch 652::LR 0.0307692307692 --> Loss 0.000777426858743\n",
      "Epoch 31::Minibatch 653::LR 0.0307692307692 --> Loss 0.00280021389325\n",
      "Epoch 31::Minibatch 654::LR 0.0307692307692 --> Loss 0.00312058726947\n",
      "Epoch 31::Minibatch 655::LR 0.0307692307692 --> Loss 0.00362468322118\n",
      "Epoch 31::Minibatch 656::LR 0.0307692307692 --> Loss 0.000755138993263\n",
      "Epoch 31::Minibatch 657::LR 0.0307692307692 --> Loss 0.00226593474547\n",
      "Epoch 31::Minibatch 658::LR 0.0307692307692 --> Loss 0.00450588226318\n",
      "Epoch 31::Minibatch 659::LR 0.0307692307692 --> Loss 0.00221396128337\n",
      "Epoch 31::Minibatch 660::LR 0.0307692307692 --> Loss 0.00263953169187\n",
      "Epoch 31::Minibatch 661::LR 0.0307692307692 --> Loss 0.00227467616399\n",
      "Epoch 31::Minibatch 662::LR 0.0307692307692 --> Loss 0.00179290572802\n",
      "Epoch 31::Minibatch 663::LR 0.0307692307692 --> Loss 0.00366615096728\n",
      "Epoch 31::Minibatch 664::LR 0.0307692307692 --> Loss 0.00316190520922\n",
      "Epoch 31::Minibatch 665::LR 0.0307692307692 --> Loss 0.000696423004071\n",
      "Epoch 31::Minibatch 666::LR 0.0307692307692 --> Loss 0.0039042143027\n",
      "Epoch 31::Minibatch 667::LR 0.0307692307692 --> Loss 0.00254085938136\n",
      "Epoch 31::Minibatch 668::LR 0.0307692307692 --> Loss 0.00633686979612\n",
      "Epoch 31::Minibatch 669::LR 0.0307692307692 --> Loss 0.00108346819878\n",
      "Epoch 31::Minibatch 670::LR 0.0307692307692 --> Loss 0.00132865011692\n",
      "Epoch 31::Minibatch 671::LR 0.0307692307692 --> Loss 0.00508570949237\n",
      "Epoch 31::Minibatch 672::LR 0.0307692307692 --> Loss 0.00339517235756\n",
      "Epoch 31::Minibatch 673::LR 0.0307692307692 --> Loss 0.00160333037376\n",
      "Epoch 31::Minibatch 674::LR 0.0307692307692 --> Loss 0.000509752283494\n",
      "Epoch 31::Minibatch 675::LR 0.0307692307692 --> Loss 0.00219478448232\n",
      "Epoch 31::Minibatch 676::LR 0.0307692307692 --> Loss 0.00215474545956\n",
      "Epoch 31::Minibatch 677::LR 0.0307692307692 --> Loss 0.00270590742429\n",
      "Epoch 31::Minibatch 678::LR 0.0307692307692 --> Loss 0.0018660179774\n",
      "Epoch 31::Minibatch 679::LR 0.0307692307692 --> Loss 0.0033164636294\n",
      "Epoch 31::Minibatch 680::LR 0.0307692307692 --> Loss 0.00212226947149\n",
      "Epoch 31::Minibatch 681::LR 0.0307692307692 --> Loss 0.00238455494245\n",
      "Epoch 31::Minibatch 682::LR 0.0307692307692 --> Loss 0.000761803338925\n",
      "Epoch 31::Minibatch 683::LR 0.0307692307692 --> Loss 0.00230773111184\n",
      "Epoch 31::Minibatch 684::LR 0.0307692307692 --> Loss 0.0023389784495\n",
      "Epoch 31::Minibatch 685::LR 0.0307692307692 --> Loss 0.00282040119171\n",
      "Epoch 31::Minibatch 686::LR 0.0307692307692 --> Loss 0.001582566003\n",
      "Epoch 31::Minibatch 687::LR 0.0307692307692 --> Loss 0.000876600444317\n",
      "Epoch 31::Minibatch 688::LR 0.0307692307692 --> Loss 0.00279933154583\n",
      "Epoch 31::Minibatch 689::LR 0.0307692307692 --> Loss 0.00247003038724\n",
      "Epoch 31::Minibatch 690::LR 0.0307692307692 --> Loss 0.00187873999278\n",
      "Epoch 31::Minibatch 691::LR 0.0307692307692 --> Loss 0.000657773415248\n",
      "Epoch 31::Minibatch 692::LR 0.0307692307692 --> Loss 0.00244256556034\n",
      "Epoch 31::Minibatch 693::LR 0.0307692307692 --> Loss 0.00261143843333\n",
      "Epoch 31::Minibatch 694::LR 0.0307692307692 --> Loss 0.00299315909545\n",
      "Epoch 31::Minibatch 695::LR 0.0307692307692 --> Loss 0.00179315149784\n",
      "Epoch 31::Minibatch 696::LR 0.0307692307692 --> Loss 0.00203120609125\n",
      "Epoch 31::Minibatch 697::LR 0.0307692307692 --> Loss 0.00139941116174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 698::LR 0.0307692307692 --> Loss 0.00166105349859\n",
      "Epoch 31::Minibatch 699::LR 0.0307692307692 --> Loss 0.00370660702387\n",
      "Epoch 31::Minibatch 700::LR 0.0307692307692 --> Loss 0.00257840494315\n",
      "Epoch 31::Minibatch 701::LR 0.0307692307692 --> Loss 0.0018897330761\n",
      "Epoch 31::Minibatch 702::LR 0.0307692307692 --> Loss 0.00166644146045\n",
      "Epoch 31::Minibatch 703::LR 0.0307692307692 --> Loss 0.0043089667956\n",
      "Epoch 31::Minibatch 704::LR 0.0307692307692 --> Loss 0.00180339694023\n",
      "Epoch 31::Minibatch 705::LR 0.0307692307692 --> Loss 0.00283997019132\n",
      "Epoch 31::Minibatch 706::LR 0.0307692307692 --> Loss 0.00220484793186\n",
      "Epoch 31::Minibatch 707::LR 0.0307692307692 --> Loss 0.00117925186952\n",
      "Epoch 31::Minibatch 708::LR 0.0307692307692 --> Loss 0.00173044979572\n",
      "Epoch 31::Minibatch 709::LR 0.0307692307692 --> Loss 0.00167036175728\n",
      "Epoch 31::Minibatch 710::LR 0.0307692307692 --> Loss 0.00258180916309\n",
      "Epoch 31::Minibatch 711::LR 0.0307692307692 --> Loss 0.00197298308214\n",
      "Epoch 31::Minibatch 712::LR 0.0307692307692 --> Loss 0.00135988632838\n",
      "Epoch 31::Minibatch 713::LR 0.0307692307692 --> Loss 0.00179424782594\n",
      "Epoch 31::Minibatch 714::LR 0.0307692307692 --> Loss 0.00285850346088\n",
      "Epoch 31::Minibatch 715::LR 0.0307692307692 --> Loss 0.00292540172736\n",
      "Epoch 31::Minibatch 716::LR 0.0307692307692 --> Loss 0.00166110694408\n",
      "Epoch 31::Minibatch 717::LR 0.0307692307692 --> Loss 0.00166592260202\n",
      "Epoch 31::Minibatch 718::LR 0.0307692307692 --> Loss 0.00127862552802\n",
      "Epoch 31::Minibatch 719::LR 0.0307692307692 --> Loss 0.00172348082066\n",
      "Epoch 31::Minibatch 720::LR 0.0307692307692 --> Loss 0.00275129536788\n",
      "Epoch 31::Minibatch 721::LR 0.0307692307692 --> Loss 0.000604911247889\n",
      "Epoch 31::Minibatch 722::LR 0.0307692307692 --> Loss 0.0046024219195\n",
      "Epoch 31::Minibatch 723::LR 0.0307692307692 --> Loss 0.00482571601868\n",
      "Epoch 31::Minibatch 724::LR 0.0307692307692 --> Loss 0.000964686771234\n",
      "Epoch 31::Minibatch 725::LR 0.0307692307692 --> Loss 0.00206050197283\n",
      "Epoch 31::Minibatch 726::LR 0.0307692307692 --> Loss 0.00368924299876\n",
      "Epoch 31::Minibatch 727::LR 0.0307692307692 --> Loss 0.00307035942872\n",
      "Epoch 31::Minibatch 728::LR 0.0307692307692 --> Loss 0.000641115307808\n",
      "Epoch 31::Minibatch 729::LR 0.0307692307692 --> Loss 0.000718251417081\n",
      "Epoch 31::Minibatch 730::LR 0.0307692307692 --> Loss 0.00291074812412\n",
      "Epoch 31::Minibatch 731::LR 0.0307692307692 --> Loss 0.00261366466681\n",
      "Epoch 31::Minibatch 732::LR 0.0307692307692 --> Loss 0.00204611043135\n",
      "Epoch 31::Minibatch 733::LR 0.0307692307692 --> Loss 0.000598571697871\n",
      "Epoch 31::Minibatch 734::LR 0.0307692307692 --> Loss 0.00164475500584\n",
      "Epoch 31::Minibatch 735::LR 0.0307692307692 --> Loss 0.0024702201287\n",
      "Epoch 31::Minibatch 736::LR 0.0307692307692 --> Loss 0.0034754439195\n",
      "Epoch 31::Minibatch 737::LR 0.0307692307692 --> Loss 0.00293068190416\n",
      "Epoch 31::Minibatch 738::LR 0.0307692307692 --> Loss 0.00140098710855\n",
      "Epoch 31::Minibatch 739::LR 0.0307692307692 --> Loss 0.00238406519095\n",
      "Epoch 31::Minibatch 740::LR 0.0307692307692 --> Loss 0.00376410603523\n",
      "Epoch 31::Minibatch 741::LR 0.0307692307692 --> Loss 0.0025308885177\n",
      "Epoch 31::Minibatch 742::LR 0.0307692307692 --> Loss 0.00207777937253\n",
      "Epoch 31::Minibatch 743::LR 0.0307692307692 --> Loss 0.00150305718184\n",
      "Epoch 31::Minibatch 744::LR 0.0307692307692 --> Loss 0.0018688694636\n",
      "Epoch 31::Minibatch 745::LR 0.0307692307692 --> Loss 0.00277172942956\n",
      "Epoch 31::Minibatch 746::LR 0.0307692307692 --> Loss 0.00285051564376\n",
      "Epoch 31::Minibatch 747::LR 0.0307692307692 --> Loss 0.00175887147586\n",
      "Epoch 31::Minibatch 748::LR 0.0307692307692 --> Loss 0.000620605349541\n",
      "Epoch 31::Minibatch 749::LR 0.0307692307692 --> Loss 0.0016729259491\n",
      "Epoch 31::Minibatch 750::LR 0.0307692307692 --> Loss 0.00241818149885\n",
      "Epoch 31::Minibatch 751::LR 0.0307692307692 --> Loss 0.00291358908017\n",
      "Epoch 31::Minibatch 752::LR 0.0307692307692 --> Loss 0.00142646749814\n",
      "Epoch 31::Minibatch 753::LR 0.0307692307692 --> Loss 0.00219259421031\n",
      "Epoch 31::Minibatch 754::LR 0.0307692307692 --> Loss 0.00241594493389\n",
      "Epoch 31::Minibatch 755::LR 0.0307692307692 --> Loss 0.00266022245089\n",
      "Epoch 31::Minibatch 756::LR 0.0307692307692 --> Loss 0.00130749454101\n",
      "Epoch 31::Minibatch 757::LR 0.0307692307692 --> Loss 0.000605067610741\n",
      "Epoch 31::Minibatch 758::LR 0.0307692307692 --> Loss 0.00156409988801\n",
      "Epoch 31::Minibatch 759::LR 0.0307692307692 --> Loss 0.00342708468437\n",
      "Epoch 31::Minibatch 760::LR 0.0307692307692 --> Loss 0.00280330300331\n",
      "Epoch 31::Minibatch 761::LR 0.0307692307692 --> Loss 0.00564828276634\n",
      "Epoch 31::Minibatch 762::LR 0.0307692307692 --> Loss 0.00356759031614\n",
      "Epoch 31::Minibatch 763::LR 0.0307692307692 --> Loss 0.00344057122866\n",
      "Epoch 31::Minibatch 764::LR 0.0307692307692 --> Loss 0.00303039987882\n",
      "Epoch 31::Minibatch 765::LR 0.0307692307692 --> Loss 0.00125017871459\n",
      "Epoch 31::Minibatch 766::LR 0.0307692307692 --> Loss 0.00230093061924\n",
      "Epoch 31::Minibatch 767::LR 0.0307692307692 --> Loss 0.00479392449061\n",
      "Epoch 31::Minibatch 768::LR 0.0307692307692 --> Loss 0.00364565054576\n",
      "Epoch 31::Minibatch 769::LR 0.0307692307692 --> Loss 0.00183587412039\n",
      "Epoch 31::Minibatch 770::LR 0.0307692307692 --> Loss 0.00150840828816\n",
      "Epoch 31::Minibatch 771::LR 0.0307692307692 --> Loss 0.00341886758804\n",
      "Epoch 31::Minibatch 772::LR 0.0307692307692 --> Loss 0.00361172119776\n",
      "Epoch 31::Minibatch 773::LR 0.0307692307692 --> Loss 0.00318567474683\n",
      "Epoch 31::Minibatch 774::LR 0.0307692307692 --> Loss 0.00188314696153\n",
      "Epoch 31::Minibatch 775::LR 0.0307692307692 --> Loss 0.00330909053485\n",
      "Epoch 31::Minibatch 776::LR 0.0307692307692 --> Loss 0.00377430438995\n",
      "Epoch 31::Minibatch 777::LR 0.0307692307692 --> Loss 0.00614501833916\n",
      "Epoch 31::Minibatch 778::LR 0.0307692307692 --> Loss 0.00735090176264\n",
      "Epoch 31::Minibatch 779::LR 0.0307692307692 --> Loss 0.00248795231183\n",
      "Epoch 31::Minibatch 780::LR 0.0307692307692 --> Loss 0.00150894492865\n",
      "Epoch 31::Minibatch 781::LR 0.0307692307692 --> Loss 0.00348171273867\n",
      "Epoch 31::Minibatch 782::LR 0.0307692307692 --> Loss 0.00380144238472\n",
      "Epoch 31::Minibatch 783::LR 0.0307692307692 --> Loss 0.00226565877597\n",
      "Epoch 31::Minibatch 784::LR 0.0307692307692 --> Loss 0.000708618362745\n",
      "Epoch 31::Minibatch 785::LR 0.0307692307692 --> Loss 0.00331977546215\n",
      "Epoch 31::Minibatch 786::LR 0.0307692307692 --> Loss 0.00350392619769\n",
      "Epoch 31::Minibatch 787::LR 0.0307692307692 --> Loss 0.00257111032804\n",
      "Epoch 31::Minibatch 788::LR 0.0307692307692 --> Loss 0.00238264818986\n",
      "Epoch 31::Minibatch 789::LR 0.0307692307692 --> Loss 0.000725069145362\n",
      "Epoch 31::Minibatch 790::LR 0.0307692307692 --> Loss 0.00313409368197\n",
      "Epoch 31::Minibatch 791::LR 0.0307692307692 --> Loss 0.00328459739685\n",
      "Epoch 31::Minibatch 792::LR 0.0307692307692 --> Loss 0.00297755181789\n",
      "Epoch 31::Minibatch 793::LR 0.0307692307692 --> Loss 0.00164752483368\n",
      "Epoch 31::Minibatch 794::LR 0.0307692307692 --> Loss 0.000983147819837\n",
      "Epoch 31::Minibatch 795::LR 0.0307692307692 --> Loss 0.00266083478928\n",
      "Epoch 31::Minibatch 796::LR 0.0307692307692 --> Loss 0.00488344709078\n",
      "Epoch 31::Minibatch 797::LR 0.0307692307692 --> Loss 0.00580570141474\n",
      "Epoch 31::Minibatch 798::LR 0.0307692307692 --> Loss 0.00300884286563\n",
      "Epoch 31::Minibatch 799::LR 0.0307692307692 --> Loss 0.00225031793118\n",
      "Epoch 31::Minibatch 800::LR 0.0307692307692 --> Loss 0.00200215319792\n",
      "Epoch 31::Minibatch 801::LR 0.0307692307692 --> Loss 0.00389513770739\n",
      "Epoch 31::Minibatch 802::LR 0.0307692307692 --> Loss 0.00120938281218\n",
      "Epoch 31::Minibatch 803::LR 0.0307692307692 --> Loss 0.00294127523899\n",
      "Epoch 31::Minibatch 804::LR 0.0307692307692 --> Loss 0.00207815607389\n",
      "Epoch 31::Minibatch 805::LR 0.0307692307692 --> Loss 0.00218693733215\n",
      "Epoch 31::Minibatch 806::LR 0.0307692307692 --> Loss 0.00337482730548\n",
      "Epoch 31::Minibatch 807::LR 0.0307692307692 --> Loss 0.0030715183417\n",
      "Epoch 31::Minibatch 808::LR 0.0307692307692 --> Loss 0.00282681723436\n",
      "Epoch 31::Minibatch 809::LR 0.0307692307692 --> Loss 0.00310715576013\n",
      "Epoch 31::Minibatch 810::LR 0.0307692307692 --> Loss 0.00426162640254\n",
      "Epoch 31::Minibatch 811::LR 0.0307692307692 --> Loss 0.00408189813296\n",
      "Epoch 31::Minibatch 812::LR 0.0307692307692 --> Loss 0.00374877969424\n",
      "Epoch 31::Minibatch 813::LR 0.0307692307692 --> Loss 0.00313968896866\n",
      "Epoch 31::Minibatch 814::LR 0.0307692307692 --> Loss 0.00153415759405\n",
      "Epoch 31::Minibatch 815::LR 0.0307692307692 --> Loss 0.0035135169824\n",
      "Epoch 31::Minibatch 816::LR 0.0307692307692 --> Loss 0.00395553390185\n",
      "Epoch 31::Minibatch 817::LR 0.0307692307692 --> Loss 0.0049000732104\n",
      "Epoch 31::Minibatch 818::LR 0.0307692307692 --> Loss 0.00124017387629\n",
      "Epoch 31::Minibatch 819::LR 0.0307692307692 --> Loss 0.000719179262718\n",
      "Epoch 31::Minibatch 820::LR 0.0307692307692 --> Loss 0.00508470932643\n",
      "Epoch 31::Minibatch 821::LR 0.0307692307692 --> Loss 0.00305693805218\n",
      "Epoch 31::Minibatch 822::LR 0.0307692307692 --> Loss 0.00365688761075\n",
      "Epoch 31::Minibatch 823::LR 0.0307692307692 --> Loss 0.00126103738944\n",
      "Epoch 31::Minibatch 824::LR 0.0307692307692 --> Loss 0.00136159469684\n",
      "Epoch 31::Minibatch 825::LR 0.0307692307692 --> Loss 0.00370413502057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 826::LR 0.0307692307692 --> Loss 0.0043288175265\n",
      "Epoch 31::Minibatch 827::LR 0.0307692307692 --> Loss 0.00205471893152\n",
      "Epoch 31::Minibatch 828::LR 0.0307692307692 --> Loss 0.0004883727928\n",
      "Epoch 31::Minibatch 829::LR 0.0307692307692 --> Loss 0.00226654688517\n",
      "Epoch 31::Minibatch 830::LR 0.0307692307692 --> Loss 0.00402159055074\n",
      "Epoch 31::Minibatch 831::LR 0.0307692307692 --> Loss 0.0023990247647\n",
      "Epoch 31::Minibatch 832::LR 0.0307692307692 --> Loss 0.00211175024509\n",
      "Epoch 31::Minibatch 833::LR 0.0307692307692 --> Loss 0.00181598703067\n",
      "Epoch 31::Minibatch 834::LR 0.0307692307692 --> Loss 0.000786057760318\n",
      "Epoch 31::Minibatch 835::LR 0.0307692307692 --> Loss 0.00376798113187\n",
      "Epoch 31::Minibatch 836::LR 0.0307692307692 --> Loss 0.00357321063677\n",
      "Epoch 31::Minibatch 837::LR 0.0307692307692 --> Loss 0.00223079403241\n",
      "Epoch 31::Minibatch 838::LR 0.0307692307692 --> Loss 0.000641730427742\n",
      "Epoch 31::Minibatch 839::LR 0.0307692307692 --> Loss 0.00238772590955\n",
      "Epoch 31::Minibatch 840::LR 0.0307692307692 --> Loss 0.00283808072408\n",
      "Epoch 31::Minibatch 841::LR 0.0307692307692 --> Loss 0.00275058249633\n",
      "Epoch 31::Minibatch 842::LR 0.0307692307692 --> Loss 0.00209035078684\n",
      "Epoch 31::Minibatch 843::LR 0.0307692307692 --> Loss 0.000976890722911\n",
      "Epoch 31::Minibatch 844::LR 0.0307692307692 --> Loss 0.00146588852008\n",
      "Epoch 31::Minibatch 845::LR 0.0307692307692 --> Loss 0.00403518279394\n",
      "Epoch 31::Minibatch 846::LR 0.0307692307692 --> Loss 0.00166550457478\n",
      "Epoch 31::Minibatch 847::LR 0.0307692307692 --> Loss 0.00234036246936\n",
      "Epoch 31::Minibatch 848::LR 0.0307692307692 --> Loss 0.00109805464745\n",
      "Epoch 31::Minibatch 849::LR 0.0307692307692 --> Loss 0.00178425172965\n",
      "Epoch 31::Minibatch 850::LR 0.0307692307692 --> Loss 0.00314355075359\n",
      "Epoch 31::Minibatch 851::LR 0.0307692307692 --> Loss 0.00254248301188\n",
      "Epoch 31::Minibatch 852::LR 0.0307692307692 --> Loss 0.00111955295006\n",
      "Epoch 31::Minibatch 853::LR 0.0307692307692 --> Loss 0.00130172282457\n",
      "Epoch 31::Minibatch 854::LR 0.0307692307692 --> Loss 0.002527881066\n",
      "Epoch 31::Minibatch 855::LR 0.0307692307692 --> Loss 0.00211057802041\n",
      "Epoch 31::Minibatch 856::LR 0.0307692307692 --> Loss 0.0017784422636\n",
      "Epoch 31::Minibatch 857::LR 0.0307692307692 --> Loss 0.00120692819357\n",
      "Epoch 31::Minibatch 858::LR 0.0307692307692 --> Loss 0.000597915053368\n",
      "Epoch 31::Minibatch 859::LR 0.0307692307692 --> Loss 0.00196272571882\n",
      "Epoch 31::Minibatch 860::LR 0.0307692307692 --> Loss 0.00129126985868\n",
      "Epoch 31::Minibatch 861::LR 0.0307692307692 --> Loss 0.000943188468615\n",
      "Epoch 31::Minibatch 862::LR 0.0307692307692 --> Loss 0.00369808554649\n",
      "Epoch 31::Minibatch 863::LR 0.0307692307692 --> Loss 0.00336160739263\n",
      "Epoch 31::Minibatch 864::LR 0.0307692307692 --> Loss 0.00261777222157\n",
      "Epoch 31::Minibatch 865::LR 0.0307692307692 --> Loss 0.000494535664717\n",
      "Epoch 31::Minibatch 866::LR 0.0307692307692 --> Loss 0.00207946221034\n",
      "Epoch 31::Minibatch 867::LR 0.0307692307692 --> Loss 0.0028736170133\n",
      "Epoch 31::Minibatch 868::LR 0.0307692307692 --> Loss 0.00240991850694\n",
      "Epoch 31::Minibatch 869::LR 0.0307692307692 --> Loss 0.00212549348672\n",
      "Epoch 31::Minibatch 870::LR 0.0307692307692 --> Loss 0.00327748735746\n",
      "Epoch 31::Minibatch 871::LR 0.0307692307692 --> Loss 0.00160410175721\n",
      "Epoch 31::Minibatch 872::LR 0.0307692307692 --> Loss 0.00213384628296\n",
      "Epoch 31::Minibatch 873::LR 0.0307692307692 --> Loss 0.00245004951954\n",
      "Epoch 31::Minibatch 874::LR 0.0307692307692 --> Loss 0.00527090469996\n",
      "Epoch 31::Minibatch 875::LR 0.0307692307692 --> Loss 0.000606185545524\n",
      "Epoch 31::Minibatch 876::LR 0.0307692307692 --> Loss 0.00277213136355\n",
      "Epoch 31::Minibatch 877::LR 0.0307692307692 --> Loss 0.00472470323245\n",
      "Epoch 31::Minibatch 878::LR 0.0307692307692 --> Loss 0.00298435946306\n",
      "Epoch 31::Minibatch 879::LR 0.0307692307692 --> Loss 0.00391785979271\n",
      "Epoch 31::Minibatch 880::LR 0.0307692307692 --> Loss 0.00485318342845\n",
      "Epoch 31::Minibatch 881::LR 0.0307692307692 --> Loss 0.0042192697525\n",
      "Epoch 31::Minibatch 882::LR 0.0307692307692 --> Loss 0.00191483020782\n",
      "Epoch 31::Minibatch 883::LR 0.0307692307692 --> Loss 0.00358767549197\n",
      "Epoch 31::Minibatch 884::LR 0.0307692307692 --> Loss 0.00277804394563\n",
      "Epoch 31::Minibatch 885::LR 0.0307692307692 --> Loss 0.00257955571016\n",
      "Epoch 31::Minibatch 886::LR 0.0307692307692 --> Loss 0.000437310934067\n",
      "Epoch 31::Minibatch 887::LR 0.0307692307692 --> Loss 0.00542787710826\n",
      "Epoch 31::Minibatch 888::LR 0.0307692307692 --> Loss 0.00245788753033\n",
      "Epoch 31::Minibatch 889::LR 0.0307692307692 --> Loss 0.00252525250117\n",
      "Epoch 31::Minibatch 890::LR 0.0307692307692 --> Loss 0.00365244110425\n",
      "Epoch 31::Minibatch 891::LR 0.0307692307692 --> Loss 0.00172535399596\n",
      "Epoch 31::Minibatch 892::LR 0.0307692307692 --> Loss 0.000796006818612\n",
      "Epoch 31::Minibatch 893::LR 0.0307692307692 --> Loss 0.00227134247621\n",
      "Epoch 31::Minibatch 894::LR 0.0307692307692 --> Loss 0.00199685494105\n",
      "Epoch 31::Minibatch 895::LR 0.0307692307692 --> Loss 0.00227721273899\n",
      "Epoch 31::Minibatch 896::LR 0.0307692307692 --> Loss 0.00124208589395\n",
      "Epoch 31::Minibatch 897::LR 0.0307692307692 --> Loss 0.000672340194384\n",
      "Epoch 31::Minibatch 898::LR 0.0307692307692 --> Loss 0.00199105819066\n",
      "Epoch 31::Minibatch 899::LR 0.0307692307692 --> Loss 0.00244980136553\n",
      "Epoch 31::Minibatch 900::LR 0.0307692307692 --> Loss 0.00307227750619\n",
      "Epoch 31::Minibatch 901::LR 0.0307692307692 --> Loss 0.000583228319883\n",
      "Epoch 31::Minibatch 902::LR 0.0307692307692 --> Loss 0.0013934853673\n",
      "Epoch 31::Minibatch 903::LR 0.0307692307692 --> Loss 0.00252882957458\n",
      "Epoch 31::Minibatch 904::LR 0.0307692307692 --> Loss 0.00180351098378\n",
      "Epoch 31::Minibatch 905::LR 0.0307692307692 --> Loss 0.00139631340901\n",
      "Epoch 31::Minibatch 906::LR 0.0307692307692 --> Loss 0.00102610349655\n",
      "Epoch 31::Minibatch 907::LR 0.0307692307692 --> Loss 0.00154704153538\n",
      "Epoch 31::Minibatch 908::LR 0.0307692307692 --> Loss 0.00206948300203\n",
      "Epoch 31::Minibatch 909::LR 0.0307692307692 --> Loss 0.00192837933699\n",
      "Epoch 31::Minibatch 910::LR 0.0307692307692 --> Loss 0.000839336911837\n",
      "Epoch 31::Minibatch 911::LR 0.0307692307692 --> Loss 0.00126411815484\n",
      "Epoch 31::Minibatch 912::LR 0.0307692307692 --> Loss 0.0020379469792\n",
      "Epoch 31::Minibatch 913::LR 0.0307692307692 --> Loss 0.00224821209908\n",
      "Epoch 31::Minibatch 914::LR 0.0307692307692 --> Loss 0.00122551520665\n",
      "Epoch 31::Minibatch 915::LR 0.0307692307692 --> Loss 0.000522790700197\n",
      "Epoch 31::Minibatch 916::LR 0.0307692307692 --> Loss 0.00205660164356\n",
      "Epoch 31::Minibatch 917::LR 0.0307692307692 --> Loss 0.0033032343785\n",
      "Epoch 31::Minibatch 918::LR 0.0307692307692 --> Loss 0.00501668254534\n",
      "Epoch 31::Minibatch 919::LR 0.0307692307692 --> Loss 0.000535121113062\n",
      "Epoch 31::Minibatch 920::LR 0.0307692307692 --> Loss 0.0124668447177\n",
      "Epoch 31::Minibatch 921::LR 0.0307692307692 --> Loss 0.00294371326764\n",
      "Epoch 31::Minibatch 922::LR 0.0307692307692 --> Loss 0.00296494404475\n",
      "Epoch 31::Minibatch 923::LR 0.0307692307692 --> Loss 0.00119370520115\n",
      "Epoch 31::Minibatch 924::LR 0.0307692307692 --> Loss 0.00316883385181\n",
      "Epoch 31::Minibatch 925::LR 0.0307692307692 --> Loss 0.00219098865986\n",
      "Epoch 31::Minibatch 926::LR 0.0307692307692 --> Loss 0.00468235254288\n",
      "Epoch 31::Minibatch 927::LR 0.0307692307692 --> Loss 0.00539092699687\n",
      "Epoch 31::Minibatch 928::LR 0.0307692307692 --> Loss 0.00596218705177\n",
      "Epoch 31::Minibatch 929::LR 0.0307692307692 --> Loss 0.00541111588478\n",
      "Epoch 31::Minibatch 930::LR 0.0307692307692 --> Loss 0.00904277165731\n",
      "Epoch 31::Minibatch 931::LR 0.0307692307692 --> Loss 0.00304101804892\n",
      "Epoch 31::Minibatch 932::LR 0.0307692307692 --> Loss 0.00534557898839\n",
      "Epoch 31::Minibatch 933::LR 0.0307692307692 --> Loss 0.00245698491732\n",
      "Epoch 31::Minibatch 934::LR 0.0307692307692 --> Loss 0.00316398700078\n",
      "Epoch 31::Minibatch 935::LR 0.0307692307692 --> Loss 0.00469547430674\n",
      "Epoch 31::Minibatch 936::LR 0.0307692307692 --> Loss 0.000945311586062\n",
      "Epoch 31::Minibatch 937::LR 0.0307692307692 --> Loss 0.0024576040109\n",
      "Epoch 31::Minibatch 938::LR 0.0307692307692 --> Loss 0.00210751573245\n",
      "Epoch 31::Minibatch 939::LR 0.0307692307692 --> Loss 0.00227780103683\n",
      "Epoch 31::Minibatch 940::LR 0.0307692307692 --> Loss 0.000928342143695\n",
      "Epoch 31::Minibatch 941::LR 0.0307692307692 --> Loss 0.000756595283747\n",
      "Epoch 31::Minibatch 942::LR 0.0307692307692 --> Loss 0.0024979497989\n",
      "Epoch 31::Minibatch 943::LR 0.0307692307692 --> Loss 0.00237485051155\n",
      "Epoch 31::Minibatch 944::LR 0.0307692307692 --> Loss 0.00171441137791\n",
      "Epoch 31::Minibatch 945::LR 0.0307692307692 --> Loss 0.000966824988524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31::Minibatch 946::LR 0.0307692307692 --> Loss 0.00246318002542\n",
      "Epoch 31::Minibatch 947::LR 0.0307692307692 --> Loss 0.00227400581042\n",
      "Epoch 31::Minibatch 948::LR 0.0307692307692 --> Loss 0.00413767973582\n",
      "Epoch 31::Minibatch 949::LR 0.0307692307692 --> Loss 0.00172401150068\n",
      "Epoch 31::Minibatch 950::LR 0.0307692307692 --> Loss 0.000700068672498\n",
      "Epoch 31::Minibatch 951::LR 0.0307692307692 --> Loss 0.00335268537203\n",
      "Epoch 31::Minibatch 952::LR 0.0307692307692 --> Loss 0.00234127600988\n",
      "Epoch 31::Minibatch 953::LR 0.0307692307692 --> Loss 0.00140973061323\n",
      "Epoch 31::Minibatch 954::LR 0.0307692307692 --> Loss 0.000939146776994\n",
      "Epoch 31::Minibatch 955::LR 0.0307692307692 --> Loss 0.00254276792208\n",
      "Epoch 31::Minibatch 956::LR 0.0307692307692 --> Loss 0.00313970307509\n",
      "Epoch 31::Minibatch 957::LR 0.0307692307692 --> Loss 0.00182331879934\n",
      "Epoch 31::Minibatch 958::LR 0.0307692307692 --> Loss 0.00218330343564\n",
      "Epoch 31::Minibatch 959::LR 0.0307692307692 --> Loss 0.00255145092805\n",
      "Epoch 31::Minibatch 960::LR 0.0307692307692 --> Loss 0.00542564113935\n",
      "Epoch 31::Minibatch 961::LR 0.0307692307692 --> Loss 0.00300849954287\n",
      "Epoch 31::Minibatch 962::LR 0.0307692307692 --> Loss 0.00240708251794\n",
      "Epoch 31::Minibatch 963::LR 0.0307692307692 --> Loss 0.00104404161374\n",
      "Epoch 31::Minibatch 964::LR 0.0307692307692 --> Loss 0.00233416994413\n",
      "Epoch 31::Minibatch 965::LR 0.0307692307692 --> Loss 0.00634209553401\n",
      "Epoch 31::Minibatch 966::LR 0.0307692307692 --> Loss 0.00486274242401\n",
      "Epoch 31::Minibatch 967::LR 0.0307692307692 --> Loss 0.00127374251684\n",
      "Epoch 31::Minibatch 968::LR 0.0307692307692 --> Loss 0.00105766773224\n",
      "Epoch 31::Minibatch 969::LR 0.0307692307692 --> Loss 0.00473048408826\n",
      "Epoch 31::Minibatch 970::LR 0.0307692307692 --> Loss 0.00455915490786\n",
      "Epoch 31::Minibatch 971::LR 0.0307692307692 --> Loss 0.00332708577315\n",
      "Epoch 31::Minibatch 972::LR 0.0307692307692 --> Loss 0.00833111763\n",
      "Epoch 31::Minibatch 973::LR 0.0307692307692 --> Loss 0.00925709168116\n",
      "Epoch 31::Minibatch 974::LR 0.0307692307692 --> Loss 0.00820340553919\n",
      "Epoch 31::Minibatch 975::LR 0.0307692307692 --> Loss 0.00447229544322\n",
      "Epoch 31::Minibatch 976::LR 0.0307692307692 --> Loss 0.00364333868027\n",
      "Epoch 31::Minibatch 977::LR 0.0307692307692 --> Loss 0.00339091380437\n",
      "Epoch 31::Minibatch 978::LR 0.0307692307692 --> Loss 0.00331874946753\n",
      "Epoch 31::Minibatch 979::LR 0.0307692307692 --> Loss 0.00308677474658\n",
      "Epoch 31::Minibatch 980::LR 0.0307692307692 --> Loss 0.00345843275388\n",
      "Epoch 31::Minibatch 981::LR 0.0307692307692 --> Loss 0.00431825677554\n",
      "Epoch 31::Minibatch 982::LR 0.0307692307692 --> Loss 0.00443908691406\n",
      "Epoch 31::Minibatch 983::LR 0.0307692307692 --> Loss 0.00253968954086\n",
      "Epoch 31::Minibatch 984::LR 0.0307692307692 --> Loss 0.00178773581982\n",
      "Epoch 31::Minibatch 985::LR 0.0307692307692 --> Loss 0.00336363593737\n",
      "Epoch 31::Minibatch 986::LR 0.0307692307692 --> Loss 0.00305666565895\n",
      "Epoch 31::Minibatch 987::LR 0.0307692307692 --> Loss 0.00336482961973\n",
      "Epoch 31::Minibatch 988::LR 0.0307692307692 --> Loss 0.00267830570539\n",
      "Epoch 31::Minibatch 989::LR 0.0307692307692 --> Loss 0.00295912484328\n",
      "Epoch 31::Minibatch 990::LR 0.0307692307692 --> Loss 0.00276521186034\n",
      "Epoch 31::Minibatch 991::LR 0.0307692307692 --> Loss 0.00139398207267\n",
      "Epoch 31::Minibatch 992::LR 0.0307692307692 --> Loss 0.00162440071503\n",
      "Epoch 31::Minibatch 993::LR 0.0307692307692 --> Loss 0.00301418860753\n",
      "Epoch 31::Minibatch 994::LR 0.0307692307692 --> Loss 0.00197994907697\n",
      "Epoch 31::Minibatch 995::LR 0.0307692307692 --> Loss 0.000798434515794\n",
      "Epoch 31::Minibatch 996::LR 0.0307692307692 --> Loss 0.00268059571584\n",
      "Epoch 31::Minibatch 997::LR 0.0307692307692 --> Loss 0.00218859016895\n",
      "Epoch 31::Minibatch 998::LR 0.0307692307692 --> Loss 0.00249206801256\n",
      "Epoch 31::Minibatch 999::LR 0.0307692307692 --> Loss 0.0021255505085\n",
      "Epoch 31::Minibatch 1000::LR 0.0307692307692 --> Loss 0.0025601263841\n",
      "Epoch 31::Minibatch 1001::LR 0.0307692307692 --> Loss 0.0020305532217\n",
      "Epoch 31::Minibatch 1002::LR 0.0307692307692 --> Loss 0.00157773971558\n",
      "Epoch 31::Minibatch 1003::LR 0.0307692307692 --> Loss 0.00257171471914\n",
      "Epoch 31::Minibatch 1004::LR 0.0307692307692 --> Loss 0.00106692155202\n",
      "Epoch 31::Minibatch 1005::LR 0.0307692307692 --> Loss 0.00258788685004\n",
      "Epoch 31::Minibatch 1006::LR 0.0307692307692 --> Loss 0.0013676182429\n",
      "Epoch 31::Minibatch 1007::LR 0.0307692307692 --> Loss 0.00179123799006\n",
      "Epoch 31::Minibatch 1008::LR 0.0307692307692 --> Loss 0.0009240218997\n",
      "Epoch 31::Minibatch 1009::LR 0.0307692307692 --> Loss 0.00122923274835\n",
      "Epoch 31::Minibatch 1010::LR 0.0307692307692 --> Loss 0.00114342729251\n",
      "Epoch 31::Minibatch 1011::LR 0.0307692307692 --> Loss 0.00168606181939\n",
      "Epoch 31::Minibatch 1012::LR 0.0307692307692 --> Loss 0.00141887704531\n",
      "Epoch 31::Minibatch 1013::LR 0.0307692307692 --> Loss 0.00352383097013\n",
      "Epoch 31::Minibatch 1014::LR 0.0307692307692 --> Loss 0.0032844132185\n",
      "Epoch 31::Minibatch 1015::LR 0.0307692307692 --> Loss 0.00153370410204\n",
      "Epoch 31::Minibatch 1016::LR 0.0307692307692 --> Loss 0.0044927628835\n",
      "Epoch 31::Minibatch 1017::LR 0.0307692307692 --> Loss 0.00312230388323\n",
      "Epoch 31::Minibatch 1018::LR 0.0307692307692 --> Loss 0.00251649856567\n",
      "Epoch 31::Minibatch 1019::LR 0.0307692307692 --> Loss 0.00158860146999\n",
      "Epoch 31::Minibatch 1020::LR 0.0307692307692 --> Loss 0.00170654316743\n",
      "Epoch 31::Minibatch 1021::LR 0.0307692307692 --> Loss 0.00182869493961\n",
      "Epoch 31::Minibatch 1022::LR 0.0307692307692 --> Loss 0.00134548187256\n",
      "Epoch 31::Minibatch 1023::LR 0.0307692307692 --> Loss 0.00101114869118\n",
      "Epoch 31::Minibatch 1024::LR 0.0307692307692 --> Loss 0.00100821306308\n",
      "Epoch 31::Minibatch 1025::LR 0.0307692307692 --> Loss 0.00136477510134\n",
      "Epoch 31::Minibatch 1026::LR 0.0307692307692 --> Loss 0.000703415125608\n",
      "Epoch 31::Minibatch 1027::LR 0.0307692307692 --> Loss 0.000975021421909\n",
      "Epoch 31::Minibatch 1028::LR 0.0307692307692 --> Loss 0.000729977935553\n",
      "Epoch 31::Minibatch 1029::LR 0.0307692307692 --> Loss 0.000743074417114\n",
      "Epoch 31::Minibatch 1030::LR 0.0307692307692 --> Loss 0.000907208919525\n",
      "Epoch 31::Minibatch 1031::LR 0.0307692307692 --> Loss 0.000694641421239\n",
      "Epoch 31::Minibatch 1032::LR 0.0307692307692 --> Loss 0.000775561879079\n",
      "Epoch 31::Minibatch 1033::LR 0.0307692307692 --> Loss 0.000659885406494\n",
      "Epoch 31::Minibatch 1034::LR 0.0307692307692 --> Loss 0.000626527915398\n",
      "Epoch 31::Minibatch 1035::LR 0.0307692307692 --> Loss 0.000411451160908\n",
      "Epoch 31::Minibatch 1036::LR 0.0307692307692 --> Loss 0.000328861524661\n",
      "Epoch 31::Minibatch 1037::LR 0.0307692307692 --> Loss 0.000604102760553\n",
      "Epoch 31::Minibatch 1038::LR 0.0307692307692 --> Loss 0.00108180592457\n",
      "Epoch 31::Minibatch 1039::LR 0.0307692307692 --> Loss 0.000877562463284\n",
      "Epoch 31::Minibatch 1040::LR 0.0307692307692 --> Loss 0.000344959894816\n",
      "Epoch 31::Minibatch 1041::LR 0.0307692307692 --> Loss 0.000496217012405\n",
      "Epoch 32::Minibatch 1::LR 0.0284615384615 --> Loss 0.00762171824773\n",
      "Epoch 32::Minibatch 2::LR 0.0284615384615 --> Loss 0.00479840954145\n",
      "Epoch 32::Minibatch 3::LR 0.0284615384615 --> Loss 0.00303900301456\n",
      "Epoch 32::Minibatch 4::LR 0.0284615384615 --> Loss 0.00380430459976\n",
      "Epoch 32::Minibatch 5::LR 0.0284615384615 --> Loss 0.00437839229902\n",
      "Epoch 32::Minibatch 6::LR 0.0284615384615 --> Loss 0.00207391897837\n",
      "Epoch 32::Minibatch 7::LR 0.0284615384615 --> Loss 0.00712151050568\n",
      "Epoch 32::Minibatch 8::LR 0.0284615384615 --> Loss 0.00662901918093\n",
      "Epoch 32::Minibatch 9::LR 0.0284615384615 --> Loss 0.00515134255091\n",
      "Epoch 32::Minibatch 10::LR 0.0284615384615 --> Loss 0.00236040572325\n",
      "Epoch 32::Minibatch 11::LR 0.0284615384615 --> Loss 0.00220940987269\n",
      "Epoch 32::Minibatch 12::LR 0.0284615384615 --> Loss 0.00334911584854\n",
      "Epoch 32::Minibatch 13::LR 0.0284615384615 --> Loss 0.00529969731967\n",
      "Epoch 32::Minibatch 14::LR 0.0284615384615 --> Loss 0.00527661283811\n",
      "Epoch 32::Minibatch 15::LR 0.0284615384615 --> Loss 0.00455987930298\n",
      "Epoch 32::Minibatch 16::LR 0.0284615384615 --> Loss 0.000717374682426\n",
      "Epoch 32::Minibatch 17::LR 0.0284615384615 --> Loss 0.00319555838903\n",
      "Epoch 32::Minibatch 18::LR 0.0284615384615 --> Loss 0.00265218436718\n",
      "Epoch 32::Minibatch 19::LR 0.0284615384615 --> Loss 0.00159393211206\n",
      "Epoch 32::Minibatch 20::LR 0.0284615384615 --> Loss 0.00212455729644\n",
      "Epoch 32::Minibatch 21::LR 0.0284615384615 --> Loss 0.00339157660802\n",
      "Epoch 32::Minibatch 22::LR 0.0284615384615 --> Loss 0.00222826242447\n",
      "Epoch 32::Minibatch 23::LR 0.0284615384615 --> Loss 0.000918223261833\n",
      "Epoch 32::Minibatch 24::LR 0.0284615384615 --> Loss 0.000506569047769\n",
      "Epoch 32::Minibatch 25::LR 0.0284615384615 --> Loss 0.00135423819224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 26::LR 0.0284615384615 --> Loss 0.00154983649651\n",
      "Epoch 32::Minibatch 27::LR 0.0284615384615 --> Loss 0.00116386085749\n",
      "Epoch 32::Minibatch 28::LR 0.0284615384615 --> Loss 0.000509749948978\n",
      "Epoch 32::Minibatch 29::LR 0.0284615384615 --> Loss 0.000615462313096\n",
      "Epoch 32::Minibatch 30::LR 0.0284615384615 --> Loss 0.00111694018046\n",
      "Epoch 32::Minibatch 31::LR 0.0284615384615 --> Loss 0.00159912417332\n",
      "Epoch 32::Minibatch 32::LR 0.0284615384615 --> Loss 0.00141300400098\n",
      "Epoch 32::Minibatch 33::LR 0.0284615384615 --> Loss 0.000814711153507\n",
      "Epoch 32::Minibatch 34::LR 0.0284615384615 --> Loss 0.00203775425752\n",
      "Epoch 32::Minibatch 35::LR 0.0284615384615 --> Loss 0.00290136396885\n",
      "Epoch 32::Minibatch 36::LR 0.0284615384615 --> Loss 0.00224715709686\n",
      "Epoch 32::Minibatch 37::LR 0.0284615384615 --> Loss 0.000721209843953\n",
      "Epoch 32::Minibatch 38::LR 0.0284615384615 --> Loss 0.000738998303811\n",
      "Epoch 32::Minibatch 39::LR 0.0284615384615 --> Loss 0.00213227609793\n",
      "Epoch 32::Minibatch 40::LR 0.0284615384615 --> Loss 0.00307224710782\n",
      "Epoch 32::Minibatch 41::LR 0.0284615384615 --> Loss 0.00244487822056\n",
      "Epoch 32::Minibatch 42::LR 0.0284615384615 --> Loss 0.00447343468666\n",
      "Epoch 32::Minibatch 43::LR 0.0284615384615 --> Loss 0.00202499628067\n",
      "Epoch 32::Minibatch 44::LR 0.0284615384615 --> Loss 0.00334275444349\n",
      "Epoch 32::Minibatch 45::LR 0.0284615384615 --> Loss 0.00241576552391\n",
      "Epoch 32::Minibatch 46::LR 0.0284615384615 --> Loss 0.00304669002692\n",
      "Epoch 32::Minibatch 47::LR 0.0284615384615 --> Loss 0.00327262818813\n",
      "Epoch 32::Minibatch 48::LR 0.0284615384615 --> Loss 0.00476428588231\n",
      "Epoch 32::Minibatch 49::LR 0.0284615384615 --> Loss 0.00540865500768\n",
      "Epoch 32::Minibatch 50::LR 0.0284615384615 --> Loss 0.00596123139064\n",
      "Epoch 32::Minibatch 51::LR 0.0284615384615 --> Loss 0.00427359143893\n",
      "Epoch 32::Minibatch 52::LR 0.0284615384615 --> Loss 0.00340175112089\n",
      "Epoch 32::Minibatch 53::LR 0.0284615384615 --> Loss 0.00337469339371\n",
      "Epoch 32::Minibatch 54::LR 0.0284615384615 --> Loss 0.0039807955424\n",
      "Epoch 32::Minibatch 55::LR 0.0284615384615 --> Loss 0.000993633667628\n",
      "Epoch 32::Minibatch 56::LR 0.0284615384615 --> Loss 0.0027447750171\n",
      "Epoch 32::Minibatch 57::LR 0.0284615384615 --> Loss 0.00455544312795\n",
      "Epoch 32::Minibatch 58::LR 0.0284615384615 --> Loss 0.00319389084975\n",
      "Epoch 32::Minibatch 59::LR 0.0284615384615 --> Loss 0.00244175632795\n",
      "Epoch 32::Minibatch 60::LR 0.0284615384615 --> Loss 0.00249255438646\n",
      "Epoch 32::Minibatch 61::LR 0.0284615384615 --> Loss 0.000715798089902\n",
      "Epoch 32::Minibatch 62::LR 0.0284615384615 --> Loss 0.00250141978264\n",
      "Epoch 32::Minibatch 63::LR 0.0284615384615 --> Loss 0.00203276991844\n",
      "Epoch 32::Minibatch 64::LR 0.0284615384615 --> Loss 0.000815432518721\n",
      "Epoch 32::Minibatch 65::LR 0.0284615384615 --> Loss 0.00212748527527\n",
      "Epoch 32::Minibatch 66::LR 0.0284615384615 --> Loss 0.00276605824629\n",
      "Epoch 32::Minibatch 67::LR 0.0284615384615 --> Loss 0.00249027589957\n",
      "Epoch 32::Minibatch 68::LR 0.0284615384615 --> Loss 0.00182193199793\n",
      "Epoch 32::Minibatch 69::LR 0.0284615384615 --> Loss 0.00359013517698\n",
      "Epoch 32::Minibatch 70::LR 0.0284615384615 --> Loss 0.00319523791472\n",
      "Epoch 32::Minibatch 71::LR 0.0284615384615 --> Loss 0.00223200003306\n",
      "Epoch 32::Minibatch 72::LR 0.0284615384615 --> Loss 0.00054552346468\n",
      "Epoch 32::Minibatch 73::LR 0.0284615384615 --> Loss 0.0036617620786\n",
      "Epoch 32::Minibatch 74::LR 0.0284615384615 --> Loss 0.00396624207497\n",
      "Epoch 32::Minibatch 75::LR 0.0284615384615 --> Loss 0.00205740253131\n",
      "Epoch 32::Minibatch 76::LR 0.0284615384615 --> Loss 0.000519095162551\n",
      "Epoch 32::Minibatch 77::LR 0.0284615384615 --> Loss 0.00328386803468\n",
      "Epoch 32::Minibatch 78::LR 0.0284615384615 --> Loss 0.0039478357633\n",
      "Epoch 32::Minibatch 79::LR 0.0284615384615 --> Loss 0.00169011950493\n",
      "Epoch 32::Minibatch 80::LR 0.0284615384615 --> Loss 0.00280080238978\n",
      "Epoch 32::Minibatch 81::LR 0.0284615384615 --> Loss 0.00249307235082\n",
      "Epoch 32::Minibatch 82::LR 0.0284615384615 --> Loss 0.00181356529395\n",
      "Epoch 32::Minibatch 83::LR 0.0284615384615 --> Loss 0.00382468819618\n",
      "Epoch 32::Minibatch 84::LR 0.0284615384615 --> Loss 0.00183913985888\n",
      "Epoch 32::Minibatch 85::LR 0.0284615384615 --> Loss 0.00249861478806\n",
      "Epoch 32::Minibatch 86::LR 0.0284615384615 --> Loss 0.00207337280114\n",
      "Epoch 32::Minibatch 87::LR 0.0284615384615 --> Loss 0.00218709588051\n",
      "Epoch 32::Minibatch 88::LR 0.0284615384615 --> Loss 0.00165147304535\n",
      "Epoch 32::Minibatch 89::LR 0.0284615384615 --> Loss 0.00217617750168\n",
      "Epoch 32::Minibatch 90::LR 0.0284615384615 --> Loss 0.00104331483444\n",
      "Epoch 32::Minibatch 91::LR 0.0284615384615 --> Loss 0.000871805051963\n",
      "Epoch 32::Minibatch 92::LR 0.0284615384615 --> Loss 0.0025349299113\n",
      "Epoch 32::Minibatch 93::LR 0.0284615384615 --> Loss 0.00168649951617\n",
      "Epoch 32::Minibatch 94::LR 0.0284615384615 --> Loss 0.00173523863157\n",
      "Epoch 32::Minibatch 95::LR 0.0284615384615 --> Loss 0.00190244317055\n",
      "Epoch 32::Minibatch 96::LR 0.0284615384615 --> Loss 0.0046744855245\n",
      "Epoch 32::Minibatch 97::LR 0.0284615384615 --> Loss 0.00300817390283\n",
      "Epoch 32::Minibatch 98::LR 0.0284615384615 --> Loss 0.00108421504498\n",
      "Epoch 32::Minibatch 99::LR 0.0284615384615 --> Loss 0.00140947530667\n",
      "Epoch 32::Minibatch 100::LR 0.0284615384615 --> Loss 0.00414842367172\n",
      "Epoch 32::Minibatch 101::LR 0.0284615384615 --> Loss 0.000896552105745\n",
      "Epoch 32::Minibatch 102::LR 0.0284615384615 --> Loss 0.00385438243548\n",
      "Epoch 32::Minibatch 103::LR 0.0284615384615 --> Loss 0.00386247714361\n",
      "Epoch 32::Minibatch 104::LR 0.0284615384615 --> Loss 0.00264382481575\n",
      "Epoch 32::Minibatch 105::LR 0.0284615384615 --> Loss 0.00206178943316\n",
      "Epoch 32::Minibatch 106::LR 0.0284615384615 --> Loss 0.0133984311422\n",
      "Epoch 32::Minibatch 107::LR 0.0284615384615 --> Loss 0.00474242170652\n",
      "Epoch 32::Minibatch 108::LR 0.0284615384615 --> Loss 0.000918946564198\n",
      "Epoch 32::Minibatch 109::LR 0.0284615384615 --> Loss 0.00429884552956\n",
      "Epoch 32::Minibatch 110::LR 0.0284615384615 --> Loss 0.0022013258934\n",
      "Epoch 32::Minibatch 111::LR 0.0284615384615 --> Loss 0.000807794332504\n",
      "Epoch 32::Minibatch 112::LR 0.0284615384615 --> Loss 0.00325591226419\n",
      "Epoch 32::Minibatch 113::LR 0.0284615384615 --> Loss 0.00236114362876\n",
      "Epoch 32::Minibatch 114::LR 0.0284615384615 --> Loss 0.00132422477007\n",
      "Epoch 32::Minibatch 115::LR 0.0284615384615 --> Loss 0.00111585646868\n",
      "Epoch 32::Minibatch 116::LR 0.0284615384615 --> Loss 0.00261638522148\n",
      "Epoch 32::Minibatch 117::LR 0.0284615384615 --> Loss 0.0040787144502\n",
      "Epoch 32::Minibatch 118::LR 0.0284615384615 --> Loss 0.00650927027067\n",
      "Epoch 32::Minibatch 119::LR 0.0284615384615 --> Loss 0.000487664937973\n",
      "Epoch 32::Minibatch 120::LR 0.0284615384615 --> Loss 0.00162444700797\n",
      "Epoch 32::Minibatch 121::LR 0.0284615384615 --> Loss 0.00233217835426\n",
      "Epoch 32::Minibatch 122::LR 0.0284615384615 --> Loss 0.00385026176771\n",
      "Epoch 32::Minibatch 123::LR 0.0284615384615 --> Loss 0.000661681443453\n",
      "Epoch 32::Minibatch 124::LR 0.0284615384615 --> Loss 0.00259421428045\n",
      "Epoch 32::Minibatch 125::LR 0.0284615384615 --> Loss 0.00438984751701\n",
      "Epoch 32::Minibatch 126::LR 0.0284615384615 --> Loss 0.0024202422301\n",
      "Epoch 32::Minibatch 127::LR 0.0284615384615 --> Loss 0.00485741774241\n",
      "Epoch 32::Minibatch 128::LR 0.0284615384615 --> Loss 0.00349658409754\n",
      "Epoch 32::Minibatch 129::LR 0.0284615384615 --> Loss 0.00237106005351\n",
      "Epoch 32::Minibatch 130::LR 0.0284615384615 --> Loss 0.00430928866069\n",
      "Epoch 32::Minibatch 131::LR 0.0284615384615 --> Loss 0.00170035143693\n",
      "Epoch 32::Minibatch 132::LR 0.0284615384615 --> Loss 0.00280148088932\n",
      "Epoch 32::Minibatch 133::LR 0.0284615384615 --> Loss 0.00270927190781\n",
      "Epoch 32::Minibatch 134::LR 0.0284615384615 --> Loss 0.00210131069024\n",
      "Epoch 32::Minibatch 135::LR 0.0284615384615 --> Loss 0.00126620282729\n",
      "Epoch 32::Minibatch 136::LR 0.0284615384615 --> Loss 0.00240770975749\n",
      "Epoch 32::Minibatch 137::LR 0.0284615384615 --> Loss 0.00335976441701\n",
      "Epoch 32::Minibatch 138::LR 0.0284615384615 --> Loss 0.00120737423499\n",
      "Epoch 32::Minibatch 139::LR 0.0284615384615 --> Loss 0.00186429897944\n",
      "Epoch 32::Minibatch 140::LR 0.0284615384615 --> Loss 0.0023713807265\n",
      "Epoch 32::Minibatch 141::LR 0.0284615384615 --> Loss 0.00287853638331\n",
      "Epoch 32::Minibatch 142::LR 0.0284615384615 --> Loss 0.00269100268682\n",
      "Epoch 32::Minibatch 143::LR 0.0284615384615 --> Loss 0.000536214361588\n",
      "Epoch 32::Minibatch 144::LR 0.0284615384615 --> Loss 0.00336248954137\n",
      "Epoch 32::Minibatch 145::LR 0.0284615384615 --> Loss 0.00411197741826\n",
      "Epoch 32::Minibatch 146::LR 0.0284615384615 --> Loss 0.00249055624008\n",
      "Epoch 32::Minibatch 147::LR 0.0284615384615 --> Loss 0.00178515930971\n",
      "Epoch 32::Minibatch 148::LR 0.0284615384615 --> Loss 0.000966926614443\n",
      "Epoch 32::Minibatch 149::LR 0.0284615384615 --> Loss 0.00285713136196\n",
      "Epoch 32::Minibatch 150::LR 0.0284615384615 --> Loss 0.00265640715758\n",
      "Epoch 32::Minibatch 151::LR 0.0284615384615 --> Loss 0.00427988648415\n",
      "Epoch 32::Minibatch 152::LR 0.0284615384615 --> Loss 0.000901516377926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 153::LR 0.0284615384615 --> Loss 0.00162965297699\n",
      "Epoch 32::Minibatch 154::LR 0.0284615384615 --> Loss 0.00200729211171\n",
      "Epoch 32::Minibatch 155::LR 0.0284615384615 --> Loss 0.00406819740931\n",
      "Epoch 32::Minibatch 156::LR 0.0284615384615 --> Loss 0.00234999338786\n",
      "Epoch 32::Minibatch 157::LR 0.0284615384615 --> Loss 0.000684792846441\n",
      "Epoch 32::Minibatch 158::LR 0.0284615384615 --> Loss 0.00315971473853\n",
      "Epoch 32::Minibatch 159::LR 0.0284615384615 --> Loss 0.00272146582603\n",
      "Epoch 32::Minibatch 160::LR 0.0284615384615 --> Loss 0.00264975031217\n",
      "Epoch 32::Minibatch 161::LR 0.0284615384615 --> Loss 0.000999662776788\n",
      "Epoch 32::Minibatch 162::LR 0.0284615384615 --> Loss 0.00394085764885\n",
      "Epoch 32::Minibatch 163::LR 0.0284615384615 --> Loss 0.00239909470081\n",
      "Epoch 32::Minibatch 164::LR 0.0284615384615 --> Loss 0.00253064731757\n",
      "Epoch 32::Minibatch 165::LR 0.0284615384615 --> Loss 0.000496925959984\n",
      "Epoch 32::Minibatch 166::LR 0.0284615384615 --> Loss 0.00170666217804\n",
      "Epoch 32::Minibatch 167::LR 0.0284615384615 --> Loss 0.00247388144334\n",
      "Epoch 32::Minibatch 168::LR 0.0284615384615 --> Loss 0.00214000960191\n",
      "Epoch 32::Minibatch 169::LR 0.0284615384615 --> Loss 0.000988755822182\n",
      "Epoch 32::Minibatch 170::LR 0.0284615384615 --> Loss 0.000953379174074\n",
      "Epoch 32::Minibatch 171::LR 0.0284615384615 --> Loss 0.00250811000665\n",
      "Epoch 32::Minibatch 172::LR 0.0284615384615 --> Loss 0.00425033609072\n",
      "Epoch 32::Minibatch 173::LR 0.0284615384615 --> Loss 0.00199853181839\n",
      "Epoch 32::Minibatch 174::LR 0.0284615384615 --> Loss 0.000960718592008\n",
      "Epoch 32::Minibatch 175::LR 0.0284615384615 --> Loss 0.0023575737079\n",
      "Epoch 32::Minibatch 176::LR 0.0284615384615 --> Loss 0.00311981379986\n",
      "Epoch 32::Minibatch 177::LR 0.0284615384615 --> Loss 0.00427330732346\n",
      "Epoch 32::Minibatch 178::LR 0.0284615384615 --> Loss 0.00150574088097\n",
      "Epoch 32::Minibatch 179::LR 0.0284615384615 --> Loss 0.00120707243681\n",
      "Epoch 32::Minibatch 180::LR 0.0284615384615 --> Loss 0.00339406013489\n",
      "Epoch 32::Minibatch 181::LR 0.0284615384615 --> Loss 0.0030551469326\n",
      "Epoch 32::Minibatch 182::LR 0.0284615384615 --> Loss 0.000707924664021\n",
      "Epoch 32::Minibatch 183::LR 0.0284615384615 --> Loss 0.00156679650148\n",
      "Epoch 32::Minibatch 184::LR 0.0284615384615 --> Loss 0.0034001493454\n",
      "Epoch 32::Minibatch 185::LR 0.0284615384615 --> Loss 0.00267661889394\n",
      "Epoch 32::Minibatch 186::LR 0.0284615384615 --> Loss 0.000929647684097\n",
      "Epoch 32::Minibatch 187::LR 0.0284615384615 --> Loss 0.00127328167359\n",
      "Epoch 32::Minibatch 188::LR 0.0284615384615 --> Loss 0.00404951492945\n",
      "Epoch 32::Minibatch 189::LR 0.0284615384615 --> Loss 0.00413496891658\n",
      "Epoch 32::Minibatch 190::LR 0.0284615384615 --> Loss 0.00231148680051\n",
      "Epoch 32::Minibatch 191::LR 0.0284615384615 --> Loss 0.000450562934081\n",
      "Epoch 32::Minibatch 192::LR 0.0284615384615 --> Loss 0.00277260859807\n",
      "Epoch 32::Minibatch 193::LR 0.0284615384615 --> Loss 0.00268338898818\n",
      "Epoch 32::Minibatch 194::LR 0.0284615384615 --> Loss 0.00173759102821\n",
      "Epoch 32::Minibatch 195::LR 0.0284615384615 --> Loss 0.000375955154498\n",
      "Epoch 32::Minibatch 196::LR 0.0284615384615 --> Loss 0.00134907851617\n",
      "Epoch 32::Minibatch 197::LR 0.0284615384615 --> Loss 0.00295484383901\n",
      "Epoch 32::Minibatch 198::LR 0.0284615384615 --> Loss 0.002304550608\n",
      "Epoch 32::Minibatch 199::LR 0.0284615384615 --> Loss 0.000290287286043\n",
      "Epoch 32::Minibatch 200::LR 0.0284615384615 --> Loss 0.00203771412373\n",
      "Epoch 32::Minibatch 201::LR 0.0284615384615 --> Loss 0.00193129301071\n",
      "Epoch 32::Minibatch 202::LR 0.0284615384615 --> Loss 0.001818151474\n",
      "Epoch 32::Minibatch 203::LR 0.0284615384615 --> Loss 0.00175149857998\n",
      "Epoch 32::Minibatch 204::LR 0.0284615384615 --> Loss 0.00141667624315\n",
      "Epoch 32::Minibatch 205::LR 0.0284615384615 --> Loss 0.00221024096012\n",
      "Epoch 32::Minibatch 206::LR 0.0284615384615 --> Loss 0.00551639755567\n",
      "Epoch 32::Minibatch 207::LR 0.0284615384615 --> Loss 0.00139806270599\n",
      "Epoch 32::Minibatch 208::LR 0.0284615384615 --> Loss 0.0011051979661\n",
      "Epoch 32::Minibatch 209::LR 0.0284615384615 --> Loss 0.00247191150983\n",
      "Epoch 32::Minibatch 210::LR 0.0284615384615 --> Loss 0.00232893149058\n",
      "Epoch 32::Minibatch 211::LR 0.0284615384615 --> Loss 0.00264751235644\n",
      "Epoch 32::Minibatch 212::LR 0.0284615384615 --> Loss 0.00376970251401\n",
      "Epoch 32::Minibatch 213::LR 0.0284615384615 --> Loss 0.00541481018066\n",
      "Epoch 32::Minibatch 214::LR 0.0284615384615 --> Loss 0.00721260786057\n",
      "Epoch 32::Minibatch 215::LR 0.0284615384615 --> Loss 0.00135967105627\n",
      "Epoch 32::Minibatch 216::LR 0.0284615384615 --> Loss 0.00529808680216\n",
      "Epoch 32::Minibatch 217::LR 0.0284615384615 --> Loss 0.00584934512774\n",
      "Epoch 32::Minibatch 218::LR 0.0284615384615 --> Loss 0.00389524539312\n",
      "Epoch 32::Minibatch 219::LR 0.0284615384615 --> Loss 0.00439210851987\n",
      "Epoch 32::Minibatch 220::LR 0.0284615384615 --> Loss 0.00435669660568\n",
      "Epoch 32::Minibatch 221::LR 0.0284615384615 --> Loss 0.00424814462662\n",
      "Epoch 32::Minibatch 222::LR 0.0284615384615 --> Loss 0.00316296577454\n",
      "Epoch 32::Minibatch 223::LR 0.0284615384615 --> Loss 0.00138346344233\n",
      "Epoch 32::Minibatch 224::LR 0.0284615384615 --> Loss 0.00160034120083\n",
      "Epoch 32::Minibatch 225::LR 0.0284615384615 --> Loss 0.00777805566788\n",
      "Epoch 32::Minibatch 226::LR 0.0284615384615 --> Loss 0.00365738471349\n",
      "Epoch 32::Minibatch 227::LR 0.0284615384615 --> Loss 0.00167818208536\n",
      "Epoch 32::Minibatch 228::LR 0.0284615384615 --> Loss 0.000656782239676\n",
      "Epoch 32::Minibatch 229::LR 0.0284615384615 --> Loss 0.00471340179443\n",
      "Epoch 32::Minibatch 230::LR 0.0284615384615 --> Loss 0.00368687113126\n",
      "Epoch 32::Minibatch 231::LR 0.0284615384615 --> Loss 0.00266086061796\n",
      "Epoch 32::Minibatch 232::LR 0.0284615384615 --> Loss 0.00116545985142\n",
      "Epoch 32::Minibatch 233::LR 0.0284615384615 --> Loss 0.00246027827263\n",
      "Epoch 32::Minibatch 234::LR 0.0284615384615 --> Loss 0.00732017437617\n",
      "Epoch 32::Minibatch 235::LR 0.0284615384615 --> Loss 0.00456335544586\n",
      "Epoch 32::Minibatch 236::LR 0.0284615384615 --> Loss 0.00167728086313\n",
      "Epoch 32::Minibatch 237::LR 0.0284615384615 --> Loss 0.000593055933714\n",
      "Epoch 32::Minibatch 238::LR 0.0284615384615 --> Loss 0.00343612511953\n",
      "Epoch 32::Minibatch 239::LR 0.0284615384615 --> Loss 0.00295692582925\n",
      "Epoch 32::Minibatch 240::LR 0.0284615384615 --> Loss 0.00324876924356\n",
      "Epoch 32::Minibatch 241::LR 0.0284615384615 --> Loss 0.000743948817253\n",
      "Epoch 32::Minibatch 242::LR 0.0284615384615 --> Loss 0.00672718207041\n",
      "Epoch 32::Minibatch 243::LR 0.0284615384615 --> Loss 0.00327487766743\n",
      "Epoch 32::Minibatch 244::LR 0.0284615384615 --> Loss 0.00274588565032\n",
      "Epoch 32::Minibatch 245::LR 0.0284615384615 --> Loss 0.000430888036887\n",
      "Epoch 32::Minibatch 246::LR 0.0284615384615 --> Loss 0.00191476384799\n",
      "Epoch 32::Minibatch 247::LR 0.0284615384615 --> Loss 0.0106357534726\n",
      "Epoch 32::Minibatch 248::LR 0.0284615384615 --> Loss 0.00434514244397\n",
      "Epoch 32::Minibatch 249::LR 0.0284615384615 --> Loss 0.0024177801609\n",
      "Epoch 32::Minibatch 250::LR 0.0284615384615 --> Loss 0.00235144615173\n",
      "Epoch 32::Minibatch 251::LR 0.0284615384615 --> Loss 0.00233961443106\n",
      "Epoch 32::Minibatch 252::LR 0.0284615384615 --> Loss 0.00161836743355\n",
      "Epoch 32::Minibatch 253::LR 0.0284615384615 --> Loss 0.00280727684498\n",
      "Epoch 32::Minibatch 254::LR 0.0284615384615 --> Loss 0.00484065890312\n",
      "Epoch 32::Minibatch 255::LR 0.0284615384615 --> Loss 0.00384028514226\n",
      "Epoch 32::Minibatch 256::LR 0.0284615384615 --> Loss 0.00140756815672\n",
      "Epoch 32::Minibatch 257::LR 0.0284615384615 --> Loss 0.00114055981239\n",
      "Epoch 32::Minibatch 258::LR 0.0284615384615 --> Loss 0.00365290085475\n",
      "Epoch 32::Minibatch 259::LR 0.0284615384615 --> Loss 0.00160005152225\n",
      "Epoch 32::Minibatch 260::LR 0.0284615384615 --> Loss 0.00184541801612\n",
      "Epoch 32::Minibatch 261::LR 0.0284615384615 --> Loss 0.00266538540522\n",
      "Epoch 32::Minibatch 262::LR 0.0284615384615 --> Loss 0.00181738535563\n",
      "Epoch 32::Minibatch 263::LR 0.0284615384615 --> Loss 0.00228662351767\n",
      "Epoch 32::Minibatch 264::LR 0.0284615384615 --> Loss 0.00355582873027\n",
      "Epoch 32::Minibatch 265::LR 0.0284615384615 --> Loss 0.00992179632187\n",
      "Epoch 32::Minibatch 266::LR 0.0284615384615 --> Loss 0.000887129108111\n",
      "Epoch 32::Minibatch 267::LR 0.0284615384615 --> Loss 0.00912593126297\n",
      "Epoch 32::Minibatch 268::LR 0.0284615384615 --> Loss 0.00104172825813\n",
      "Epoch 32::Minibatch 269::LR 0.0284615384615 --> Loss 0.00346194505692\n",
      "Epoch 32::Minibatch 270::LR 0.0284615384615 --> Loss 0.00727292696635\n",
      "Epoch 32::Minibatch 271::LR 0.0284615384615 --> Loss 0.00243391414483\n",
      "Epoch 32::Minibatch 272::LR 0.0284615384615 --> Loss 0.00439993580182\n",
      "Epoch 32::Minibatch 273::LR 0.0284615384615 --> Loss 0.0013907734553\n",
      "Epoch 32::Minibatch 274::LR 0.0284615384615 --> Loss 0.00177146156629\n",
      "Epoch 32::Minibatch 275::LR 0.0284615384615 --> Loss 0.00247132599354\n",
      "Epoch 32::Minibatch 276::LR 0.0284615384615 --> Loss 0.003354083697\n",
      "Epoch 32::Minibatch 277::LR 0.0284615384615 --> Loss 0.000873064498107\n",
      "Epoch 32::Minibatch 278::LR 0.0284615384615 --> Loss 0.00253882487615\n",
      "Epoch 32::Minibatch 279::LR 0.0284615384615 --> Loss 0.00201337794463\n",
      "Epoch 32::Minibatch 280::LR 0.0284615384615 --> Loss 0.00178034087022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 281::LR 0.0284615384615 --> Loss 0.00112870593866\n",
      "Epoch 32::Minibatch 282::LR 0.0284615384615 --> Loss 0.00202028433482\n",
      "Epoch 32::Minibatch 283::LR 0.0284615384615 --> Loss 0.00192484676838\n",
      "Epoch 32::Minibatch 284::LR 0.0284615384615 --> Loss 0.00157102942467\n",
      "Epoch 32::Minibatch 285::LR 0.0284615384615 --> Loss 0.00112790346146\n",
      "Epoch 32::Minibatch 286::LR 0.0284615384615 --> Loss 0.00196492711703\n",
      "Epoch 32::Minibatch 287::LR 0.0284615384615 --> Loss 0.0019433927536\n",
      "Epoch 32::Minibatch 288::LR 0.0284615384615 --> Loss 0.00105830440919\n",
      "Epoch 32::Minibatch 289::LR 0.0284615384615 --> Loss 0.00155703792969\n",
      "Epoch 32::Minibatch 290::LR 0.0284615384615 --> Loss 0.00184877554576\n",
      "Epoch 32::Minibatch 291::LR 0.0284615384615 --> Loss 0.0016612191995\n",
      "Epoch 32::Minibatch 292::LR 0.0284615384615 --> Loss 0.000587323705355\n",
      "Epoch 32::Minibatch 293::LR 0.0284615384615 --> Loss 0.00148885389169\n",
      "Epoch 32::Minibatch 294::LR 0.0284615384615 --> Loss 0.00161465138197\n",
      "Epoch 32::Minibatch 295::LR 0.0284615384615 --> Loss 0.00187887072563\n",
      "Epoch 32::Minibatch 296::LR 0.0284615384615 --> Loss 0.00162256658077\n",
      "Epoch 32::Minibatch 297::LR 0.0284615384615 --> Loss 0.00141930997372\n",
      "Epoch 32::Minibatch 298::LR 0.0284615384615 --> Loss 0.00142261087894\n",
      "Epoch 32::Minibatch 299::LR 0.0284615384615 --> Loss 0.000814540088177\n",
      "Epoch 32::Minibatch 300::LR 0.0284615384615 --> Loss 0.00268579204877\n",
      "Epoch 32::Minibatch 301::LR 0.0284615384615 --> Loss 0.00259707351526\n",
      "Epoch 32::Minibatch 302::LR 0.0284615384615 --> Loss 0.00238554934661\n",
      "Epoch 32::Minibatch 303::LR 0.0284615384615 --> Loss 0.000831522146861\n",
      "Epoch 32::Minibatch 304::LR 0.0284615384615 --> Loss 0.00293720324834\n",
      "Epoch 32::Minibatch 305::LR 0.0284615384615 --> Loss 0.00171320080757\n",
      "Epoch 32::Minibatch 306::LR 0.0284615384615 --> Loss 0.00093837082386\n",
      "Epoch 32::Minibatch 307::LR 0.0284615384615 --> Loss 0.00240014394124\n",
      "Epoch 32::Minibatch 308::LR 0.0284615384615 --> Loss 0.00202024062475\n",
      "Epoch 32::Minibatch 309::LR 0.0284615384615 --> Loss 0.00104444742203\n",
      "Epoch 32::Minibatch 310::LR 0.0284615384615 --> Loss 0.0011943846941\n",
      "Epoch 32::Minibatch 311::LR 0.0284615384615 --> Loss 0.00179607907931\n",
      "Epoch 32::Minibatch 312::LR 0.0284615384615 --> Loss 0.00285340706507\n",
      "Epoch 32::Minibatch 313::LR 0.0284615384615 --> Loss 0.00233811954657\n",
      "Epoch 32::Minibatch 314::LR 0.0284615384615 --> Loss 0.00192385454973\n",
      "Epoch 32::Minibatch 315::LR 0.0284615384615 --> Loss 0.00104837040106\n",
      "Epoch 32::Minibatch 316::LR 0.0284615384615 --> Loss 0.00234530727069\n",
      "Epoch 32::Minibatch 317::LR 0.0284615384615 --> Loss 0.00156447976828\n",
      "Epoch 32::Minibatch 318::LR 0.0284615384615 --> Loss 0.0013084401687\n",
      "Epoch 32::Minibatch 319::LR 0.0284615384615 --> Loss 0.00230908413728\n",
      "Epoch 32::Minibatch 320::LR 0.0284615384615 --> Loss 0.00303384025892\n",
      "Epoch 32::Minibatch 321::LR 0.0284615384615 --> Loss 0.000842517614365\n",
      "Epoch 32::Minibatch 322::LR 0.0284615384615 --> Loss 0.00344825228055\n",
      "Epoch 32::Minibatch 323::LR 0.0284615384615 --> Loss 0.00341799139977\n",
      "Epoch 32::Minibatch 324::LR 0.0284615384615 --> Loss 0.00265002032121\n",
      "Epoch 32::Minibatch 325::LR 0.0284615384615 --> Loss 0.00237139860789\n",
      "Epoch 32::Minibatch 326::LR 0.0284615384615 --> Loss 0.0052771683534\n",
      "Epoch 32::Minibatch 327::LR 0.0284615384615 --> Loss 0.00222905377547\n",
      "Epoch 32::Minibatch 328::LR 0.0284615384615 --> Loss 0.00294614473979\n",
      "Epoch 32::Minibatch 329::LR 0.0284615384615 --> Loss 0.00119224329789\n",
      "Epoch 32::Minibatch 330::LR 0.0284615384615 --> Loss 0.00158870985111\n",
      "Epoch 32::Minibatch 331::LR 0.0284615384615 --> Loss 0.00253400524457\n",
      "Epoch 32::Minibatch 332::LR 0.0284615384615 --> Loss 0.00245215594769\n",
      "Epoch 32::Minibatch 333::LR 0.0284615384615 --> Loss 0.00146981924772\n",
      "Epoch 32::Minibatch 334::LR 0.0284615384615 --> Loss 0.00440870046616\n",
      "Epoch 32::Minibatch 335::LR 0.0284615384615 --> Loss 0.00190061370532\n",
      "Epoch 32::Minibatch 336::LR 0.0284615384615 --> Loss 0.00225949068864\n",
      "Epoch 32::Minibatch 337::LR 0.0284615384615 --> Loss 0.0037376443545\n",
      "Epoch 32::Minibatch 338::LR 0.0284615384615 --> Loss 0.000554392486811\n",
      "Epoch 32::Minibatch 339::LR 0.0284615384615 --> Loss 0.00324593782425\n",
      "Epoch 32::Minibatch 340::LR 0.0284615384615 --> Loss 0.00368015289307\n",
      "Epoch 32::Minibatch 341::LR 0.0284615384615 --> Loss 0.00430482506752\n",
      "Epoch 32::Minibatch 342::LR 0.0284615384615 --> Loss 0.0030582255125\n",
      "Epoch 32::Minibatch 343::LR 0.0284615384615 --> Loss 0.00163918584585\n",
      "Epoch 32::Minibatch 344::LR 0.0284615384615 --> Loss 0.00316102127234\n",
      "Epoch 32::Minibatch 345::LR 0.0284615384615 --> Loss 0.00408184607824\n",
      "Epoch 32::Minibatch 346::LR 0.0284615384615 --> Loss 0.0053672170639\n",
      "Epoch 32::Minibatch 347::LR 0.0284615384615 --> Loss 0.000819520850976\n",
      "Epoch 32::Minibatch 348::LR 0.0284615384615 --> Loss 0.00299582521121\n",
      "Epoch 32::Minibatch 349::LR 0.0284615384615 --> Loss 0.00336569547653\n",
      "Epoch 32::Minibatch 350::LR 0.0284615384615 --> Loss 0.00165118157864\n",
      "Epoch 32::Minibatch 351::LR 0.0284615384615 --> Loss 0.00343181331952\n",
      "Epoch 32::Minibatch 352::LR 0.0284615384615 --> Loss 0.00489967107773\n",
      "Epoch 32::Minibatch 353::LR 0.0284615384615 --> Loss 0.00350332816442\n",
      "Epoch 32::Minibatch 354::LR 0.0284615384615 --> Loss 0.00294092198213\n",
      "Epoch 32::Minibatch 355::LR 0.0284615384615 --> Loss 0.00625593344371\n",
      "Epoch 32::Minibatch 356::LR 0.0284615384615 --> Loss 0.003153804938\n",
      "Epoch 32::Minibatch 357::LR 0.0284615384615 --> Loss 0.00117321232955\n",
      "Epoch 32::Minibatch 358::LR 0.0284615384615 --> Loss 0.00195141772429\n",
      "Epoch 32::Minibatch 359::LR 0.0284615384615 --> Loss 0.00267352680365\n",
      "Epoch 32::Minibatch 360::LR 0.0284615384615 --> Loss 0.0022954672575\n",
      "Epoch 32::Minibatch 361::LR 0.0284615384615 --> Loss 0.00226365288099\n",
      "Epoch 32::Minibatch 362::LR 0.0284615384615 --> Loss 0.00225242416064\n",
      "Epoch 32::Minibatch 363::LR 0.0284615384615 --> Loss 0.000636080503464\n",
      "Epoch 32::Minibatch 364::LR 0.0284615384615 --> Loss 0.00197055439154\n",
      "Epoch 32::Minibatch 365::LR 0.0284615384615 --> Loss 0.00200383047263\n",
      "Epoch 32::Minibatch 366::LR 0.0284615384615 --> Loss 0.00212249120076\n",
      "Epoch 32::Minibatch 367::LR 0.0284615384615 --> Loss 0.000995284219583\n",
      "Epoch 32::Minibatch 368::LR 0.0284615384615 --> Loss 0.000973379015923\n",
      "Epoch 32::Minibatch 369::LR 0.0284615384615 --> Loss 0.0027600089709\n",
      "Epoch 32::Minibatch 370::LR 0.0284615384615 --> Loss 0.00220820407073\n",
      "Epoch 32::Minibatch 371::LR 0.0284615384615 --> Loss 0.00184631089369\n",
      "Epoch 32::Minibatch 372::LR 0.0284615384615 --> Loss 0.000428751409054\n",
      "Epoch 32::Minibatch 373::LR 0.0284615384615 --> Loss 0.0018059104681\n",
      "Epoch 32::Minibatch 374::LR 0.0284615384615 --> Loss 0.00225211580594\n",
      "Epoch 32::Minibatch 375::LR 0.0284615384615 --> Loss 0.00188934862614\n",
      "Epoch 32::Minibatch 376::LR 0.0284615384615 --> Loss 0.00120707879464\n",
      "Epoch 32::Minibatch 377::LR 0.0284615384615 --> Loss 0.00190982838472\n",
      "Epoch 32::Minibatch 378::LR 0.0284615384615 --> Loss 0.00209292550882\n",
      "Epoch 32::Minibatch 379::LR 0.0284615384615 --> Loss 0.00232109308243\n",
      "Epoch 32::Minibatch 380::LR 0.0284615384615 --> Loss 0.00156365772088\n",
      "Epoch 32::Minibatch 381::LR 0.0284615384615 --> Loss 0.000993674397469\n",
      "Epoch 32::Minibatch 382::LR 0.0284615384615 --> Loss 0.00203595757484\n",
      "Epoch 32::Minibatch 383::LR 0.0284615384615 --> Loss 0.00198915481567\n",
      "Epoch 32::Minibatch 384::LR 0.0284615384615 --> Loss 0.00111958434184\n",
      "Epoch 32::Minibatch 385::LR 0.0284615384615 --> Loss 0.00105664889018\n",
      "Epoch 32::Minibatch 386::LR 0.0284615384615 --> Loss 0.00224584877491\n",
      "Epoch 32::Minibatch 387::LR 0.0284615384615 --> Loss 0.00236310501893\n",
      "Epoch 32::Minibatch 388::LR 0.0284615384615 --> Loss 0.00121351182461\n",
      "Epoch 32::Minibatch 389::LR 0.0284615384615 --> Loss 0.00178383171558\n",
      "Epoch 32::Minibatch 390::LR 0.0284615384615 --> Loss 0.00326824406783\n",
      "Epoch 32::Minibatch 391::LR 0.0284615384615 --> Loss 0.00255461414655\n",
      "Epoch 32::Minibatch 392::LR 0.0284615384615 --> Loss 0.00255870640278\n",
      "Epoch 32::Minibatch 393::LR 0.0284615384615 --> Loss 0.00273022413254\n",
      "Epoch 32::Minibatch 394::LR 0.0284615384615 --> Loss 0.00200789193312\n",
      "Epoch 32::Minibatch 395::LR 0.0284615384615 --> Loss 0.00207137366136\n",
      "Epoch 32::Minibatch 396::LR 0.0284615384615 --> Loss 0.00193876187007\n",
      "Epoch 32::Minibatch 397::LR 0.0284615384615 --> Loss 0.00207506318887\n",
      "Epoch 32::Minibatch 398::LR 0.0284615384615 --> Loss 0.0020640283823\n",
      "Epoch 32::Minibatch 399::LR 0.0284615384615 --> Loss 0.00237029949824\n",
      "Epoch 32::Minibatch 400::LR 0.0284615384615 --> Loss 0.0020075861613\n",
      "Epoch 32::Minibatch 401::LR 0.0284615384615 --> Loss 0.00340839266777\n",
      "Epoch 32::Minibatch 402::LR 0.0284615384615 --> Loss 0.00171865959962\n",
      "Epoch 32::Minibatch 403::LR 0.0284615384615 --> Loss 0.00142638375362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 404::LR 0.0284615384615 --> Loss 0.00133658538262\n",
      "Epoch 32::Minibatch 405::LR 0.0284615384615 --> Loss 0.0033317510287\n",
      "Epoch 32::Minibatch 406::LR 0.0284615384615 --> Loss 0.00233838796616\n",
      "Epoch 32::Minibatch 407::LR 0.0284615384615 --> Loss 0.00170326193174\n",
      "Epoch 32::Minibatch 408::LR 0.0284615384615 --> Loss 0.000431912094355\n",
      "Epoch 32::Minibatch 409::LR 0.0284615384615 --> Loss 0.00220848759015\n",
      "Epoch 32::Minibatch 410::LR 0.0284615384615 --> Loss 0.00313135941823\n",
      "Epoch 32::Minibatch 411::LR 0.0284615384615 --> Loss 0.00165897776683\n",
      "Epoch 32::Minibatch 412::LR 0.0284615384615 --> Loss 0.00094103872776\n",
      "Epoch 32::Minibatch 413::LR 0.0284615384615 --> Loss 0.00197032610575\n",
      "Epoch 32::Minibatch 414::LR 0.0284615384615 --> Loss 0.00187049508095\n",
      "Epoch 32::Minibatch 415::LR 0.0284615384615 --> Loss 0.00116935958465\n",
      "Epoch 32::Minibatch 416::LR 0.0284615384615 --> Loss 0.000789219836394\n",
      "Epoch 32::Minibatch 417::LR 0.0284615384615 --> Loss 0.00167448699474\n",
      "Epoch 32::Minibatch 418::LR 0.0284615384615 --> Loss 0.00258465925852\n",
      "Epoch 32::Minibatch 419::LR 0.0284615384615 --> Loss 0.000488973408937\n",
      "Epoch 32::Minibatch 420::LR 0.0284615384615 --> Loss 0.000687693258127\n",
      "Epoch 32::Minibatch 421::LR 0.0284615384615 --> Loss 0.0018674103419\n",
      "Epoch 32::Minibatch 422::LR 0.0284615384615 --> Loss 0.00205627858639\n",
      "Epoch 32::Minibatch 423::LR 0.0284615384615 --> Loss 0.000981107354164\n",
      "Epoch 32::Minibatch 424::LR 0.0284615384615 --> Loss 0.00151550352573\n",
      "Epoch 32::Minibatch 425::LR 0.0284615384615 --> Loss 0.00286085526148\n",
      "Epoch 32::Minibatch 426::LR 0.0284615384615 --> Loss 0.00198639074961\n",
      "Epoch 32::Minibatch 427::LR 0.0284615384615 --> Loss 0.000732537756364\n",
      "Epoch 32::Minibatch 428::LR 0.0284615384615 --> Loss 0.000931910673777\n",
      "Epoch 32::Minibatch 429::LR 0.0284615384615 --> Loss 0.002237474521\n",
      "Epoch 32::Minibatch 430::LR 0.0284615384615 --> Loss 0.00790148258209\n",
      "Epoch 32::Minibatch 431::LR 0.0284615384615 --> Loss 0.00357337435087\n",
      "Epoch 32::Minibatch 432::LR 0.0284615384615 --> Loss 0.00400909384092\n",
      "Epoch 32::Minibatch 433::LR 0.0284615384615 --> Loss 0.00253037134806\n",
      "Epoch 32::Minibatch 434::LR 0.0284615384615 --> Loss 0.00243815700213\n",
      "Epoch 32::Minibatch 435::LR 0.0284615384615 --> Loss 0.00224798838298\n",
      "Epoch 32::Minibatch 436::LR 0.0284615384615 --> Loss 0.0015935159723\n",
      "Epoch 32::Minibatch 437::LR 0.0284615384615 --> Loss 0.0028145468235\n",
      "Epoch 32::Minibatch 438::LR 0.0284615384615 --> Loss 0.00226223150889\n",
      "Epoch 32::Minibatch 439::LR 0.0284615384615 --> Loss 0.00191603978475\n",
      "Epoch 32::Minibatch 440::LR 0.0284615384615 --> Loss 0.00296009302139\n",
      "Epoch 32::Minibatch 441::LR 0.0284615384615 --> Loss 0.00276697496573\n",
      "Epoch 32::Minibatch 442::LR 0.0284615384615 --> Loss 0.00247481564681\n",
      "Epoch 32::Minibatch 443::LR 0.0284615384615 --> Loss 0.00345013459524\n",
      "Epoch 32::Minibatch 444::LR 0.0284615384615 --> Loss 0.002662525177\n",
      "Epoch 32::Minibatch 445::LR 0.0284615384615 --> Loss 0.000845418175062\n",
      "Epoch 32::Minibatch 446::LR 0.0284615384615 --> Loss 0.0013591731588\n",
      "Epoch 32::Minibatch 447::LR 0.0284615384615 --> Loss 0.00228111863136\n",
      "Epoch 32::Minibatch 448::LR 0.0284615384615 --> Loss 0.00230452378591\n",
      "Epoch 32::Minibatch 449::LR 0.0284615384615 --> Loss 0.00355832060178\n",
      "Epoch 32::Minibatch 450::LR 0.0284615384615 --> Loss 0.00212284485499\n",
      "Epoch 32::Minibatch 451::LR 0.0284615384615 --> Loss 0.00381732185682\n",
      "Epoch 32::Minibatch 452::LR 0.0284615384615 --> Loss 0.00228645384312\n",
      "Epoch 32::Minibatch 453::LR 0.0284615384615 --> Loss 0.000348184828957\n",
      "Epoch 32::Minibatch 454::LR 0.0284615384615 --> Loss 0.00341736237208\n",
      "Epoch 32::Minibatch 455::LR 0.0284615384615 --> Loss 0.00257669667403\n",
      "Epoch 32::Minibatch 456::LR 0.0284615384615 --> Loss 0.00304069956144\n",
      "Epoch 32::Minibatch 457::LR 0.0284615384615 --> Loss 0.00186952034632\n",
      "Epoch 32::Minibatch 458::LR 0.0284615384615 --> Loss 0.000713559339444\n",
      "Epoch 32::Minibatch 459::LR 0.0284615384615 --> Loss 0.00382835268974\n",
      "Epoch 32::Minibatch 460::LR 0.0284615384615 --> Loss 0.00242150962353\n",
      "Epoch 32::Minibatch 461::LR 0.0284615384615 --> Loss 0.00367274522781\n",
      "Epoch 32::Minibatch 462::LR 0.0284615384615 --> Loss 0.000368566562732\n",
      "Epoch 32::Minibatch 463::LR 0.0284615384615 --> Loss 0.00409444967906\n",
      "Epoch 32::Minibatch 464::LR 0.0284615384615 --> Loss 0.00194081763426\n",
      "Epoch 32::Minibatch 465::LR 0.0284615384615 --> Loss 0.00449973781904\n",
      "Epoch 32::Minibatch 466::LR 0.0284615384615 --> Loss 0.0049443658193\n",
      "Epoch 32::Minibatch 467::LR 0.0284615384615 --> Loss 0.00505745530128\n",
      "Epoch 32::Minibatch 468::LR 0.0284615384615 --> Loss 0.00563278675079\n",
      "Epoch 32::Minibatch 469::LR 0.0284615384615 --> Loss 0.0059598215421\n",
      "Epoch 32::Minibatch 470::LR 0.0284615384615 --> Loss 0.00356521288554\n",
      "Epoch 32::Minibatch 471::LR 0.0284615384615 --> Loss 0.00165976494551\n",
      "Epoch 32::Minibatch 472::LR 0.0284615384615 --> Loss 0.00355852882067\n",
      "Epoch 32::Minibatch 473::LR 0.0284615384615 --> Loss 0.00230714937051\n",
      "Epoch 32::Minibatch 474::LR 0.0284615384615 --> Loss 0.000689086814721\n",
      "Epoch 32::Minibatch 475::LR 0.0284615384615 --> Loss 0.00476306080818\n",
      "Epoch 32::Minibatch 476::LR 0.0284615384615 --> Loss 0.00761137326558\n",
      "Epoch 32::Minibatch 477::LR 0.0284615384615 --> Loss 0.000915727118651\n",
      "Epoch 32::Minibatch 478::LR 0.0284615384615 --> Loss 0.00240533371766\n",
      "Epoch 32::Minibatch 479::LR 0.0284615384615 --> Loss 0.00195922235648\n",
      "Epoch 32::Minibatch 480::LR 0.0284615384615 --> Loss 0.00151220252117\n",
      "Epoch 32::Minibatch 481::LR 0.0284615384615 --> Loss 0.000957907835642\n",
      "Epoch 32::Minibatch 482::LR 0.0284615384615 --> Loss 0.00206596871217\n",
      "Epoch 32::Minibatch 483::LR 0.0284615384615 --> Loss 0.00301526586215\n",
      "Epoch 32::Minibatch 484::LR 0.0284615384615 --> Loss 0.00338457028071\n",
      "Epoch 32::Minibatch 485::LR 0.0284615384615 --> Loss 0.000761500994364\n",
      "Epoch 32::Minibatch 486::LR 0.0284615384615 --> Loss 0.00280966818333\n",
      "Epoch 32::Minibatch 487::LR 0.0284615384615 --> Loss 0.0032915465037\n",
      "Epoch 32::Minibatch 488::LR 0.0284615384615 --> Loss 0.00201774219672\n",
      "Epoch 32::Minibatch 489::LR 0.0284615384615 --> Loss 0.00306812306245\n",
      "Epoch 32::Minibatch 490::LR 0.0284615384615 --> Loss 0.000411952088277\n",
      "Epoch 32::Minibatch 491::LR 0.0284615384615 --> Loss 0.00319158136845\n",
      "Epoch 32::Minibatch 492::LR 0.0284615384615 --> Loss 0.00306343793869\n",
      "Epoch 32::Minibatch 493::LR 0.0284615384615 --> Loss 0.00301704704762\n",
      "Epoch 32::Minibatch 494::LR 0.0284615384615 --> Loss 0.0007324394087\n",
      "Epoch 32::Minibatch 495::LR 0.0284615384615 --> Loss 0.00182541489601\n",
      "Epoch 32::Minibatch 496::LR 0.0284615384615 --> Loss 0.0027800232172\n",
      "Epoch 32::Minibatch 497::LR 0.0284615384615 --> Loss 0.000914412240187\n",
      "Epoch 32::Minibatch 498::LR 0.0284615384615 --> Loss 0.000549610257149\n",
      "Epoch 32::Minibatch 499::LR 0.0284615384615 --> Loss 0.00339998761813\n",
      "Epoch 32::Minibatch 500::LR 0.0284615384615 --> Loss 0.00142467925946\n",
      "Epoch 32::Minibatch 501::LR 0.0284615384615 --> Loss 0.00202789465586\n",
      "Epoch 32::Minibatch 502::LR 0.0284615384615 --> Loss 0.00373364130656\n",
      "Epoch 32::Minibatch 503::LR 0.0284615384615 --> Loss 0.00676043907801\n",
      "Epoch 32::Minibatch 504::LR 0.0284615384615 --> Loss 0.00668094237645\n",
      "Epoch 32::Minibatch 505::LR 0.0284615384615 --> Loss 0.00393616040548\n",
      "Epoch 32::Minibatch 506::LR 0.0284615384615 --> Loss 0.00330241918564\n",
      "Epoch 32::Minibatch 507::LR 0.0284615384615 --> Loss 0.00573565920194\n",
      "Epoch 32::Minibatch 508::LR 0.0284615384615 --> Loss 0.00338445901871\n",
      "Epoch 32::Minibatch 509::LR 0.0284615384615 --> Loss 0.00423374334971\n",
      "Epoch 32::Minibatch 510::LR 0.0284615384615 --> Loss 0.00437879165014\n",
      "Epoch 32::Minibatch 511::LR 0.0284615384615 --> Loss 0.00399811069171\n",
      "Epoch 32::Minibatch 512::LR 0.0284615384615 --> Loss 0.00268093963464\n",
      "Epoch 32::Minibatch 513::LR 0.0284615384615 --> Loss 0.000596112559239\n",
      "Epoch 32::Minibatch 514::LR 0.0284615384615 --> Loss 0.00262293219566\n",
      "Epoch 32::Minibatch 515::LR 0.0284615384615 --> Loss 0.00299005369345\n",
      "Epoch 32::Minibatch 516::LR 0.0284615384615 --> Loss 0.00390840689341\n",
      "Epoch 32::Minibatch 517::LR 0.0284615384615 --> Loss 0.00362211227417\n",
      "Epoch 32::Minibatch 518::LR 0.0284615384615 --> Loss 0.00257432619731\n",
      "Epoch 32::Minibatch 519::LR 0.0284615384615 --> Loss 0.00354891061783\n",
      "Epoch 32::Minibatch 520::LR 0.0284615384615 --> Loss 0.00557464361191\n",
      "Epoch 32::Minibatch 521::LR 0.0284615384615 --> Loss 0.00563178102175\n",
      "Epoch 32::Minibatch 522::LR 0.0284615384615 --> Loss 0.00711887836456\n",
      "Epoch 32::Minibatch 523::LR 0.0284615384615 --> Loss 0.000622721910477\n",
      "Epoch 32::Minibatch 524::LR 0.0284615384615 --> Loss 0.00138982166847\n",
      "Epoch 32::Minibatch 525::LR 0.0284615384615 --> Loss 0.00304837147395\n",
      "Epoch 32::Minibatch 526::LR 0.0284615384615 --> Loss 0.00369991779327\n",
      "Epoch 32::Minibatch 527::LR 0.0284615384615 --> Loss 0.00212426344554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 528::LR 0.0284615384615 --> Loss 0.000924371977647\n",
      "Epoch 32::Minibatch 529::LR 0.0284615384615 --> Loss 0.00380607803663\n",
      "Epoch 32::Minibatch 530::LR 0.0284615384615 --> Loss 0.0037771765391\n",
      "Epoch 32::Minibatch 531::LR 0.0284615384615 --> Loss 0.00335570335388\n",
      "Epoch 32::Minibatch 532::LR 0.0284615384615 --> Loss 0.0025910794735\n",
      "Epoch 32::Minibatch 533::LR 0.0284615384615 --> Loss 0.00487544735273\n",
      "Epoch 32::Minibatch 534::LR 0.0284615384615 --> Loss 0.00367728908857\n",
      "Epoch 32::Minibatch 535::LR 0.0284615384615 --> Loss 0.00331455687682\n",
      "Epoch 32::Minibatch 536::LR 0.0284615384615 --> Loss 0.00210533857346\n",
      "Epoch 32::Minibatch 537::LR 0.0284615384615 --> Loss 0.000583358108997\n",
      "Epoch 32::Minibatch 538::LR 0.0284615384615 --> Loss 0.00163118253152\n",
      "Epoch 32::Minibatch 539::LR 0.0284615384615 --> Loss 0.00331037243207\n",
      "Epoch 32::Minibatch 540::LR 0.0284615384615 --> Loss 0.00338475028674\n",
      "Epoch 32::Minibatch 541::LR 0.0284615384615 --> Loss 0.00283775508404\n",
      "Epoch 32::Minibatch 542::LR 0.0284615384615 --> Loss 0.00243027448654\n",
      "Epoch 32::Minibatch 543::LR 0.0284615384615 --> Loss 0.00256669680278\n",
      "Epoch 32::Minibatch 544::LR 0.0284615384615 --> Loss 0.0040311229229\n",
      "Epoch 32::Minibatch 545::LR 0.0284615384615 --> Loss 0.00197081247965\n",
      "Epoch 32::Minibatch 546::LR 0.0284615384615 --> Loss 0.000660245120525\n",
      "Epoch 32::Minibatch 547::LR 0.0284615384615 --> Loss 0.00257680336634\n",
      "Epoch 32::Minibatch 548::LR 0.0284615384615 --> Loss 0.00339353283246\n",
      "Epoch 32::Minibatch 549::LR 0.0284615384615 --> Loss 0.00886284907659\n",
      "Epoch 32::Minibatch 550::LR 0.0284615384615 --> Loss 0.00118546009064\n",
      "Epoch 32::Minibatch 551::LR 0.0284615384615 --> Loss 0.00245923161507\n",
      "Epoch 32::Minibatch 552::LR 0.0284615384615 --> Loss 0.00342886606852\n",
      "Epoch 32::Minibatch 553::LR 0.0284615384615 --> Loss 0.00295378963153\n",
      "Epoch 32::Minibatch 554::LR 0.0284615384615 --> Loss 0.00361929178238\n",
      "Epoch 32::Minibatch 555::LR 0.0284615384615 --> Loss 0.000939649343491\n",
      "Epoch 32::Minibatch 556::LR 0.0284615384615 --> Loss 0.00191603263219\n",
      "Epoch 32::Minibatch 557::LR 0.0284615384615 --> Loss 0.00240472038587\n",
      "Epoch 32::Minibatch 558::LR 0.0284615384615 --> Loss 0.00358090281487\n",
      "Epoch 32::Minibatch 559::LR 0.0284615384615 --> Loss 0.00364994128545\n",
      "Epoch 32::Minibatch 560::LR 0.0284615384615 --> Loss 0.00305213570595\n",
      "Epoch 32::Minibatch 561::LR 0.0284615384615 --> Loss 0.00261892914772\n",
      "Epoch 32::Minibatch 562::LR 0.0284615384615 --> Loss 0.00233680844307\n",
      "Epoch 32::Minibatch 563::LR 0.0284615384615 --> Loss 0.00396252671878\n",
      "Epoch 32::Minibatch 564::LR 0.0284615384615 --> Loss 0.0030373241504\n",
      "Epoch 32::Minibatch 565::LR 0.0284615384615 --> Loss 0.00357414325078\n",
      "Epoch 32::Minibatch 566::LR 0.0284615384615 --> Loss 0.0021716161569\n",
      "Epoch 32::Minibatch 567::LR 0.0284615384615 --> Loss 0.00253724197547\n",
      "Epoch 32::Minibatch 568::LR 0.0284615384615 --> Loss 0.00173268040021\n",
      "Epoch 32::Minibatch 569::LR 0.0284615384615 --> Loss 0.000560071021318\n",
      "Epoch 32::Minibatch 570::LR 0.0284615384615 --> Loss 0.00161653190851\n",
      "Epoch 32::Minibatch 571::LR 0.0284615384615 --> Loss 0.00204608003298\n",
      "Epoch 32::Minibatch 572::LR 0.0284615384615 --> Loss 0.00220342755318\n",
      "Epoch 32::Minibatch 573::LR 0.0284615384615 --> Loss 0.0014330693086\n",
      "Epoch 32::Minibatch 574::LR 0.0284615384615 --> Loss 0.00104303538799\n",
      "Epoch 32::Minibatch 575::LR 0.0284615384615 --> Loss 0.00171082139015\n",
      "Epoch 32::Minibatch 576::LR 0.0284615384615 --> Loss 0.00202346722285\n",
      "Epoch 32::Minibatch 577::LR 0.0284615384615 --> Loss 0.00160230964422\n",
      "Epoch 32::Minibatch 578::LR 0.0284615384615 --> Loss 0.00126033186913\n",
      "Epoch 32::Minibatch 579::LR 0.0284615384615 --> Loss 0.00117966790994\n",
      "Epoch 32::Minibatch 580::LR 0.0284615384615 --> Loss 0.00191670080026\n",
      "Epoch 32::Minibatch 581::LR 0.0284615384615 --> Loss 0.001702739199\n",
      "Epoch 32::Minibatch 582::LR 0.0284615384615 --> Loss 0.00418920238813\n",
      "Epoch 32::Minibatch 583::LR 0.0284615384615 --> Loss 0.000952719449997\n",
      "Epoch 32::Minibatch 584::LR 0.0284615384615 --> Loss 0.00130891978741\n",
      "Epoch 32::Minibatch 585::LR 0.0284615384615 --> Loss 0.00391342997551\n",
      "Epoch 32::Minibatch 586::LR 0.0284615384615 --> Loss 0.00372329036395\n",
      "Epoch 32::Minibatch 587::LR 0.0284615384615 --> Loss 0.00111131797234\n",
      "Epoch 32::Minibatch 588::LR 0.0284615384615 --> Loss 0.00136750290791\n",
      "Epoch 32::Minibatch 589::LR 0.0284615384615 --> Loss 0.00272906819979\n",
      "Epoch 32::Minibatch 590::LR 0.0284615384615 --> Loss 0.00179081718127\n",
      "Epoch 32::Minibatch 591::LR 0.0284615384615 --> Loss 0.00268375635147\n",
      "Epoch 32::Minibatch 592::LR 0.0284615384615 --> Loss 0.00114722470442\n",
      "Epoch 32::Minibatch 593::LR 0.0284615384615 --> Loss 0.00245446284612\n",
      "Epoch 32::Minibatch 594::LR 0.0284615384615 --> Loss 0.00254570603371\n",
      "Epoch 32::Minibatch 595::LR 0.0284615384615 --> Loss 0.00303781688213\n",
      "Epoch 32::Minibatch 596::LR 0.0284615384615 --> Loss 0.00183267275492\n",
      "Epoch 32::Minibatch 597::LR 0.0284615384615 --> Loss 0.00116319715977\n",
      "Epoch 32::Minibatch 598::LR 0.0284615384615 --> Loss 0.00279095987479\n",
      "Epoch 32::Minibatch 599::LR 0.0284615384615 --> Loss 0.00178459445635\n",
      "Epoch 32::Minibatch 600::LR 0.0284615384615 --> Loss 0.0021161866188\n",
      "Epoch 32::Minibatch 601::LR 0.0284615384615 --> Loss 0.00371837298075\n",
      "Epoch 32::Minibatch 602::LR 0.0284615384615 --> Loss 0.00207934002082\n",
      "Epoch 32::Minibatch 603::LR 0.0284615384615 --> Loss 0.00261281828086\n",
      "Epoch 32::Minibatch 604::LR 0.0284615384615 --> Loss 0.00162392218908\n",
      "Epoch 32::Minibatch 605::LR 0.0284615384615 --> Loss 0.00227048158646\n",
      "Epoch 32::Minibatch 606::LR 0.0284615384615 --> Loss 0.00184585571289\n",
      "Epoch 32::Minibatch 607::LR 0.0284615384615 --> Loss 0.000823068916798\n",
      "Epoch 32::Minibatch 608::LR 0.0284615384615 --> Loss 0.00154706666867\n",
      "Epoch 32::Minibatch 609::LR 0.0284615384615 --> Loss 0.00241874436537\n",
      "Epoch 32::Minibatch 610::LR 0.0284615384615 --> Loss 0.0040386291345\n",
      "Epoch 32::Minibatch 611::LR 0.0284615384615 --> Loss 0.00267019470533\n",
      "Epoch 32::Minibatch 612::LR 0.0284615384615 --> Loss 0.000469702382882\n",
      "Epoch 32::Minibatch 613::LR 0.0284615384615 --> Loss 0.00131047517061\n",
      "Epoch 32::Minibatch 614::LR 0.0284615384615 --> Loss 0.00239846169949\n",
      "Epoch 32::Minibatch 615::LR 0.0284615384615 --> Loss 0.00164848903815\n",
      "Epoch 32::Minibatch 616::LR 0.0284615384615 --> Loss 0.000914312601089\n",
      "Epoch 32::Minibatch 617::LR 0.0284615384615 --> Loss 0.000491005976995\n",
      "Epoch 32::Minibatch 618::LR 0.0284615384615 --> Loss 0.0028903055191\n",
      "Epoch 32::Minibatch 619::LR 0.0284615384615 --> Loss 0.0019269857804\n",
      "Epoch 32::Minibatch 620::LR 0.0284615384615 --> Loss 0.00168566385905\n",
      "Epoch 32::Minibatch 621::LR 0.0284615384615 --> Loss 0.000844337642193\n",
      "Epoch 32::Minibatch 622::LR 0.0284615384615 --> Loss 0.000778828511635\n",
      "Epoch 32::Minibatch 623::LR 0.0284615384615 --> Loss 0.00221513748169\n",
      "Epoch 32::Minibatch 624::LR 0.0284615384615 --> Loss 0.00176539421082\n",
      "Epoch 32::Minibatch 625::LR 0.0284615384615 --> Loss 0.00265002389749\n",
      "Epoch 32::Minibatch 626::LR 0.0284615384615 --> Loss 0.00357273340225\n",
      "Epoch 32::Minibatch 627::LR 0.0284615384615 --> Loss 0.00126644333204\n",
      "Epoch 32::Minibatch 628::LR 0.0284615384615 --> Loss 0.000875863134861\n",
      "Epoch 32::Minibatch 629::LR 0.0284615384615 --> Loss 0.00305590073268\n",
      "Epoch 32::Minibatch 630::LR 0.0284615384615 --> Loss 0.00299218972524\n",
      "Epoch 32::Minibatch 631::LR 0.0284615384615 --> Loss 0.00511946837107\n",
      "Epoch 32::Minibatch 632::LR 0.0284615384615 --> Loss 0.000793654024601\n",
      "Epoch 32::Minibatch 633::LR 0.0284615384615 --> Loss 0.00161305308342\n",
      "Epoch 32::Minibatch 634::LR 0.0284615384615 --> Loss 0.00317534506321\n",
      "Epoch 32::Minibatch 635::LR 0.0284615384615 --> Loss 0.00540607492129\n",
      "Epoch 32::Minibatch 636::LR 0.0284615384615 --> Loss 0.00455516219139\n",
      "Epoch 32::Minibatch 637::LR 0.0284615384615 --> Loss 0.000710722555717\n",
      "Epoch 32::Minibatch 638::LR 0.0284615384615 --> Loss 0.00148378809293\n",
      "Epoch 32::Minibatch 639::LR 0.0284615384615 --> Loss 0.00317448794842\n",
      "Epoch 32::Minibatch 640::LR 0.0284615384615 --> Loss 0.00453314026197\n",
      "Epoch 32::Minibatch 641::LR 0.0284615384615 --> Loss 0.00302861869335\n",
      "Epoch 32::Minibatch 642::LR 0.0284615384615 --> Loss 0.000532120962938\n",
      "Epoch 32::Minibatch 643::LR 0.0284615384615 --> Loss 0.00230613927046\n",
      "Epoch 32::Minibatch 644::LR 0.0284615384615 --> Loss 0.00385471582413\n",
      "Epoch 32::Minibatch 645::LR 0.0284615384615 --> Loss 0.00446401317914\n",
      "Epoch 32::Minibatch 646::LR 0.0284615384615 --> Loss 0.00150531291962\n",
      "Epoch 32::Minibatch 647::LR 0.0284615384615 --> Loss 0.000464465171099\n",
      "Epoch 32::Minibatch 648::LR 0.0284615384615 --> Loss 0.00274671256542\n",
      "Epoch 32::Minibatch 649::LR 0.0284615384615 --> Loss 0.00318814535936\n",
      "Epoch 32::Minibatch 650::LR 0.0284615384615 --> Loss 0.00314448455969\n",
      "Epoch 32::Minibatch 651::LR 0.0284615384615 --> Loss 0.00132439315319\n",
      "Epoch 32::Minibatch 652::LR 0.0284615384615 --> Loss 0.000776967406273\n",
      "Epoch 32::Minibatch 653::LR 0.0284615384615 --> Loss 0.00279540260633\n",
      "Epoch 32::Minibatch 654::LR 0.0284615384615 --> Loss 0.00311740438143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 655::LR 0.0284615384615 --> Loss 0.00363483826319\n",
      "Epoch 32::Minibatch 656::LR 0.0284615384615 --> Loss 0.000755604108175\n",
      "Epoch 32::Minibatch 657::LR 0.0284615384615 --> Loss 0.00226532816887\n",
      "Epoch 32::Minibatch 658::LR 0.0284615384615 --> Loss 0.00447856227557\n",
      "Epoch 32::Minibatch 659::LR 0.0284615384615 --> Loss 0.00220653514067\n",
      "Epoch 32::Minibatch 660::LR 0.0284615384615 --> Loss 0.00264009396235\n",
      "Epoch 32::Minibatch 661::LR 0.0284615384615 --> Loss 0.00226092497508\n",
      "Epoch 32::Minibatch 662::LR 0.0284615384615 --> Loss 0.00179208040237\n",
      "Epoch 32::Minibatch 663::LR 0.0284615384615 --> Loss 0.0036568514506\n",
      "Epoch 32::Minibatch 664::LR 0.0284615384615 --> Loss 0.00314095358054\n",
      "Epoch 32::Minibatch 665::LR 0.0284615384615 --> Loss 0.000694943418105\n",
      "Epoch 32::Minibatch 666::LR 0.0284615384615 --> Loss 0.00390385190646\n",
      "Epoch 32::Minibatch 667::LR 0.0284615384615 --> Loss 0.00254100501537\n",
      "Epoch 32::Minibatch 668::LR 0.0284615384615 --> Loss 0.0062947511673\n",
      "Epoch 32::Minibatch 669::LR 0.0284615384615 --> Loss 0.0010821223259\n",
      "Epoch 32::Minibatch 670::LR 0.0284615384615 --> Loss 0.0013274132212\n",
      "Epoch 32::Minibatch 671::LR 0.0284615384615 --> Loss 0.00506949941317\n",
      "Epoch 32::Minibatch 672::LR 0.0284615384615 --> Loss 0.00337360183398\n",
      "Epoch 32::Minibatch 673::LR 0.0284615384615 --> Loss 0.00160122394562\n",
      "Epoch 32::Minibatch 674::LR 0.0284615384615 --> Loss 0.000509756207466\n",
      "Epoch 32::Minibatch 675::LR 0.0284615384615 --> Loss 0.00219603260358\n",
      "Epoch 32::Minibatch 676::LR 0.0284615384615 --> Loss 0.00215798993905\n",
      "Epoch 32::Minibatch 677::LR 0.0284615384615 --> Loss 0.00269946495692\n",
      "Epoch 32::Minibatch 678::LR 0.0284615384615 --> Loss 0.00186231533686\n",
      "Epoch 32::Minibatch 679::LR 0.0284615384615 --> Loss 0.00330610970656\n",
      "Epoch 32::Minibatch 680::LR 0.0284615384615 --> Loss 0.00212052841981\n",
      "Epoch 32::Minibatch 681::LR 0.0284615384615 --> Loss 0.00237912158171\n",
      "Epoch 32::Minibatch 682::LR 0.0284615384615 --> Loss 0.000761804083983\n",
      "Epoch 32::Minibatch 683::LR 0.0284615384615 --> Loss 0.00230103055636\n",
      "Epoch 32::Minibatch 684::LR 0.0284615384615 --> Loss 0.00233922461669\n",
      "Epoch 32::Minibatch 685::LR 0.0284615384615 --> Loss 0.00281530360381\n",
      "Epoch 32::Minibatch 686::LR 0.0284615384615 --> Loss 0.00158322632313\n",
      "Epoch 32::Minibatch 687::LR 0.0284615384615 --> Loss 0.000877919296424\n",
      "Epoch 32::Minibatch 688::LR 0.0284615384615 --> Loss 0.00280218084653\n",
      "Epoch 32::Minibatch 689::LR 0.0284615384615 --> Loss 0.0024658759435\n",
      "Epoch 32::Minibatch 690::LR 0.0284615384615 --> Loss 0.00187524497509\n",
      "Epoch 32::Minibatch 691::LR 0.0284615384615 --> Loss 0.00065765072902\n",
      "Epoch 32::Minibatch 692::LR 0.0284615384615 --> Loss 0.00244144837062\n",
      "Epoch 32::Minibatch 693::LR 0.0284615384615 --> Loss 0.00261485596498\n",
      "Epoch 32::Minibatch 694::LR 0.0284615384615 --> Loss 0.00298999011517\n",
      "Epoch 32::Minibatch 695::LR 0.0284615384615 --> Loss 0.00179678459962\n",
      "Epoch 32::Minibatch 696::LR 0.0284615384615 --> Loss 0.00202923715115\n",
      "Epoch 32::Minibatch 697::LR 0.0284615384615 --> Loss 0.00139889965455\n",
      "Epoch 32::Minibatch 698::LR 0.0284615384615 --> Loss 0.00166251321634\n",
      "Epoch 32::Minibatch 699::LR 0.0284615384615 --> Loss 0.00369722803434\n",
      "Epoch 32::Minibatch 700::LR 0.0284615384615 --> Loss 0.00257078111172\n",
      "Epoch 32::Minibatch 701::LR 0.0284615384615 --> Loss 0.00188359121482\n",
      "Epoch 32::Minibatch 702::LR 0.0284615384615 --> Loss 0.00166694084803\n",
      "Epoch 32::Minibatch 703::LR 0.0284615384615 --> Loss 0.00430171370506\n",
      "Epoch 32::Minibatch 704::LR 0.0284615384615 --> Loss 0.0018033961455\n",
      "Epoch 32::Minibatch 705::LR 0.0284615384615 --> Loss 0.00283563911915\n",
      "Epoch 32::Minibatch 706::LR 0.0284615384615 --> Loss 0.0022012056907\n",
      "Epoch 32::Minibatch 707::LR 0.0284615384615 --> Loss 0.00117976953586\n",
      "Epoch 32::Minibatch 708::LR 0.0284615384615 --> Loss 0.00173035025597\n",
      "Epoch 32::Minibatch 709::LR 0.0284615384615 --> Loss 0.00166954576969\n",
      "Epoch 32::Minibatch 710::LR 0.0284615384615 --> Loss 0.0025847941637\n",
      "Epoch 32::Minibatch 711::LR 0.0284615384615 --> Loss 0.00197676618894\n",
      "Epoch 32::Minibatch 712::LR 0.0284615384615 --> Loss 0.0013627482454\n",
      "Epoch 32::Minibatch 713::LR 0.0284615384615 --> Loss 0.00179681460063\n",
      "Epoch 32::Minibatch 714::LR 0.0284615384615 --> Loss 0.00286521712939\n",
      "Epoch 32::Minibatch 715::LR 0.0284615384615 --> Loss 0.00292383233706\n",
      "Epoch 32::Minibatch 716::LR 0.0284615384615 --> Loss 0.00166426738103\n",
      "Epoch 32::Minibatch 717::LR 0.0284615384615 --> Loss 0.00166915873686\n",
      "Epoch 32::Minibatch 718::LR 0.0284615384615 --> Loss 0.00128059814374\n",
      "Epoch 32::Minibatch 719::LR 0.0284615384615 --> Loss 0.0017275150617\n",
      "Epoch 32::Minibatch 720::LR 0.0284615384615 --> Loss 0.00276621639729\n",
      "Epoch 32::Minibatch 721::LR 0.0284615384615 --> Loss 0.000604565640291\n",
      "Epoch 32::Minibatch 722::LR 0.0284615384615 --> Loss 0.00458909749985\n",
      "Epoch 32::Minibatch 723::LR 0.0284615384615 --> Loss 0.00481709480286\n",
      "Epoch 32::Minibatch 724::LR 0.0284615384615 --> Loss 0.000964506765207\n",
      "Epoch 32::Minibatch 725::LR 0.0284615384615 --> Loss 0.00205261409283\n",
      "Epoch 32::Minibatch 726::LR 0.0284615384615 --> Loss 0.00363202969233\n",
      "Epoch 32::Minibatch 727::LR 0.0284615384615 --> Loss 0.00304845412572\n",
      "Epoch 32::Minibatch 728::LR 0.0284615384615 --> Loss 0.000641051282485\n",
      "Epoch 32::Minibatch 729::LR 0.0284615384615 --> Loss 0.000716836253802\n",
      "Epoch 32::Minibatch 730::LR 0.0284615384615 --> Loss 0.00290920893351\n",
      "Epoch 32::Minibatch 731::LR 0.0284615384615 --> Loss 0.00261863390605\n",
      "Epoch 32::Minibatch 732::LR 0.0284615384615 --> Loss 0.00203452467918\n",
      "Epoch 32::Minibatch 733::LR 0.0284615384615 --> Loss 0.000593891590834\n",
      "Epoch 32::Minibatch 734::LR 0.0284615384615 --> Loss 0.00163932363192\n",
      "Epoch 32::Minibatch 735::LR 0.0284615384615 --> Loss 0.00247962772846\n",
      "Epoch 32::Minibatch 736::LR 0.0284615384615 --> Loss 0.00347519993782\n",
      "Epoch 32::Minibatch 737::LR 0.0284615384615 --> Loss 0.00291812260946\n",
      "Epoch 32::Minibatch 738::LR 0.0284615384615 --> Loss 0.00138669689496\n",
      "Epoch 32::Minibatch 739::LR 0.0284615384615 --> Loss 0.00237483064334\n",
      "Epoch 32::Minibatch 740::LR 0.0284615384615 --> Loss 0.00375751296679\n",
      "Epoch 32::Minibatch 741::LR 0.0284615384615 --> Loss 0.00252225160599\n",
      "Epoch 32::Minibatch 742::LR 0.0284615384615 --> Loss 0.0020740433534\n",
      "Epoch 32::Minibatch 743::LR 0.0284615384615 --> Loss 0.00150827844938\n",
      "Epoch 32::Minibatch 744::LR 0.0284615384615 --> Loss 0.00187427977721\n",
      "Epoch 32::Minibatch 745::LR 0.0284615384615 --> Loss 0.00276782731215\n",
      "Epoch 32::Minibatch 746::LR 0.0284615384615 --> Loss 0.00284210721652\n",
      "Epoch 32::Minibatch 747::LR 0.0284615384615 --> Loss 0.0017561240991\n",
      "Epoch 32::Minibatch 748::LR 0.0284615384615 --> Loss 0.000620974848668\n",
      "Epoch 32::Minibatch 749::LR 0.0284615384615 --> Loss 0.00167539437612\n",
      "Epoch 32::Minibatch 750::LR 0.0284615384615 --> Loss 0.00241546968619\n",
      "Epoch 32::Minibatch 751::LR 0.0284615384615 --> Loss 0.00292675276597\n",
      "Epoch 32::Minibatch 752::LR 0.0284615384615 --> Loss 0.0014443046848\n",
      "Epoch 32::Minibatch 753::LR 0.0284615384615 --> Loss 0.00219240208467\n",
      "Epoch 32::Minibatch 754::LR 0.0284615384615 --> Loss 0.00241778075695\n",
      "Epoch 32::Minibatch 755::LR 0.0284615384615 --> Loss 0.00265912234783\n",
      "Epoch 32::Minibatch 756::LR 0.0284615384615 --> Loss 0.00130288650592\n",
      "Epoch 32::Minibatch 757::LR 0.0284615384615 --> Loss 0.000595801472664\n",
      "Epoch 32::Minibatch 758::LR 0.0284615384615 --> Loss 0.00156217177709\n",
      "Epoch 32::Minibatch 759::LR 0.0284615384615 --> Loss 0.00340325554212\n",
      "Epoch 32::Minibatch 760::LR 0.0284615384615 --> Loss 0.00278893252214\n",
      "Epoch 32::Minibatch 761::LR 0.0284615384615 --> Loss 0.00559452970823\n",
      "Epoch 32::Minibatch 762::LR 0.0284615384615 --> Loss 0.00355138103167\n",
      "Epoch 32::Minibatch 763::LR 0.0284615384615 --> Loss 0.00343073089918\n",
      "Epoch 32::Minibatch 764::LR 0.0284615384615 --> Loss 0.0030224921306\n",
      "Epoch 32::Minibatch 765::LR 0.0284615384615 --> Loss 0.00124617099762\n",
      "Epoch 32::Minibatch 766::LR 0.0284615384615 --> Loss 0.00230047821999\n",
      "Epoch 32::Minibatch 767::LR 0.0284615384615 --> Loss 0.00477804700534\n",
      "Epoch 32::Minibatch 768::LR 0.0284615384615 --> Loss 0.00364087978999\n",
      "Epoch 32::Minibatch 769::LR 0.0284615384615 --> Loss 0.00183225472768\n",
      "Epoch 32::Minibatch 770::LR 0.0284615384615 --> Loss 0.00151039550702\n",
      "Epoch 32::Minibatch 771::LR 0.0284615384615 --> Loss 0.00340026378632\n",
      "Epoch 32::Minibatch 772::LR 0.0284615384615 --> Loss 0.00362392266591\n",
      "Epoch 32::Minibatch 773::LR 0.0284615384615 --> Loss 0.0031893068552\n",
      "Epoch 32::Minibatch 774::LR 0.0284615384615 --> Loss 0.00188908894857\n",
      "Epoch 32::Minibatch 775::LR 0.0284615384615 --> Loss 0.00328125059605\n",
      "Epoch 32::Minibatch 776::LR 0.0284615384615 --> Loss 0.00379563450813\n",
      "Epoch 32::Minibatch 777::LR 0.0284615384615 --> Loss 0.00607172131538\n",
      "Epoch 32::Minibatch 778::LR 0.0284615384615 --> Loss 0.00722622315089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 779::LR 0.0284615384615 --> Loss 0.00249210596085\n",
      "Epoch 32::Minibatch 780::LR 0.0284615384615 --> Loss 0.0015036046505\n",
      "Epoch 32::Minibatch 781::LR 0.0284615384615 --> Loss 0.00348803957303\n",
      "Epoch 32::Minibatch 782::LR 0.0284615384615 --> Loss 0.00380353569984\n",
      "Epoch 32::Minibatch 783::LR 0.0284615384615 --> Loss 0.00226428647836\n",
      "Epoch 32::Minibatch 784::LR 0.0284615384615 --> Loss 0.000709248979886\n",
      "Epoch 32::Minibatch 785::LR 0.0284615384615 --> Loss 0.00334570447604\n",
      "Epoch 32::Minibatch 786::LR 0.0284615384615 --> Loss 0.00352831641833\n",
      "Epoch 32::Minibatch 787::LR 0.0284615384615 --> Loss 0.00256884733836\n",
      "Epoch 32::Minibatch 788::LR 0.0284615384615 --> Loss 0.00239270110925\n",
      "Epoch 32::Minibatch 789::LR 0.0284615384615 --> Loss 0.000724658618371\n",
      "Epoch 32::Minibatch 790::LR 0.0284615384615 --> Loss 0.00313803911209\n",
      "Epoch 32::Minibatch 791::LR 0.0284615384615 --> Loss 0.00327194690704\n",
      "Epoch 32::Minibatch 792::LR 0.0284615384615 --> Loss 0.00297811130683\n",
      "Epoch 32::Minibatch 793::LR 0.0284615384615 --> Loss 0.00164260019859\n",
      "Epoch 32::Minibatch 794::LR 0.0284615384615 --> Loss 0.000982396602631\n",
      "Epoch 32::Minibatch 795::LR 0.0284615384615 --> Loss 0.00264661808809\n",
      "Epoch 32::Minibatch 796::LR 0.0284615384615 --> Loss 0.00484245936076\n",
      "Epoch 32::Minibatch 797::LR 0.0284615384615 --> Loss 0.00574401775996\n",
      "Epoch 32::Minibatch 798::LR 0.0284615384615 --> Loss 0.00299456775188\n",
      "Epoch 32::Minibatch 799::LR 0.0284615384615 --> Loss 0.00224686940511\n",
      "Epoch 32::Minibatch 800::LR 0.0284615384615 --> Loss 0.00200166324774\n",
      "Epoch 32::Minibatch 801::LR 0.0284615384615 --> Loss 0.00387008508046\n",
      "Epoch 32::Minibatch 802::LR 0.0284615384615 --> Loss 0.00120432039102\n",
      "Epoch 32::Minibatch 803::LR 0.0284615384615 --> Loss 0.00294570207596\n",
      "Epoch 32::Minibatch 804::LR 0.0284615384615 --> Loss 0.0020739052693\n",
      "Epoch 32::Minibatch 805::LR 0.0284615384615 --> Loss 0.00218403061231\n",
      "Epoch 32::Minibatch 806::LR 0.0284615384615 --> Loss 0.00336368282636\n",
      "Epoch 32::Minibatch 807::LR 0.0284615384615 --> Loss 0.00307215750217\n",
      "Epoch 32::Minibatch 808::LR 0.0284615384615 --> Loss 0.00284094293912\n",
      "Epoch 32::Minibatch 809::LR 0.0284615384615 --> Loss 0.00307799637318\n",
      "Epoch 32::Minibatch 810::LR 0.0284615384615 --> Loss 0.00421551903089\n",
      "Epoch 32::Minibatch 811::LR 0.0284615384615 --> Loss 0.00404218991597\n",
      "Epoch 32::Minibatch 812::LR 0.0284615384615 --> Loss 0.00371489048004\n",
      "Epoch 32::Minibatch 813::LR 0.0284615384615 --> Loss 0.00309874475002\n",
      "Epoch 32::Minibatch 814::LR 0.0284615384615 --> Loss 0.0015275127689\n",
      "Epoch 32::Minibatch 815::LR 0.0284615384615 --> Loss 0.00350059668223\n",
      "Epoch 32::Minibatch 816::LR 0.0284615384615 --> Loss 0.00394379814466\n",
      "Epoch 32::Minibatch 817::LR 0.0284615384615 --> Loss 0.0048384197553\n",
      "Epoch 32::Minibatch 818::LR 0.0284615384615 --> Loss 0.0012385114034\n",
      "Epoch 32::Minibatch 819::LR 0.0284615384615 --> Loss 0.000721087058385\n",
      "Epoch 32::Minibatch 820::LR 0.0284615384615 --> Loss 0.00506716926893\n",
      "Epoch 32::Minibatch 821::LR 0.0284615384615 --> Loss 0.00305642863115\n",
      "Epoch 32::Minibatch 822::LR 0.0284615384615 --> Loss 0.0036586578687\n",
      "Epoch 32::Minibatch 823::LR 0.0284615384615 --> Loss 0.00125896970431\n",
      "Epoch 32::Minibatch 824::LR 0.0284615384615 --> Loss 0.00136243273815\n",
      "Epoch 32::Minibatch 825::LR 0.0284615384615 --> Loss 0.00371470967929\n",
      "Epoch 32::Minibatch 826::LR 0.0284615384615 --> Loss 0.00435899655024\n",
      "Epoch 32::Minibatch 827::LR 0.0284615384615 --> Loss 0.00205498019854\n",
      "Epoch 32::Minibatch 828::LR 0.0284615384615 --> Loss 0.000487744112809\n",
      "Epoch 32::Minibatch 829::LR 0.0284615384615 --> Loss 0.00226331035296\n",
      "Epoch 32::Minibatch 830::LR 0.0284615384615 --> Loss 0.00399998148282\n",
      "Epoch 32::Minibatch 831::LR 0.0284615384615 --> Loss 0.00238855977853\n",
      "Epoch 32::Minibatch 832::LR 0.0284615384615 --> Loss 0.00210369686286\n",
      "Epoch 32::Minibatch 833::LR 0.0284615384615 --> Loss 0.00181335806847\n",
      "Epoch 32::Minibatch 834::LR 0.0284615384615 --> Loss 0.000787168393532\n",
      "Epoch 32::Minibatch 835::LR 0.0284615384615 --> Loss 0.00377453684807\n",
      "Epoch 32::Minibatch 836::LR 0.0284615384615 --> Loss 0.00356919328372\n",
      "Epoch 32::Minibatch 837::LR 0.0284615384615 --> Loss 0.00223726371924\n",
      "Epoch 32::Minibatch 838::LR 0.0284615384615 --> Loss 0.000643100688855\n",
      "Epoch 32::Minibatch 839::LR 0.0284615384615 --> Loss 0.00238038003445\n",
      "Epoch 32::Minibatch 840::LR 0.0284615384615 --> Loss 0.00283689379692\n",
      "Epoch 32::Minibatch 841::LR 0.0284615384615 --> Loss 0.0027486538887\n",
      "Epoch 32::Minibatch 842::LR 0.0284615384615 --> Loss 0.00209325532118\n",
      "Epoch 32::Minibatch 843::LR 0.0284615384615 --> Loss 0.000974958439668\n",
      "Epoch 32::Minibatch 844::LR 0.0284615384615 --> Loss 0.00146504054467\n",
      "Epoch 32::Minibatch 845::LR 0.0284615384615 --> Loss 0.00401714722315\n",
      "Epoch 32::Minibatch 846::LR 0.0284615384615 --> Loss 0.00166612933079\n",
      "Epoch 32::Minibatch 847::LR 0.0284615384615 --> Loss 0.00234729528427\n",
      "Epoch 32::Minibatch 848::LR 0.0284615384615 --> Loss 0.00110649267832\n",
      "Epoch 32::Minibatch 849::LR 0.0284615384615 --> Loss 0.00178335924943\n",
      "Epoch 32::Minibatch 850::LR 0.0284615384615 --> Loss 0.00314438819885\n",
      "Epoch 32::Minibatch 851::LR 0.0284615384615 --> Loss 0.0025380808115\n",
      "Epoch 32::Minibatch 852::LR 0.0284615384615 --> Loss 0.00112377762794\n",
      "Epoch 32::Minibatch 853::LR 0.0284615384615 --> Loss 0.00130231340726\n",
      "Epoch 32::Minibatch 854::LR 0.0284615384615 --> Loss 0.00252521534761\n",
      "Epoch 32::Minibatch 855::LR 0.0284615384615 --> Loss 0.002107574145\n",
      "Epoch 32::Minibatch 856::LR 0.0284615384615 --> Loss 0.00177746514479\n",
      "Epoch 32::Minibatch 857::LR 0.0284615384615 --> Loss 0.00120678901672\n",
      "Epoch 32::Minibatch 858::LR 0.0284615384615 --> Loss 0.000598749667406\n",
      "Epoch 32::Minibatch 859::LR 0.0284615384615 --> Loss 0.00196809212367\n",
      "Epoch 32::Minibatch 860::LR 0.0284615384615 --> Loss 0.00129440039396\n",
      "Epoch 32::Minibatch 861::LR 0.0284615384615 --> Loss 0.000944026112556\n",
      "Epoch 32::Minibatch 862::LR 0.0284615384615 --> Loss 0.00370316028595\n",
      "Epoch 32::Minibatch 863::LR 0.0284615384615 --> Loss 0.00335989157359\n",
      "Epoch 32::Minibatch 864::LR 0.0284615384615 --> Loss 0.00260749379794\n",
      "Epoch 32::Minibatch 865::LR 0.0284615384615 --> Loss 0.000501239498456\n",
      "Epoch 32::Minibatch 866::LR 0.0284615384615 --> Loss 0.00207671006521\n",
      "Epoch 32::Minibatch 867::LR 0.0284615384615 --> Loss 0.00287026683489\n",
      "Epoch 32::Minibatch 868::LR 0.0284615384615 --> Loss 0.00241378088792\n",
      "Epoch 32::Minibatch 869::LR 0.0284615384615 --> Loss 0.00212792317073\n",
      "Epoch 32::Minibatch 870::LR 0.0284615384615 --> Loss 0.00326018412908\n",
      "Epoch 32::Minibatch 871::LR 0.0284615384615 --> Loss 0.00161076893409\n",
      "Epoch 32::Minibatch 872::LR 0.0284615384615 --> Loss 0.00212419668833\n",
      "Epoch 32::Minibatch 873::LR 0.0284615384615 --> Loss 0.00245027760665\n",
      "Epoch 32::Minibatch 874::LR 0.0284615384615 --> Loss 0.00520446976026\n",
      "Epoch 32::Minibatch 875::LR 0.0284615384615 --> Loss 0.000615272323291\n",
      "Epoch 32::Minibatch 876::LR 0.0284615384615 --> Loss 0.00274920841058\n",
      "Epoch 32::Minibatch 877::LR 0.0284615384615 --> Loss 0.004640635252\n",
      "Epoch 32::Minibatch 878::LR 0.0284615384615 --> Loss 0.00296188970407\n",
      "Epoch 32::Minibatch 879::LR 0.0284615384615 --> Loss 0.00390834331512\n",
      "Epoch 32::Minibatch 880::LR 0.0284615384615 --> Loss 0.00485526959101\n",
      "Epoch 32::Minibatch 881::LR 0.0284615384615 --> Loss 0.00420860767365\n",
      "Epoch 32::Minibatch 882::LR 0.0284615384615 --> Loss 0.00191019892693\n",
      "Epoch 32::Minibatch 883::LR 0.0284615384615 --> Loss 0.00359987298648\n",
      "Epoch 32::Minibatch 884::LR 0.0284615384615 --> Loss 0.00278388480345\n",
      "Epoch 32::Minibatch 885::LR 0.0284615384615 --> Loss 0.00258149147034\n",
      "Epoch 32::Minibatch 886::LR 0.0284615384615 --> Loss 0.000436521222194\n",
      "Epoch 32::Minibatch 887::LR 0.0284615384615 --> Loss 0.00545571525892\n",
      "Epoch 32::Minibatch 888::LR 0.0284615384615 --> Loss 0.00244880040487\n",
      "Epoch 32::Minibatch 889::LR 0.0284615384615 --> Loss 0.0025126105547\n",
      "Epoch 32::Minibatch 890::LR 0.0284615384615 --> Loss 0.00362816492716\n",
      "Epoch 32::Minibatch 891::LR 0.0284615384615 --> Loss 0.00171812077363\n",
      "Epoch 32::Minibatch 892::LR 0.0284615384615 --> Loss 0.00079274982214\n",
      "Epoch 32::Minibatch 893::LR 0.0284615384615 --> Loss 0.00226125895977\n",
      "Epoch 32::Minibatch 894::LR 0.0284615384615 --> Loss 0.00198702454567\n",
      "Epoch 32::Minibatch 895::LR 0.0284615384615 --> Loss 0.00227061092854\n",
      "Epoch 32::Minibatch 896::LR 0.0284615384615 --> Loss 0.00124347706636\n",
      "Epoch 32::Minibatch 897::LR 0.0284615384615 --> Loss 0.000670467962821\n",
      "Epoch 32::Minibatch 898::LR 0.0284615384615 --> Loss 0.00198161343733\n",
      "Epoch 32::Minibatch 899::LR 0.0284615384615 --> Loss 0.00244774897893\n",
      "Epoch 32::Minibatch 900::LR 0.0284615384615 --> Loss 0.00306039194266\n",
      "Epoch 32::Minibatch 901::LR 0.0284615384615 --> Loss 0.000583127488693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 902::LR 0.0284615384615 --> Loss 0.00139211714268\n",
      "Epoch 32::Minibatch 903::LR 0.0284615384615 --> Loss 0.00253111342589\n",
      "Epoch 32::Minibatch 904::LR 0.0284615384615 --> Loss 0.00179988443851\n",
      "Epoch 32::Minibatch 905::LR 0.0284615384615 --> Loss 0.00139420231183\n",
      "Epoch 32::Minibatch 906::LR 0.0284615384615 --> Loss 0.00102330327034\n",
      "Epoch 32::Minibatch 907::LR 0.0284615384615 --> Loss 0.00154465576013\n",
      "Epoch 32::Minibatch 908::LR 0.0284615384615 --> Loss 0.00206602772077\n",
      "Epoch 32::Minibatch 909::LR 0.0284615384615 --> Loss 0.00192623933156\n",
      "Epoch 32::Minibatch 910::LR 0.0284615384615 --> Loss 0.000839250087738\n",
      "Epoch 32::Minibatch 911::LR 0.0284615384615 --> Loss 0.00126654207706\n",
      "Epoch 32::Minibatch 912::LR 0.0284615384615 --> Loss 0.00204354166985\n",
      "Epoch 32::Minibatch 913::LR 0.0284615384615 --> Loss 0.00225783268611\n",
      "Epoch 32::Minibatch 914::LR 0.0284615384615 --> Loss 0.00123255580664\n",
      "Epoch 32::Minibatch 915::LR 0.0284615384615 --> Loss 0.000525848120451\n",
      "Epoch 32::Minibatch 916::LR 0.0284615384615 --> Loss 0.00204152027766\n",
      "Epoch 32::Minibatch 917::LR 0.0284615384615 --> Loss 0.0032729279995\n",
      "Epoch 32::Minibatch 918::LR 0.0284615384615 --> Loss 0.00490874767303\n",
      "Epoch 32::Minibatch 919::LR 0.0284615384615 --> Loss 0.000536823223035\n",
      "Epoch 32::Minibatch 920::LR 0.0284615384615 --> Loss 0.012373761336\n",
      "Epoch 32::Minibatch 921::LR 0.0284615384615 --> Loss 0.00296258866787\n",
      "Epoch 32::Minibatch 922::LR 0.0284615384615 --> Loss 0.00297165592511\n",
      "Epoch 32::Minibatch 923::LR 0.0284615384615 --> Loss 0.00117563774188\n",
      "Epoch 32::Minibatch 924::LR 0.0284615384615 --> Loss 0.00315455893675\n",
      "Epoch 32::Minibatch 925::LR 0.0284615384615 --> Loss 0.00219291230043\n",
      "Epoch 32::Minibatch 926::LR 0.0284615384615 --> Loss 0.00462724129359\n",
      "Epoch 32::Minibatch 927::LR 0.0284615384615 --> Loss 0.00525350054105\n",
      "Epoch 32::Minibatch 928::LR 0.0284615384615 --> Loss 0.00593623598417\n",
      "Epoch 32::Minibatch 929::LR 0.0284615384615 --> Loss 0.00532926400503\n",
      "Epoch 32::Minibatch 930::LR 0.0284615384615 --> Loss 0.00910208861033\n",
      "Epoch 32::Minibatch 931::LR 0.0284615384615 --> Loss 0.00302082002163\n",
      "Epoch 32::Minibatch 932::LR 0.0284615384615 --> Loss 0.00527493913968\n",
      "Epoch 32::Minibatch 933::LR 0.0284615384615 --> Loss 0.00241108238697\n",
      "Epoch 32::Minibatch 934::LR 0.0284615384615 --> Loss 0.00308926165104\n",
      "Epoch 32::Minibatch 935::LR 0.0284615384615 --> Loss 0.00460322817167\n",
      "Epoch 32::Minibatch 936::LR 0.0284615384615 --> Loss 0.000912622710069\n",
      "Epoch 32::Minibatch 937::LR 0.0284615384615 --> Loss 0.00240927418073\n",
      "Epoch 32::Minibatch 938::LR 0.0284615384615 --> Loss 0.00205833077431\n",
      "Epoch 32::Minibatch 939::LR 0.0284615384615 --> Loss 0.00223574082057\n",
      "Epoch 32::Minibatch 940::LR 0.0284615384615 --> Loss 0.000923622151216\n",
      "Epoch 32::Minibatch 941::LR 0.0284615384615 --> Loss 0.000751216957966\n",
      "Epoch 32::Minibatch 942::LR 0.0284615384615 --> Loss 0.00250504374504\n",
      "Epoch 32::Minibatch 943::LR 0.0284615384615 --> Loss 0.00235028723876\n",
      "Epoch 32::Minibatch 944::LR 0.0284615384615 --> Loss 0.00169399480025\n",
      "Epoch 32::Minibatch 945::LR 0.0284615384615 --> Loss 0.000950024326642\n",
      "Epoch 32::Minibatch 946::LR 0.0284615384615 --> Loss 0.00242711822192\n",
      "Epoch 32::Minibatch 947::LR 0.0284615384615 --> Loss 0.00224776566029\n",
      "Epoch 32::Minibatch 948::LR 0.0284615384615 --> Loss 0.00407191157341\n",
      "Epoch 32::Minibatch 949::LR 0.0284615384615 --> Loss 0.00171534578005\n",
      "Epoch 32::Minibatch 950::LR 0.0284615384615 --> Loss 0.000695980588595\n",
      "Epoch 32::Minibatch 951::LR 0.0284615384615 --> Loss 0.0033491230011\n",
      "Epoch 32::Minibatch 952::LR 0.0284615384615 --> Loss 0.00233680685361\n",
      "Epoch 32::Minibatch 953::LR 0.0284615384615 --> Loss 0.00141082495451\n",
      "Epoch 32::Minibatch 954::LR 0.0284615384615 --> Loss 0.000936370491982\n",
      "Epoch 32::Minibatch 955::LR 0.0284615384615 --> Loss 0.00254567344983\n",
      "Epoch 32::Minibatch 956::LR 0.0284615384615 --> Loss 0.00310901562373\n",
      "Epoch 32::Minibatch 957::LR 0.0284615384615 --> Loss 0.00182300746441\n",
      "Epoch 32::Minibatch 958::LR 0.0284615384615 --> Loss 0.00218151271343\n",
      "Epoch 32::Minibatch 959::LR 0.0284615384615 --> Loss 0.00253501574198\n",
      "Epoch 32::Minibatch 960::LR 0.0284615384615 --> Loss 0.00537932197253\n",
      "Epoch 32::Minibatch 961::LR 0.0284615384615 --> Loss 0.00298433105151\n",
      "Epoch 32::Minibatch 962::LR 0.0284615384615 --> Loss 0.00237202922503\n",
      "Epoch 32::Minibatch 963::LR 0.0284615384615 --> Loss 0.00104207873344\n",
      "Epoch 32::Minibatch 964::LR 0.0284615384615 --> Loss 0.00232930382093\n",
      "Epoch 32::Minibatch 965::LR 0.0284615384615 --> Loss 0.00629191120466\n",
      "Epoch 32::Minibatch 966::LR 0.0284615384615 --> Loss 0.00485050678253\n",
      "Epoch 32::Minibatch 967::LR 0.0284615384615 --> Loss 0.00126165429751\n",
      "Epoch 32::Minibatch 968::LR 0.0284615384615 --> Loss 0.00103844851255\n",
      "Epoch 32::Minibatch 969::LR 0.0284615384615 --> Loss 0.00462826609612\n",
      "Epoch 32::Minibatch 970::LR 0.0284615384615 --> Loss 0.0044623096784\n",
      "Epoch 32::Minibatch 971::LR 0.0284615384615 --> Loss 0.00330746809642\n",
      "Epoch 32::Minibatch 972::LR 0.0284615384615 --> Loss 0.0081191889445\n",
      "Epoch 32::Minibatch 973::LR 0.0284615384615 --> Loss 0.00929894208908\n",
      "Epoch 32::Minibatch 974::LR 0.0284615384615 --> Loss 0.0081604552269\n",
      "Epoch 32::Minibatch 975::LR 0.0284615384615 --> Loss 0.0045353825887\n",
      "Epoch 32::Minibatch 976::LR 0.0284615384615 --> Loss 0.00361662824949\n",
      "Epoch 32::Minibatch 977::LR 0.0284615384615 --> Loss 0.00333984295527\n",
      "Epoch 32::Minibatch 978::LR 0.0284615384615 --> Loss 0.00326016406218\n",
      "Epoch 32::Minibatch 979::LR 0.0284615384615 --> Loss 0.00301694869995\n",
      "Epoch 32::Minibatch 980::LR 0.0284615384615 --> Loss 0.00341089685758\n",
      "Epoch 32::Minibatch 981::LR 0.0284615384615 --> Loss 0.00423113505046\n",
      "Epoch 32::Minibatch 982::LR 0.0284615384615 --> Loss 0.00427220225334\n",
      "Epoch 32::Minibatch 983::LR 0.0284615384615 --> Loss 0.00249310334524\n",
      "Epoch 32::Minibatch 984::LR 0.0284615384615 --> Loss 0.00173179527124\n",
      "Epoch 32::Minibatch 985::LR 0.0284615384615 --> Loss 0.00327570319176\n",
      "Epoch 32::Minibatch 986::LR 0.0284615384615 --> Loss 0.00297089795272\n",
      "Epoch 32::Minibatch 987::LR 0.0284615384615 --> Loss 0.00329034964244\n",
      "Epoch 32::Minibatch 988::LR 0.0284615384615 --> Loss 0.00261066476504\n",
      "Epoch 32::Minibatch 989::LR 0.0284615384615 --> Loss 0.00290451904138\n",
      "Epoch 32::Minibatch 990::LR 0.0284615384615 --> Loss 0.00272763371468\n",
      "Epoch 32::Minibatch 991::LR 0.0284615384615 --> Loss 0.00136306087176\n",
      "Epoch 32::Minibatch 992::LR 0.0284615384615 --> Loss 0.00160362889369\n",
      "Epoch 32::Minibatch 993::LR 0.0284615384615 --> Loss 0.00297112623851\n",
      "Epoch 32::Minibatch 994::LR 0.0284615384615 --> Loss 0.00195975224177\n",
      "Epoch 32::Minibatch 995::LR 0.0284615384615 --> Loss 0.000790052860975\n",
      "Epoch 32::Minibatch 996::LR 0.0284615384615 --> Loss 0.00264981170495\n",
      "Epoch 32::Minibatch 997::LR 0.0284615384615 --> Loss 0.00218080163002\n",
      "Epoch 32::Minibatch 998::LR 0.0284615384615 --> Loss 0.00248282690843\n",
      "Epoch 32::Minibatch 999::LR 0.0284615384615 --> Loss 0.00212114373843\n",
      "Epoch 32::Minibatch 1000::LR 0.0284615384615 --> Loss 0.00256383319696\n",
      "Epoch 32::Minibatch 1001::LR 0.0284615384615 --> Loss 0.00203081667423\n",
      "Epoch 32::Minibatch 1002::LR 0.0284615384615 --> Loss 0.00153430650632\n",
      "Epoch 32::Minibatch 1003::LR 0.0284615384615 --> Loss 0.00251246432463\n",
      "Epoch 32::Minibatch 1004::LR 0.0284615384615 --> Loss 0.00106551428636\n",
      "Epoch 32::Minibatch 1005::LR 0.0284615384615 --> Loss 0.00255745212237\n",
      "Epoch 32::Minibatch 1006::LR 0.0284615384615 --> Loss 0.00134120613337\n",
      "Epoch 32::Minibatch 1007::LR 0.0284615384615 --> Loss 0.00176439106464\n",
      "Epoch 32::Minibatch 1008::LR 0.0284615384615 --> Loss 0.000921241044998\n",
      "Epoch 32::Minibatch 1009::LR 0.0284615384615 --> Loss 0.00122325122356\n",
      "Epoch 32::Minibatch 1010::LR 0.0284615384615 --> Loss 0.00114498138428\n",
      "Epoch 32::Minibatch 1011::LR 0.0284615384615 --> Loss 0.0016367589434\n",
      "Epoch 32::Minibatch 1012::LR 0.0284615384615 --> Loss 0.00140432814757\n",
      "Epoch 32::Minibatch 1013::LR 0.0284615384615 --> Loss 0.00347901264826\n",
      "Epoch 32::Minibatch 1014::LR 0.0284615384615 --> Loss 0.00323837439219\n",
      "Epoch 32::Minibatch 1015::LR 0.0284615384615 --> Loss 0.00152663230896\n",
      "Epoch 32::Minibatch 1016::LR 0.0284615384615 --> Loss 0.00446186939875\n",
      "Epoch 32::Minibatch 1017::LR 0.0284615384615 --> Loss 0.00312627951304\n",
      "Epoch 32::Minibatch 1018::LR 0.0284615384615 --> Loss 0.00249246180058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32::Minibatch 1019::LR 0.0284615384615 --> Loss 0.00156545321147\n",
      "Epoch 32::Minibatch 1020::LR 0.0284615384615 --> Loss 0.00169020930926\n",
      "Epoch 32::Minibatch 1021::LR 0.0284615384615 --> Loss 0.001816594402\n",
      "Epoch 32::Minibatch 1022::LR 0.0284615384615 --> Loss 0.00133268882831\n",
      "Epoch 32::Minibatch 1023::LR 0.0284615384615 --> Loss 0.00100068231424\n",
      "Epoch 32::Minibatch 1024::LR 0.0284615384615 --> Loss 0.000999732514222\n",
      "Epoch 32::Minibatch 1025::LR 0.0284615384615 --> Loss 0.00136125008265\n",
      "Epoch 32::Minibatch 1026::LR 0.0284615384615 --> Loss 0.000697244356076\n",
      "Epoch 32::Minibatch 1027::LR 0.0284615384615 --> Loss 0.000971847573916\n",
      "Epoch 32::Minibatch 1028::LR 0.0284615384615 --> Loss 0.000724818011125\n",
      "Epoch 32::Minibatch 1029::LR 0.0284615384615 --> Loss 0.000741680612167\n",
      "Epoch 32::Minibatch 1030::LR 0.0284615384615 --> Loss 0.00090320477883\n",
      "Epoch 32::Minibatch 1031::LR 0.0284615384615 --> Loss 0.000689810067415\n",
      "Epoch 32::Minibatch 1032::LR 0.0284615384615 --> Loss 0.000774330149094\n",
      "Epoch 32::Minibatch 1033::LR 0.0284615384615 --> Loss 0.000659087647994\n",
      "Epoch 32::Minibatch 1034::LR 0.0284615384615 --> Loss 0.000625523378452\n",
      "Epoch 32::Minibatch 1035::LR 0.0284615384615 --> Loss 0.00040968713661\n",
      "Epoch 32::Minibatch 1036::LR 0.0284615384615 --> Loss 0.000327157328526\n",
      "Epoch 32::Minibatch 1037::LR 0.0284615384615 --> Loss 0.000606542080641\n",
      "Epoch 32::Minibatch 1038::LR 0.0284615384615 --> Loss 0.00106303165356\n",
      "Epoch 32::Minibatch 1039::LR 0.0284615384615 --> Loss 0.000872195363045\n",
      "Epoch 32::Minibatch 1040::LR 0.0284615384615 --> Loss 0.000342147772511\n",
      "Epoch 32::Minibatch 1041::LR 0.0284615384615 --> Loss 0.000491712441047\n",
      "Epoch 33::Minibatch 1::LR 0.0261538461538 --> Loss 0.00752521197001\n",
      "Epoch 33::Minibatch 2::LR 0.0261538461538 --> Loss 0.00467267950376\n",
      "Epoch 33::Minibatch 3::LR 0.0261538461538 --> Loss 0.00297675251961\n",
      "Epoch 33::Minibatch 4::LR 0.0261538461538 --> Loss 0.00376670320829\n",
      "Epoch 33::Minibatch 5::LR 0.0261538461538 --> Loss 0.00435240626335\n",
      "Epoch 33::Minibatch 6::LR 0.0261538461538 --> Loss 0.0020523271958\n",
      "Epoch 33::Minibatch 7::LR 0.0261538461538 --> Loss 0.00706638336182\n",
      "Epoch 33::Minibatch 8::LR 0.0261538461538 --> Loss 0.00656906922658\n",
      "Epoch 33::Minibatch 9::LR 0.0261538461538 --> Loss 0.00511897881826\n",
      "Epoch 33::Minibatch 10::LR 0.0261538461538 --> Loss 0.00232838193576\n",
      "Epoch 33::Minibatch 11::LR 0.0261538461538 --> Loss 0.00218833764394\n",
      "Epoch 33::Minibatch 12::LR 0.0261538461538 --> Loss 0.00333065410455\n",
      "Epoch 33::Minibatch 13::LR 0.0261538461538 --> Loss 0.00528726140658\n",
      "Epoch 33::Minibatch 14::LR 0.0261538461538 --> Loss 0.00526789824168\n",
      "Epoch 33::Minibatch 15::LR 0.0261538461538 --> Loss 0.0045598022143\n",
      "Epoch 33::Minibatch 16::LR 0.0261538461538 --> Loss 0.000709669689337\n",
      "Epoch 33::Minibatch 17::LR 0.0261538461538 --> Loss 0.00319914003213\n",
      "Epoch 33::Minibatch 18::LR 0.0261538461538 --> Loss 0.00266389489174\n",
      "Epoch 33::Minibatch 19::LR 0.0261538461538 --> Loss 0.00161544760068\n",
      "Epoch 33::Minibatch 20::LR 0.0261538461538 --> Loss 0.00214872757594\n",
      "Epoch 33::Minibatch 21::LR 0.0261538461538 --> Loss 0.00340538342794\n",
      "Epoch 33::Minibatch 22::LR 0.0261538461538 --> Loss 0.00222859760125\n",
      "Epoch 33::Minibatch 23::LR 0.0261538461538 --> Loss 0.000930219590664\n",
      "Epoch 33::Minibatch 24::LR 0.0261538461538 --> Loss 0.000518583506346\n",
      "Epoch 33::Minibatch 25::LR 0.0261538461538 --> Loss 0.00137638856967\n",
      "Epoch 33::Minibatch 26::LR 0.0261538461538 --> Loss 0.00157100528479\n",
      "Epoch 33::Minibatch 27::LR 0.0261538461538 --> Loss 0.00118910978238\n",
      "Epoch 33::Minibatch 28::LR 0.0261538461538 --> Loss 0.000521447658539\n",
      "Epoch 33::Minibatch 29::LR 0.0261538461538 --> Loss 0.000638345430295\n",
      "Epoch 33::Minibatch 30::LR 0.0261538461538 --> Loss 0.0011456678311\n",
      "Epoch 33::Minibatch 31::LR 0.0261538461538 --> Loss 0.00162419448296\n",
      "Epoch 33::Minibatch 32::LR 0.0261538461538 --> Loss 0.00143034984668\n",
      "Epoch 33::Minibatch 33::LR 0.0261538461538 --> Loss 0.000821467041969\n",
      "Epoch 33::Minibatch 34::LR 0.0261538461538 --> Loss 0.00202969352404\n",
      "Epoch 33::Minibatch 35::LR 0.0261538461538 --> Loss 0.00284049053987\n",
      "Epoch 33::Minibatch 36::LR 0.0261538461538 --> Loss 0.00225369513035\n",
      "Epoch 33::Minibatch 37::LR 0.0261538461538 --> Loss 0.000733255843321\n",
      "Epoch 33::Minibatch 38::LR 0.0261538461538 --> Loss 0.000747475624084\n",
      "Epoch 33::Minibatch 39::LR 0.0261538461538 --> Loss 0.00211667656898\n",
      "Epoch 33::Minibatch 40::LR 0.0261538461538 --> Loss 0.00306733469168\n",
      "Epoch 33::Minibatch 41::LR 0.0261538461538 --> Loss 0.00243396639824\n",
      "Epoch 33::Minibatch 42::LR 0.0261538461538 --> Loss 0.00434673627218\n",
      "Epoch 33::Minibatch 43::LR 0.0261538461538 --> Loss 0.00203603684902\n",
      "Epoch 33::Minibatch 44::LR 0.0261538461538 --> Loss 0.00337970217069\n",
      "Epoch 33::Minibatch 45::LR 0.0261538461538 --> Loss 0.00242496212324\n",
      "Epoch 33::Minibatch 46::LR 0.0261538461538 --> Loss 0.00302367548148\n",
      "Epoch 33::Minibatch 47::LR 0.0261538461538 --> Loss 0.00320419609547\n",
      "Epoch 33::Minibatch 48::LR 0.0261538461538 --> Loss 0.0046800382932\n",
      "Epoch 33::Minibatch 49::LR 0.0261538461538 --> Loss 0.0053325454394\n",
      "Epoch 33::Minibatch 50::LR 0.0261538461538 --> Loss 0.00593295375506\n",
      "Epoch 33::Minibatch 51::LR 0.0261538461538 --> Loss 0.00414929111799\n",
      "Epoch 33::Minibatch 52::LR 0.0261538461538 --> Loss 0.00339185198148\n",
      "Epoch 33::Minibatch 53::LR 0.0261538461538 --> Loss 0.00337318142255\n",
      "Epoch 33::Minibatch 54::LR 0.0261538461538 --> Loss 0.00397477984428\n",
      "Epoch 33::Minibatch 55::LR 0.0261538461538 --> Loss 0.000995142459869\n",
      "Epoch 33::Minibatch 56::LR 0.0261538461538 --> Loss 0.00275147000949\n",
      "Epoch 33::Minibatch 57::LR 0.0261538461538 --> Loss 0.00450431346893\n",
      "Epoch 33::Minibatch 58::LR 0.0261538461538 --> Loss 0.00318554679553\n",
      "Epoch 33::Minibatch 59::LR 0.0261538461538 --> Loss 0.00244156857332\n",
      "Epoch 33::Minibatch 60::LR 0.0261538461538 --> Loss 0.00250156362851\n",
      "Epoch 33::Minibatch 61::LR 0.0261538461538 --> Loss 0.00070944711566\n",
      "Epoch 33::Minibatch 62::LR 0.0261538461538 --> Loss 0.00247158726056\n",
      "Epoch 33::Minibatch 63::LR 0.0261538461538 --> Loss 0.00204143603643\n",
      "Epoch 33::Minibatch 64::LR 0.0261538461538 --> Loss 0.000812940100829\n",
      "Epoch 33::Minibatch 65::LR 0.0261538461538 --> Loss 0.00211728354295\n",
      "Epoch 33::Minibatch 66::LR 0.0261538461538 --> Loss 0.00278320670128\n",
      "Epoch 33::Minibatch 67::LR 0.0261538461538 --> Loss 0.00247152189414\n",
      "Epoch 33::Minibatch 68::LR 0.0261538461538 --> Loss 0.00181533952554\n",
      "Epoch 33::Minibatch 69::LR 0.0261538461538 --> Loss 0.00356763203939\n",
      "Epoch 33::Minibatch 70::LR 0.0261538461538 --> Loss 0.0031805340449\n",
      "Epoch 33::Minibatch 71::LR 0.0261538461538 --> Loss 0.00222613155842\n",
      "Epoch 33::Minibatch 72::LR 0.0261538461538 --> Loss 0.000547652741273\n",
      "Epoch 33::Minibatch 73::LR 0.0261538461538 --> Loss 0.0036436355114\n",
      "Epoch 33::Minibatch 74::LR 0.0261538461538 --> Loss 0.00395384311676\n",
      "Epoch 33::Minibatch 75::LR 0.0261538461538 --> Loss 0.00203130642573\n",
      "Epoch 33::Minibatch 76::LR 0.0261538461538 --> Loss 0.000517718444268\n",
      "Epoch 33::Minibatch 77::LR 0.0261538461538 --> Loss 0.00326000551383\n",
      "Epoch 33::Minibatch 78::LR 0.0261538461538 --> Loss 0.00396745999654\n",
      "Epoch 33::Minibatch 79::LR 0.0261538461538 --> Loss 0.00167239228884\n",
      "Epoch 33::Minibatch 80::LR 0.0261538461538 --> Loss 0.0027725203832\n",
      "Epoch 33::Minibatch 81::LR 0.0261538461538 --> Loss 0.00247639973958\n",
      "Epoch 33::Minibatch 82::LR 0.0261538461538 --> Loss 0.0017990920941\n",
      "Epoch 33::Minibatch 83::LR 0.0261538461538 --> Loss 0.00377709587415\n",
      "Epoch 33::Minibatch 84::LR 0.0261538461538 --> Loss 0.00182829797268\n",
      "Epoch 33::Minibatch 85::LR 0.0261538461538 --> Loss 0.00247816681862\n",
      "Epoch 33::Minibatch 86::LR 0.0261538461538 --> Loss 0.00206471363703\n",
      "Epoch 33::Minibatch 87::LR 0.0261538461538 --> Loss 0.00217035909494\n",
      "Epoch 33::Minibatch 88::LR 0.0261538461538 --> Loss 0.00164360105991\n",
      "Epoch 33::Minibatch 89::LR 0.0261538461538 --> Loss 0.00216693441073\n",
      "Epoch 33::Minibatch 90::LR 0.0261538461538 --> Loss 0.00104225794474\n",
      "Epoch 33::Minibatch 91::LR 0.0261538461538 --> Loss 0.000873539447784\n",
      "Epoch 33::Minibatch 92::LR 0.0261538461538 --> Loss 0.00252419531345\n",
      "Epoch 33::Minibatch 93::LR 0.0261538461538 --> Loss 0.00168151458104\n",
      "Epoch 33::Minibatch 94::LR 0.0261538461538 --> Loss 0.00173365672429\n",
      "Epoch 33::Minibatch 95::LR 0.0261538461538 --> Loss 0.00190899312496\n",
      "Epoch 33::Minibatch 96::LR 0.0261538461538 --> Loss 0.00459495464961\n",
      "Epoch 33::Minibatch 97::LR 0.0261538461538 --> Loss 0.00300107300282\n",
      "Epoch 33::Minibatch 98::LR 0.0261538461538 --> Loss 0.00109274337689\n",
      "Epoch 33::Minibatch 99::LR 0.0261538461538 --> Loss 0.0014193636179\n",
      "Epoch 33::Minibatch 100::LR 0.0261538461538 --> Loss 0.00408419013023\n",
      "Epoch 33::Minibatch 101::LR 0.0261538461538 --> Loss 0.000896661778291\n",
      "Epoch 33::Minibatch 102::LR 0.0261538461538 --> Loss 0.00384385983149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 103::LR 0.0261538461538 --> Loss 0.00384496887525\n",
      "Epoch 33::Minibatch 104::LR 0.0261538461538 --> Loss 0.00263678113619\n",
      "Epoch 33::Minibatch 105::LR 0.0261538461538 --> Loss 0.00202500303586\n",
      "Epoch 33::Minibatch 106::LR 0.0261538461538 --> Loss 0.0130492043495\n",
      "Epoch 33::Minibatch 107::LR 0.0261538461538 --> Loss 0.00472975055377\n",
      "Epoch 33::Minibatch 108::LR 0.0261538461538 --> Loss 0.000913187861443\n",
      "Epoch 33::Minibatch 109::LR 0.0261538461538 --> Loss 0.00430017868678\n",
      "Epoch 33::Minibatch 110::LR 0.0261538461538 --> Loss 0.00219479858875\n",
      "Epoch 33::Minibatch 111::LR 0.0261538461538 --> Loss 0.000801293452581\n",
      "Epoch 33::Minibatch 112::LR 0.0261538461538 --> Loss 0.00324431677659\n",
      "Epoch 33::Minibatch 113::LR 0.0261538461538 --> Loss 0.0023472849528\n",
      "Epoch 33::Minibatch 114::LR 0.0261538461538 --> Loss 0.0013190750281\n",
      "Epoch 33::Minibatch 115::LR 0.0261538461538 --> Loss 0.0011042179664\n",
      "Epoch 33::Minibatch 116::LR 0.0261538461538 --> Loss 0.00261440296968\n",
      "Epoch 33::Minibatch 117::LR 0.0261538461538 --> Loss 0.00409786701202\n",
      "Epoch 33::Minibatch 118::LR 0.0261538461538 --> Loss 0.00647597233454\n",
      "Epoch 33::Minibatch 119::LR 0.0261538461538 --> Loss 0.00047964438796\n",
      "Epoch 33::Minibatch 120::LR 0.0261538461538 --> Loss 0.00162777235111\n",
      "Epoch 33::Minibatch 121::LR 0.0261538461538 --> Loss 0.00231595814228\n",
      "Epoch 33::Minibatch 122::LR 0.0261538461538 --> Loss 0.00386740048726\n",
      "Epoch 33::Minibatch 123::LR 0.0261538461538 --> Loss 0.000642556995153\n",
      "Epoch 33::Minibatch 124::LR 0.0261538461538 --> Loss 0.00259799222151\n",
      "Epoch 33::Minibatch 125::LR 0.0261538461538 --> Loss 0.00437787850698\n",
      "Epoch 33::Minibatch 126::LR 0.0261538461538 --> Loss 0.00239959438642\n",
      "Epoch 33::Minibatch 127::LR 0.0261538461538 --> Loss 0.00490982850393\n",
      "Epoch 33::Minibatch 128::LR 0.0261538461538 --> Loss 0.00348753650983\n",
      "Epoch 33::Minibatch 129::LR 0.0261538461538 --> Loss 0.0023478714625\n",
      "Epoch 33::Minibatch 130::LR 0.0261538461538 --> Loss 0.00430438836416\n",
      "Epoch 33::Minibatch 131::LR 0.0261538461538 --> Loss 0.00169380525748\n",
      "Epoch 33::Minibatch 132::LR 0.0261538461538 --> Loss 0.00278065840403\n",
      "Epoch 33::Minibatch 133::LR 0.0261538461538 --> Loss 0.00269664307435\n",
      "Epoch 33::Minibatch 134::LR 0.0261538461538 --> Loss 0.00208676536878\n",
      "Epoch 33::Minibatch 135::LR 0.0261538461538 --> Loss 0.00124638537566\n",
      "Epoch 33::Minibatch 136::LR 0.0261538461538 --> Loss 0.00238441824913\n",
      "Epoch 33::Minibatch 137::LR 0.0261538461538 --> Loss 0.00333296318849\n",
      "Epoch 33::Minibatch 138::LR 0.0261538461538 --> Loss 0.00120103249947\n",
      "Epoch 33::Minibatch 139::LR 0.0261538461538 --> Loss 0.00185870230198\n",
      "Epoch 33::Minibatch 140::LR 0.0261538461538 --> Loss 0.00236211518447\n",
      "Epoch 33::Minibatch 141::LR 0.0261538461538 --> Loss 0.00286805589994\n",
      "Epoch 33::Minibatch 142::LR 0.0261538461538 --> Loss 0.00268567939599\n",
      "Epoch 33::Minibatch 143::LR 0.0261538461538 --> Loss 0.000532353868087\n",
      "Epoch 33::Minibatch 144::LR 0.0261538461538 --> Loss 0.00337498466174\n",
      "Epoch 33::Minibatch 145::LR 0.0261538461538 --> Loss 0.00410157839457\n",
      "Epoch 33::Minibatch 146::LR 0.0261538461538 --> Loss 0.00248571256797\n",
      "Epoch 33::Minibatch 147::LR 0.0261538461538 --> Loss 0.00178445716699\n",
      "Epoch 33::Minibatch 148::LR 0.0261538461538 --> Loss 0.000962671736876\n",
      "Epoch 33::Minibatch 149::LR 0.0261538461538 --> Loss 0.00286113202572\n",
      "Epoch 33::Minibatch 150::LR 0.0261538461538 --> Loss 0.00265335241954\n",
      "Epoch 33::Minibatch 151::LR 0.0261538461538 --> Loss 0.00428561766942\n",
      "Epoch 33::Minibatch 152::LR 0.0261538461538 --> Loss 0.000900359948476\n",
      "Epoch 33::Minibatch 153::LR 0.0261538461538 --> Loss 0.00161739667257\n",
      "Epoch 33::Minibatch 154::LR 0.0261538461538 --> Loss 0.00200407822927\n",
      "Epoch 33::Minibatch 155::LR 0.0261538461538 --> Loss 0.00404218276342\n",
      "Epoch 33::Minibatch 156::LR 0.0261538461538 --> Loss 0.00234777172407\n",
      "Epoch 33::Minibatch 157::LR 0.0261538461538 --> Loss 0.00068391824762\n",
      "Epoch 33::Minibatch 158::LR 0.0261538461538 --> Loss 0.00317033251127\n",
      "Epoch 33::Minibatch 159::LR 0.0261538461538 --> Loss 0.002720160683\n",
      "Epoch 33::Minibatch 160::LR 0.0261538461538 --> Loss 0.00265431821346\n",
      "Epoch 33::Minibatch 161::LR 0.0261538461538 --> Loss 0.000997723738352\n",
      "Epoch 33::Minibatch 162::LR 0.0261538461538 --> Loss 0.00395839095116\n",
      "Epoch 33::Minibatch 163::LR 0.0261538461538 --> Loss 0.00240214029948\n",
      "Epoch 33::Minibatch 164::LR 0.0261538461538 --> Loss 0.00253647545973\n",
      "Epoch 33::Minibatch 165::LR 0.0261538461538 --> Loss 0.000494500150283\n",
      "Epoch 33::Minibatch 166::LR 0.0261538461538 --> Loss 0.00170214851697\n",
      "Epoch 33::Minibatch 167::LR 0.0261538461538 --> Loss 0.00247762282689\n",
      "Epoch 33::Minibatch 168::LR 0.0261538461538 --> Loss 0.00213797171911\n",
      "Epoch 33::Minibatch 169::LR 0.0261538461538 --> Loss 0.000986324350039\n",
      "Epoch 33::Minibatch 170::LR 0.0261538461538 --> Loss 0.000950205922127\n",
      "Epoch 33::Minibatch 171::LR 0.0261538461538 --> Loss 0.00251056512197\n",
      "Epoch 33::Minibatch 172::LR 0.0261538461538 --> Loss 0.00425256093343\n",
      "Epoch 33::Minibatch 173::LR 0.0261538461538 --> Loss 0.00200776557128\n",
      "Epoch 33::Minibatch 174::LR 0.0261538461538 --> Loss 0.000955929954847\n",
      "Epoch 33::Minibatch 175::LR 0.0261538461538 --> Loss 0.00236571669579\n",
      "Epoch 33::Minibatch 176::LR 0.0261538461538 --> Loss 0.00310611267885\n",
      "Epoch 33::Minibatch 177::LR 0.0261538461538 --> Loss 0.00425653815269\n",
      "Epoch 33::Minibatch 178::LR 0.0261538461538 --> Loss 0.00149445176125\n",
      "Epoch 33::Minibatch 179::LR 0.0261538461538 --> Loss 0.00119077712297\n",
      "Epoch 33::Minibatch 180::LR 0.0261538461538 --> Loss 0.00337059259415\n",
      "Epoch 33::Minibatch 181::LR 0.0261538461538 --> Loss 0.00304036915302\n",
      "Epoch 33::Minibatch 182::LR 0.0261538461538 --> Loss 0.000702351381381\n",
      "Epoch 33::Minibatch 183::LR 0.0261538461538 --> Loss 0.00155578662952\n",
      "Epoch 33::Minibatch 184::LR 0.0261538461538 --> Loss 0.00339525818825\n",
      "Epoch 33::Minibatch 185::LR 0.0261538461538 --> Loss 0.00265343487263\n",
      "Epoch 33::Minibatch 186::LR 0.0261538461538 --> Loss 0.000924753248692\n",
      "Epoch 33::Minibatch 187::LR 0.0261538461538 --> Loss 0.00127069026232\n",
      "Epoch 33::Minibatch 188::LR 0.0261538461538 --> Loss 0.00402780214945\n",
      "Epoch 33::Minibatch 189::LR 0.0261538461538 --> Loss 0.00410918593407\n",
      "Epoch 33::Minibatch 190::LR 0.0261538461538 --> Loss 0.00230567793051\n",
      "Epoch 33::Minibatch 191::LR 0.0261538461538 --> Loss 0.000448018958171\n",
      "Epoch 33::Minibatch 192::LR 0.0261538461538 --> Loss 0.00277367194494\n",
      "Epoch 33::Minibatch 193::LR 0.0261538461538 --> Loss 0.00268803715706\n",
      "Epoch 33::Minibatch 194::LR 0.0261538461538 --> Loss 0.00173287252585\n",
      "Epoch 33::Minibatch 195::LR 0.0261538461538 --> Loss 0.000374643852313\n",
      "Epoch 33::Minibatch 196::LR 0.0261538461538 --> Loss 0.00135459880034\n",
      "Epoch 33::Minibatch 197::LR 0.0261538461538 --> Loss 0.00295656740665\n",
      "Epoch 33::Minibatch 198::LR 0.0261538461538 --> Loss 0.00231015324593\n",
      "Epoch 33::Minibatch 199::LR 0.0261538461538 --> Loss 0.000289973939459\n",
      "Epoch 33::Minibatch 200::LR 0.0261538461538 --> Loss 0.00203693985939\n",
      "Epoch 33::Minibatch 201::LR 0.0261538461538 --> Loss 0.00193002084891\n",
      "Epoch 33::Minibatch 202::LR 0.0261538461538 --> Loss 0.00181535065174\n",
      "Epoch 33::Minibatch 203::LR 0.0261538461538 --> Loss 0.00175197521845\n",
      "Epoch 33::Minibatch 204::LR 0.0261538461538 --> Loss 0.00141561359167\n",
      "Epoch 33::Minibatch 205::LR 0.0261538461538 --> Loss 0.00221289197604\n",
      "Epoch 33::Minibatch 206::LR 0.0261538461538 --> Loss 0.00544487317403\n",
      "Epoch 33::Minibatch 207::LR 0.0261538461538 --> Loss 0.00139794766903\n",
      "Epoch 33::Minibatch 208::LR 0.0261538461538 --> Loss 0.00110433290402\n",
      "Epoch 33::Minibatch 209::LR 0.0261538461538 --> Loss 0.00249113937219\n",
      "Epoch 33::Minibatch 210::LR 0.0261538461538 --> Loss 0.00234399100145\n",
      "Epoch 33::Minibatch 211::LR 0.0261538461538 --> Loss 0.00267095506191\n",
      "Epoch 33::Minibatch 212::LR 0.0261538461538 --> Loss 0.00375689744949\n",
      "Epoch 33::Minibatch 213::LR 0.0261538461538 --> Loss 0.00539036750793\n",
      "Epoch 33::Minibatch 214::LR 0.0261538461538 --> Loss 0.00708832025528\n",
      "Epoch 33::Minibatch 215::LR 0.0261538461538 --> Loss 0.00135850101709\n",
      "Epoch 33::Minibatch 216::LR 0.0261538461538 --> Loss 0.00528198281924\n",
      "Epoch 33::Minibatch 217::LR 0.0261538461538 --> Loss 0.00582291086515\n",
      "Epoch 33::Minibatch 218::LR 0.0261538461538 --> Loss 0.00389416853587\n",
      "Epoch 33::Minibatch 219::LR 0.0261538461538 --> Loss 0.00440499663353\n",
      "Epoch 33::Minibatch 220::LR 0.0261538461538 --> Loss 0.0043472913901\n",
      "Epoch 33::Minibatch 221::LR 0.0261538461538 --> Loss 0.00425179521243\n",
      "Epoch 33::Minibatch 222::LR 0.0261538461538 --> Loss 0.0031589871645\n",
      "Epoch 33::Minibatch 223::LR 0.0261538461538 --> Loss 0.00138166864713\n",
      "Epoch 33::Minibatch 224::LR 0.0261538461538 --> Loss 0.00159206916889\n",
      "Epoch 33::Minibatch 225::LR 0.0261538461538 --> Loss 0.00781379938126\n",
      "Epoch 33::Minibatch 226::LR 0.0261538461538 --> Loss 0.00364486932755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 227::LR 0.0261538461538 --> Loss 0.0016778254509\n",
      "Epoch 33::Minibatch 228::LR 0.0261538461538 --> Loss 0.000652327189843\n",
      "Epoch 33::Minibatch 229::LR 0.0261538461538 --> Loss 0.00471589485804\n",
      "Epoch 33::Minibatch 230::LR 0.0261538461538 --> Loss 0.00366648753484\n",
      "Epoch 33::Minibatch 231::LR 0.0261538461538 --> Loss 0.00266255319118\n",
      "Epoch 33::Minibatch 232::LR 0.0261538461538 --> Loss 0.00116266270479\n",
      "Epoch 33::Minibatch 233::LR 0.0261538461538 --> Loss 0.00246267080307\n",
      "Epoch 33::Minibatch 234::LR 0.0261538461538 --> Loss 0.00735498110453\n",
      "Epoch 33::Minibatch 235::LR 0.0261538461538 --> Loss 0.00456299622854\n",
      "Epoch 33::Minibatch 236::LR 0.0261538461538 --> Loss 0.00167188465595\n",
      "Epoch 33::Minibatch 237::LR 0.0261538461538 --> Loss 0.000587296634912\n",
      "Epoch 33::Minibatch 238::LR 0.0261538461538 --> Loss 0.00344333688418\n",
      "Epoch 33::Minibatch 239::LR 0.0261538461538 --> Loss 0.00295681337516\n",
      "Epoch 33::Minibatch 240::LR 0.0261538461538 --> Loss 0.0032527222236\n",
      "Epoch 33::Minibatch 241::LR 0.0261538461538 --> Loss 0.000743781427542\n",
      "Epoch 33::Minibatch 242::LR 0.0261538461538 --> Loss 0.00671153227488\n",
      "Epoch 33::Minibatch 243::LR 0.0261538461538 --> Loss 0.00325820922852\n",
      "Epoch 33::Minibatch 244::LR 0.0261538461538 --> Loss 0.00273223082225\n",
      "Epoch 33::Minibatch 245::LR 0.0261538461538 --> Loss 0.000428029000759\n",
      "Epoch 33::Minibatch 246::LR 0.0261538461538 --> Loss 0.00190360506376\n",
      "Epoch 33::Minibatch 247::LR 0.0261538461538 --> Loss 0.0104716571172\n",
      "Epoch 33::Minibatch 248::LR 0.0261538461538 --> Loss 0.00433811426163\n",
      "Epoch 33::Minibatch 249::LR 0.0261538461538 --> Loss 0.00240280270576\n",
      "Epoch 33::Minibatch 250::LR 0.0261538461538 --> Loss 0.00234104275703\n",
      "Epoch 33::Minibatch 251::LR 0.0261538461538 --> Loss 0.002331392169\n",
      "Epoch 33::Minibatch 252::LR 0.0261538461538 --> Loss 0.00160854717096\n",
      "Epoch 33::Minibatch 253::LR 0.0261538461538 --> Loss 0.00278670867284\n",
      "Epoch 33::Minibatch 254::LR 0.0261538461538 --> Loss 0.00482494910558\n",
      "Epoch 33::Minibatch 255::LR 0.0261538461538 --> Loss 0.00384031732877\n",
      "Epoch 33::Minibatch 256::LR 0.0261538461538 --> Loss 0.00139301290115\n",
      "Epoch 33::Minibatch 257::LR 0.0261538461538 --> Loss 0.00113651573658\n",
      "Epoch 33::Minibatch 258::LR 0.0261538461538 --> Loss 0.00365646441778\n",
      "Epoch 33::Minibatch 259::LR 0.0261538461538 --> Loss 0.00158675342798\n",
      "Epoch 33::Minibatch 260::LR 0.0261538461538 --> Loss 0.00184238195419\n",
      "Epoch 33::Minibatch 261::LR 0.0261538461538 --> Loss 0.00265078485012\n",
      "Epoch 33::Minibatch 262::LR 0.0261538461538 --> Loss 0.00181032637755\n",
      "Epoch 33::Minibatch 263::LR 0.0261538461538 --> Loss 0.00228072007497\n",
      "Epoch 33::Minibatch 264::LR 0.0261538461538 --> Loss 0.00355067928632\n",
      "Epoch 33::Minibatch 265::LR 0.0261538461538 --> Loss 0.00991953929265\n",
      "Epoch 33::Minibatch 266::LR 0.0261538461538 --> Loss 0.000876820087433\n",
      "Epoch 33::Minibatch 267::LR 0.0261538461538 --> Loss 0.00906796058019\n",
      "Epoch 33::Minibatch 268::LR 0.0261538461538 --> Loss 0.00103068421284\n",
      "Epoch 33::Minibatch 269::LR 0.0261538461538 --> Loss 0.0034635925293\n",
      "Epoch 33::Minibatch 270::LR 0.0261538461538 --> Loss 0.00733022928238\n",
      "Epoch 33::Minibatch 271::LR 0.0261538461538 --> Loss 0.0024119802316\n",
      "Epoch 33::Minibatch 272::LR 0.0261538461538 --> Loss 0.00442382017771\n",
      "Epoch 33::Minibatch 273::LR 0.0261538461538 --> Loss 0.00136873195569\n",
      "Epoch 33::Minibatch 274::LR 0.0261538461538 --> Loss 0.00176833013693\n",
      "Epoch 33::Minibatch 275::LR 0.0261538461538 --> Loss 0.00245660603046\n",
      "Epoch 33::Minibatch 276::LR 0.0261538461538 --> Loss 0.00334111054738\n",
      "Epoch 33::Minibatch 277::LR 0.0261538461538 --> Loss 0.000862680077553\n",
      "Epoch 33::Minibatch 278::LR 0.0261538461538 --> Loss 0.00252836088339\n",
      "Epoch 33::Minibatch 279::LR 0.0261538461538 --> Loss 0.00198419670264\n",
      "Epoch 33::Minibatch 280::LR 0.0261538461538 --> Loss 0.00175626079241\n",
      "Epoch 33::Minibatch 281::LR 0.0261538461538 --> Loss 0.00111343741417\n",
      "Epoch 33::Minibatch 282::LR 0.0261538461538 --> Loss 0.00199968139331\n",
      "Epoch 33::Minibatch 283::LR 0.0261538461538 --> Loss 0.00190183718999\n",
      "Epoch 33::Minibatch 284::LR 0.0261538461538 --> Loss 0.00155416021744\n",
      "Epoch 33::Minibatch 285::LR 0.0261538461538 --> Loss 0.00111823578676\n",
      "Epoch 33::Minibatch 286::LR 0.0261538461538 --> Loss 0.00194673200448\n",
      "Epoch 33::Minibatch 287::LR 0.0261538461538 --> Loss 0.00192734241486\n",
      "Epoch 33::Minibatch 288::LR 0.0261538461538 --> Loss 0.00104991585016\n",
      "Epoch 33::Minibatch 289::LR 0.0261538461538 --> Loss 0.00154718736808\n",
      "Epoch 33::Minibatch 290::LR 0.0261538461538 --> Loss 0.00183629234632\n",
      "Epoch 33::Minibatch 291::LR 0.0261538461538 --> Loss 0.00165133059025\n",
      "Epoch 33::Minibatch 292::LR 0.0261538461538 --> Loss 0.000583904286226\n",
      "Epoch 33::Minibatch 293::LR 0.0261538461538 --> Loss 0.00148252159357\n",
      "Epoch 33::Minibatch 294::LR 0.0261538461538 --> Loss 0.00161539991697\n",
      "Epoch 33::Minibatch 295::LR 0.0261538461538 --> Loss 0.00187449534734\n",
      "Epoch 33::Minibatch 296::LR 0.0261538461538 --> Loss 0.00161667495966\n",
      "Epoch 33::Minibatch 297::LR 0.0261538461538 --> Loss 0.00141592909892\n",
      "Epoch 33::Minibatch 298::LR 0.0261538461538 --> Loss 0.00142019361258\n",
      "Epoch 33::Minibatch 299::LR 0.0261538461538 --> Loss 0.000813978115718\n",
      "Epoch 33::Minibatch 300::LR 0.0261538461538 --> Loss 0.00267602125804\n",
      "Epoch 33::Minibatch 301::LR 0.0261538461538 --> Loss 0.00258808890978\n",
      "Epoch 33::Minibatch 302::LR 0.0261538461538 --> Loss 0.00237939298153\n",
      "Epoch 33::Minibatch 303::LR 0.0261538461538 --> Loss 0.00082860827446\n",
      "Epoch 33::Minibatch 304::LR 0.0261538461538 --> Loss 0.00292530139287\n",
      "Epoch 33::Minibatch 305::LR 0.0261538461538 --> Loss 0.00171341836452\n",
      "Epoch 33::Minibatch 306::LR 0.0261538461538 --> Loss 0.000937506953875\n",
      "Epoch 33::Minibatch 307::LR 0.0261538461538 --> Loss 0.0023974831899\n",
      "Epoch 33::Minibatch 308::LR 0.0261538461538 --> Loss 0.00201864083608\n",
      "Epoch 33::Minibatch 309::LR 0.0261538461538 --> Loss 0.00104518781106\n",
      "Epoch 33::Minibatch 310::LR 0.0261538461538 --> Loss 0.00119627585014\n",
      "Epoch 33::Minibatch 311::LR 0.0261538461538 --> Loss 0.00179778138796\n",
      "Epoch 33::Minibatch 312::LR 0.0261538461538 --> Loss 0.00284958620866\n",
      "Epoch 33::Minibatch 313::LR 0.0261538461538 --> Loss 0.00233354886373\n",
      "Epoch 33::Minibatch 314::LR 0.0261538461538 --> Loss 0.00192341943582\n",
      "Epoch 33::Minibatch 315::LR 0.0261538461538 --> Loss 0.00105060458183\n",
      "Epoch 33::Minibatch 316::LR 0.0261538461538 --> Loss 0.00234568397204\n",
      "Epoch 33::Minibatch 317::LR 0.0261538461538 --> Loss 0.00156530102094\n",
      "Epoch 33::Minibatch 318::LR 0.0261538461538 --> Loss 0.00131200273832\n",
      "Epoch 33::Minibatch 319::LR 0.0261538461538 --> Loss 0.00230883578459\n",
      "Epoch 33::Minibatch 320::LR 0.0261538461538 --> Loss 0.00302332182725\n",
      "Epoch 33::Minibatch 321::LR 0.0261538461538 --> Loss 0.00084235817194\n",
      "Epoch 33::Minibatch 322::LR 0.0261538461538 --> Loss 0.00343059937159\n",
      "Epoch 33::Minibatch 323::LR 0.0261538461538 --> Loss 0.00341230551402\n",
      "Epoch 33::Minibatch 324::LR 0.0261538461538 --> Loss 0.00265143692493\n",
      "Epoch 33::Minibatch 325::LR 0.0261538461538 --> Loss 0.00236980319023\n",
      "Epoch 33::Minibatch 326::LR 0.0261538461538 --> Loss 0.00525310516357\n",
      "Epoch 33::Minibatch 327::LR 0.0261538461538 --> Loss 0.0022260560592\n",
      "Epoch 33::Minibatch 328::LR 0.0261538461538 --> Loss 0.00292736212413\n",
      "Epoch 33::Minibatch 329::LR 0.0261538461538 --> Loss 0.00118969589472\n",
      "Epoch 33::Minibatch 330::LR 0.0261538461538 --> Loss 0.00158853848775\n",
      "Epoch 33::Minibatch 331::LR 0.0261538461538 --> Loss 0.00253374417623\n",
      "Epoch 33::Minibatch 332::LR 0.0261538461538 --> Loss 0.00244843145212\n",
      "Epoch 33::Minibatch 333::LR 0.0261538461538 --> Loss 0.00147123535474\n",
      "Epoch 33::Minibatch 334::LR 0.0261538461538 --> Loss 0.00440450231234\n",
      "Epoch 33::Minibatch 335::LR 0.0261538461538 --> Loss 0.00190187096596\n",
      "Epoch 33::Minibatch 336::LR 0.0261538461538 --> Loss 0.00226285099983\n",
      "Epoch 33::Minibatch 337::LR 0.0261538461538 --> Loss 0.00375491539637\n",
      "Epoch 33::Minibatch 338::LR 0.0261538461538 --> Loss 0.000556391626596\n",
      "Epoch 33::Minibatch 339::LR 0.0261538461538 --> Loss 0.00323837419351\n",
      "Epoch 33::Minibatch 340::LR 0.0261538461538 --> Loss 0.00366166830063\n",
      "Epoch 33::Minibatch 341::LR 0.0261538461538 --> Loss 0.00427706201871\n",
      "Epoch 33::Minibatch 342::LR 0.0261538461538 --> Loss 0.00305583894253\n",
      "Epoch 33::Minibatch 343::LR 0.0261538461538 --> Loss 0.00163848270973\n",
      "Epoch 33::Minibatch 344::LR 0.0261538461538 --> Loss 0.00316069483757\n",
      "Epoch 33::Minibatch 345::LR 0.0261538461538 --> Loss 0.00406964659691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 346::LR 0.0261538461538 --> Loss 0.00534401575724\n",
      "Epoch 33::Minibatch 347::LR 0.0261538461538 --> Loss 0.000817857285341\n",
      "Epoch 33::Minibatch 348::LR 0.0261538461538 --> Loss 0.00297186275323\n",
      "Epoch 33::Minibatch 349::LR 0.0261538461538 --> Loss 0.00335204482079\n",
      "Epoch 33::Minibatch 350::LR 0.0261538461538 --> Loss 0.00164559523265\n",
      "Epoch 33::Minibatch 351::LR 0.0261538461538 --> Loss 0.00342472155889\n",
      "Epoch 33::Minibatch 352::LR 0.0261538461538 --> Loss 0.00489047765732\n",
      "Epoch 33::Minibatch 353::LR 0.0261538461538 --> Loss 0.0034984322389\n",
      "Epoch 33::Minibatch 354::LR 0.0261538461538 --> Loss 0.00294167101383\n",
      "Epoch 33::Minibatch 355::LR 0.0261538461538 --> Loss 0.00626937150955\n",
      "Epoch 33::Minibatch 356::LR 0.0261538461538 --> Loss 0.00315702617168\n",
      "Epoch 33::Minibatch 357::LR 0.0261538461538 --> Loss 0.00117675840855\n",
      "Epoch 33::Minibatch 358::LR 0.0261538461538 --> Loss 0.00194221973419\n",
      "Epoch 33::Minibatch 359::LR 0.0261538461538 --> Loss 0.00267086009185\n",
      "Epoch 33::Minibatch 360::LR 0.0261538461538 --> Loss 0.00228731075923\n",
      "Epoch 33::Minibatch 361::LR 0.0261538461538 --> Loss 0.00225409309069\n",
      "Epoch 33::Minibatch 362::LR 0.0261538461538 --> Loss 0.00224409659704\n",
      "Epoch 33::Minibatch 363::LR 0.0261538461538 --> Loss 0.000635236452023\n",
      "Epoch 33::Minibatch 364::LR 0.0261538461538 --> Loss 0.00196900765101\n",
      "Epoch 33::Minibatch 365::LR 0.0261538461538 --> Loss 0.00199880162875\n",
      "Epoch 33::Minibatch 366::LR 0.0261538461538 --> Loss 0.00211554865042\n",
      "Epoch 33::Minibatch 367::LR 0.0261538461538 --> Loss 0.000990331669648\n",
      "Epoch 33::Minibatch 368::LR 0.0261538461538 --> Loss 0.000973587334156\n",
      "Epoch 33::Minibatch 369::LR 0.0261538461538 --> Loss 0.00274968047937\n",
      "Epoch 33::Minibatch 370::LR 0.0261538461538 --> Loss 0.00220332682133\n",
      "Epoch 33::Minibatch 371::LR 0.0261538461538 --> Loss 0.00184280713399\n",
      "Epoch 33::Minibatch 372::LR 0.0261538461538 --> Loss 0.000428771227598\n",
      "Epoch 33::Minibatch 373::LR 0.0261538461538 --> Loss 0.00180821200212\n",
      "Epoch 33::Minibatch 374::LR 0.0261538461538 --> Loss 0.00225425958633\n",
      "Epoch 33::Minibatch 375::LR 0.0261538461538 --> Loss 0.00189274787903\n",
      "Epoch 33::Minibatch 376::LR 0.0261538461538 --> Loss 0.00120355208715\n",
      "Epoch 33::Minibatch 377::LR 0.0261538461538 --> Loss 0.00190810263157\n",
      "Epoch 33::Minibatch 378::LR 0.0261538461538 --> Loss 0.00209075331688\n",
      "Epoch 33::Minibatch 379::LR 0.0261538461538 --> Loss 0.00231772343318\n",
      "Epoch 33::Minibatch 380::LR 0.0261538461538 --> Loss 0.00156192918619\n",
      "Epoch 33::Minibatch 381::LR 0.0261538461538 --> Loss 0.000995085537434\n",
      "Epoch 33::Minibatch 382::LR 0.0261538461538 --> Loss 0.00203868468602\n",
      "Epoch 33::Minibatch 383::LR 0.0261538461538 --> Loss 0.00199131608009\n",
      "Epoch 33::Minibatch 384::LR 0.0261538461538 --> Loss 0.00112504055103\n",
      "Epoch 33::Minibatch 385::LR 0.0261538461538 --> Loss 0.00105881124735\n",
      "Epoch 33::Minibatch 386::LR 0.0261538461538 --> Loss 0.002252283295\n",
      "Epoch 33::Minibatch 387::LR 0.0261538461538 --> Loss 0.00236453493436\n",
      "Epoch 33::Minibatch 388::LR 0.0261538461538 --> Loss 0.00121815105279\n",
      "Epoch 33::Minibatch 389::LR 0.0261538461538 --> Loss 0.00178416947524\n",
      "Epoch 33::Minibatch 390::LR 0.0261538461538 --> Loss 0.0032520866394\n",
      "Epoch 33::Minibatch 391::LR 0.0261538461538 --> Loss 0.00254895885785\n",
      "Epoch 33::Minibatch 392::LR 0.0261538461538 --> Loss 0.00255599578222\n",
      "Epoch 33::Minibatch 393::LR 0.0261538461538 --> Loss 0.0027291260163\n",
      "Epoch 33::Minibatch 394::LR 0.0261538461538 --> Loss 0.00200684607029\n",
      "Epoch 33::Minibatch 395::LR 0.0261538461538 --> Loss 0.00207382082939\n",
      "Epoch 33::Minibatch 396::LR 0.0261538461538 --> Loss 0.00194073438644\n",
      "Epoch 33::Minibatch 397::LR 0.0261538461538 --> Loss 0.00207753241062\n",
      "Epoch 33::Minibatch 398::LR 0.0261538461538 --> Loss 0.00206674059232\n",
      "Epoch 33::Minibatch 399::LR 0.0261538461538 --> Loss 0.00237212737401\n",
      "Epoch 33::Minibatch 400::LR 0.0261538461538 --> Loss 0.00200944761435\n",
      "Epoch 33::Minibatch 401::LR 0.0261538461538 --> Loss 0.00340490261714\n",
      "Epoch 33::Minibatch 402::LR 0.0261538461538 --> Loss 0.00171531438828\n",
      "Epoch 33::Minibatch 403::LR 0.0261538461538 --> Loss 0.00142574508985\n",
      "Epoch 33::Minibatch 404::LR 0.0261538461538 --> Loss 0.00133146464825\n",
      "Epoch 33::Minibatch 405::LR 0.0261538461538 --> Loss 0.00332668085893\n",
      "Epoch 33::Minibatch 406::LR 0.0261538461538 --> Loss 0.00233248392741\n",
      "Epoch 33::Minibatch 407::LR 0.0261538461538 --> Loss 0.00170321961244\n",
      "Epoch 33::Minibatch 408::LR 0.0261538461538 --> Loss 0.00043293595314\n",
      "Epoch 33::Minibatch 409::LR 0.0261538461538 --> Loss 0.00220784107844\n",
      "Epoch 33::Minibatch 410::LR 0.0261538461538 --> Loss 0.00313052475452\n",
      "Epoch 33::Minibatch 411::LR 0.0261538461538 --> Loss 0.0016621145606\n",
      "Epoch 33::Minibatch 412::LR 0.0261538461538 --> Loss 0.000941135187944\n",
      "Epoch 33::Minibatch 413::LR 0.0261538461538 --> Loss 0.00197295149167\n",
      "Epoch 33::Minibatch 414::LR 0.0261538461538 --> Loss 0.00187386790911\n",
      "Epoch 33::Minibatch 415::LR 0.0261538461538 --> Loss 0.00117222100496\n",
      "Epoch 33::Minibatch 416::LR 0.0261538461538 --> Loss 0.000789200365543\n",
      "Epoch 33::Minibatch 417::LR 0.0261538461538 --> Loss 0.00167508006096\n",
      "Epoch 33::Minibatch 418::LR 0.0261538461538 --> Loss 0.00258023579915\n",
      "Epoch 33::Minibatch 419::LR 0.0261538461538 --> Loss 0.00049010142684\n",
      "Epoch 33::Minibatch 420::LR 0.0261538461538 --> Loss 0.000689972837766\n",
      "Epoch 33::Minibatch 421::LR 0.0261538461538 --> Loss 0.00186677157879\n",
      "Epoch 33::Minibatch 422::LR 0.0261538461538 --> Loss 0.00205450832844\n",
      "Epoch 33::Minibatch 423::LR 0.0261538461538 --> Loss 0.000984513064226\n",
      "Epoch 33::Minibatch 424::LR 0.0261538461538 --> Loss 0.00151695092519\n",
      "Epoch 33::Minibatch 425::LR 0.0261538461538 --> Loss 0.00285925030708\n",
      "Epoch 33::Minibatch 426::LR 0.0261538461538 --> Loss 0.00198836922646\n",
      "Epoch 33::Minibatch 427::LR 0.0261538461538 --> Loss 0.000736286193132\n",
      "Epoch 33::Minibatch 428::LR 0.0261538461538 --> Loss 0.00092592994372\n",
      "Epoch 33::Minibatch 429::LR 0.0261538461538 --> Loss 0.00223265230656\n",
      "Epoch 33::Minibatch 430::LR 0.0261538461538 --> Loss 0.00778529246648\n",
      "Epoch 33::Minibatch 431::LR 0.0261538461538 --> Loss 0.00355304439863\n",
      "Epoch 33::Minibatch 432::LR 0.0261538461538 --> Loss 0.0039787042141\n",
      "Epoch 33::Minibatch 433::LR 0.0261538461538 --> Loss 0.00253053625425\n",
      "Epoch 33::Minibatch 434::LR 0.0261538461538 --> Loss 0.00243236720562\n",
      "Epoch 33::Minibatch 435::LR 0.0261538461538 --> Loss 0.00224641859531\n",
      "Epoch 33::Minibatch 436::LR 0.0261538461538 --> Loss 0.00158979753653\n",
      "Epoch 33::Minibatch 437::LR 0.0261538461538 --> Loss 0.00279705524445\n",
      "Epoch 33::Minibatch 438::LR 0.0261538461538 --> Loss 0.00224787076314\n",
      "Epoch 33::Minibatch 439::LR 0.0261538461538 --> Loss 0.00190947989623\n",
      "Epoch 33::Minibatch 440::LR 0.0261538461538 --> Loss 0.00294857402643\n",
      "Epoch 33::Minibatch 441::LR 0.0261538461538 --> Loss 0.00275702178478\n",
      "Epoch 33::Minibatch 442::LR 0.0261538461538 --> Loss 0.00246266484261\n",
      "Epoch 33::Minibatch 443::LR 0.0261538461538 --> Loss 0.00344176928202\n",
      "Epoch 33::Minibatch 444::LR 0.0261538461538 --> Loss 0.00265405337016\n",
      "Epoch 33::Minibatch 445::LR 0.0261538461538 --> Loss 0.000843678514163\n",
      "Epoch 33::Minibatch 446::LR 0.0261538461538 --> Loss 0.00135557274024\n",
      "Epoch 33::Minibatch 447::LR 0.0261538461538 --> Loss 0.00227424065272\n",
      "Epoch 33::Minibatch 448::LR 0.0261538461538 --> Loss 0.00230186641216\n",
      "Epoch 33::Minibatch 449::LR 0.0261538461538 --> Loss 0.00355175058047\n",
      "Epoch 33::Minibatch 450::LR 0.0261538461538 --> Loss 0.00211666266123\n",
      "Epoch 33::Minibatch 451::LR 0.0261538461538 --> Loss 0.00380749344826\n",
      "Epoch 33::Minibatch 452::LR 0.0261538461538 --> Loss 0.00228250960509\n",
      "Epoch 33::Minibatch 453::LR 0.0261538461538 --> Loss 0.000347326174378\n",
      "Epoch 33::Minibatch 454::LR 0.0261538461538 --> Loss 0.00340430855751\n",
      "Epoch 33::Minibatch 455::LR 0.0261538461538 --> Loss 0.00257042487462\n",
      "Epoch 33::Minibatch 456::LR 0.0261538461538 --> Loss 0.00303958316644\n",
      "Epoch 33::Minibatch 457::LR 0.0261538461538 --> Loss 0.00186748286088\n",
      "Epoch 33::Minibatch 458::LR 0.0261538461538 --> Loss 0.000712800522645\n",
      "Epoch 33::Minibatch 459::LR 0.0261538461538 --> Loss 0.00381245215734\n",
      "Epoch 33::Minibatch 460::LR 0.0261538461538 --> Loss 0.00241612136364\n",
      "Epoch 33::Minibatch 461::LR 0.0261538461538 --> Loss 0.0036610798041\n",
      "Epoch 33::Minibatch 462::LR 0.0261538461538 --> Loss 0.000367794185877\n",
      "Epoch 33::Minibatch 463::LR 0.0261538461538 --> Loss 0.00406632383664\n",
      "Epoch 33::Minibatch 464::LR 0.0261538461538 --> Loss 0.00193724274635\n",
      "Epoch 33::Minibatch 465::LR 0.0261538461538 --> Loss 0.00446143269539\n",
      "Epoch 33::Minibatch 466::LR 0.0261538461538 --> Loss 0.00493269681931\n",
      "Epoch 33::Minibatch 467::LR 0.0261538461538 --> Loss 0.00503101706505\n",
      "Epoch 33::Minibatch 468::LR 0.0261538461538 --> Loss 0.00560877482096\n",
      "Epoch 33::Minibatch 469::LR 0.0261538461538 --> Loss 0.00592867771784\n",
      "Epoch 33::Minibatch 470::LR 0.0261538461538 --> Loss 0.00355762322744\n",
      "Epoch 33::Minibatch 471::LR 0.0261538461538 --> Loss 0.00165663182735\n",
      "Epoch 33::Minibatch 472::LR 0.0261538461538 --> Loss 0.00355937838554\n",
      "Epoch 33::Minibatch 473::LR 0.0261538461538 --> Loss 0.00230902433395\n",
      "Epoch 33::Minibatch 474::LR 0.0261538461538 --> Loss 0.000688382784526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 475::LR 0.0261538461538 --> Loss 0.00474079489708\n",
      "Epoch 33::Minibatch 476::LR 0.0261538461538 --> Loss 0.00759594678879\n",
      "Epoch 33::Minibatch 477::LR 0.0261538461538 --> Loss 0.000915182034175\n",
      "Epoch 33::Minibatch 478::LR 0.0261538461538 --> Loss 0.00240170240402\n",
      "Epoch 33::Minibatch 479::LR 0.0261538461538 --> Loss 0.00195773104827\n",
      "Epoch 33::Minibatch 480::LR 0.0261538461538 --> Loss 0.00151049494743\n",
      "Epoch 33::Minibatch 481::LR 0.0261538461538 --> Loss 0.00095810353756\n",
      "Epoch 33::Minibatch 482::LR 0.0261538461538 --> Loss 0.00206452528636\n",
      "Epoch 33::Minibatch 483::LR 0.0261538461538 --> Loss 0.00300800959269\n",
      "Epoch 33::Minibatch 484::LR 0.0261538461538 --> Loss 0.00337520480156\n",
      "Epoch 33::Minibatch 485::LR 0.0261538461538 --> Loss 0.000761139641205\n",
      "Epoch 33::Minibatch 486::LR 0.0261538461538 --> Loss 0.00280928909779\n",
      "Epoch 33::Minibatch 487::LR 0.0261538461538 --> Loss 0.0032885915041\n",
      "Epoch 33::Minibatch 488::LR 0.0261538461538 --> Loss 0.00201576749484\n",
      "Epoch 33::Minibatch 489::LR 0.0261538461538 --> Loss 0.00306338389715\n",
      "Epoch 33::Minibatch 490::LR 0.0261538461538 --> Loss 0.00041222607096\n",
      "Epoch 33::Minibatch 491::LR 0.0261538461538 --> Loss 0.00316643397013\n",
      "Epoch 33::Minibatch 492::LR 0.0261538461538 --> Loss 0.00306334177653\n",
      "Epoch 33::Minibatch 493::LR 0.0261538461538 --> Loss 0.00301476875941\n",
      "Epoch 33::Minibatch 494::LR 0.0261538461538 --> Loss 0.000732065588236\n",
      "Epoch 33::Minibatch 495::LR 0.0261538461538 --> Loss 0.00182289024194\n",
      "Epoch 33::Minibatch 496::LR 0.0261538461538 --> Loss 0.00277762929598\n",
      "Epoch 33::Minibatch 497::LR 0.0261538461538 --> Loss 0.000913569529851\n",
      "Epoch 33::Minibatch 498::LR 0.0261538461538 --> Loss 0.00054903904597\n",
      "Epoch 33::Minibatch 499::LR 0.0261538461538 --> Loss 0.00339203278224\n",
      "Epoch 33::Minibatch 500::LR 0.0261538461538 --> Loss 0.00142368376255\n",
      "Epoch 33::Minibatch 501::LR 0.0261538461538 --> Loss 0.00201669812202\n",
      "Epoch 33::Minibatch 502::LR 0.0261538461538 --> Loss 0.00372917771339\n",
      "Epoch 33::Minibatch 503::LR 0.0261538461538 --> Loss 0.00671293179194\n",
      "Epoch 33::Minibatch 504::LR 0.0261538461538 --> Loss 0.00663418769836\n",
      "Epoch 33::Minibatch 505::LR 0.0261538461538 --> Loss 0.00391654253006\n",
      "Epoch 33::Minibatch 506::LR 0.0261538461538 --> Loss 0.00329365332921\n",
      "Epoch 33::Minibatch 507::LR 0.0261538461538 --> Loss 0.00571664492289\n",
      "Epoch 33::Minibatch 508::LR 0.0261538461538 --> Loss 0.00338246424993\n",
      "Epoch 33::Minibatch 509::LR 0.0261538461538 --> Loss 0.00421984871229\n",
      "Epoch 33::Minibatch 510::LR 0.0261538461538 --> Loss 0.00437071402868\n",
      "Epoch 33::Minibatch 511::LR 0.0261538461538 --> Loss 0.00400481581688\n",
      "Epoch 33::Minibatch 512::LR 0.0261538461538 --> Loss 0.00268151839574\n",
      "Epoch 33::Minibatch 513::LR 0.0261538461538 --> Loss 0.000594357649485\n",
      "Epoch 33::Minibatch 514::LR 0.0261538461538 --> Loss 0.00261342803637\n",
      "Epoch 33::Minibatch 515::LR 0.0261538461538 --> Loss 0.002989128232\n",
      "Epoch 33::Minibatch 516::LR 0.0261538461538 --> Loss 0.00390345136325\n",
      "Epoch 33::Minibatch 517::LR 0.0261538461538 --> Loss 0.00362863858541\n",
      "Epoch 33::Minibatch 518::LR 0.0261538461538 --> Loss 0.00257307767868\n",
      "Epoch 33::Minibatch 519::LR 0.0261538461538 --> Loss 0.0035584406058\n",
      "Epoch 33::Minibatch 520::LR 0.0261538461538 --> Loss 0.00559503396352\n",
      "Epoch 33::Minibatch 521::LR 0.0261538461538 --> Loss 0.00565222501755\n",
      "Epoch 33::Minibatch 522::LR 0.0261538461538 --> Loss 0.00706640720367\n",
      "Epoch 33::Minibatch 523::LR 0.0261538461538 --> Loss 0.000621930609147\n",
      "Epoch 33::Minibatch 524::LR 0.0261538461538 --> Loss 0.00138756603003\n",
      "Epoch 33::Minibatch 525::LR 0.0261538461538 --> Loss 0.0030374066035\n",
      "Epoch 33::Minibatch 526::LR 0.0261538461538 --> Loss 0.00368344346682\n",
      "Epoch 33::Minibatch 527::LR 0.0261538461538 --> Loss 0.00211985290051\n",
      "Epoch 33::Minibatch 528::LR 0.0261538461538 --> Loss 0.000919837156932\n",
      "Epoch 33::Minibatch 529::LR 0.0261538461538 --> Loss 0.00379107356071\n",
      "Epoch 33::Minibatch 530::LR 0.0261538461538 --> Loss 0.00376400152842\n",
      "Epoch 33::Minibatch 531::LR 0.0261538461538 --> Loss 0.00334700942039\n",
      "Epoch 33::Minibatch 532::LR 0.0261538461538 --> Loss 0.00258575240771\n",
      "Epoch 33::Minibatch 533::LR 0.0261538461538 --> Loss 0.00487593372663\n",
      "Epoch 33::Minibatch 534::LR 0.0261538461538 --> Loss 0.00367453813553\n",
      "Epoch 33::Minibatch 535::LR 0.0261538461538 --> Loss 0.00332469026248\n",
      "Epoch 33::Minibatch 536::LR 0.0261538461538 --> Loss 0.00210598389308\n",
      "Epoch 33::Minibatch 537::LR 0.0261538461538 --> Loss 0.000582191795111\n",
      "Epoch 33::Minibatch 538::LR 0.0261538461538 --> Loss 0.00162804931402\n",
      "Epoch 33::Minibatch 539::LR 0.0261538461538 --> Loss 0.00330383499463\n",
      "Epoch 33::Minibatch 540::LR 0.0261538461538 --> Loss 0.0033808640639\n",
      "Epoch 33::Minibatch 541::LR 0.0261538461538 --> Loss 0.0028341293335\n",
      "Epoch 33::Minibatch 542::LR 0.0261538461538 --> Loss 0.00242908140024\n",
      "Epoch 33::Minibatch 543::LR 0.0261538461538 --> Loss 0.00255764345328\n",
      "Epoch 33::Minibatch 544::LR 0.0261538461538 --> Loss 0.00404489159584\n",
      "Epoch 33::Minibatch 545::LR 0.0261538461538 --> Loss 0.0019648194313\n",
      "Epoch 33::Minibatch 546::LR 0.0261538461538 --> Loss 0.000660843948523\n",
      "Epoch 33::Minibatch 547::LR 0.0261538461538 --> Loss 0.00257448852062\n",
      "Epoch 33::Minibatch 548::LR 0.0261538461538 --> Loss 0.00338061849276\n",
      "Epoch 33::Minibatch 549::LR 0.0261538461538 --> Loss 0.00888779640198\n",
      "Epoch 33::Minibatch 550::LR 0.0261538461538 --> Loss 0.00118633518616\n",
      "Epoch 33::Minibatch 551::LR 0.0261538461538 --> Loss 0.00246047457059\n",
      "Epoch 33::Minibatch 552::LR 0.0261538461538 --> Loss 0.0034249552091\n",
      "Epoch 33::Minibatch 553::LR 0.0261538461538 --> Loss 0.00294021189213\n",
      "Epoch 33::Minibatch 554::LR 0.0261538461538 --> Loss 0.00360849817594\n",
      "Epoch 33::Minibatch 555::LR 0.0261538461538 --> Loss 0.000937431653341\n",
      "Epoch 33::Minibatch 556::LR 0.0261538461538 --> Loss 0.00191192905108\n",
      "Epoch 33::Minibatch 557::LR 0.0261538461538 --> Loss 0.00240801870823\n",
      "Epoch 33::Minibatch 558::LR 0.0261538461538 --> Loss 0.00357450048129\n",
      "Epoch 33::Minibatch 559::LR 0.0261538461538 --> Loss 0.00364761273066\n",
      "Epoch 33::Minibatch 560::LR 0.0261538461538 --> Loss 0.0030506525437\n",
      "Epoch 33::Minibatch 561::LR 0.0261538461538 --> Loss 0.00261631608009\n",
      "Epoch 33::Minibatch 562::LR 0.0261538461538 --> Loss 0.00233561694622\n",
      "Epoch 33::Minibatch 563::LR 0.0261538461538 --> Loss 0.00395952026049\n",
      "Epoch 33::Minibatch 564::LR 0.0261538461538 --> Loss 0.00303383628527\n",
      "Epoch 33::Minibatch 565::LR 0.0261538461538 --> Loss 0.00357003092766\n",
      "Epoch 33::Minibatch 566::LR 0.0261538461538 --> Loss 0.00216622630755\n",
      "Epoch 33::Minibatch 567::LR 0.0261538461538 --> Loss 0.00253806908925\n",
      "Epoch 33::Minibatch 568::LR 0.0261538461538 --> Loss 0.00172765771548\n",
      "Epoch 33::Minibatch 569::LR 0.0261538461538 --> Loss 0.000559647728999\n",
      "Epoch 33::Minibatch 570::LR 0.0261538461538 --> Loss 0.00161130229632\n",
      "Epoch 33::Minibatch 571::LR 0.0261538461538 --> Loss 0.00203501264254\n",
      "Epoch 33::Minibatch 572::LR 0.0261538461538 --> Loss 0.00219269573689\n",
      "Epoch 33::Minibatch 573::LR 0.0261538461538 --> Loss 0.00142794032892\n",
      "Epoch 33::Minibatch 574::LR 0.0261538461538 --> Loss 0.00104252636433\n",
      "Epoch 33::Minibatch 575::LR 0.0261538461538 --> Loss 0.00170589148998\n",
      "Epoch 33::Minibatch 576::LR 0.0261538461538 --> Loss 0.00201871216297\n",
      "Epoch 33::Minibatch 577::LR 0.0261538461538 --> Loss 0.00159823536873\n",
      "Epoch 33::Minibatch 578::LR 0.0261538461538 --> Loss 0.00125803848108\n",
      "Epoch 33::Minibatch 579::LR 0.0261538461538 --> Loss 0.00117825249831\n",
      "Epoch 33::Minibatch 580::LR 0.0261538461538 --> Loss 0.00191499590874\n",
      "Epoch 33::Minibatch 581::LR 0.0261538461538 --> Loss 0.00170149366061\n",
      "Epoch 33::Minibatch 582::LR 0.0261538461538 --> Loss 0.0041935356458\n",
      "Epoch 33::Minibatch 583::LR 0.0261538461538 --> Loss 0.000953286588192\n",
      "Epoch 33::Minibatch 584::LR 0.0261538461538 --> Loss 0.00130916893482\n",
      "Epoch 33::Minibatch 585::LR 0.0261538461538 --> Loss 0.0038938053449\n",
      "Epoch 33::Minibatch 586::LR 0.0261538461538 --> Loss 0.00370973944664\n",
      "Epoch 33::Minibatch 587::LR 0.0261538461538 --> Loss 0.00110992590586\n",
      "Epoch 33::Minibatch 588::LR 0.0261538461538 --> Loss 0.00136477609475\n",
      "Epoch 33::Minibatch 589::LR 0.0261538461538 --> Loss 0.0027235809962\n",
      "Epoch 33::Minibatch 590::LR 0.0261538461538 --> Loss 0.00178217271964\n",
      "Epoch 33::Minibatch 591::LR 0.0261538461538 --> Loss 0.00266449669997\n",
      "Epoch 33::Minibatch 592::LR 0.0261538461538 --> Loss 0.00114526321491\n",
      "Epoch 33::Minibatch 593::LR 0.0261538461538 --> Loss 0.00244653324286\n",
      "Epoch 33::Minibatch 594::LR 0.0261538461538 --> Loss 0.00253236571948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 595::LR 0.0261538461538 --> Loss 0.00303659995397\n",
      "Epoch 33::Minibatch 596::LR 0.0261538461538 --> Loss 0.00182594517867\n",
      "Epoch 33::Minibatch 597::LR 0.0261538461538 --> Loss 0.00116070787112\n",
      "Epoch 33::Minibatch 598::LR 0.0261538461538 --> Loss 0.00277910987536\n",
      "Epoch 33::Minibatch 599::LR 0.0261538461538 --> Loss 0.00178048710028\n",
      "Epoch 33::Minibatch 600::LR 0.0261538461538 --> Loss 0.00210964779059\n",
      "Epoch 33::Minibatch 601::LR 0.0261538461538 --> Loss 0.00370839397113\n",
      "Epoch 33::Minibatch 602::LR 0.0261538461538 --> Loss 0.00207681039969\n",
      "Epoch 33::Minibatch 603::LR 0.0261538461538 --> Loss 0.00261110802492\n",
      "Epoch 33::Minibatch 604::LR 0.0261538461538 --> Loss 0.00162160317103\n",
      "Epoch 33::Minibatch 605::LR 0.0261538461538 --> Loss 0.0022639699777\n",
      "Epoch 33::Minibatch 606::LR 0.0261538461538 --> Loss 0.00184035758177\n",
      "Epoch 33::Minibatch 607::LR 0.0261538461538 --> Loss 0.00082166860501\n",
      "Epoch 33::Minibatch 608::LR 0.0261538461538 --> Loss 0.00154411673546\n",
      "Epoch 33::Minibatch 609::LR 0.0261538461538 --> Loss 0.00241961618265\n",
      "Epoch 33::Minibatch 610::LR 0.0261538461538 --> Loss 0.0040416765213\n",
      "Epoch 33::Minibatch 611::LR 0.0261538461538 --> Loss 0.00267761031787\n",
      "Epoch 33::Minibatch 612::LR 0.0261538461538 --> Loss 0.000469239155451\n",
      "Epoch 33::Minibatch 613::LR 0.0261538461538 --> Loss 0.0013107479612\n",
      "Epoch 33::Minibatch 614::LR 0.0261538461538 --> Loss 0.00239508410295\n",
      "Epoch 33::Minibatch 615::LR 0.0261538461538 --> Loss 0.00164583007495\n",
      "Epoch 33::Minibatch 616::LR 0.0261538461538 --> Loss 0.000913435022036\n",
      "Epoch 33::Minibatch 617::LR 0.0261538461538 --> Loss 0.000490706364314\n",
      "Epoch 33::Minibatch 618::LR 0.0261538461538 --> Loss 0.00290492912134\n",
      "Epoch 33::Minibatch 619::LR 0.0261538461538 --> Loss 0.00192699491978\n",
      "Epoch 33::Minibatch 620::LR 0.0261538461538 --> Loss 0.00168274919192\n",
      "Epoch 33::Minibatch 621::LR 0.0261538461538 --> Loss 0.00084349433581\n",
      "Epoch 33::Minibatch 622::LR 0.0261538461538 --> Loss 0.000777823974689\n",
      "Epoch 33::Minibatch 623::LR 0.0261538461538 --> Loss 0.00221439202627\n",
      "Epoch 33::Minibatch 624::LR 0.0261538461538 --> Loss 0.00176268239816\n",
      "Epoch 33::Minibatch 625::LR 0.0261538461538 --> Loss 0.00263605713844\n",
      "Epoch 33::Minibatch 626::LR 0.0261538461538 --> Loss 0.00352844397227\n",
      "Epoch 33::Minibatch 627::LR 0.0261538461538 --> Loss 0.00126403659582\n",
      "Epoch 33::Minibatch 628::LR 0.0261538461538 --> Loss 0.000874905387561\n",
      "Epoch 33::Minibatch 629::LR 0.0261538461538 --> Loss 0.00303398529689\n",
      "Epoch 33::Minibatch 630::LR 0.0261538461538 --> Loss 0.00297222793102\n",
      "Epoch 33::Minibatch 631::LR 0.0261538461538 --> Loss 0.00505443851153\n",
      "Epoch 33::Minibatch 632::LR 0.0261538461538 --> Loss 0.000794307688872\n",
      "Epoch 33::Minibatch 633::LR 0.0261538461538 --> Loss 0.00160992731651\n",
      "Epoch 33::Minibatch 634::LR 0.0261538461538 --> Loss 0.00316895604134\n",
      "Epoch 33::Minibatch 635::LR 0.0261538461538 --> Loss 0.00538323283195\n",
      "Epoch 33::Minibatch 636::LR 0.0261538461538 --> Loss 0.00452918132146\n",
      "Epoch 33::Minibatch 637::LR 0.0261538461538 --> Loss 0.000707818617423\n",
      "Epoch 33::Minibatch 638::LR 0.0261538461538 --> Loss 0.00148444930712\n",
      "Epoch 33::Minibatch 639::LR 0.0261538461538 --> Loss 0.00316776712735\n",
      "Epoch 33::Minibatch 640::LR 0.0261538461538 --> Loss 0.00450237194697\n",
      "Epoch 33::Minibatch 641::LR 0.0261538461538 --> Loss 0.00302057921886\n",
      "Epoch 33::Minibatch 642::LR 0.0261538461538 --> Loss 0.000532135218382\n",
      "Epoch 33::Minibatch 643::LR 0.0261538461538 --> Loss 0.00230397125085\n",
      "Epoch 33::Minibatch 644::LR 0.0261538461538 --> Loss 0.00384714921316\n",
      "Epoch 33::Minibatch 645::LR 0.0261538461538 --> Loss 0.00448375026385\n",
      "Epoch 33::Minibatch 646::LR 0.0261538461538 --> Loss 0.00150719235341\n",
      "Epoch 33::Minibatch 647::LR 0.0261538461538 --> Loss 0.000462627261877\n",
      "Epoch 33::Minibatch 648::LR 0.0261538461538 --> Loss 0.00273151139418\n",
      "Epoch 33::Minibatch 649::LR 0.0261538461538 --> Loss 0.00316111207008\n",
      "Epoch 33::Minibatch 650::LR 0.0261538461538 --> Loss 0.00312788705031\n",
      "Epoch 33::Minibatch 651::LR 0.0261538461538 --> Loss 0.001320558091\n",
      "Epoch 33::Minibatch 652::LR 0.0261538461538 --> Loss 0.000776895831029\n",
      "Epoch 33::Minibatch 653::LR 0.0261538461538 --> Loss 0.00279060860475\n",
      "Epoch 33::Minibatch 654::LR 0.0261538461538 --> Loss 0.00311314423879\n",
      "Epoch 33::Minibatch 655::LR 0.0261538461538 --> Loss 0.00364474534988\n",
      "Epoch 33::Minibatch 656::LR 0.0261538461538 --> Loss 0.000755988856157\n",
      "Epoch 33::Minibatch 657::LR 0.0261538461538 --> Loss 0.00226449052493\n",
      "Epoch 33::Minibatch 658::LR 0.0261538461538 --> Loss 0.00445042689641\n",
      "Epoch 33::Minibatch 659::LR 0.0261538461538 --> Loss 0.00219995955626\n",
      "Epoch 33::Minibatch 660::LR 0.0261538461538 --> Loss 0.00264208892981\n",
      "Epoch 33::Minibatch 661::LR 0.0261538461538 --> Loss 0.00224650939306\n",
      "Epoch 33::Minibatch 662::LR 0.0261538461538 --> Loss 0.00179052472115\n",
      "Epoch 33::Minibatch 663::LR 0.0261538461538 --> Loss 0.00364526748657\n",
      "Epoch 33::Minibatch 664::LR 0.0261538461538 --> Loss 0.00311994989713\n",
      "Epoch 33::Minibatch 665::LR 0.0261538461538 --> Loss 0.000693687051535\n",
      "Epoch 33::Minibatch 666::LR 0.0261538461538 --> Loss 0.00390338778496\n",
      "Epoch 33::Minibatch 667::LR 0.0261538461538 --> Loss 0.00254138191541\n",
      "Epoch 33::Minibatch 668::LR 0.0261538461538 --> Loss 0.00625269412994\n",
      "Epoch 33::Minibatch 669::LR 0.0261538461538 --> Loss 0.00108077585697\n",
      "Epoch 33::Minibatch 670::LR 0.0261538461538 --> Loss 0.00132574518522\n",
      "Epoch 33::Minibatch 671::LR 0.0261538461538 --> Loss 0.00505423267682\n",
      "Epoch 33::Minibatch 672::LR 0.0261538461538 --> Loss 0.00335218946139\n",
      "Epoch 33::Minibatch 673::LR 0.0261538461538 --> Loss 0.00159898777803\n",
      "Epoch 33::Minibatch 674::LR 0.0261538461538 --> Loss 0.000509901891152\n",
      "Epoch 33::Minibatch 675::LR 0.0261538461538 --> Loss 0.00219735205173\n",
      "Epoch 33::Minibatch 676::LR 0.0261538461538 --> Loss 0.00216174940268\n",
      "Epoch 33::Minibatch 677::LR 0.0261538461538 --> Loss 0.00269316673279\n",
      "Epoch 33::Minibatch 678::LR 0.0261538461538 --> Loss 0.00185867190361\n",
      "Epoch 33::Minibatch 679::LR 0.0261538461538 --> Loss 0.00329570015272\n",
      "Epoch 33::Minibatch 680::LR 0.0261538461538 --> Loss 0.00211898465951\n",
      "Epoch 33::Minibatch 681::LR 0.0261538461538 --> Loss 0.00237340271473\n",
      "Epoch 33::Minibatch 682::LR 0.0261538461538 --> Loss 0.00076193138957\n",
      "Epoch 33::Minibatch 683::LR 0.0261538461538 --> Loss 0.00229398310184\n",
      "Epoch 33::Minibatch 684::LR 0.0261538461538 --> Loss 0.00233966171741\n",
      "Epoch 33::Minibatch 685::LR 0.0261538461538 --> Loss 0.00281023144722\n",
      "Epoch 33::Minibatch 686::LR 0.0261538461538 --> Loss 0.00158346643051\n",
      "Epoch 33::Minibatch 687::LR 0.0261538461538 --> Loss 0.000879066884518\n",
      "Epoch 33::Minibatch 688::LR 0.0261538461538 --> Loss 0.00280502438545\n",
      "Epoch 33::Minibatch 689::LR 0.0261538461538 --> Loss 0.00246191342672\n",
      "Epoch 33::Minibatch 690::LR 0.0261538461538 --> Loss 0.00187142630418\n",
      "Epoch 33::Minibatch 691::LR 0.0261538461538 --> Loss 0.000657624900341\n",
      "Epoch 33::Minibatch 692::LR 0.0261538461538 --> Loss 0.0024401930968\n",
      "Epoch 33::Minibatch 693::LR 0.0261538461538 --> Loss 0.00261851608753\n",
      "Epoch 33::Minibatch 694::LR 0.0261538461538 --> Loss 0.00298699001471\n",
      "Epoch 33::Minibatch 695::LR 0.0261538461538 --> Loss 0.00180098414421\n",
      "Epoch 33::Minibatch 696::LR 0.0261538461538 --> Loss 0.00202728629112\n",
      "Epoch 33::Minibatch 697::LR 0.0261538461538 --> Loss 0.00139835188786\n",
      "Epoch 33::Minibatch 698::LR 0.0261538461538 --> Loss 0.00166381170352\n",
      "Epoch 33::Minibatch 699::LR 0.0261538461538 --> Loss 0.00368718187014\n",
      "Epoch 33::Minibatch 700::LR 0.0261538461538 --> Loss 0.00256245195866\n",
      "Epoch 33::Minibatch 701::LR 0.0261538461538 --> Loss 0.00187756637732\n",
      "Epoch 33::Minibatch 702::LR 0.0261538461538 --> Loss 0.00166770776113\n",
      "Epoch 33::Minibatch 703::LR 0.0261538461538 --> Loss 0.00429294904073\n",
      "Epoch 33::Minibatch 704::LR 0.0261538461538 --> Loss 0.00180375814438\n",
      "Epoch 33::Minibatch 705::LR 0.0261538461538 --> Loss 0.00283091187477\n",
      "Epoch 33::Minibatch 706::LR 0.0261538461538 --> Loss 0.00219709714254\n",
      "Epoch 33::Minibatch 707::LR 0.0261538461538 --> Loss 0.00118011385202\n",
      "Epoch 33::Minibatch 708::LR 0.0261538461538 --> Loss 0.00173023641109\n",
      "Epoch 33::Minibatch 709::LR 0.0261538461538 --> Loss 0.00166868428389\n",
      "Epoch 33::Minibatch 710::LR 0.0261538461538 --> Loss 0.0025871082147\n",
      "Epoch 33::Minibatch 711::LR 0.0261538461538 --> Loss 0.001980676651\n",
      "Epoch 33::Minibatch 712::LR 0.0261538461538 --> Loss 0.00136610835791\n",
      "Epoch 33::Minibatch 713::LR 0.0261538461538 --> Loss 0.00179987728596\n",
      "Epoch 33::Minibatch 714::LR 0.0261538461538 --> Loss 0.0028720074892\n",
      "Epoch 33::Minibatch 715::LR 0.0261538461538 --> Loss 0.00292194922765\n",
      "Epoch 33::Minibatch 716::LR 0.0261538461538 --> Loss 0.00166755775611\n",
      "Epoch 33::Minibatch 717::LR 0.0261538461538 --> Loss 0.00167277912299\n",
      "Epoch 33::Minibatch 718::LR 0.0261538461538 --> Loss 0.00128304133813\n",
      "Epoch 33::Minibatch 719::LR 0.0261538461538 --> Loss 0.00173167188962\n",
      "Epoch 33::Minibatch 720::LR 0.0261538461538 --> Loss 0.00278084297975\n",
      "Epoch 33::Minibatch 721::LR 0.0261538461538 --> Loss 0.000604519943396\n",
      "Epoch 33::Minibatch 722::LR 0.0261538461538 --> Loss 0.0045755636692\n",
      "Epoch 33::Minibatch 723::LR 0.0261538461538 --> Loss 0.00480808456739\n",
      "Epoch 33::Minibatch 724::LR 0.0261538461538 --> Loss 0.000964585840702\n",
      "Epoch 33::Minibatch 725::LR 0.0261538461538 --> Loss 0.00204483131568\n",
      "Epoch 33::Minibatch 726::LR 0.0261538461538 --> Loss 0.00357578833898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 727::LR 0.0261538461538 --> Loss 0.00302572131157\n",
      "Epoch 33::Minibatch 728::LR 0.0261538461538 --> Loss 0.000641174167395\n",
      "Epoch 33::Minibatch 729::LR 0.0261538461538 --> Loss 0.00071565185984\n",
      "Epoch 33::Minibatch 730::LR 0.0261538461538 --> Loss 0.00290635287762\n",
      "Epoch 33::Minibatch 731::LR 0.0261538461538 --> Loss 0.00262320359548\n",
      "Epoch 33::Minibatch 732::LR 0.0261538461538 --> Loss 0.00202335019906\n",
      "Epoch 33::Minibatch 733::LR 0.0261538461538 --> Loss 0.000589532504479\n",
      "Epoch 33::Minibatch 734::LR 0.0261538461538 --> Loss 0.00163428048293\n",
      "Epoch 33::Minibatch 735::LR 0.0261538461538 --> Loss 0.00248916228612\n",
      "Epoch 33::Minibatch 736::LR 0.0261538461538 --> Loss 0.00347513198853\n",
      "Epoch 33::Minibatch 737::LR 0.0261538461538 --> Loss 0.00290522237619\n",
      "Epoch 33::Minibatch 738::LR 0.0261538461538 --> Loss 0.00137182017167\n",
      "Epoch 33::Minibatch 739::LR 0.0261538461538 --> Loss 0.00236453314622\n",
      "Epoch 33::Minibatch 740::LR 0.0261538461538 --> Loss 0.00375078996023\n",
      "Epoch 33::Minibatch 741::LR 0.0261538461538 --> Loss 0.002513859272\n",
      "Epoch 33::Minibatch 742::LR 0.0261538461538 --> Loss 0.00207004368305\n",
      "Epoch 33::Minibatch 743::LR 0.0261538461538 --> Loss 0.00151278734207\n",
      "Epoch 33::Minibatch 744::LR 0.0261538461538 --> Loss 0.00187954465548\n",
      "Epoch 33::Minibatch 745::LR 0.0261538461538 --> Loss 0.00276411135991\n",
      "Epoch 33::Minibatch 746::LR 0.0261538461538 --> Loss 0.00283318420251\n",
      "Epoch 33::Minibatch 747::LR 0.0261538461538 --> Loss 0.00175309101741\n",
      "Epoch 33::Minibatch 748::LR 0.0261538461538 --> Loss 0.000621372262637\n",
      "Epoch 33::Minibatch 749::LR 0.0261538461538 --> Loss 0.00167757749557\n",
      "Epoch 33::Minibatch 750::LR 0.0261538461538 --> Loss 0.00241258382797\n",
      "Epoch 33::Minibatch 751::LR 0.0261538461538 --> Loss 0.00293997883797\n",
      "Epoch 33::Minibatch 752::LR 0.0261538461538 --> Loss 0.00146223773559\n",
      "Epoch 33::Minibatch 753::LR 0.0261538461538 --> Loss 0.00219278454781\n",
      "Epoch 33::Minibatch 754::LR 0.0261538461538 --> Loss 0.00242003063361\n",
      "Epoch 33::Minibatch 755::LR 0.0261538461538 --> Loss 0.00265775819619\n",
      "Epoch 33::Minibatch 756::LR 0.0261538461538 --> Loss 0.00129851400852\n",
      "Epoch 33::Minibatch 757::LR 0.0261538461538 --> Loss 0.000587109724681\n",
      "Epoch 33::Minibatch 758::LR 0.0261538461538 --> Loss 0.0015607898434\n",
      "Epoch 33::Minibatch 759::LR 0.0261538461538 --> Loss 0.00337719082832\n",
      "Epoch 33::Minibatch 760::LR 0.0261538461538 --> Loss 0.00277769684792\n",
      "Epoch 33::Minibatch 761::LR 0.0261538461538 --> Loss 0.00553812384605\n",
      "Epoch 33::Minibatch 762::LR 0.0261538461538 --> Loss 0.00353277762731\n",
      "Epoch 33::Minibatch 763::LR 0.0261538461538 --> Loss 0.0034196416537\n",
      "Epoch 33::Minibatch 764::LR 0.0261538461538 --> Loss 0.00301033695539\n",
      "Epoch 33::Minibatch 765::LR 0.0261538461538 --> Loss 0.00124162425598\n",
      "Epoch 33::Minibatch 766::LR 0.0261538461538 --> Loss 0.00230076432228\n",
      "Epoch 33::Minibatch 767::LR 0.0261538461538 --> Loss 0.00476105690002\n",
      "Epoch 33::Minibatch 768::LR 0.0261538461538 --> Loss 0.00363485217094\n",
      "Epoch 33::Minibatch 769::LR 0.0261538461538 --> Loss 0.00182800849279\n",
      "Epoch 33::Minibatch 770::LR 0.0261538461538 --> Loss 0.00151170313358\n",
      "Epoch 33::Minibatch 771::LR 0.0261538461538 --> Loss 0.00338135004044\n",
      "Epoch 33::Minibatch 772::LR 0.0261538461538 --> Loss 0.00363553365072\n",
      "Epoch 33::Minibatch 773::LR 0.0261538461538 --> Loss 0.00319234391054\n",
      "Epoch 33::Minibatch 774::LR 0.0261538461538 --> Loss 0.00189456284046\n",
      "Epoch 33::Minibatch 775::LR 0.0261538461538 --> Loss 0.00325342237949\n",
      "Epoch 33::Minibatch 776::LR 0.0261538461538 --> Loss 0.00381762742996\n",
      "Epoch 33::Minibatch 777::LR 0.0261538461538 --> Loss 0.00600060383479\n",
      "Epoch 33::Minibatch 778::LR 0.0261538461538 --> Loss 0.00710326194763\n",
      "Epoch 33::Minibatch 779::LR 0.0261538461538 --> Loss 0.0024944070975\n",
      "Epoch 33::Minibatch 780::LR 0.0261538461538 --> Loss 0.0014983522892\n",
      "Epoch 33::Minibatch 781::LR 0.0261538461538 --> Loss 0.0034919989109\n",
      "Epoch 33::Minibatch 782::LR 0.0261538461538 --> Loss 0.00380757490794\n",
      "Epoch 33::Minibatch 783::LR 0.0261538461538 --> Loss 0.00226304550966\n",
      "Epoch 33::Minibatch 784::LR 0.0261538461538 --> Loss 0.000710020860036\n",
      "Epoch 33::Minibatch 785::LR 0.0261538461538 --> Loss 0.00337508877118\n",
      "Epoch 33::Minibatch 786::LR 0.0261538461538 --> Loss 0.0035557115078\n",
      "Epoch 33::Minibatch 787::LR 0.0261538461538 --> Loss 0.00256780246894\n",
      "Epoch 33::Minibatch 788::LR 0.0261538461538 --> Loss 0.00240433216095\n",
      "Epoch 33::Minibatch 789::LR 0.0261538461538 --> Loss 0.000724255045255\n",
      "Epoch 33::Minibatch 790::LR 0.0261538461538 --> Loss 0.00314358532429\n",
      "Epoch 33::Minibatch 791::LR 0.0261538461538 --> Loss 0.00325726588567\n",
      "Epoch 33::Minibatch 792::LR 0.0261538461538 --> Loss 0.00297967672348\n",
      "Epoch 33::Minibatch 793::LR 0.0261538461538 --> Loss 0.00163796156645\n",
      "Epoch 33::Minibatch 794::LR 0.0261538461538 --> Loss 0.000982077817122\n",
      "Epoch 33::Minibatch 795::LR 0.0261538461538 --> Loss 0.00263343254725\n",
      "Epoch 33::Minibatch 796::LR 0.0261538461538 --> Loss 0.0048016277949\n",
      "Epoch 33::Minibatch 797::LR 0.0261538461538 --> Loss 0.00568574945132\n",
      "Epoch 33::Minibatch 798::LR 0.0261538461538 --> Loss 0.00298117677371\n",
      "Epoch 33::Minibatch 799::LR 0.0261538461538 --> Loss 0.00224384963512\n",
      "Epoch 33::Minibatch 800::LR 0.0261538461538 --> Loss 0.00200094858805\n",
      "Epoch 33::Minibatch 801::LR 0.0261538461538 --> Loss 0.00384429216385\n",
      "Epoch 33::Minibatch 802::LR 0.0261538461538 --> Loss 0.00119900176922\n",
      "Epoch 33::Minibatch 803::LR 0.0261538461538 --> Loss 0.0029501114289\n",
      "Epoch 33::Minibatch 804::LR 0.0261538461538 --> Loss 0.00206962386767\n",
      "Epoch 33::Minibatch 805::LR 0.0261538461538 --> Loss 0.0021808530887\n",
      "Epoch 33::Minibatch 806::LR 0.0261538461538 --> Loss 0.00334950327873\n",
      "Epoch 33::Minibatch 807::LR 0.0261538461538 --> Loss 0.0030713091294\n",
      "Epoch 33::Minibatch 808::LR 0.0261538461538 --> Loss 0.00285327196121\n",
      "Epoch 33::Minibatch 809::LR 0.0261538461538 --> Loss 0.00304973642031\n",
      "Epoch 33::Minibatch 810::LR 0.0261538461538 --> Loss 0.00416992942492\n",
      "Epoch 33::Minibatch 811::LR 0.0261538461538 --> Loss 0.00400252302488\n",
      "Epoch 33::Minibatch 812::LR 0.0261538461538 --> Loss 0.00368167678515\n",
      "Epoch 33::Minibatch 813::LR 0.0261538461538 --> Loss 0.00305829505126\n",
      "Epoch 33::Minibatch 814::LR 0.0261538461538 --> Loss 0.00152129352093\n",
      "Epoch 33::Minibatch 815::LR 0.0261538461538 --> Loss 0.00348580598831\n",
      "Epoch 33::Minibatch 816::LR 0.0261538461538 --> Loss 0.0039315756162\n",
      "Epoch 33::Minibatch 817::LR 0.0261538461538 --> Loss 0.00477788011233\n",
      "Epoch 33::Minibatch 818::LR 0.0261538461538 --> Loss 0.00123694549004\n",
      "Epoch 33::Minibatch 819::LR 0.0261538461538 --> Loss 0.000723181664944\n",
      "Epoch 33::Minibatch 820::LR 0.0261538461538 --> Loss 0.00504953225454\n",
      "Epoch 33::Minibatch 821::LR 0.0261538461538 --> Loss 0.00305706858635\n",
      "Epoch 33::Minibatch 822::LR 0.0261538461538 --> Loss 0.00366093794505\n",
      "Epoch 33::Minibatch 823::LR 0.0261538461538 --> Loss 0.00125719040632\n",
      "Epoch 33::Minibatch 824::LR 0.0261538461538 --> Loss 0.00136359363794\n",
      "Epoch 33::Minibatch 825::LR 0.0261538461538 --> Loss 0.00372636795044\n",
      "Epoch 33::Minibatch 826::LR 0.0261538461538 --> Loss 0.0043881380558\n",
      "Epoch 33::Minibatch 827::LR 0.0261538461538 --> Loss 0.00205540080865\n",
      "Epoch 33::Minibatch 828::LR 0.0261538461538 --> Loss 0.000487303634485\n",
      "Epoch 33::Minibatch 829::LR 0.0261538461538 --> Loss 0.00226077477137\n",
      "Epoch 33::Minibatch 830::LR 0.0261538461538 --> Loss 0.00397801478704\n",
      "Epoch 33::Minibatch 831::LR 0.0261538461538 --> Loss 0.00237797498703\n",
      "Epoch 33::Minibatch 832::LR 0.0261538461538 --> Loss 0.00209547221661\n",
      "Epoch 33::Minibatch 833::LR 0.0261538461538 --> Loss 0.0018111795187\n",
      "Epoch 33::Minibatch 834::LR 0.0261538461538 --> Loss 0.000788239488999\n",
      "Epoch 33::Minibatch 835::LR 0.0261538461538 --> Loss 0.00378338893255\n",
      "Epoch 33::Minibatch 836::LR 0.0261538461538 --> Loss 0.00356637875239\n",
      "Epoch 33::Minibatch 837::LR 0.0261538461538 --> Loss 0.0022443562746\n",
      "Epoch 33::Minibatch 838::LR 0.0261538461538 --> Loss 0.000644685228666\n",
      "Epoch 33::Minibatch 839::LR 0.0261538461538 --> Loss 0.00237276653449\n",
      "Epoch 33::Minibatch 840::LR 0.0261538461538 --> Loss 0.00283664762974\n",
      "Epoch 33::Minibatch 841::LR 0.0261538461538 --> Loss 0.00274734199047\n",
      "Epoch 33::Minibatch 842::LR 0.0261538461538 --> Loss 0.00209611356258\n",
      "Epoch 33::Minibatch 843::LR 0.0261538461538 --> Loss 0.000972997546196\n",
      "Epoch 33::Minibatch 844::LR 0.0261538461538 --> Loss 0.00146426528692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 845::LR 0.0261538461538 --> Loss 0.00399903416634\n",
      "Epoch 33::Minibatch 846::LR 0.0261538461538 --> Loss 0.00166682561239\n",
      "Epoch 33::Minibatch 847::LR 0.0261538461538 --> Loss 0.00235466082891\n",
      "Epoch 33::Minibatch 848::LR 0.0261538461538 --> Loss 0.00111545523008\n",
      "Epoch 33::Minibatch 849::LR 0.0261538461538 --> Loss 0.0017830346028\n",
      "Epoch 33::Minibatch 850::LR 0.0261538461538 --> Loss 0.00314616044362\n",
      "Epoch 33::Minibatch 851::LR 0.0261538461538 --> Loss 0.0025342053175\n",
      "Epoch 33::Minibatch 852::LR 0.0261538461538 --> Loss 0.00112839907408\n",
      "Epoch 33::Minibatch 853::LR 0.0261538461538 --> Loss 0.00130310465892\n",
      "Epoch 33::Minibatch 854::LR 0.0261538461538 --> Loss 0.00252266387145\n",
      "Epoch 33::Minibatch 855::LR 0.0261538461538 --> Loss 0.00210464318593\n",
      "Epoch 33::Minibatch 856::LR 0.0261538461538 --> Loss 0.0017762162288\n",
      "Epoch 33::Minibatch 857::LR 0.0261538461538 --> Loss 0.00120636761189\n",
      "Epoch 33::Minibatch 858::LR 0.0261538461538 --> Loss 0.000599650790294\n",
      "Epoch 33::Minibatch 859::LR 0.0261538461538 --> Loss 0.00197355985641\n",
      "Epoch 33::Minibatch 860::LR 0.0261538461538 --> Loss 0.00129742145538\n",
      "Epoch 33::Minibatch 861::LR 0.0261538461538 --> Loss 0.000944882829984\n",
      "Epoch 33::Minibatch 862::LR 0.0261538461538 --> Loss 0.00370824654897\n",
      "Epoch 33::Minibatch 863::LR 0.0261538461538 --> Loss 0.00335697849592\n",
      "Epoch 33::Minibatch 864::LR 0.0261538461538 --> Loss 0.00259886801243\n",
      "Epoch 33::Minibatch 865::LR 0.0261538461538 --> Loss 0.000508341143529\n",
      "Epoch 33::Minibatch 866::LR 0.0261538461538 --> Loss 0.00207328816255\n",
      "Epoch 33::Minibatch 867::LR 0.0261538461538 --> Loss 0.00286603430907\n",
      "Epoch 33::Minibatch 868::LR 0.0261538461538 --> Loss 0.00241837263107\n",
      "Epoch 33::Minibatch 869::LR 0.0261538461538 --> Loss 0.00213070650895\n",
      "Epoch 33::Minibatch 870::LR 0.0261538461538 --> Loss 0.00324269334475\n",
      "Epoch 33::Minibatch 871::LR 0.0261538461538 --> Loss 0.00161767313878\n",
      "Epoch 33::Minibatch 872::LR 0.0261538461538 --> Loss 0.00211490412553\n",
      "Epoch 33::Minibatch 873::LR 0.0261538461538 --> Loss 0.00245132605235\n",
      "Epoch 33::Minibatch 874::LR 0.0261538461538 --> Loss 0.00513807257016\n",
      "Epoch 33::Minibatch 875::LR 0.0261538461538 --> Loss 0.000625018924475\n",
      "Epoch 33::Minibatch 876::LR 0.0261538461538 --> Loss 0.00272646745046\n",
      "Epoch 33::Minibatch 877::LR 0.0261538461538 --> Loss 0.00455431818962\n",
      "Epoch 33::Minibatch 878::LR 0.0261538461538 --> Loss 0.00293790698051\n",
      "Epoch 33::Minibatch 879::LR 0.0261538461538 --> Loss 0.00389821171761\n",
      "Epoch 33::Minibatch 880::LR 0.0261538461538 --> Loss 0.00485754688581\n",
      "Epoch 33::Minibatch 881::LR 0.0261538461538 --> Loss 0.00419595559438\n",
      "Epoch 33::Minibatch 882::LR 0.0261538461538 --> Loss 0.0019052930673\n",
      "Epoch 33::Minibatch 883::LR 0.0261538461538 --> Loss 0.00361169934273\n",
      "Epoch 33::Minibatch 884::LR 0.0261538461538 --> Loss 0.00278986950715\n",
      "Epoch 33::Minibatch 885::LR 0.0261538461538 --> Loss 0.00258320530256\n",
      "Epoch 33::Minibatch 886::LR 0.0261538461538 --> Loss 0.000436401466529\n",
      "Epoch 33::Minibatch 887::LR 0.0261538461538 --> Loss 0.005485060215\n",
      "Epoch 33::Minibatch 888::LR 0.0261538461538 --> Loss 0.00243994116783\n",
      "Epoch 33::Minibatch 889::LR 0.0261538461538 --> Loss 0.00250086744626\n",
      "Epoch 33::Minibatch 890::LR 0.0261538461538 --> Loss 0.00360639373461\n",
      "Epoch 33::Minibatch 891::LR 0.0261538461538 --> Loss 0.00171104252338\n",
      "Epoch 33::Minibatch 892::LR 0.0261538461538 --> Loss 0.000789612432321\n",
      "Epoch 33::Minibatch 893::LR 0.0261538461538 --> Loss 0.00225187937419\n",
      "Epoch 33::Minibatch 894::LR 0.0261538461538 --> Loss 0.00197735408942\n",
      "Epoch 33::Minibatch 895::LR 0.0261538461538 --> Loss 0.00226427475611\n",
      "Epoch 33::Minibatch 896::LR 0.0261538461538 --> Loss 0.0012452746431\n",
      "Epoch 33::Minibatch 897::LR 0.0261538461538 --> Loss 0.000668758402268\n",
      "Epoch 33::Minibatch 898::LR 0.0261538461538 --> Loss 0.00197083334128\n",
      "Epoch 33::Minibatch 899::LR 0.0261538461538 --> Loss 0.00244549592336\n",
      "Epoch 33::Minibatch 900::LR 0.0261538461538 --> Loss 0.00304777701696\n",
      "Epoch 33::Minibatch 901::LR 0.0261538461538 --> Loss 0.000583059986432\n",
      "Epoch 33::Minibatch 902::LR 0.0261538461538 --> Loss 0.00139072994391\n",
      "Epoch 33::Minibatch 903::LR 0.0261538461538 --> Loss 0.00253395279249\n",
      "Epoch 33::Minibatch 904::LR 0.0261538461538 --> Loss 0.00179713348548\n",
      "Epoch 33::Minibatch 905::LR 0.0261538461538 --> Loss 0.00139205018679\n",
      "Epoch 33::Minibatch 906::LR 0.0261538461538 --> Loss 0.00102062374353\n",
      "Epoch 33::Minibatch 907::LR 0.0261538461538 --> Loss 0.00154248277346\n",
      "Epoch 33::Minibatch 908::LR 0.0261538461538 --> Loss 0.00206394135952\n",
      "Epoch 33::Minibatch 909::LR 0.0261538461538 --> Loss 0.00192482332389\n",
      "Epoch 33::Minibatch 910::LR 0.0261538461538 --> Loss 0.000839712719123\n",
      "Epoch 33::Minibatch 911::LR 0.0261538461538 --> Loss 0.00126894434293\n",
      "Epoch 33::Minibatch 912::LR 0.0261538461538 --> Loss 0.002049741745\n",
      "Epoch 33::Minibatch 913::LR 0.0261538461538 --> Loss 0.00226808011532\n",
      "Epoch 33::Minibatch 914::LR 0.0261538461538 --> Loss 0.00124014834563\n",
      "Epoch 33::Minibatch 915::LR 0.0261538461538 --> Loss 0.000529007017612\n",
      "Epoch 33::Minibatch 916::LR 0.0261538461538 --> Loss 0.00202579001586\n",
      "Epoch 33::Minibatch 917::LR 0.0261538461538 --> Loss 0.00323518355687\n",
      "Epoch 33::Minibatch 918::LR 0.0261538461538 --> Loss 0.00478584329287\n",
      "Epoch 33::Minibatch 919::LR 0.0261538461538 --> Loss 0.000539490183194\n",
      "Epoch 33::Minibatch 920::LR 0.0261538461538 --> Loss 0.0122417982419\n",
      "Epoch 33::Minibatch 921::LR 0.0261538461538 --> Loss 0.00297729849815\n",
      "Epoch 33::Minibatch 922::LR 0.0261538461538 --> Loss 0.00297946770986\n",
      "Epoch 33::Minibatch 923::LR 0.0261538461538 --> Loss 0.00115878800551\n",
      "Epoch 33::Minibatch 924::LR 0.0261538461538 --> Loss 0.0031437544028\n",
      "Epoch 33::Minibatch 925::LR 0.0261538461538 --> Loss 0.00219555894534\n",
      "Epoch 33::Minibatch 926::LR 0.0261538461538 --> Loss 0.00457027713458\n",
      "Epoch 33::Minibatch 927::LR 0.0261538461538 --> Loss 0.00512012481689\n",
      "Epoch 33::Minibatch 928::LR 0.0261538461538 --> Loss 0.00591106891632\n",
      "Epoch 33::Minibatch 929::LR 0.0261538461538 --> Loss 0.00524703303973\n",
      "Epoch 33::Minibatch 930::LR 0.0261538461538 --> Loss 0.0091622598966\n",
      "Epoch 33::Minibatch 931::LR 0.0261538461538 --> Loss 0.00300207058589\n",
      "Epoch 33::Minibatch 932::LR 0.0261538461538 --> Loss 0.00520795543989\n",
      "Epoch 33::Minibatch 933::LR 0.0261538461538 --> Loss 0.00236799617608\n",
      "Epoch 33::Minibatch 934::LR 0.0261538461538 --> Loss 0.00301734685898\n",
      "Epoch 33::Minibatch 935::LR 0.0261538461538 --> Loss 0.00451361060143\n",
      "Epoch 33::Minibatch 936::LR 0.0261538461538 --> Loss 0.00088044722875\n",
      "Epoch 33::Minibatch 937::LR 0.0261538461538 --> Loss 0.00236216008663\n",
      "Epoch 33::Minibatch 938::LR 0.0261538461538 --> Loss 0.00201034903526\n",
      "Epoch 33::Minibatch 939::LR 0.0261538461538 --> Loss 0.00219470004241\n",
      "Epoch 33::Minibatch 940::LR 0.0261538461538 --> Loss 0.000918888449669\n",
      "Epoch 33::Minibatch 941::LR 0.0261538461538 --> Loss 0.000745977014303\n",
      "Epoch 33::Minibatch 942::LR 0.0261538461538 --> Loss 0.00251182198524\n",
      "Epoch 33::Minibatch 943::LR 0.0261538461538 --> Loss 0.00232683022817\n",
      "Epoch 33::Minibatch 944::LR 0.0261538461538 --> Loss 0.00167382359505\n",
      "Epoch 33::Minibatch 945::LR 0.0261538461538 --> Loss 0.000933204491933\n",
      "Epoch 33::Minibatch 946::LR 0.0261538461538 --> Loss 0.00239126423995\n",
      "Epoch 33::Minibatch 947::LR 0.0261538461538 --> Loss 0.00222157597542\n",
      "Epoch 33::Minibatch 948::LR 0.0261538461538 --> Loss 0.00400573015213\n",
      "Epoch 33::Minibatch 949::LR 0.0261538461538 --> Loss 0.00170634190241\n",
      "Epoch 33::Minibatch 950::LR 0.0261538461538 --> Loss 0.00069187199076\n",
      "Epoch 33::Minibatch 951::LR 0.0261538461538 --> Loss 0.00334541360537\n",
      "Epoch 33::Minibatch 952::LR 0.0261538461538 --> Loss 0.0023321167628\n",
      "Epoch 33::Minibatch 953::LR 0.0261538461538 --> Loss 0.00141165465117\n",
      "Epoch 33::Minibatch 954::LR 0.0261538461538 --> Loss 0.000933582683404\n",
      "Epoch 33::Minibatch 955::LR 0.0261538461538 --> Loss 0.00254856646061\n",
      "Epoch 33::Minibatch 956::LR 0.0261538461538 --> Loss 0.00307904402415\n",
      "Epoch 33::Minibatch 957::LR 0.0261538461538 --> Loss 0.00182267407576\n",
      "Epoch 33::Minibatch 958::LR 0.0261538461538 --> Loss 0.00217962960402\n",
      "Epoch 33::Minibatch 959::LR 0.0261538461538 --> Loss 0.00251848995686\n",
      "Epoch 33::Minibatch 960::LR 0.0261538461538 --> Loss 0.00533499876658\n",
      "Epoch 33::Minibatch 961::LR 0.0261538461538 --> Loss 0.00295866727829\n",
      "Epoch 33::Minibatch 962::LR 0.0261538461538 --> Loss 0.00233541329702\n",
      "Epoch 33::Minibatch 963::LR 0.0261538461538 --> Loss 0.00103989988565\n",
      "Epoch 33::Minibatch 964::LR 0.0261538461538 --> Loss 0.00232370018959\n",
      "Epoch 33::Minibatch 965::LR 0.0261538461538 --> Loss 0.00624957680702\n",
      "Epoch 33::Minibatch 966::LR 0.0261538461538 --> Loss 0.00484113295873\n",
      "Epoch 33::Minibatch 967::LR 0.0261538461538 --> Loss 0.0012497924765\n",
      "Epoch 33::Minibatch 968::LR 0.0261538461538 --> Loss 0.001019196709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33::Minibatch 969::LR 0.0261538461538 --> Loss 0.00452646772067\n",
      "Epoch 33::Minibatch 970::LR 0.0261538461538 --> Loss 0.00436284303665\n",
      "Epoch 33::Minibatch 971::LR 0.0261538461538 --> Loss 0.00328538636367\n",
      "Epoch 33::Minibatch 972::LR 0.0261538461538 --> Loss 0.00789074341456\n",
      "Epoch 33::Minibatch 973::LR 0.0261538461538 --> Loss 0.00933279593786\n",
      "Epoch 33::Minibatch 974::LR 0.0261538461538 --> Loss 0.0081063858668\n",
      "Epoch 33::Minibatch 975::LR 0.0261538461538 --> Loss 0.00461959004402\n",
      "Epoch 33::Minibatch 976::LR 0.0261538461538 --> Loss 0.003592167298\n",
      "Epoch 33::Minibatch 977::LR 0.0261538461538 --> Loss 0.00329033533732\n",
      "Epoch 33::Minibatch 978::LR 0.0261538461538 --> Loss 0.00320433994134\n",
      "Epoch 33::Minibatch 979::LR 0.0261538461538 --> Loss 0.0029514837265\n",
      "Epoch 33::Minibatch 980::LR 0.0261538461538 --> Loss 0.00336432337761\n",
      "Epoch 33::Minibatch 981::LR 0.0261538461538 --> Loss 0.00414403239886\n",
      "Epoch 33::Minibatch 982::LR 0.0261538461538 --> Loss 0.0041076529026\n",
      "Epoch 33::Minibatch 983::LR 0.0261538461538 --> Loss 0.00244359294573\n",
      "Epoch 33::Minibatch 984::LR 0.0261538461538 --> Loss 0.00167773663998\n",
      "Epoch 33::Minibatch 985::LR 0.0261538461538 --> Loss 0.00318697869778\n",
      "Epoch 33::Minibatch 986::LR 0.0261538461538 --> Loss 0.00288430094719\n",
      "Epoch 33::Minibatch 987::LR 0.0261538461538 --> Loss 0.00321703473727\n",
      "Epoch 33::Minibatch 988::LR 0.0261538461538 --> Loss 0.00254202286402\n",
      "Epoch 33::Minibatch 989::LR 0.0261538461538 --> Loss 0.00284894724687\n",
      "Epoch 33::Minibatch 990::LR 0.0261538461538 --> Loss 0.00268940230211\n",
      "Epoch 33::Minibatch 991::LR 0.0261538461538 --> Loss 0.00133227517207\n",
      "Epoch 33::Minibatch 992::LR 0.0261538461538 --> Loss 0.00158384392659\n",
      "Epoch 33::Minibatch 993::LR 0.0261538461538 --> Loss 0.00292744994164\n",
      "Epoch 33::Minibatch 994::LR 0.0261538461538 --> Loss 0.00193868637085\n",
      "Epoch 33::Minibatch 995::LR 0.0261538461538 --> Loss 0.000781494677067\n",
      "Epoch 33::Minibatch 996::LR 0.0261538461538 --> Loss 0.00261870781581\n",
      "Epoch 33::Minibatch 997::LR 0.0261538461538 --> Loss 0.00217232247194\n",
      "Epoch 33::Minibatch 998::LR 0.0261538461538 --> Loss 0.00247217079004\n",
      "Epoch 33::Minibatch 999::LR 0.0261538461538 --> Loss 0.00211526493231\n",
      "Epoch 33::Minibatch 1000::LR 0.0261538461538 --> Loss 0.00256649076939\n",
      "Epoch 33::Minibatch 1001::LR 0.0261538461538 --> Loss 0.00203076442083\n",
      "Epoch 33::Minibatch 1002::LR 0.0261538461538 --> Loss 0.00149356027444\n",
      "Epoch 33::Minibatch 1003::LR 0.0261538461538 --> Loss 0.00245263238748\n",
      "Epoch 33::Minibatch 1004::LR 0.0261538461538 --> Loss 0.00106408576171\n",
      "Epoch 33::Minibatch 1005::LR 0.0261538461538 --> Loss 0.00253928979238\n",
      "Epoch 33::Minibatch 1006::LR 0.0261538461538 --> Loss 0.00131594628096\n",
      "Epoch 33::Minibatch 1007::LR 0.0261538461538 --> Loss 0.00174065649509\n",
      "Epoch 33::Minibatch 1008::LR 0.0261538461538 --> Loss 0.000918610095978\n",
      "Epoch 33::Minibatch 1009::LR 0.0261538461538 --> Loss 0.00121987680594\n",
      "Epoch 33::Minibatch 1010::LR 0.0261538461538 --> Loss 0.00114942739407\n",
      "Epoch 33::Minibatch 1011::LR 0.0261538461538 --> Loss 0.00159387360017\n",
      "Epoch 33::Minibatch 1012::LR 0.0261538461538 --> Loss 0.00138374209404\n",
      "Epoch 33::Minibatch 1013::LR 0.0261538461538 --> Loss 0.00343511104584\n",
      "Epoch 33::Minibatch 1014::LR 0.0261538461538 --> Loss 0.00319400290648\n",
      "Epoch 33::Minibatch 1015::LR 0.0261538461538 --> Loss 0.00152040868998\n",
      "Epoch 33::Minibatch 1016::LR 0.0261538461538 --> Loss 0.00443105538686\n",
      "Epoch 33::Minibatch 1017::LR 0.0261538461538 --> Loss 0.00312843183676\n",
      "Epoch 33::Minibatch 1018::LR 0.0261538461538 --> Loss 0.00246911803881\n",
      "Epoch 33::Minibatch 1019::LR 0.0261538461538 --> Loss 0.0015432592233\n",
      "Epoch 33::Minibatch 1020::LR 0.0261538461538 --> Loss 0.00167478422324\n",
      "Epoch 33::Minibatch 1021::LR 0.0261538461538 --> Loss 0.00180502812068\n",
      "Epoch 33::Minibatch 1022::LR 0.0261538461538 --> Loss 0.00132044941187\n",
      "Epoch 33::Minibatch 1023::LR 0.0261538461538 --> Loss 0.000990611612797\n",
      "Epoch 33::Minibatch 1024::LR 0.0261538461538 --> Loss 0.000991630752881\n",
      "Epoch 33::Minibatch 1025::LR 0.0261538461538 --> Loss 0.00135774155458\n",
      "Epoch 33::Minibatch 1026::LR 0.0261538461538 --> Loss 0.000691387057304\n",
      "Epoch 33::Minibatch 1027::LR 0.0261538461538 --> Loss 0.000968798796336\n",
      "Epoch 33::Minibatch 1028::LR 0.0261538461538 --> Loss 0.000719687640667\n",
      "Epoch 33::Minibatch 1029::LR 0.0261538461538 --> Loss 0.000740352769693\n",
      "Epoch 33::Minibatch 1030::LR 0.0261538461538 --> Loss 0.000899148086707\n",
      "Epoch 33::Minibatch 1031::LR 0.0261538461538 --> Loss 0.000684791902701\n",
      "Epoch 33::Minibatch 1032::LR 0.0261538461538 --> Loss 0.000772872318824\n",
      "Epoch 33::Minibatch 1033::LR 0.0261538461538 --> Loss 0.000658077448606\n",
      "Epoch 33::Minibatch 1034::LR 0.0261538461538 --> Loss 0.000624481042226\n",
      "Epoch 33::Minibatch 1035::LR 0.0261538461538 --> Loss 0.000408008297284\n",
      "Epoch 33::Minibatch 1036::LR 0.0261538461538 --> Loss 0.00032555423677\n",
      "Epoch 33::Minibatch 1037::LR 0.0261538461538 --> Loss 0.000608973801136\n",
      "Epoch 33::Minibatch 1038::LR 0.0261538461538 --> Loss 0.00104411641757\n",
      "Epoch 33::Minibatch 1039::LR 0.0261538461538 --> Loss 0.000867163340251\n",
      "Epoch 33::Minibatch 1040::LR 0.0261538461538 --> Loss 0.00033953992029\n",
      "Epoch 33::Minibatch 1041::LR 0.0261538461538 --> Loss 0.000487492581209\n",
      "Epoch 34::Minibatch 1::LR 0.0238461538462 --> Loss 0.00743304491043\n",
      "Epoch 34::Minibatch 2::LR 0.0238461538462 --> Loss 0.00465046922366\n",
      "Epoch 34::Minibatch 3::LR 0.0238461538462 --> Loss 0.00291906674703\n",
      "Epoch 34::Minibatch 4::LR 0.0238461538462 --> Loss 0.00373658895493\n",
      "Epoch 34::Minibatch 5::LR 0.0238461538462 --> Loss 0.00432831168175\n",
      "Epoch 34::Minibatch 6::LR 0.0238461538462 --> Loss 0.00203148365021\n",
      "Epoch 34::Minibatch 7::LR 0.0238461538462 --> Loss 0.0070196668307\n",
      "Epoch 34::Minibatch 8::LR 0.0238461538462 --> Loss 0.00652448415756\n",
      "Epoch 34::Minibatch 9::LR 0.0238461538462 --> Loss 0.0050968448321\n",
      "Epoch 34::Minibatch 10::LR 0.0238461538462 --> Loss 0.00230159461498\n",
      "Epoch 34::Minibatch 11::LR 0.0238461538462 --> Loss 0.00216830174128\n",
      "Epoch 34::Minibatch 12::LR 0.0238461538462 --> Loss 0.00332150538762\n",
      "Epoch 34::Minibatch 13::LR 0.0238461538462 --> Loss 0.00529055595398\n",
      "Epoch 34::Minibatch 14::LR 0.0238461538462 --> Loss 0.00526805202166\n",
      "Epoch 34::Minibatch 15::LR 0.0238461538462 --> Loss 0.00455995639165\n",
      "Epoch 34::Minibatch 16::LR 0.0238461538462 --> Loss 0.000702932476997\n",
      "Epoch 34::Minibatch 17::LR 0.0238461538462 --> Loss 0.00320727129777\n",
      "Epoch 34::Minibatch 18::LR 0.0238461538462 --> Loss 0.00267725348473\n",
      "Epoch 34::Minibatch 19::LR 0.0238461538462 --> Loss 0.0016356002291\n",
      "Epoch 34::Minibatch 20::LR 0.0238461538462 --> Loss 0.00217377543449\n",
      "Epoch 34::Minibatch 21::LR 0.0238461538462 --> Loss 0.00342129468918\n",
      "Epoch 34::Minibatch 22::LR 0.0238461538462 --> Loss 0.00223042408625\n",
      "Epoch 34::Minibatch 23::LR 0.0238461538462 --> Loss 0.000944493909677\n",
      "Epoch 34::Minibatch 24::LR 0.0238461538462 --> Loss 0.000530707786481\n",
      "Epoch 34::Minibatch 25::LR 0.0238461538462 --> Loss 0.00140006323655\n",
      "Epoch 34::Minibatch 26::LR 0.0238461538462 --> Loss 0.00159398933252\n",
      "Epoch 34::Minibatch 27::LR 0.0238461538462 --> Loss 0.0012180313468\n",
      "Epoch 34::Minibatch 28::LR 0.0238461538462 --> Loss 0.000534323453903\n",
      "Epoch 34::Minibatch 29::LR 0.0238461538462 --> Loss 0.000662508805593\n",
      "Epoch 34::Minibatch 30::LR 0.0238461538462 --> Loss 0.00117698738972\n",
      "Epoch 34::Minibatch 31::LR 0.0238461538462 --> Loss 0.00165194998185\n",
      "Epoch 34::Minibatch 32::LR 0.0238461538462 --> Loss 0.00145088950793\n",
      "Epoch 34::Minibatch 33::LR 0.0238461538462 --> Loss 0.000828871428967\n",
      "Epoch 34::Minibatch 34::LR 0.0238461538462 --> Loss 0.00202632586161\n",
      "Epoch 34::Minibatch 35::LR 0.0238461538462 --> Loss 0.00276307344437\n",
      "Epoch 34::Minibatch 36::LR 0.0238461538462 --> Loss 0.00224757591883\n",
      "Epoch 34::Minibatch 37::LR 0.0238461538462 --> Loss 0.000742734869321\n",
      "Epoch 34::Minibatch 38::LR 0.0238461538462 --> Loss 0.000756988724073\n",
      "Epoch 34::Minibatch 39::LR 0.0238461538462 --> Loss 0.00210311055183\n",
      "Epoch 34::Minibatch 40::LR 0.0238461538462 --> Loss 0.00306110858917\n",
      "Epoch 34::Minibatch 41::LR 0.0238461538462 --> Loss 0.00242360273997\n",
      "Epoch 34::Minibatch 42::LR 0.0238461538462 --> Loss 0.00421315630277\n",
      "Epoch 34::Minibatch 43::LR 0.0238461538462 --> Loss 0.0020459185044\n",
      "Epoch 34::Minibatch 44::LR 0.0238461538462 --> Loss 0.00341511527697\n",
      "Epoch 34::Minibatch 45::LR 0.0238461538462 --> Loss 0.00243567923705\n",
      "Epoch 34::Minibatch 46::LR 0.0238461538462 --> Loss 0.00299982865651\n",
      "Epoch 34::Minibatch 47::LR 0.0238461538462 --> Loss 0.00313709894816\n",
      "Epoch 34::Minibatch 48::LR 0.0238461538462 --> Loss 0.00459471305211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 49::LR 0.0238461538462 --> Loss 0.0052539451917\n",
      "Epoch 34::Minibatch 50::LR 0.0238461538462 --> Loss 0.00590280413628\n",
      "Epoch 34::Minibatch 51::LR 0.0238461538462 --> Loss 0.00403012275696\n",
      "Epoch 34::Minibatch 52::LR 0.0238461538462 --> Loss 0.00337887446086\n",
      "Epoch 34::Minibatch 53::LR 0.0238461538462 --> Loss 0.00336791714032\n",
      "Epoch 34::Minibatch 54::LR 0.0238461538462 --> Loss 0.00396573583285\n",
      "Epoch 34::Minibatch 55::LR 0.0238461538462 --> Loss 0.00099650700887\n",
      "Epoch 34::Minibatch 56::LR 0.0238461538462 --> Loss 0.00275628288587\n",
      "Epoch 34::Minibatch 57::LR 0.0238461538462 --> Loss 0.00445418477058\n",
      "Epoch 34::Minibatch 58::LR 0.0238461538462 --> Loss 0.00317724327246\n",
      "Epoch 34::Minibatch 59::LR 0.0238461538462 --> Loss 0.00244031389554\n",
      "Epoch 34::Minibatch 60::LR 0.0238461538462 --> Loss 0.00250951031844\n",
      "Epoch 34::Minibatch 61::LR 0.0238461538462 --> Loss 0.000703731675943\n",
      "Epoch 34::Minibatch 62::LR 0.0238461538462 --> Loss 0.00244374374549\n",
      "Epoch 34::Minibatch 63::LR 0.0238461538462 --> Loss 0.00205152630806\n",
      "Epoch 34::Minibatch 64::LR 0.0238461538462 --> Loss 0.000810738454262\n",
      "Epoch 34::Minibatch 65::LR 0.0238461538462 --> Loss 0.00210731824239\n",
      "Epoch 34::Minibatch 66::LR 0.0238461538462 --> Loss 0.00280192097028\n",
      "Epoch 34::Minibatch 67::LR 0.0238461538462 --> Loss 0.00245347599188\n",
      "Epoch 34::Minibatch 68::LR 0.0238461538462 --> Loss 0.00180895765622\n",
      "Epoch 34::Minibatch 69::LR 0.0238461538462 --> Loss 0.00354601979256\n",
      "Epoch 34::Minibatch 70::LR 0.0238461538462 --> Loss 0.00316960295041\n",
      "Epoch 34::Minibatch 71::LR 0.0238461538462 --> Loss 0.00222037116687\n",
      "Epoch 34::Minibatch 72::LR 0.0238461538462 --> Loss 0.000548762977123\n",
      "Epoch 34::Minibatch 73::LR 0.0238461538462 --> Loss 0.00362658977509\n",
      "Epoch 34::Minibatch 74::LR 0.0238461538462 --> Loss 0.00394034226735\n",
      "Epoch 34::Minibatch 75::LR 0.0238461538462 --> Loss 0.00200529535611\n",
      "Epoch 34::Minibatch 76::LR 0.0238461538462 --> Loss 0.000516941994429\n",
      "Epoch 34::Minibatch 77::LR 0.0238461538462 --> Loss 0.00323973377546\n",
      "Epoch 34::Minibatch 78::LR 0.0238461538462 --> Loss 0.00398905396461\n",
      "Epoch 34::Minibatch 79::LR 0.0238461538462 --> Loss 0.0016556079189\n",
      "Epoch 34::Minibatch 80::LR 0.0238461538462 --> Loss 0.00274440844854\n",
      "Epoch 34::Minibatch 81::LR 0.0238461538462 --> Loss 0.00246038715045\n",
      "Epoch 34::Minibatch 82::LR 0.0238461538462 --> Loss 0.0017839495341\n",
      "Epoch 34::Minibatch 83::LR 0.0238461538462 --> Loss 0.00372893373171\n",
      "Epoch 34::Minibatch 84::LR 0.0238461538462 --> Loss 0.00181709090869\n",
      "Epoch 34::Minibatch 85::LR 0.0238461538462 --> Loss 0.00245767116547\n",
      "Epoch 34::Minibatch 86::LR 0.0238461538462 --> Loss 0.00205642819405\n",
      "Epoch 34::Minibatch 87::LR 0.0238461538462 --> Loss 0.00215368469556\n",
      "Epoch 34::Minibatch 88::LR 0.0238461538462 --> Loss 0.0016355329752\n",
      "Epoch 34::Minibatch 89::LR 0.0238461538462 --> Loss 0.00215790530046\n",
      "Epoch 34::Minibatch 90::LR 0.0238461538462 --> Loss 0.00104176570972\n",
      "Epoch 34::Minibatch 91::LR 0.0238461538462 --> Loss 0.000875532925129\n",
      "Epoch 34::Minibatch 92::LR 0.0238461538462 --> Loss 0.00251322070758\n",
      "Epoch 34::Minibatch 93::LR 0.0238461538462 --> Loss 0.0016761002938\n",
      "Epoch 34::Minibatch 94::LR 0.0238461538462 --> Loss 0.00173273424308\n",
      "Epoch 34::Minibatch 95::LR 0.0238461538462 --> Loss 0.00191472351551\n",
      "Epoch 34::Minibatch 96::LR 0.0238461538462 --> Loss 0.00451404849688\n",
      "Epoch 34::Minibatch 97::LR 0.0238461538462 --> Loss 0.00299407283465\n",
      "Epoch 34::Minibatch 98::LR 0.0238461538462 --> Loss 0.00110090861718\n",
      "Epoch 34::Minibatch 99::LR 0.0238461538462 --> Loss 0.00142915834983\n",
      "Epoch 34::Minibatch 100::LR 0.0238461538462 --> Loss 0.00402004202207\n",
      "Epoch 34::Minibatch 101::LR 0.0238461538462 --> Loss 0.000896859268347\n",
      "Epoch 34::Minibatch 102::LR 0.0238461538462 --> Loss 0.00383048693339\n",
      "Epoch 34::Minibatch 103::LR 0.0238461538462 --> Loss 0.003825776577\n",
      "Epoch 34::Minibatch 104::LR 0.0238461538462 --> Loss 0.00262929817041\n",
      "Epoch 34::Minibatch 105::LR 0.0238461538462 --> Loss 0.00199186841647\n",
      "Epoch 34::Minibatch 106::LR 0.0238461538462 --> Loss 0.0126948539416\n",
      "Epoch 34::Minibatch 107::LR 0.0238461538462 --> Loss 0.00471598426501\n",
      "Epoch 34::Minibatch 108::LR 0.0238461538462 --> Loss 0.000907081663609\n",
      "Epoch 34::Minibatch 109::LR 0.0238461538462 --> Loss 0.00430046955744\n",
      "Epoch 34::Minibatch 110::LR 0.0238461538462 --> Loss 0.00218870460987\n",
      "Epoch 34::Minibatch 111::LR 0.0238461538462 --> Loss 0.000795277853807\n",
      "Epoch 34::Minibatch 112::LR 0.0238461538462 --> Loss 0.00323420445124\n",
      "Epoch 34::Minibatch 113::LR 0.0238461538462 --> Loss 0.00233379562696\n",
      "Epoch 34::Minibatch 114::LR 0.0238461538462 --> Loss 0.00131448348363\n",
      "Epoch 34::Minibatch 115::LR 0.0238461538462 --> Loss 0.00109254727761\n",
      "Epoch 34::Minibatch 116::LR 0.0238461538462 --> Loss 0.00261501908302\n",
      "Epoch 34::Minibatch 117::LR 0.0238461538462 --> Loss 0.00411428848902\n",
      "Epoch 34::Minibatch 118::LR 0.0238461538462 --> Loss 0.00644209980965\n",
      "Epoch 34::Minibatch 119::LR 0.0238461538462 --> Loss 0.000471626669168\n",
      "Epoch 34::Minibatch 120::LR 0.0238461538462 --> Loss 0.00163264264663\n",
      "Epoch 34::Minibatch 121::LR 0.0238461538462 --> Loss 0.00230033497016\n",
      "Epoch 34::Minibatch 122::LR 0.0238461538462 --> Loss 0.00388389468193\n",
      "Epoch 34::Minibatch 123::LR 0.0238461538462 --> Loss 0.000624592105548\n",
      "Epoch 34::Minibatch 124::LR 0.0238461538462 --> Loss 0.00260447363059\n",
      "Epoch 34::Minibatch 125::LR 0.0238461538462 --> Loss 0.00436623414358\n",
      "Epoch 34::Minibatch 126::LR 0.0238461538462 --> Loss 0.00237790207068\n",
      "Epoch 34::Minibatch 127::LR 0.0238461538462 --> Loss 0.00496441443761\n",
      "Epoch 34::Minibatch 128::LR 0.0238461538462 --> Loss 0.00347825129827\n",
      "Epoch 34::Minibatch 129::LR 0.0238461538462 --> Loss 0.00232394615809\n",
      "Epoch 34::Minibatch 130::LR 0.0238461538462 --> Loss 0.00429955005646\n",
      "Epoch 34::Minibatch 131::LR 0.0238461538462 --> Loss 0.0016864969333\n",
      "Epoch 34::Minibatch 132::LR 0.0238461538462 --> Loss 0.00275953968366\n",
      "Epoch 34::Minibatch 133::LR 0.0238461538462 --> Loss 0.00268519103527\n",
      "Epoch 34::Minibatch 134::LR 0.0238461538462 --> Loss 0.00207378089428\n",
      "Epoch 34::Minibatch 135::LR 0.0238461538462 --> Loss 0.00122689793507\n",
      "Epoch 34::Minibatch 136::LR 0.0238461538462 --> Loss 0.00236150026321\n",
      "Epoch 34::Minibatch 137::LR 0.0238461538462 --> Loss 0.00330605765184\n",
      "Epoch 34::Minibatch 138::LR 0.0238461538462 --> Loss 0.00119432995717\n",
      "Epoch 34::Minibatch 139::LR 0.0238461538462 --> Loss 0.00185256024202\n",
      "Epoch 34::Minibatch 140::LR 0.0238461538462 --> Loss 0.00235187272231\n",
      "Epoch 34::Minibatch 141::LR 0.0238461538462 --> Loss 0.00285732765992\n",
      "Epoch 34::Minibatch 142::LR 0.0238461538462 --> Loss 0.00268123487631\n",
      "Epoch 34::Minibatch 143::LR 0.0238461538462 --> Loss 0.00052823031942\n",
      "Epoch 34::Minibatch 144::LR 0.0238461538462 --> Loss 0.00338754455249\n",
      "Epoch 34::Minibatch 145::LR 0.0238461538462 --> Loss 0.00409157276154\n",
      "Epoch 34::Minibatch 146::LR 0.0238461538462 --> Loss 0.00248053967953\n",
      "Epoch 34::Minibatch 147::LR 0.0238461538462 --> Loss 0.0017835666736\n",
      "Epoch 34::Minibatch 148::LR 0.0238461538462 --> Loss 0.000957901378473\n",
      "Epoch 34::Minibatch 149::LR 0.0238461538462 --> Loss 0.00286479214827\n",
      "Epoch 34::Minibatch 150::LR 0.0238461538462 --> Loss 0.00264954706033\n",
      "Epoch 34::Minibatch 151::LR 0.0238461538462 --> Loss 0.004291254282\n",
      "Epoch 34::Minibatch 152::LR 0.0238461538462 --> Loss 0.000898874004682\n",
      "Epoch 34::Minibatch 153::LR 0.0238461538462 --> Loss 0.00160458306472\n",
      "Epoch 34::Minibatch 154::LR 0.0238461538462 --> Loss 0.00200001935164\n",
      "Epoch 34::Minibatch 155::LR 0.0238461538462 --> Loss 0.00401886224747\n",
      "Epoch 34::Minibatch 156::LR 0.0238461538462 --> Loss 0.00234557708104\n",
      "Epoch 34::Minibatch 157::LR 0.0238461538462 --> Loss 0.000682732264201\n",
      "Epoch 34::Minibatch 158::LR 0.0238461538462 --> Loss 0.00318105081717\n",
      "Epoch 34::Minibatch 159::LR 0.0238461538462 --> Loss 0.00271827280521\n",
      "Epoch 34::Minibatch 160::LR 0.0238461538462 --> Loss 0.002658867836\n",
      "Epoch 34::Minibatch 161::LR 0.0238461538462 --> Loss 0.000995450615883\n",
      "Epoch 34::Minibatch 162::LR 0.0238461538462 --> Loss 0.00397591352463\n",
      "Epoch 34::Minibatch 163::LR 0.0238461538462 --> Loss 0.0024051964283\n",
      "Epoch 34::Minibatch 164::LR 0.0238461538462 --> Loss 0.00254236340523\n",
      "Epoch 34::Minibatch 165::LR 0.0238461538462 --> Loss 0.000491520762444\n",
      "Epoch 34::Minibatch 166::LR 0.0238461538462 --> Loss 0.00169713020325\n",
      "Epoch 34::Minibatch 167::LR 0.0238461538462 --> Loss 0.00248077233632\n",
      "Epoch 34::Minibatch 168::LR 0.0238461538462 --> Loss 0.00213537553946\n",
      "Epoch 34::Minibatch 169::LR 0.0238461538462 --> Loss 0.000983074804147\n",
      "Epoch 34::Minibatch 170::LR 0.0238461538462 --> Loss 0.000946787198385\n",
      "Epoch 34::Minibatch 171::LR 0.0238461538462 --> Loss 0.00251359264056\n",
      "Epoch 34::Minibatch 172::LR 0.0238461538462 --> Loss 0.00425807634989\n",
      "Epoch 34::Minibatch 173::LR 0.0238461538462 --> Loss 0.00201828042666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 174::LR 0.0238461538462 --> Loss 0.000950992306074\n",
      "Epoch 34::Minibatch 175::LR 0.0238461538462 --> Loss 0.00237420161565\n",
      "Epoch 34::Minibatch 176::LR 0.0238461538462 --> Loss 0.00309421737989\n",
      "Epoch 34::Minibatch 177::LR 0.0238461538462 --> Loss 0.00423904220263\n",
      "Epoch 34::Minibatch 178::LR 0.0238461538462 --> Loss 0.00148402760426\n",
      "Epoch 34::Minibatch 179::LR 0.0238461538462 --> Loss 0.00117739627759\n",
      "Epoch 34::Minibatch 180::LR 0.0238461538462 --> Loss 0.00335251172384\n",
      "Epoch 34::Minibatch 181::LR 0.0238461538462 --> Loss 0.00302613377571\n",
      "Epoch 34::Minibatch 182::LR 0.0238461538462 --> Loss 0.000697128971418\n",
      "Epoch 34::Minibatch 183::LR 0.0238461538462 --> Loss 0.00154542843501\n",
      "Epoch 34::Minibatch 184::LR 0.0238461538462 --> Loss 0.00338909824689\n",
      "Epoch 34::Minibatch 185::LR 0.0238461538462 --> Loss 0.00263397415479\n",
      "Epoch 34::Minibatch 186::LR 0.0238461538462 --> Loss 0.000919597446918\n",
      "Epoch 34::Minibatch 187::LR 0.0238461538462 --> Loss 0.00126801947753\n",
      "Epoch 34::Minibatch 188::LR 0.0238461538462 --> Loss 0.00400814374288\n",
      "Epoch 34::Minibatch 189::LR 0.0238461538462 --> Loss 0.00408569852511\n",
      "Epoch 34::Minibatch 190::LR 0.0238461538462 --> Loss 0.00229951043924\n",
      "Epoch 34::Minibatch 191::LR 0.0238461538462 --> Loss 0.0004454322656\n",
      "Epoch 34::Minibatch 192::LR 0.0238461538462 --> Loss 0.00277509629726\n",
      "Epoch 34::Minibatch 193::LR 0.0238461538462 --> Loss 0.00269351204236\n",
      "Epoch 34::Minibatch 194::LR 0.0238461538462 --> Loss 0.00172779877981\n",
      "Epoch 34::Minibatch 195::LR 0.0238461538462 --> Loss 0.000373505900304\n",
      "Epoch 34::Minibatch 196::LR 0.0238461538462 --> Loss 0.00136221895615\n",
      "Epoch 34::Minibatch 197::LR 0.0238461538462 --> Loss 0.00295953075091\n",
      "Epoch 34::Minibatch 198::LR 0.0238461538462 --> Loss 0.00231630722682\n",
      "Epoch 34::Minibatch 199::LR 0.0238461538462 --> Loss 0.000289814124505\n",
      "Epoch 34::Minibatch 200::LR 0.0238461538462 --> Loss 0.00203600446383\n",
      "Epoch 34::Minibatch 201::LR 0.0238461538462 --> Loss 0.00192854960759\n",
      "Epoch 34::Minibatch 202::LR 0.0238461538462 --> Loss 0.00181216239929\n",
      "Epoch 34::Minibatch 203::LR 0.0238461538462 --> Loss 0.00175360103448\n",
      "Epoch 34::Minibatch 204::LR 0.0238461538462 --> Loss 0.00141502976418\n",
      "Epoch 34::Minibatch 205::LR 0.0238461538462 --> Loss 0.00221569120884\n",
      "Epoch 34::Minibatch 206::LR 0.0238461538462 --> Loss 0.00537125229836\n",
      "Epoch 34::Minibatch 207::LR 0.0238461538462 --> Loss 0.00139760206143\n",
      "Epoch 34::Minibatch 208::LR 0.0238461538462 --> Loss 0.00110357215007\n",
      "Epoch 34::Minibatch 209::LR 0.0238461538462 --> Loss 0.00250963528951\n",
      "Epoch 34::Minibatch 210::LR 0.0238461538462 --> Loss 0.00235878944397\n",
      "Epoch 34::Minibatch 211::LR 0.0238461538462 --> Loss 0.00269331157207\n",
      "Epoch 34::Minibatch 212::LR 0.0238461538462 --> Loss 0.00374379118284\n",
      "Epoch 34::Minibatch 213::LR 0.0238461538462 --> Loss 0.0053668085734\n",
      "Epoch 34::Minibatch 214::LR 0.0238461538462 --> Loss 0.0069677790006\n",
      "Epoch 34::Minibatch 215::LR 0.0238461538462 --> Loss 0.00135872940222\n",
      "Epoch 34::Minibatch 216::LR 0.0238461538462 --> Loss 0.00526760776838\n",
      "Epoch 34::Minibatch 217::LR 0.0238461538462 --> Loss 0.00579747279485\n",
      "Epoch 34::Minibatch 218::LR 0.0238461538462 --> Loss 0.00389275670052\n",
      "Epoch 34::Minibatch 219::LR 0.0238461538462 --> Loss 0.00441993673642\n",
      "Epoch 34::Minibatch 220::LR 0.0238461538462 --> Loss 0.00433967789014\n",
      "Epoch 34::Minibatch 221::LR 0.0238461538462 --> Loss 0.004257649978\n",
      "Epoch 34::Minibatch 222::LR 0.0238461538462 --> Loss 0.00315533161163\n",
      "Epoch 34::Minibatch 223::LR 0.0238461538462 --> Loss 0.00137963801622\n",
      "Epoch 34::Minibatch 224::LR 0.0238461538462 --> Loss 0.0015845054388\n",
      "Epoch 34::Minibatch 225::LR 0.0238461538462 --> Loss 0.00784879922867\n",
      "Epoch 34::Minibatch 226::LR 0.0238461538462 --> Loss 0.00363211035728\n",
      "Epoch 34::Minibatch 227::LR 0.0238461538462 --> Loss 0.00167747855186\n",
      "Epoch 34::Minibatch 228::LR 0.0238461538462 --> Loss 0.000647673010826\n",
      "Epoch 34::Minibatch 229::LR 0.0238461538462 --> Loss 0.00472194552422\n",
      "Epoch 34::Minibatch 230::LR 0.0238461538462 --> Loss 0.00364544590314\n",
      "Epoch 34::Minibatch 231::LR 0.0238461538462 --> Loss 0.00266360302766\n",
      "Epoch 34::Minibatch 232::LR 0.0238461538462 --> Loss 0.00115974247456\n",
      "Epoch 34::Minibatch 233::LR 0.0238461538462 --> Loss 0.00246525208155\n",
      "Epoch 34::Minibatch 234::LR 0.0238461538462 --> Loss 0.00739131450653\n",
      "Epoch 34::Minibatch 235::LR 0.0238461538462 --> Loss 0.00456262071927\n",
      "Epoch 34::Minibatch 236::LR 0.0238461538462 --> Loss 0.00166636476914\n",
      "Epoch 34::Minibatch 237::LR 0.0238461538462 --> Loss 0.000581173300743\n",
      "Epoch 34::Minibatch 238::LR 0.0238461538462 --> Loss 0.00345136324565\n",
      "Epoch 34::Minibatch 239::LR 0.0238461538462 --> Loss 0.00295657157898\n",
      "Epoch 34::Minibatch 240::LR 0.0238461538462 --> Loss 0.00325748284658\n",
      "Epoch 34::Minibatch 241::LR 0.0238461538462 --> Loss 0.000743837207556\n",
      "Epoch 34::Minibatch 242::LR 0.0238461538462 --> Loss 0.00669700225194\n",
      "Epoch 34::Minibatch 243::LR 0.0238461538462 --> Loss 0.00324394106865\n",
      "Epoch 34::Minibatch 244::LR 0.0238461538462 --> Loss 0.00271944125493\n",
      "Epoch 34::Minibatch 245::LR 0.0238461538462 --> Loss 0.000424695213636\n",
      "Epoch 34::Minibatch 246::LR 0.0238461538462 --> Loss 0.00189171433449\n",
      "Epoch 34::Minibatch 247::LR 0.0238461538462 --> Loss 0.0103076815605\n",
      "Epoch 34::Minibatch 248::LR 0.0238461538462 --> Loss 0.0043314353625\n",
      "Epoch 34::Minibatch 249::LR 0.0238461538462 --> Loss 0.00238848189513\n",
      "Epoch 34::Minibatch 250::LR 0.0238461538462 --> Loss 0.00233200947444\n",
      "Epoch 34::Minibatch 251::LR 0.0238461538462 --> Loss 0.00232422371705\n",
      "Epoch 34::Minibatch 252::LR 0.0238461538462 --> Loss 0.00159931371609\n",
      "Epoch 34::Minibatch 253::LR 0.0238461538462 --> Loss 0.00276652852694\n",
      "Epoch 34::Minibatch 254::LR 0.0238461538462 --> Loss 0.00480801781019\n",
      "Epoch 34::Minibatch 255::LR 0.0238461538462 --> Loss 0.00384637991587\n",
      "Epoch 34::Minibatch 256::LR 0.0238461538462 --> Loss 0.00137823363145\n",
      "Epoch 34::Minibatch 257::LR 0.0238461538462 --> Loss 0.00113302528858\n",
      "Epoch 34::Minibatch 258::LR 0.0238461538462 --> Loss 0.00365982055664\n",
      "Epoch 34::Minibatch 259::LR 0.0238461538462 --> Loss 0.00157304475705\n",
      "Epoch 34::Minibatch 260::LR 0.0238461538462 --> Loss 0.00184066375097\n",
      "Epoch 34::Minibatch 261::LR 0.0238461538462 --> Loss 0.00264304041862\n",
      "Epoch 34::Minibatch 262::LR 0.0238461538462 --> Loss 0.00180407583714\n",
      "Epoch 34::Minibatch 263::LR 0.0238461538462 --> Loss 0.00227435211341\n",
      "Epoch 34::Minibatch 264::LR 0.0238461538462 --> Loss 0.00354618787766\n",
      "Epoch 34::Minibatch 265::LR 0.0238461538462 --> Loss 0.00992301305135\n",
      "Epoch 34::Minibatch 266::LR 0.0238461538462 --> Loss 0.000866543054581\n",
      "Epoch 34::Minibatch 267::LR 0.0238461538462 --> Loss 0.00901211579641\n",
      "Epoch 34::Minibatch 268::LR 0.0238461538462 --> Loss 0.00101981649796\n",
      "Epoch 34::Minibatch 269::LR 0.0238461538462 --> Loss 0.00345911502838\n",
      "Epoch 34::Minibatch 270::LR 0.0238461538462 --> Loss 0.00739250818888\n",
      "Epoch 34::Minibatch 271::LR 0.0238461538462 --> Loss 0.00239027500153\n",
      "Epoch 34::Minibatch 272::LR 0.0238461538462 --> Loss 0.00444281498591\n",
      "Epoch 34::Minibatch 273::LR 0.0238461538462 --> Loss 0.0013470963637\n",
      "Epoch 34::Minibatch 274::LR 0.0238461538462 --> Loss 0.00176518559456\n",
      "Epoch 34::Minibatch 275::LR 0.0238461538462 --> Loss 0.00244213779767\n",
      "Epoch 34::Minibatch 276::LR 0.0238461538462 --> Loss 0.0033279633522\n",
      "Epoch 34::Minibatch 277::LR 0.0238461538462 --> Loss 0.000852218468984\n",
      "Epoch 34::Minibatch 278::LR 0.0238461538462 --> Loss 0.00251779556274\n",
      "Epoch 34::Minibatch 279::LR 0.0238461538462 --> Loss 0.00195486505826\n",
      "Epoch 34::Minibatch 280::LR 0.0238461538462 --> Loss 0.00173229555289\n",
      "Epoch 34::Minibatch 281::LR 0.0238461538462 --> Loss 0.00109767595927\n",
      "Epoch 34::Minibatch 282::LR 0.0238461538462 --> Loss 0.00197872837385\n",
      "Epoch 34::Minibatch 283::LR 0.0238461538462 --> Loss 0.00187844336033\n",
      "Epoch 34::Minibatch 284::LR 0.0238461538462 --> Loss 0.00153713872035\n",
      "Epoch 34::Minibatch 285::LR 0.0238461538462 --> Loss 0.00110807796319\n",
      "Epoch 34::Minibatch 286::LR 0.0238461538462 --> Loss 0.00192812343438\n",
      "Epoch 34::Minibatch 287::LR 0.0238461538462 --> Loss 0.00191127796968\n",
      "Epoch 34::Minibatch 288::LR 0.0238461538462 --> Loss 0.00104104558627\n",
      "Epoch 34::Minibatch 289::LR 0.0238461538462 --> Loss 0.0015364002188\n",
      "Epoch 34::Minibatch 290::LR 0.0238461538462 --> Loss 0.00182338853677\n",
      "Epoch 34::Minibatch 291::LR 0.0238461538462 --> Loss 0.00164116173983\n",
      "Epoch 34::Minibatch 292::LR 0.0238461538462 --> Loss 0.000580114026864\n",
      "Epoch 34::Minibatch 293::LR 0.0238461538462 --> Loss 0.00147576222817\n",
      "Epoch 34::Minibatch 294::LR 0.0238461538462 --> Loss 0.00161586642265\n",
      "Epoch 34::Minibatch 295::LR 0.0238461538462 --> Loss 0.00186954458555\n",
      "Epoch 34::Minibatch 296::LR 0.0238461538462 --> Loss 0.00161034623782\n",
      "Epoch 34::Minibatch 297::LR 0.0238461538462 --> Loss 0.00141205797593\n",
      "Epoch 34::Minibatch 298::LR 0.0238461538462 --> Loss 0.00141747663418\n",
      "Epoch 34::Minibatch 299::LR 0.0238461538462 --> Loss 0.000813083599011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 300::LR 0.0238461538462 --> Loss 0.00266584634781\n",
      "Epoch 34::Minibatch 301::LR 0.0238461538462 --> Loss 0.0025786370039\n",
      "Epoch 34::Minibatch 302::LR 0.0238461538462 --> Loss 0.00237407664458\n",
      "Epoch 34::Minibatch 303::LR 0.0238461538462 --> Loss 0.000824928482374\n",
      "Epoch 34::Minibatch 304::LR 0.0238461538462 --> Loss 0.00291296561559\n",
      "Epoch 34::Minibatch 305::LR 0.0238461538462 --> Loss 0.00171295146147\n",
      "Epoch 34::Minibatch 306::LR 0.0238461538462 --> Loss 0.000935873389244\n",
      "Epoch 34::Minibatch 307::LR 0.0238461538462 --> Loss 0.0023946861426\n",
      "Epoch 34::Minibatch 308::LR 0.0238461538462 --> Loss 0.00201616009076\n",
      "Epoch 34::Minibatch 309::LR 0.0238461538462 --> Loss 0.00104533731937\n",
      "Epoch 34::Minibatch 310::LR 0.0238461538462 --> Loss 0.0011974443992\n",
      "Epoch 34::Minibatch 311::LR 0.0238461538462 --> Loss 0.00179849902789\n",
      "Epoch 34::Minibatch 312::LR 0.0238461538462 --> Loss 0.00284636497498\n",
      "Epoch 34::Minibatch 313::LR 0.0238461538462 --> Loss 0.00232860207558\n",
      "Epoch 34::Minibatch 314::LR 0.0238461538462 --> Loss 0.00192275365194\n",
      "Epoch 34::Minibatch 315::LR 0.0238461538462 --> Loss 0.00105199585358\n",
      "Epoch 34::Minibatch 316::LR 0.0238461538462 --> Loss 0.00234559178352\n",
      "Epoch 34::Minibatch 317::LR 0.0238461538462 --> Loss 0.0015654489398\n",
      "Epoch 34::Minibatch 318::LR 0.0238461538462 --> Loss 0.00131477524837\n",
      "Epoch 34::Minibatch 319::LR 0.0238461538462 --> Loss 0.0023080120484\n",
      "Epoch 34::Minibatch 320::LR 0.0238461538462 --> Loss 0.00301275134087\n",
      "Epoch 34::Minibatch 321::LR 0.0238461538462 --> Loss 0.0008422194918\n",
      "Epoch 34::Minibatch 322::LR 0.0238461538462 --> Loss 0.00341218312581\n",
      "Epoch 34::Minibatch 323::LR 0.0238461538462 --> Loss 0.00340733647346\n",
      "Epoch 34::Minibatch 324::LR 0.0238461538462 --> Loss 0.00265223840872\n",
      "Epoch 34::Minibatch 325::LR 0.0238461538462 --> Loss 0.00236849963665\n",
      "Epoch 34::Minibatch 326::LR 0.0238461538462 --> Loss 0.00522777557373\n",
      "Epoch 34::Minibatch 327::LR 0.0238461538462 --> Loss 0.00222217977047\n",
      "Epoch 34::Minibatch 328::LR 0.0238461538462 --> Loss 0.00290855367978\n",
      "Epoch 34::Minibatch 329::LR 0.0238461538462 --> Loss 0.00118737310171\n",
      "Epoch 34::Minibatch 330::LR 0.0238461538462 --> Loss 0.0015880543987\n",
      "Epoch 34::Minibatch 331::LR 0.0238461538462 --> Loss 0.00253352801005\n",
      "Epoch 34::Minibatch 332::LR 0.0238461538462 --> Loss 0.00244433045387\n",
      "Epoch 34::Minibatch 333::LR 0.0238461538462 --> Loss 0.00147250900666\n",
      "Epoch 34::Minibatch 334::LR 0.0238461538462 --> Loss 0.00439904808998\n",
      "Epoch 34::Minibatch 335::LR 0.0238461538462 --> Loss 0.00190315643946\n",
      "Epoch 34::Minibatch 336::LR 0.0238461538462 --> Loss 0.00226579010487\n",
      "Epoch 34::Minibatch 337::LR 0.0238461538462 --> Loss 0.00377090573311\n",
      "Epoch 34::Minibatch 338::LR 0.0238461538462 --> Loss 0.000557707051436\n",
      "Epoch 34::Minibatch 339::LR 0.0238461538462 --> Loss 0.00323037127654\n",
      "Epoch 34::Minibatch 340::LR 0.0238461538462 --> Loss 0.00364398519198\n",
      "Epoch 34::Minibatch 341::LR 0.0238461538462 --> Loss 0.0042499423027\n",
      "Epoch 34::Minibatch 342::LR 0.0238461538462 --> Loss 0.00305331230164\n",
      "Epoch 34::Minibatch 343::LR 0.0238461538462 --> Loss 0.00163786073526\n",
      "Epoch 34::Minibatch 344::LR 0.0238461538462 --> Loss 0.00315983275572\n",
      "Epoch 34::Minibatch 345::LR 0.0238461538462 --> Loss 0.00405685901642\n",
      "Epoch 34::Minibatch 346::LR 0.0238461538462 --> Loss 0.00532055179278\n",
      "Epoch 34::Minibatch 347::LR 0.0238461538462 --> Loss 0.000818826307853\n",
      "Epoch 34::Minibatch 348::LR 0.0238461538462 --> Loss 0.00294924438\n",
      "Epoch 34::Minibatch 349::LR 0.0238461538462 --> Loss 0.00334010362625\n",
      "Epoch 34::Minibatch 350::LR 0.0238461538462 --> Loss 0.00164455254873\n",
      "Epoch 34::Minibatch 351::LR 0.0238461538462 --> Loss 0.00342268029849\n",
      "Epoch 34::Minibatch 352::LR 0.0238461538462 --> Loss 0.00487916310628\n",
      "Epoch 34::Minibatch 353::LR 0.0238461538462 --> Loss 0.00349333167076\n",
      "Epoch 34::Minibatch 354::LR 0.0238461538462 --> Loss 0.00294082740943\n",
      "Epoch 34::Minibatch 355::LR 0.0238461538462 --> Loss 0.0062821773688\n",
      "Epoch 34::Minibatch 356::LR 0.0238461538462 --> Loss 0.003161277771\n",
      "Epoch 34::Minibatch 357::LR 0.0238461538462 --> Loss 0.00118535786867\n",
      "Epoch 34::Minibatch 358::LR 0.0238461538462 --> Loss 0.00193286657333\n",
      "Epoch 34::Minibatch 359::LR 0.0238461538462 --> Loss 0.00266795873642\n",
      "Epoch 34::Minibatch 360::LR 0.0238461538462 --> Loss 0.00227914830049\n",
      "Epoch 34::Minibatch 361::LR 0.0238461538462 --> Loss 0.00224364837011\n",
      "Epoch 34::Minibatch 362::LR 0.0238461538462 --> Loss 0.00223562757174\n",
      "Epoch 34::Minibatch 363::LR 0.0238461538462 --> Loss 0.000633945266406\n",
      "Epoch 34::Minibatch 364::LR 0.0238461538462 --> Loss 0.00196702420712\n",
      "Epoch 34::Minibatch 365::LR 0.0238461538462 --> Loss 0.00199308832486\n",
      "Epoch 34::Minibatch 366::LR 0.0238461538462 --> Loss 0.00210819860299\n",
      "Epoch 34::Minibatch 367::LR 0.0238461538462 --> Loss 0.000984982252121\n",
      "Epoch 34::Minibatch 368::LR 0.0238461538462 --> Loss 0.00097332606713\n",
      "Epoch 34::Minibatch 369::LR 0.0238461538462 --> Loss 0.00273829181989\n",
      "Epoch 34::Minibatch 370::LR 0.0238461538462 --> Loss 0.00219753821691\n",
      "Epoch 34::Minibatch 371::LR 0.0238461538462 --> Loss 0.0018387868007\n",
      "Epoch 34::Minibatch 372::LR 0.0238461538462 --> Loss 0.000428448965152\n",
      "Epoch 34::Minibatch 373::LR 0.0238461538462 --> Loss 0.00180985271931\n",
      "Epoch 34::Minibatch 374::LR 0.0238461538462 --> Loss 0.00225530584653\n",
      "Epoch 34::Minibatch 375::LR 0.0238461538462 --> Loss 0.00189567188422\n",
      "Epoch 34::Minibatch 376::LR 0.0238461538462 --> Loss 0.0011993915836\n",
      "Epoch 34::Minibatch 377::LR 0.0238461538462 --> Loss 0.001905986468\n",
      "Epoch 34::Minibatch 378::LR 0.0238461538462 --> Loss 0.0020880005757\n",
      "Epoch 34::Minibatch 379::LR 0.0238461538462 --> Loss 0.00231374442577\n",
      "Epoch 34::Minibatch 380::LR 0.0238461538462 --> Loss 0.00155970017115\n",
      "Epoch 34::Minibatch 381::LR 0.0238461538462 --> Loss 0.000996206899484\n",
      "Epoch 34::Minibatch 382::LR 0.0238461538462 --> Loss 0.00204110383987\n",
      "Epoch 34::Minibatch 383::LR 0.0238461538462 --> Loss 0.00199281613032\n",
      "Epoch 34::Minibatch 384::LR 0.0238461538462 --> Loss 0.00113029380639\n",
      "Epoch 34::Minibatch 385::LR 0.0238461538462 --> Loss 0.00106076618036\n",
      "Epoch 34::Minibatch 386::LR 0.0238461538462 --> Loss 0.00225867331028\n",
      "Epoch 34::Minibatch 387::LR 0.0238461538462 --> Loss 0.00236524919669\n",
      "Epoch 34::Minibatch 388::LR 0.0238461538462 --> Loss 0.00122243871291\n",
      "Epoch 34::Minibatch 389::LR 0.0238461538462 --> Loss 0.00178438166777\n",
      "Epoch 34::Minibatch 390::LR 0.0238461538462 --> Loss 0.00323575456937\n",
      "Epoch 34::Minibatch 391::LR 0.0238461538462 --> Loss 0.00254333913326\n",
      "Epoch 34::Minibatch 392::LR 0.0238461538462 --> Loss 0.00255325555801\n",
      "Epoch 34::Minibatch 393::LR 0.0238461538462 --> Loss 0.0027280207475\n",
      "Epoch 34::Minibatch 394::LR 0.0238461538462 --> Loss 0.00200601299604\n",
      "Epoch 34::Minibatch 395::LR 0.0238461538462 --> Loss 0.00207621117433\n",
      "Epoch 34::Minibatch 396::LR 0.0238461538462 --> Loss 0.00194272617499\n",
      "Epoch 34::Minibatch 397::LR 0.0238461538462 --> Loss 0.0020802005132\n",
      "Epoch 34::Minibatch 398::LR 0.0238461538462 --> Loss 0.00206954717636\n",
      "Epoch 34::Minibatch 399::LR 0.0238461538462 --> Loss 0.00237389703592\n",
      "Epoch 34::Minibatch 400::LR 0.0238461538462 --> Loss 0.00201148013274\n",
      "Epoch 34::Minibatch 401::LR 0.0238461538462 --> Loss 0.00340340852737\n",
      "Epoch 34::Minibatch 402::LR 0.0238461538462 --> Loss 0.00171472847462\n",
      "Epoch 34::Minibatch 403::LR 0.0238461538462 --> Loss 0.00142750968536\n",
      "Epoch 34::Minibatch 404::LR 0.0238461538462 --> Loss 0.00132629007101\n",
      "Epoch 34::Minibatch 405::LR 0.0238461538462 --> Loss 0.00332184314728\n",
      "Epoch 34::Minibatch 406::LR 0.0238461538462 --> Loss 0.00232881228129\n",
      "Epoch 34::Minibatch 407::LR 0.0238461538462 --> Loss 0.00170405089855\n",
      "Epoch 34::Minibatch 408::LR 0.0238461538462 --> Loss 0.0004335608085\n",
      "Epoch 34::Minibatch 409::LR 0.0238461538462 --> Loss 0.00220498879751\n",
      "Epoch 34::Minibatch 410::LR 0.0238461538462 --> Loss 0.00313031236331\n",
      "Epoch 34::Minibatch 411::LR 0.0238461538462 --> Loss 0.00166569878658\n",
      "Epoch 34::Minibatch 412::LR 0.0238461538462 --> Loss 0.000941662589709\n",
      "Epoch 34::Minibatch 413::LR 0.0238461538462 --> Loss 0.00197592635949\n",
      "Epoch 34::Minibatch 414::LR 0.0238461538462 --> Loss 0.00187771081924\n",
      "Epoch 34::Minibatch 415::LR 0.0238461538462 --> Loss 0.00117564161619\n",
      "Epoch 34::Minibatch 416::LR 0.0238461538462 --> Loss 0.000789366314809\n",
      "Epoch 34::Minibatch 417::LR 0.0238461538462 --> Loss 0.00167599479357\n",
      "Epoch 34::Minibatch 418::LR 0.0238461538462 --> Loss 0.00257557411989\n",
      "Epoch 34::Minibatch 419::LR 0.0238461538462 --> Loss 0.000490774114927\n",
      "Epoch 34::Minibatch 420::LR 0.0238461538462 --> Loss 0.000691710511843\n",
      "Epoch 34::Minibatch 421::LR 0.0238461538462 --> Loss 0.00186591267586\n",
      "Epoch 34::Minibatch 422::LR 0.0238461538462 --> Loss 0.00205252289772\n",
      "Epoch 34::Minibatch 423::LR 0.0238461538462 --> Loss 0.000987560649713\n",
      "Epoch 34::Minibatch 424::LR 0.0238461538462 --> Loss 0.00151832948128\n",
      "Epoch 34::Minibatch 425::LR 0.0238461538462 --> Loss 0.00285747508208\n",
      "Epoch 34::Minibatch 426::LR 0.0238461538462 --> Loss 0.00199022551378\n",
      "Epoch 34::Minibatch 427::LR 0.0238461538462 --> Loss 0.000739732036988\n",
      "Epoch 34::Minibatch 428::LR 0.0238461538462 --> Loss 0.000919457475344\n",
      "Epoch 34::Minibatch 429::LR 0.0238461538462 --> Loss 0.00222793658574\n",
      "Epoch 34::Minibatch 430::LR 0.0238461538462 --> Loss 0.00766753117243\n",
      "Epoch 34::Minibatch 431::LR 0.0238461538462 --> Loss 0.0035322022438\n",
      "Epoch 34::Minibatch 432::LR 0.0238461538462 --> Loss 0.0039475663503\n",
      "Epoch 34::Minibatch 433::LR 0.0238461538462 --> Loss 0.00253159741561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 434::LR 0.0238461538462 --> Loss 0.00242671767871\n",
      "Epoch 34::Minibatch 435::LR 0.0238461538462 --> Loss 0.00224547088146\n",
      "Epoch 34::Minibatch 436::LR 0.0238461538462 --> Loss 0.00158605267604\n",
      "Epoch 34::Minibatch 437::LR 0.0238461538462 --> Loss 0.00278050502141\n",
      "Epoch 34::Minibatch 438::LR 0.0238461538462 --> Loss 0.00223421374957\n",
      "Epoch 34::Minibatch 439::LR 0.0238461538462 --> Loss 0.00190306564172\n",
      "Epoch 34::Minibatch 440::LR 0.0238461538462 --> Loss 0.00293779174487\n",
      "Epoch 34::Minibatch 441::LR 0.0238461538462 --> Loss 0.00274777809779\n",
      "Epoch 34::Minibatch 442::LR 0.0238461538462 --> Loss 0.00245115498702\n",
      "Epoch 34::Minibatch 443::LR 0.0238461538462 --> Loss 0.00343406041463\n",
      "Epoch 34::Minibatch 444::LR 0.0238461538462 --> Loss 0.00264617900054\n",
      "Epoch 34::Minibatch 445::LR 0.0238461538462 --> Loss 0.000842047631741\n",
      "Epoch 34::Minibatch 446::LR 0.0238461538462 --> Loss 0.00135219216347\n",
      "Epoch 34::Minibatch 447::LR 0.0238461538462 --> Loss 0.00226773877939\n",
      "Epoch 34::Minibatch 448::LR 0.0238461538462 --> Loss 0.00229964454969\n",
      "Epoch 34::Minibatch 449::LR 0.0238461538462 --> Loss 0.00354573289553\n",
      "Epoch 34::Minibatch 450::LR 0.0238461538462 --> Loss 0.00211113413175\n",
      "Epoch 34::Minibatch 451::LR 0.0238461538462 --> Loss 0.00379801710447\n",
      "Epoch 34::Minibatch 452::LR 0.0238461538462 --> Loss 0.00227873206139\n",
      "Epoch 34::Minibatch 453::LR 0.0238461538462 --> Loss 0.000346469630798\n",
      "Epoch 34::Minibatch 454::LR 0.0238461538462 --> Loss 0.0033910381794\n",
      "Epoch 34::Minibatch 455::LR 0.0238461538462 --> Loss 0.00256440838178\n",
      "Epoch 34::Minibatch 456::LR 0.0238461538462 --> Loss 0.00303896089395\n",
      "Epoch 34::Minibatch 457::LR 0.0238461538462 --> Loss 0.00186592519283\n",
      "Epoch 34::Minibatch 458::LR 0.0238461538462 --> Loss 0.00071217139562\n",
      "Epoch 34::Minibatch 459::LR 0.0238461538462 --> Loss 0.00379562020302\n",
      "Epoch 34::Minibatch 460::LR 0.0238461538462 --> Loss 0.00241120080153\n",
      "Epoch 34::Minibatch 461::LR 0.0238461538462 --> Loss 0.00364960471789\n",
      "Epoch 34::Minibatch 462::LR 0.0238461538462 --> Loss 0.000367026155194\n",
      "Epoch 34::Minibatch 463::LR 0.0238461538462 --> Loss 0.00403797109922\n",
      "Epoch 34::Minibatch 464::LR 0.0238461538462 --> Loss 0.00193401773771\n",
      "Epoch 34::Minibatch 465::LR 0.0238461538462 --> Loss 0.00442440311114\n",
      "Epoch 34::Minibatch 466::LR 0.0238461538462 --> Loss 0.00492148439089\n",
      "Epoch 34::Minibatch 467::LR 0.0238461538462 --> Loss 0.00500645240148\n",
      "Epoch 34::Minibatch 468::LR 0.0238461538462 --> Loss 0.00558482527733\n",
      "Epoch 34::Minibatch 469::LR 0.0238461538462 --> Loss 0.00589841683706\n",
      "Epoch 34::Minibatch 470::LR 0.0238461538462 --> Loss 0.00355046749115\n",
      "Epoch 34::Minibatch 471::LR 0.0238461538462 --> Loss 0.00165361275276\n",
      "Epoch 34::Minibatch 472::LR 0.0238461538462 --> Loss 0.0035608279705\n",
      "Epoch 34::Minibatch 473::LR 0.0238461538462 --> Loss 0.00231099128723\n",
      "Epoch 34::Minibatch 474::LR 0.0238461538462 --> Loss 0.000687731901805\n",
      "Epoch 34::Minibatch 475::LR 0.0238461538462 --> Loss 0.00471850236257\n",
      "Epoch 34::Minibatch 476::LR 0.0238461538462 --> Loss 0.00758029858271\n",
      "Epoch 34::Minibatch 477::LR 0.0238461538462 --> Loss 0.000914790531\n",
      "Epoch 34::Minibatch 478::LR 0.0238461538462 --> Loss 0.00239861687024\n",
      "Epoch 34::Minibatch 479::LR 0.0238461538462 --> Loss 0.00195660948753\n",
      "Epoch 34::Minibatch 480::LR 0.0238461538462 --> Loss 0.00150890409946\n",
      "Epoch 34::Minibatch 481::LR 0.0238461538462 --> Loss 0.000958229204019\n",
      "Epoch 34::Minibatch 482::LR 0.0238461538462 --> Loss 0.00206318537394\n",
      "Epoch 34::Minibatch 483::LR 0.0238461538462 --> Loss 0.00300091127555\n",
      "Epoch 34::Minibatch 484::LR 0.0238461538462 --> Loss 0.00336619059245\n",
      "Epoch 34::Minibatch 485::LR 0.0238461538462 --> Loss 0.000761045267185\n",
      "Epoch 34::Minibatch 486::LR 0.0238461538462 --> Loss 0.00281001786391\n",
      "Epoch 34::Minibatch 487::LR 0.0238461538462 --> Loss 0.003285617431\n",
      "Epoch 34::Minibatch 488::LR 0.0238461538462 --> Loss 0.00201393882434\n",
      "Epoch 34::Minibatch 489::LR 0.0238461538462 --> Loss 0.00305982311567\n",
      "Epoch 34::Minibatch 490::LR 0.0238461538462 --> Loss 0.000412378236651\n",
      "Epoch 34::Minibatch 491::LR 0.0238461538462 --> Loss 0.00314167221387\n",
      "Epoch 34::Minibatch 492::LR 0.0238461538462 --> Loss 0.00306318203608\n",
      "Epoch 34::Minibatch 493::LR 0.0238461538462 --> Loss 0.00301271796227\n",
      "Epoch 34::Minibatch 494::LR 0.0238461538462 --> Loss 0.000731582343578\n",
      "Epoch 34::Minibatch 495::LR 0.0238461538462 --> Loss 0.0018205221494\n",
      "Epoch 34::Minibatch 496::LR 0.0238461538462 --> Loss 0.00277586420377\n",
      "Epoch 34::Minibatch 497::LR 0.0238461538462 --> Loss 0.000913046598434\n",
      "Epoch 34::Minibatch 498::LR 0.0238461538462 --> Loss 0.000548517107964\n",
      "Epoch 34::Minibatch 499::LR 0.0238461538462 --> Loss 0.00338468273481\n",
      "Epoch 34::Minibatch 500::LR 0.0238461538462 --> Loss 0.00142288376888\n",
      "Epoch 34::Minibatch 501::LR 0.0238461538462 --> Loss 0.00200502912203\n",
      "Epoch 34::Minibatch 502::LR 0.0238461538462 --> Loss 0.00372456669807\n",
      "Epoch 34::Minibatch 503::LR 0.0238461538462 --> Loss 0.00666936953863\n",
      "Epoch 34::Minibatch 504::LR 0.0238461538462 --> Loss 0.00658900777499\n",
      "Epoch 34::Minibatch 505::LR 0.0238461538462 --> Loss 0.00389701485634\n",
      "Epoch 34::Minibatch 506::LR 0.0238461538462 --> Loss 0.00328483800093\n",
      "Epoch 34::Minibatch 507::LR 0.0238461538462 --> Loss 0.00569786310196\n",
      "Epoch 34::Minibatch 508::LR 0.0238461538462 --> Loss 0.00338061094284\n",
      "Epoch 34::Minibatch 509::LR 0.0238461538462 --> Loss 0.00420677542686\n",
      "Epoch 34::Minibatch 510::LR 0.0238461538462 --> Loss 0.00436336954435\n",
      "Epoch 34::Minibatch 511::LR 0.0238461538462 --> Loss 0.00401189605395\n",
      "Epoch 34::Minibatch 512::LR 0.0238461538462 --> Loss 0.00268236617247\n",
      "Epoch 34::Minibatch 513::LR 0.0238461538462 --> Loss 0.000592594891787\n",
      "Epoch 34::Minibatch 514::LR 0.0238461538462 --> Loss 0.00260255277157\n",
      "Epoch 34::Minibatch 515::LR 0.0238461538462 --> Loss 0.00298816144466\n",
      "Epoch 34::Minibatch 516::LR 0.0238461538462 --> Loss 0.00389969746272\n",
      "Epoch 34::Minibatch 517::LR 0.0238461538462 --> Loss 0.00363470991453\n",
      "Epoch 34::Minibatch 518::LR 0.0238461538462 --> Loss 0.00257156531016\n",
      "Epoch 34::Minibatch 519::LR 0.0238461538462 --> Loss 0.00356893181801\n",
      "Epoch 34::Minibatch 520::LR 0.0238461538462 --> Loss 0.00561661839485\n",
      "Epoch 34::Minibatch 521::LR 0.0238461538462 --> Loss 0.00567233204842\n",
      "Epoch 34::Minibatch 522::LR 0.0238461538462 --> Loss 0.00701048135757\n",
      "Epoch 34::Minibatch 523::LR 0.0238461538462 --> Loss 0.000621329794327\n",
      "Epoch 34::Minibatch 524::LR 0.0238461538462 --> Loss 0.00138543824355\n",
      "Epoch 34::Minibatch 525::LR 0.0238461538462 --> Loss 0.00302649815877\n",
      "Epoch 34::Minibatch 526::LR 0.0238461538462 --> Loss 0.00366789499919\n",
      "Epoch 34::Minibatch 527::LR 0.0238461538462 --> Loss 0.00211561739445\n",
      "Epoch 34::Minibatch 528::LR 0.0238461538462 --> Loss 0.000915426214536\n",
      "Epoch 34::Minibatch 529::LR 0.0238461538462 --> Loss 0.00377568125725\n",
      "Epoch 34::Minibatch 530::LR 0.0238461538462 --> Loss 0.0037412917614\n",
      "Epoch 34::Minibatch 531::LR 0.0238461538462 --> Loss 0.00332465092341\n",
      "Epoch 34::Minibatch 532::LR 0.0238461538462 --> Loss 0.00257793585459\n",
      "Epoch 34::Minibatch 533::LR 0.0238461538462 --> Loss 0.0048640914758\n",
      "Epoch 34::Minibatch 534::LR 0.0238461538462 --> Loss 0.0036682510376\n",
      "Epoch 34::Minibatch 535::LR 0.0238461538462 --> Loss 0.00332806507746\n",
      "Epoch 34::Minibatch 536::LR 0.0238461538462 --> Loss 0.0021067204078\n",
      "Epoch 34::Minibatch 537::LR 0.0238461538462 --> Loss 0.000581010182699\n",
      "Epoch 34::Minibatch 538::LR 0.0238461538462 --> Loss 0.00162512580554\n",
      "Epoch 34::Minibatch 539::LR 0.0238461538462 --> Loss 0.00329803943634\n",
      "Epoch 34::Minibatch 540::LR 0.0238461538462 --> Loss 0.0033775071303\n",
      "Epoch 34::Minibatch 541::LR 0.0238461538462 --> Loss 0.00283042053382\n",
      "Epoch 34::Minibatch 542::LR 0.0238461538462 --> Loss 0.00242424190044\n",
      "Epoch 34::Minibatch 543::LR 0.0238461538462 --> Loss 0.00254887123903\n",
      "Epoch 34::Minibatch 544::LR 0.0238461538462 --> Loss 0.00405889193217\n",
      "Epoch 34::Minibatch 545::LR 0.0238461538462 --> Loss 0.00195882042249\n",
      "Epoch 34::Minibatch 546::LR 0.0238461538462 --> Loss 0.000661527961493\n",
      "Epoch 34::Minibatch 547::LR 0.0238461538462 --> Loss 0.00257209340731\n",
      "Epoch 34::Minibatch 548::LR 0.0238461538462 --> Loss 0.00336777885755\n",
      "Epoch 34::Minibatch 549::LR 0.0238461538462 --> Loss 0.00891507228216\n",
      "Epoch 34::Minibatch 550::LR 0.0238461538462 --> Loss 0.00118735591571\n",
      "Epoch 34::Minibatch 551::LR 0.0238461538462 --> Loss 0.00246172746023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 552::LR 0.0238461538462 --> Loss 0.00342158476512\n",
      "Epoch 34::Minibatch 553::LR 0.0238461538462 --> Loss 0.00292677938938\n",
      "Epoch 34::Minibatch 554::LR 0.0238461538462 --> Loss 0.00359704375267\n",
      "Epoch 34::Minibatch 555::LR 0.0238461538462 --> Loss 0.000935307840506\n",
      "Epoch 34::Minibatch 556::LR 0.0238461538462 --> Loss 0.00190812826157\n",
      "Epoch 34::Minibatch 557::LR 0.0238461538462 --> Loss 0.00240759650866\n",
      "Epoch 34::Minibatch 558::LR 0.0238461538462 --> Loss 0.00356804450353\n",
      "Epoch 34::Minibatch 559::LR 0.0238461538462 --> Loss 0.00364541530609\n",
      "Epoch 34::Minibatch 560::LR 0.0238461538462 --> Loss 0.00304953893026\n",
      "Epoch 34::Minibatch 561::LR 0.0238461538462 --> Loss 0.0026139130195\n",
      "Epoch 34::Minibatch 562::LR 0.0238461538462 --> Loss 0.00233372469743\n",
      "Epoch 34::Minibatch 563::LR 0.0238461538462 --> Loss 0.003956113259\n",
      "Epoch 34::Minibatch 564::LR 0.0238461538462 --> Loss 0.0030300450325\n",
      "Epoch 34::Minibatch 565::LR 0.0238461538462 --> Loss 0.00356680194537\n",
      "Epoch 34::Minibatch 566::LR 0.0238461538462 --> Loss 0.0021612338225\n",
      "Epoch 34::Minibatch 567::LR 0.0238461538462 --> Loss 0.00253966848056\n",
      "Epoch 34::Minibatch 568::LR 0.0238461538462 --> Loss 0.00172290583452\n",
      "Epoch 34::Minibatch 569::LR 0.0238461538462 --> Loss 0.00055921792984\n",
      "Epoch 34::Minibatch 570::LR 0.0238461538462 --> Loss 0.00160642315944\n",
      "Epoch 34::Minibatch 571::LR 0.0238461538462 --> Loss 0.00202456692855\n",
      "Epoch 34::Minibatch 572::LR 0.0238461538462 --> Loss 0.00218268215656\n",
      "Epoch 34::Minibatch 573::LR 0.0238461538462 --> Loss 0.00142322202524\n",
      "Epoch 34::Minibatch 574::LR 0.0238461538462 --> Loss 0.00104203442732\n",
      "Epoch 34::Minibatch 575::LR 0.0238461538462 --> Loss 0.00170137703419\n",
      "Epoch 34::Minibatch 576::LR 0.0238461538462 --> Loss 0.00201427062352\n",
      "Epoch 34::Minibatch 577::LR 0.0238461538462 --> Loss 0.00159459451834\n",
      "Epoch 34::Minibatch 578::LR 0.0238461538462 --> Loss 0.0012560163935\n",
      "Epoch 34::Minibatch 579::LR 0.0238461538462 --> Loss 0.00117684861024\n",
      "Epoch 34::Minibatch 580::LR 0.0238461538462 --> Loss 0.00191381057103\n",
      "Epoch 34::Minibatch 581::LR 0.0238461538462 --> Loss 0.00170043508212\n",
      "Epoch 34::Minibatch 582::LR 0.0238461538462 --> Loss 0.00419844905535\n",
      "Epoch 34::Minibatch 583::LR 0.0238461538462 --> Loss 0.000953757067521\n",
      "Epoch 34::Minibatch 584::LR 0.0238461538462 --> Loss 0.00130945344766\n",
      "Epoch 34::Minibatch 585::LR 0.0238461538462 --> Loss 0.00387460271517\n",
      "Epoch 34::Minibatch 586::LR 0.0238461538462 --> Loss 0.00369643410047\n",
      "Epoch 34::Minibatch 587::LR 0.0238461538462 --> Loss 0.00110877394676\n",
      "Epoch 34::Minibatch 588::LR 0.0238461538462 --> Loss 0.00136213739713\n",
      "Epoch 34::Minibatch 589::LR 0.0238461538462 --> Loss 0.00271757225196\n",
      "Epoch 34::Minibatch 590::LR 0.0238461538462 --> Loss 0.00177381257216\n",
      "Epoch 34::Minibatch 591::LR 0.0238461538462 --> Loss 0.00264596422513\n",
      "Epoch 34::Minibatch 592::LR 0.0238461538462 --> Loss 0.00114323238532\n",
      "Epoch 34::Minibatch 593::LR 0.0238461538462 --> Loss 0.00243895729383\n",
      "Epoch 34::Minibatch 594::LR 0.0238461538462 --> Loss 0.00251914540927\n",
      "Epoch 34::Minibatch 595::LR 0.0238461538462 --> Loss 0.00303542296092\n",
      "Epoch 34::Minibatch 596::LR 0.0238461538462 --> Loss 0.00181903759638\n",
      "Epoch 34::Minibatch 597::LR 0.0238461538462 --> Loss 0.00115804493427\n",
      "Epoch 34::Minibatch 598::LR 0.0238461538462 --> Loss 0.00276752054691\n",
      "Epoch 34::Minibatch 599::LR 0.0238461538462 --> Loss 0.0017762507995\n",
      "Epoch 34::Minibatch 600::LR 0.0238461538462 --> Loss 0.00210310856501\n",
      "Epoch 34::Minibatch 601::LR 0.0238461538462 --> Loss 0.00369887868563\n",
      "Epoch 34::Minibatch 602::LR 0.0238461538462 --> Loss 0.0020743427674\n",
      "Epoch 34::Minibatch 603::LR 0.0238461538462 --> Loss 0.00260965585709\n",
      "Epoch 34::Minibatch 604::LR 0.0238461538462 --> Loss 0.00161913156509\n",
      "Epoch 34::Minibatch 605::LR 0.0238461538462 --> Loss 0.00225752393405\n",
      "Epoch 34::Minibatch 606::LR 0.0238461538462 --> Loss 0.00183478792508\n",
      "Epoch 34::Minibatch 607::LR 0.0238461538462 --> Loss 0.00082011555632\n",
      "Epoch 34::Minibatch 608::LR 0.0238461538462 --> Loss 0.00154109100501\n",
      "Epoch 34::Minibatch 609::LR 0.0238461538462 --> Loss 0.00242024878661\n",
      "Epoch 34::Minibatch 610::LR 0.0238461538462 --> Loss 0.00404499610265\n",
      "Epoch 34::Minibatch 611::LR 0.0238461538462 --> Loss 0.00268554190795\n",
      "Epoch 34::Minibatch 612::LR 0.0238461538462 --> Loss 0.000468690743049\n",
      "Epoch 34::Minibatch 613::LR 0.0238461538462 --> Loss 0.00131094952424\n",
      "Epoch 34::Minibatch 614::LR 0.0238461538462 --> Loss 0.00239157517751\n",
      "Epoch 34::Minibatch 615::LR 0.0238461538462 --> Loss 0.00164311865966\n",
      "Epoch 34::Minibatch 616::LR 0.0238461538462 --> Loss 0.000912518203259\n",
      "Epoch 34::Minibatch 617::LR 0.0238461538462 --> Loss 0.000490339150031\n",
      "Epoch 34::Minibatch 618::LR 0.0238461538462 --> Loss 0.00292085985343\n",
      "Epoch 34::Minibatch 619::LR 0.0238461538462 --> Loss 0.00192680001259\n",
      "Epoch 34::Minibatch 620::LR 0.0238461538462 --> Loss 0.00168017506599\n",
      "Epoch 34::Minibatch 621::LR 0.0238461538462 --> Loss 0.00084279914697\n",
      "Epoch 34::Minibatch 622::LR 0.0238461538462 --> Loss 0.000776863694191\n",
      "Epoch 34::Minibatch 623::LR 0.0238461538462 --> Loss 0.00221353332202\n",
      "Epoch 34::Minibatch 624::LR 0.0238461538462 --> Loss 0.0017596924305\n",
      "Epoch 34::Minibatch 625::LR 0.0238461538462 --> Loss 0.00262269059817\n",
      "Epoch 34::Minibatch 626::LR 0.0238461538462 --> Loss 0.00348549326261\n",
      "Epoch 34::Minibatch 627::LR 0.0238461538462 --> Loss 0.00126196761926\n",
      "Epoch 34::Minibatch 628::LR 0.0238461538462 --> Loss 0.00087407608827\n",
      "Epoch 34::Minibatch 629::LR 0.0238461538462 --> Loss 0.00301208058993\n",
      "Epoch 34::Minibatch 630::LR 0.0238461538462 --> Loss 0.00295232216517\n",
      "Epoch 34::Minibatch 631::LR 0.0238461538462 --> Loss 0.00499090711276\n",
      "Epoch 34::Minibatch 632::LR 0.0238461538462 --> Loss 0.00079505910476\n",
      "Epoch 34::Minibatch 633::LR 0.0238461538462 --> Loss 0.00160660356283\n",
      "Epoch 34::Minibatch 634::LR 0.0238461538462 --> Loss 0.00316227912903\n",
      "Epoch 34::Minibatch 635::LR 0.0238461538462 --> Loss 0.00535759449005\n",
      "Epoch 34::Minibatch 636::LR 0.0238461538462 --> Loss 0.00450373768806\n",
      "Epoch 34::Minibatch 637::LR 0.0238461538462 --> Loss 0.000705082416534\n",
      "Epoch 34::Minibatch 638::LR 0.0238461538462 --> Loss 0.0014853199323\n",
      "Epoch 34::Minibatch 639::LR 0.0238461538462 --> Loss 0.00316153526306\n",
      "Epoch 34::Minibatch 640::LR 0.0238461538462 --> Loss 0.00447239319483\n",
      "Epoch 34::Minibatch 641::LR 0.0238461538462 --> Loss 0.00301276624203\n",
      "Epoch 34::Minibatch 642::LR 0.0238461538462 --> Loss 0.000532301515341\n",
      "Epoch 34::Minibatch 643::LR 0.0238461538462 --> Loss 0.00230188866456\n",
      "Epoch 34::Minibatch 644::LR 0.0238461538462 --> Loss 0.00383988221486\n",
      "Epoch 34::Minibatch 645::LR 0.0238461538462 --> Loss 0.00450330853462\n",
      "Epoch 34::Minibatch 646::LR 0.0238461538462 --> Loss 0.00150950958331\n",
      "Epoch 34::Minibatch 647::LR 0.0238461538462 --> Loss 0.000460976312558\n",
      "Epoch 34::Minibatch 648::LR 0.0238461538462 --> Loss 0.00271621505419\n",
      "Epoch 34::Minibatch 649::LR 0.0238461538462 --> Loss 0.00313345253468\n",
      "Epoch 34::Minibatch 650::LR 0.0238461538462 --> Loss 0.00311053315798\n",
      "Epoch 34::Minibatch 651::LR 0.0238461538462 --> Loss 0.0013168173035\n",
      "Epoch 34::Minibatch 652::LR 0.0238461538462 --> Loss 0.000776987373829\n",
      "Epoch 34::Minibatch 653::LR 0.0238461538462 --> Loss 0.00278549671173\n",
      "Epoch 34::Minibatch 654::LR 0.0238461538462 --> Loss 0.00310810983181\n",
      "Epoch 34::Minibatch 655::LR 0.0238461538462 --> Loss 0.00365469574928\n",
      "Epoch 34::Minibatch 656::LR 0.0238461538462 --> Loss 0.000756515363852\n",
      "Epoch 34::Minibatch 657::LR 0.0238461538462 --> Loss 0.0022631897529\n",
      "Epoch 34::Minibatch 658::LR 0.0238461538462 --> Loss 0.00442203958829\n",
      "Epoch 34::Minibatch 659::LR 0.0238461538462 --> Loss 0.00219282885393\n",
      "Epoch 34::Minibatch 660::LR 0.0238461538462 --> Loss 0.00264249404271\n",
      "Epoch 34::Minibatch 661::LR 0.0238461538462 --> Loss 0.00223285516103\n",
      "Epoch 34::Minibatch 662::LR 0.0238461538462 --> Loss 0.00178945263227\n",
      "Epoch 34::Minibatch 663::LR 0.0238461538462 --> Loss 0.00363189578056\n",
      "Epoch 34::Minibatch 664::LR 0.0238461538462 --> Loss 0.00309756596883\n",
      "Epoch 34::Minibatch 665::LR 0.0238461538462 --> Loss 0.000692496548096\n",
      "Epoch 34::Minibatch 666::LR 0.0238461538462 --> Loss 0.00390269676844\n",
      "Epoch 34::Minibatch 667::LR 0.0238461538462 --> Loss 0.00254202703635\n",
      "Epoch 34::Minibatch 668::LR 0.0238461538462 --> Loss 0.00621091246605\n",
      "Epoch 34::Minibatch 669::LR 0.0238461538462 --> Loss 0.00107926934958\n",
      "Epoch 34::Minibatch 670::LR 0.0238461538462 --> Loss 0.00132432818413\n",
      "Epoch 34::Minibatch 671::LR 0.0238461538462 --> Loss 0.00503956715266\n",
      "Epoch 34::Minibatch 672::LR 0.0238461538462 --> Loss 0.00333115657171\n",
      "Epoch 34::Minibatch 673::LR 0.0238461538462 --> Loss 0.00159663875898\n",
      "Epoch 34::Minibatch 674::LR 0.0238461538462 --> Loss 0.000510001828273\n",
      "Epoch 34::Minibatch 675::LR 0.0238461538462 --> Loss 0.00219840049744\n",
      "Epoch 34::Minibatch 676::LR 0.0238461538462 --> Loss 0.00216562410196\n",
      "Epoch 34::Minibatch 677::LR 0.0238461538462 --> Loss 0.00268666168054\n",
      "Epoch 34::Minibatch 678::LR 0.0238461538462 --> Loss 0.0018551637729\n",
      "Epoch 34::Minibatch 679::LR 0.0238461538462 --> Loss 0.00328591605028\n",
      "Epoch 34::Minibatch 680::LR 0.0238461538462 --> Loss 0.00211724917094\n",
      "Epoch 34::Minibatch 681::LR 0.0238461538462 --> Loss 0.00236755172412\n",
      "Epoch 34::Minibatch 682::LR 0.0238461538462 --> Loss 0.000761948376894\n",
      "Epoch 34::Minibatch 683::LR 0.0238461538462 --> Loss 0.00228626092275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 684::LR 0.0238461538462 --> Loss 0.00234025458495\n",
      "Epoch 34::Minibatch 685::LR 0.0238461538462 --> Loss 0.00280531108379\n",
      "Epoch 34::Minibatch 686::LR 0.0238461538462 --> Loss 0.00158334225416\n",
      "Epoch 34::Minibatch 687::LR 0.0238461538462 --> Loss 0.000879815717538\n",
      "Epoch 34::Minibatch 688::LR 0.0238461538462 --> Loss 0.00280747036139\n",
      "Epoch 34::Minibatch 689::LR 0.0238461538462 --> Loss 0.00245801369349\n",
      "Epoch 34::Minibatch 690::LR 0.0238461538462 --> Loss 0.0018676173687\n",
      "Epoch 34::Minibatch 691::LR 0.0238461538462 --> Loss 0.000657535543044\n",
      "Epoch 34::Minibatch 692::LR 0.0238461538462 --> Loss 0.00243888000647\n",
      "Epoch 34::Minibatch 693::LR 0.0238461538462 --> Loss 0.0026223830382\n",
      "Epoch 34::Minibatch 694::LR 0.0238461538462 --> Loss 0.00298357864221\n",
      "Epoch 34::Minibatch 695::LR 0.0238461538462 --> Loss 0.00180514017741\n",
      "Epoch 34::Minibatch 696::LR 0.0238461538462 --> Loss 0.00202529291312\n",
      "Epoch 34::Minibatch 697::LR 0.0238461538462 --> Loss 0.00139785309633\n",
      "Epoch 34::Minibatch 698::LR 0.0238461538462 --> Loss 0.0016650801897\n",
      "Epoch 34::Minibatch 699::LR 0.0238461538462 --> Loss 0.00367707649867\n",
      "Epoch 34::Minibatch 700::LR 0.0238461538462 --> Loss 0.00255423486233\n",
      "Epoch 34::Minibatch 701::LR 0.0238461538462 --> Loss 0.00187161763509\n",
      "Epoch 34::Minibatch 702::LR 0.0238461538462 --> Loss 0.00166846474012\n",
      "Epoch 34::Minibatch 703::LR 0.0238461538462 --> Loss 0.00428237160047\n",
      "Epoch 34::Minibatch 704::LR 0.0238461538462 --> Loss 0.00180407504241\n",
      "Epoch 34::Minibatch 705::LR 0.0238461538462 --> Loss 0.00282575905323\n",
      "Epoch 34::Minibatch 706::LR 0.0238461538462 --> Loss 0.0021929649512\n",
      "Epoch 34::Minibatch 707::LR 0.0238461538462 --> Loss 0.00118086685737\n",
      "Epoch 34::Minibatch 708::LR 0.0238461538462 --> Loss 0.00173021753629\n",
      "Epoch 34::Minibatch 709::LR 0.0238461538462 --> Loss 0.00166787664096\n",
      "Epoch 34::Minibatch 710::LR 0.0238461538462 --> Loss 0.00258918980757\n",
      "Epoch 34::Minibatch 711::LR 0.0238461538462 --> Loss 0.00198451181253\n",
      "Epoch 34::Minibatch 712::LR 0.0238461538462 --> Loss 0.00136961956819\n",
      "Epoch 34::Minibatch 713::LR 0.0238461538462 --> Loss 0.00180289447308\n",
      "Epoch 34::Minibatch 714::LR 0.0238461538462 --> Loss 0.00287843306859\n",
      "Epoch 34::Minibatch 715::LR 0.0238461538462 --> Loss 0.0029194800059\n",
      "Epoch 34::Minibatch 716::LR 0.0238461538462 --> Loss 0.00167068958282\n",
      "Epoch 34::Minibatch 717::LR 0.0238461538462 --> Loss 0.00167616724968\n",
      "Epoch 34::Minibatch 718::LR 0.0238461538462 --> Loss 0.00128530879815\n",
      "Epoch 34::Minibatch 719::LR 0.0238461538462 --> Loss 0.00173575103283\n",
      "Epoch 34::Minibatch 720::LR 0.0238461538462 --> Loss 0.00279503424962\n",
      "Epoch 34::Minibatch 721::LR 0.0238461538462 --> Loss 0.00060453414917\n",
      "Epoch 34::Minibatch 722::LR 0.0238461538462 --> Loss 0.00456141789754\n",
      "Epoch 34::Minibatch 723::LR 0.0238461538462 --> Loss 0.00479801615079\n",
      "Epoch 34::Minibatch 724::LR 0.0238461538462 --> Loss 0.000964564780394\n",
      "Epoch 34::Minibatch 725::LR 0.0238461538462 --> Loss 0.00203685462475\n",
      "Epoch 34::Minibatch 726::LR 0.0238461538462 --> Loss 0.00352022488912\n",
      "Epoch 34::Minibatch 727::LR 0.0238461538462 --> Loss 0.00300222555796\n",
      "Epoch 34::Minibatch 728::LR 0.0238461538462 --> Loss 0.000641255875429\n",
      "Epoch 34::Minibatch 729::LR 0.0238461538462 --> Loss 0.000714536408583\n",
      "Epoch 34::Minibatch 730::LR 0.0238461538462 --> Loss 0.00290200630824\n",
      "Epoch 34::Minibatch 731::LR 0.0238461538462 --> Loss 0.00262670000394\n",
      "Epoch 34::Minibatch 732::LR 0.0238461538462 --> Loss 0.00201239128908\n",
      "Epoch 34::Minibatch 733::LR 0.0238461538462 --> Loss 0.00058521370093\n",
      "Epoch 34::Minibatch 734::LR 0.0238461538462 --> Loss 0.00162928084532\n",
      "Epoch 34::Minibatch 735::LR 0.0238461538462 --> Loss 0.00249849776427\n",
      "Epoch 34::Minibatch 736::LR 0.0238461538462 --> Loss 0.0034746436278\n",
      "Epoch 34::Minibatch 737::LR 0.0238461538462 --> Loss 0.00289175351461\n",
      "Epoch 34::Minibatch 738::LR 0.0238461538462 --> Loss 0.00135610272487\n",
      "Epoch 34::Minibatch 739::LR 0.0238461538462 --> Loss 0.00235309143861\n",
      "Epoch 34::Minibatch 740::LR 0.0238461538462 --> Loss 0.003744272391\n",
      "Epoch 34::Minibatch 741::LR 0.0238461538462 --> Loss 0.00250571052233\n",
      "Epoch 34::Minibatch 742::LR 0.0238461538462 --> Loss 0.00206580062707\n",
      "Epoch 34::Minibatch 743::LR 0.0238461538462 --> Loss 0.00151629060507\n",
      "Epoch 34::Minibatch 744::LR 0.0238461538462 --> Loss 0.00188444236914\n",
      "Epoch 34::Minibatch 745::LR 0.0238461538462 --> Loss 0.0027606566747\n",
      "Epoch 34::Minibatch 746::LR 0.0238461538462 --> Loss 0.00282472372055\n",
      "Epoch 34::Minibatch 747::LR 0.0238461538462 --> Loss 0.00175021052361\n",
      "Epoch 34::Minibatch 748::LR 0.0238461538462 --> Loss 0.000621865640084\n",
      "Epoch 34::Minibatch 749::LR 0.0238461538462 --> Loss 0.00168000161648\n",
      "Epoch 34::Minibatch 750::LR 0.0238461538462 --> Loss 0.00240993559361\n",
      "Epoch 34::Minibatch 751::LR 0.0238461538462 --> Loss 0.00295321822166\n",
      "Epoch 34::Minibatch 752::LR 0.0238461538462 --> Loss 0.00148000369469\n",
      "Epoch 34::Minibatch 753::LR 0.0238461538462 --> Loss 0.00219342490037\n",
      "Epoch 34::Minibatch 754::LR 0.0238461538462 --> Loss 0.00242242852847\n",
      "Epoch 34::Minibatch 755::LR 0.0238461538462 --> Loss 0.00265629331271\n",
      "Epoch 34::Minibatch 756::LR 0.0238461538462 --> Loss 0.00129425684611\n",
      "Epoch 34::Minibatch 757::LR 0.0238461538462 --> Loss 0.000578840424617\n",
      "Epoch 34::Minibatch 758::LR 0.0238461538462 --> Loss 0.00155982544025\n",
      "Epoch 34::Minibatch 759::LR 0.0238461538462 --> Loss 0.00335180521011\n",
      "Epoch 34::Minibatch 760::LR 0.0238461538462 --> Loss 0.00276464184125\n",
      "Epoch 34::Minibatch 761::LR 0.0238461538462 --> Loss 0.0054787059625\n",
      "Epoch 34::Minibatch 762::LR 0.0238461538462 --> Loss 0.00351401726405\n",
      "Epoch 34::Minibatch 763::LR 0.0238461538462 --> Loss 0.00340767979622\n",
      "Epoch 34::Minibatch 764::LR 0.0238461538462 --> Loss 0.00300093154112\n",
      "Epoch 34::Minibatch 765::LR 0.0238461538462 --> Loss 0.00123726646105\n",
      "Epoch 34::Minibatch 766::LR 0.0238461538462 --> Loss 0.00229963461558\n",
      "Epoch 34::Minibatch 767::LR 0.0238461538462 --> Loss 0.00474260608355\n",
      "Epoch 34::Minibatch 768::LR 0.0238461538462 --> Loss 0.00362785696983\n",
      "Epoch 34::Minibatch 769::LR 0.0238461538462 --> Loss 0.00182396491369\n",
      "Epoch 34::Minibatch 770::LR 0.0238461538462 --> Loss 0.00151236365239\n",
      "Epoch 34::Minibatch 771::LR 0.0238461538462 --> Loss 0.00336158474286\n",
      "Epoch 34::Minibatch 772::LR 0.0238461538462 --> Loss 0.00364464243253\n",
      "Epoch 34::Minibatch 773::LR 0.0238461538462 --> Loss 0.00319440484047\n",
      "Epoch 34::Minibatch 774::LR 0.0238461538462 --> Loss 0.00189916948477\n",
      "Epoch 34::Minibatch 775::LR 0.0238461538462 --> Loss 0.00322551488876\n",
      "Epoch 34::Minibatch 776::LR 0.0238461538462 --> Loss 0.00383980989456\n",
      "Epoch 34::Minibatch 777::LR 0.0238461538462 --> Loss 0.00593140125275\n",
      "Epoch 34::Minibatch 778::LR 0.0238461538462 --> Loss 0.00698239723841\n",
      "Epoch 34::Minibatch 779::LR 0.0238461538462 --> Loss 0.00249504347642\n",
      "Epoch 34::Minibatch 780::LR 0.0238461538462 --> Loss 0.00149314691623\n",
      "Epoch 34::Minibatch 781::LR 0.0238461538462 --> Loss 0.00349561413129\n",
      "Epoch 34::Minibatch 782::LR 0.0238461538462 --> Loss 0.00381355365117\n",
      "Epoch 34::Minibatch 783::LR 0.0238461538462 --> Loss 0.00226197203\n",
      "Epoch 34::Minibatch 784::LR 0.0238461538462 --> Loss 0.000710698465506\n",
      "Epoch 34::Minibatch 785::LR 0.0238461538462 --> Loss 0.00340728839238\n",
      "Epoch 34::Minibatch 786::LR 0.0238461538462 --> Loss 0.00358510096868\n",
      "Epoch 34::Minibatch 787::LR 0.0238461538462 --> Loss 0.00256731371085\n",
      "Epoch 34::Minibatch 788::LR 0.0238461538462 --> Loss 0.00241742491722\n",
      "Epoch 34::Minibatch 789::LR 0.0238461538462 --> Loss 0.000723880777756\n",
      "Epoch 34::Minibatch 790::LR 0.0238461538462 --> Loss 0.00314958194892\n",
      "Epoch 34::Minibatch 791::LR 0.0238461538462 --> Loss 0.0032444669803\n",
      "Epoch 34::Minibatch 792::LR 0.0238461538462 --> Loss 0.0029820472002\n",
      "Epoch 34::Minibatch 793::LR 0.0238461538462 --> Loss 0.00163356492917\n",
      "Epoch 34::Minibatch 794::LR 0.0238461538462 --> Loss 0.000981809099515\n",
      "Epoch 34::Minibatch 795::LR 0.0238461538462 --> Loss 0.00262079974016\n",
      "Epoch 34::Minibatch 796::LR 0.0238461538462 --> Loss 0.00476105928421\n",
      "Epoch 34::Minibatch 797::LR 0.0238461538462 --> Loss 0.00563042442004\n",
      "Epoch 34::Minibatch 798::LR 0.0238461538462 --> Loss 0.00296841621399\n",
      "Epoch 34::Minibatch 799::LR 0.0238461538462 --> Loss 0.00224110126495\n",
      "Epoch 34::Minibatch 800::LR 0.0238461538462 --> Loss 0.00200033565362\n",
      "Epoch 34::Minibatch 801::LR 0.0238461538462 --> Loss 0.00381873289744\n",
      "Epoch 34::Minibatch 802::LR 0.0238461538462 --> Loss 0.00119394252698\n",
      "Epoch 34::Minibatch 803::LR 0.0238461538462 --> Loss 0.00295447051525\n",
      "Epoch 34::Minibatch 804::LR 0.0238461538462 --> Loss 0.00206568499406\n",
      "Epoch 34::Minibatch 805::LR 0.0238461538462 --> Loss 0.00217822015285\n",
      "Epoch 34::Minibatch 806::LR 0.0238461538462 --> Loss 0.00333240350087\n",
      "Epoch 34::Minibatch 807::LR 0.0238461538462 --> Loss 0.00306981245677\n",
      "Epoch 34::Minibatch 808::LR 0.0238461538462 --> Loss 0.00286356449127\n",
      "Epoch 34::Minibatch 809::LR 0.0238461538462 --> Loss 0.00302214125792\n",
      "Epoch 34::Minibatch 810::LR 0.0238461538462 --> Loss 0.00412481188774\n",
      "Epoch 34::Minibatch 811::LR 0.0238461538462 --> Loss 0.00396267652512\n",
      "Epoch 34::Minibatch 812::LR 0.0238461538462 --> Loss 0.00364870548248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 813::LR 0.0238461538462 --> Loss 0.00302019278208\n",
      "Epoch 34::Minibatch 814::LR 0.0238461538462 --> Loss 0.00151513506969\n",
      "Epoch 34::Minibatch 815::LR 0.0238461538462 --> Loss 0.00347191691399\n",
      "Epoch 34::Minibatch 816::LR 0.0238461538462 --> Loss 0.0039196284612\n",
      "Epoch 34::Minibatch 817::LR 0.0238461538462 --> Loss 0.00471862475077\n",
      "Epoch 34::Minibatch 818::LR 0.0238461538462 --> Loss 0.00123528520266\n",
      "Epoch 34::Minibatch 819::LR 0.0238461538462 --> Loss 0.000725173056126\n",
      "Epoch 34::Minibatch 820::LR 0.0238461538462 --> Loss 0.00503141641617\n",
      "Epoch 34::Minibatch 821::LR 0.0238461538462 --> Loss 0.00305824259917\n",
      "Epoch 34::Minibatch 822::LR 0.0238461538462 --> Loss 0.00366368850072\n",
      "Epoch 34::Minibatch 823::LR 0.0238461538462 --> Loss 0.00125507354736\n",
      "Epoch 34::Minibatch 824::LR 0.0238461538462 --> Loss 0.00136500000954\n",
      "Epoch 34::Minibatch 825::LR 0.0238461538462 --> Loss 0.00373893221219\n",
      "Epoch 34::Minibatch 826::LR 0.0238461538462 --> Loss 0.00441547552745\n",
      "Epoch 34::Minibatch 827::LR 0.0238461538462 --> Loss 0.00205560723941\n",
      "Epoch 34::Minibatch 828::LR 0.0238461538462 --> Loss 0.000486872990926\n",
      "Epoch 34::Minibatch 829::LR 0.0238461538462 --> Loss 0.00225891470909\n",
      "Epoch 34::Minibatch 830::LR 0.0238461538462 --> Loss 0.00395573536555\n",
      "Epoch 34::Minibatch 831::LR 0.0238461538462 --> Loss 0.00236758391062\n",
      "Epoch 34::Minibatch 832::LR 0.0238461538462 --> Loss 0.00208743194739\n",
      "Epoch 34::Minibatch 833::LR 0.0238461538462 --> Loss 0.00180835704009\n",
      "Epoch 34::Minibatch 834::LR 0.0238461538462 --> Loss 0.000789265433947\n",
      "Epoch 34::Minibatch 835::LR 0.0238461538462 --> Loss 0.0037938551108\n",
      "Epoch 34::Minibatch 836::LR 0.0238461538462 --> Loss 0.00356443246206\n",
      "Epoch 34::Minibatch 837::LR 0.0238461538462 --> Loss 0.00225173930327\n",
      "Epoch 34::Minibatch 838::LR 0.0238461538462 --> Loss 0.000646165211995\n",
      "Epoch 34::Minibatch 839::LR 0.0238461538462 --> Loss 0.00236472785473\n",
      "Epoch 34::Minibatch 840::LR 0.0238461538462 --> Loss 0.00283681631088\n",
      "Epoch 34::Minibatch 841::LR 0.0238461538462 --> Loss 0.00274636824926\n",
      "Epoch 34::Minibatch 842::LR 0.0238461538462 --> Loss 0.00209918657939\n",
      "Epoch 34::Minibatch 843::LR 0.0238461538462 --> Loss 0.00097102701664\n",
      "Epoch 34::Minibatch 844::LR 0.0238461538462 --> Loss 0.00146360228459\n",
      "Epoch 34::Minibatch 845::LR 0.0238461538462 --> Loss 0.00398101011912\n",
      "Epoch 34::Minibatch 846::LR 0.0238461538462 --> Loss 0.00166771411896\n",
      "Epoch 34::Minibatch 847::LR 0.0238461538462 --> Loss 0.00236238141855\n",
      "Epoch 34::Minibatch 848::LR 0.0238461538462 --> Loss 0.00112459570169\n",
      "Epoch 34::Minibatch 849::LR 0.0238461538462 --> Loss 0.00178303360939\n",
      "Epoch 34::Minibatch 850::LR 0.0238461538462 --> Loss 0.00314846217632\n",
      "Epoch 34::Minibatch 851::LR 0.0238461538462 --> Loss 0.00253034830093\n",
      "Epoch 34::Minibatch 852::LR 0.0238461538462 --> Loss 0.00113304764032\n",
      "Epoch 34::Minibatch 853::LR 0.0238461538462 --> Loss 0.0013039029638\n",
      "Epoch 34::Minibatch 854::LR 0.0238461538462 --> Loss 0.00252042988936\n",
      "Epoch 34::Minibatch 855::LR 0.0238461538462 --> Loss 0.00210207283497\n",
      "Epoch 34::Minibatch 856::LR 0.0238461538462 --> Loss 0.00177522102992\n",
      "Epoch 34::Minibatch 857::LR 0.0238461538462 --> Loss 0.00120615939299\n",
      "Epoch 34::Minibatch 858::LR 0.0238461538462 --> Loss 0.000600632429123\n",
      "Epoch 34::Minibatch 859::LR 0.0238461538462 --> Loss 0.0019793210427\n",
      "Epoch 34::Minibatch 860::LR 0.0238461538462 --> Loss 0.00130062252283\n",
      "Epoch 34::Minibatch 861::LR 0.0238461538462 --> Loss 0.00094575603803\n",
      "Epoch 34::Minibatch 862::LR 0.0238461538462 --> Loss 0.00371340592702\n",
      "Epoch 34::Minibatch 863::LR 0.0238461538462 --> Loss 0.00335515697797\n",
      "Epoch 34::Minibatch 864::LR 0.0238461538462 --> Loss 0.00259188711643\n",
      "Epoch 34::Minibatch 865::LR 0.0238461538462 --> Loss 0.0005156442523\n",
      "Epoch 34::Minibatch 866::LR 0.0238461538462 --> Loss 0.00207046826681\n",
      "Epoch 34::Minibatch 867::LR 0.0238461538462 --> Loss 0.00286282380422\n",
      "Epoch 34::Minibatch 868::LR 0.0238461538462 --> Loss 0.00242361446222\n",
      "Epoch 34::Minibatch 869::LR 0.0238461538462 --> Loss 0.00213369925817\n",
      "Epoch 34::Minibatch 870::LR 0.0238461538462 --> Loss 0.00322553098202\n",
      "Epoch 34::Minibatch 871::LR 0.0238461538462 --> Loss 0.00162493318319\n",
      "Epoch 34::Minibatch 872::LR 0.0238461538462 --> Loss 0.00210564017296\n",
      "Epoch 34::Minibatch 873::LR 0.0238461538462 --> Loss 0.00245280345281\n",
      "Epoch 34::Minibatch 874::LR 0.0238461538462 --> Loss 0.00507168531418\n",
      "Epoch 34::Minibatch 875::LR 0.0238461538462 --> Loss 0.000635219166676\n",
      "Epoch 34::Minibatch 876::LR 0.0238461538462 --> Loss 0.00270363509655\n",
      "Epoch 34::Minibatch 877::LR 0.0238461538462 --> Loss 0.00446592847506\n",
      "Epoch 34::Minibatch 878::LR 0.0238461538462 --> Loss 0.00291266242663\n",
      "Epoch 34::Minibatch 879::LR 0.0238461538462 --> Loss 0.00388713041941\n",
      "Epoch 34::Minibatch 880::LR 0.0238461538462 --> Loss 0.00485980510712\n",
      "Epoch 34::Minibatch 881::LR 0.0238461538462 --> Loss 0.00418136397998\n",
      "Epoch 34::Minibatch 882::LR 0.0238461538462 --> Loss 0.0019000385205\n",
      "Epoch 34::Minibatch 883::LR 0.0238461538462 --> Loss 0.00362289428711\n",
      "Epoch 34::Minibatch 884::LR 0.0238461538462 --> Loss 0.00279589354992\n",
      "Epoch 34::Minibatch 885::LR 0.0238461538462 --> Loss 0.00258463998636\n",
      "Epoch 34::Minibatch 886::LR 0.0238461538462 --> Loss 0.000436655481656\n",
      "Epoch 34::Minibatch 887::LR 0.0238461538462 --> Loss 0.00551511247953\n",
      "Epoch 34::Minibatch 888::LR 0.0238461538462 --> Loss 0.00243184804916\n",
      "Epoch 34::Minibatch 889::LR 0.0238461538462 --> Loss 0.0024907875061\n",
      "Epoch 34::Minibatch 890::LR 0.0238461538462 --> Loss 0.00358715136846\n",
      "Epoch 34::Minibatch 891::LR 0.0238461538462 --> Loss 0.00170414884885\n",
      "Epoch 34::Minibatch 892::LR 0.0238461538462 --> Loss 0.0007866089046\n",
      "Epoch 34::Minibatch 893::LR 0.0238461538462 --> Loss 0.00224248468876\n",
      "Epoch 34::Minibatch 894::LR 0.0238461538462 --> Loss 0.00196789900462\n",
      "Epoch 34::Minibatch 895::LR 0.0238461538462 --> Loss 0.00225850601991\n",
      "Epoch 34::Minibatch 896::LR 0.0238461538462 --> Loss 0.00124745001396\n",
      "Epoch 34::Minibatch 897::LR 0.0238461538462 --> Loss 0.000667193432649\n",
      "Epoch 34::Minibatch 898::LR 0.0238461538462 --> Loss 0.00196086088816\n",
      "Epoch 34::Minibatch 899::LR 0.0238461538462 --> Loss 0.00244342803955\n",
      "Epoch 34::Minibatch 900::LR 0.0238461538462 --> Loss 0.00303490360578\n",
      "Epoch 34::Minibatch 901::LR 0.0238461538462 --> Loss 0.000583085964123\n",
      "Epoch 34::Minibatch 902::LR 0.0238461538462 --> Loss 0.00138945500056\n",
      "Epoch 34::Minibatch 903::LR 0.0238461538462 --> Loss 0.00253778954347\n",
      "Epoch 34::Minibatch 904::LR 0.0238461538462 --> Loss 0.00179526766141\n",
      "Epoch 34::Minibatch 905::LR 0.0238461538462 --> Loss 0.00139022052288\n",
      "Epoch 34::Minibatch 906::LR 0.0238461538462 --> Loss 0.00101810405652\n",
      "Epoch 34::Minibatch 907::LR 0.0238461538462 --> Loss 0.00154051800569\n",
      "Epoch 34::Minibatch 908::LR 0.0238461538462 --> Loss 0.0020626493295\n",
      "Epoch 34::Minibatch 909::LR 0.0238461538462 --> Loss 0.00192399044832\n",
      "Epoch 34::Minibatch 910::LR 0.0238461538462 --> Loss 0.000839730203152\n",
      "Epoch 34::Minibatch 911::LR 0.0238461538462 --> Loss 0.00127146671216\n",
      "Epoch 34::Minibatch 912::LR 0.0238461538462 --> Loss 0.00205626746019\n",
      "Epoch 34::Minibatch 913::LR 0.0238461538462 --> Loss 0.00227935612202\n",
      "Epoch 34::Minibatch 914::LR 0.0238461538462 --> Loss 0.00124854703744\n",
      "Epoch 34::Minibatch 915::LR 0.0238461538462 --> Loss 0.000532297790051\n",
      "Epoch 34::Minibatch 916::LR 0.0238461538462 --> Loss 0.00200996160507\n",
      "Epoch 34::Minibatch 917::LR 0.0238461538462 --> Loss 0.00320096731186\n",
      "Epoch 34::Minibatch 918::LR 0.0238461538462 --> Loss 0.00464916547139\n",
      "Epoch 34::Minibatch 919::LR 0.0238461538462 --> Loss 0.000542861322562\n",
      "Epoch 34::Minibatch 920::LR 0.0238461538462 --> Loss 0.0120738212268\n",
      "Epoch 34::Minibatch 921::LR 0.0238461538462 --> Loss 0.00299428701401\n",
      "Epoch 34::Minibatch 922::LR 0.0238461538462 --> Loss 0.00298811753591\n",
      "Epoch 34::Minibatch 923::LR 0.0238461538462 --> Loss 0.00114305516084\n",
      "Epoch 34::Minibatch 924::LR 0.0238461538462 --> Loss 0.00313737908999\n",
      "Epoch 34::Minibatch 925::LR 0.0238461538462 --> Loss 0.00220091164112\n",
      "Epoch 34::Minibatch 926::LR 0.0238461538462 --> Loss 0.0045114270846\n",
      "Epoch 34::Minibatch 927::LR 0.0238461538462 --> Loss 0.00499131679535\n",
      "Epoch 34::Minibatch 928::LR 0.0238461538462 --> Loss 0.0058870947361\n",
      "Epoch 34::Minibatch 929::LR 0.0238461538462 --> Loss 0.00516490499179\n",
      "Epoch 34::Minibatch 930::LR 0.0238461538462 --> Loss 0.00921631336212\n",
      "Epoch 34::Minibatch 931::LR 0.0238461538462 --> Loss 0.00298465867837\n",
      "Epoch 34::Minibatch 932::LR 0.0238461538462 --> Loss 0.00514606118202\n",
      "Epoch 34::Minibatch 933::LR 0.0238461538462 --> Loss 0.00232863942782\n",
      "Epoch 34::Minibatch 934::LR 0.0238461538462 --> Loss 0.00294835666815\n",
      "Epoch 34::Minibatch 935::LR 0.0238461538462 --> Loss 0.00442685961723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34::Minibatch 936::LR 0.0238461538462 --> Loss 0.000848444004854\n",
      "Epoch 34::Minibatch 937::LR 0.0238461538462 --> Loss 0.00231600443522\n",
      "Epoch 34::Minibatch 938::LR 0.0238461538462 --> Loss 0.00196341077487\n",
      "Epoch 34::Minibatch 939::LR 0.0238461538462 --> Loss 0.0021546036005\n",
      "Epoch 34::Minibatch 940::LR 0.0238461538462 --> Loss 0.000914585093657\n",
      "Epoch 34::Minibatch 941::LR 0.0238461538462 --> Loss 0.000740846246481\n",
      "Epoch 34::Minibatch 942::LR 0.0238461538462 --> Loss 0.00251867175102\n",
      "Epoch 34::Minibatch 943::LR 0.0238461538462 --> Loss 0.00230443080266\n",
      "Epoch 34::Minibatch 944::LR 0.0238461538462 --> Loss 0.00165388196707\n",
      "Epoch 34::Minibatch 945::LR 0.0238461538462 --> Loss 0.000916164120038\n",
      "Epoch 34::Minibatch 946::LR 0.0238461538462 --> Loss 0.00235573649406\n",
      "Epoch 34::Minibatch 947::LR 0.0238461538462 --> Loss 0.00219558616479\n",
      "Epoch 34::Minibatch 948::LR 0.0238461538462 --> Loss 0.00393968780835\n",
      "Epoch 34::Minibatch 949::LR 0.0238461538462 --> Loss 0.00169776101907\n",
      "Epoch 34::Minibatch 950::LR 0.0238461538462 --> Loss 0.000687809884548\n",
      "Epoch 34::Minibatch 951::LR 0.0238461538462 --> Loss 0.00334157864253\n",
      "Epoch 34::Minibatch 952::LR 0.0238461538462 --> Loss 0.00232734461625\n",
      "Epoch 34::Minibatch 953::LR 0.0238461538462 --> Loss 0.00141243845224\n",
      "Epoch 34::Minibatch 954::LR 0.0238461538462 --> Loss 0.000930829147498\n",
      "Epoch 34::Minibatch 955::LR 0.0238461538462 --> Loss 0.00255172510942\n",
      "Epoch 34::Minibatch 956::LR 0.0238461538462 --> Loss 0.00305007656415\n",
      "Epoch 34::Minibatch 957::LR 0.0238461538462 --> Loss 0.00182294428349\n",
      "Epoch 34::Minibatch 958::LR 0.0238461538462 --> Loss 0.00217795232932\n",
      "Epoch 34::Minibatch 959::LR 0.0238461538462 --> Loss 0.00250179886818\n",
      "Epoch 34::Minibatch 960::LR 0.0238461538462 --> Loss 0.00529338955879\n",
      "Epoch 34::Minibatch 961::LR 0.0238461538462 --> Loss 0.00293246746063\n",
      "Epoch 34::Minibatch 962::LR 0.0238461538462 --> Loss 0.00229875087738\n",
      "Epoch 34::Minibatch 963::LR 0.0238461538462 --> Loss 0.00103714644909\n",
      "Epoch 34::Minibatch 964::LR 0.0238461538462 --> Loss 0.00231729010741\n",
      "Epoch 34::Minibatch 965::LR 0.0238461538462 --> Loss 0.00621607383092\n",
      "Epoch 34::Minibatch 966::LR 0.0238461538462 --> Loss 0.0048354446888\n",
      "Epoch 34::Minibatch 967::LR 0.0238461538462 --> Loss 0.00123858571053\n",
      "Epoch 34::Minibatch 968::LR 0.0238461538462 --> Loss 0.000999897221724\n",
      "Epoch 34::Minibatch 969::LR 0.0238461538462 --> Loss 0.00442497928937\n",
      "Epoch 34::Minibatch 970::LR 0.0238461538462 --> Loss 0.00426021695137\n",
      "Epoch 34::Minibatch 971::LR 0.0238461538462 --> Loss 0.00325922310352\n",
      "Epoch 34::Minibatch 972::LR 0.0238461538462 --> Loss 0.00764428933462\n",
      "Epoch 34::Minibatch 973::LR 0.0238461538462 --> Loss 0.00934925317764\n",
      "Epoch 34::Minibatch 974::LR 0.0238461538462 --> Loss 0.00803764263789\n",
      "Epoch 34::Minibatch 975::LR 0.0238461538462 --> Loss 0.00472989797592\n",
      "Epoch 34::Minibatch 976::LR 0.0238461538462 --> Loss 0.00356992999713\n",
      "Epoch 34::Minibatch 977::LR 0.0238461538462 --> Loss 0.00324410676956\n",
      "Epoch 34::Minibatch 978::LR 0.0238461538462 --> Loss 0.00315083821615\n",
      "Epoch 34::Minibatch 979::LR 0.0238461538462 --> Loss 0.00289156575998\n",
      "Epoch 34::Minibatch 980::LR 0.0238461538462 --> Loss 0.0033189624548\n",
      "Epoch 34::Minibatch 981::LR 0.0238461538462 --> Loss 0.00405647913615\n",
      "Epoch 34::Minibatch 982::LR 0.0238461538462 --> Loss 0.00394551038742\n",
      "Epoch 34::Minibatch 983::LR 0.0238461538462 --> Loss 0.00239258448283\n",
      "Epoch 34::Minibatch 984::LR 0.0238461538462 --> Loss 0.00162493288517\n",
      "Epoch 34::Minibatch 985::LR 0.0238461538462 --> Loss 0.00309736271699\n",
      "Epoch 34::Minibatch 986::LR 0.0238461538462 --> Loss 0.00279665450255\n",
      "Epoch 34::Minibatch 987::LR 0.0238461538462 --> Loss 0.00314496239026\n",
      "Epoch 34::Minibatch 988::LR 0.0238461538462 --> Loss 0.00247207144896\n",
      "Epoch 34::Minibatch 989::LR 0.0238461538462 --> Loss 0.00279226124287\n",
      "Epoch 34::Minibatch 990::LR 0.0238461538462 --> Loss 0.00265067338943\n",
      "Epoch 34::Minibatch 991::LR 0.0238461538462 --> Loss 0.0013017787536\n",
      "Epoch 34::Minibatch 992::LR 0.0238461538462 --> Loss 0.00156415720781\n",
      "Epoch 34::Minibatch 993::LR 0.0238461538462 --> Loss 0.00288289388021\n",
      "Epoch 34::Minibatch 994::LR 0.0238461538462 --> Loss 0.00191669642925\n",
      "Epoch 34::Minibatch 995::LR 0.0238461538462 --> Loss 0.000772761801879\n",
      "Epoch 34::Minibatch 996::LR 0.0238461538462 --> Loss 0.00258670707544\n",
      "Epoch 34::Minibatch 997::LR 0.0238461538462 --> Loss 0.00216240306695\n",
      "Epoch 34::Minibatch 998::LR 0.0238461538462 --> Loss 0.00245967149734\n",
      "Epoch 34::Minibatch 999::LR 0.0238461538462 --> Loss 0.00210789700349\n",
      "Epoch 34::Minibatch 1000::LR 0.0238461538462 --> Loss 0.00256767431895\n",
      "Epoch 34::Minibatch 1001::LR 0.0238461538462 --> Loss 0.00202963670095\n",
      "Epoch 34::Minibatch 1002::LR 0.0238461538462 --> Loss 0.00145664443572\n",
      "Epoch 34::Minibatch 1003::LR 0.0238461538462 --> Loss 0.00239453792572\n",
      "Epoch 34::Minibatch 1004::LR 0.0238461538462 --> Loss 0.00106233656406\n",
      "Epoch 34::Minibatch 1005::LR 0.0238461538462 --> Loss 0.00253419836362\n",
      "Epoch 34::Minibatch 1006::LR 0.0238461538462 --> Loss 0.00129099965096\n",
      "Epoch 34::Minibatch 1007::LR 0.0238461538462 --> Loss 0.0017184082667\n",
      "Epoch 34::Minibatch 1008::LR 0.0238461538462 --> Loss 0.000915831923485\n",
      "Epoch 34::Minibatch 1009::LR 0.0238461538462 --> Loss 0.00121768534184\n",
      "Epoch 34::Minibatch 1010::LR 0.0238461538462 --> Loss 0.00115544706583\n",
      "Epoch 34::Minibatch 1011::LR 0.0238461538462 --> Loss 0.00156029393276\n",
      "Epoch 34::Minibatch 1012::LR 0.0238461538462 --> Loss 0.0013599828879\n",
      "Epoch 34::Minibatch 1013::LR 0.0238461538462 --> Loss 0.00339166879654\n",
      "Epoch 34::Minibatch 1014::LR 0.0238461538462 --> Loss 0.0031504325072\n",
      "Epoch 34::Minibatch 1015::LR 0.0238461538462 --> Loss 0.00151421576738\n",
      "Epoch 34::Minibatch 1016::LR 0.0238461538462 --> Loss 0.00439969539642\n",
      "Epoch 34::Minibatch 1017::LR 0.0238461538462 --> Loss 0.00312890708447\n",
      "Epoch 34::Minibatch 1018::LR 0.0238461538462 --> Loss 0.00244606892268\n",
      "Epoch 34::Minibatch 1019::LR 0.0238461538462 --> Loss 0.00152173986038\n",
      "Epoch 34::Minibatch 1020::LR 0.0238461538462 --> Loss 0.00165998518467\n",
      "Epoch 34::Minibatch 1021::LR 0.0238461538462 --> Loss 0.00179342031479\n",
      "Epoch 34::Minibatch 1022::LR 0.0238461538462 --> Loss 0.00130818992853\n",
      "Epoch 34::Minibatch 1023::LR 0.0238461538462 --> Loss 0.000980739196142\n",
      "Epoch 34::Minibatch 1024::LR 0.0238461538462 --> Loss 0.000983811318874\n",
      "Epoch 34::Minibatch 1025::LR 0.0238461538462 --> Loss 0.0013541657726\n",
      "Epoch 34::Minibatch 1026::LR 0.0238461538462 --> Loss 0.000685848891735\n",
      "Epoch 34::Minibatch 1027::LR 0.0238461538462 --> Loss 0.000965854724248\n",
      "Epoch 34::Minibatch 1028::LR 0.0238461538462 --> Loss 0.000714608480533\n",
      "Epoch 34::Minibatch 1029::LR 0.0238461538462 --> Loss 0.000739058007797\n",
      "Epoch 34::Minibatch 1030::LR 0.0238461538462 --> Loss 0.000895044306914\n",
      "Epoch 34::Minibatch 1031::LR 0.0238461538462 --> Loss 0.000679592440526\n",
      "Epoch 34::Minibatch 1032::LR 0.0238461538462 --> Loss 0.000771165788174\n",
      "Epoch 34::Minibatch 1033::LR 0.0238461538462 --> Loss 0.000656823019187\n",
      "Epoch 34::Minibatch 1034::LR 0.0238461538462 --> Loss 0.000623361865679\n",
      "Epoch 34::Minibatch 1035::LR 0.0238461538462 --> Loss 0.00040640493234\n",
      "Epoch 34::Minibatch 1036::LR 0.0238461538462 --> Loss 0.000324082672596\n",
      "Epoch 34::Minibatch 1037::LR 0.0238461538462 --> Loss 0.000611348897219\n",
      "Epoch 34::Minibatch 1038::LR 0.0238461538462 --> Loss 0.00102519045273\n",
      "Epoch 34::Minibatch 1039::LR 0.0238461538462 --> Loss 0.000862453579903\n",
      "Epoch 34::Minibatch 1040::LR 0.0238461538462 --> Loss 0.000337138026953\n",
      "Epoch 34::Minibatch 1041::LR 0.0238461538462 --> Loss 0.00048356756568\n",
      "Epoch 35::Minibatch 1::LR 0.0215384615385 --> Loss 0.00734466393789\n",
      "Epoch 35::Minibatch 2::LR 0.0215384615385 --> Loss 0.0045659617583\n",
      "Epoch 35::Minibatch 3::LR 0.0215384615385 --> Loss 0.00285775502523\n",
      "Epoch 35::Minibatch 4::LR 0.0215384615385 --> Loss 0.00370230436325\n",
      "Epoch 35::Minibatch 5::LR 0.0215384615385 --> Loss 0.00430188258489\n",
      "Epoch 35::Minibatch 6::LR 0.0215384615385 --> Loss 0.00200969258944\n",
      "Epoch 35::Minibatch 7::LR 0.0215384615385 --> Loss 0.00696684439977\n",
      "Epoch 35::Minibatch 8::LR 0.0215384615385 --> Loss 0.006471499602\n",
      "Epoch 35::Minibatch 9::LR 0.0215384615385 --> Loss 0.00506649295489\n",
      "Epoch 35::Minibatch 10::LR 0.0215384615385 --> Loss 0.00227134346962\n",
      "Epoch 35::Minibatch 11::LR 0.0215384615385 --> Loss 0.00214614629745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 12::LR 0.0215384615385 --> Loss 0.00330705781778\n",
      "Epoch 35::Minibatch 13::LR 0.0215384615385 --> Loss 0.00528409401576\n",
      "Epoch 35::Minibatch 14::LR 0.0215384615385 --> Loss 0.00526254177094\n",
      "Epoch 35::Minibatch 15::LR 0.0215384615385 --> Loss 0.00455725709597\n",
      "Epoch 35::Minibatch 16::LR 0.0215384615385 --> Loss 0.000695977707704\n",
      "Epoch 35::Minibatch 17::LR 0.0215384615385 --> Loss 0.0032120035092\n",
      "Epoch 35::Minibatch 18::LR 0.0215384615385 --> Loss 0.00269027968248\n",
      "Epoch 35::Minibatch 19::LR 0.0215384615385 --> Loss 0.00165611038605\n",
      "Epoch 35::Minibatch 20::LR 0.0215384615385 --> Loss 0.00219840367635\n",
      "Epoch 35::Minibatch 21::LR 0.0215384615385 --> Loss 0.00343715429306\n",
      "Epoch 35::Minibatch 22::LR 0.0215384615385 --> Loss 0.00223191579183\n",
      "Epoch 35::Minibatch 23::LR 0.0215384615385 --> Loss 0.000957296689351\n",
      "Epoch 35::Minibatch 24::LR 0.0215384615385 --> Loss 0.000542762627204\n",
      "Epoch 35::Minibatch 25::LR 0.0215384615385 --> Loss 0.00142338365316\n",
      "Epoch 35::Minibatch 26::LR 0.0215384615385 --> Loss 0.00161655386289\n",
      "Epoch 35::Minibatch 27::LR 0.0215384615385 --> Loss 0.00124685714642\n",
      "Epoch 35::Minibatch 28::LR 0.0215384615385 --> Loss 0.000547161201636\n",
      "Epoch 35::Minibatch 29::LR 0.0215384615385 --> Loss 0.000687648355961\n",
      "Epoch 35::Minibatch 30::LR 0.0215384615385 --> Loss 0.00120944003264\n",
      "Epoch 35::Minibatch 31::LR 0.0215384615385 --> Loss 0.00167987108231\n",
      "Epoch 35::Minibatch 32::LR 0.0215384615385 --> Loss 0.00147146721681\n",
      "Epoch 35::Minibatch 33::LR 0.0215384615385 --> Loss 0.000836853484313\n",
      "Epoch 35::Minibatch 34::LR 0.0215384615385 --> Loss 0.00202431559563\n",
      "Epoch 35::Minibatch 35::LR 0.0215384615385 --> Loss 0.00270174721877\n",
      "Epoch 35::Minibatch 36::LR 0.0215384615385 --> Loss 0.00224939425786\n",
      "Epoch 35::Minibatch 37::LR 0.0215384615385 --> Loss 0.000754752755165\n",
      "Epoch 35::Minibatch 38::LR 0.0215384615385 --> Loss 0.000768370678027\n",
      "Epoch 35::Minibatch 39::LR 0.0215384615385 --> Loss 0.00209102968375\n",
      "Epoch 35::Minibatch 40::LR 0.0215384615385 --> Loss 0.00305791874727\n",
      "Epoch 35::Minibatch 41::LR 0.0215384615385 --> Loss 0.00241355895996\n",
      "Epoch 35::Minibatch 42::LR 0.0215384615385 --> Loss 0.0040799677372\n",
      "Epoch 35::Minibatch 43::LR 0.0215384615385 --> Loss 0.00205298821131\n",
      "Epoch 35::Minibatch 44::LR 0.0215384615385 --> Loss 0.00344805757205\n",
      "Epoch 35::Minibatch 45::LR 0.0215384615385 --> Loss 0.00244567076365\n",
      "Epoch 35::Minibatch 46::LR 0.0215384615385 --> Loss 0.00297531326612\n",
      "Epoch 35::Minibatch 47::LR 0.0215384615385 --> Loss 0.00307166953882\n",
      "Epoch 35::Minibatch 48::LR 0.0215384615385 --> Loss 0.00450831333796\n",
      "Epoch 35::Minibatch 49::LR 0.0215384615385 --> Loss 0.00517147461573\n",
      "Epoch 35::Minibatch 50::LR 0.0215384615385 --> Loss 0.00586901942889\n",
      "Epoch 35::Minibatch 51::LR 0.0215384615385 --> Loss 0.00391313234965\n",
      "Epoch 35::Minibatch 52::LR 0.0215384615385 --> Loss 0.00336387832959\n",
      "Epoch 35::Minibatch 53::LR 0.0215384615385 --> Loss 0.00336312333743\n",
      "Epoch 35::Minibatch 54::LR 0.0215384615385 --> Loss 0.00395595232646\n",
      "Epoch 35::Minibatch 55::LR 0.0215384615385 --> Loss 0.000998182197412\n",
      "Epoch 35::Minibatch 56::LR 0.0215384615385 --> Loss 0.00275991678238\n",
      "Epoch 35::Minibatch 57::LR 0.0215384615385 --> Loss 0.00440518140793\n",
      "Epoch 35::Minibatch 58::LR 0.0215384615385 --> Loss 0.00316849529743\n",
      "Epoch 35::Minibatch 59::LR 0.0215384615385 --> Loss 0.00243649741014\n",
      "Epoch 35::Minibatch 60::LR 0.0215384615385 --> Loss 0.00251534859339\n",
      "Epoch 35::Minibatch 61::LR 0.0215384615385 --> Loss 0.000698569665353\n",
      "Epoch 35::Minibatch 62::LR 0.0215384615385 --> Loss 0.00241673012575\n",
      "Epoch 35::Minibatch 63::LR 0.0215384615385 --> Loss 0.00206254303455\n",
      "Epoch 35::Minibatch 64::LR 0.0215384615385 --> Loss 0.00080933680137\n",
      "Epoch 35::Minibatch 65::LR 0.0215384615385 --> Loss 0.00209845761458\n",
      "Epoch 35::Minibatch 66::LR 0.0215384615385 --> Loss 0.00282226542632\n",
      "Epoch 35::Minibatch 67::LR 0.0215384615385 --> Loss 0.00243587831656\n",
      "Epoch 35::Minibatch 68::LR 0.0215384615385 --> Loss 0.00180354992549\n",
      "Epoch 35::Minibatch 69::LR 0.0215384615385 --> Loss 0.00352483590444\n",
      "Epoch 35::Minibatch 70::LR 0.0215384615385 --> Loss 0.00315845429897\n",
      "Epoch 35::Minibatch 71::LR 0.0215384615385 --> Loss 0.00221469918887\n",
      "Epoch 35::Minibatch 72::LR 0.0215384615385 --> Loss 0.000550672014554\n",
      "Epoch 35::Minibatch 73::LR 0.0215384615385 --> Loss 0.00360961039861\n",
      "Epoch 35::Minibatch 74::LR 0.0215384615385 --> Loss 0.00392733295759\n",
      "Epoch 35::Minibatch 75::LR 0.0215384615385 --> Loss 0.00197848379612\n",
      "Epoch 35::Minibatch 76::LR 0.0215384615385 --> Loss 0.000516423930724\n",
      "Epoch 35::Minibatch 77::LR 0.0215384615385 --> Loss 0.00322142839432\n",
      "Epoch 35::Minibatch 78::LR 0.0215384615385 --> Loss 0.00401239871979\n",
      "Epoch 35::Minibatch 79::LR 0.0215384615385 --> Loss 0.00163880904516\n",
      "Epoch 35::Minibatch 80::LR 0.0215384615385 --> Loss 0.00271659652392\n",
      "Epoch 35::Minibatch 81::LR 0.0215384615385 --> Loss 0.00244503041108\n",
      "Epoch 35::Minibatch 82::LR 0.0215384615385 --> Loss 0.00176920851072\n",
      "Epoch 35::Minibatch 83::LR 0.0215384615385 --> Loss 0.00368132154147\n",
      "Epoch 35::Minibatch 84::LR 0.0215384615385 --> Loss 0.00180619438489\n",
      "Epoch 35::Minibatch 85::LR 0.0215384615385 --> Loss 0.00243703564008\n",
      "Epoch 35::Minibatch 86::LR 0.0215384615385 --> Loss 0.00204830308755\n",
      "Epoch 35::Minibatch 87::LR 0.0215384615385 --> Loss 0.00213775197665\n",
      "Epoch 35::Minibatch 88::LR 0.0215384615385 --> Loss 0.00162782977025\n",
      "Epoch 35::Minibatch 89::LR 0.0215384615385 --> Loss 0.00214915891488\n",
      "Epoch 35::Minibatch 90::LR 0.0215384615385 --> Loss 0.00104139963786\n",
      "Epoch 35::Minibatch 91::LR 0.0215384615385 --> Loss 0.000877748727798\n",
      "Epoch 35::Minibatch 92::LR 0.0215384615385 --> Loss 0.00250253081322\n",
      "Epoch 35::Minibatch 93::LR 0.0215384615385 --> Loss 0.00167099654675\n",
      "Epoch 35::Minibatch 94::LR 0.0215384615385 --> Loss 0.0017314461867\n",
      "Epoch 35::Minibatch 95::LR 0.0215384615385 --> Loss 0.00192086021105\n",
      "Epoch 35::Minibatch 96::LR 0.0215384615385 --> Loss 0.00443307042122\n",
      "Epoch 35::Minibatch 97::LR 0.0215384615385 --> Loss 0.00298744261265\n",
      "Epoch 35::Minibatch 98::LR 0.0215384615385 --> Loss 0.00110954582691\n",
      "Epoch 35::Minibatch 99::LR 0.0215384615385 --> Loss 0.00143972575665\n",
      "Epoch 35::Minibatch 100::LR 0.0215384615385 --> Loss 0.00395678798358\n",
      "Epoch 35::Minibatch 101::LR 0.0215384615385 --> Loss 0.00089756856362\n",
      "Epoch 35::Minibatch 102::LR 0.0215384615385 --> Loss 0.00381520271301\n",
      "Epoch 35::Minibatch 103::LR 0.0215384615385 --> Loss 0.00380568782489\n",
      "Epoch 35::Minibatch 104::LR 0.0215384615385 --> Loss 0.0026221382618\n",
      "Epoch 35::Minibatch 105::LR 0.0215384615385 --> Loss 0.00195824801922\n",
      "Epoch 35::Minibatch 106::LR 0.0215384615385 --> Loss 0.0123372713725\n",
      "Epoch 35::Minibatch 107::LR 0.0215384615385 --> Loss 0.00470079978307\n",
      "Epoch 35::Minibatch 108::LR 0.0215384615385 --> Loss 0.000901368955771\n",
      "Epoch 35::Minibatch 109::LR 0.0215384615385 --> Loss 0.00429997324944\n",
      "Epoch 35::Minibatch 110::LR 0.0215384615385 --> Loss 0.00218313515186\n",
      "Epoch 35::Minibatch 111::LR 0.0215384615385 --> Loss 0.000789399395386\n",
      "Epoch 35::Minibatch 112::LR 0.0215384615385 --> Loss 0.00322577238083\n",
      "Epoch 35::Minibatch 113::LR 0.0215384615385 --> Loss 0.00232153137525\n",
      "Epoch 35::Minibatch 114::LR 0.0215384615385 --> Loss 0.00131090670824\n",
      "Epoch 35::Minibatch 115::LR 0.0215384615385 --> Loss 0.00108164191246\n",
      "Epoch 35::Minibatch 116::LR 0.0215384615385 --> Loss 0.00261651058992\n",
      "Epoch 35::Minibatch 117::LR 0.0215384615385 --> Loss 0.00412883321444\n",
      "Epoch 35::Minibatch 118::LR 0.0215384615385 --> Loss 0.00640648404757\n",
      "Epoch 35::Minibatch 119::LR 0.0215384615385 --> Loss 0.000464156468709\n",
      "Epoch 35::Minibatch 120::LR 0.0215384615385 --> Loss 0.00163930346568\n",
      "Epoch 35::Minibatch 121::LR 0.0215384615385 --> Loss 0.00228568613529\n",
      "Epoch 35::Minibatch 122::LR 0.0215384615385 --> Loss 0.00389918963114\n",
      "Epoch 35::Minibatch 123::LR 0.0215384615385 --> Loss 0.000607617348433\n",
      "Epoch 35::Minibatch 124::LR 0.0215384615385 --> Loss 0.00261440972487\n",
      "Epoch 35::Minibatch 125::LR 0.0215384615385 --> Loss 0.00435528437297\n",
      "Epoch 35::Minibatch 126::LR 0.0215384615385 --> Loss 0.00235660493374\n",
      "Epoch 35::Minibatch 127::LR 0.0215384615385 --> Loss 0.00502171119054\n",
      "Epoch 35::Minibatch 128::LR 0.0215384615385 --> Loss 0.00346876263618\n",
      "Epoch 35::Minibatch 129::LR 0.0215384615385 --> Loss 0.00230040768782\n",
      "Epoch 35::Minibatch 130::LR 0.0215384615385 --> Loss 0.00429389913877\n",
      "Epoch 35::Minibatch 131::LR 0.0215384615385 --> Loss 0.00167895575364\n",
      "Epoch 35::Minibatch 132::LR 0.0215384615385 --> Loss 0.00273774723212\n",
      "Epoch 35::Minibatch 133::LR 0.0215384615385 --> Loss 0.00267319142818\n",
      "Epoch 35::Minibatch 134::LR 0.0215384615385 --> Loss 0.00206125716368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 135::LR 0.0215384615385 --> Loss 0.00120787233114\n",
      "Epoch 35::Minibatch 136::LR 0.0215384615385 --> Loss 0.00233799139659\n",
      "Epoch 35::Minibatch 137::LR 0.0215384615385 --> Loss 0.00327845811844\n",
      "Epoch 35::Minibatch 138::LR 0.0215384615385 --> Loss 0.0011880081892\n",
      "Epoch 35::Minibatch 139::LR 0.0215384615385 --> Loss 0.00184632400672\n",
      "Epoch 35::Minibatch 140::LR 0.0215384615385 --> Loss 0.00234156211217\n",
      "Epoch 35::Minibatch 141::LR 0.0215384615385 --> Loss 0.00284586191177\n",
      "Epoch 35::Minibatch 142::LR 0.0215384615385 --> Loss 0.00267731587092\n",
      "Epoch 35::Minibatch 143::LR 0.0215384615385 --> Loss 0.000524696807067\n",
      "Epoch 35::Minibatch 144::LR 0.0215384615385 --> Loss 0.00340097149213\n",
      "Epoch 35::Minibatch 145::LR 0.0215384615385 --> Loss 0.00408274451892\n",
      "Epoch 35::Minibatch 146::LR 0.0215384615385 --> Loss 0.00247569044431\n",
      "Epoch 35::Minibatch 147::LR 0.0215384615385 --> Loss 0.00178313374519\n",
      "Epoch 35::Minibatch 148::LR 0.0215384615385 --> Loss 0.000953019360701\n",
      "Epoch 35::Minibatch 149::LR 0.0215384615385 --> Loss 0.00286911626657\n",
      "Epoch 35::Minibatch 150::LR 0.0215384615385 --> Loss 0.00264616946379\n",
      "Epoch 35::Minibatch 151::LR 0.0215384615385 --> Loss 0.00429736773173\n",
      "Epoch 35::Minibatch 152::LR 0.0215384615385 --> Loss 0.000897568662961\n",
      "Epoch 35::Minibatch 153::LR 0.0215384615385 --> Loss 0.00159274319808\n",
      "Epoch 35::Minibatch 154::LR 0.0215384615385 --> Loss 0.00199625412623\n",
      "Epoch 35::Minibatch 155::LR 0.0215384615385 --> Loss 0.00399470647176\n",
      "Epoch 35::Minibatch 156::LR 0.0215384615385 --> Loss 0.0023436019818\n",
      "Epoch 35::Minibatch 157::LR 0.0215384615385 --> Loss 0.000681897997856\n",
      "Epoch 35::Minibatch 158::LR 0.0215384615385 --> Loss 0.0031936387221\n",
      "Epoch 35::Minibatch 159::LR 0.0215384615385 --> Loss 0.00271666626136\n",
      "Epoch 35::Minibatch 160::LR 0.0215384615385 --> Loss 0.00266397615274\n",
      "Epoch 35::Minibatch 161::LR 0.0215384615385 --> Loss 0.000993212759495\n",
      "Epoch 35::Minibatch 162::LR 0.0215384615385 --> Loss 0.00399464527766\n",
      "Epoch 35::Minibatch 163::LR 0.0215384615385 --> Loss 0.00240889906883\n",
      "Epoch 35::Minibatch 164::LR 0.0215384615385 --> Loss 0.0025491331021\n",
      "Epoch 35::Minibatch 165::LR 0.0215384615385 --> Loss 0.000488659193118\n",
      "Epoch 35::Minibatch 166::LR 0.0215384615385 --> Loss 0.00169265270233\n",
      "Epoch 35::Minibatch 167::LR 0.0215384615385 --> Loss 0.00248467803001\n",
      "Epoch 35::Minibatch 168::LR 0.0215384615385 --> Loss 0.00213328381379\n",
      "Epoch 35::Minibatch 169::LR 0.0215384615385 --> Loss 0.000979906221231\n",
      "Epoch 35::Minibatch 170::LR 0.0215384615385 --> Loss 0.000943438609441\n",
      "Epoch 35::Minibatch 171::LR 0.0215384615385 --> Loss 0.00251670797666\n",
      "Epoch 35::Minibatch 172::LR 0.0215384615385 --> Loss 0.00426588217417\n",
      "Epoch 35::Minibatch 173::LR 0.0215384615385 --> Loss 0.00202957848708\n",
      "Epoch 35::Minibatch 174::LR 0.0215384615385 --> Loss 0.000946561296781\n",
      "Epoch 35::Minibatch 175::LR 0.0215384615385 --> Loss 0.00238405724367\n",
      "Epoch 35::Minibatch 176::LR 0.0215384615385 --> Loss 0.00308104654153\n",
      "Epoch 35::Minibatch 177::LR 0.0215384615385 --> Loss 0.00422213872274\n",
      "Epoch 35::Minibatch 178::LR 0.0215384615385 --> Loss 0.00147284080585\n",
      "Epoch 35::Minibatch 179::LR 0.0215384615385 --> Loss 0.00116166551908\n",
      "Epoch 35::Minibatch 180::LR 0.0215384615385 --> Loss 0.00332984189192\n",
      "Epoch 35::Minibatch 181::LR 0.0215384615385 --> Loss 0.00301200866699\n",
      "Epoch 35::Minibatch 182::LR 0.0215384615385 --> Loss 0.000691576898098\n",
      "Epoch 35::Minibatch 183::LR 0.0215384615385 --> Loss 0.00153418610493\n",
      "Epoch 35::Minibatch 184::LR 0.0215384615385 --> Loss 0.00338326295217\n",
      "Epoch 35::Minibatch 185::LR 0.0215384615385 --> Loss 0.00260962545872\n",
      "Epoch 35::Minibatch 186::LR 0.0215384615385 --> Loss 0.000913973251979\n",
      "Epoch 35::Minibatch 187::LR 0.0215384615385 --> Loss 0.00126458972692\n",
      "Epoch 35::Minibatch 188::LR 0.0215384615385 --> Loss 0.00398466706276\n",
      "Epoch 35::Minibatch 189::LR 0.0215384615385 --> Loss 0.00405982891719\n",
      "Epoch 35::Minibatch 190::LR 0.0215384615385 --> Loss 0.00229154845079\n",
      "Epoch 35::Minibatch 191::LR 0.0215384615385 --> Loss 0.000442615002394\n",
      "Epoch 35::Minibatch 192::LR 0.0215384615385 --> Loss 0.00277497311433\n",
      "Epoch 35::Minibatch 193::LR 0.0215384615385 --> Loss 0.00269729296366\n",
      "Epoch 35::Minibatch 194::LR 0.0215384615385 --> Loss 0.00172231535117\n",
      "Epoch 35::Minibatch 195::LR 0.0215384615385 --> Loss 0.000372085720301\n",
      "Epoch 35::Minibatch 196::LR 0.0215384615385 --> Loss 0.00136706580718\n",
      "Epoch 35::Minibatch 197::LR 0.0215384615385 --> Loss 0.00296011944612\n",
      "Epoch 35::Minibatch 198::LR 0.0215384615385 --> Loss 0.00232112745444\n",
      "Epoch 35::Minibatch 199::LR 0.0215384615385 --> Loss 0.000289381345113\n",
      "Epoch 35::Minibatch 200::LR 0.0215384615385 --> Loss 0.00203525066376\n",
      "Epoch 35::Minibatch 201::LR 0.0215384615385 --> Loss 0.0019270670414\n",
      "Epoch 35::Minibatch 202::LR 0.0215384615385 --> Loss 0.00180924276511\n",
      "Epoch 35::Minibatch 203::LR 0.0215384615385 --> Loss 0.00175512035688\n",
      "Epoch 35::Minibatch 204::LR 0.0215384615385 --> Loss 0.00141444077094\n",
      "Epoch 35::Minibatch 205::LR 0.0215384615385 --> Loss 0.00221882343292\n",
      "Epoch 35::Minibatch 206::LR 0.0215384615385 --> Loss 0.00529612620672\n",
      "Epoch 35::Minibatch 207::LR 0.0215384615385 --> Loss 0.00139719684919\n",
      "Epoch 35::Minibatch 208::LR 0.0215384615385 --> Loss 0.00110287467639\n",
      "Epoch 35::Minibatch 209::LR 0.0215384615385 --> Loss 0.0025273813804\n",
      "Epoch 35::Minibatch 210::LR 0.0215384615385 --> Loss 0.00237340291341\n",
      "Epoch 35::Minibatch 211::LR 0.0215384615385 --> Loss 0.00271460413933\n",
      "Epoch 35::Minibatch 212::LR 0.0215384615385 --> Loss 0.00373096545537\n",
      "Epoch 35::Minibatch 213::LR 0.0215384615385 --> Loss 0.00534451127052\n",
      "Epoch 35::Minibatch 214::LR 0.0215384615385 --> Loss 0.00685119231542\n",
      "Epoch 35::Minibatch 215::LR 0.0215384615385 --> Loss 0.00135798841715\n",
      "Epoch 35::Minibatch 216::LR 0.0215384615385 --> Loss 0.00525222063065\n",
      "Epoch 35::Minibatch 217::LR 0.0215384615385 --> Loss 0.00577188372612\n",
      "Epoch 35::Minibatch 218::LR 0.0215384615385 --> Loss 0.00389127810796\n",
      "Epoch 35::Minibatch 219::LR 0.0215384615385 --> Loss 0.00443351507187\n",
      "Epoch 35::Minibatch 220::LR 0.0215384615385 --> Loss 0.00433174173037\n",
      "Epoch 35::Minibatch 221::LR 0.0215384615385 --> Loss 0.00426393866539\n",
      "Epoch 35::Minibatch 222::LR 0.0215384615385 --> Loss 0.00315208772818\n",
      "Epoch 35::Minibatch 223::LR 0.0215384615385 --> Loss 0.00137773851554\n",
      "Epoch 35::Minibatch 224::LR 0.0215384615385 --> Loss 0.00157704124848\n",
      "Epoch 35::Minibatch 225::LR 0.0215384615385 --> Loss 0.00788314183553\n",
      "Epoch 35::Minibatch 226::LR 0.0215384615385 --> Loss 0.0036192103227\n",
      "Epoch 35::Minibatch 227::LR 0.0215384615385 --> Loss 0.00167713026206\n",
      "Epoch 35::Minibatch 228::LR 0.0215384615385 --> Loss 0.000643306175868\n",
      "Epoch 35::Minibatch 229::LR 0.0215384615385 --> Loss 0.00472988088926\n",
      "Epoch 35::Minibatch 230::LR 0.0215384615385 --> Loss 0.0036244002978\n",
      "Epoch 35::Minibatch 231::LR 0.0215384615385 --> Loss 0.00266482174397\n",
      "Epoch 35::Minibatch 232::LR 0.0215384615385 --> Loss 0.00115684996049\n",
      "Epoch 35::Minibatch 233::LR 0.0215384615385 --> Loss 0.00246740937233\n",
      "Epoch 35::Minibatch 234::LR 0.0215384615385 --> Loss 0.00742919365565\n",
      "Epoch 35::Minibatch 235::LR 0.0215384615385 --> Loss 0.00456239183744\n",
      "Epoch 35::Minibatch 236::LR 0.0215384615385 --> Loss 0.00166107853254\n",
      "Epoch 35::Minibatch 237::LR 0.0215384615385 --> Loss 0.000575263500214\n",
      "Epoch 35::Minibatch 238::LR 0.0215384615385 --> Loss 0.00346081932386\n",
      "Epoch 35::Minibatch 239::LR 0.0215384615385 --> Loss 0.00295647978783\n",
      "Epoch 35::Minibatch 240::LR 0.0215384615385 --> Loss 0.00326360801856\n",
      "Epoch 35::Minibatch 241::LR 0.0215384615385 --> Loss 0.000743906249603\n",
      "Epoch 35::Minibatch 242::LR 0.0215384615385 --> Loss 0.00668428103129\n",
      "Epoch 35::Minibatch 243::LR 0.0215384615385 --> Loss 0.00322862704595\n",
      "Epoch 35::Minibatch 244::LR 0.0215384615385 --> Loss 0.00270633300145\n",
      "Epoch 35::Minibatch 245::LR 0.0215384615385 --> Loss 0.000421578834454\n",
      "Epoch 35::Minibatch 246::LR 0.0215384615385 --> Loss 0.00187982797623\n",
      "Epoch 35::Minibatch 247::LR 0.0215384615385 --> Loss 0.0101442146301\n",
      "Epoch 35::Minibatch 248::LR 0.0215384615385 --> Loss 0.00432530522346\n",
      "Epoch 35::Minibatch 249::LR 0.0215384615385 --> Loss 0.00237494250139\n",
      "Epoch 35::Minibatch 250::LR 0.0215384615385 --> Loss 0.00232363859812\n",
      "Epoch 35::Minibatch 251::LR 0.0215384615385 --> Loss 0.00231745282809\n",
      "Epoch 35::Minibatch 252::LR 0.0215384615385 --> Loss 0.00159011214972\n",
      "Epoch 35::Minibatch 253::LR 0.0215384615385 --> Loss 0.00274616817633\n",
      "Epoch 35::Minibatch 254::LR 0.0215384615385 --> Loss 0.00479248563449\n",
      "Epoch 35::Minibatch 255::LR 0.0215384615385 --> Loss 0.00384891748428\n",
      "Epoch 35::Minibatch 256::LR 0.0215384615385 --> Loss 0.00136385331551\n",
      "Epoch 35::Minibatch 257::LR 0.0215384615385 --> Loss 0.00112979471684\n",
      "Epoch 35::Minibatch 258::LR 0.0215384615385 --> Loss 0.00366325974464\n",
      "Epoch 35::Minibatch 259::LR 0.0215384615385 --> Loss 0.00155934154987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 260::LR 0.0215384615385 --> Loss 0.00183804512024\n",
      "Epoch 35::Minibatch 261::LR 0.0215384615385 --> Loss 0.00263212343057\n",
      "Epoch 35::Minibatch 262::LR 0.0215384615385 --> Loss 0.00179758906364\n",
      "Epoch 35::Minibatch 263::LR 0.0215384615385 --> Loss 0.00226830800374\n",
      "Epoch 35::Minibatch 264::LR 0.0215384615385 --> Loss 0.00354213992755\n",
      "Epoch 35::Minibatch 265::LR 0.0215384615385 --> Loss 0.00993192911148\n",
      "Epoch 35::Minibatch 266::LR 0.0215384615385 --> Loss 0.000855932533741\n",
      "Epoch 35::Minibatch 267::LR 0.0215384615385 --> Loss 0.00895783185959\n",
      "Epoch 35::Minibatch 268::LR 0.0215384615385 --> Loss 0.00100855549177\n",
      "Epoch 35::Minibatch 269::LR 0.0215384615385 --> Loss 0.00345812877019\n",
      "Epoch 35::Minibatch 270::LR 0.0215384615385 --> Loss 0.00745968818665\n",
      "Epoch 35::Minibatch 271::LR 0.0215384615385 --> Loss 0.00236744662126\n",
      "Epoch 35::Minibatch 272::LR 0.0215384615385 --> Loss 0.00446426749229\n",
      "Epoch 35::Minibatch 273::LR 0.0215384615385 --> Loss 0.0013244459033\n",
      "Epoch 35::Minibatch 274::LR 0.0215384615385 --> Loss 0.00176150778929\n",
      "Epoch 35::Minibatch 275::LR 0.0215384615385 --> Loss 0.00242681066195\n",
      "Epoch 35::Minibatch 276::LR 0.0215384615385 --> Loss 0.00331320524216\n",
      "Epoch 35::Minibatch 277::LR 0.0215384615385 --> Loss 0.000841267704964\n",
      "Epoch 35::Minibatch 278::LR 0.0215384615385 --> Loss 0.00250603715579\n",
      "Epoch 35::Minibatch 279::LR 0.0215384615385 --> Loss 0.00192438403765\n",
      "Epoch 35::Minibatch 280::LR 0.0215384615385 --> Loss 0.00170707722505\n",
      "Epoch 35::Minibatch 281::LR 0.0215384615385 --> Loss 0.00108117004236\n",
      "Epoch 35::Minibatch 282::LR 0.0215384615385 --> Loss 0.00195621311665\n",
      "Epoch 35::Minibatch 283::LR 0.0215384615385 --> Loss 0.00185377279917\n",
      "Epoch 35::Minibatch 284::LR 0.0215384615385 --> Loss 0.00151871681213\n",
      "Epoch 35::Minibatch 285::LR 0.0215384615385 --> Loss 0.00109716067712\n",
      "Epoch 35::Minibatch 286::LR 0.0215384615385 --> Loss 0.00190810819467\n",
      "Epoch 35::Minibatch 287::LR 0.0215384615385 --> Loss 0.00189346075058\n",
      "Epoch 35::Minibatch 288::LR 0.0215384615385 --> Loss 0.00103123664856\n",
      "Epoch 35::Minibatch 289::LR 0.0215384615385 --> Loss 0.00152428130309\n",
      "Epoch 35::Minibatch 290::LR 0.0215384615385 --> Loss 0.00180908660094\n",
      "Epoch 35::Minibatch 291::LR 0.0215384615385 --> Loss 0.00162967175245\n",
      "Epoch 35::Minibatch 292::LR 0.0215384615385 --> Loss 0.000575774262349\n",
      "Epoch 35::Minibatch 293::LR 0.0215384615385 --> Loss 0.00146756649017\n",
      "Epoch 35::Minibatch 294::LR 0.0215384615385 --> Loss 0.00161570727825\n",
      "Epoch 35::Minibatch 295::LR 0.0215384615385 --> Loss 0.00186314284801\n",
      "Epoch 35::Minibatch 296::LR 0.0215384615385 --> Loss 0.00160243719816\n",
      "Epoch 35::Minibatch 297::LR 0.0215384615385 --> Loss 0.00140691538652\n",
      "Epoch 35::Minibatch 298::LR 0.0215384615385 --> Loss 0.00141337613265\n",
      "Epoch 35::Minibatch 299::LR 0.0215384615385 --> Loss 0.000811674992243\n",
      "Epoch 35::Minibatch 300::LR 0.0215384615385 --> Loss 0.00265522301197\n",
      "Epoch 35::Minibatch 301::LR 0.0215384615385 --> Loss 0.00256912271182\n",
      "Epoch 35::Minibatch 302::LR 0.0215384615385 --> Loss 0.00236900130908\n",
      "Epoch 35::Minibatch 303::LR 0.0215384615385 --> Loss 0.000821072906256\n",
      "Epoch 35::Minibatch 304::LR 0.0215384615385 --> Loss 0.00290074964364\n",
      "Epoch 35::Minibatch 305::LR 0.0215384615385 --> Loss 0.0017120329539\n",
      "Epoch 35::Minibatch 306::LR 0.0215384615385 --> Loss 0.000933923025926\n",
      "Epoch 35::Minibatch 307::LR 0.0215384615385 --> Loss 0.00239273111025\n",
      "Epoch 35::Minibatch 308::LR 0.0215384615385 --> Loss 0.00201276818911\n",
      "Epoch 35::Minibatch 309::LR 0.0215384615385 --> Loss 0.00104485154152\n",
      "Epoch 35::Minibatch 310::LR 0.0215384615385 --> Loss 0.00119781921307\n",
      "Epoch 35::Minibatch 311::LR 0.0215384615385 --> Loss 0.0017983943224\n",
      "Epoch 35::Minibatch 312::LR 0.0215384615385 --> Loss 0.00284348408381\n",
      "Epoch 35::Minibatch 313::LR 0.0215384615385 --> Loss 0.00232361475627\n",
      "Epoch 35::Minibatch 314::LR 0.0215384615385 --> Loss 0.00192176481088\n",
      "Epoch 35::Minibatch 315::LR 0.0215384615385 --> Loss 0.00105314701796\n",
      "Epoch 35::Minibatch 316::LR 0.0215384615385 --> Loss 0.00234506865342\n",
      "Epoch 35::Minibatch 317::LR 0.0215384615385 --> Loss 0.00156542857488\n",
      "Epoch 35::Minibatch 318::LR 0.0215384615385 --> Loss 0.00131714344025\n",
      "Epoch 35::Minibatch 319::LR 0.0215384615385 --> Loss 0.00230658809344\n",
      "Epoch 35::Minibatch 320::LR 0.0215384615385 --> Loss 0.00300187150637\n",
      "Epoch 35::Minibatch 321::LR 0.0215384615385 --> Loss 0.000841692884763\n",
      "Epoch 35::Minibatch 322::LR 0.0215384615385 --> Loss 0.00339285095533\n",
      "Epoch 35::Minibatch 323::LR 0.0215384615385 --> Loss 0.00340227683385\n",
      "Epoch 35::Minibatch 324::LR 0.0215384615385 --> Loss 0.00265316625436\n",
      "Epoch 35::Minibatch 325::LR 0.0215384615385 --> Loss 0.00236685315768\n",
      "Epoch 35::Minibatch 326::LR 0.0215384615385 --> Loss 0.0052005636692\n",
      "Epoch 35::Minibatch 327::LR 0.0215384615385 --> Loss 0.0022180579106\n",
      "Epoch 35::Minibatch 328::LR 0.0215384615385 --> Loss 0.00289030353228\n",
      "Epoch 35::Minibatch 329::LR 0.0215384615385 --> Loss 0.00118446270625\n",
      "Epoch 35::Minibatch 330::LR 0.0215384615385 --> Loss 0.00158749381701\n",
      "Epoch 35::Minibatch 331::LR 0.0215384615385 --> Loss 0.00253302454948\n",
      "Epoch 35::Minibatch 332::LR 0.0215384615385 --> Loss 0.00244032065074\n",
      "Epoch 35::Minibatch 333::LR 0.0215384615385 --> Loss 0.00147331198057\n",
      "Epoch 35::Minibatch 334::LR 0.0215384615385 --> Loss 0.00439273436864\n",
      "Epoch 35::Minibatch 335::LR 0.0215384615385 --> Loss 0.0019041655461\n",
      "Epoch 35::Minibatch 336::LR 0.0215384615385 --> Loss 0.00226798653603\n",
      "Epoch 35::Minibatch 337::LR 0.0215384615385 --> Loss 0.00378567973773\n",
      "Epoch 35::Minibatch 338::LR 0.0215384615385 --> Loss 0.000558979113897\n",
      "Epoch 35::Minibatch 339::LR 0.0215384615385 --> Loss 0.00322215139866\n",
      "Epoch 35::Minibatch 340::LR 0.0215384615385 --> Loss 0.00362662394842\n",
      "Epoch 35::Minibatch 341::LR 0.0215384615385 --> Loss 0.00422363241514\n",
      "Epoch 35::Minibatch 342::LR 0.0215384615385 --> Loss 0.00305076082548\n",
      "Epoch 35::Minibatch 343::LR 0.0215384615385 --> Loss 0.00163731922706\n",
      "Epoch 35::Minibatch 344::LR 0.0215384615385 --> Loss 0.00315833985806\n",
      "Epoch 35::Minibatch 345::LR 0.0215384615385 --> Loss 0.00404404004415\n",
      "Epoch 35::Minibatch 346::LR 0.0215384615385 --> Loss 0.00529681801796\n",
      "Epoch 35::Minibatch 347::LR 0.0215384615385 --> Loss 0.000818560421467\n",
      "Epoch 35::Minibatch 348::LR 0.0215384615385 --> Loss 0.00292768021425\n",
      "Epoch 35::Minibatch 349::LR 0.0215384615385 --> Loss 0.00332648515701\n",
      "Epoch 35::Minibatch 350::LR 0.0215384615385 --> Loss 0.00164174606403\n",
      "Epoch 35::Minibatch 351::LR 0.0215384615385 --> Loss 0.0034181257089\n",
      "Epoch 35::Minibatch 352::LR 0.0215384615385 --> Loss 0.00486654837926\n",
      "Epoch 35::Minibatch 353::LR 0.0215384615385 --> Loss 0.00348788221677\n",
      "Epoch 35::Minibatch 354::LR 0.0215384615385 --> Loss 0.00294053375721\n",
      "Epoch 35::Minibatch 355::LR 0.0215384615385 --> Loss 0.00629516482353\n",
      "Epoch 35::Minibatch 356::LR 0.0215384615385 --> Loss 0.00316498756409\n",
      "Epoch 35::Minibatch 357::LR 0.0215384615385 --> Loss 0.00119207332532\n",
      "Epoch 35::Minibatch 358::LR 0.0215384615385 --> Loss 0.00192398925622\n",
      "Epoch 35::Minibatch 359::LR 0.0215384615385 --> Loss 0.00266515254974\n",
      "Epoch 35::Minibatch 360::LR 0.0215384615385 --> Loss 0.0022710720698\n",
      "Epoch 35::Minibatch 361::LR 0.0215384615385 --> Loss 0.00223348518213\n",
      "Epoch 35::Minibatch 362::LR 0.0215384615385 --> Loss 0.00222705483437\n",
      "Epoch 35::Minibatch 363::LR 0.0215384615385 --> Loss 0.000632709364096\n",
      "Epoch 35::Minibatch 364::LR 0.0215384615385 --> Loss 0.00196504076322\n",
      "Epoch 35::Minibatch 365::LR 0.0215384615385 --> Loss 0.00198753972848\n",
      "Epoch 35::Minibatch 366::LR 0.0215384615385 --> Loss 0.0021007523934\n",
      "Epoch 35::Minibatch 367::LR 0.0215384615385 --> Loss 0.000979688366254\n",
      "Epoch 35::Minibatch 368::LR 0.0215384615385 --> Loss 0.000973187188307\n",
      "Epoch 35::Minibatch 369::LR 0.0215384615385 --> Loss 0.00272625565529\n",
      "Epoch 35::Minibatch 370::LR 0.0215384615385 --> Loss 0.00219140768051\n",
      "Epoch 35::Minibatch 371::LR 0.0215384615385 --> Loss 0.00183436075846\n",
      "Epoch 35::Minibatch 372::LR 0.0215384615385 --> Loss 0.00042815476656\n",
      "Epoch 35::Minibatch 373::LR 0.0215384615385 --> Loss 0.00181136171023\n",
      "Epoch 35::Minibatch 374::LR 0.0215384615385 --> Loss 0.00225565810998\n",
      "Epoch 35::Minibatch 375::LR 0.0215384615385 --> Loss 0.00189831197262\n",
      "Epoch 35::Minibatch 376::LR 0.0215384615385 --> Loss 0.00119501560926\n",
      "Epoch 35::Minibatch 377::LR 0.0215384615385 --> Loss 0.00190385182699\n",
      "Epoch 35::Minibatch 378::LR 0.0215384615385 --> Loss 0.00208539287249\n",
      "Epoch 35::Minibatch 379::LR 0.0215384615385 --> Loss 0.0023099164168\n",
      "Epoch 35::Minibatch 380::LR 0.0215384615385 --> Loss 0.00155744075775\n",
      "Epoch 35::Minibatch 381::LR 0.0215384615385 --> Loss 0.000997427205245\n",
      "Epoch 35::Minibatch 382::LR 0.0215384615385 --> Loss 0.00204359471798\n",
      "Epoch 35::Minibatch 383::LR 0.0215384615385 --> Loss 0.00199411948522\n",
      "Epoch 35::Minibatch 384::LR 0.0215384615385 --> Loss 0.0011353957653\n",
      "Epoch 35::Minibatch 385::LR 0.0215384615385 --> Loss 0.00106281995773\n",
      "Epoch 35::Minibatch 386::LR 0.0215384615385 --> Loss 0.00226504385471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 387::LR 0.0215384615385 --> Loss 0.00236603319645\n",
      "Epoch 35::Minibatch 388::LR 0.0215384615385 --> Loss 0.00122675180435\n",
      "Epoch 35::Minibatch 389::LR 0.0215384615385 --> Loss 0.0017848243316\n",
      "Epoch 35::Minibatch 390::LR 0.0215384615385 --> Loss 0.00321933090687\n",
      "Epoch 35::Minibatch 391::LR 0.0215384615385 --> Loss 0.00253790994485\n",
      "Epoch 35::Minibatch 392::LR 0.0215384615385 --> Loss 0.00255029420058\n",
      "Epoch 35::Minibatch 393::LR 0.0215384615385 --> Loss 0.00272711177667\n",
      "Epoch 35::Minibatch 394::LR 0.0215384615385 --> Loss 0.00200553655624\n",
      "Epoch 35::Minibatch 395::LR 0.0215384615385 --> Loss 0.00207869072755\n",
      "Epoch 35::Minibatch 396::LR 0.0215384615385 --> Loss 0.00194482366244\n",
      "Epoch 35::Minibatch 397::LR 0.0215384615385 --> Loss 0.00208316326141\n",
      "Epoch 35::Minibatch 398::LR 0.0215384615385 --> Loss 0.00207264284293\n",
      "Epoch 35::Minibatch 399::LR 0.0215384615385 --> Loss 0.0023759218057\n",
      "Epoch 35::Minibatch 400::LR 0.0215384615385 --> Loss 0.00201382835706\n",
      "Epoch 35::Minibatch 401::LR 0.0215384615385 --> Loss 0.00340072631836\n",
      "Epoch 35::Minibatch 402::LR 0.0215384615385 --> Loss 0.00171305060387\n",
      "Epoch 35::Minibatch 403::LR 0.0215384615385 --> Loss 0.00142827004194\n",
      "Epoch 35::Minibatch 404::LR 0.0215384615385 --> Loss 0.00132164915403\n",
      "Epoch 35::Minibatch 405::LR 0.0215384615385 --> Loss 0.0033176535368\n",
      "Epoch 35::Minibatch 406::LR 0.0215384615385 --> Loss 0.00232458889484\n",
      "Epoch 35::Minibatch 407::LR 0.0215384615385 --> Loss 0.00170482774576\n",
      "Epoch 35::Minibatch 408::LR 0.0215384615385 --> Loss 0.000434436351061\n",
      "Epoch 35::Minibatch 409::LR 0.0215384615385 --> Loss 0.00220396995544\n",
      "Epoch 35::Minibatch 410::LR 0.0215384615385 --> Loss 0.00313011387984\n",
      "Epoch 35::Minibatch 411::LR 0.0215384615385 --> Loss 0.00166908621788\n",
      "Epoch 35::Minibatch 412::LR 0.0215384615385 --> Loss 0.000941950480143\n",
      "Epoch 35::Minibatch 413::LR 0.0215384615385 --> Loss 0.0019787744681\n",
      "Epoch 35::Minibatch 414::LR 0.0215384615385 --> Loss 0.00188118418058\n",
      "Epoch 35::Minibatch 415::LR 0.0215384615385 --> Loss 0.0011786716183\n",
      "Epoch 35::Minibatch 416::LR 0.0215384615385 --> Loss 0.000789409677188\n",
      "Epoch 35::Minibatch 417::LR 0.0215384615385 --> Loss 0.00167683680852\n",
      "Epoch 35::Minibatch 418::LR 0.0215384615385 --> Loss 0.00257129649321\n",
      "Epoch 35::Minibatch 419::LR 0.0215384615385 --> Loss 0.000491770903269\n",
      "Epoch 35::Minibatch 420::LR 0.0215384615385 --> Loss 0.000694025258223\n",
      "Epoch 35::Minibatch 421::LR 0.0215384615385 --> Loss 0.00186570346355\n",
      "Epoch 35::Minibatch 422::LR 0.0215384615385 --> Loss 0.0020510884126\n",
      "Epoch 35::Minibatch 423::LR 0.0215384615385 --> Loss 0.000991100768248\n",
      "Epoch 35::Minibatch 424::LR 0.0215384615385 --> Loss 0.00152023126682\n",
      "Epoch 35::Minibatch 425::LR 0.0215384615385 --> Loss 0.00285622914632\n",
      "Epoch 35::Minibatch 426::LR 0.0215384615385 --> Loss 0.00199252486229\n",
      "Epoch 35::Minibatch 427::LR 0.0215384615385 --> Loss 0.000743541270494\n",
      "Epoch 35::Minibatch 428::LR 0.0215384615385 --> Loss 0.000913340648015\n",
      "Epoch 35::Minibatch 429::LR 0.0215384615385 --> Loss 0.00222390611966\n",
      "Epoch 35::Minibatch 430::LR 0.0215384615385 --> Loss 0.00754850069682\n",
      "Epoch 35::Minibatch 431::LR 0.0215384615385 --> Loss 0.00351130406062\n",
      "Epoch 35::Minibatch 432::LR 0.0215384615385 --> Loss 0.00391582647959\n",
      "Epoch 35::Minibatch 433::LR 0.0215384615385 --> Loss 0.00253291885058\n",
      "Epoch 35::Minibatch 434::LR 0.0215384615385 --> Loss 0.0024210703373\n",
      "Epoch 35::Minibatch 435::LR 0.0215384615385 --> Loss 0.0022448293368\n",
      "Epoch 35::Minibatch 436::LR 0.0215384615385 --> Loss 0.0015822660923\n",
      "Epoch 35::Minibatch 437::LR 0.0215384615385 --> Loss 0.00276474754016\n",
      "Epoch 35::Minibatch 438::LR 0.0215384615385 --> Loss 0.00222113847733\n",
      "Epoch 35::Minibatch 439::LR 0.0215384615385 --> Loss 0.00189671357473\n",
      "Epoch 35::Minibatch 440::LR 0.0215384615385 --> Loss 0.00292760213216\n",
      "Epoch 35::Minibatch 441::LR 0.0215384615385 --> Loss 0.00273907899857\n",
      "Epoch 35::Minibatch 442::LR 0.0215384615385 --> Loss 0.00244023243586\n",
      "Epoch 35::Minibatch 443::LR 0.0215384615385 --> Loss 0.00342703421911\n",
      "Epoch 35::Minibatch 444::LR 0.0215384615385 --> Loss 0.00263887166977\n",
      "Epoch 35::Minibatch 445::LR 0.0215384615385 --> Loss 0.000840545992057\n",
      "Epoch 35::Minibatch 446::LR 0.0215384615385 --> Loss 0.0013490147392\n",
      "Epoch 35::Minibatch 447::LR 0.0215384615385 --> Loss 0.00226154148579\n",
      "Epoch 35::Minibatch 448::LR 0.0215384615385 --> Loss 0.0022977801164\n",
      "Epoch 35::Minibatch 449::LR 0.0215384615385 --> Loss 0.00354033430417\n",
      "Epoch 35::Minibatch 450::LR 0.0215384615385 --> Loss 0.00210619767507\n",
      "Epoch 35::Minibatch 451::LR 0.0215384615385 --> Loss 0.00378877321879\n",
      "Epoch 35::Minibatch 452::LR 0.0215384615385 --> Loss 0.00227507630984\n",
      "Epoch 35::Minibatch 453::LR 0.0215384615385 --> Loss 0.000345642169317\n",
      "Epoch 35::Minibatch 454::LR 0.0215384615385 --> Loss 0.00337755362193\n",
      "Epoch 35::Minibatch 455::LR 0.0215384615385 --> Loss 0.00255857865016\n",
      "Epoch 35::Minibatch 456::LR 0.0215384615385 --> Loss 0.00303886771202\n",
      "Epoch 35::Minibatch 457::LR 0.0215384615385 --> Loss 0.00186477899551\n",
      "Epoch 35::Minibatch 458::LR 0.0215384615385 --> Loss 0.000711675286293\n",
      "Epoch 35::Minibatch 459::LR 0.0215384615385 --> Loss 0.00377801418304\n",
      "Epoch 35::Minibatch 460::LR 0.0215384615385 --> Loss 0.00240661899249\n",
      "Epoch 35::Minibatch 461::LR 0.0215384615385 --> Loss 0.00363823930422\n",
      "Epoch 35::Minibatch 462::LR 0.0215384615385 --> Loss 0.000366289416949\n",
      "Epoch 35::Minibatch 463::LR 0.0215384615385 --> Loss 0.00400957107544\n",
      "Epoch 35::Minibatch 464::LR 0.0215384615385 --> Loss 0.00193109075228\n",
      "Epoch 35::Minibatch 465::LR 0.0215384615385 --> Loss 0.00438813169797\n",
      "Epoch 35::Minibatch 466::LR 0.0215384615385 --> Loss 0.00490995605787\n",
      "Epoch 35::Minibatch 467::LR 0.0215384615385 --> Loss 0.00498296896617\n",
      "Epoch 35::Minibatch 468::LR 0.0215384615385 --> Loss 0.00556064407031\n",
      "Epoch 35::Minibatch 469::LR 0.0215384615385 --> Loss 0.00586970766385\n",
      "Epoch 35::Minibatch 470::LR 0.0215384615385 --> Loss 0.00354314287504\n",
      "Epoch 35::Minibatch 471::LR 0.0215384615385 --> Loss 0.0016502832373\n",
      "Epoch 35::Minibatch 472::LR 0.0215384615385 --> Loss 0.00356190005938\n",
      "Epoch 35::Minibatch 473::LR 0.0215384615385 --> Loss 0.00231253663699\n",
      "Epoch 35::Minibatch 474::LR 0.0215384615385 --> Loss 0.000686810364326\n",
      "Epoch 35::Minibatch 475::LR 0.0215384615385 --> Loss 0.00469591101011\n",
      "Epoch 35::Minibatch 476::LR 0.0215384615385 --> Loss 0.00756306012472\n",
      "Epoch 35::Minibatch 477::LR 0.0215384615385 --> Loss 0.000914136171341\n",
      "Epoch 35::Minibatch 478::LR 0.0215384615385 --> Loss 0.0023956712087\n",
      "Epoch 35::Minibatch 479::LR 0.0215384615385 --> Loss 0.00195483942827\n",
      "Epoch 35::Minibatch 480::LR 0.0215384615385 --> Loss 0.00150698105494\n",
      "Epoch 35::Minibatch 481::LR 0.0215384615385 --> Loss 0.000958320001761\n",
      "Epoch 35::Minibatch 482::LR 0.0215384615385 --> Loss 0.0020617278417\n",
      "Epoch 35::Minibatch 483::LR 0.0215384615385 --> Loss 0.00299382229646\n",
      "Epoch 35::Minibatch 484::LR 0.0215384615385 --> Loss 0.0033570599556\n",
      "Epoch 35::Minibatch 485::LR 0.0215384615385 --> Loss 0.000760522087415\n",
      "Epoch 35::Minibatch 486::LR 0.0215384615385 --> Loss 0.0028116329511\n",
      "Epoch 35::Minibatch 487::LR 0.0215384615385 --> Loss 0.00328263421853\n",
      "Epoch 35::Minibatch 488::LR 0.0215384615385 --> Loss 0.00201182027658\n",
      "Epoch 35::Minibatch 489::LR 0.0215384615385 --> Loss 0.00305802961191\n",
      "Epoch 35::Minibatch 490::LR 0.0215384615385 --> Loss 0.000412494838238\n",
      "Epoch 35::Minibatch 491::LR 0.0215384615385 --> Loss 0.00311690310637\n",
      "Epoch 35::Minibatch 492::LR 0.0215384615385 --> Loss 0.003062915802\n",
      "Epoch 35::Minibatch 493::LR 0.0215384615385 --> Loss 0.00301047861576\n",
      "Epoch 35::Minibatch 494::LR 0.0215384615385 --> Loss 0.000731031696002\n",
      "Epoch 35::Minibatch 495::LR 0.0215384615385 --> Loss 0.00181856294473\n",
      "Epoch 35::Minibatch 496::LR 0.0215384615385 --> Loss 0.00277432064215\n",
      "Epoch 35::Minibatch 497::LR 0.0215384615385 --> Loss 0.000912149349848\n",
      "Epoch 35::Minibatch 498::LR 0.0215384615385 --> Loss 0.000547835032145\n",
      "Epoch 35::Minibatch 499::LR 0.0215384615385 --> Loss 0.00337783018748\n",
      "Epoch 35::Minibatch 500::LR 0.0215384615385 --> Loss 0.00142193128665\n",
      "Epoch 35::Minibatch 501::LR 0.0215384615385 --> Loss 0.00199335098267\n",
      "Epoch 35::Minibatch 502::LR 0.0215384615385 --> Loss 0.00371952454249\n",
      "Epoch 35::Minibatch 503::LR 0.0215384615385 --> Loss 0.00662913600604\n",
      "Epoch 35::Minibatch 504::LR 0.0215384615385 --> Loss 0.00654521028201\n",
      "Epoch 35::Minibatch 505::LR 0.0215384615385 --> Loss 0.00387759685516\n",
      "Epoch 35::Minibatch 506::LR 0.0215384615385 --> Loss 0.00327574868997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 507::LR 0.0215384615385 --> Loss 0.00567893584569\n",
      "Epoch 35::Minibatch 508::LR 0.0215384615385 --> Loss 0.00337875286738\n",
      "Epoch 35::Minibatch 509::LR 0.0215384615385 --> Loss 0.0041943860054\n",
      "Epoch 35::Minibatch 510::LR 0.0215384615385 --> Loss 0.00435675422351\n",
      "Epoch 35::Minibatch 511::LR 0.0215384615385 --> Loss 0.00401921312014\n",
      "Epoch 35::Minibatch 512::LR 0.0215384615385 --> Loss 0.00268359442552\n",
      "Epoch 35::Minibatch 513::LR 0.0215384615385 --> Loss 0.00059097096324\n",
      "Epoch 35::Minibatch 514::LR 0.0215384615385 --> Loss 0.00259134729703\n",
      "Epoch 35::Minibatch 515::LR 0.0215384615385 --> Loss 0.00298725545406\n",
      "Epoch 35::Minibatch 516::LR 0.0215384615385 --> Loss 0.00389688491821\n",
      "Epoch 35::Minibatch 517::LR 0.0215384615385 --> Loss 0.0036401339372\n",
      "Epoch 35::Minibatch 518::LR 0.0215384615385 --> Loss 0.00256991545359\n",
      "Epoch 35::Minibatch 519::LR 0.0215384615385 --> Loss 0.00357992291451\n",
      "Epoch 35::Minibatch 520::LR 0.0215384615385 --> Loss 0.0056392800808\n",
      "Epoch 35::Minibatch 521::LR 0.0215384615385 --> Loss 0.00569824298223\n",
      "Epoch 35::Minibatch 522::LR 0.0215384615385 --> Loss 0.00695631663005\n",
      "Epoch 35::Minibatch 523::LR 0.0215384615385 --> Loss 0.000620621591806\n",
      "Epoch 35::Minibatch 524::LR 0.0215384615385 --> Loss 0.0013830969731\n",
      "Epoch 35::Minibatch 525::LR 0.0215384615385 --> Loss 0.00301561752955\n",
      "Epoch 35::Minibatch 526::LR 0.0215384615385 --> Loss 0.00365241765976\n",
      "Epoch 35::Minibatch 527::LR 0.0215384615385 --> Loss 0.0021118837595\n",
      "Epoch 35::Minibatch 528::LR 0.0215384615385 --> Loss 0.000911431610584\n",
      "Epoch 35::Minibatch 529::LR 0.0215384615385 --> Loss 0.00376105308533\n",
      "Epoch 35::Minibatch 530::LR 0.0215384615385 --> Loss 0.00372484167417\n",
      "Epoch 35::Minibatch 531::LR 0.0215384615385 --> Loss 0.00330988566081\n",
      "Epoch 35::Minibatch 532::LR 0.0215384615385 --> Loss 0.00257159193357\n",
      "Epoch 35::Minibatch 533::LR 0.0215384615385 --> Loss 0.00485918283463\n",
      "Epoch 35::Minibatch 534::LR 0.0215384615385 --> Loss 0.0036648841699\n",
      "Epoch 35::Minibatch 535::LR 0.0215384615385 --> Loss 0.00333542426427\n",
      "Epoch 35::Minibatch 536::LR 0.0215384615385 --> Loss 0.00210756262143\n",
      "Epoch 35::Minibatch 537::LR 0.0215384615385 --> Loss 0.000579974899689\n",
      "Epoch 35::Minibatch 538::LR 0.0215384615385 --> Loss 0.0016220164299\n",
      "Epoch 35::Minibatch 539::LR 0.0215384615385 --> Loss 0.00329200545947\n",
      "Epoch 35::Minibatch 540::LR 0.0215384615385 --> Loss 0.00337365587552\n",
      "Epoch 35::Minibatch 541::LR 0.0215384615385 --> Loss 0.00282688081264\n",
      "Epoch 35::Minibatch 542::LR 0.0215384615385 --> Loss 0.00242191334565\n",
      "Epoch 35::Minibatch 543::LR 0.0215384615385 --> Loss 0.00254022419453\n",
      "Epoch 35::Minibatch 544::LR 0.0215384615385 --> Loss 0.00407312273979\n",
      "Epoch 35::Minibatch 545::LR 0.0215384615385 --> Loss 0.00195229331652\n",
      "Epoch 35::Minibatch 546::LR 0.0215384615385 --> Loss 0.000662005196015\n",
      "Epoch 35::Minibatch 547::LR 0.0215384615385 --> Loss 0.0025696794192\n",
      "Epoch 35::Minibatch 548::LR 0.0215384615385 --> Loss 0.00335555315018\n",
      "Epoch 35::Minibatch 549::LR 0.0215384615385 --> Loss 0.00894346237183\n",
      "Epoch 35::Minibatch 550::LR 0.0215384615385 --> Loss 0.00118810931842\n",
      "Epoch 35::Minibatch 551::LR 0.0215384615385 --> Loss 0.0024628551801\n",
      "Epoch 35::Minibatch 552::LR 0.0215384615385 --> Loss 0.00341841816902\n",
      "Epoch 35::Minibatch 553::LR 0.0215384615385 --> Loss 0.00291374405225\n",
      "Epoch 35::Minibatch 554::LR 0.0215384615385 --> Loss 0.00358451882998\n",
      "Epoch 35::Minibatch 555::LR 0.0215384615385 --> Loss 0.00093302210172\n",
      "Epoch 35::Minibatch 556::LR 0.0215384615385 --> Loss 0.00190404176712\n",
      "Epoch 35::Minibatch 557::LR 0.0215384615385 --> Loss 0.00240967571735\n",
      "Epoch 35::Minibatch 558::LR 0.0215384615385 --> Loss 0.00356357256571\n",
      "Epoch 35::Minibatch 559::LR 0.0215384615385 --> Loss 0.00364368478457\n",
      "Epoch 35::Minibatch 560::LR 0.0215384615385 --> Loss 0.00304929832617\n",
      "Epoch 35::Minibatch 561::LR 0.0215384615385 --> Loss 0.00261173268159\n",
      "Epoch 35::Minibatch 562::LR 0.0215384615385 --> Loss 0.00233226875464\n",
      "Epoch 35::Minibatch 563::LR 0.0215384615385 --> Loss 0.00395247817039\n",
      "Epoch 35::Minibatch 564::LR 0.0215384615385 --> Loss 0.00302653451761\n",
      "Epoch 35::Minibatch 565::LR 0.0215384615385 --> Loss 0.00356355309486\n",
      "Epoch 35::Minibatch 566::LR 0.0215384615385 --> Loss 0.00215611338615\n",
      "Epoch 35::Minibatch 567::LR 0.0215384615385 --> Loss 0.00254115919272\n",
      "Epoch 35::Minibatch 568::LR 0.0215384615385 --> Loss 0.00171792248885\n",
      "Epoch 35::Minibatch 569::LR 0.0215384615385 --> Loss 0.000558646023273\n",
      "Epoch 35::Minibatch 570::LR 0.0215384615385 --> Loss 0.00160129239162\n",
      "Epoch 35::Minibatch 571::LR 0.0215384615385 --> Loss 0.00201374868552\n",
      "Epoch 35::Minibatch 572::LR 0.0215384615385 --> Loss 0.00217218995094\n",
      "Epoch 35::Minibatch 573::LR 0.0215384615385 --> Loss 0.00141807248195\n",
      "Epoch 35::Minibatch 574::LR 0.0215384615385 --> Loss 0.00104140967131\n",
      "Epoch 35::Minibatch 575::LR 0.0215384615385 --> Loss 0.00169645051161\n",
      "Epoch 35::Minibatch 576::LR 0.0215384615385 --> Loss 0.00200971762339\n",
      "Epoch 35::Minibatch 577::LR 0.0215384615385 --> Loss 0.0015904845794\n",
      "Epoch 35::Minibatch 578::LR 0.0215384615385 --> Loss 0.00125357518593\n",
      "Epoch 35::Minibatch 579::LR 0.0215384615385 --> Loss 0.00117528051138\n",
      "Epoch 35::Minibatch 580::LR 0.0215384615385 --> Loss 0.00191218972206\n",
      "Epoch 35::Minibatch 581::LR 0.0215384615385 --> Loss 0.00169911483924\n",
      "Epoch 35::Minibatch 582::LR 0.0215384615385 --> Loss 0.00420297423999\n",
      "Epoch 35::Minibatch 583::LR 0.0215384615385 --> Loss 0.000954088568687\n",
      "Epoch 35::Minibatch 584::LR 0.0215384615385 --> Loss 0.00130969206492\n",
      "Epoch 35::Minibatch 585::LR 0.0215384615385 --> Loss 0.00385543823242\n",
      "Epoch 35::Minibatch 586::LR 0.0215384615385 --> Loss 0.00368295629819\n",
      "Epoch 35::Minibatch 587::LR 0.0215384615385 --> Loss 0.00110732406378\n",
      "Epoch 35::Minibatch 588::LR 0.0215384615385 --> Loss 0.00135936240355\n",
      "Epoch 35::Minibatch 589::LR 0.0215384615385 --> Loss 0.00271087567012\n",
      "Epoch 35::Minibatch 590::LR 0.0215384615385 --> Loss 0.00176547825336\n",
      "Epoch 35::Minibatch 591::LR 0.0215384615385 --> Loss 0.00262790938218\n",
      "Epoch 35::Minibatch 592::LR 0.0215384615385 --> Loss 0.00114122092724\n",
      "Epoch 35::Minibatch 593::LR 0.0215384615385 --> Loss 0.00243186612924\n",
      "Epoch 35::Minibatch 594::LR 0.0215384615385 --> Loss 0.00250590205193\n",
      "Epoch 35::Minibatch 595::LR 0.0215384615385 --> Loss 0.00303394734859\n",
      "Epoch 35::Minibatch 596::LR 0.0215384615385 --> Loss 0.00181211948395\n",
      "Epoch 35::Minibatch 597::LR 0.0215384615385 --> Loss 0.00115535110235\n",
      "Epoch 35::Minibatch 598::LR 0.0215384615385 --> Loss 0.00275624950727\n",
      "Epoch 35::Minibatch 599::LR 0.0215384615385 --> Loss 0.00177220880985\n",
      "Epoch 35::Minibatch 600::LR 0.0215384615385 --> Loss 0.00209664245447\n",
      "Epoch 35::Minibatch 601::LR 0.0215384615385 --> Loss 0.00368930101395\n",
      "Epoch 35::Minibatch 602::LR 0.0215384615385 --> Loss 0.00207176427046\n",
      "Epoch 35::Minibatch 603::LR 0.0215384615385 --> Loss 0.00260826726755\n",
      "Epoch 35::Minibatch 604::LR 0.0215384615385 --> Loss 0.00161684840918\n",
      "Epoch 35::Minibatch 605::LR 0.0215384615385 --> Loss 0.00225112835566\n",
      "Epoch 35::Minibatch 606::LR 0.0215384615385 --> Loss 0.00182918409506\n",
      "Epoch 35::Minibatch 607::LR 0.0215384615385 --> Loss 0.000818601697683\n",
      "Epoch 35::Minibatch 608::LR 0.0215384615385 --> Loss 0.00153809050719\n",
      "Epoch 35::Minibatch 609::LR 0.0215384615385 --> Loss 0.00242077410221\n",
      "Epoch 35::Minibatch 610::LR 0.0215384615385 --> Loss 0.00404866059621\n",
      "Epoch 35::Minibatch 611::LR 0.0215384615385 --> Loss 0.00269410093625\n",
      "Epoch 35::Minibatch 612::LR 0.0215384615385 --> Loss 0.000468227813641\n",
      "Epoch 35::Minibatch 613::LR 0.0215384615385 --> Loss 0.00131124615669\n",
      "Epoch 35::Minibatch 614::LR 0.0215384615385 --> Loss 0.00238804002603\n",
      "Epoch 35::Minibatch 615::LR 0.0215384615385 --> Loss 0.001640364031\n",
      "Epoch 35::Minibatch 616::LR 0.0215384615385 --> Loss 0.000911619961262\n",
      "Epoch 35::Minibatch 617::LR 0.0215384615385 --> Loss 0.000490046789249\n",
      "Epoch 35::Minibatch 618::LR 0.0215384615385 --> Loss 0.00293848832448\n",
      "Epoch 35::Minibatch 619::LR 0.0215384615385 --> Loss 0.00192660133044\n",
      "Epoch 35::Minibatch 620::LR 0.0215384615385 --> Loss 0.0016771697998\n",
      "Epoch 35::Minibatch 621::LR 0.0215384615385 --> Loss 0.000841860771179\n",
      "Epoch 35::Minibatch 622::LR 0.0215384615385 --> Loss 0.000775864819686\n",
      "Epoch 35::Minibatch 623::LR 0.0215384615385 --> Loss 0.00221278985341\n",
      "Epoch 35::Minibatch 624::LR 0.0215384615385 --> Loss 0.00175687770049\n",
      "Epoch 35::Minibatch 625::LR 0.0215384615385 --> Loss 0.00260978380839\n",
      "Epoch 35::Minibatch 626::LR 0.0215384615385 --> Loss 0.00344370603561\n",
      "Epoch 35::Minibatch 627::LR 0.0215384615385 --> Loss 0.00125986725092\n",
      "Epoch 35::Minibatch 628::LR 0.0215384615385 --> Loss 0.000873241523902\n",
      "Epoch 35::Minibatch 629::LR 0.0215384615385 --> Loss 0.00299023389816\n",
      "Epoch 35::Minibatch 630::LR 0.0215384615385 --> Loss 0.00293257772923\n",
      "Epoch 35::Minibatch 631::LR 0.0215384615385 --> Loss 0.00492867906888\n",
      "Epoch 35::Minibatch 632::LR 0.0215384615385 --> Loss 0.000795837144057\n",
      "Epoch 35::Minibatch 633::LR 0.0215384615385 --> Loss 0.00160326719284\n",
      "Epoch 35::Minibatch 634::LR 0.0215384615385 --> Loss 0.00315535604954\n",
      "Epoch 35::Minibatch 635::LR 0.0215384615385 --> Loss 0.00532954970996\n",
      "Epoch 35::Minibatch 636::LR 0.0215384615385 --> Loss 0.00447865168254\n",
      "Epoch 35::Minibatch 637::LR 0.0215384615385 --> Loss 0.000702521751324\n",
      "Epoch 35::Minibatch 638::LR 0.0215384615385 --> Loss 0.00148655364911\n",
      "Epoch 35::Minibatch 639::LR 0.0215384615385 --> Loss 0.00315550188224\n",
      "Epoch 35::Minibatch 640::LR 0.0215384615385 --> Loss 0.00444218595823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 641::LR 0.0215384615385 --> Loss 0.00300471981366\n",
      "Epoch 35::Minibatch 642::LR 0.0215384615385 --> Loss 0.000532486637433\n",
      "Epoch 35::Minibatch 643::LR 0.0215384615385 --> Loss 0.00229977170626\n",
      "Epoch 35::Minibatch 644::LR 0.0215384615385 --> Loss 0.00383248408635\n",
      "Epoch 35::Minibatch 645::LR 0.0215384615385 --> Loss 0.00452261368434\n",
      "Epoch 35::Minibatch 646::LR 0.0215384615385 --> Loss 0.00151209533215\n",
      "Epoch 35::Minibatch 647::LR 0.0215384615385 --> Loss 0.000459667692582\n",
      "Epoch 35::Minibatch 648::LR 0.0215384615385 --> Loss 0.0027009554704\n",
      "Epoch 35::Minibatch 649::LR 0.0215384615385 --> Loss 0.00310531675816\n",
      "Epoch 35::Minibatch 650::LR 0.0215384615385 --> Loss 0.00309221029282\n",
      "Epoch 35::Minibatch 651::LR 0.0215384615385 --> Loss 0.00131301164627\n",
      "Epoch 35::Minibatch 652::LR 0.0215384615385 --> Loss 0.000777385532856\n",
      "Epoch 35::Minibatch 653::LR 0.0215384615385 --> Loss 0.00278019746145\n",
      "Epoch 35::Minibatch 654::LR 0.0215384615385 --> Loss 0.00310199240843\n",
      "Epoch 35::Minibatch 655::LR 0.0215384615385 --> Loss 0.00366446495056\n",
      "Epoch 35::Minibatch 656::LR 0.0215384615385 --> Loss 0.000757024288177\n",
      "Epoch 35::Minibatch 657::LR 0.0215384615385 --> Loss 0.00226154784362\n",
      "Epoch 35::Minibatch 658::LR 0.0215384615385 --> Loss 0.00439282536507\n",
      "Epoch 35::Minibatch 659::LR 0.0215384615385 --> Loss 0.00218597531319\n",
      "Epoch 35::Minibatch 660::LR 0.0215384615385 --> Loss 0.00264316380024\n",
      "Epoch 35::Minibatch 661::LR 0.0215384615385 --> Loss 0.00221905986468\n",
      "Epoch 35::Minibatch 662::LR 0.0215384615385 --> Loss 0.0017880543073\n",
      "Epoch 35::Minibatch 663::LR 0.0215384615385 --> Loss 0.0036162896951\n",
      "Epoch 35::Minibatch 664::LR 0.0215384615385 --> Loss 0.00307464996974\n",
      "Epoch 35::Minibatch 665::LR 0.0215384615385 --> Loss 0.000691469411055\n",
      "Epoch 35::Minibatch 666::LR 0.0215384615385 --> Loss 0.00390161832174\n",
      "Epoch 35::Minibatch 667::LR 0.0215384615385 --> Loss 0.00254291951656\n",
      "Epoch 35::Minibatch 668::LR 0.0215384615385 --> Loss 0.00616930921872\n",
      "Epoch 35::Minibatch 669::LR 0.0215384615385 --> Loss 0.00107767691215\n",
      "Epoch 35::Minibatch 670::LR 0.0215384615385 --> Loss 0.00132266153892\n",
      "Epoch 35::Minibatch 671::LR 0.0215384615385 --> Loss 0.00502573569616\n",
      "Epoch 35::Minibatch 672::LR 0.0215384615385 --> Loss 0.00331032117208\n",
      "Epoch 35::Minibatch 673::LR 0.0215384615385 --> Loss 0.00159412016471\n",
      "Epoch 35::Minibatch 674::LR 0.0215384615385 --> Loss 0.00051015595595\n",
      "Epoch 35::Minibatch 675::LR 0.0215384615385 --> Loss 0.00219918767611\n",
      "Epoch 35::Minibatch 676::LR 0.0215384615385 --> Loss 0.00216986179352\n",
      "Epoch 35::Minibatch 677::LR 0.0215384615385 --> Loss 0.00268008410931\n",
      "Epoch 35::Minibatch 678::LR 0.0215384615385 --> Loss 0.00185169816017\n",
      "Epoch 35::Minibatch 679::LR 0.0215384615385 --> Loss 0.00327627897263\n",
      "Epoch 35::Minibatch 680::LR 0.0215384615385 --> Loss 0.00211551686128\n",
      "Epoch 35::Minibatch 681::LR 0.0215384615385 --> Loss 0.00236142377059\n",
      "Epoch 35::Minibatch 682::LR 0.0215384615385 --> Loss 0.000761987417936\n",
      "Epoch 35::Minibatch 683::LR 0.0215384615385 --> Loss 0.00227799991767\n",
      "Epoch 35::Minibatch 684::LR 0.0215384615385 --> Loss 0.00234098176161\n",
      "Epoch 35::Minibatch 685::LR 0.0215384615385 --> Loss 0.00280039012432\n",
      "Epoch 35::Minibatch 686::LR 0.0215384615385 --> Loss 0.00158272733291\n",
      "Epoch 35::Minibatch 687::LR 0.0215384615385 --> Loss 0.000880211591721\n",
      "Epoch 35::Minibatch 688::LR 0.0215384615385 --> Loss 0.0028095861276\n",
      "Epoch 35::Minibatch 689::LR 0.0215384615385 --> Loss 0.00245427588622\n",
      "Epoch 35::Minibatch 690::LR 0.0215384615385 --> Loss 0.00186359425386\n",
      "Epoch 35::Minibatch 691::LR 0.0215384615385 --> Loss 0.000657478223244\n",
      "Epoch 35::Minibatch 692::LR 0.0215384615385 --> Loss 0.00243738253911\n",
      "Epoch 35::Minibatch 693::LR 0.0215384615385 --> Loss 0.00262645681699\n",
      "Epoch 35::Minibatch 694::LR 0.0215384615385 --> Loss 0.00298004647096\n",
      "Epoch 35::Minibatch 695::LR 0.0215384615385 --> Loss 0.00180962721507\n",
      "Epoch 35::Minibatch 696::LR 0.0215384615385 --> Loss 0.00202327887217\n",
      "Epoch 35::Minibatch 697::LR 0.0215384615385 --> Loss 0.00139730026325\n",
      "Epoch 35::Minibatch 698::LR 0.0215384615385 --> Loss 0.00166615953048\n",
      "Epoch 35::Minibatch 699::LR 0.0215384615385 --> Loss 0.00366672515869\n",
      "Epoch 35::Minibatch 700::LR 0.0215384615385 --> Loss 0.0025455480814\n",
      "Epoch 35::Minibatch 701::LR 0.0215384615385 --> Loss 0.00186571041743\n",
      "Epoch 35::Minibatch 702::LR 0.0215384615385 --> Loss 0.00166936218739\n",
      "Epoch 35::Minibatch 703::LR 0.0215384615385 --> Loss 0.00426994403203\n",
      "Epoch 35::Minibatch 704::LR 0.0215384615385 --> Loss 0.00180458565553\n",
      "Epoch 35::Minibatch 705::LR 0.0215384615385 --> Loss 0.00282011210918\n",
      "Epoch 35::Minibatch 706::LR 0.0215384615385 --> Loss 0.00218850811323\n",
      "Epoch 35::Minibatch 707::LR 0.0215384615385 --> Loss 0.00118168691794\n",
      "Epoch 35::Minibatch 708::LR 0.0215384615385 --> Loss 0.00173016011715\n",
      "Epoch 35::Minibatch 709::LR 0.0215384615385 --> Loss 0.00166703939438\n",
      "Epoch 35::Minibatch 710::LR 0.0215384615385 --> Loss 0.00259060144424\n",
      "Epoch 35::Minibatch 711::LR 0.0215384615385 --> Loss 0.0019883286953\n",
      "Epoch 35::Minibatch 712::LR 0.0215384615385 --> Loss 0.00137349237998\n",
      "Epoch 35::Minibatch 713::LR 0.0215384615385 --> Loss 0.0018061987559\n",
      "Epoch 35::Minibatch 714::LR 0.0215384615385 --> Loss 0.00288465559483\n",
      "Epoch 35::Minibatch 715::LR 0.0215384615385 --> Loss 0.00291634698709\n",
      "Epoch 35::Minibatch 716::LR 0.0215384615385 --> Loss 0.00167379717032\n",
      "Epoch 35::Minibatch 717::LR 0.0215384615385 --> Loss 0.00167968451977\n",
      "Epoch 35::Minibatch 718::LR 0.0215384615385 --> Loss 0.00128777325153\n",
      "Epoch 35::Minibatch 719::LR 0.0215384615385 --> Loss 0.00173982878526\n",
      "Epoch 35::Minibatch 720::LR 0.0215384615385 --> Loss 0.00280861616135\n",
      "Epoch 35::Minibatch 721::LR 0.0215384615385 --> Loss 0.000604750613372\n",
      "Epoch 35::Minibatch 722::LR 0.0215384615385 --> Loss 0.00454669515292\n",
      "Epoch 35::Minibatch 723::LR 0.0215384615385 --> Loss 0.00478708028793\n",
      "Epoch 35::Minibatch 724::LR 0.0215384615385 --> Loss 0.000964674750964\n",
      "Epoch 35::Minibatch 725::LR 0.0215384615385 --> Loss 0.00202903012435\n",
      "Epoch 35::Minibatch 726::LR 0.0215384615385 --> Loss 0.00346549669902\n",
      "Epoch 35::Minibatch 727::LR 0.0215384615385 --> Loss 0.00297815998395\n",
      "Epoch 35::Minibatch 728::LR 0.0215384615385 --> Loss 0.000641429473956\n",
      "Epoch 35::Minibatch 729::LR 0.0215384615385 --> Loss 0.000713605632385\n",
      "Epoch 35::Minibatch 730::LR 0.0215384615385 --> Loss 0.00289638141791\n",
      "Epoch 35::Minibatch 731::LR 0.0215384615385 --> Loss 0.0026294140021\n",
      "Epoch 35::Minibatch 732::LR 0.0215384615385 --> Loss 0.0020018919309\n",
      "Epoch 35::Minibatch 733::LR 0.0215384615385 --> Loss 0.000581128895283\n",
      "Epoch 35::Minibatch 734::LR 0.0215384615385 --> Loss 0.00162468810876\n",
      "Epoch 35::Minibatch 735::LR 0.0215384615385 --> Loss 0.00250770509243\n",
      "Epoch 35::Minibatch 736::LR 0.0215384615385 --> Loss 0.0034740503629\n",
      "Epoch 35::Minibatch 737::LR 0.0215384615385 --> Loss 0.00287778019905\n",
      "Epoch 35::Minibatch 738::LR 0.0215384615385 --> Loss 0.00133949329456\n",
      "Epoch 35::Minibatch 739::LR 0.0215384615385 --> Loss 0.00234062333902\n",
      "Epoch 35::Minibatch 740::LR 0.0215384615385 --> Loss 0.00373773654302\n",
      "Epoch 35::Minibatch 741::LR 0.0215384615385 --> Loss 0.00249775886536\n",
      "Epoch 35::Minibatch 742::LR 0.0215384615385 --> Loss 0.00206121663253\n",
      "Epoch 35::Minibatch 743::LR 0.0215384615385 --> Loss 0.0015186966459\n",
      "Epoch 35::Minibatch 744::LR 0.0215384615385 --> Loss 0.00188890079657\n",
      "Epoch 35::Minibatch 745::LR 0.0215384615385 --> Loss 0.00275740404924\n",
      "Epoch 35::Minibatch 746::LR 0.0215384615385 --> Loss 0.00281607846419\n",
      "Epoch 35::Minibatch 747::LR 0.0215384615385 --> Loss 0.00174719631672\n",
      "Epoch 35::Minibatch 748::LR 0.0215384615385 --> Loss 0.000622371633848\n",
      "Epoch 35::Minibatch 749::LR 0.0215384615385 --> Loss 0.00168224493663\n",
      "Epoch 35::Minibatch 750::LR 0.0215384615385 --> Loss 0.00240721126397\n",
      "Epoch 35::Minibatch 751::LR 0.0215384615385 --> Loss 0.00296629607677\n",
      "Epoch 35::Minibatch 752::LR 0.0215384615385 --> Loss 0.00149756848812\n",
      "Epoch 35::Minibatch 753::LR 0.0215384615385 --> Loss 0.00219449559848\n",
      "Epoch 35::Minibatch 754::LR 0.0215384615385 --> Loss 0.00242517550786\n",
      "Epoch 35::Minibatch 755::LR 0.0215384615385 --> Loss 0.00265452643236\n",
      "Epoch 35::Minibatch 756::LR 0.0215384615385 --> Loss 0.00129024326801\n",
      "Epoch 35::Minibatch 757::LR 0.0215384615385 --> Loss 0.000571154306332\n",
      "Epoch 35::Minibatch 758::LR 0.0215384615385 --> Loss 0.00155946046114\n",
      "Epoch 35::Minibatch 759::LR 0.0215384615385 --> Loss 0.00332523564498\n",
      "Epoch 35::Minibatch 760::LR 0.0215384615385 --> Loss 0.00275324781736\n",
      "Epoch 35::Minibatch 761::LR 0.0215384615385 --> Loss 0.00541620095571\n",
      "Epoch 35::Minibatch 762::LR 0.0215384615385 --> Loss 0.00349368691444\n",
      "Epoch 35::Minibatch 763::LR 0.0215384615385 --> Loss 0.00339440107346\n",
      "Epoch 35::Minibatch 764::LR 0.0215384615385 --> Loss 0.00299011806647\n",
      "Epoch 35::Minibatch 765::LR 0.0215384615385 --> Loss 0.00123258441687\n",
      "Epoch 35::Minibatch 766::LR 0.0215384615385 --> Loss 0.00229840258757\n",
      "Epoch 35::Minibatch 767::LR 0.0215384615385 --> Loss 0.00472245494525\n",
      "Epoch 35::Minibatch 768::LR 0.0215384615385 --> Loss 0.0036196064949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 769::LR 0.0215384615385 --> Loss 0.00181954701742\n",
      "Epoch 35::Minibatch 770::LR 0.0215384615385 --> Loss 0.00151252279679\n",
      "Epoch 35::Minibatch 771::LR 0.0215384615385 --> Loss 0.00334111054738\n",
      "Epoch 35::Minibatch 772::LR 0.0215384615385 --> Loss 0.00365162650744\n",
      "Epoch 35::Minibatch 773::LR 0.0215384615385 --> Loss 0.00319526831309\n",
      "Epoch 35::Minibatch 774::LR 0.0215384615385 --> Loss 0.00190289517244\n",
      "Epoch 35::Minibatch 775::LR 0.0215384615385 --> Loss 0.0031974730889\n",
      "Epoch 35::Minibatch 776::LR 0.0215384615385 --> Loss 0.00386195262273\n",
      "Epoch 35::Minibatch 777::LR 0.0215384615385 --> Loss 0.0058641131719\n",
      "Epoch 35::Minibatch 778::LR 0.0215384615385 --> Loss 0.00686337868373\n",
      "Epoch 35::Minibatch 779::LR 0.0215384615385 --> Loss 0.00249377767245\n",
      "Epoch 35::Minibatch 780::LR 0.0215384615385 --> Loss 0.00148793309927\n",
      "Epoch 35::Minibatch 781::LR 0.0215384615385 --> Loss 0.00349709471067\n",
      "Epoch 35::Minibatch 782::LR 0.0215384615385 --> Loss 0.00382124662399\n",
      "Epoch 35::Minibatch 783::LR 0.0215384615385 --> Loss 0.00226106007894\n",
      "Epoch 35::Minibatch 784::LR 0.0215384615385 --> Loss 0.000711373587449\n",
      "Epoch 35::Minibatch 785::LR 0.0215384615385 --> Loss 0.00344188014666\n",
      "Epoch 35::Minibatch 786::LR 0.0215384615385 --> Loss 0.00361626068751\n",
      "Epoch 35::Minibatch 787::LR 0.0215384615385 --> Loss 0.00256770074368\n",
      "Epoch 35::Minibatch 788::LR 0.0215384615385 --> Loss 0.00243193348249\n",
      "Epoch 35::Minibatch 789::LR 0.0215384615385 --> Loss 0.000723476658265\n",
      "Epoch 35::Minibatch 790::LR 0.0215384615385 --> Loss 0.00315697689851\n",
      "Epoch 35::Minibatch 791::LR 0.0215384615385 --> Loss 0.0032311040163\n",
      "Epoch 35::Minibatch 792::LR 0.0215384615385 --> Loss 0.00298495491346\n",
      "Epoch 35::Minibatch 793::LR 0.0215384615385 --> Loss 0.00162941485643\n",
      "Epoch 35::Minibatch 794::LR 0.0215384615385 --> Loss 0.000981797277927\n",
      "Epoch 35::Minibatch 795::LR 0.0215384615385 --> Loss 0.00260899325212\n",
      "Epoch 35::Minibatch 796::LR 0.0215384615385 --> Loss 0.00472100337346\n",
      "Epoch 35::Minibatch 797::LR 0.0215384615385 --> Loss 0.00557810703913\n",
      "Epoch 35::Minibatch 798::LR 0.0215384615385 --> Loss 0.0029565101862\n",
      "Epoch 35::Minibatch 799::LR 0.0215384615385 --> Loss 0.00223872641722\n",
      "Epoch 35::Minibatch 800::LR 0.0215384615385 --> Loss 0.00199951728185\n",
      "Epoch 35::Minibatch 801::LR 0.0215384615385 --> Loss 0.00379319747289\n",
      "Epoch 35::Minibatch 802::LR 0.0215384615385 --> Loss 0.0011887683471\n",
      "Epoch 35::Minibatch 803::LR 0.0215384615385 --> Loss 0.00295870482922\n",
      "Epoch 35::Minibatch 804::LR 0.0215384615385 --> Loss 0.0020617800951\n",
      "Epoch 35::Minibatch 805::LR 0.0215384615385 --> Loss 0.00217552522818\n",
      "Epoch 35::Minibatch 806::LR 0.0215384615385 --> Loss 0.003312048316\n",
      "Epoch 35::Minibatch 807::LR 0.0215384615385 --> Loss 0.00306691110134\n",
      "Epoch 35::Minibatch 808::LR 0.0215384615385 --> Loss 0.00287123819192\n",
      "Epoch 35::Minibatch 809::LR 0.0215384615385 --> Loss 0.00299514790376\n",
      "Epoch 35::Minibatch 810::LR 0.0215384615385 --> Loss 0.00408037900925\n",
      "Epoch 35::Minibatch 811::LR 0.0215384615385 --> Loss 0.00392265796661\n",
      "Epoch 35::Minibatch 812::LR 0.0215384615385 --> Loss 0.00361623446147\n",
      "Epoch 35::Minibatch 813::LR 0.0215384615385 --> Loss 0.002983755668\n",
      "Epoch 35::Minibatch 814::LR 0.0215384615385 --> Loss 0.00150916109482\n",
      "Epoch 35::Minibatch 815::LR 0.0215384615385 --> Loss 0.00345683733622\n",
      "Epoch 35::Minibatch 816::LR 0.0215384615385 --> Loss 0.0039073018233\n",
      "Epoch 35::Minibatch 817::LR 0.0215384615385 --> Loss 0.00466131567955\n",
      "Epoch 35::Minibatch 818::LR 0.0215384615385 --> Loss 0.00123363594214\n",
      "Epoch 35::Minibatch 819::LR 0.0215384615385 --> Loss 0.000727205574512\n",
      "Epoch 35::Minibatch 820::LR 0.0215384615385 --> Loss 0.00501295924187\n",
      "Epoch 35::Minibatch 821::LR 0.0215384615385 --> Loss 0.00306025365988\n",
      "Epoch 35::Minibatch 822::LR 0.0215384615385 --> Loss 0.00366676608721\n",
      "Epoch 35::Minibatch 823::LR 0.0215384615385 --> Loss 0.00125308285157\n",
      "Epoch 35::Minibatch 824::LR 0.0215384615385 --> Loss 0.00136666347583\n",
      "Epoch 35::Minibatch 825::LR 0.0215384615385 --> Loss 0.00375240961711\n",
      "Epoch 35::Minibatch 826::LR 0.0215384615385 --> Loss 0.00444068829219\n",
      "Epoch 35::Minibatch 827::LR 0.0215384615385 --> Loss 0.00205569386482\n",
      "Epoch 35::Minibatch 828::LR 0.0215384615385 --> Loss 0.00048653965195\n",
      "Epoch 35::Minibatch 829::LR 0.0215384615385 --> Loss 0.00225770652294\n",
      "Epoch 35::Minibatch 830::LR 0.0215384615385 --> Loss 0.00393318335215\n",
      "Epoch 35::Minibatch 831::LR 0.0215384615385 --> Loss 0.00235715270042\n",
      "Epoch 35::Minibatch 832::LR 0.0215384615385 --> Loss 0.00207931657632\n",
      "Epoch 35::Minibatch 833::LR 0.0215384615385 --> Loss 0.00180562496185\n",
      "Epoch 35::Minibatch 834::LR 0.0215384615385 --> Loss 0.000790221244097\n",
      "Epoch 35::Minibatch 835::LR 0.0215384615385 --> Loss 0.00380666732788\n",
      "Epoch 35::Minibatch 836::LR 0.0215384615385 --> Loss 0.00356366554896\n",
      "Epoch 35::Minibatch 837::LR 0.0215384615385 --> Loss 0.00225951135159\n",
      "Epoch 35::Minibatch 838::LR 0.0215384615385 --> Loss 0.000647713343302\n",
      "Epoch 35::Minibatch 839::LR 0.0215384615385 --> Loss 0.00235641101996\n",
      "Epoch 35::Minibatch 840::LR 0.0215384615385 --> Loss 0.00283776382605\n",
      "Epoch 35::Minibatch 841::LR 0.0215384615385 --> Loss 0.00274584849675\n",
      "Epoch 35::Minibatch 842::LR 0.0215384615385 --> Loss 0.00210223595301\n",
      "Epoch 35::Minibatch 843::LR 0.0215384615385 --> Loss 0.000969022115072\n",
      "Epoch 35::Minibatch 844::LR 0.0215384615385 --> Loss 0.00146298229694\n",
      "Epoch 35::Minibatch 845::LR 0.0215384615385 --> Loss 0.00396292805672\n",
      "Epoch 35::Minibatch 846::LR 0.0215384615385 --> Loss 0.00166866381963\n",
      "Epoch 35::Minibatch 847::LR 0.0215384615385 --> Loss 0.00237043758233\n",
      "Epoch 35::Minibatch 848::LR 0.0215384615385 --> Loss 0.00113408615192\n",
      "Epoch 35::Minibatch 849::LR 0.0215384615385 --> Loss 0.00178352693717\n",
      "Epoch 35::Minibatch 850::LR 0.0215384615385 --> Loss 0.00315160195033\n",
      "Epoch 35::Minibatch 851::LR 0.0215384615385 --> Loss 0.00252663056056\n",
      "Epoch 35::Minibatch 852::LR 0.0215384615385 --> Loss 0.00113792320093\n",
      "Epoch 35::Minibatch 853::LR 0.0215384615385 --> Loss 0.00130481630564\n",
      "Epoch 35::Minibatch 854::LR 0.0215384615385 --> Loss 0.00251844068368\n",
      "Epoch 35::Minibatch 855::LR 0.0215384615385 --> Loss 0.0020996773243\n",
      "Epoch 35::Minibatch 856::LR 0.0215384615385 --> Loss 0.00177412350972\n",
      "Epoch 35::Minibatch 857::LR 0.0215384615385 --> Loss 0.00120583424966\n",
      "Epoch 35::Minibatch 858::LR 0.0215384615385 --> Loss 0.00060167123874\n",
      "Epoch 35::Minibatch 859::LR 0.0215384615385 --> Loss 0.00198520481586\n",
      "Epoch 35::Minibatch 860::LR 0.0215384615385 --> Loss 0.00130379637082\n",
      "Epoch 35::Minibatch 861::LR 0.0215384615385 --> Loss 0.000946636497974\n",
      "Epoch 35::Minibatch 862::LR 0.0215384615385 --> Loss 0.00371854503949\n",
      "Epoch 35::Minibatch 863::LR 0.0215384615385 --> Loss 0.00335306604703\n",
      "Epoch 35::Minibatch 864::LR 0.0215384615385 --> Loss 0.00258679171403\n",
      "Epoch 35::Minibatch 865::LR 0.0215384615385 --> Loss 0.000523272156715\n",
      "Epoch 35::Minibatch 866::LR 0.0215384615385 --> Loss 0.00206742525101\n",
      "Epoch 35::Minibatch 867::LR 0.0215384615385 --> Loss 0.00285943984985\n",
      "Epoch 35::Minibatch 868::LR 0.0215384615385 --> Loss 0.00242958207925\n",
      "Epoch 35::Minibatch 869::LR 0.0215384615385 --> Loss 0.0021369800965\n",
      "Epoch 35::Minibatch 870::LR 0.0215384615385 --> Loss 0.00320837636789\n",
      "Epoch 35::Minibatch 871::LR 0.0215384615385 --> Loss 0.00163251399994\n",
      "Epoch 35::Minibatch 872::LR 0.0215384615385 --> Loss 0.00209672729174\n",
      "Epoch 35::Minibatch 873::LR 0.0215384615385 --> Loss 0.00245503922304\n",
      "Epoch 35::Minibatch 874::LR 0.0215384615385 --> Loss 0.00500575701396\n",
      "Epoch 35::Minibatch 875::LR 0.0215384615385 --> Loss 0.000646054546038\n",
      "Epoch 35::Minibatch 876::LR 0.0215384615385 --> Loss 0.00268078287443\n",
      "Epoch 35::Minibatch 877::LR 0.0215384615385 --> Loss 0.00437658588092\n",
      "Epoch 35::Minibatch 878::LR 0.0215384615385 --> Loss 0.0028862841924\n",
      "Epoch 35::Minibatch 879::LR 0.0215384615385 --> Loss 0.00387541890144\n",
      "Epoch 35::Minibatch 880::LR 0.0215384615385 --> Loss 0.00486251711845\n",
      "Epoch 35::Minibatch 881::LR 0.0215384615385 --> Loss 0.00416471441587\n",
      "Epoch 35::Minibatch 882::LR 0.0215384615385 --> Loss 0.00189442296823\n",
      "Epoch 35::Minibatch 883::LR 0.0215384615385 --> Loss 0.00363328377406\n",
      "Epoch 35::Minibatch 884::LR 0.0215384615385 --> Loss 0.00280196030935\n",
      "Epoch 35::Minibatch 885::LR 0.0215384615385 --> Loss 0.00258581876755\n",
      "Epoch 35::Minibatch 886::LR 0.0215384615385 --> Loss 0.000437473058701\n",
      "Epoch 35::Minibatch 887::LR 0.0215384615385 --> Loss 0.00554538965225\n",
      "Epoch 35::Minibatch 888::LR 0.0215384615385 --> Loss 0.0024242546161\n",
      "Epoch 35::Minibatch 889::LR 0.0215384615385 --> Loss 0.00248197535674\n",
      "Epoch 35::Minibatch 890::LR 0.0215384615385 --> Loss 0.00357056180636\n",
      "Epoch 35::Minibatch 891::LR 0.0215384615385 --> Loss 0.00169746001561\n",
      "Epoch 35::Minibatch 892::LR 0.0215384615385 --> Loss 0.000783746689558\n",
      "Epoch 35::Minibatch 893::LR 0.0215384615385 --> Loss 0.00223363876343\n",
      "Epoch 35::Minibatch 894::LR 0.0215384615385 --> Loss 0.00195864597956\n",
      "Epoch 35::Minibatch 895::LR 0.0215384615385 --> Loss 0.00225319564342\n",
      "Epoch 35::Minibatch 896::LR 0.0215384615385 --> Loss 0.00125007927418\n",
      "Epoch 35::Minibatch 897::LR 0.0215384615385 --> Loss 0.000665811002254\n",
      "Epoch 35::Minibatch 898::LR 0.0215384615385 --> Loss 0.00195037265619\n",
      "Epoch 35::Minibatch 899::LR 0.0215384615385 --> Loss 0.00244129896164\n",
      "Epoch 35::Minibatch 900::LR 0.0215384615385 --> Loss 0.00302145381769\n",
      "Epoch 35::Minibatch 901::LR 0.0215384615385 --> Loss 0.000583181579908\n",
      "Epoch 35::Minibatch 902::LR 0.0215384615385 --> Loss 0.00138820787271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 903::LR 0.0215384615385 --> Loss 0.00254251043002\n",
      "Epoch 35::Minibatch 904::LR 0.0215384615385 --> Loss 0.0017943829298\n",
      "Epoch 35::Minibatch 905::LR 0.0215384615385 --> Loss 0.00138851026694\n",
      "Epoch 35::Minibatch 906::LR 0.0215384615385 --> Loss 0.00101573904355\n",
      "Epoch 35::Minibatch 907::LR 0.0215384615385 --> Loss 0.00153878947099\n",
      "Epoch 35::Minibatch 908::LR 0.0215384615385 --> Loss 0.00206267098586\n",
      "Epoch 35::Minibatch 909::LR 0.0215384615385 --> Loss 0.00192391733329\n",
      "Epoch 35::Minibatch 910::LR 0.0215384615385 --> Loss 0.000839947164059\n",
      "Epoch 35::Minibatch 911::LR 0.0215384615385 --> Loss 0.00127403299014\n",
      "Epoch 35::Minibatch 912::LR 0.0215384615385 --> Loss 0.00206333458424\n",
      "Epoch 35::Minibatch 913::LR 0.0215384615385 --> Loss 0.00229156454404\n",
      "Epoch 35::Minibatch 914::LR 0.0215384615385 --> Loss 0.00125775396824\n",
      "Epoch 35::Minibatch 915::LR 0.0215384615385 --> Loss 0.000535717308521\n",
      "Epoch 35::Minibatch 916::LR 0.0215384615385 --> Loss 0.00199380119642\n",
      "Epoch 35::Minibatch 917::LR 0.0215384615385 --> Loss 0.00316387693087\n",
      "Epoch 35::Minibatch 918::LR 0.0215384615385 --> Loss 0.00449801246325\n",
      "Epoch 35::Minibatch 919::LR 0.0215384615385 --> Loss 0.000547220806281\n",
      "Epoch 35::Minibatch 920::LR 0.0215384615385 --> Loss 0.0118638149897\n",
      "Epoch 35::Minibatch 921::LR 0.0215384615385 --> Loss 0.00300870895386\n",
      "Epoch 35::Minibatch 922::LR 0.0215384615385 --> Loss 0.00299750109514\n",
      "Epoch 35::Minibatch 923::LR 0.0215384615385 --> Loss 0.00112897674243\n",
      "Epoch 35::Minibatch 924::LR 0.0215384615385 --> Loss 0.00313515444597\n",
      "Epoch 35::Minibatch 925::LR 0.0215384615385 --> Loss 0.00220715165138\n",
      "Epoch 35::Minibatch 926::LR 0.0215384615385 --> Loss 0.00445109605789\n",
      "Epoch 35::Minibatch 927::LR 0.0215384615385 --> Loss 0.00486810644468\n",
      "Epoch 35::Minibatch 928::LR 0.0215384615385 --> Loss 0.00586422602336\n",
      "Epoch 35::Minibatch 929::LR 0.0215384615385 --> Loss 0.00508348703384\n",
      "Epoch 35::Minibatch 930::LR 0.0215384615385 --> Loss 0.00925501028697\n",
      "Epoch 35::Minibatch 931::LR 0.0215384615385 --> Loss 0.00296869814396\n",
      "Epoch 35::Minibatch 932::LR 0.0215384615385 --> Loss 0.00508834203084\n",
      "Epoch 35::Minibatch 933::LR 0.0215384615385 --> Loss 0.00229276994864\n",
      "Epoch 35::Minibatch 934::LR 0.0215384615385 --> Loss 0.00288273056348\n",
      "Epoch 35::Minibatch 935::LR 0.0215384615385 --> Loss 0.00434307018916\n",
      "Epoch 35::Minibatch 936::LR 0.0215384615385 --> Loss 0.000817200342814\n",
      "Epoch 35::Minibatch 937::LR 0.0215384615385 --> Loss 0.00227136254311\n",
      "Epoch 35::Minibatch 938::LR 0.0215384615385 --> Loss 0.00191802442074\n",
      "Epoch 35::Minibatch 939::LR 0.0215384615385 --> Loss 0.00211587250233\n",
      "Epoch 35::Minibatch 940::LR 0.0215384615385 --> Loss 0.000910448729992\n",
      "Epoch 35::Minibatch 941::LR 0.0215384615385 --> Loss 0.000735841443141\n",
      "Epoch 35::Minibatch 942::LR 0.0215384615385 --> Loss 0.00252516150475\n",
      "Epoch 35::Minibatch 943::LR 0.0215384615385 --> Loss 0.00228330453237\n",
      "Epoch 35::Minibatch 944::LR 0.0215384615385 --> Loss 0.00163440426191\n",
      "Epoch 35::Minibatch 945::LR 0.0215384615385 --> Loss 0.000899372299512\n",
      "Epoch 35::Minibatch 946::LR 0.0215384615385 --> Loss 0.00232088228067\n",
      "Epoch 35::Minibatch 947::LR 0.0215384615385 --> Loss 0.00216999650002\n",
      "Epoch 35::Minibatch 948::LR 0.0215384615385 --> Loss 0.00387405117353\n",
      "Epoch 35::Minibatch 949::LR 0.0215384615385 --> Loss 0.00168933272362\n",
      "Epoch 35::Minibatch 950::LR 0.0215384615385 --> Loss 0.000683847864469\n",
      "Epoch 35::Minibatch 951::LR 0.0215384615385 --> Loss 0.00333741863569\n",
      "Epoch 35::Minibatch 952::LR 0.0215384615385 --> Loss 0.00232242445151\n",
      "Epoch 35::Minibatch 953::LR 0.0215384615385 --> Loss 0.00141306747993\n",
      "Epoch 35::Minibatch 954::LR 0.0215384615385 --> Loss 0.000928146342436\n",
      "Epoch 35::Minibatch 955::LR 0.0215384615385 --> Loss 0.00255490879218\n",
      "Epoch 35::Minibatch 956::LR 0.0215384615385 --> Loss 0.00302229543527\n",
      "Epoch 35::Minibatch 957::LR 0.0215384615385 --> Loss 0.00182353814443\n",
      "Epoch 35::Minibatch 958::LR 0.0215384615385 --> Loss 0.00217644751072\n",
      "Epoch 35::Minibatch 959::LR 0.0215384615385 --> Loss 0.00248530109723\n",
      "Epoch 35::Minibatch 960::LR 0.0215384615385 --> Loss 0.00525435447693\n",
      "Epoch 35::Minibatch 961::LR 0.0215384615385 --> Loss 0.00290545761585\n",
      "Epoch 35::Minibatch 962::LR 0.0215384615385 --> Loss 0.00226159056028\n",
      "Epoch 35::Minibatch 963::LR 0.0215384615385 --> Loss 0.00103424241145\n",
      "Epoch 35::Minibatch 964::LR 0.0215384615385 --> Loss 0.00231029093266\n",
      "Epoch 35::Minibatch 965::LR 0.0215384615385 --> Loss 0.00619146267573\n",
      "Epoch 35::Minibatch 966::LR 0.0215384615385 --> Loss 0.00483420133591\n",
      "Epoch 35::Minibatch 967::LR 0.0215384615385 --> Loss 0.00122788697481\n",
      "Epoch 35::Minibatch 968::LR 0.0215384615385 --> Loss 0.000980600118637\n",
      "Epoch 35::Minibatch 969::LR 0.0215384615385 --> Loss 0.00432378570239\n",
      "Epoch 35::Minibatch 970::LR 0.0215384615385 --> Loss 0.00415519714355\n",
      "Epoch 35::Minibatch 971::LR 0.0215384615385 --> Loss 0.00322941680749\n",
      "Epoch 35::Minibatch 972::LR 0.0215384615385 --> Loss 0.00738378922145\n",
      "Epoch 35::Minibatch 973::LR 0.0215384615385 --> Loss 0.00934056917826\n",
      "Epoch 35::Minibatch 974::LR 0.0215384615385 --> Loss 0.00795497496923\n",
      "Epoch 35::Minibatch 975::LR 0.0215384615385 --> Loss 0.00486576279004\n",
      "Epoch 35::Minibatch 976::LR 0.0215384615385 --> Loss 0.00354954679807\n",
      "Epoch 35::Minibatch 977::LR 0.0215384615385 --> Loss 0.00320022145907\n",
      "Epoch 35::Minibatch 978::LR 0.0215384615385 --> Loss 0.00309985756874\n",
      "Epoch 35::Minibatch 979::LR 0.0215384615385 --> Loss 0.00283800800641\n",
      "Epoch 35::Minibatch 980::LR 0.0215384615385 --> Loss 0.00327500681082\n",
      "Epoch 35::Minibatch 981::LR 0.0215384615385 --> Loss 0.00396902998288\n",
      "Epoch 35::Minibatch 982::LR 0.0215384615385 --> Loss 0.00378557960192\n",
      "Epoch 35::Minibatch 983::LR 0.0215384615385 --> Loss 0.00233910461267\n",
      "Epoch 35::Minibatch 984::LR 0.0215384615385 --> Loss 0.00157313615084\n",
      "Epoch 35::Minibatch 985::LR 0.0215384615385 --> Loss 0.00300659437974\n",
      "Epoch 35::Minibatch 986::LR 0.0215384615385 --> Loss 0.00270772953828\n",
      "Epoch 35::Minibatch 987::LR 0.0215384615385 --> Loss 0.00307379881541\n",
      "Epoch 35::Minibatch 988::LR 0.0215384615385 --> Loss 0.00240072568258\n",
      "Epoch 35::Minibatch 989::LR 0.0215384615385 --> Loss 0.00273416260878\n",
      "Epoch 35::Minibatch 990::LR 0.0215384615385 --> Loss 0.00261089404424\n",
      "Epoch 35::Minibatch 991::LR 0.0215384615385 --> Loss 0.00127103249232\n",
      "Epoch 35::Minibatch 992::LR 0.0215384615385 --> Loss 0.00154451787472\n",
      "Epoch 35::Minibatch 993::LR 0.0215384615385 --> Loss 0.00283725519975\n",
      "Epoch 35::Minibatch 994::LR 0.0215384615385 --> Loss 0.00189326445262\n",
      "Epoch 35::Minibatch 995::LR 0.0215384615385 --> Loss 0.000763663252195\n",
      "Epoch 35::Minibatch 996::LR 0.0215384615385 --> Loss 0.00255337774754\n",
      "Epoch 35::Minibatch 997::LR 0.0215384615385 --> Loss 0.00215037961801\n",
      "Epoch 35::Minibatch 998::LR 0.0215384615385 --> Loss 0.0024446362257\n",
      "Epoch 35::Minibatch 999::LR 0.0215384615385 --> Loss 0.00209844013055\n",
      "Epoch 35::Minibatch 1000::LR 0.0215384615385 --> Loss 0.00256666640441\n",
      "Epoch 35::Minibatch 1001::LR 0.0215384615385 --> Loss 0.0020271162192\n",
      "Epoch 35::Minibatch 1002::LR 0.0215384615385 --> Loss 0.00142545451721\n",
      "Epoch 35::Minibatch 1003::LR 0.0215384615385 --> Loss 0.00234048207601\n",
      "Epoch 35::Minibatch 1004::LR 0.0215384615385 --> Loss 0.00106021334728\n",
      "Epoch 35::Minibatch 1005::LR 0.0215384615385 --> Loss 0.00253257195155\n",
      "Epoch 35::Minibatch 1006::LR 0.0215384615385 --> Loss 0.00126506457726\n",
      "Epoch 35::Minibatch 1007::LR 0.0215384615385 --> Loss 0.00169415811698\n",
      "Epoch 35::Minibatch 1008::LR 0.0215384615385 --> Loss 0.000912866592407\n",
      "Epoch 35::Minibatch 1009::LR 0.0215384615385 --> Loss 0.00121262292067\n",
      "Epoch 35::Minibatch 1010::LR 0.0215384615385 --> Loss 0.00115883767605\n",
      "Epoch 35::Minibatch 1011::LR 0.0215384615385 --> Loss 0.00153532385826\n",
      "Epoch 35::Minibatch 1012::LR 0.0215384615385 --> Loss 0.00133953809738\n",
      "Epoch 35::Minibatch 1013::LR 0.0215384615385 --> Loss 0.00334872961044\n",
      "Epoch 35::Minibatch 1014::LR 0.0215384615385 --> Loss 0.00310816268126\n",
      "Epoch 35::Minibatch 1015::LR 0.0215384615385 --> Loss 0.00150838722785\n",
      "Epoch 35::Minibatch 1016::LR 0.0215384615385 --> Loss 0.00436806599299\n",
      "Epoch 35::Minibatch 1017::LR 0.0215384615385 --> Loss 0.00312820653121\n",
      "Epoch 35::Minibatch 1018::LR 0.0215384615385 --> Loss 0.00242334743341\n",
      "Epoch 35::Minibatch 1019::LR 0.0215384615385 --> Loss 0.00150099903345\n",
      "Epoch 35::Minibatch 1020::LR 0.0215384615385 --> Loss 0.00164587815603\n",
      "Epoch 35::Minibatch 1021::LR 0.0215384615385 --> Loss 0.00178196986516\n",
      "Epoch 35::Minibatch 1022::LR 0.0215384615385 --> Loss 0.00129615604877\n",
      "Epoch 35::Minibatch 1023::LR 0.0215384615385 --> Loss 0.000971157054106\n",
      "Epoch 35::Minibatch 1024::LR 0.0215384615385 --> Loss 0.000976322889328\n",
      "Epoch 35::Minibatch 1025::LR 0.0215384615385 --> Loss 0.00135055601597\n",
      "Epoch 35::Minibatch 1026::LR 0.0215384615385 --> Loss 0.000680637260278\n",
      "Epoch 35::Minibatch 1027::LR 0.0215384615385 --> Loss 0.00096299012502\n",
      "Epoch 35::Minibatch 1028::LR 0.0215384615385 --> Loss 0.000709607452154\n",
      "Epoch 35::Minibatch 1029::LR 0.0215384615385 --> Loss 0.000737767269214\n",
      "Epoch 35::Minibatch 1030::LR 0.0215384615385 --> Loss 0.000890898704529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35::Minibatch 1031::LR 0.0215384615385 --> Loss 0.000674219975869\n",
      "Epoch 35::Minibatch 1032::LR 0.0215384615385 --> Loss 0.000769194314877\n",
      "Epoch 35::Minibatch 1033::LR 0.0215384615385 --> Loss 0.000655295550823\n",
      "Epoch 35::Minibatch 1034::LR 0.0215384615385 --> Loss 0.000622110565503\n",
      "Epoch 35::Minibatch 1035::LR 0.0215384615385 --> Loss 0.000404856701692\n",
      "Epoch 35::Minibatch 1036::LR 0.0215384615385 --> Loss 0.000322747950753\n",
      "Epoch 35::Minibatch 1037::LR 0.0215384615385 --> Loss 0.000613609651724\n",
      "Epoch 35::Minibatch 1038::LR 0.0215384615385 --> Loss 0.00100637982289\n",
      "Epoch 35::Minibatch 1039::LR 0.0215384615385 --> Loss 0.000858038862546\n",
      "Epoch 35::Minibatch 1040::LR 0.0215384615385 --> Loss 0.000334933449825\n",
      "Epoch 35::Minibatch 1041::LR 0.0215384615385 --> Loss 0.000479933520158\n",
      "Epoch 36::Minibatch 1::LR 0.0192307692308 --> Loss 0.00726098378499\n",
      "Epoch 36::Minibatch 2::LR 0.0192307692308 --> Loss 0.0045168586572\n",
      "Epoch 36::Minibatch 3::LR 0.0192307692308 --> Loss 0.00279737114906\n",
      "Epoch 36::Minibatch 4::LR 0.0192307692308 --> Loss 0.00366954723994\n",
      "Epoch 36::Minibatch 5::LR 0.0192307692308 --> Loss 0.00427531083425\n",
      "Epoch 36::Minibatch 6::LR 0.0192307692308 --> Loss 0.00198786199093\n",
      "Epoch 36::Minibatch 7::LR 0.0192307692308 --> Loss 0.00691572189331\n",
      "Epoch 36::Minibatch 8::LR 0.0192307692308 --> Loss 0.00642220934232\n",
      "Epoch 36::Minibatch 9::LR 0.0192307692308 --> Loss 0.00503749251366\n",
      "Epoch 36::Minibatch 10::LR 0.0192307692308 --> Loss 0.00224220295747\n",
      "Epoch 36::Minibatch 11::LR 0.0192307692308 --> Loss 0.00212377250195\n",
      "Epoch 36::Minibatch 12::LR 0.0192307692308 --> Loss 0.00329497138659\n",
      "Epoch 36::Minibatch 13::LR 0.0192307692308 --> Loss 0.00528090874354\n",
      "Epoch 36::Minibatch 14::LR 0.0192307692308 --> Loss 0.00525915026665\n",
      "Epoch 36::Minibatch 15::LR 0.0192307692308 --> Loss 0.00455293814341\n",
      "Epoch 36::Minibatch 16::LR 0.0192307692308 --> Loss 0.000689507176479\n",
      "Epoch 36::Minibatch 17::LR 0.0192307692308 --> Loss 0.0032175107797\n",
      "Epoch 36::Minibatch 18::LR 0.0192307692308 --> Loss 0.00270411511262\n",
      "Epoch 36::Minibatch 19::LR 0.0192307692308 --> Loss 0.00167610963186\n",
      "Epoch 36::Minibatch 20::LR 0.0192307692308 --> Loss 0.00222332417965\n",
      "Epoch 36::Minibatch 21::LR 0.0192307692308 --> Loss 0.00345404664675\n",
      "Epoch 36::Minibatch 22::LR 0.0192307692308 --> Loss 0.00223407725493\n",
      "Epoch 36::Minibatch 23::LR 0.0192307692308 --> Loss 0.000970381895701\n",
      "Epoch 36::Minibatch 24::LR 0.0192307692308 --> Loss 0.00055471504728\n",
      "Epoch 36::Minibatch 25::LR 0.0192307692308 --> Loss 0.00144730677207\n",
      "Epoch 36::Minibatch 26::LR 0.0192307692308 --> Loss 0.00163984338442\n",
      "Epoch 36::Minibatch 27::LR 0.0192307692308 --> Loss 0.00127757310867\n",
      "Epoch 36::Minibatch 28::LR 0.0192307692308 --> Loss 0.000560517509778\n",
      "Epoch 36::Minibatch 29::LR 0.0192307692308 --> Loss 0.000714000662168\n",
      "Epoch 36::Minibatch 30::LR 0.0192307692308 --> Loss 0.00124386956294\n",
      "Epoch 36::Minibatch 31::LR 0.0192307692308 --> Loss 0.00170936028163\n",
      "Epoch 36::Minibatch 32::LR 0.0192307692308 --> Loss 0.00149382740259\n",
      "Epoch 36::Minibatch 33::LR 0.0192307692308 --> Loss 0.000845383107662\n",
      "Epoch 36::Minibatch 34::LR 0.0192307692308 --> Loss 0.00202459851901\n",
      "Epoch 36::Minibatch 35::LR 0.0192307692308 --> Loss 0.00264019529025\n",
      "Epoch 36::Minibatch 36::LR 0.0192307692308 --> Loss 0.00224812448025\n",
      "Epoch 36::Minibatch 37::LR 0.0192307692308 --> Loss 0.000766409734885\n",
      "Epoch 36::Minibatch 38::LR 0.0192307692308 --> Loss 0.000781442771355\n",
      "Epoch 36::Minibatch 39::LR 0.0192307692308 --> Loss 0.00208152333895\n",
      "Epoch 36::Minibatch 40::LR 0.0192307692308 --> Loss 0.00305487930775\n",
      "Epoch 36::Minibatch 41::LR 0.0192307692308 --> Loss 0.00240365684032\n",
      "Epoch 36::Minibatch 42::LR 0.0192307692308 --> Loss 0.00394483089447\n",
      "Epoch 36::Minibatch 43::LR 0.0192307692308 --> Loss 0.00205793937047\n",
      "Epoch 36::Minibatch 44::LR 0.0192307692308 --> Loss 0.00347618063291\n",
      "Epoch 36::Minibatch 45::LR 0.0192307692308 --> Loss 0.00245496153831\n",
      "Epoch 36::Minibatch 46::LR 0.0192307692308 --> Loss 0.0029501503706\n",
      "Epoch 36::Minibatch 47::LR 0.0192307692308 --> Loss 0.00300816734632\n",
      "Epoch 36::Minibatch 48::LR 0.0192307692308 --> Loss 0.00442107876142\n",
      "Epoch 36::Minibatch 49::LR 0.0192307692308 --> Loss 0.00508617202441\n",
      "Epoch 36::Minibatch 50::LR 0.0192307692308 --> Loss 0.00583214084307\n",
      "Epoch 36::Minibatch 51::LR 0.0192307692308 --> Loss 0.0037978553772\n",
      "Epoch 36::Minibatch 52::LR 0.0192307692308 --> Loss 0.00334551493327\n",
      "Epoch 36::Minibatch 53::LR 0.0192307692308 --> Loss 0.00335629542669\n",
      "Epoch 36::Minibatch 54::LR 0.0192307692308 --> Loss 0.00394410332044\n",
      "Epoch 36::Minibatch 55::LR 0.0192307692308 --> Loss 0.00100003997485\n",
      "Epoch 36::Minibatch 56::LR 0.0192307692308 --> Loss 0.00276166498661\n",
      "Epoch 36::Minibatch 57::LR 0.0192307692308 --> Loss 0.00435710072517\n",
      "Epoch 36::Minibatch 58::LR 0.0192307692308 --> Loss 0.00315948446592\n",
      "Epoch 36::Minibatch 59::LR 0.0192307692308 --> Loss 0.00243015865485\n",
      "Epoch 36::Minibatch 60::LR 0.0192307692308 --> Loss 0.00251903553804\n",
      "Epoch 36::Minibatch 61::LR 0.0192307692308 --> Loss 0.000694151471059\n",
      "Epoch 36::Minibatch 62::LR 0.0192307692308 --> Loss 0.00239088674386\n",
      "Epoch 36::Minibatch 63::LR 0.0192307692308 --> Loss 0.00207448939482\n",
      "Epoch 36::Minibatch 64::LR 0.0192307692308 --> Loss 0.000808660537004\n",
      "Epoch 36::Minibatch 65::LR 0.0192307692308 --> Loss 0.00209044218063\n",
      "Epoch 36::Minibatch 66::LR 0.0192307692308 --> Loss 0.00284328420957\n",
      "Epoch 36::Minibatch 67::LR 0.0192307692308 --> Loss 0.00241920510928\n",
      "Epoch 36::Minibatch 68::LR 0.0192307692308 --> Loss 0.00179895361265\n",
      "Epoch 36::Minibatch 69::LR 0.0192307692308 --> Loss 0.00350431720416\n",
      "Epoch 36::Minibatch 70::LR 0.0192307692308 --> Loss 0.00314904669921\n",
      "Epoch 36::Minibatch 71::LR 0.0192307692308 --> Loss 0.00220921138922\n",
      "Epoch 36::Minibatch 72::LR 0.0192307692308 --> Loss 0.000552506397168\n",
      "Epoch 36::Minibatch 73::LR 0.0192307692308 --> Loss 0.00359288175901\n",
      "Epoch 36::Minibatch 74::LR 0.0192307692308 --> Loss 0.00391409198443\n",
      "Epoch 36::Minibatch 75::LR 0.0192307692308 --> Loss 0.0019512617588\n",
      "Epoch 36::Minibatch 76::LR 0.0192307692308 --> Loss 0.000516382654508\n",
      "Epoch 36::Minibatch 77::LR 0.0192307692308 --> Loss 0.00320569892724\n",
      "Epoch 36::Minibatch 78::LR 0.0192307692308 --> Loss 0.0040376551946\n",
      "Epoch 36::Minibatch 79::LR 0.0192307692308 --> Loss 0.00162281860908\n",
      "Epoch 36::Minibatch 80::LR 0.0192307692308 --> Loss 0.00268922785918\n",
      "Epoch 36::Minibatch 81::LR 0.0192307692308 --> Loss 0.0024304997921\n",
      "Epoch 36::Minibatch 82::LR 0.0192307692308 --> Loss 0.00175460239251\n",
      "Epoch 36::Minibatch 83::LR 0.0192307692308 --> Loss 0.00363372325897\n",
      "Epoch 36::Minibatch 84::LR 0.0192307692308 --> Loss 0.00179560164611\n",
      "Epoch 36::Minibatch 85::LR 0.0192307692308 --> Loss 0.00241657197475\n",
      "Epoch 36::Minibatch 86::LR 0.0192307692308 --> Loss 0.00204062600931\n",
      "Epoch 36::Minibatch 87::LR 0.0192307692308 --> Loss 0.00212252656619\n",
      "Epoch 36::Minibatch 88::LR 0.0192307692308 --> Loss 0.00162040382624\n",
      "Epoch 36::Minibatch 89::LR 0.0192307692308 --> Loss 0.0021409056584\n",
      "Epoch 36::Minibatch 90::LR 0.0192307692308 --> Loss 0.00104142308235\n",
      "Epoch 36::Minibatch 91::LR 0.0192307692308 --> Loss 0.000880245169004\n",
      "Epoch 36::Minibatch 92::LR 0.0192307692308 --> Loss 0.00249196469784\n",
      "Epoch 36::Minibatch 93::LR 0.0192307692308 --> Loss 0.00166613241037\n",
      "Epoch 36::Minibatch 94::LR 0.0192307692308 --> Loss 0.00173047641913\n",
      "Epoch 36::Minibatch 95::LR 0.0192307692308 --> Loss 0.00192692855994\n",
      "Epoch 36::Minibatch 96::LR 0.0192307692308 --> Loss 0.00435172319412\n",
      "Epoch 36::Minibatch 97::LR 0.0192307692308 --> Loss 0.00298105617364\n",
      "Epoch 36::Minibatch 98::LR 0.0192307692308 --> Loss 0.00111825058858\n",
      "Epoch 36::Minibatch 99::LR 0.0192307692308 --> Loss 0.00145073930422\n",
      "Epoch 36::Minibatch 100::LR 0.0192307692308 --> Loss 0.00389385382334\n",
      "Epoch 36::Minibatch 101::LR 0.0192307692308 --> Loss 0.000898653268814\n",
      "Epoch 36::Minibatch 102::LR 0.0192307692308 --> Loss 0.00379703998566\n",
      "Epoch 36::Minibatch 103::LR 0.0192307692308 --> Loss 0.00378425121307\n",
      "Epoch 36::Minibatch 104::LR 0.0192307692308 --> Loss 0.00261485914389\n",
      "Epoch 36::Minibatch 105::LR 0.0192307692308 --> Loss 0.0019261632363\n",
      "Epoch 36::Minibatch 106::LR 0.0192307692308 --> Loss 0.011974307696\n",
      "Epoch 36::Minibatch 107::LR 0.0192307692308 --> Loss 0.00468403061231\n",
      "Epoch 36::Minibatch 108::LR 0.0192307692308 --> Loss 0.00089554131031\n",
      "Epoch 36::Minibatch 109::LR 0.0192307692308 --> Loss 0.00429785768191\n",
      "Epoch 36::Minibatch 110::LR 0.0192307692308 --> Loss 0.00217793047428\n",
      "Epoch 36::Minibatch 111::LR 0.0192307692308 --> Loss 0.000783738891284\n",
      "Epoch 36::Minibatch 112::LR 0.0192307692308 --> Loss 0.00321863591671\n",
      "Epoch 36::Minibatch 113::LR 0.0192307692308 --> Loss 0.00230986654758\n",
      "Epoch 36::Minibatch 114::LR 0.0192307692308 --> Loss 0.00130798528592\n",
      "Epoch 36::Minibatch 115::LR 0.0192307692308 --> Loss 0.00107114007076\n",
      "Epoch 36::Minibatch 116::LR 0.0192307692308 --> Loss 0.00261943459511\n",
      "Epoch 36::Minibatch 117::LR 0.0192307692308 --> Loss 0.00413981993993\n",
      "Epoch 36::Minibatch 118::LR 0.0192307692308 --> Loss 0.00636938730876\n",
      "Epoch 36::Minibatch 119::LR 0.0192307692308 --> Loss 0.000456970532735\n",
      "Epoch 36::Minibatch 120::LR 0.0192307692308 --> Loss 0.0016470203797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 121::LR 0.0192307692308 --> Loss 0.00227184275786\n",
      "Epoch 36::Minibatch 122::LR 0.0192307692308 --> Loss 0.00391244133313\n",
      "Epoch 36::Minibatch 123::LR 0.0192307692308 --> Loss 0.00059183349212\n",
      "Epoch 36::Minibatch 124::LR 0.0192307692308 --> Loss 0.0026272102197\n",
      "Epoch 36::Minibatch 125::LR 0.0192307692308 --> Loss 0.00434474825859\n",
      "Epoch 36::Minibatch 126::LR 0.0192307692308 --> Loss 0.00233497818311\n",
      "Epoch 36::Minibatch 127::LR 0.0192307692308 --> Loss 0.00508011778196\n",
      "Epoch 36::Minibatch 128::LR 0.0192307692308 --> Loss 0.0034590057532\n",
      "Epoch 36::Minibatch 129::LR 0.0192307692308 --> Loss 0.00227675477664\n",
      "Epoch 36::Minibatch 130::LR 0.0192307692308 --> Loss 0.00428784012794\n",
      "Epoch 36::Minibatch 131::LR 0.0192307692308 --> Loss 0.00167077898979\n",
      "Epoch 36::Minibatch 132::LR 0.0192307692308 --> Loss 0.00271542270978\n",
      "Epoch 36::Minibatch 133::LR 0.0192307692308 --> Loss 0.0026614232858\n",
      "Epoch 36::Minibatch 134::LR 0.0192307692308 --> Loss 0.00204984486103\n",
      "Epoch 36::Minibatch 135::LR 0.0192307692308 --> Loss 0.0011893683672\n",
      "Epoch 36::Minibatch 136::LR 0.0192307692308 --> Loss 0.00231450299422\n",
      "Epoch 36::Minibatch 137::LR 0.0192307692308 --> Loss 0.00325056234996\n",
      "Epoch 36::Minibatch 138::LR 0.0192307692308 --> Loss 0.00118172814449\n",
      "Epoch 36::Minibatch 139::LR 0.0192307692308 --> Loss 0.00183980723222\n",
      "Epoch 36::Minibatch 140::LR 0.0192307692308 --> Loss 0.00233077387015\n",
      "Epoch 36::Minibatch 141::LR 0.0192307692308 --> Loss 0.00283400058746\n",
      "Epoch 36::Minibatch 142::LR 0.0192307692308 --> Loss 0.00267383992672\n",
      "Epoch 36::Minibatch 143::LR 0.0192307692308 --> Loss 0.000521359294653\n",
      "Epoch 36::Minibatch 144::LR 0.0192307692308 --> Loss 0.0034147075812\n",
      "Epoch 36::Minibatch 145::LR 0.0192307692308 --> Loss 0.00407470226288\n",
      "Epoch 36::Minibatch 146::LR 0.0192307692308 --> Loss 0.00247084915638\n",
      "Epoch 36::Minibatch 147::LR 0.0192307692308 --> Loss 0.00178286472956\n",
      "Epoch 36::Minibatch 148::LR 0.0192307692308 --> Loss 0.000947867333889\n",
      "Epoch 36::Minibatch 149::LR 0.0192307692308 --> Loss 0.00287362953027\n",
      "Epoch 36::Minibatch 150::LR 0.0192307692308 --> Loss 0.00264259854952\n",
      "Epoch 36::Minibatch 151::LR 0.0192307692308 --> Loss 0.00430355588595\n",
      "Epoch 36::Minibatch 152::LR 0.0192307692308 --> Loss 0.000896196564039\n",
      "Epoch 36::Minibatch 153::LR 0.0192307692308 --> Loss 0.00158120006323\n",
      "Epoch 36::Minibatch 154::LR 0.0192307692308 --> Loss 0.00199220657349\n",
      "Epoch 36::Minibatch 155::LR 0.0192307692308 --> Loss 0.00397092541059\n",
      "Epoch 36::Minibatch 156::LR 0.0192307692308 --> Loss 0.00234171867371\n",
      "Epoch 36::Minibatch 157::LR 0.0192307692308 --> Loss 0.000681105951468\n",
      "Epoch 36::Minibatch 158::LR 0.0192307692308 --> Loss 0.00320743362109\n",
      "Epoch 36::Minibatch 159::LR 0.0192307692308 --> Loss 0.00271487593651\n",
      "Epoch 36::Minibatch 160::LR 0.0192307692308 --> Loss 0.00266932388147\n",
      "Epoch 36::Minibatch 161::LR 0.0192307692308 --> Loss 0.000990903278192\n",
      "Epoch 36::Minibatch 162::LR 0.0192307692308 --> Loss 0.00401383002599\n",
      "Epoch 36::Minibatch 163::LR 0.0192307692308 --> Loss 0.00241292496522\n",
      "Epoch 36::Minibatch 164::LR 0.0192307692308 --> Loss 0.0025564088424\n",
      "Epoch 36::Minibatch 165::LR 0.0192307692308 --> Loss 0.000485562831163\n",
      "Epoch 36::Minibatch 166::LR 0.0192307692308 --> Loss 0.00168814659119\n",
      "Epoch 36::Minibatch 167::LR 0.0192307692308 --> Loss 0.00248859365781\n",
      "Epoch 36::Minibatch 168::LR 0.0192307692308 --> Loss 0.00213118831317\n",
      "Epoch 36::Minibatch 169::LR 0.0192307692308 --> Loss 0.000976365506649\n",
      "Epoch 36::Minibatch 170::LR 0.0192307692308 --> Loss 0.000940031905969\n",
      "Epoch 36::Minibatch 171::LR 0.0192307692308 --> Loss 0.00252011795839\n",
      "Epoch 36::Minibatch 172::LR 0.0192307692308 --> Loss 0.00427633523941\n",
      "Epoch 36::Minibatch 173::LR 0.0192307692308 --> Loss 0.00204195380211\n",
      "Epoch 36::Minibatch 174::LR 0.0192307692308 --> Loss 0.000942330459754\n",
      "Epoch 36::Minibatch 175::LR 0.0192307692308 --> Loss 0.00239487926165\n",
      "Epoch 36::Minibatch 176::LR 0.0192307692308 --> Loss 0.00306820452213\n",
      "Epoch 36::Minibatch 177::LR 0.0192307692308 --> Loss 0.00420494159063\n",
      "Epoch 36::Minibatch 178::LR 0.0192307692308 --> Loss 0.00146182070176\n",
      "Epoch 36::Minibatch 179::LR 0.0192307692308 --> Loss 0.00114645093679\n",
      "Epoch 36::Minibatch 180::LR 0.0192307692308 --> Loss 0.00330766876539\n",
      "Epoch 36::Minibatch 181::LR 0.0192307692308 --> Loss 0.00299842894077\n",
      "Epoch 36::Minibatch 182::LR 0.0192307692308 --> Loss 0.000686087508996\n",
      "Epoch 36::Minibatch 183::LR 0.0192307692308 --> Loss 0.00152291864157\n",
      "Epoch 36::Minibatch 184::LR 0.0192307692308 --> Loss 0.00337702711423\n",
      "Epoch 36::Minibatch 185::LR 0.0192307692308 --> Loss 0.00258499662081\n",
      "Epoch 36::Minibatch 186::LR 0.0192307692308 --> Loss 0.00090803583463\n",
      "Epoch 36::Minibatch 187::LR 0.0192307692308 --> Loss 0.0012608290712\n",
      "Epoch 36::Minibatch 188::LR 0.0192307692308 --> Loss 0.00396044850349\n",
      "Epoch 36::Minibatch 189::LR 0.0192307692308 --> Loss 0.0040342203776\n",
      "Epoch 36::Minibatch 190::LR 0.0192307692308 --> Loss 0.00228254755338\n",
      "Epoch 36::Minibatch 191::LR 0.0192307692308 --> Loss 0.000439646939437\n",
      "Epoch 36::Minibatch 192::LR 0.0192307692308 --> Loss 0.00277422805627\n",
      "Epoch 36::Minibatch 193::LR 0.0192307692308 --> Loss 0.00270069777966\n",
      "Epoch 36::Minibatch 194::LR 0.0192307692308 --> Loss 0.00171648760637\n",
      "Epoch 36::Minibatch 195::LR 0.0192307692308 --> Loss 0.000370603402456\n",
      "Epoch 36::Minibatch 196::LR 0.0192307692308 --> Loss 0.00137160797914\n",
      "Epoch 36::Minibatch 197::LR 0.0192307692308 --> Loss 0.002960212032\n",
      "Epoch 36::Minibatch 198::LR 0.0192307692308 --> Loss 0.00232551515102\n",
      "Epoch 36::Minibatch 199::LR 0.0192307692308 --> Loss 0.000288872892658\n",
      "Epoch 36::Minibatch 200::LR 0.0192307692308 --> Loss 0.00203449388345\n",
      "Epoch 36::Minibatch 201::LR 0.0192307692308 --> Loss 0.00192543288072\n",
      "Epoch 36::Minibatch 202::LR 0.0192307692308 --> Loss 0.0018062667052\n",
      "Epoch 36::Minibatch 203::LR 0.0192307692308 --> Loss 0.00175724943479\n",
      "Epoch 36::Minibatch 204::LR 0.0192307692308 --> Loss 0.00141411393881\n",
      "Epoch 36::Minibatch 205::LR 0.0192307692308 --> Loss 0.00222220698992\n",
      "Epoch 36::Minibatch 206::LR 0.0192307692308 --> Loss 0.00521924535433\n",
      "Epoch 36::Minibatch 207::LR 0.0192307692308 --> Loss 0.00139665395021\n",
      "Epoch 36::Minibatch 208::LR 0.0192307692308 --> Loss 0.00110229631265\n",
      "Epoch 36::Minibatch 209::LR 0.0192307692308 --> Loss 0.00254406869411\n",
      "Epoch 36::Minibatch 210::LR 0.0192307692308 --> Loss 0.00238770624002\n",
      "Epoch 36::Minibatch 211::LR 0.0192307692308 --> Loss 0.00273469348749\n",
      "Epoch 36::Minibatch 212::LR 0.0192307692308 --> Loss 0.00371805826823\n",
      "Epoch 36::Minibatch 213::LR 0.0192307692308 --> Loss 0.00532324433327\n",
      "Epoch 36::Minibatch 214::LR 0.0192307692308 --> Loss 0.0067392484347\n",
      "Epoch 36::Minibatch 215::LR 0.0192307692308 --> Loss 0.00135746111472\n",
      "Epoch 36::Minibatch 216::LR 0.0192307692308 --> Loss 0.00523738106092\n",
      "Epoch 36::Minibatch 217::LR 0.0192307692308 --> Loss 0.00574691812197\n",
      "Epoch 36::Minibatch 218::LR 0.0192307692308 --> Loss 0.00388955990473\n",
      "Epoch 36::Minibatch 219::LR 0.0192307692308 --> Loss 0.0044478726387\n",
      "Epoch 36::Minibatch 220::LR 0.0192307692308 --> Loss 0.00432458678881\n",
      "Epoch 36::Minibatch 221::LR 0.0192307692308 --> Loss 0.00427174011866\n",
      "Epoch 36::Minibatch 222::LR 0.0192307692308 --> Loss 0.0031492805481\n",
      "Epoch 36::Minibatch 223::LR 0.0192307692308 --> Loss 0.00137575626373\n",
      "Epoch 36::Minibatch 224::LR 0.0192307692308 --> Loss 0.00157000422478\n",
      "Epoch 36::Minibatch 225::LR 0.0192307692308 --> Loss 0.00791673262914\n",
      "Epoch 36::Minibatch 226::LR 0.0192307692308 --> Loss 0.00360629081726\n",
      "Epoch 36::Minibatch 227::LR 0.0192307692308 --> Loss 0.00167679071426\n",
      "Epoch 36::Minibatch 228::LR 0.0192307692308 --> Loss 0.000638956675927\n",
      "Epoch 36::Minibatch 229::LR 0.0192307692308 --> Loss 0.0047411386172\n",
      "Epoch 36::Minibatch 230::LR 0.0192307692308 --> Loss 0.00360317627589\n",
      "Epoch 36::Minibatch 231::LR 0.0192307692308 --> Loss 0.00266587853432\n",
      "Epoch 36::Minibatch 232::LR 0.0192307692308 --> Loss 0.00115388890107\n",
      "Epoch 36::Minibatch 233::LR 0.0192307692308 --> Loss 0.00246948202451\n",
      "Epoch 36::Minibatch 234::LR 0.0192307692308 --> Loss 0.00746857086817\n",
      "Epoch 36::Minibatch 235::LR 0.0192307692308 --> Loss 0.00456154266993\n",
      "Epoch 36::Minibatch 236::LR 0.0192307692308 --> Loss 0.00165587017934\n",
      "Epoch 36::Minibatch 237::LR 0.0192307692308 --> Loss 0.000569262107213\n",
      "Epoch 36::Minibatch 238::LR 0.0192307692308 --> Loss 0.00347148021062\n",
      "Epoch 36::Minibatch 239::LR 0.0192307692308 --> Loss 0.00295644362768\n",
      "Epoch 36::Minibatch 240::LR 0.0192307692308 --> Loss 0.00327113131682\n",
      "Epoch 36::Minibatch 241::LR 0.0192307692308 --> Loss 0.000744116852681\n",
      "Epoch 36::Minibatch 242::LR 0.0192307692308 --> Loss 0.00667317867279\n",
      "Epoch 36::Minibatch 243::LR 0.0192307692308 --> Loss 0.00321409583092\n",
      "Epoch 36::Minibatch 244::LR 0.0192307692308 --> Loss 0.00269355456034\n",
      "Epoch 36::Minibatch 245::LR 0.0192307692308 --> Loss 0.000418297847112\n",
      "Epoch 36::Minibatch 246::LR 0.0192307692308 --> Loss 0.00186749279499\n",
      "Epoch 36::Minibatch 247::LR 0.0192307692308 --> Loss 0.00998100996017\n",
      "Epoch 36::Minibatch 248::LR 0.0192307692308 --> Loss 0.00431964238485\n",
      "Epoch 36::Minibatch 249::LR 0.0192307692308 --> Loss 0.00236205935478\n",
      "Epoch 36::Minibatch 250::LR 0.0192307692308 --> Loss 0.00231626232465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 251::LR 0.0192307692308 --> Loss 0.00231129030387\n",
      "Epoch 36::Minibatch 252::LR 0.0192307692308 --> Loss 0.00158118993044\n",
      "Epoch 36::Minibatch 253::LR 0.0192307692308 --> Loss 0.00272597829501\n",
      "Epoch 36::Minibatch 254::LR 0.0192307692308 --> Loss 0.00477699359258\n",
      "Epoch 36::Minibatch 255::LR 0.0192307692308 --> Loss 0.00385271708171\n",
      "Epoch 36::Minibatch 256::LR 0.0192307692308 --> Loss 0.00134955743949\n",
      "Epoch 36::Minibatch 257::LR 0.0192307692308 --> Loss 0.00112702101469\n",
      "Epoch 36::Minibatch 258::LR 0.0192307692308 --> Loss 0.00366660157839\n",
      "Epoch 36::Minibatch 259::LR 0.0192307692308 --> Loss 0.00154538661242\n",
      "Epoch 36::Minibatch 260::LR 0.0192307692308 --> Loss 0.00183567305406\n",
      "Epoch 36::Minibatch 261::LR 0.0192307692308 --> Loss 0.00262345751127\n",
      "Epoch 36::Minibatch 262::LR 0.0192307692308 --> Loss 0.001791472435\n",
      "Epoch 36::Minibatch 263::LR 0.0192307692308 --> Loss 0.00226218760014\n",
      "Epoch 36::Minibatch 264::LR 0.0192307692308 --> Loss 0.00353878537814\n",
      "Epoch 36::Minibatch 265::LR 0.0192307692308 --> Loss 0.00994752645493\n",
      "Epoch 36::Minibatch 266::LR 0.0192307692308 --> Loss 0.000845180253188\n",
      "Epoch 36::Minibatch 267::LR 0.0192307692308 --> Loss 0.0089061776797\n",
      "Epoch 36::Minibatch 268::LR 0.0192307692308 --> Loss 0.000997182230155\n",
      "Epoch 36::Minibatch 269::LR 0.0192307692308 --> Loss 0.00345553835233\n",
      "Epoch 36::Minibatch 270::LR 0.0192307692308 --> Loss 0.00753330071767\n",
      "Epoch 36::Minibatch 271::LR 0.0192307692308 --> Loss 0.0023441127936\n",
      "Epoch 36::Minibatch 272::LR 0.0192307692308 --> Loss 0.0044841837883\n",
      "Epoch 36::Minibatch 273::LR 0.0192307692308 --> Loss 0.00130149791638\n",
      "Epoch 36::Minibatch 274::LR 0.0192307692308 --> Loss 0.00175752818584\n",
      "Epoch 36::Minibatch 275::LR 0.0192307692308 --> Loss 0.00241115788619\n",
      "Epoch 36::Minibatch 276::LR 0.0192307692308 --> Loss 0.00329745630423\n",
      "Epoch 36::Minibatch 277::LR 0.0192307692308 --> Loss 0.000830032626788\n",
      "Epoch 36::Minibatch 278::LR 0.0192307692308 --> Loss 0.00249352475007\n",
      "Epoch 36::Minibatch 279::LR 0.0192307692308 --> Loss 0.00189325153828\n",
      "Epoch 36::Minibatch 280::LR 0.0192307692308 --> Loss 0.00168129285177\n",
      "Epoch 36::Minibatch 281::LR 0.0192307692308 --> Loss 0.00106405814489\n",
      "Epoch 36::Minibatch 282::LR 0.0192307692308 --> Loss 0.00193264921506\n",
      "Epoch 36::Minibatch 283::LR 0.0192307692308 --> Loss 0.00182827234268\n",
      "Epoch 36::Minibatch 284::LR 0.0192307692308 --> Loss 0.0014995170633\n",
      "Epoch 36::Minibatch 285::LR 0.0192307692308 --> Loss 0.00108560591936\n",
      "Epoch 36::Minibatch 286::LR 0.0192307692308 --> Loss 0.00188712179661\n",
      "Epoch 36::Minibatch 287::LR 0.0192307692308 --> Loss 0.00187473197778\n",
      "Epoch 36::Minibatch 288::LR 0.0192307692308 --> Loss 0.00102072050174\n",
      "Epoch 36::Minibatch 289::LR 0.0192307692308 --> Loss 0.00151096145312\n",
      "Epoch 36::Minibatch 290::LR 0.0192307692308 --> Loss 0.00179382324219\n",
      "Epoch 36::Minibatch 291::LR 0.0192307692308 --> Loss 0.00161733269691\n",
      "Epoch 36::Minibatch 292::LR 0.0192307692308 --> Loss 0.000570940275987\n",
      "Epoch 36::Minibatch 293::LR 0.0192307692308 --> Loss 0.00145838747422\n",
      "Epoch 36::Minibatch 294::LR 0.0192307692308 --> Loss 0.00161504010359\n",
      "Epoch 36::Minibatch 295::LR 0.0192307692308 --> Loss 0.00185562312603\n",
      "Epoch 36::Minibatch 296::LR 0.0192307692308 --> Loss 0.00159348328908\n",
      "Epoch 36::Minibatch 297::LR 0.0192307692308 --> Loss 0.00140081544717\n",
      "Epoch 36::Minibatch 298::LR 0.0192307692308 --> Loss 0.00140836546818\n",
      "Epoch 36::Minibatch 299::LR 0.0192307692308 --> Loss 0.000809796750546\n",
      "Epoch 36::Minibatch 300::LR 0.0192307692308 --> Loss 0.00264406303565\n",
      "Epoch 36::Minibatch 301::LR 0.0192307692308 --> Loss 0.00255923469861\n",
      "Epoch 36::Minibatch 302::LR 0.0192307692308 --> Loss 0.00236443599065\n",
      "Epoch 36::Minibatch 303::LR 0.0192307692308 --> Loss 0.000816617409388\n",
      "Epoch 36::Minibatch 304::LR 0.0192307692308 --> Loss 0.0028883198897\n",
      "Epoch 36::Minibatch 305::LR 0.0192307692308 --> Loss 0.00171039044857\n",
      "Epoch 36::Minibatch 306::LR 0.0192307692308 --> Loss 0.000931297043959\n",
      "Epoch 36::Minibatch 307::LR 0.0192307692308 --> Loss 0.00239121377468\n",
      "Epoch 36::Minibatch 308::LR 0.0192307692308 --> Loss 0.00200828452905\n",
      "Epoch 36::Minibatch 309::LR 0.0192307692308 --> Loss 0.00104363938173\n",
      "Epoch 36::Minibatch 310::LR 0.0192307692308 --> Loss 0.00119729161263\n",
      "Epoch 36::Minibatch 311::LR 0.0192307692308 --> Loss 0.00179718414942\n",
      "Epoch 36::Minibatch 312::LR 0.0192307692308 --> Loss 0.00284103393555\n",
      "Epoch 36::Minibatch 313::LR 0.0192307692308 --> Loss 0.00231837272644\n",
      "Epoch 36::Minibatch 314::LR 0.0192307692308 --> Loss 0.00192041834195\n",
      "Epoch 36::Minibatch 315::LR 0.0192307692308 --> Loss 0.00105361034473\n",
      "Epoch 36::Minibatch 316::LR 0.0192307692308 --> Loss 0.0023439002037\n",
      "Epoch 36::Minibatch 317::LR 0.0192307692308 --> Loss 0.0015648334225\n",
      "Epoch 36::Minibatch 318::LR 0.0192307692308 --> Loss 0.00131876260042\n",
      "Epoch 36::Minibatch 319::LR 0.0192307692308 --> Loss 0.00230437417825\n",
      "Epoch 36::Minibatch 320::LR 0.0192307692308 --> Loss 0.00299068530401\n",
      "Epoch 36::Minibatch 321::LR 0.0192307692308 --> Loss 0.000840880175432\n",
      "Epoch 36::Minibatch 322::LR 0.0192307692308 --> Loss 0.0033726700147\n",
      "Epoch 36::Minibatch 323::LR 0.0192307692308 --> Loss 0.00339747349421\n",
      "Epoch 36::Minibatch 324::LR 0.0192307692308 --> Loss 0.00265377163887\n",
      "Epoch 36::Minibatch 325::LR 0.0192307692308 --> Loss 0.00236510733763\n",
      "Epoch 36::Minibatch 326::LR 0.0192307692308 --> Loss 0.00517146031062\n",
      "Epoch 36::Minibatch 327::LR 0.0192307692308 --> Loss 0.00221321026484\n",
      "Epoch 36::Minibatch 328::LR 0.0192307692308 --> Loss 0.00287229319414\n",
      "Epoch 36::Minibatch 329::LR 0.0192307692308 --> Loss 0.00118126660585\n",
      "Epoch 36::Minibatch 330::LR 0.0192307692308 --> Loss 0.0015865790844\n",
      "Epoch 36::Minibatch 331::LR 0.0192307692308 --> Loss 0.00253234505653\n",
      "Epoch 36::Minibatch 332::LR 0.0192307692308 --> Loss 0.00243614971638\n",
      "Epoch 36::Minibatch 333::LR 0.0192307692308 --> Loss 0.00147364616394\n",
      "Epoch 36::Minibatch 334::LR 0.0192307692308 --> Loss 0.0043851629893\n",
      "Epoch 36::Minibatch 335::LR 0.0192307692308 --> Loss 0.00190495828787\n",
      "Epoch 36::Minibatch 336::LR 0.0192307692308 --> Loss 0.00226954599222\n",
      "Epoch 36::Minibatch 337::LR 0.0192307692308 --> Loss 0.00379883090655\n",
      "Epoch 36::Minibatch 338::LR 0.0192307692308 --> Loss 0.000559754570325\n",
      "Epoch 36::Minibatch 339::LR 0.0192307692308 --> Loss 0.003213570714\n",
      "Epoch 36::Minibatch 340::LR 0.0192307692308 --> Loss 0.00360968271891\n",
      "Epoch 36::Minibatch 341::LR 0.0192307692308 --> Loss 0.0041978987058\n",
      "Epoch 36::Minibatch 342::LR 0.0192307692308 --> Loss 0.0030478511254\n",
      "Epoch 36::Minibatch 343::LR 0.0192307692308 --> Loss 0.00163676689068\n",
      "Epoch 36::Minibatch 344::LR 0.0192307692308 --> Loss 0.00315615594387\n",
      "Epoch 36::Minibatch 345::LR 0.0192307692308 --> Loss 0.00403084317843\n",
      "Epoch 36::Minibatch 346::LR 0.0192307692308 --> Loss 0.00527302463849\n",
      "Epoch 36::Minibatch 347::LR 0.0192307692308 --> Loss 0.000819054643313\n",
      "Epoch 36::Minibatch 348::LR 0.0192307692308 --> Loss 0.00290809849898\n",
      "Epoch 36::Minibatch 349::LR 0.0192307692308 --> Loss 0.00331300318241\n",
      "Epoch 36::Minibatch 350::LR 0.0192307692308 --> Loss 0.0016405570507\n",
      "Epoch 36::Minibatch 351::LR 0.0192307692308 --> Loss 0.00341509103775\n",
      "Epoch 36::Minibatch 352::LR 0.0192307692308 --> Loss 0.00485228061676\n",
      "Epoch 36::Minibatch 353::LR 0.0192307692308 --> Loss 0.00348214467367\n",
      "Epoch 36::Minibatch 354::LR 0.0192307692308 --> Loss 0.00293959677219\n",
      "Epoch 36::Minibatch 355::LR 0.0192307692308 --> Loss 0.00630738457044\n",
      "Epoch 36::Minibatch 356::LR 0.0192307692308 --> Loss 0.00316893061002\n",
      "Epoch 36::Minibatch 357::LR 0.0192307692308 --> Loss 0.00120078086853\n",
      "Epoch 36::Minibatch 358::LR 0.0192307692308 --> Loss 0.00191517074903\n",
      "Epoch 36::Minibatch 359::LR 0.0192307692308 --> Loss 0.00266221443812\n",
      "Epoch 36::Minibatch 360::LR 0.0192307692308 --> Loss 0.00226290484269\n",
      "Epoch 36::Minibatch 361::LR 0.0192307692308 --> Loss 0.00222290217876\n",
      "Epoch 36::Minibatch 362::LR 0.0192307692308 --> Loss 0.00221820731958\n",
      "Epoch 36::Minibatch 363::LR 0.0192307692308 --> Loss 0.000631188253562\n",
      "Epoch 36::Minibatch 364::LR 0.0192307692308 --> Loss 0.00196267167727\n",
      "Epoch 36::Minibatch 365::LR 0.0192307692308 --> Loss 0.00198158065478\n",
      "Epoch 36::Minibatch 366::LR 0.0192307692308 --> Loss 0.00209288477898\n",
      "Epoch 36::Minibatch 367::LR 0.0192307692308 --> Loss 0.000974144736926\n",
      "Epoch 36::Minibatch 368::LR 0.0192307692308 --> Loss 0.000972737073898\n",
      "Epoch 36::Minibatch 369::LR 0.0192307692308 --> Loss 0.00271316230297\n",
      "Epoch 36::Minibatch 370::LR 0.0192307692308 --> Loss 0.00218446493149\n",
      "Epoch 36::Minibatch 371::LR 0.0192307692308 --> Loss 0.00182934641838\n",
      "Epoch 36::Minibatch 372::LR 0.0192307692308 --> Loss 0.000427628656228\n",
      "Epoch 36::Minibatch 373::LR 0.0192307692308 --> Loss 0.00181224524975\n",
      "Epoch 36::Minibatch 374::LR 0.0192307692308 --> Loss 0.00225486179193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 375::LR 0.0192307692308 --> Loss 0.00190037369728\n",
      "Epoch 36::Minibatch 376::LR 0.0192307692308 --> Loss 0.00119016488393\n",
      "Epoch 36::Minibatch 377::LR 0.0192307692308 --> Loss 0.00190137326717\n",
      "Epoch 36::Minibatch 378::LR 0.0192307692308 --> Loss 0.00208243310452\n",
      "Epoch 36::Minibatch 379::LR 0.0192307692308 --> Loss 0.00230579753717\n",
      "Epoch 36::Minibatch 380::LR 0.0192307692308 --> Loss 0.00155485878388\n",
      "Epoch 36::Minibatch 381::LR 0.0192307692308 --> Loss 0.000998466213544\n",
      "Epoch 36::Minibatch 382::LR 0.0192307692308 --> Loss 0.00204576392968\n",
      "Epoch 36::Minibatch 383::LR 0.0192307692308 --> Loss 0.00199482878049\n",
      "Epoch 36::Minibatch 384::LR 0.0192307692308 --> Loss 0.00114014327526\n",
      "Epoch 36::Minibatch 385::LR 0.0192307692308 --> Loss 0.0010647431016\n",
      "Epoch 36::Minibatch 386::LR 0.0192307692308 --> Loss 0.00227116743724\n",
      "Epoch 36::Minibatch 387::LR 0.0192307692308 --> Loss 0.0023663999637\n",
      "Epoch 36::Minibatch 388::LR 0.0192307692308 --> Loss 0.00123080809911\n",
      "Epoch 36::Minibatch 389::LR 0.0192307692308 --> Loss 0.00178524235884\n",
      "Epoch 36::Minibatch 390::LR 0.0192307692308 --> Loss 0.00320259869099\n",
      "Epoch 36::Minibatch 391::LR 0.0192307692308 --> Loss 0.0025325012207\n",
      "Epoch 36::Minibatch 392::LR 0.0192307692308 --> Loss 0.00254705111186\n",
      "Epoch 36::Minibatch 393::LR 0.0192307692308 --> Loss 0.00272619684537\n",
      "Epoch 36::Minibatch 394::LR 0.0192307692308 --> Loss 0.00200495103995\n",
      "Epoch 36::Minibatch 395::LR 0.0192307692308 --> Loss 0.00208104630311\n",
      "Epoch 36::Minibatch 396::LR 0.0192307692308 --> Loss 0.00194686909517\n",
      "Epoch 36::Minibatch 397::LR 0.0192307692308 --> Loss 0.00208627422651\n",
      "Epoch 36::Minibatch 398::LR 0.0192307692308 --> Loss 0.00207581937313\n",
      "Epoch 36::Minibatch 399::LR 0.0192307692308 --> Loss 0.00237795571486\n",
      "Epoch 36::Minibatch 400::LR 0.0192307692308 --> Loss 0.0020163744688\n",
      "Epoch 36::Minibatch 401::LR 0.0192307692308 --> Loss 0.00339848955472\n",
      "Epoch 36::Minibatch 402::LR 0.0192307692308 --> Loss 0.00171239455541\n",
      "Epoch 36::Minibatch 403::LR 0.0192307692308 --> Loss 0.00143005659183\n",
      "Epoch 36::Minibatch 404::LR 0.0192307692308 --> Loss 0.00131722261508\n",
      "Epoch 36::Minibatch 405::LR 0.0192307692308 --> Loss 0.0033137579759\n",
      "Epoch 36::Minibatch 406::LR 0.0192307692308 --> Loss 0.00232145587603\n",
      "Epoch 36::Minibatch 407::LR 0.0192307692308 --> Loss 0.00170603295167\n",
      "Epoch 36::Minibatch 408::LR 0.0192307692308 --> Loss 0.0004351212581\n",
      "Epoch 36::Minibatch 409::LR 0.0192307692308 --> Loss 0.00220263799032\n",
      "Epoch 36::Minibatch 410::LR 0.0192307692308 --> Loss 0.00313017904758\n",
      "Epoch 36::Minibatch 411::LR 0.0192307692308 --> Loss 0.00167257368565\n",
      "Epoch 36::Minibatch 412::LR 0.0192307692308 --> Loss 0.000942271053791\n",
      "Epoch 36::Minibatch 413::LR 0.0192307692308 --> Loss 0.00198163747787\n",
      "Epoch 36::Minibatch 414::LR 0.0192307692308 --> Loss 0.00188463012377\n",
      "Epoch 36::Minibatch 415::LR 0.0192307692308 --> Loss 0.00118170430263\n",
      "Epoch 36::Minibatch 416::LR 0.0192307692308 --> Loss 0.000789403865735\n",
      "Epoch 36::Minibatch 417::LR 0.0192307692308 --> Loss 0.00167765597502\n",
      "Epoch 36::Minibatch 418::LR 0.0192307692308 --> Loss 0.00256685475508\n",
      "Epoch 36::Minibatch 419::LR 0.0192307692308 --> Loss 0.000492606461048\n",
      "Epoch 36::Minibatch 420::LR 0.0192307692308 --> Loss 0.000696215331554\n",
      "Epoch 36::Minibatch 421::LR 0.0192307692308 --> Loss 0.00186560153961\n",
      "Epoch 36::Minibatch 422::LR 0.0192307692308 --> Loss 0.00204978704453\n",
      "Epoch 36::Minibatch 423::LR 0.0192307692308 --> Loss 0.000994606912136\n",
      "Epoch 36::Minibatch 424::LR 0.0192307692308 --> Loss 0.00152222961187\n",
      "Epoch 36::Minibatch 425::LR 0.0192307692308 --> Loss 0.00285513997078\n",
      "Epoch 36::Minibatch 426::LR 0.0192307692308 --> Loss 0.00199493229389\n",
      "Epoch 36::Minibatch 427::LR 0.0192307692308 --> Loss 0.000747231990099\n",
      "Epoch 36::Minibatch 428::LR 0.0192307692308 --> Loss 0.000907289882501\n",
      "Epoch 36::Minibatch 429::LR 0.0192307692308 --> Loss 0.00222031911214\n",
      "Epoch 36::Minibatch 430::LR 0.0192307692308 --> Loss 0.00742887179057\n",
      "Epoch 36::Minibatch 431::LR 0.0192307692308 --> Loss 0.00349030534426\n",
      "Epoch 36::Minibatch 432::LR 0.0192307692308 --> Loss 0.00388351957003\n",
      "Epoch 36::Minibatch 433::LR 0.0192307692308 --> Loss 0.00253481666247\n",
      "Epoch 36::Minibatch 434::LR 0.0192307692308 --> Loss 0.00241544524829\n",
      "Epoch 36::Minibatch 435::LR 0.0192307692308 --> Loss 0.00224460303783\n",
      "Epoch 36::Minibatch 436::LR 0.0192307692308 --> Loss 0.00157842467229\n",
      "Epoch 36::Minibatch 437::LR 0.0192307692308 --> Loss 0.00274980505308\n",
      "Epoch 36::Minibatch 438::LR 0.0192307692308 --> Loss 0.00220868905385\n",
      "Epoch 36::Minibatch 439::LR 0.0192307692308 --> Loss 0.00189041833083\n",
      "Epoch 36::Minibatch 440::LR 0.0192307692308 --> Loss 0.00291809618473\n",
      "Epoch 36::Minibatch 441::LR 0.0192307692308 --> Loss 0.00273098905881\n",
      "Epoch 36::Minibatch 442::LR 0.0192307692308 --> Loss 0.00242991944154\n",
      "Epoch 36::Minibatch 443::LR 0.0192307692308 --> Loss 0.00342076182365\n",
      "Epoch 36::Minibatch 444::LR 0.0192307692308 --> Loss 0.00263218482335\n",
      "Epoch 36::Minibatch 445::LR 0.0192307692308 --> Loss 0.000839169224103\n",
      "Epoch 36::Minibatch 446::LR 0.0192307692308 --> Loss 0.00134603321552\n",
      "Epoch 36::Minibatch 447::LR 0.0192307692308 --> Loss 0.00225567658742\n",
      "Epoch 36::Minibatch 448::LR 0.0192307692308 --> Loss 0.00229628562927\n",
      "Epoch 36::Minibatch 449::LR 0.0192307692308 --> Loss 0.00353543718656\n",
      "Epoch 36::Minibatch 450::LR 0.0192307692308 --> Loss 0.00210186620553\n",
      "Epoch 36::Minibatch 451::LR 0.0192307692308 --> Loss 0.00377974748611\n",
      "Epoch 36::Minibatch 452::LR 0.0192307692308 --> Loss 0.00227154374123\n",
      "Epoch 36::Minibatch 453::LR 0.0192307692308 --> Loss 0.000344817688068\n",
      "Epoch 36::Minibatch 454::LR 0.0192307692308 --> Loss 0.00336387952169\n",
      "Epoch 36::Minibatch 455::LR 0.0192307692308 --> Loss 0.00255297640959\n",
      "Epoch 36::Minibatch 456::LR 0.0192307692308 --> Loss 0.00303927322229\n",
      "Epoch 36::Minibatch 457::LR 0.0192307692308 --> Loss 0.00186406354109\n",
      "Epoch 36::Minibatch 458::LR 0.0192307692308 --> Loss 0.000711308519046\n",
      "Epoch 36::Minibatch 459::LR 0.0192307692308 --> Loss 0.00375963250796\n",
      "Epoch 36::Minibatch 460::LR 0.0192307692308 --> Loss 0.00240237653255\n",
      "Epoch 36::Minibatch 461::LR 0.0192307692308 --> Loss 0.00362691919009\n",
      "Epoch 36::Minibatch 462::LR 0.0192307692308 --> Loss 0.000365564078093\n",
      "Epoch 36::Minibatch 463::LR 0.0192307692308 --> Loss 0.00398082971573\n",
      "Epoch 36::Minibatch 464::LR 0.0192307692308 --> Loss 0.00192847649256\n",
      "Epoch 36::Minibatch 465::LR 0.0192307692308 --> Loss 0.00435298681259\n",
      "Epoch 36::Minibatch 466::LR 0.0192307692308 --> Loss 0.00489869356155\n",
      "Epoch 36::Minibatch 467::LR 0.0192307692308 --> Loss 0.00496078491211\n",
      "Epoch 36::Minibatch 468::LR 0.0192307692308 --> Loss 0.0055361978213\n",
      "Epoch 36::Minibatch 469::LR 0.0192307692308 --> Loss 0.00584289391836\n",
      "Epoch 36::Minibatch 470::LR 0.0192307692308 --> Loss 0.00353582501411\n",
      "Epoch 36::Minibatch 471::LR 0.0192307692308 --> Loss 0.0016467560331\n",
      "Epoch 36::Minibatch 472::LR 0.0192307692308 --> Loss 0.00356311837832\n",
      "Epoch 36::Minibatch 473::LR 0.0192307692308 --> Loss 0.00231393635273\n",
      "Epoch 36::Minibatch 474::LR 0.0192307692308 --> Loss 0.000685738474131\n",
      "Epoch 36::Minibatch 475::LR 0.0192307692308 --> Loss 0.00467346231143\n",
      "Epoch 36::Minibatch 476::LR 0.0192307692308 --> Loss 0.00754482269287\n",
      "Epoch 36::Minibatch 477::LR 0.0192307692308 --> Loss 0.000913400848707\n",
      "Epoch 36::Minibatch 478::LR 0.0192307692308 --> Loss 0.00239342431227\n",
      "Epoch 36::Minibatch 479::LR 0.0192307692308 --> Loss 0.00195293049018\n",
      "Epoch 36::Minibatch 480::LR 0.0192307692308 --> Loss 0.00150491952896\n",
      "Epoch 36::Minibatch 481::LR 0.0192307692308 --> Loss 0.000958342651526\n",
      "Epoch 36::Minibatch 482::LR 0.0192307692308 --> Loss 0.00206018348535\n",
      "Epoch 36::Minibatch 483::LR 0.0192307692308 --> Loss 0.00298669497172\n",
      "Epoch 36::Minibatch 484::LR 0.0192307692308 --> Loss 0.00334803899129\n",
      "Epoch 36::Minibatch 485::LR 0.0192307692308 --> Loss 0.000759914070368\n",
      "Epoch 36::Minibatch 486::LR 0.0192307692308 --> Loss 0.00281406025092\n",
      "Epoch 36::Minibatch 487::LR 0.0192307692308 --> Loss 0.00327951431274\n",
      "Epoch 36::Minibatch 488::LR 0.0192307692308 --> Loss 0.00200960000356\n",
      "Epoch 36::Minibatch 489::LR 0.0192307692308 --> Loss 0.00305826246738\n",
      "Epoch 36::Minibatch 490::LR 0.0192307692308 --> Loss 0.000412511403362\n",
      "Epoch 36::Minibatch 491::LR 0.0192307692308 --> Loss 0.00309214909871\n",
      "Epoch 36::Minibatch 492::LR 0.0192307692308 --> Loss 0.00306254545848\n",
      "Epoch 36::Minibatch 493::LR 0.0192307692308 --> Loss 0.00300831834475\n",
      "Epoch 36::Minibatch 494::LR 0.0192307692308 --> Loss 0.000730371326208\n",
      "Epoch 36::Minibatch 495::LR 0.0192307692308 --> Loss 0.00181698898474\n",
      "Epoch 36::Minibatch 496::LR 0.0192307692308 --> Loss 0.0027730902036\n",
      "Epoch 36::Minibatch 497::LR 0.0192307692308 --> Loss 0.000911209781965\n",
      "Epoch 36::Minibatch 498::LR 0.0192307692308 --> Loss 0.000547074526548\n",
      "Epoch 36::Minibatch 499::LR 0.0192307692308 --> Loss 0.00337146719297\n",
      "Epoch 36::Minibatch 500::LR 0.0192307692308 --> Loss 0.00142100562652\n",
      "Epoch 36::Minibatch 501::LR 0.0192307692308 --> Loss 0.00198141217232\n",
      "Epoch 36::Minibatch 502::LR 0.0192307692308 --> Loss 0.00371390859286\n",
      "Epoch 36::Minibatch 503::LR 0.0192307692308 --> Loss 0.00659152746201\n",
      "Epoch 36::Minibatch 504::LR 0.0192307692308 --> Loss 0.00650264779727\n",
      "Epoch 36::Minibatch 505::LR 0.0192307692308 --> Loss 0.00385832945506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 506::LR 0.0192307692308 --> Loss 0.00326636751493\n",
      "Epoch 36::Minibatch 507::LR 0.0192307692308 --> Loss 0.00566003084183\n",
      "Epoch 36::Minibatch 508::LR 0.0192307692308 --> Loss 0.00337698141734\n",
      "Epoch 36::Minibatch 509::LR 0.0192307692308 --> Loss 0.00418255567551\n",
      "Epoch 36::Minibatch 510::LR 0.0192307692308 --> Loss 0.00435091177622\n",
      "Epoch 36::Minibatch 511::LR 0.0192307692308 --> Loss 0.00402680794398\n",
      "Epoch 36::Minibatch 512::LR 0.0192307692308 --> Loss 0.00268522143364\n",
      "Epoch 36::Minibatch 513::LR 0.0192307692308 --> Loss 0.000589380462964\n",
      "Epoch 36::Minibatch 514::LR 0.0192307692308 --> Loss 0.00258041838805\n",
      "Epoch 36::Minibatch 515::LR 0.0192307692308 --> Loss 0.00298631072044\n",
      "Epoch 36::Minibatch 516::LR 0.0192307692308 --> Loss 0.00389491915703\n",
      "Epoch 36::Minibatch 517::LR 0.0192307692308 --> Loss 0.00364472746849\n",
      "Epoch 36::Minibatch 518::LR 0.0192307692308 --> Loss 0.00256805121899\n",
      "Epoch 36::Minibatch 519::LR 0.0192307692308 --> Loss 0.00359142184258\n",
      "Epoch 36::Minibatch 520::LR 0.0192307692308 --> Loss 0.00566271821658\n",
      "Epoch 36::Minibatch 521::LR 0.0192307692308 --> Loss 0.00572693308194\n",
      "Epoch 36::Minibatch 522::LR 0.0192307692308 --> Loss 0.00690102179845\n",
      "Epoch 36::Minibatch 523::LR 0.0192307692308 --> Loss 0.000619932512442\n",
      "Epoch 36::Minibatch 524::LR 0.0192307692308 --> Loss 0.00138069093227\n",
      "Epoch 36::Minibatch 525::LR 0.0192307692308 --> Loss 0.00300469438235\n",
      "Epoch 36::Minibatch 526::LR 0.0192307692308 --> Loss 0.00363741874695\n",
      "Epoch 36::Minibatch 527::LR 0.0192307692308 --> Loss 0.00210835158825\n",
      "Epoch 36::Minibatch 528::LR 0.0192307692308 --> Loss 0.00090766509374\n",
      "Epoch 36::Minibatch 529::LR 0.0192307692308 --> Loss 0.00374692042669\n",
      "Epoch 36::Minibatch 530::LR 0.0192307692308 --> Loss 0.00370606660843\n",
      "Epoch 36::Minibatch 531::LR 0.0192307692308 --> Loss 0.0032913984855\n",
      "Epoch 36::Minibatch 532::LR 0.0192307692308 --> Loss 0.00256457269192\n",
      "Epoch 36::Minibatch 533::LR 0.0192307692308 --> Loss 0.00485087831815\n",
      "Epoch 36::Minibatch 534::LR 0.0192307692308 --> Loss 0.00366077979406\n",
      "Epoch 36::Minibatch 535::LR 0.0192307692308 --> Loss 0.003340771993\n",
      "Epoch 36::Minibatch 536::LR 0.0192307692308 --> Loss 0.00210846404235\n",
      "Epoch 36::Minibatch 537::LR 0.0192307692308 --> Loss 0.00057897840937\n",
      "Epoch 36::Minibatch 538::LR 0.0192307692308 --> Loss 0.00161887705326\n",
      "Epoch 36::Minibatch 539::LR 0.0192307692308 --> Loss 0.00328622500102\n",
      "Epoch 36::Minibatch 540::LR 0.0192307692308 --> Loss 0.0033698952198\n",
      "Epoch 36::Minibatch 541::LR 0.0192307692308 --> Loss 0.00282334446907\n",
      "Epoch 36::Minibatch 542::LR 0.0192307692308 --> Loss 0.00241863409678\n",
      "Epoch 36::Minibatch 543::LR 0.0192307692308 --> Loss 0.0025317388773\n",
      "Epoch 36::Minibatch 544::LR 0.0192307692308 --> Loss 0.0040872613589\n",
      "Epoch 36::Minibatch 545::LR 0.0192307692308 --> Loss 0.00194550534089\n",
      "Epoch 36::Minibatch 546::LR 0.0192307692308 --> Loss 0.00066239207983\n",
      "Epoch 36::Minibatch 547::LR 0.0192307692308 --> Loss 0.00256714562575\n",
      "Epoch 36::Minibatch 548::LR 0.0192307692308 --> Loss 0.00334356466929\n",
      "Epoch 36::Minibatch 549::LR 0.0192307692308 --> Loss 0.00897235790888\n",
      "Epoch 36::Minibatch 550::LR 0.0192307692308 --> Loss 0.00118878652652\n",
      "Epoch 36::Minibatch 551::LR 0.0192307692308 --> Loss 0.00246386408806\n",
      "Epoch 36::Minibatch 552::LR 0.0192307692308 --> Loss 0.00341550350189\n",
      "Epoch 36::Minibatch 553::LR 0.0192307692308 --> Loss 0.00290098547935\n",
      "Epoch 36::Minibatch 554::LR 0.0192307692308 --> Loss 0.00357103904088\n",
      "Epoch 36::Minibatch 555::LR 0.0192307692308 --> Loss 0.000930679341157\n",
      "Epoch 36::Minibatch 556::LR 0.0192307692308 --> Loss 0.00189993957678\n",
      "Epoch 36::Minibatch 557::LR 0.0192307692308 --> Loss 0.00241080323855\n",
      "Epoch 36::Minibatch 558::LR 0.0192307692308 --> Loss 0.00356066505114\n",
      "Epoch 36::Minibatch 559::LR 0.0192307692308 --> Loss 0.00364223599434\n",
      "Epoch 36::Minibatch 560::LR 0.0192307692308 --> Loss 0.00305034339428\n",
      "Epoch 36::Minibatch 561::LR 0.0192307692308 --> Loss 0.00260973294576\n",
      "Epoch 36::Minibatch 562::LR 0.0192307692308 --> Loss 0.0023305674394\n",
      "Epoch 36::Minibatch 563::LR 0.0192307692308 --> Loss 0.0039482208093\n",
      "Epoch 36::Minibatch 564::LR 0.0192307692308 --> Loss 0.00302290638288\n",
      "Epoch 36::Minibatch 565::LR 0.0192307692308 --> Loss 0.00356082081795\n",
      "Epoch 36::Minibatch 566::LR 0.0192307692308 --> Loss 0.00215107699235\n",
      "Epoch 36::Minibatch 567::LR 0.0192307692308 --> Loss 0.00254294792811\n",
      "Epoch 36::Minibatch 568::LR 0.0192307692308 --> Loss 0.00171292940776\n",
      "Epoch 36::Minibatch 569::LR 0.0192307692308 --> Loss 0.000557977507512\n",
      "Epoch 36::Minibatch 570::LR 0.0192307692308 --> Loss 0.00159618328015\n",
      "Epoch 36::Minibatch 571::LR 0.0192307692308 --> Loss 0.00200303316116\n",
      "Epoch 36::Minibatch 572::LR 0.0192307692308 --> Loss 0.00216183980306\n",
      "Epoch 36::Minibatch 573::LR 0.0192307692308 --> Loss 0.00141289710999\n",
      "Epoch 36::Minibatch 574::LR 0.0192307692308 --> Loss 0.00104070017735\n",
      "Epoch 36::Minibatch 575::LR 0.0192307692308 --> Loss 0.00169148286184\n",
      "Epoch 36::Minibatch 576::LR 0.0192307692308 --> Loss 0.00200525561968\n",
      "Epoch 36::Minibatch 577::LR 0.0192307692308 --> Loss 0.00158633033435\n",
      "Epoch 36::Minibatch 578::LR 0.0192307692308 --> Loss 0.00125101864338\n",
      "Epoch 36::Minibatch 579::LR 0.0192307692308 --> Loss 0.00117358922958\n",
      "Epoch 36::Minibatch 580::LR 0.0192307692308 --> Loss 0.00191055297852\n",
      "Epoch 36::Minibatch 581::LR 0.0192307692308 --> Loss 0.00169773499171\n",
      "Epoch 36::Minibatch 582::LR 0.0192307692308 --> Loss 0.00420744180679\n",
      "Epoch 36::Minibatch 583::LR 0.0192307692308 --> Loss 0.000954245626926\n",
      "Epoch 36::Minibatch 584::LR 0.0192307692308 --> Loss 0.00130988846223\n",
      "Epoch 36::Minibatch 585::LR 0.0192307692308 --> Loss 0.00383620937665\n",
      "Epoch 36::Minibatch 586::LR 0.0192307692308 --> Loss 0.00366931756337\n",
      "Epoch 36::Minibatch 587::LR 0.0192307692308 --> Loss 0.00110582143068\n",
      "Epoch 36::Minibatch 588::LR 0.0192307692308 --> Loss 0.00135654519002\n",
      "Epoch 36::Minibatch 589::LR 0.0192307692308 --> Loss 0.0027035065492\n",
      "Epoch 36::Minibatch 590::LR 0.0192307692308 --> Loss 0.00175729870796\n",
      "Epoch 36::Minibatch 591::LR 0.0192307692308 --> Loss 0.00261048575242\n",
      "Epoch 36::Minibatch 592::LR 0.0192307692308 --> Loss 0.0011391783754\n",
      "Epoch 36::Minibatch 593::LR 0.0192307692308 --> Loss 0.00242524703344\n",
      "Epoch 36::Minibatch 594::LR 0.0192307692308 --> Loss 0.00249267160892\n",
      "Epoch 36::Minibatch 595::LR 0.0192307692308 --> Loss 0.00303231934706\n",
      "Epoch 36::Minibatch 596::LR 0.0192307692308 --> Loss 0.00180504838626\n",
      "Epoch 36::Minibatch 597::LR 0.0192307692308 --> Loss 0.00115254471699\n",
      "Epoch 36::Minibatch 598::LR 0.0192307692308 --> Loss 0.00274529099464\n",
      "Epoch 36::Minibatch 599::LR 0.0192307692308 --> Loss 0.00176817397277\n",
      "Epoch 36::Minibatch 600::LR 0.0192307692308 --> Loss 0.00209020733833\n",
      "Epoch 36::Minibatch 601::LR 0.0192307692308 --> Loss 0.00367989261945\n",
      "Epoch 36::Minibatch 602::LR 0.0192307692308 --> Loss 0.00206913411617\n",
      "Epoch 36::Minibatch 603::LR 0.0192307692308 --> Loss 0.00260705371698\n",
      "Epoch 36::Minibatch 604::LR 0.0192307692308 --> Loss 0.0016146076719\n",
      "Epoch 36::Minibatch 605::LR 0.0192307692308 --> Loss 0.00224476516247\n",
      "Epoch 36::Minibatch 606::LR 0.0192307692308 --> Loss 0.00182350019614\n",
      "Epoch 36::Minibatch 607::LR 0.0192307692308 --> Loss 0.000817024856806\n",
      "Epoch 36::Minibatch 608::LR 0.0192307692308 --> Loss 0.00153507471085\n",
      "Epoch 36::Minibatch 609::LR 0.0192307692308 --> Loss 0.00242108464241\n",
      "Epoch 36::Minibatch 610::LR 0.0192307692308 --> Loss 0.00405252377192\n",
      "Epoch 36::Minibatch 611::LR 0.0192307692308 --> Loss 0.0027031604449\n",
      "Epoch 36::Minibatch 612::LR 0.0192307692308 --> Loss 0.000467746506135\n",
      "Epoch 36::Minibatch 613::LR 0.0192307692308 --> Loss 0.00131150126457\n",
      "Epoch 36::Minibatch 614::LR 0.0192307692308 --> Loss 0.00238439957301\n",
      "Epoch 36::Minibatch 615::LR 0.0192307692308 --> Loss 0.00163754224777\n",
      "Epoch 36::Minibatch 616::LR 0.0192307692308 --> Loss 0.000910709301631\n",
      "Epoch 36::Minibatch 617::LR 0.0192307692308 --> Loss 0.00048974742492\n",
      "Epoch 36::Minibatch 618::LR 0.0192307692308 --> Loss 0.00295778632164\n",
      "Epoch 36::Minibatch 619::LR 0.0192307692308 --> Loss 0.0019262522459\n",
      "Epoch 36::Minibatch 620::LR 0.0192307692308 --> Loss 0.00167409698168\n",
      "Epoch 36::Minibatch 621::LR 0.0192307692308 --> Loss 0.000840858221054\n",
      "Epoch 36::Minibatch 622::LR 0.0192307692308 --> Loss 0.000774843345086\n",
      "Epoch 36::Minibatch 623::LR 0.0192307692308 --> Loss 0.00221203664939\n",
      "Epoch 36::Minibatch 624::LR 0.0192307692308 --> Loss 0.00175398548444\n",
      "Epoch 36::Minibatch 625::LR 0.0192307692308 --> Loss 0.00259730021159\n",
      "Epoch 36::Minibatch 626::LR 0.0192307692308 --> Loss 0.00340308348338\n",
      "Epoch 36::Minibatch 627::LR 0.0192307692308 --> Loss 0.0012578912576\n",
      "Epoch 36::Minibatch 628::LR 0.0192307692308 --> Loss 0.000872456232707\n",
      "Epoch 36::Minibatch 629::LR 0.0192307692308 --> Loss 0.00296841859818\n",
      "Epoch 36::Minibatch 630::LR 0.0192307692308 --> Loss 0.00291290680567\n",
      "Epoch 36::Minibatch 631::LR 0.0192307692308 --> Loss 0.00486786524455\n",
      "Epoch 36::Minibatch 632::LR 0.0192307692308 --> Loss 0.000796666145325\n",
      "Epoch 36::Minibatch 633::LR 0.0192307692308 --> Loss 0.00159981399775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 634::LR 0.0192307692308 --> Loss 0.00314814627171\n",
      "Epoch 36::Minibatch 635::LR 0.0192307692308 --> Loss 0.00529915849368\n",
      "Epoch 36::Minibatch 636::LR 0.0192307692308 --> Loss 0.00445371190707\n",
      "Epoch 36::Minibatch 637::LR 0.0192307692308 --> Loss 0.000700134982665\n",
      "Epoch 36::Minibatch 638::LR 0.0192307692308 --> Loss 0.00148798515399\n",
      "Epoch 36::Minibatch 639::LR 0.0192307692308 --> Loss 0.00314977010091\n",
      "Epoch 36::Minibatch 640::LR 0.0192307692308 --> Loss 0.00441228429476\n",
      "Epoch 36::Minibatch 641::LR 0.0192307692308 --> Loss 0.00299681802591\n",
      "Epoch 36::Minibatch 642::LR 0.0192307692308 --> Loss 0.00053274144729\n",
      "Epoch 36::Minibatch 643::LR 0.0192307692308 --> Loss 0.00229765832424\n",
      "Epoch 36::Minibatch 644::LR 0.0192307692308 --> Loss 0.00382506648699\n",
      "Epoch 36::Minibatch 645::LR 0.0192307692308 --> Loss 0.00454156200091\n",
      "Epoch 36::Minibatch 646::LR 0.0192307692308 --> Loss 0.00151499440273\n",
      "Epoch 36::Minibatch 647::LR 0.0192307692308 --> Loss 0.00045860995849\n",
      "Epoch 36::Minibatch 648::LR 0.0192307692308 --> Loss 0.00268565475941\n",
      "Epoch 36::Minibatch 649::LR 0.0192307692308 --> Loss 0.0030766304334\n",
      "Epoch 36::Minibatch 650::LR 0.0192307692308 --> Loss 0.0030729752779\n",
      "Epoch 36::Minibatch 651::LR 0.0192307692308 --> Loss 0.00130920747916\n",
      "Epoch 36::Minibatch 652::LR 0.0192307692308 --> Loss 0.000777995338043\n",
      "Epoch 36::Minibatch 653::LR 0.0192307692308 --> Loss 0.00277454257011\n",
      "Epoch 36::Minibatch 654::LR 0.0192307692308 --> Loss 0.00309482932091\n",
      "Epoch 36::Minibatch 655::LR 0.0192307692308 --> Loss 0.00367410262426\n",
      "Epoch 36::Minibatch 656::LR 0.0192307692308 --> Loss 0.000757586757342\n",
      "Epoch 36::Minibatch 657::LR 0.0192307692308 --> Loss 0.0022594845295\n",
      "Epoch 36::Minibatch 658::LR 0.0192307692308 --> Loss 0.00436292171478\n",
      "Epoch 36::Minibatch 659::LR 0.0192307692308 --> Loss 0.00217889964581\n",
      "Epoch 36::Minibatch 660::LR 0.0192307692308 --> Loss 0.00264298160871\n",
      "Epoch 36::Minibatch 661::LR 0.0192307692308 --> Loss 0.00220562378565\n",
      "Epoch 36::Minibatch 662::LR 0.0192307692308 --> Loss 0.00178672532241\n",
      "Epoch 36::Minibatch 663::LR 0.0192307692308 --> Loss 0.00359861254692\n",
      "Epoch 36::Minibatch 664::LR 0.0192307692308 --> Loss 0.00305113355319\n",
      "Epoch 36::Minibatch 665::LR 0.0192307692308 --> Loss 0.000690556416909\n",
      "Epoch 36::Minibatch 666::LR 0.0192307692308 --> Loss 0.00389997720718\n",
      "Epoch 36::Minibatch 667::LR 0.0192307692308 --> Loss 0.00254408121109\n",
      "Epoch 36::Minibatch 668::LR 0.0192307692308 --> Loss 0.00612803896268\n",
      "Epoch 36::Minibatch 669::LR 0.0192307692308 --> Loss 0.0010759400328\n",
      "Epoch 36::Minibatch 670::LR 0.0192307692308 --> Loss 0.00132102121909\n",
      "Epoch 36::Minibatch 671::LR 0.0192307692308 --> Loss 0.00501262744268\n",
      "Epoch 36::Minibatch 672::LR 0.0192307692308 --> Loss 0.0032897845904\n",
      "Epoch 36::Minibatch 673::LR 0.0192307692308 --> Loss 0.00159143199523\n",
      "Epoch 36::Minibatch 674::LR 0.0192307692308 --> Loss 0.000510303775469\n",
      "Epoch 36::Minibatch 675::LR 0.0192307692308 --> Loss 0.00219947795073\n",
      "Epoch 36::Minibatch 676::LR 0.0192307692308 --> Loss 0.00217436591784\n",
      "Epoch 36::Minibatch 677::LR 0.0192307692308 --> Loss 0.00267331600189\n",
      "Epoch 36::Minibatch 678::LR 0.0192307692308 --> Loss 0.00184832175573\n",
      "Epoch 36::Minibatch 679::LR 0.0192307692308 --> Loss 0.00326701939106\n",
      "Epoch 36::Minibatch 680::LR 0.0192307692308 --> Loss 0.00211366256078\n",
      "Epoch 36::Minibatch 681::LR 0.0192307692308 --> Loss 0.00235516448816\n",
      "Epoch 36::Minibatch 682::LR 0.0192307692308 --> Loss 0.000761979122957\n",
      "Epoch 36::Minibatch 683::LR 0.0192307692308 --> Loss 0.00226912061373\n",
      "Epoch 36::Minibatch 684::LR 0.0192307692308 --> Loss 0.00234181602796\n",
      "Epoch 36::Minibatch 685::LR 0.0192307692308 --> Loss 0.002795479695\n",
      "Epoch 36::Minibatch 686::LR 0.0192307692308 --> Loss 0.00158159077168\n",
      "Epoch 36::Minibatch 687::LR 0.0192307692308 --> Loss 0.000880156457424\n",
      "Epoch 36::Minibatch 688::LR 0.0192307692308 --> Loss 0.00281115233898\n",
      "Epoch 36::Minibatch 689::LR 0.0192307692308 --> Loss 0.00245066523552\n",
      "Epoch 36::Minibatch 690::LR 0.0192307692308 --> Loss 0.00185947358608\n",
      "Epoch 36::Minibatch 691::LR 0.0192307692308 --> Loss 0.000657410720984\n",
      "Epoch 36::Minibatch 692::LR 0.0192307692308 --> Loss 0.00243568281333\n",
      "Epoch 36::Minibatch 693::LR 0.0192307692308 --> Loss 0.00263068020344\n",
      "Epoch 36::Minibatch 694::LR 0.0192307692308 --> Loss 0.00297620256742\n",
      "Epoch 36::Minibatch 695::LR 0.0192307692308 --> Loss 0.00181427121162\n",
      "Epoch 36::Minibatch 696::LR 0.0192307692308 --> Loss 0.00202122549216\n",
      "Epoch 36::Minibatch 697::LR 0.0192307692308 --> Loss 0.00139672329028\n",
      "Epoch 36::Minibatch 698::LR 0.0192307692308 --> Loss 0.00166710774104\n",
      "Epoch 36::Minibatch 699::LR 0.0192307692308 --> Loss 0.00365642905235\n",
      "Epoch 36::Minibatch 700::LR 0.0192307692308 --> Loss 0.00253667473793\n",
      "Epoch 36::Minibatch 701::LR 0.0192307692308 --> Loss 0.00185978055\n",
      "Epoch 36::Minibatch 702::LR 0.0192307692308 --> Loss 0.00167029500008\n",
      "Epoch 36::Minibatch 703::LR 0.0192307692308 --> Loss 0.00425541520119\n",
      "Epoch 36::Minibatch 704::LR 0.0192307692308 --> Loss 0.00180517196655\n",
      "Epoch 36::Minibatch 705::LR 0.0192307692308 --> Loss 0.00281390825907\n",
      "Epoch 36::Minibatch 706::LR 0.0192307692308 --> Loss 0.00218381444613\n",
      "Epoch 36::Minibatch 707::LR 0.0192307692308 --> Loss 0.00118274698655\n",
      "Epoch 36::Minibatch 708::LR 0.0192307692308 --> Loss 0.00173011461894\n",
      "Epoch 36::Minibatch 709::LR 0.0192307692308 --> Loss 0.00166621247927\n",
      "Epoch 36::Minibatch 710::LR 0.0192307692308 --> Loss 0.00259138623873\n",
      "Epoch 36::Minibatch 711::LR 0.0192307692308 --> Loss 0.0019920283556\n",
      "Epoch 36::Minibatch 712::LR 0.0192307692308 --> Loss 0.00137761553129\n",
      "Epoch 36::Minibatch 713::LR 0.0192307692308 --> Loss 0.00180963973204\n",
      "Epoch 36::Minibatch 714::LR 0.0192307692308 --> Loss 0.00289043486118\n",
      "Epoch 36::Minibatch 715::LR 0.0192307692308 --> Loss 0.0029123177131\n",
      "Epoch 36::Minibatch 716::LR 0.0192307692308 --> Loss 0.0016767625014\n",
      "Epoch 36::Minibatch 717::LR 0.0192307692308 --> Loss 0.00168312271436\n",
      "Epoch 36::Minibatch 718::LR 0.0192307692308 --> Loss 0.00129022061825\n",
      "Epoch 36::Minibatch 719::LR 0.0192307692308 --> Loss 0.00174380064011\n",
      "Epoch 36::Minibatch 720::LR 0.0192307692308 --> Loss 0.00282140731812\n",
      "Epoch 36::Minibatch 721::LR 0.0192307692308 --> Loss 0.000605095674594\n",
      "Epoch 36::Minibatch 722::LR 0.0192307692308 --> Loss 0.00453113238017\n",
      "Epoch 36::Minibatch 723::LR 0.0192307692308 --> Loss 0.00477495710055\n",
      "Epoch 36::Minibatch 724::LR 0.0192307692308 --> Loss 0.000964806973934\n",
      "Epoch 36::Minibatch 725::LR 0.0192307692308 --> Loss 0.00202125469844\n",
      "Epoch 36::Minibatch 726::LR 0.0192307692308 --> Loss 0.00341150124868\n",
      "Epoch 36::Minibatch 727::LR 0.0192307692308 --> Loss 0.00295367956161\n",
      "Epoch 36::Minibatch 728::LR 0.0192307692308 --> Loss 0.000641621301572\n",
      "Epoch 36::Minibatch 729::LR 0.0192307692308 --> Loss 0.000712813685338\n",
      "Epoch 36::Minibatch 730::LR 0.0192307692308 --> Loss 0.00288951138655\n",
      "Epoch 36::Minibatch 731::LR 0.0192307692308 --> Loss 0.00263108472029\n",
      "Epoch 36::Minibatch 732::LR 0.0192307692308 --> Loss 0.0019918268919\n",
      "Epoch 36::Minibatch 733::LR 0.0192307692308 --> Loss 0.000577182819446\n",
      "Epoch 36::Minibatch 734::LR 0.0192307692308 --> Loss 0.00162029276292\n",
      "Epoch 36::Minibatch 735::LR 0.0192307692308 --> Loss 0.00251662154992\n",
      "Epoch 36::Minibatch 736::LR 0.0192307692308 --> Loss 0.00347314675649\n",
      "Epoch 36::Minibatch 737::LR 0.0192307692308 --> Loss 0.0028631901741\n",
      "Epoch 36::Minibatch 738::LR 0.0192307692308 --> Loss 0.00132180203994\n",
      "Epoch 36::Minibatch 739::LR 0.0192307692308 --> Loss 0.00232708553473\n",
      "Epoch 36::Minibatch 740::LR 0.0192307692308 --> Loss 0.00373132785161\n",
      "Epoch 36::Minibatch 741::LR 0.0192307692308 --> Loss 0.0024900184075\n",
      "Epoch 36::Minibatch 742::LR 0.0192307692308 --> Loss 0.0020562595129\n",
      "Epoch 36::Minibatch 743::LR 0.0192307692308 --> Loss 0.00151975731055\n",
      "Epoch 36::Minibatch 744::LR 0.0192307692308 --> Loss 0.00189274350802\n",
      "Epoch 36::Minibatch 745::LR 0.0192307692308 --> Loss 0.00275440732638\n",
      "Epoch 36::Minibatch 746::LR 0.0192307692308 --> Loss 0.00280760228634\n",
      "Epoch 36::Minibatch 747::LR 0.0192307692308 --> Loss 0.00174420436223\n",
      "Epoch 36::Minibatch 748::LR 0.0192307692308 --> Loss 0.000622914234797\n",
      "Epoch 36::Minibatch 749::LR 0.0192307692308 --> Loss 0.00168447355429\n",
      "Epoch 36::Minibatch 750::LR 0.0192307692308 --> Loss 0.00240457475185\n",
      "Epoch 36::Minibatch 751::LR 0.0192307692308 --> Loss 0.00297905067603\n",
      "Epoch 36::Minibatch 752::LR 0.0192307692308 --> Loss 0.00151472677787\n",
      "Epoch 36::Minibatch 753::LR 0.0192307692308 --> Loss 0.00219588617484\n",
      "Epoch 36::Minibatch 754::LR 0.0192307692308 --> Loss 0.00242819388707\n",
      "Epoch 36::Minibatch 755::LR 0.0192307692308 --> Loss 0.00265252331893\n",
      "Epoch 36::Minibatch 756::LR 0.0192307692308 --> Loss 0.00128644059102\n",
      "Epoch 36::Minibatch 757::LR 0.0192307692308 --> Loss 0.000564010540644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 758::LR 0.0192307692308 --> Loss 0.00155966818333\n",
      "Epoch 36::Minibatch 759::LR 0.0192307692308 --> Loss 0.00329839169979\n",
      "Epoch 36::Minibatch 760::LR 0.0192307692308 --> Loss 0.00274178465207\n",
      "Epoch 36::Minibatch 761::LR 0.0192307692308 --> Loss 0.00535077850024\n",
      "Epoch 36::Minibatch 762::LR 0.0192307692308 --> Loss 0.00347266197205\n",
      "Epoch 36::Minibatch 763::LR 0.0192307692308 --> Loss 0.00337982614835\n",
      "Epoch 36::Minibatch 764::LR 0.0192307692308 --> Loss 0.00298009733359\n",
      "Epoch 36::Minibatch 765::LR 0.0192307692308 --> Loss 0.00122783462207\n",
      "Epoch 36::Minibatch 766::LR 0.0192307692308 --> Loss 0.00229607303937\n",
      "Epoch 36::Minibatch 767::LR 0.0192307692308 --> Loss 0.00470028122266\n",
      "Epoch 36::Minibatch 768::LR 0.0192307692308 --> Loss 0.00361012657483\n",
      "Epoch 36::Minibatch 769::LR 0.0192307692308 --> Loss 0.00181497434775\n",
      "Epoch 36::Minibatch 770::LR 0.0192307692308 --> Loss 0.00151226967573\n",
      "Epoch 36::Minibatch 771::LR 0.0192307692308 --> Loss 0.0033197615544\n",
      "Epoch 36::Minibatch 772::LR 0.0192307692308 --> Loss 0.00365561286608\n",
      "Epoch 36::Minibatch 773::LR 0.0192307692308 --> Loss 0.00319458742936\n",
      "Epoch 36::Minibatch 774::LR 0.0192307692308 --> Loss 0.0019054154555\n",
      "Epoch 36::Minibatch 775::LR 0.0192307692308 --> Loss 0.00316922565301\n",
      "Epoch 36::Minibatch 776::LR 0.0192307692308 --> Loss 0.00388350168864\n",
      "Epoch 36::Minibatch 777::LR 0.0192307692308 --> Loss 0.00579828381538\n",
      "Epoch 36::Minibatch 778::LR 0.0192307692308 --> Loss 0.0067462293307\n",
      "Epoch 36::Minibatch 779::LR 0.0192307692308 --> Loss 0.00249064644178\n",
      "Epoch 36::Minibatch 780::LR 0.0192307692308 --> Loss 0.00148268570503\n",
      "Epoch 36::Minibatch 781::LR 0.0192307692308 --> Loss 0.00349691192309\n",
      "Epoch 36::Minibatch 782::LR 0.0192307692308 --> Loss 0.00383047779401\n",
      "Epoch 36::Minibatch 783::LR 0.0192307692308 --> Loss 0.00226031780243\n",
      "Epoch 36::Minibatch 784::LR 0.0192307692308 --> Loss 0.000711936056614\n",
      "Epoch 36::Minibatch 785::LR 0.0192307692308 --> Loss 0.00347811857859\n",
      "Epoch 36::Minibatch 786::LR 0.0192307692308 --> Loss 0.00364824652672\n",
      "Epoch 36::Minibatch 787::LR 0.0192307692308 --> Loss 0.00256866335869\n",
      "Epoch 36::Minibatch 788::LR 0.0192307692308 --> Loss 0.00244761526585\n",
      "Epoch 36::Minibatch 789::LR 0.0192307692308 --> Loss 0.000723056445519\n",
      "Epoch 36::Minibatch 790::LR 0.0192307692308 --> Loss 0.00316514054934\n",
      "Epoch 36::Minibatch 791::LR 0.0192307692308 --> Loss 0.00321846306324\n",
      "Epoch 36::Minibatch 792::LR 0.0192307692308 --> Loss 0.00298803667227\n",
      "Epoch 36::Minibatch 793::LR 0.0192307692308 --> Loss 0.00162548393011\n",
      "Epoch 36::Minibatch 794::LR 0.0192307692308 --> Loss 0.000981910030047\n",
      "Epoch 36::Minibatch 795::LR 0.0192307692308 --> Loss 0.00259791870912\n",
      "Epoch 36::Minibatch 796::LR 0.0192307692308 --> Loss 0.00468188126882\n",
      "Epoch 36::Minibatch 797::LR 0.0192307692308 --> Loss 0.00552862962087\n",
      "Epoch 36::Minibatch 798::LR 0.0192307692308 --> Loss 0.00294540504615\n",
      "Epoch 36::Minibatch 799::LR 0.0192307692308 --> Loss 0.00223670601845\n",
      "Epoch 36::Minibatch 800::LR 0.0192307692308 --> Loss 0.00199858824412\n",
      "Epoch 36::Minibatch 801::LR 0.0192307692308 --> Loss 0.00376820246379\n",
      "Epoch 36::Minibatch 802::LR 0.0192307692308 --> Loss 0.0011836690704\n",
      "Epoch 36::Minibatch 803::LR 0.0192307692308 --> Loss 0.00296279907227\n",
      "Epoch 36::Minibatch 804::LR 0.0192307692308 --> Loss 0.00205804506938\n",
      "Epoch 36::Minibatch 805::LR 0.0192307692308 --> Loss 0.00217302242915\n",
      "Epoch 36::Minibatch 806::LR 0.0192307692308 --> Loss 0.00328845481078\n",
      "Epoch 36::Minibatch 807::LR 0.0192307692308 --> Loss 0.0030628267924\n",
      "Epoch 36::Minibatch 808::LR 0.0192307692308 --> Loss 0.00287603616714\n",
      "Epoch 36::Minibatch 809::LR 0.0192307692308 --> Loss 0.00296855449677\n",
      "Epoch 36::Minibatch 810::LR 0.0192307692308 --> Loss 0.00403668045998\n",
      "Epoch 36::Minibatch 811::LR 0.0192307692308 --> Loss 0.00388235092163\n",
      "Epoch 36::Minibatch 812::LR 0.0192307692308 --> Loss 0.00358406066895\n",
      "Epoch 36::Minibatch 813::LR 0.0192307692308 --> Loss 0.00294997394085\n",
      "Epoch 36::Minibatch 814::LR 0.0192307692308 --> Loss 0.0015031922857\n",
      "Epoch 36::Minibatch 815::LR 0.0192307692308 --> Loss 0.0034414990743\n",
      "Epoch 36::Minibatch 816::LR 0.0192307692308 --> Loss 0.00389466603597\n",
      "Epoch 36::Minibatch 817::LR 0.0192307692308 --> Loss 0.00460608363152\n",
      "Epoch 36::Minibatch 818::LR 0.0192307692308 --> Loss 0.00123192042112\n",
      "Epoch 36::Minibatch 819::LR 0.0192307692308 --> Loss 0.000729175110658\n",
      "Epoch 36::Minibatch 820::LR 0.0192307692308 --> Loss 0.00499396006266\n",
      "Epoch 36::Minibatch 821::LR 0.0192307692308 --> Loss 0.00306280851364\n",
      "Epoch 36::Minibatch 822::LR 0.0192307692308 --> Loss 0.00367000778516\n",
      "Epoch 36::Minibatch 823::LR 0.0192307692308 --> Loss 0.00125093787909\n",
      "Epoch 36::Minibatch 824::LR 0.0192307692308 --> Loss 0.0013685614864\n",
      "Epoch 36::Minibatch 825::LR 0.0192307692308 --> Loss 0.00376666148504\n",
      "Epoch 36::Minibatch 826::LR 0.0192307692308 --> Loss 0.0044632033507\n",
      "Epoch 36::Minibatch 827::LR 0.0192307692308 --> Loss 0.00205544014772\n",
      "Epoch 36::Minibatch 828::LR 0.0192307692308 --> Loss 0.0004862383008\n",
      "Epoch 36::Minibatch 829::LR 0.0192307692308 --> Loss 0.00225715438525\n",
      "Epoch 36::Minibatch 830::LR 0.0192307692308 --> Loss 0.00391043424606\n",
      "Epoch 36::Minibatch 831::LR 0.0192307692308 --> Loss 0.00234682699045\n",
      "Epoch 36::Minibatch 832::LR 0.0192307692308 --> Loss 0.00207126001517\n",
      "Epoch 36::Minibatch 833::LR 0.0192307692308 --> Loss 0.0018026214838\n",
      "Epoch 36::Minibatch 834::LR 0.0192307692308 --> Loss 0.000791129966577\n",
      "Epoch 36::Minibatch 835::LR 0.0192307692308 --> Loss 0.00382166663806\n",
      "Epoch 36::Minibatch 836::LR 0.0192307692308 --> Loss 0.003563961188\n",
      "Epoch 36::Minibatch 837::LR 0.0192307692308 --> Loss 0.0022674647967\n",
      "Epoch 36::Minibatch 838::LR 0.0192307692308 --> Loss 0.000649203906457\n",
      "Epoch 36::Minibatch 839::LR 0.0192307692308 --> Loss 0.00234778920809\n",
      "Epoch 36::Minibatch 840::LR 0.0192307692308 --> Loss 0.00283930440744\n",
      "Epoch 36::Minibatch 841::LR 0.0192307692308 --> Loss 0.00274564524492\n",
      "Epoch 36::Minibatch 842::LR 0.0192307692308 --> Loss 0.00210529625416\n",
      "Epoch 36::Minibatch 843::LR 0.0192307692308 --> Loss 0.000967002014319\n",
      "Epoch 36::Minibatch 844::LR 0.0192307692308 --> Loss 0.00146241416534\n",
      "Epoch 36::Minibatch 845::LR 0.0192307692308 --> Loss 0.00394486904144\n",
      "Epoch 36::Minibatch 846::LR 0.0192307692308 --> Loss 0.00166970988115\n",
      "Epoch 36::Minibatch 847::LR 0.0192307692308 --> Loss 0.00237873156865\n",
      "Epoch 36::Minibatch 848::LR 0.0192307692308 --> Loss 0.00114377568165\n",
      "Epoch 36::Minibatch 849::LR 0.0192307692308 --> Loss 0.00178441345692\n",
      "Epoch 36::Minibatch 850::LR 0.0192307692308 --> Loss 0.00315541327\n",
      "Epoch 36::Minibatch 851::LR 0.0192307692308 --> Loss 0.00252276301384\n",
      "Epoch 36::Minibatch 852::LR 0.0192307692308 --> Loss 0.00114285985629\n",
      "Epoch 36::Minibatch 853::LR 0.0192307692308 --> Loss 0.00130575686693\n",
      "Epoch 36::Minibatch 854::LR 0.0192307692308 --> Loss 0.00251680036386\n",
      "Epoch 36::Minibatch 855::LR 0.0192307692308 --> Loss 0.00209757606188\n",
      "Epoch 36::Minibatch 856::LR 0.0192307692308 --> Loss 0.00177311281363\n",
      "Epoch 36::Minibatch 857::LR 0.0192307692308 --> Loss 0.00120556016763\n",
      "Epoch 36::Minibatch 858::LR 0.0192307692308 --> Loss 0.000602782020966\n",
      "Epoch 36::Minibatch 859::LR 0.0192307692308 --> Loss 0.00199128389359\n",
      "Epoch 36::Minibatch 860::LR 0.0192307692308 --> Loss 0.0013070577383\n",
      "Epoch 36::Minibatch 861::LR 0.0192307692308 --> Loss 0.000947533647219\n",
      "Epoch 36::Minibatch 862::LR 0.0192307692308 --> Loss 0.00372370481491\n",
      "Epoch 36::Minibatch 863::LR 0.0192307692308 --> Loss 0.00335148215294\n",
      "Epoch 36::Minibatch 864::LR 0.0192307692308 --> Loss 0.0025835976998\n",
      "Epoch 36::Minibatch 865::LR 0.0192307692308 --> Loss 0.000531134009361\n",
      "Epoch 36::Minibatch 866::LR 0.0192307692308 --> Loss 0.00206463774045\n",
      "Epoch 36::Minibatch 867::LR 0.0192307692308 --> Loss 0.00285668730736\n",
      "Epoch 36::Minibatch 868::LR 0.0192307692308 --> Loss 0.00243623097738\n",
      "Epoch 36::Minibatch 869::LR 0.0192307692308 --> Loss 0.00214042782784\n",
      "Epoch 36::Minibatch 870::LR 0.0192307692308 --> Loss 0.00319143394629\n",
      "Epoch 36::Minibatch 871::LR 0.0192307692308 --> Loss 0.00164044340452\n",
      "Epoch 36::Minibatch 872::LR 0.0192307692308 --> Loss 0.00208808024724\n",
      "Epoch 36::Minibatch 873::LR 0.0192307692308 --> Loss 0.00245788931847\n",
      "Epoch 36::Minibatch 874::LR 0.0192307692308 --> Loss 0.00494049708049\n",
      "Epoch 36::Minibatch 875::LR 0.0192307692308 --> Loss 0.000657443304857\n",
      "Epoch 36::Minibatch 876::LR 0.0192307692308 --> Loss 0.00265776753426\n",
      "Epoch 36::Minibatch 877::LR 0.0192307692308 --> Loss 0.00428735415141\n",
      "Epoch 36::Minibatch 878::LR 0.0192307692308 --> Loss 0.00285911003749\n",
      "Epoch 36::Minibatch 879::LR 0.0192307692308 --> Loss 0.00386305014292\n",
      "Epoch 36::Minibatch 880::LR 0.0192307692308 --> Loss 0.00486577749252\n",
      "Epoch 36::Minibatch 881::LR 0.0192307692308 --> Loss 0.00414603590965\n",
      "Epoch 36::Minibatch 882::LR 0.0192307692308 --> Loss 0.00188842137655\n",
      "Epoch 36::Minibatch 883::LR 0.0192307692308 --> Loss 0.00364266991615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 884::LR 0.0192307692308 --> Loss 0.00280807475249\n",
      "Epoch 36::Minibatch 885::LR 0.0192307692308 --> Loss 0.00258673091729\n",
      "Epoch 36::Minibatch 886::LR 0.0192307692308 --> Loss 0.000438740054766\n",
      "Epoch 36::Minibatch 887::LR 0.0192307692308 --> Loss 0.0055751144886\n",
      "Epoch 36::Minibatch 888::LR 0.0192307692308 --> Loss 0.00241741220156\n",
      "Epoch 36::Minibatch 889::LR 0.0192307692308 --> Loss 0.00247463742892\n",
      "Epoch 36::Minibatch 890::LR 0.0192307692308 --> Loss 0.0035565662384\n",
      "Epoch 36::Minibatch 891::LR 0.0192307692308 --> Loss 0.00169099966685\n",
      "Epoch 36::Minibatch 892::LR 0.0192307692308 --> Loss 0.000781062593063\n",
      "Epoch 36::Minibatch 893::LR 0.0192307692308 --> Loss 0.00222499450048\n",
      "Epoch 36::Minibatch 894::LR 0.0192307692308 --> Loss 0.00194966554642\n",
      "Epoch 36::Minibatch 895::LR 0.0192307692308 --> Loss 0.00224846720695\n",
      "Epoch 36::Minibatch 896::LR 0.0192307692308 --> Loss 0.00125317285458\n",
      "Epoch 36::Minibatch 897::LR 0.0192307692308 --> Loss 0.000664645681779\n",
      "Epoch 36::Minibatch 898::LR 0.0192307692308 --> Loss 0.00194020291169\n",
      "Epoch 36::Minibatch 899::LR 0.0192307692308 --> Loss 0.0024392614762\n",
      "Epoch 36::Minibatch 900::LR 0.0192307692308 --> Loss 0.0030075921615\n",
      "Epoch 36::Minibatch 901::LR 0.0192307692308 --> Loss 0.000583394070466\n",
      "Epoch 36::Minibatch 902::LR 0.0192307692308 --> Loss 0.00138706872861\n",
      "Epoch 36::Minibatch 903::LR 0.0192307692308 --> Loss 0.00254820803801\n",
      "Epoch 36::Minibatch 904::LR 0.0192307692308 --> Loss 0.00179450809956\n",
      "Epoch 36::Minibatch 905::LR 0.0192307692308 --> Loss 0.00138708094756\n",
      "Epoch 36::Minibatch 906::LR 0.0192307692308 --> Loss 0.0010135747989\n",
      "Epoch 36::Minibatch 907::LR 0.0192307692308 --> Loss 0.00153735945622\n",
      "Epoch 36::Minibatch 908::LR 0.0192307692308 --> Loss 0.00206384162108\n",
      "Epoch 36::Minibatch 909::LR 0.0192307692308 --> Loss 0.00192454675833\n",
      "Epoch 36::Minibatch 910::LR 0.0192307692308 --> Loss 0.000840041836103\n",
      "Epoch 36::Minibatch 911::LR 0.0192307692308 --> Loss 0.00127672344446\n",
      "Epoch 36::Minibatch 912::LR 0.0192307692308 --> Loss 0.00207081139088\n",
      "Epoch 36::Minibatch 913::LR 0.0192307692308 --> Loss 0.00230492095153\n",
      "Epoch 36::Minibatch 914::LR 0.0192307692308 --> Loss 0.00126792003711\n",
      "Epoch 36::Minibatch 915::LR 0.0192307692308 --> Loss 0.000539302527905\n",
      "Epoch 36::Minibatch 916::LR 0.0192307692308 --> Loss 0.00197755535444\n",
      "Epoch 36::Minibatch 917::LR 0.0192307692308 --> Loss 0.00312743345896\n",
      "Epoch 36::Minibatch 918::LR 0.0192307692308 --> Loss 0.00433495124181\n",
      "Epoch 36::Minibatch 919::LR 0.0192307692308 --> Loss 0.000552527308464\n",
      "Epoch 36::Minibatch 920::LR 0.0192307692308 --> Loss 0.0116120171547\n",
      "Epoch 36::Minibatch 921::LR 0.0192307692308 --> Loss 0.00302220841249\n",
      "Epoch 36::Minibatch 922::LR 0.0192307692308 --> Loss 0.00300756593545\n",
      "Epoch 36::Minibatch 923::LR 0.0192307692308 --> Loss 0.00111671070258\n",
      "Epoch 36::Minibatch 924::LR 0.0192307692308 --> Loss 0.00313739339511\n",
      "Epoch 36::Minibatch 925::LR 0.0192307692308 --> Loss 0.0022147111098\n",
      "Epoch 36::Minibatch 926::LR 0.0192307692308 --> Loss 0.00438948829969\n",
      "Epoch 36::Minibatch 927::LR 0.0192307692308 --> Loss 0.00475114345551\n",
      "Epoch 36::Minibatch 928::LR 0.0192307692308 --> Loss 0.00584244847298\n",
      "Epoch 36::Minibatch 929::LR 0.0192307692308 --> Loss 0.00500331918399\n",
      "Epoch 36::Minibatch 930::LR 0.0192307692308 --> Loss 0.00926785707474\n",
      "Epoch 36::Minibatch 931::LR 0.0192307692308 --> Loss 0.00295423229535\n",
      "Epoch 36::Minibatch 932::LR 0.0192307692308 --> Loss 0.00503496607145\n",
      "Epoch 36::Minibatch 933::LR 0.0192307692308 --> Loss 0.00226091126601\n",
      "Epoch 36::Minibatch 934::LR 0.0192307692308 --> Loss 0.0028207842509\n",
      "Epoch 36::Minibatch 935::LR 0.0192307692308 --> Loss 0.0042624994119\n",
      "Epoch 36::Minibatch 936::LR 0.0192307692308 --> Loss 0.000786880950133\n",
      "Epoch 36::Minibatch 937::LR 0.0192307692308 --> Loss 0.0022284634908\n",
      "Epoch 36::Minibatch 938::LR 0.0192307692308 --> Loss 0.00187447249889\n",
      "Epoch 36::Minibatch 939::LR 0.0192307692308 --> Loss 0.00207880973816\n",
      "Epoch 36::Minibatch 940::LR 0.0192307692308 --> Loss 0.000906694233418\n",
      "Epoch 36::Minibatch 941::LR 0.0192307692308 --> Loss 0.000730993896723\n",
      "Epoch 36::Minibatch 942::LR 0.0192307692308 --> Loss 0.00253133694331\n",
      "Epoch 36::Minibatch 943::LR 0.0192307692308 --> Loss 0.00226360678673\n",
      "Epoch 36::Minibatch 944::LR 0.0192307692308 --> Loss 0.00161557257175\n",
      "Epoch 36::Minibatch 945::LR 0.0192307692308 --> Loss 0.000882956882318\n",
      "Epoch 36::Minibatch 946::LR 0.0192307692308 --> Loss 0.0022870528698\n",
      "Epoch 36::Minibatch 947::LR 0.0192307692308 --> Loss 0.00214515129725\n",
      "Epoch 36::Minibatch 948::LR 0.0192307692308 --> Loss 0.00380949457486\n",
      "Epoch 36::Minibatch 949::LR 0.0192307692308 --> Loss 0.00168147246043\n",
      "Epoch 36::Minibatch 950::LR 0.0192307692308 --> Loss 0.000680081397295\n",
      "Epoch 36::Minibatch 951::LR 0.0192307692308 --> Loss 0.00333281258742\n",
      "Epoch 36::Minibatch 952::LR 0.0192307692308 --> Loss 0.00231751342614\n",
      "Epoch 36::Minibatch 953::LR 0.0192307692308 --> Loss 0.0014136894544\n",
      "Epoch 36::Minibatch 954::LR 0.0192307692308 --> Loss 0.000925612747669\n",
      "Epoch 36::Minibatch 955::LR 0.0192307692308 --> Loss 0.00255823274453\n",
      "Epoch 36::Minibatch 956::LR 0.0192307692308 --> Loss 0.00299612323443\n",
      "Epoch 36::Minibatch 957::LR 0.0192307692308 --> Loss 0.00182481030623\n",
      "Epoch 36::Minibatch 958::LR 0.0192307692308 --> Loss 0.00217537542184\n",
      "Epoch 36::Minibatch 959::LR 0.0192307692308 --> Loss 0.00246928155422\n",
      "Epoch 36::Minibatch 960::LR 0.0192307692308 --> Loss 0.00521824717522\n",
      "Epoch 36::Minibatch 961::LR 0.0192307692308 --> Loss 0.00287826836109\n",
      "Epoch 36::Minibatch 962::LR 0.0192307692308 --> Loss 0.00222485264142\n",
      "Epoch 36::Minibatch 963::LR 0.0192307692308 --> Loss 0.00103117326895\n",
      "Epoch 36::Minibatch 964::LR 0.0192307692308 --> Loss 0.00230287253857\n",
      "Epoch 36::Minibatch 965::LR 0.0192307692308 --> Loss 0.00617524226507\n",
      "Epoch 36::Minibatch 966::LR 0.0192307692308 --> Loss 0.00483817696571\n",
      "Epoch 36::Minibatch 967::LR 0.0192307692308 --> Loss 0.00121799180905\n",
      "Epoch 36::Minibatch 968::LR 0.0192307692308 --> Loss 0.000961421529452\n",
      "Epoch 36::Minibatch 969::LR 0.0192307692308 --> Loss 0.00422323028247\n",
      "Epoch 36::Minibatch 970::LR 0.0192307692308 --> Loss 0.0040482099851\n",
      "Epoch 36::Minibatch 971::LR 0.0192307692308 --> Loss 0.00319530149301\n",
      "Epoch 36::Minibatch 972::LR 0.0192307692308 --> Loss 0.00711148579915\n",
      "Epoch 36::Minibatch 973::LR 0.0192307692308 --> Loss 0.00929742097855\n",
      "Epoch 36::Minibatch 974::LR 0.0192307692308 --> Loss 0.00785652081172\n",
      "Epoch 36::Minibatch 975::LR 0.0192307692308 --> Loss 0.0050243639946\n",
      "Epoch 36::Minibatch 976::LR 0.0192307692308 --> Loss 0.00353050549825\n",
      "Epoch 36::Minibatch 977::LR 0.0192307692308 --> Loss 0.00315918624401\n",
      "Epoch 36::Minibatch 978::LR 0.0192307692308 --> Loss 0.00305105745792\n",
      "Epoch 36::Minibatch 979::LR 0.0192307692308 --> Loss 0.0027922942241\n",
      "Epoch 36::Minibatch 980::LR 0.0192307692308 --> Loss 0.00323251903057\n",
      "Epoch 36::Minibatch 981::LR 0.0192307692308 --> Loss 0.00388172070185\n",
      "Epoch 36::Minibatch 982::LR 0.0192307692308 --> Loss 0.00362767020861\n",
      "Epoch 36::Minibatch 983::LR 0.0192307692308 --> Loss 0.0022837839524\n",
      "Epoch 36::Minibatch 984::LR 0.0192307692308 --> Loss 0.00152152667443\n",
      "Epoch 36::Minibatch 985::LR 0.0192307692308 --> Loss 0.0029145081838\n",
      "Epoch 36::Minibatch 986::LR 0.0192307692308 --> Loss 0.00261726816495\n",
      "Epoch 36::Minibatch 987::LR 0.0192307692308 --> Loss 0.00300331532955\n",
      "Epoch 36::Minibatch 988::LR 0.0192307692308 --> Loss 0.00232771317164\n",
      "Epoch 36::Minibatch 989::LR 0.0192307692308 --> Loss 0.0026744077603\n",
      "Epoch 36::Minibatch 990::LR 0.0192307692308 --> Loss 0.00256993035475\n",
      "Epoch 36::Minibatch 991::LR 0.0192307692308 --> Loss 0.00123981366555\n",
      "Epoch 36::Minibatch 992::LR 0.0192307692308 --> Loss 0.00152430812518\n",
      "Epoch 36::Minibatch 993::LR 0.0192307692308 --> Loss 0.0027901951472\n",
      "Epoch 36::Minibatch 994::LR 0.0192307692308 --> Loss 0.00186805963516\n",
      "Epoch 36::Minibatch 995::LR 0.0192307692308 --> Loss 0.0007541847229\n",
      "Epoch 36::Minibatch 996::LR 0.0192307692308 --> Loss 0.00251810908318\n",
      "Epoch 36::Minibatch 997::LR 0.0192307692308 --> Loss 0.00213537971179\n",
      "Epoch 36::Minibatch 998::LR 0.0192307692308 --> Loss 0.00242635687192\n",
      "Epoch 36::Minibatch 999::LR 0.0192307692308 --> Loss 0.00208657264709\n",
      "Epoch 36::Minibatch 1000::LR 0.0192307692308 --> Loss 0.00256270011266\n",
      "Epoch 36::Minibatch 1001::LR 0.0192307692308 --> Loss 0.00202243069808\n",
      "Epoch 36::Minibatch 1002::LR 0.0192307692308 --> Loss 0.0014004945755\n",
      "Epoch 36::Minibatch 1003::LR 0.0192307692308 --> Loss 0.0022920157512\n",
      "Epoch 36::Minibatch 1004::LR 0.0192307692308 --> Loss 0.00105754276117\n",
      "Epoch 36::Minibatch 1005::LR 0.0192307692308 --> Loss 0.00251942475637\n",
      "Epoch 36::Minibatch 1006::LR 0.0192307692308 --> Loss 0.00123801449935\n",
      "Epoch 36::Minibatch 1007::LR 0.0192307692308 --> Loss 0.00166574478149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36::Minibatch 1008::LR 0.0192307692308 --> Loss 0.000909551978111\n",
      "Epoch 36::Minibatch 1009::LR 0.0192307692308 --> Loss 0.00120148658752\n",
      "Epoch 36::Minibatch 1010::LR 0.0192307692308 --> Loss 0.00115628580252\n",
      "Epoch 36::Minibatch 1011::LR 0.0192307692308 --> Loss 0.0015147815148\n",
      "Epoch 36::Minibatch 1012::LR 0.0192307692308 --> Loss 0.00132557878892\n",
      "Epoch 36::Minibatch 1013::LR 0.0192307692308 --> Loss 0.00330608983835\n",
      "Epoch 36::Minibatch 1014::LR 0.0192307692308 --> Loss 0.00306686858336\n",
      "Epoch 36::Minibatch 1015::LR 0.0192307692308 --> Loss 0.00150258163611\n",
      "Epoch 36::Minibatch 1016::LR 0.0192307692308 --> Loss 0.00433596730232\n",
      "Epoch 36::Minibatch 1017::LR 0.0192307692308 --> Loss 0.00312633971373\n",
      "Epoch 36::Minibatch 1018::LR 0.0192307692308 --> Loss 0.00240067720413\n",
      "Epoch 36::Minibatch 1019::LR 0.0192307692308 --> Loss 0.00148081163565\n",
      "Epoch 36::Minibatch 1020::LR 0.0192307692308 --> Loss 0.00163225779931\n",
      "Epoch 36::Minibatch 1021::LR 0.0192307692308 --> Loss 0.00177037894726\n",
      "Epoch 36::Minibatch 1022::LR 0.0192307692308 --> Loss 0.00128404051065\n",
      "Epoch 36::Minibatch 1023::LR 0.0192307692308 --> Loss 0.00096174399058\n",
      "Epoch 36::Minibatch 1024::LR 0.0192307692308 --> Loss 0.000969086786111\n",
      "Epoch 36::Minibatch 1025::LR 0.0192307692308 --> Loss 0.00134685734908\n",
      "Epoch 36::Minibatch 1026::LR 0.0192307692308 --> Loss 0.000675757477681\n",
      "Epoch 36::Minibatch 1027::LR 0.0192307692308 --> Loss 0.000960173209508\n",
      "Epoch 36::Minibatch 1028::LR 0.0192307692308 --> Loss 0.000704702734947\n",
      "Epoch 36::Minibatch 1029::LR 0.0192307692308 --> Loss 0.000736460487048\n",
      "Epoch 36::Minibatch 1030::LR 0.0192307692308 --> Loss 0.000886706709862\n",
      "Epoch 36::Minibatch 1031::LR 0.0192307692308 --> Loss 0.000668679227432\n",
      "Epoch 36::Minibatch 1032::LR 0.0192307692308 --> Loss 0.000766943246126\n",
      "Epoch 36::Minibatch 1033::LR 0.0192307692308 --> Loss 0.000653471102317\n",
      "Epoch 36::Minibatch 1034::LR 0.0192307692308 --> Loss 0.000620659887791\n",
      "Epoch 36::Minibatch 1035::LR 0.0192307692308 --> Loss 0.000403329109152\n",
      "Epoch 36::Minibatch 1036::LR 0.0192307692308 --> Loss 0.000321511179209\n",
      "Epoch 36::Minibatch 1037::LR 0.0192307692308 --> Loss 0.000615684986115\n",
      "Epoch 36::Minibatch 1038::LR 0.0192307692308 --> Loss 0.000987797776858\n",
      "Epoch 36::Minibatch 1039::LR 0.0192307692308 --> Loss 0.000853879749775\n",
      "Epoch 36::Minibatch 1040::LR 0.0192307692308 --> Loss 0.000332900012533\n",
      "Epoch 36::Minibatch 1041::LR 0.0192307692308 --> Loss 0.000476564218601\n",
      "Epoch 37::Minibatch 1::LR 0.0169230769231 --> Loss 0.00718215147654\n",
      "Epoch 37::Minibatch 2::LR 0.0169230769231 --> Loss 0.00445249915123\n",
      "Epoch 37::Minibatch 3::LR 0.0169230769231 --> Loss 0.0027369081974\n",
      "Epoch 37::Minibatch 4::LR 0.0169230769231 --> Loss 0.0036361738046\n",
      "Epoch 37::Minibatch 5::LR 0.0169230769231 --> Loss 0.00424770156542\n",
      "Epoch 37::Minibatch 6::LR 0.0169230769231 --> Loss 0.0019658100605\n",
      "Epoch 37::Minibatch 7::LR 0.0169230769231 --> Loss 0.00686361869176\n",
      "Epoch 37::Minibatch 8::LR 0.0169230769231 --> Loss 0.00637177149455\n",
      "Epoch 37::Minibatch 9::LR 0.0169230769231 --> Loss 0.00500634233157\n",
      "Epoch 37::Minibatch 10::LR 0.0169230769231 --> Loss 0.00221227029959\n",
      "Epoch 37::Minibatch 11::LR 0.0169230769231 --> Loss 0.00210097928842\n",
      "Epoch 37::Minibatch 12::LR 0.0169230769231 --> Loss 0.0032821359237\n",
      "Epoch 37::Minibatch 13::LR 0.0169230769231 --> Loss 0.00527562816938\n",
      "Epoch 37::Minibatch 14::LR 0.0169230769231 --> Loss 0.00525453448296\n",
      "Epoch 37::Minibatch 15::LR 0.0169230769231 --> Loss 0.00454714298248\n",
      "Epoch 37::Minibatch 16::LR 0.0169230769231 --> Loss 0.000683357814948\n",
      "Epoch 37::Minibatch 17::LR 0.0169230769231 --> Loss 0.00322219590346\n",
      "Epoch 37::Minibatch 18::LR 0.0169230769231 --> Loss 0.00271822492282\n",
      "Epoch 37::Minibatch 19::LR 0.0169230769231 --> Loss 0.00169599950314\n",
      "Epoch 37::Minibatch 20::LR 0.0169230769231 --> Loss 0.00224837740262\n",
      "Epoch 37::Minibatch 21::LR 0.0169230769231 --> Loss 0.00347159584363\n",
      "Epoch 37::Minibatch 22::LR 0.0169230769231 --> Loss 0.00223640958468\n",
      "Epoch 37::Minibatch 23::LR 0.0169230769231 --> Loss 0.000982796549797\n",
      "Epoch 37::Minibatch 24::LR 0.0169230769231 --> Loss 0.000566616356373\n",
      "Epoch 37::Minibatch 25::LR 0.0169230769231 --> Loss 0.0014715842406\n",
      "Epoch 37::Minibatch 26::LR 0.0169230769231 --> Loss 0.00166329483191\n",
      "Epoch 37::Minibatch 27::LR 0.0169230769231 --> Loss 0.00130921204885\n",
      "Epoch 37::Minibatch 28::LR 0.0169230769231 --> Loss 0.00057402903835\n",
      "Epoch 37::Minibatch 29::LR 0.0169230769231 --> Loss 0.000741737584273\n",
      "Epoch 37::Minibatch 30::LR 0.0169230769231 --> Loss 0.00128007511298\n",
      "Epoch 37::Minibatch 31::LR 0.0169230769231 --> Loss 0.00173978308837\n",
      "Epoch 37::Minibatch 32::LR 0.0169230769231 --> Loss 0.00151722490788\n",
      "Epoch 37::Minibatch 33::LR 0.0169230769231 --> Loss 0.000854392747084\n",
      "Epoch 37::Minibatch 34::LR 0.0169230769231 --> Loss 0.00202772001425\n",
      "Epoch 37::Minibatch 35::LR 0.0169230769231 --> Loss 0.00258694807688\n",
      "Epoch 37::Minibatch 36::LR 0.0169230769231 --> Loss 0.00224937677383\n",
      "Epoch 37::Minibatch 37::LR 0.0169230769231 --> Loss 0.000779079695543\n",
      "Epoch 37::Minibatch 38::LR 0.0169230769231 --> Loss 0.000796606838703\n",
      "Epoch 37::Minibatch 39::LR 0.0169230769231 --> Loss 0.00207483987013\n",
      "Epoch 37::Minibatch 40::LR 0.0169230769231 --> Loss 0.00305296242237\n",
      "Epoch 37::Minibatch 41::LR 0.0169230769231 --> Loss 0.00239376544952\n",
      "Epoch 37::Minibatch 42::LR 0.0169230769231 --> Loss 0.00381121476491\n",
      "Epoch 37::Minibatch 43::LR 0.0169230769231 --> Loss 0.00206075151761\n",
      "Epoch 37::Minibatch 44::LR 0.0169230769231 --> Loss 0.00349838574727\n",
      "Epoch 37::Minibatch 45::LR 0.0169230769231 --> Loss 0.00246231059233\n",
      "Epoch 37::Minibatch 46::LR 0.0169230769231 --> Loss 0.00292448500792\n",
      "Epoch 37::Minibatch 47::LR 0.0169230769231 --> Loss 0.00294683595498\n",
      "Epoch 37::Minibatch 48::LR 0.0169230769231 --> Loss 0.0043333764871\n",
      "Epoch 37::Minibatch 49::LR 0.0169230769231 --> Loss 0.0049980644385\n",
      "Epoch 37::Minibatch 50::LR 0.0169230769231 --> Loss 0.00579228480657\n",
      "Epoch 37::Minibatch 51::LR 0.0169230769231 --> Loss 0.00368201812108\n",
      "Epoch 37::Minibatch 52::LR 0.0169230769231 --> Loss 0.00332375486692\n",
      "Epoch 37::Minibatch 53::LR 0.0169230769231 --> Loss 0.0033485754331\n",
      "Epoch 37::Minibatch 54::LR 0.0169230769231 --> Loss 0.00393086194992\n",
      "Epoch 37::Minibatch 55::LR 0.0169230769231 --> Loss 0.00100227336089\n",
      "Epoch 37::Minibatch 56::LR 0.0169230769231 --> Loss 0.00276169995467\n",
      "Epoch 37::Minibatch 57::LR 0.0169230769231 --> Loss 0.00430995980899\n",
      "Epoch 37::Minibatch 58::LR 0.0169230769231 --> Loss 0.00315006832282\n",
      "Epoch 37::Minibatch 59::LR 0.0169230769231 --> Loss 0.00242059230804\n",
      "Epoch 37::Minibatch 60::LR 0.0169230769231 --> Loss 0.00251998802026\n",
      "Epoch 37::Minibatch 61::LR 0.0169230769231 --> Loss 0.000690601021051\n",
      "Epoch 37::Minibatch 62::LR 0.0169230769231 --> Loss 0.00236581742764\n",
      "Epoch 37::Minibatch 63::LR 0.0169230769231 --> Loss 0.00208704312642\n",
      "Epoch 37::Minibatch 64::LR 0.0169230769231 --> Loss 0.000809031973282\n",
      "Epoch 37::Minibatch 65::LR 0.0169230769231 --> Loss 0.0020836486419\n",
      "Epoch 37::Minibatch 66::LR 0.0169230769231 --> Loss 0.00286420067151\n",
      "Epoch 37::Minibatch 67::LR 0.0169230769231 --> Loss 0.00240381499132\n",
      "Epoch 37::Minibatch 68::LR 0.0169230769231 --> Loss 0.00179549554984\n",
      "Epoch 37::Minibatch 69::LR 0.0169230769231 --> Loss 0.00348443388939\n",
      "Epoch 37::Minibatch 70::LR 0.0169230769231 --> Loss 0.00314065178235\n",
      "Epoch 37::Minibatch 71::LR 0.0169230769231 --> Loss 0.00220399439335\n",
      "Epoch 37::Minibatch 72::LR 0.0169230769231 --> Loss 0.000554828842481\n",
      "Epoch 37::Minibatch 73::LR 0.0169230769231 --> Loss 0.00357568303744\n",
      "Epoch 37::Minibatch 74::LR 0.0169230769231 --> Loss 0.00390110890071\n",
      "Epoch 37::Minibatch 75::LR 0.0169230769231 --> Loss 0.00192351659139\n",
      "Epoch 37::Minibatch 76::LR 0.0169230769231 --> Loss 0.000516808480024\n",
      "Epoch 37::Minibatch 77::LR 0.0169230769231 --> Loss 0.00319189071655\n",
      "Epoch 37::Minibatch 78::LR 0.0169230769231 --> Loss 0.00406470735868\n",
      "Epoch 37::Minibatch 79::LR 0.0169230769231 --> Loss 0.00160779625177\n",
      "Epoch 37::Minibatch 80::LR 0.0169230769231 --> Loss 0.002662525177\n",
      "Epoch 37::Minibatch 81::LR 0.0169230769231 --> Loss 0.00241693437099\n",
      "Epoch 37::Minibatch 82::LR 0.0169230769231 --> Loss 0.00174067656199\n",
      "Epoch 37::Minibatch 83::LR 0.0169230769231 --> Loss 0.00358645836512\n",
      "Epoch 37::Minibatch 84::LR 0.0169230769231 --> Loss 0.00178586820761\n",
      "Epoch 37::Minibatch 85::LR 0.0169230769231 --> Loss 0.00239653726419\n",
      "Epoch 37::Minibatch 86::LR 0.0169230769231 --> Loss 0.00203357537587\n",
      "Epoch 37::Minibatch 87::LR 0.0169230769231 --> Loss 0.0021084612608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 88::LR 0.0169230769231 --> Loss 0.00161361058553\n",
      "Epoch 37::Minibatch 89::LR 0.0169230769231 --> Loss 0.00213343560696\n",
      "Epoch 37::Minibatch 90::LR 0.0169230769231 --> Loss 0.00104179233313\n",
      "Epoch 37::Minibatch 91::LR 0.0169230769231 --> Loss 0.000883077681065\n",
      "Epoch 37::Minibatch 92::LR 0.0169230769231 --> Loss 0.00248185376326\n",
      "Epoch 37::Minibatch 93::LR 0.0169230769231 --> Loss 0.00166198045015\n",
      "Epoch 37::Minibatch 94::LR 0.0169230769231 --> Loss 0.00172979633013\n",
      "Epoch 37::Minibatch 95::LR 0.0169230769231 --> Loss 0.00193343798319\n",
      "Epoch 37::Minibatch 96::LR 0.0169230769231 --> Loss 0.00427035689354\n",
      "Epoch 37::Minibatch 97::LR 0.0169230769231 --> Loss 0.00297509392103\n",
      "Epoch 37::Minibatch 98::LR 0.0169230769231 --> Loss 0.00112729370594\n",
      "Epoch 37::Minibatch 99::LR 0.0169230769231 --> Loss 0.00146268427372\n",
      "Epoch 37::Minibatch 100::LR 0.0169230769231 --> Loss 0.00383129398028\n",
      "Epoch 37::Minibatch 101::LR 0.0169230769231 --> Loss 0.000900349517663\n",
      "Epoch 37::Minibatch 102::LR 0.0169230769231 --> Loss 0.0037756383419\n",
      "Epoch 37::Minibatch 103::LR 0.0169230769231 --> Loss 0.00376173257828\n",
      "Epoch 37::Minibatch 104::LR 0.0169230769231 --> Loss 0.00260771314303\n",
      "Epoch 37::Minibatch 105::LR 0.0169230769231 --> Loss 0.00189477463563\n",
      "Epoch 37::Minibatch 106::LR 0.0169230769231 --> Loss 0.011599214077\n",
      "Epoch 37::Minibatch 107::LR 0.0169230769231 --> Loss 0.00466546177864\n",
      "Epoch 37::Minibatch 108::LR 0.0169230769231 --> Loss 0.000889750818412\n",
      "Epoch 37::Minibatch 109::LR 0.0169230769231 --> Loss 0.00429290095965\n",
      "Epoch 37::Minibatch 110::LR 0.0169230769231 --> Loss 0.00217320501804\n",
      "Epoch 37::Minibatch 111::LR 0.0169230769231 --> Loss 0.000778164913257\n",
      "Epoch 37::Minibatch 112::LR 0.0169230769231 --> Loss 0.00321261505286\n",
      "Epoch 37::Minibatch 113::LR 0.0169230769231 --> Loss 0.00229887247086\n",
      "Epoch 37::Minibatch 114::LR 0.0169230769231 --> Loss 0.00130565941334\n",
      "Epoch 37::Minibatch 115::LR 0.0169230769231 --> Loss 0.0010614062349\n",
      "Epoch 37::Minibatch 116::LR 0.0169230769231 --> Loss 0.00262308438619\n",
      "Epoch 37::Minibatch 117::LR 0.0169230769231 --> Loss 0.00414497534434\n",
      "Epoch 37::Minibatch 118::LR 0.0169230769231 --> Loss 0.00633010983467\n",
      "Epoch 37::Minibatch 119::LR 0.0169230769231 --> Loss 0.000450301021338\n",
      "Epoch 37::Minibatch 120::LR 0.0169230769231 --> Loss 0.0016553513209\n",
      "Epoch 37::Minibatch 121::LR 0.0169230769231 --> Loss 0.00225896716118\n",
      "Epoch 37::Minibatch 122::LR 0.0169230769231 --> Loss 0.00392226099968\n",
      "Epoch 37::Minibatch 123::LR 0.0169230769231 --> Loss 0.000577321449916\n",
      "Epoch 37::Minibatch 124::LR 0.0169230769231 --> Loss 0.00264261504014\n",
      "Epoch 37::Minibatch 125::LR 0.0169230769231 --> Loss 0.00433477679888\n",
      "Epoch 37::Minibatch 126::LR 0.0169230769231 --> Loss 0.00231355230014\n",
      "Epoch 37::Minibatch 127::LR 0.0169230769231 --> Loss 0.00513509750366\n",
      "Epoch 37::Minibatch 128::LR 0.0169230769231 --> Loss 0.00344915588697\n",
      "Epoch 37::Minibatch 129::LR 0.0169230769231 --> Loss 0.00225347240766\n",
      "Epoch 37::Minibatch 130::LR 0.0169230769231 --> Loss 0.0042812414964\n",
      "Epoch 37::Minibatch 131::LR 0.0169230769231 --> Loss 0.00166210711002\n",
      "Epoch 37::Minibatch 132::LR 0.0169230769231 --> Loss 0.00269258717696\n",
      "Epoch 37::Minibatch 133::LR 0.0169230769231 --> Loss 0.00264950116475\n",
      "Epoch 37::Minibatch 134::LR 0.0169230769231 --> Loss 0.00203936656316\n",
      "Epoch 37::Minibatch 135::LR 0.0169230769231 --> Loss 0.00117159456015\n",
      "Epoch 37::Minibatch 136::LR 0.0169230769231 --> Loss 0.00229097147783\n",
      "Epoch 37::Minibatch 137::LR 0.0169230769231 --> Loss 0.0032224069039\n",
      "Epoch 37::Minibatch 138::LR 0.0169230769231 --> Loss 0.0011757756273\n",
      "Epoch 37::Minibatch 139::LR 0.0169230769231 --> Loss 0.0018332829078\n",
      "Epoch 37::Minibatch 140::LR 0.0169230769231 --> Loss 0.00231993397077\n",
      "Epoch 37::Minibatch 141::LR 0.0169230769231 --> Loss 0.00282180647055\n",
      "Epoch 37::Minibatch 142::LR 0.0169230769231 --> Loss 0.00267045915127\n",
      "Epoch 37::Minibatch 143::LR 0.0169230769231 --> Loss 0.000518534332514\n",
      "Epoch 37::Minibatch 144::LR 0.0169230769231 --> Loss 0.00342870314916\n",
      "Epoch 37::Minibatch 145::LR 0.0169230769231 --> Loss 0.00406767606735\n",
      "Epoch 37::Minibatch 146::LR 0.0169230769231 --> Loss 0.0024663011233\n",
      "Epoch 37::Minibatch 147::LR 0.0169230769231 --> Loss 0.00178305963675\n",
      "Epoch 37::Minibatch 148::LR 0.0169230769231 --> Loss 0.000942691961924\n",
      "Epoch 37::Minibatch 149::LR 0.0169230769231 --> Loss 0.00287827114264\n",
      "Epoch 37::Minibatch 150::LR 0.0169230769231 --> Loss 0.00263921380043\n",
      "Epoch 37::Minibatch 151::LR 0.0169230769231 --> Loss 0.00430996775627\n",
      "Epoch 37::Minibatch 152::LR 0.0169230769231 --> Loss 0.000894969602426\n",
      "Epoch 37::Minibatch 153::LR 0.0169230769231 --> Loss 0.00157055278619\n",
      "Epoch 37::Minibatch 154::LR 0.0169230769231 --> Loss 0.00198831876119\n",
      "Epoch 37::Minibatch 155::LR 0.0169230769231 --> Loss 0.00394691904386\n",
      "Epoch 37::Minibatch 156::LR 0.0169230769231 --> Loss 0.00234002649784\n",
      "Epoch 37::Minibatch 157::LR 0.0169230769231 --> Loss 0.000680632491906\n",
      "Epoch 37::Minibatch 158::LR 0.0169230769231 --> Loss 0.00322142958641\n",
      "Epoch 37::Minibatch 159::LR 0.0169230769231 --> Loss 0.00271321137746\n",
      "Epoch 37::Minibatch 160::LR 0.0169230769231 --> Loss 0.00267514844735\n",
      "Epoch 37::Minibatch 161::LR 0.0169230769231 --> Loss 0.000988762875398\n",
      "Epoch 37::Minibatch 162::LR 0.0169230769231 --> Loss 0.00403368194898\n",
      "Epoch 37::Minibatch 163::LR 0.0169230769231 --> Loss 0.00241752247016\n",
      "Epoch 37::Minibatch 164::LR 0.0169230769231 --> Loss 0.00256454209487\n",
      "Epoch 37::Minibatch 165::LR 0.0169230769231 --> Loss 0.00048248236378\n",
      "Epoch 37::Minibatch 166::LR 0.0169230769231 --> Loss 0.00168399771055\n",
      "Epoch 37::Minibatch 167::LR 0.0169230769231 --> Loss 0.00249292870363\n",
      "Epoch 37::Minibatch 168::LR 0.0169230769231 --> Loss 0.00212949375312\n",
      "Epoch 37::Minibatch 169::LR 0.0169230769231 --> Loss 0.000972815454006\n",
      "Epoch 37::Minibatch 170::LR 0.0169230769231 --> Loss 0.000936753849188\n",
      "Epoch 37::Minibatch 171::LR 0.0169230769231 --> Loss 0.00252373298009\n",
      "Epoch 37::Minibatch 172::LR 0.0169230769231 --> Loss 0.00428906361262\n",
      "Epoch 37::Minibatch 173::LR 0.0169230769231 --> Loss 0.00205532968044\n",
      "Epoch 37::Minibatch 174::LR 0.0169230769231 --> Loss 0.000938572883606\n",
      "Epoch 37::Minibatch 175::LR 0.0169230769231 --> Loss 0.00240713357925\n",
      "Epoch 37::Minibatch 176::LR 0.0169230769231 --> Loss 0.0030552003781\n",
      "Epoch 37::Minibatch 177::LR 0.0169230769231 --> Loss 0.00418776949247\n",
      "Epoch 37::Minibatch 178::LR 0.0169230769231 --> Loss 0.00145068297784\n",
      "Epoch 37::Minibatch 179::LR 0.0169230769231 --> Loss 0.0011306732893\n",
      "Epoch 37::Minibatch 180::LR 0.0169230769231 --> Loss 0.00328386247158\n",
      "Epoch 37::Minibatch 181::LR 0.0169230769231 --> Loss 0.00298479835192\n",
      "Epoch 37::Minibatch 182::LR 0.0169230769231 --> Loss 0.000680603533983\n",
      "Epoch 37::Minibatch 183::LR 0.0169230769231 --> Loss 0.00151134093602\n",
      "Epoch 37::Minibatch 184::LR 0.0169230769231 --> Loss 0.00337048649788\n",
      "Epoch 37::Minibatch 185::LR 0.0169230769231 --> Loss 0.0025580873092\n",
      "Epoch 37::Minibatch 186::LR 0.0169230769231 --> Loss 0.000901766518752\n",
      "Epoch 37::Minibatch 187::LR 0.0169230769231 --> Loss 0.00125658462445\n",
      "Epoch 37::Minibatch 188::LR 0.0169230769231 --> Loss 0.00393416126569\n",
      "Epoch 37::Minibatch 189::LR 0.0169230769231 --> Loss 0.00400742888451\n",
      "Epoch 37::Minibatch 190::LR 0.0169230769231 --> Loss 0.00227210779985\n",
      "Epoch 37::Minibatch 191::LR 0.0169230769231 --> Loss 0.00043652638793\n",
      "Epoch 37::Minibatch 192::LR 0.0169230769231 --> Loss 0.00277229527632\n",
      "Epoch 37::Minibatch 193::LR 0.0169230769231 --> Loss 0.00270307083925\n",
      "Epoch 37::Minibatch 194::LR 0.0169230769231 --> Loss 0.00171034455299\n",
      "Epoch 37::Minibatch 195::LR 0.0169230769231 --> Loss 0.0003690165778\n",
      "Epoch 37::Minibatch 196::LR 0.0169230769231 --> Loss 0.0013744088014\n",
      "Epoch 37::Minibatch 197::LR 0.0169230769231 --> Loss 0.00295881032944\n",
      "Epoch 37::Minibatch 198::LR 0.0169230769231 --> Loss 0.00232888857524\n",
      "Epoch 37::Minibatch 199::LR 0.0169230769231 --> Loss 0.000288230702281\n",
      "Epoch 37::Minibatch 200::LR 0.0169230769231 --> Loss 0.00203387061755\n",
      "Epoch 37::Minibatch 201::LR 0.0169230769231 --> Loss 0.0019237891833\n",
      "Epoch 37::Minibatch 202::LR 0.0169230769231 --> Loss 0.00180352727572\n",
      "Epoch 37::Minibatch 203::LR 0.0169230769231 --> Loss 0.00175984740257\n",
      "Epoch 37::Minibatch 204::LR 0.0169230769231 --> Loss 0.00141402562459\n",
      "Epoch 37::Minibatch 205::LR 0.0169230769231 --> Loss 0.00222599069277\n",
      "Epoch 37::Minibatch 206::LR 0.0169230769231 --> Loss 0.00514092048009\n",
      "Epoch 37::Minibatch 207::LR 0.0169230769231 --> Loss 0.00139616956313\n",
      "Epoch 37::Minibatch 208::LR 0.0169230769231 --> Loss 0.00110196818908\n",
      "Epoch 37::Minibatch 209::LR 0.0169230769231 --> Loss 0.00255962967873\n",
      "Epoch 37::Minibatch 210::LR 0.0169230769231 --> Loss 0.00240180373192\n",
      "Epoch 37::Minibatch 211::LR 0.0169230769231 --> Loss 0.00275365769863\n",
      "Epoch 37::Minibatch 212::LR 0.0169230769231 --> Loss 0.00370530764262\n",
      "Epoch 37::Minibatch 213::LR 0.0169230769231 --> Loss 0.00530311266581\n",
      "Epoch 37::Minibatch 214::LR 0.0169230769231 --> Loss 0.0066298019886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 215::LR 0.0169230769231 --> Loss 0.0013564452529\n",
      "Epoch 37::Minibatch 216::LR 0.0169230769231 --> Loss 0.00522233168284\n",
      "Epoch 37::Minibatch 217::LR 0.0169230769231 --> Loss 0.00572249611219\n",
      "Epoch 37::Minibatch 218::LR 0.0169230769231 --> Loss 0.00388745943705\n",
      "Epoch 37::Minibatch 219::LR 0.0169230769231 --> Loss 0.00446145653725\n",
      "Epoch 37::Minibatch 220::LR 0.0169230769231 --> Loss 0.00431773265203\n",
      "Epoch 37::Minibatch 221::LR 0.0169230769231 --> Loss 0.0042805993557\n",
      "Epoch 37::Minibatch 222::LR 0.0169230769231 --> Loss 0.00314708590508\n",
      "Epoch 37::Minibatch 223::LR 0.0169230769231 --> Loss 0.00137378871441\n",
      "Epoch 37::Minibatch 224::LR 0.0169230769231 --> Loss 0.001563248535\n",
      "Epoch 37::Minibatch 225::LR 0.0169230769231 --> Loss 0.00794930060705\n",
      "Epoch 37::Minibatch 226::LR 0.0169230769231 --> Loss 0.00359347422918\n",
      "Epoch 37::Minibatch 227::LR 0.0169230769231 --> Loss 0.00167651196321\n",
      "Epoch 37::Minibatch 228::LR 0.0169230769231 --> Loss 0.000634794731935\n",
      "Epoch 37::Minibatch 229::LR 0.0169230769231 --> Loss 0.00475437005361\n",
      "Epoch 37::Minibatch 230::LR 0.0169230769231 --> Loss 0.00358214775721\n",
      "Epoch 37::Minibatch 231::LR 0.0169230769231 --> Loss 0.00266693512599\n",
      "Epoch 37::Minibatch 232::LR 0.0169230769231 --> Loss 0.00115095953147\n",
      "Epoch 37::Minibatch 233::LR 0.0169230769231 --> Loss 0.00247133255005\n",
      "Epoch 37::Minibatch 234::LR 0.0169230769231 --> Loss 0.00750881671906\n",
      "Epoch 37::Minibatch 235::LR 0.0169230769231 --> Loss 0.00455969611804\n",
      "Epoch 37::Minibatch 236::LR 0.0169230769231 --> Loss 0.00165092865626\n",
      "Epoch 37::Minibatch 237::LR 0.0169230769231 --> Loss 0.000563361148039\n",
      "Epoch 37::Minibatch 238::LR 0.0169230769231 --> Loss 0.00348362445831\n",
      "Epoch 37::Minibatch 239::LR 0.0169230769231 --> Loss 0.00295668383439\n",
      "Epoch 37::Minibatch 240::LR 0.0169230769231 --> Loss 0.00328047076861\n",
      "Epoch 37::Minibatch 241::LR 0.0169230769231 --> Loss 0.000744411846002\n",
      "Epoch 37::Minibatch 242::LR 0.0169230769231 --> Loss 0.00666391253471\n",
      "Epoch 37::Minibatch 243::LR 0.0169230769231 --> Loss 0.00319946269194\n",
      "Epoch 37::Minibatch 244::LR 0.0169230769231 --> Loss 0.00268086254597\n",
      "Epoch 37::Minibatch 245::LR 0.0169230769231 --> Loss 0.000415039211512\n",
      "Epoch 37::Minibatch 246::LR 0.0169230769231 --> Loss 0.00185490727425\n",
      "Epoch 37::Minibatch 247::LR 0.0169230769231 --> Loss 0.00981798728307\n",
      "Epoch 37::Minibatch 248::LR 0.0169230769231 --> Loss 0.00431456844012\n",
      "Epoch 37::Minibatch 249::LR 0.0169230769231 --> Loss 0.00234982788563\n",
      "Epoch 37::Minibatch 250::LR 0.0169230769231 --> Loss 0.00230970422427\n",
      "Epoch 37::Minibatch 251::LR 0.0169230769231 --> Loss 0.00230553666751\n",
      "Epoch 37::Minibatch 252::LR 0.0169230769231 --> Loss 0.00157244950533\n",
      "Epoch 37::Minibatch 253::LR 0.0169230769231 --> Loss 0.00270592709382\n",
      "Epoch 37::Minibatch 254::LR 0.0169230769231 --> Loss 0.00476214329402\n",
      "Epoch 37::Minibatch 255::LR 0.0169230769231 --> Loss 0.0038551735878\n",
      "Epoch 37::Minibatch 256::LR 0.0169230769231 --> Loss 0.00133558203777\n",
      "Epoch 37::Minibatch 257::LR 0.0169230769231 --> Loss 0.00112471888463\n",
      "Epoch 37::Minibatch 258::LR 0.0169230769231 --> Loss 0.00366988420486\n",
      "Epoch 37::Minibatch 259::LR 0.0169230769231 --> Loss 0.00153133898973\n",
      "Epoch 37::Minibatch 260::LR 0.0169230769231 --> Loss 0.00183287700017\n",
      "Epoch 37::Minibatch 261::LR 0.0169230769231 --> Loss 0.00261436283588\n",
      "Epoch 37::Minibatch 262::LR 0.0169230769231 --> Loss 0.00178543011347\n",
      "Epoch 37::Minibatch 263::LR 0.0169230769231 --> Loss 0.0022562567393\n",
      "Epoch 37::Minibatch 264::LR 0.0169230769231 --> Loss 0.00353625615438\n",
      "Epoch 37::Minibatch 265::LR 0.0169230769231 --> Loss 0.00996791521708\n",
      "Epoch 37::Minibatch 266::LR 0.0169230769231 --> Loss 0.000834273497264\n",
      "Epoch 37::Minibatch 267::LR 0.0169230769231 --> Loss 0.00885726054509\n",
      "Epoch 37::Minibatch 268::LR 0.0169230769231 --> Loss 0.000985634426276\n",
      "Epoch 37::Minibatch 269::LR 0.0169230769231 --> Loss 0.00345351457596\n",
      "Epoch 37::Minibatch 270::LR 0.0169230769231 --> Loss 0.00761317332586\n",
      "Epoch 37::Minibatch 271::LR 0.0169230769231 --> Loss 0.00232002496719\n",
      "Epoch 37::Minibatch 272::LR 0.0169230769231 --> Loss 0.00450433572133\n",
      "Epoch 37::Minibatch 273::LR 0.0169230769231 --> Loss 0.00127801050742\n",
      "Epoch 37::Minibatch 274::LR 0.0169230769231 --> Loss 0.00175317267577\n",
      "Epoch 37::Minibatch 275::LR 0.0169230769231 --> Loss 0.00239500363668\n",
      "Epoch 37::Minibatch 276::LR 0.0169230769231 --> Loss 0.003280403018\n",
      "Epoch 37::Minibatch 277::LR 0.0169230769231 --> Loss 0.000818469127019\n",
      "Epoch 37::Minibatch 278::LR 0.0169230769231 --> Loss 0.00248001635075\n",
      "Epoch 37::Minibatch 279::LR 0.0169230769231 --> Loss 0.00186130722364\n",
      "Epoch 37::Minibatch 280::LR 0.0169230769231 --> Loss 0.00165469815334\n",
      "Epoch 37::Minibatch 281::LR 0.0169230769231 --> Loss 0.00104634106159\n",
      "Epoch 37::Minibatch 282::LR 0.0169230769231 --> Loss 0.00190777381261\n",
      "Epoch 37::Minibatch 283::LR 0.0169230769231 --> Loss 0.00180180291335\n",
      "Epoch 37::Minibatch 284::LR 0.0169230769231 --> Loss 0.00147931605577\n",
      "Epoch 37::Minibatch 285::LR 0.0169230769231 --> Loss 0.00107338955005\n",
      "Epoch 37::Minibatch 286::LR 0.0169230769231 --> Loss 0.0018649427096\n",
      "Epoch 37::Minibatch 287::LR 0.0169230769231 --> Loss 0.00185473203659\n",
      "Epoch 37::Minibatch 288::LR 0.0169230769231 --> Loss 0.00100945154826\n",
      "Epoch 37::Minibatch 289::LR 0.0169230769231 --> Loss 0.00149634838104\n",
      "Epoch 37::Minibatch 290::LR 0.0169230769231 --> Loss 0.00177739560604\n",
      "Epoch 37::Minibatch 291::LR 0.0169230769231 --> Loss 0.00160392065843\n",
      "Epoch 37::Minibatch 292::LR 0.0169230769231 --> Loss 0.000565586338441\n",
      "Epoch 37::Minibatch 293::LR 0.0169230769231 --> Loss 0.00144800682863\n",
      "Epoch 37::Minibatch 294::LR 0.0169230769231 --> Loss 0.00161379893621\n",
      "Epoch 37::Minibatch 295::LR 0.0169230769231 --> Loss 0.00184677739938\n",
      "Epoch 37::Minibatch 296::LR 0.0169230769231 --> Loss 0.00158324668805\n",
      "Epoch 37::Minibatch 297::LR 0.0169230769231 --> Loss 0.00139357904593\n",
      "Epoch 37::Minibatch 298::LR 0.0169230769231 --> Loss 0.00140219211578\n",
      "Epoch 37::Minibatch 299::LR 0.0169230769231 --> Loss 0.000807398110628\n",
      "Epoch 37::Minibatch 300::LR 0.0169230769231 --> Loss 0.00263237734636\n",
      "Epoch 37::Minibatch 301::LR 0.0169230769231 --> Loss 0.00254909694195\n",
      "Epoch 37::Minibatch 302::LR 0.0169230769231 --> Loss 0.0023602994283\n",
      "Epoch 37::Minibatch 303::LR 0.0169230769231 --> Loss 0.00081172734499\n",
      "Epoch 37::Minibatch 304::LR 0.0169230769231 --> Loss 0.00287587503592\n",
      "Epoch 37::Minibatch 305::LR 0.0169230769231 --> Loss 0.00170809646447\n",
      "Epoch 37::Minibatch 306::LR 0.0169230769231 --> Loss 0.000928105513255\n",
      "Epoch 37::Minibatch 307::LR 0.0169230769231 --> Loss 0.00239054183165\n",
      "Epoch 37::Minibatch 308::LR 0.0169230769231 --> Loss 0.00200268725554\n",
      "Epoch 37::Minibatch 309::LR 0.0169230769231 --> Loss 0.00104169627031\n",
      "Epoch 37::Minibatch 310::LR 0.0169230769231 --> Loss 0.00119581411282\n",
      "Epoch 37::Minibatch 311::LR 0.0169230769231 --> Loss 0.00179487705231\n",
      "Epoch 37::Minibatch 312::LR 0.0169230769231 --> Loss 0.00283898492654\n",
      "Epoch 37::Minibatch 313::LR 0.0169230769231 --> Loss 0.00231296042601\n",
      "Epoch 37::Minibatch 314::LR 0.0169230769231 --> Loss 0.00191868801912\n",
      "Epoch 37::Minibatch 315::LR 0.0169230769231 --> Loss 0.00105353832245\n",
      "Epoch 37::Minibatch 316::LR 0.0169230769231 --> Loss 0.00234205683072\n",
      "Epoch 37::Minibatch 317::LR 0.0169230769231 --> Loss 0.00156378140052\n",
      "Epoch 37::Minibatch 318::LR 0.0169230769231 --> Loss 0.00131970564524\n",
      "Epoch 37::Minibatch 319::LR 0.0169230769231 --> Loss 0.00230132659276\n",
      "Epoch 37::Minibatch 320::LR 0.0169230769231 --> Loss 0.00297916392485\n",
      "Epoch 37::Minibatch 321::LR 0.0169230769231 --> Loss 0.000839665134748\n",
      "Epoch 37::Minibatch 322::LR 0.0169230769231 --> Loss 0.00335180997849\n",
      "Epoch 37::Minibatch 323::LR 0.0169230769231 --> Loss 0.00339275797208\n",
      "Epoch 37::Minibatch 324::LR 0.0169230769231 --> Loss 0.00265423516432\n",
      "Epoch 37::Minibatch 325::LR 0.0169230769231 --> Loss 0.00236310164134\n",
      "Epoch 37::Minibatch 326::LR 0.0169230769231 --> Loss 0.00514018098513\n",
      "Epoch 37::Minibatch 327::LR 0.0169230769231 --> Loss 0.00220778763294\n",
      "Epoch 37::Minibatch 328::LR 0.0169230769231 --> Loss 0.00285472989082\n",
      "Epoch 37::Minibatch 329::LR 0.0169230769231 --> Loss 0.00117757807175\n",
      "Epoch 37::Minibatch 330::LR 0.0169230769231 --> Loss 0.00158533751965\n",
      "Epoch 37::Minibatch 331::LR 0.0169230769231 --> Loss 0.00253142416477\n",
      "Epoch 37::Minibatch 332::LR 0.0169230769231 --> Loss 0.00243197321892\n",
      "Epoch 37::Minibatch 333::LR 0.0169230769231 --> Loss 0.00147338598967\n",
      "Epoch 37::Minibatch 334::LR 0.0169230769231 --> Loss 0.00437638759613\n",
      "Epoch 37::Minibatch 335::LR 0.0169230769231 --> Loss 0.00190548678239\n",
      "Epoch 37::Minibatch 336::LR 0.0169230769231 --> Loss 0.00227040171623\n",
      "Epoch 37::Minibatch 337::LR 0.0169230769231 --> Loss 0.003810227712\n",
      "Epoch 37::Minibatch 338::LR 0.0169230769231 --> Loss 0.000560194750627\n",
      "Epoch 37::Minibatch 339::LR 0.0169230769231 --> Loss 0.00320473631223\n",
      "Epoch 37::Minibatch 340::LR 0.0169230769231 --> Loss 0.0035929731528\n",
      "Epoch 37::Minibatch 341::LR 0.0169230769231 --> Loss 0.00417270421982\n",
      "Epoch 37::Minibatch 342::LR 0.0169230769231 --> Loss 0.00304442346096\n",
      "Epoch 37::Minibatch 343::LR 0.0169230769231 --> Loss 0.00163617014885\n",
      "Epoch 37::Minibatch 344::LR 0.0169230769231 --> Loss 0.00315328617891\n",
      "Epoch 37::Minibatch 345::LR 0.0169230769231 --> Loss 0.0040174249808\n",
      "Epoch 37::Minibatch 346::LR 0.0169230769231 --> Loss 0.00524929642677\n",
      "Epoch 37::Minibatch 347::LR 0.0169230769231 --> Loss 0.000819269021352\n",
      "Epoch 37::Minibatch 348::LR 0.0169230769231 --> Loss 0.00289058725039\n",
      "Epoch 37::Minibatch 349::LR 0.0169230769231 --> Loss 0.00329888403416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 350::LR 0.0169230769231 --> Loss 0.00163922349612\n",
      "Epoch 37::Minibatch 351::LR 0.0169230769231 --> Loss 0.00341156880061\n",
      "Epoch 37::Minibatch 352::LR 0.0169230769231 --> Loss 0.0048365342617\n",
      "Epoch 37::Minibatch 353::LR 0.0169230769231 --> Loss 0.00347611705462\n",
      "Epoch 37::Minibatch 354::LR 0.0169230769231 --> Loss 0.0029384525617\n",
      "Epoch 37::Minibatch 355::LR 0.0169230769231 --> Loss 0.00631873607635\n",
      "Epoch 37::Minibatch 356::LR 0.0169230769231 --> Loss 0.00317257841428\n",
      "Epoch 37::Minibatch 357::LR 0.0169230769231 --> Loss 0.00120960175991\n",
      "Epoch 37::Minibatch 358::LR 0.0169230769231 --> Loss 0.00190653423468\n",
      "Epoch 37::Minibatch 359::LR 0.0169230769231 --> Loss 0.00265923420588\n",
      "Epoch 37::Minibatch 360::LR 0.0169230769231 --> Loss 0.00225464999676\n",
      "Epoch 37::Minibatch 361::LR 0.0169230769231 --> Loss 0.00221218208472\n",
      "Epoch 37::Minibatch 362::LR 0.0169230769231 --> Loss 0.0022091126442\n",
      "Epoch 37::Minibatch 363::LR 0.0169230769231 --> Loss 0.000629507253567\n",
      "Epoch 37::Minibatch 364::LR 0.0169230769231 --> Loss 0.00195996324221\n",
      "Epoch 37::Minibatch 365::LR 0.0169230769231 --> Loss 0.00197538932165\n",
      "Epoch 37::Minibatch 366::LR 0.0169230769231 --> Loss 0.00208467423916\n",
      "Epoch 37::Minibatch 367::LR 0.0169230769231 --> Loss 0.00096848676602\n",
      "Epoch 37::Minibatch 368::LR 0.0169230769231 --> Loss 0.000972086886565\n",
      "Epoch 37::Minibatch 369::LR 0.0169230769231 --> Loss 0.00269909421603\n",
      "Epoch 37::Minibatch 370::LR 0.0169230769231 --> Loss 0.00217682858308\n",
      "Epoch 37::Minibatch 371::LR 0.0169230769231 --> Loss 0.00182380398115\n",
      "Epoch 37::Minibatch 372::LR 0.0169230769231 --> Loss 0.00042695676287\n",
      "Epoch 37::Minibatch 373::LR 0.0169230769231 --> Loss 0.00181255380313\n",
      "Epoch 37::Minibatch 374::LR 0.0169230769231 --> Loss 0.00225295245647\n",
      "Epoch 37::Minibatch 375::LR 0.0169230769231 --> Loss 0.00190187513828\n",
      "Epoch 37::Minibatch 376::LR 0.0169230769231 --> Loss 0.00118499616782\n",
      "Epoch 37::Minibatch 377::LR 0.0169230769231 --> Loss 0.00189861059189\n",
      "Epoch 37::Minibatch 378::LR 0.0169230769231 --> Loss 0.0020792734623\n",
      "Epoch 37::Minibatch 379::LR 0.0169230769231 --> Loss 0.00230157196522\n",
      "Epoch 37::Minibatch 380::LR 0.0169230769231 --> Loss 0.00155208895604\n",
      "Epoch 37::Minibatch 381::LR 0.0169230769231 --> Loss 0.000999407271544\n",
      "Epoch 37::Minibatch 382::LR 0.0169230769231 --> Loss 0.00204762736956\n",
      "Epoch 37::Minibatch 383::LR 0.0169230769231 --> Loss 0.00199504276117\n",
      "Epoch 37::Minibatch 384::LR 0.0169230769231 --> Loss 0.00114452769359\n",
      "Epoch 37::Minibatch 385::LR 0.0169230769231 --> Loss 0.00106659998496\n",
      "Epoch 37::Minibatch 386::LR 0.0169230769231 --> Loss 0.0022769544522\n",
      "Epoch 37::Minibatch 387::LR 0.0169230769231 --> Loss 0.00236655592918\n",
      "Epoch 37::Minibatch 388::LR 0.0169230769231 --> Loss 0.00123470058044\n",
      "Epoch 37::Minibatch 389::LR 0.0169230769231 --> Loss 0.00178571323554\n",
      "Epoch 37::Minibatch 390::LR 0.0169230769231 --> Loss 0.00318548500538\n",
      "Epoch 37::Minibatch 391::LR 0.0169230769231 --> Loss 0.0025271119674\n",
      "Epoch 37::Minibatch 392::LR 0.0169230769231 --> Loss 0.00254341959953\n",
      "Epoch 37::Minibatch 393::LR 0.0169230769231 --> Loss 0.00272527754307\n",
      "Epoch 37::Minibatch 394::LR 0.0169230769231 --> Loss 0.00200404961904\n",
      "Epoch 37::Minibatch 395::LR 0.0169230769231 --> Loss 0.00208325207233\n",
      "Epoch 37::Minibatch 396::LR 0.0169230769231 --> Loss 0.0019488265117\n",
      "Epoch 37::Minibatch 397::LR 0.0169230769231 --> Loss 0.00208949565887\n",
      "Epoch 37::Minibatch 398::LR 0.0169230769231 --> Loss 0.002079068621\n",
      "Epoch 37::Minibatch 399::LR 0.0169230769231 --> Loss 0.0023800488313\n",
      "Epoch 37::Minibatch 400::LR 0.0169230769231 --> Loss 0.00201914091905\n",
      "Epoch 37::Minibatch 401::LR 0.0169230769231 --> Loss 0.00339578032494\n",
      "Epoch 37::Minibatch 402::LR 0.0169230769231 --> Loss 0.0017117869854\n",
      "Epoch 37::Minibatch 403::LR 0.0169230769231 --> Loss 0.00143189062675\n",
      "Epoch 37::Minibatch 404::LR 0.0169230769231 --> Loss 0.00131312270959\n",
      "Epoch 37::Minibatch 405::LR 0.0169230769231 --> Loss 0.00331024428209\n",
      "Epoch 37::Minibatch 406::LR 0.0169230769231 --> Loss 0.00231877684593\n",
      "Epoch 37::Minibatch 407::LR 0.0169230769231 --> Loss 0.00170748551687\n",
      "Epoch 37::Minibatch 408::LR 0.0169230769231 --> Loss 0.000435786793629\n",
      "Epoch 37::Minibatch 409::LR 0.0169230769231 --> Loss 0.0022019247214\n",
      "Epoch 37::Minibatch 410::LR 0.0169230769231 --> Loss 0.00313029865424\n",
      "Epoch 37::Minibatch 411::LR 0.0169230769231 --> Loss 0.00167601287365\n",
      "Epoch 37::Minibatch 412::LR 0.0169230769231 --> Loss 0.00094245215257\n",
      "Epoch 37::Minibatch 413::LR 0.0169230769231 --> Loss 0.00198438008626\n",
      "Epoch 37::Minibatch 414::LR 0.0169230769231 --> Loss 0.00188783963521\n",
      "Epoch 37::Minibatch 415::LR 0.0169230769231 --> Loss 0.0011845083038\n",
      "Epoch 37::Minibatch 416::LR 0.0169230769231 --> Loss 0.000789261360963\n",
      "Epoch 37::Minibatch 417::LR 0.0169230769231 --> Loss 0.00167833904425\n",
      "Epoch 37::Minibatch 418::LR 0.0169230769231 --> Loss 0.00256238480409\n",
      "Epoch 37::Minibatch 419::LR 0.0169230769231 --> Loss 0.000493481556575\n",
      "Epoch 37::Minibatch 420::LR 0.0169230769231 --> Loss 0.000698541154464\n",
      "Epoch 37::Minibatch 421::LR 0.0169230769231 --> Loss 0.00186586459478\n",
      "Epoch 37::Minibatch 422::LR 0.0169230769231 --> Loss 0.00204890112082\n",
      "Epoch 37::Minibatch 423::LR 0.0169230769231 --> Loss 0.000998339752356\n",
      "Epoch 37::Minibatch 424::LR 0.0169230769231 --> Loss 0.0015244714419\n",
      "Epoch 37::Minibatch 425::LR 0.0169230769231 --> Loss 0.0028544463714\n",
      "Epoch 37::Minibatch 426::LR 0.0169230769231 --> Loss 0.00199766099453\n",
      "Epoch 37::Minibatch 427::LR 0.0169230769231 --> Loss 0.000750991106033\n",
      "Epoch 37::Minibatch 428::LR 0.0169230769231 --> Loss 0.000901589095592\n",
      "Epoch 37::Minibatch 429::LR 0.0169230769231 --> Loss 0.00221731464068\n",
      "Epoch 37::Minibatch 430::LR 0.0169230769231 --> Loss 0.00730929772059\n",
      "Epoch 37::Minibatch 431::LR 0.0169230769231 --> Loss 0.00346938927968\n",
      "Epoch 37::Minibatch 432::LR 0.0169230769231 --> Loss 0.0038509007295\n",
      "Epoch 37::Minibatch 433::LR 0.0169230769231 --> Loss 0.00253708422184\n",
      "Epoch 37::Minibatch 434::LR 0.0169230769231 --> Loss 0.00240979890029\n",
      "Epoch 37::Minibatch 435::LR 0.0169230769231 --> Loss 0.00224468171597\n",
      "Epoch 37::Minibatch 436::LR 0.0169230769231 --> Loss 0.00157460113366\n",
      "Epoch 37::Minibatch 437::LR 0.0169230769231 --> Loss 0.00273573478063\n",
      "Epoch 37::Minibatch 438::LR 0.0169230769231 --> Loss 0.00219700674216\n",
      "Epoch 37::Minibatch 439::LR 0.0169230769231 --> Loss 0.00188430825869\n",
      "Epoch 37::Minibatch 440::LR 0.0169230769231 --> Loss 0.00290940960248\n",
      "Epoch 37::Minibatch 441::LR 0.0169230769231 --> Loss 0.00272357662519\n",
      "Epoch 37::Minibatch 442::LR 0.0169230769231 --> Loss 0.00242035428683\n",
      "Epoch 37::Minibatch 443::LR 0.0169230769231 --> Loss 0.00341519316037\n",
      "Epoch 37::Minibatch 444::LR 0.0169230769231 --> Loss 0.00262626250585\n",
      "Epoch 37::Minibatch 445::LR 0.0169230769231 --> Loss 0.000837982396285\n",
      "Epoch 37::Minibatch 446::LR 0.0169230769231 --> Loss 0.00134334027767\n",
      "Epoch 37::Minibatch 447::LR 0.0169230769231 --> Loss 0.00225023408731\n",
      "Epoch 37::Minibatch 448::LR 0.0169230769231 --> Loss 0.00229525208473\n",
      "Epoch 37::Minibatch 449::LR 0.0169230769231 --> Loss 0.003531066974\n",
      "Epoch 37::Minibatch 450::LR 0.0169230769231 --> Loss 0.00209820667903\n",
      "Epoch 37::Minibatch 451::LR 0.0169230769231 --> Loss 0.00377102375031\n",
      "Epoch 37::Minibatch 452::LR 0.0169230769231 --> Loss 0.00226818998655\n",
      "Epoch 37::Minibatch 453::LR 0.0169230769231 --> Loss 0.000344005376101\n",
      "Epoch 37::Minibatch 454::LR 0.0169230769231 --> Loss 0.00334995230039\n",
      "Epoch 37::Minibatch 455::LR 0.0169230769231 --> Loss 0.00254765311877\n",
      "Epoch 37::Minibatch 456::LR 0.0169230769231 --> Loss 0.00304026842117\n",
      "Epoch 37::Minibatch 457::LR 0.0169230769231 --> Loss 0.00186385631561\n",
      "Epoch 37::Minibatch 458::LR 0.0169230769231 --> Loss 0.000711141924063\n",
      "Epoch 37::Minibatch 459::LR 0.0169230769231 --> Loss 0.00374000668526\n",
      "Epoch 37::Minibatch 460::LR 0.0169230769231 --> Loss 0.00239851057529\n",
      "Epoch 37::Minibatch 461::LR 0.0169230769231 --> Loss 0.00361569007238\n",
      "Epoch 37::Minibatch 462::LR 0.0169230769231 --> Loss 0.000364869534969\n",
      "Epoch 37::Minibatch 463::LR 0.0169230769231 --> Loss 0.00395064870516\n",
      "Epoch 37::Minibatch 464::LR 0.0169230769231 --> Loss 0.00192622005939\n",
      "Epoch 37::Minibatch 465::LR 0.0169230769231 --> Loss 0.00431902766228\n",
      "Epoch 37::Minibatch 466::LR 0.0169230769231 --> Loss 0.00488757491112\n",
      "Epoch 37::Minibatch 467::LR 0.0169230769231 --> Loss 0.00493962128957\n",
      "Epoch 37::Minibatch 468::LR 0.0169230769231 --> Loss 0.00551139116287\n",
      "Epoch 37::Minibatch 469::LR 0.0169230769231 --> Loss 0.00581734776497\n",
      "Epoch 37::Minibatch 470::LR 0.0169230769231 --> Loss 0.00352844834328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 471::LR 0.0169230769231 --> Loss 0.00164302170277\n",
      "Epoch 37::Minibatch 472::LR 0.0169230769231 --> Loss 0.00356434305509\n",
      "Epoch 37::Minibatch 473::LR 0.0169230769231 --> Loss 0.0023150964578\n",
      "Epoch 37::Minibatch 474::LR 0.0169230769231 --> Loss 0.000684462885062\n",
      "Epoch 37::Minibatch 475::LR 0.0169230769231 --> Loss 0.00465126991272\n",
      "Epoch 37::Minibatch 476::LR 0.0169230769231 --> Loss 0.00752531210581\n",
      "Epoch 37::Minibatch 477::LR 0.0169230769231 --> Loss 0.000912512938182\n",
      "Epoch 37::Minibatch 478::LR 0.0169230769231 --> Loss 0.00239156226317\n",
      "Epoch 37::Minibatch 479::LR 0.0169230769231 --> Loss 0.00195069611073\n",
      "Epoch 37::Minibatch 480::LR 0.0169230769231 --> Loss 0.00150266597668\n",
      "Epoch 37::Minibatch 481::LR 0.0169230769231 --> Loss 0.000958340565364\n",
      "Epoch 37::Minibatch 482::LR 0.0169230769231 --> Loss 0.00205855369568\n",
      "Epoch 37::Minibatch 483::LR 0.0169230769231 --> Loss 0.00297952433427\n",
      "Epoch 37::Minibatch 484::LR 0.0169230769231 --> Loss 0.00333909392357\n",
      "Epoch 37::Minibatch 485::LR 0.0169230769231 --> Loss 0.000759084969759\n",
      "Epoch 37::Minibatch 486::LR 0.0169230769231 --> Loss 0.00281714002291\n",
      "Epoch 37::Minibatch 487::LR 0.0169230769231 --> Loss 0.0032762914896\n",
      "Epoch 37::Minibatch 488::LR 0.0169230769231 --> Loss 0.00200722893079\n",
      "Epoch 37::Minibatch 489::LR 0.0169230769231 --> Loss 0.00305999100208\n",
      "Epoch 37::Minibatch 490::LR 0.0169230769231 --> Loss 0.000412456591924\n",
      "Epoch 37::Minibatch 491::LR 0.0169230769231 --> Loss 0.00306723852952\n",
      "Epoch 37::Minibatch 492::LR 0.0169230769231 --> Loss 0.00306213835875\n",
      "Epoch 37::Minibatch 493::LR 0.0169230769231 --> Loss 0.00300626218319\n",
      "Epoch 37::Minibatch 494::LR 0.0169230769231 --> Loss 0.00072964400053\n",
      "Epoch 37::Minibatch 495::LR 0.0169230769231 --> Loss 0.00181573987007\n",
      "Epoch 37::Minibatch 496::LR 0.0169230769231 --> Loss 0.00277204712232\n",
      "Epoch 37::Minibatch 497::LR 0.0169230769231 --> Loss 0.000910086035728\n",
      "Epoch 37::Minibatch 498::LR 0.0169230769231 --> Loss 0.000546196103096\n",
      "Epoch 37::Minibatch 499::LR 0.0169230769231 --> Loss 0.00336552580198\n",
      "Epoch 37::Minibatch 500::LR 0.0169230769231 --> Loss 0.00142005592585\n",
      "Epoch 37::Minibatch 501::LR 0.0169230769231 --> Loss 0.00196933249633\n",
      "Epoch 37::Minibatch 502::LR 0.0169230769231 --> Loss 0.0037075817585\n",
      "Epoch 37::Minibatch 503::LR 0.0169230769231 --> Loss 0.00655554850896\n",
      "Epoch 37::Minibatch 504::LR 0.0169230769231 --> Loss 0.00646119594574\n",
      "Epoch 37::Minibatch 505::LR 0.0169230769231 --> Loss 0.00383913238843\n",
      "Epoch 37::Minibatch 506::LR 0.0169230769231 --> Loss 0.00325666546822\n",
      "Epoch 37::Minibatch 507::LR 0.0169230769231 --> Loss 0.00564110358556\n",
      "Epoch 37::Minibatch 508::LR 0.0169230769231 --> Loss 0.00337531765302\n",
      "Epoch 37::Minibatch 509::LR 0.0169230769231 --> Loss 0.00417111595472\n",
      "Epoch 37::Minibatch 510::LR 0.0169230769231 --> Loss 0.00434582591057\n",
      "Epoch 37::Minibatch 511::LR 0.0169230769231 --> Loss 0.00403468966484\n",
      "Epoch 37::Minibatch 512::LR 0.0169230769231 --> Loss 0.00268737733364\n",
      "Epoch 37::Minibatch 513::LR 0.0169230769231 --> Loss 0.000587911754847\n",
      "Epoch 37::Minibatch 514::LR 0.0169230769231 --> Loss 0.00256924966971\n",
      "Epoch 37::Minibatch 515::LR 0.0169230769231 --> Loss 0.00298540731271\n",
      "Epoch 37::Minibatch 516::LR 0.0169230769231 --> Loss 0.00389352520307\n",
      "Epoch 37::Minibatch 517::LR 0.0169230769231 --> Loss 0.00364834229151\n",
      "Epoch 37::Minibatch 518::LR 0.0169230769231 --> Loss 0.00256589233875\n",
      "Epoch 37::Minibatch 519::LR 0.0169230769231 --> Loss 0.00360312819481\n",
      "Epoch 37::Minibatch 520::LR 0.0169230769231 --> Loss 0.00568661053975\n",
      "Epoch 37::Minibatch 521::LR 0.0169230769231 --> Loss 0.00575967828433\n",
      "Epoch 37::Minibatch 522::LR 0.0169230769231 --> Loss 0.00684587001801\n",
      "Epoch 37::Minibatch 523::LR 0.0169230769231 --> Loss 0.000619190682968\n",
      "Epoch 37::Minibatch 524::LR 0.0169230769231 --> Loss 0.0013781846563\n",
      "Epoch 37::Minibatch 525::LR 0.0169230769231 --> Loss 0.0029937428236\n",
      "Epoch 37::Minibatch 526::LR 0.0169230769231 --> Loss 0.00362269242605\n",
      "Epoch 37::Minibatch 527::LR 0.0169230769231 --> Loss 0.0021051599582\n",
      "Epoch 37::Minibatch 528::LR 0.0169230769231 --> Loss 0.000904260973136\n",
      "Epoch 37::Minibatch 529::LR 0.0169230769231 --> Loss 0.0037332546711\n",
      "Epoch 37::Minibatch 530::LR 0.0169230769231 --> Loss 0.00368884603182\n",
      "Epoch 37::Minibatch 531::LR 0.0169230769231 --> Loss 0.00327429016431\n",
      "Epoch 37::Minibatch 532::LR 0.0169230769231 --> Loss 0.00255789120992\n",
      "Epoch 37::Minibatch 533::LR 0.0169230769231 --> Loss 0.00484388629595\n",
      "Epoch 37::Minibatch 534::LR 0.0169230769231 --> Loss 0.00365770339966\n",
      "Epoch 37::Minibatch 535::LR 0.0169230769231 --> Loss 0.0033468858401\n",
      "Epoch 37::Minibatch 536::LR 0.0169230769231 --> Loss 0.00210943818092\n",
      "Epoch 37::Minibatch 537::LR 0.0169230769231 --> Loss 0.000578067799409\n",
      "Epoch 37::Minibatch 538::LR 0.0169230769231 --> Loss 0.00161564896504\n",
      "Epoch 37::Minibatch 539::LR 0.0169230769231 --> Loss 0.00328049699465\n",
      "Epoch 37::Minibatch 540::LR 0.0169230769231 --> Loss 0.00336605111758\n",
      "Epoch 37::Minibatch 541::LR 0.0169230769231 --> Loss 0.00281994839509\n",
      "Epoch 37::Minibatch 542::LR 0.0169230769231 --> Loss 0.00241608222326\n",
      "Epoch 37::Minibatch 543::LR 0.0169230769231 --> Loss 0.00252341389656\n",
      "Epoch 37::Minibatch 544::LR 0.0169230769231 --> Loss 0.00410111109416\n",
      "Epoch 37::Minibatch 545::LR 0.0169230769231 --> Loss 0.00193839629491\n",
      "Epoch 37::Minibatch 546::LR 0.0169230769231 --> Loss 0.000662636309862\n",
      "Epoch 37::Minibatch 547::LR 0.0169230769231 --> Loss 0.00256452878316\n",
      "Epoch 37::Minibatch 548::LR 0.0169230769231 --> Loss 0.00333196123441\n",
      "Epoch 37::Minibatch 549::LR 0.0169230769231 --> Loss 0.00900051275889\n",
      "Epoch 37::Minibatch 550::LR 0.0169230769231 --> Loss 0.00118931591511\n",
      "Epoch 37::Minibatch 551::LR 0.0169230769231 --> Loss 0.00246473650138\n",
      "Epoch 37::Minibatch 552::LR 0.0169230769231 --> Loss 0.00341273903847\n",
      "Epoch 37::Minibatch 553::LR 0.0169230769231 --> Loss 0.0028886650006\n",
      "Epoch 37::Minibatch 554::LR 0.0169230769231 --> Loss 0.00355655392011\n",
      "Epoch 37::Minibatch 555::LR 0.0169230769231 --> Loss 0.000928239226341\n",
      "Epoch 37::Minibatch 556::LR 0.0169230769231 --> Loss 0.0018957122167\n",
      "Epoch 37::Minibatch 557::LR 0.0169230769231 --> Loss 0.00241259495417\n",
      "Epoch 37::Minibatch 558::LR 0.0169230769231 --> Loss 0.00355911056201\n",
      "Epoch 37::Minibatch 559::LR 0.0169230769231 --> Loss 0.00364117026329\n",
      "Epoch 37::Minibatch 560::LR 0.0169230769231 --> Loss 0.00305219431718\n",
      "Epoch 37::Minibatch 561::LR 0.0169230769231 --> Loss 0.00260793288549\n",
      "Epoch 37::Minibatch 562::LR 0.0169230769231 --> Loss 0.00232897341251\n",
      "Epoch 37::Minibatch 563::LR 0.0169230769231 --> Loss 0.00394330223401\n",
      "Epoch 37::Minibatch 564::LR 0.0169230769231 --> Loss 0.0030193477869\n",
      "Epoch 37::Minibatch 565::LR 0.0169230769231 --> Loss 0.00355846603711\n",
      "Epoch 37::Minibatch 566::LR 0.0169230769231 --> Loss 0.00214602351189\n",
      "Epoch 37::Minibatch 567::LR 0.0169230769231 --> Loss 0.00254482607047\n",
      "Epoch 37::Minibatch 568::LR 0.0169230769231 --> Loss 0.00170783996582\n",
      "Epoch 37::Minibatch 569::LR 0.0169230769231 --> Loss 0.000557196885347\n",
      "Epoch 37::Minibatch 570::LR 0.0169230769231 --> Loss 0.00159099876881\n",
      "Epoch 37::Minibatch 571::LR 0.0169230769231 --> Loss 0.00199220856031\n",
      "Epoch 37::Minibatch 572::LR 0.0169230769231 --> Loss 0.00215136090914\n",
      "Epoch 37::Minibatch 573::LR 0.0169230769231 --> Loss 0.00140753209591\n",
      "Epoch 37::Minibatch 574::LR 0.0169230769231 --> Loss 0.00103990127643\n",
      "Epoch 37::Minibatch 575::LR 0.0169230769231 --> Loss 0.00168631037076\n",
      "Epoch 37::Minibatch 576::LR 0.0169230769231 --> Loss 0.00200079381466\n",
      "Epoch 37::Minibatch 577::LR 0.0169230769231 --> Loss 0.00158193786939\n",
      "Epoch 37::Minibatch 578::LR 0.0169230769231 --> Loss 0.00124820788701\n",
      "Epoch 37::Minibatch 579::LR 0.0169230769231 --> Loss 0.00117175430059\n",
      "Epoch 37::Minibatch 580::LR 0.0169230769231 --> Loss 0.00190870861212\n",
      "Epoch 37::Minibatch 581::LR 0.0169230769231 --> Loss 0.00169622222582\n",
      "Epoch 37::Minibatch 582::LR 0.0169230769231 --> Loss 0.00421146154404\n",
      "Epoch 37::Minibatch 583::LR 0.0169230769231 --> Loss 0.000954253772895\n",
      "Epoch 37::Minibatch 584::LR 0.0169230769231 --> Loss 0.00131005694469\n",
      "Epoch 37::Minibatch 585::LR 0.0169230769231 --> Loss 0.00381675362587\n",
      "Epoch 37::Minibatch 586::LR 0.0169230769231 --> Loss 0.00365537166595\n",
      "Epoch 37::Minibatch 587::LR 0.0169230769231 --> Loss 0.0011041533947\n",
      "Epoch 37::Minibatch 588::LR 0.0169230769231 --> Loss 0.00135365645091\n",
      "Epoch 37::Minibatch 589::LR 0.0169230769231 --> Loss 0.00269547363122\n",
      "Epoch 37::Minibatch 590::LR 0.0169230769231 --> Loss 0.001749244531\n",
      "Epoch 37::Minibatch 591::LR 0.0169230769231 --> Loss 0.00259366472562\n",
      "Epoch 37::Minibatch 592::LR 0.0169230769231 --> Loss 0.00113715430101\n",
      "Epoch 37::Minibatch 593::LR 0.0169230769231 --> Loss 0.00241921087106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 594::LR 0.0169230769231 --> Loss 0.00247944533825\n",
      "Epoch 37::Minibatch 595::LR 0.0169230769231 --> Loss 0.00303046981494\n",
      "Epoch 37::Minibatch 596::LR 0.0169230769231 --> Loss 0.00179791172345\n",
      "Epoch 37::Minibatch 597::LR 0.0169230769231 --> Loss 0.00114969184001\n",
      "Epoch 37::Minibatch 598::LR 0.0169230769231 --> Loss 0.00273472627004\n",
      "Epoch 37::Minibatch 599::LR 0.0169230769231 --> Loss 0.00176426430543\n",
      "Epoch 37::Minibatch 600::LR 0.0169230769231 --> Loss 0.00208386480808\n",
      "Epoch 37::Minibatch 601::LR 0.0169230769231 --> Loss 0.00367051482201\n",
      "Epoch 37::Minibatch 602::LR 0.0169230769231 --> Loss 0.00206642905871\n",
      "Epoch 37::Minibatch 603::LR 0.0169230769231 --> Loss 0.00260599315166\n",
      "Epoch 37::Minibatch 604::LR 0.0169230769231 --> Loss 0.0016125630339\n",
      "Epoch 37::Minibatch 605::LR 0.0169230769231 --> Loss 0.00223848760128\n",
      "Epoch 37::Minibatch 606::LR 0.0169230769231 --> Loss 0.00181780854861\n",
      "Epoch 37::Minibatch 607::LR 0.0169230769231 --> Loss 0.00081546386083\n",
      "Epoch 37::Minibatch 608::LR 0.0169230769231 --> Loss 0.00153210719426\n",
      "Epoch 37::Minibatch 609::LR 0.0169230769231 --> Loss 0.00242123802503\n",
      "Epoch 37::Minibatch 610::LR 0.0169230769231 --> Loss 0.00405662933985\n",
      "Epoch 37::Minibatch 611::LR 0.0169230769231 --> Loss 0.00271276950836\n",
      "Epoch 37::Minibatch 612::LR 0.0169230769231 --> Loss 0.000467309057713\n",
      "Epoch 37::Minibatch 613::LR 0.0169230769231 --> Loss 0.00131181955338\n",
      "Epoch 37::Minibatch 614::LR 0.0169230769231 --> Loss 0.0023807434241\n",
      "Epoch 37::Minibatch 615::LR 0.0169230769231 --> Loss 0.00163470427195\n",
      "Epoch 37::Minibatch 616::LR 0.0169230769231 --> Loss 0.000909843146801\n",
      "Epoch 37::Minibatch 617::LR 0.0169230769231 --> Loss 0.0004894977808\n",
      "Epoch 37::Minibatch 618::LR 0.0169230769231 --> Loss 0.0029789964358\n",
      "Epoch 37::Minibatch 619::LR 0.0169230769231 --> Loss 0.00192583660285\n",
      "Epoch 37::Minibatch 620::LR 0.0169230769231 --> Loss 0.00167080720266\n",
      "Epoch 37::Minibatch 621::LR 0.0169230769231 --> Loss 0.000839715997378\n",
      "Epoch 37::Minibatch 622::LR 0.0169230769231 --> Loss 0.000773804485798\n",
      "Epoch 37::Minibatch 623::LR 0.0169230769231 --> Loss 0.00221138954163\n",
      "Epoch 37::Minibatch 624::LR 0.0169230769231 --> Loss 0.00175125320752\n",
      "Epoch 37::Minibatch 625::LR 0.0169230769231 --> Loss 0.00258521258831\n",
      "Epoch 37::Minibatch 626::LR 0.0169230769231 --> Loss 0.00336355487506\n",
      "Epoch 37::Minibatch 627::LR 0.0169230769231 --> Loss 0.00125594456991\n",
      "Epoch 37::Minibatch 628::LR 0.0169230769231 --> Loss 0.000871700147788\n",
      "Epoch 37::Minibatch 629::LR 0.0169230769231 --> Loss 0.00294670740763\n",
      "Epoch 37::Minibatch 630::LR 0.0169230769231 --> Loss 0.00289335926374\n",
      "Epoch 37::Minibatch 631::LR 0.0169230769231 --> Loss 0.00480844974518\n",
      "Epoch 37::Minibatch 632::LR 0.0169230769231 --> Loss 0.000797535677751\n",
      "Epoch 37::Minibatch 633::LR 0.0169230769231 --> Loss 0.00159632494052\n",
      "Epoch 37::Minibatch 634::LR 0.0169230769231 --> Loss 0.00314069588979\n",
      "Epoch 37::Minibatch 635::LR 0.0169230769231 --> Loss 0.0052666413784\n",
      "Epoch 37::Minibatch 636::LR 0.0169230769231 --> Loss 0.00442873517672\n",
      "Epoch 37::Minibatch 637::LR 0.0169230769231 --> Loss 0.000697941879431\n",
      "Epoch 37::Minibatch 638::LR 0.0169230769231 --> Loss 0.00148964802424\n",
      "Epoch 37::Minibatch 639::LR 0.0169230769231 --> Loss 0.00314425031344\n",
      "Epoch 37::Minibatch 640::LR 0.0169230769231 --> Loss 0.00438242236773\n",
      "Epoch 37::Minibatch 641::LR 0.0169230769231 --> Loss 0.00298888802528\n",
      "Epoch 37::Minibatch 642::LR 0.0169230769231 --> Loss 0.000533032566309\n",
      "Epoch 37::Minibatch 643::LR 0.0169230769231 --> Loss 0.00229554096858\n",
      "Epoch 37::Minibatch 644::LR 0.0169230769231 --> Loss 0.00381751020749\n",
      "Epoch 37::Minibatch 645::LR 0.0169230769231 --> Loss 0.00456009864807\n",
      "Epoch 37::Minibatch 646::LR 0.0169230769231 --> Loss 0.00151816229026\n",
      "Epoch 37::Minibatch 647::LR 0.0169230769231 --> Loss 0.000457869867484\n",
      "Epoch 37::Minibatch 648::LR 0.0169230769231 --> Loss 0.00267039895058\n",
      "Epoch 37::Minibatch 649::LR 0.0169230769231 --> Loss 0.00304747641087\n",
      "Epoch 37::Minibatch 650::LR 0.0169230769231 --> Loss 0.00305280188719\n",
      "Epoch 37::Minibatch 651::LR 0.0169230769231 --> Loss 0.00130539337794\n",
      "Epoch 37::Minibatch 652::LR 0.0169230769231 --> Loss 0.00077887242039\n",
      "Epoch 37::Minibatch 653::LR 0.0169230769231 --> Loss 0.00276855727037\n",
      "Epoch 37::Minibatch 654::LR 0.0169230769231 --> Loss 0.00308651645978\n",
      "Epoch 37::Minibatch 655::LR 0.0169230769231 --> Loss 0.00368352969488\n",
      "Epoch 37::Minibatch 656::LR 0.0169230769231 --> Loss 0.00075816621383\n",
      "Epoch 37::Minibatch 657::LR 0.0169230769231 --> Loss 0.00225706020991\n",
      "Epoch 37::Minibatch 658::LR 0.0169230769231 --> Loss 0.00433215300242\n",
      "Epoch 37::Minibatch 659::LR 0.0169230769231 --> Loss 0.00217184563478\n",
      "Epoch 37::Minibatch 660::LR 0.0169230769231 --> Loss 0.00264243404071\n",
      "Epoch 37::Minibatch 661::LR 0.0169230769231 --> Loss 0.00219233453274\n",
      "Epoch 37::Minibatch 662::LR 0.0169230769231 --> Loss 0.00178528368473\n",
      "Epoch 37::Minibatch 663::LR 0.0169230769231 --> Loss 0.00357882102331\n",
      "Epoch 37::Minibatch 664::LR 0.0169230769231 --> Loss 0.00302693506082\n",
      "Epoch 37::Minibatch 665::LR 0.0169230769231 --> Loss 0.000689831425746\n",
      "Epoch 37::Minibatch 666::LR 0.0169230769231 --> Loss 0.00389764388402\n",
      "Epoch 37::Minibatch 667::LR 0.0169230769231 --> Loss 0.00254554649194\n",
      "Epoch 37::Minibatch 668::LR 0.0169230769231 --> Loss 0.00608725190163\n",
      "Epoch 37::Minibatch 669::LR 0.0169230769231 --> Loss 0.0010741079847\n",
      "Epoch 37::Minibatch 670::LR 0.0169230769231 --> Loss 0.00131929288308\n",
      "Epoch 37::Minibatch 671::LR 0.0169230769231 --> Loss 0.00500035484632\n",
      "Epoch 37::Minibatch 672::LR 0.0169230769231 --> Loss 0.00326957146327\n",
      "Epoch 37::Minibatch 673::LR 0.0169230769231 --> Loss 0.00158858160178\n",
      "Epoch 37::Minibatch 674::LR 0.0169230769231 --> Loss 0.000510488251845\n",
      "Epoch 37::Minibatch 675::LR 0.0169230769231 --> Loss 0.00219917436441\n",
      "Epoch 37::Minibatch 676::LR 0.0169230769231 --> Loss 0.00217926859856\n",
      "Epoch 37::Minibatch 677::LR 0.0169230769231 --> Loss 0.00266643404961\n",
      "Epoch 37::Minibatch 678::LR 0.0169230769231 --> Loss 0.00184505303701\n",
      "Epoch 37::Minibatch 679::LR 0.0169230769231 --> Loss 0.00325804789861\n",
      "Epoch 37::Minibatch 680::LR 0.0169230769231 --> Loss 0.00211177448432\n",
      "Epoch 37::Minibatch 681::LR 0.0169230769231 --> Loss 0.00234877785047\n",
      "Epoch 37::Minibatch 682::LR 0.0169230769231 --> Loss 0.000761987368266\n",
      "Epoch 37::Minibatch 683::LR 0.0169230769231 --> Loss 0.00225974023342\n",
      "Epoch 37::Minibatch 684::LR 0.0169230769231 --> Loss 0.00234278003375\n",
      "Epoch 37::Minibatch 685::LR 0.0169230769231 --> Loss 0.00279053747654\n",
      "Epoch 37::Minibatch 686::LR 0.0169230769231 --> Loss 0.00157989144325\n",
      "Epoch 37::Minibatch 687::LR 0.0169230769231 --> Loss 0.000879670381546\n",
      "Epoch 37::Minibatch 688::LR 0.0169230769231 --> Loss 0.00281215031942\n",
      "Epoch 37::Minibatch 689::LR 0.0169230769231 --> Loss 0.0024472562472\n",
      "Epoch 37::Minibatch 690::LR 0.0169230769231 --> Loss 0.00185525675615\n",
      "Epoch 37::Minibatch 691::LR 0.0169230769231 --> Loss 0.000657390306393\n",
      "Epoch 37::Minibatch 692::LR 0.0169230769231 --> Loss 0.00243376513322\n",
      "Epoch 37::Minibatch 693::LR 0.0169230769231 --> Loss 0.00263504048189\n",
      "Epoch 37::Minibatch 694::LR 0.0169230769231 --> Loss 0.00297214627266\n",
      "Epoch 37::Minibatch 695::LR 0.0169230769231 --> Loss 0.00181918243567\n",
      "Epoch 37::Minibatch 696::LR 0.0169230769231 --> Loss 0.00201915343602\n",
      "Epoch 37::Minibatch 697::LR 0.0169230769231 --> Loss 0.00139613558849\n",
      "Epoch 37::Minibatch 698::LR 0.0169230769231 --> Loss 0.00166795591513\n",
      "Epoch 37::Minibatch 699::LR 0.0169230769231 --> Loss 0.00364615559578\n",
      "Epoch 37::Minibatch 700::LR 0.0169230769231 --> Loss 0.00252749522527\n",
      "Epoch 37::Minibatch 701::LR 0.0169230769231 --> Loss 0.00185376505057\n",
      "Epoch 37::Minibatch 702::LR 0.0169230769231 --> Loss 0.00167130132516\n",
      "Epoch 37::Minibatch 703::LR 0.0169230769231 --> Loss 0.00423860947291\n",
      "Epoch 37::Minibatch 704::LR 0.0169230769231 --> Loss 0.00180589477221\n",
      "Epoch 37::Minibatch 705::LR 0.0169230769231 --> Loss 0.00280707895756\n",
      "Epoch 37::Minibatch 706::LR 0.0169230769231 --> Loss 0.00217879354954\n",
      "Epoch 37::Minibatch 707::LR 0.0169230769231 --> Loss 0.00118402252595\n",
      "Epoch 37::Minibatch 708::LR 0.0169230769231 --> Loss 0.00173008064429\n",
      "Epoch 37::Minibatch 709::LR 0.0169230769231 --> Loss 0.001665409108\n",
      "Epoch 37::Minibatch 710::LR 0.0169230769231 --> Loss 0.00259131848812\n",
      "Epoch 37::Minibatch 711::LR 0.0169230769231 --> Loss 0.00199557761351\n",
      "Epoch 37::Minibatch 712::LR 0.0169230769231 --> Loss 0.00138206293186\n",
      "Epoch 37::Minibatch 713::LR 0.0169230769231 --> Loss 0.00181334217389\n",
      "Epoch 37::Minibatch 714::LR 0.0169230769231 --> Loss 0.00289568424225\n",
      "Epoch 37::Minibatch 715::LR 0.0169230769231 --> Loss 0.00290722727776\n",
      "Epoch 37::Minibatch 716::LR 0.0169230769231 --> Loss 0.00167960504691\n",
      "Epoch 37::Minibatch 717::LR 0.0169230769231 --> Loss 0.00168659130732\n",
      "Epoch 37::Minibatch 718::LR 0.0169230769231 --> Loss 0.00129274090131\n",
      "Epoch 37::Minibatch 719::LR 0.0169230769231 --> Loss 0.00174765884876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 720::LR 0.0169230769231 --> Loss 0.00283322473367\n",
      "Epoch 37::Minibatch 721::LR 0.0169230769231 --> Loss 0.000605637580156\n",
      "Epoch 37::Minibatch 722::LR 0.0169230769231 --> Loss 0.00451461116473\n",
      "Epoch 37::Minibatch 723::LR 0.0169230769231 --> Loss 0.00476157824198\n",
      "Epoch 37::Minibatch 724::LR 0.0169230769231 --> Loss 0.000965042412281\n",
      "Epoch 37::Minibatch 725::LR 0.0169230769231 --> Loss 0.00201339900494\n",
      "Epoch 37::Minibatch 726::LR 0.0169230769231 --> Loss 0.00335828065872\n",
      "Epoch 37::Minibatch 727::LR 0.0169230769231 --> Loss 0.0029289962848\n",
      "Epoch 37::Minibatch 728::LR 0.0169230769231 --> Loss 0.000641879638036\n",
      "Epoch 37::Minibatch 729::LR 0.0169230769231 --> Loss 0.000712218781312\n",
      "Epoch 37::Minibatch 730::LR 0.0169230769231 --> Loss 0.0028815672795\n",
      "Epoch 37::Minibatch 731::LR 0.0169230769231 --> Loss 0.00263176143169\n",
      "Epoch 37::Minibatch 732::LR 0.0169230769231 --> Loss 0.00198235988617\n",
      "Epoch 37::Minibatch 733::LR 0.0169230769231 --> Loss 0.000573467264573\n",
      "Epoch 37::Minibatch 734::LR 0.0169230769231 --> Loss 0.0016158759594\n",
      "Epoch 37::Minibatch 735::LR 0.0169230769231 --> Loss 0.00252522269885\n",
      "Epoch 37::Minibatch 736::LR 0.0169230769231 --> Loss 0.00347202221553\n",
      "Epoch 37::Minibatch 737::LR 0.0169230769231 --> Loss 0.00284796953201\n",
      "Epoch 37::Minibatch 738::LR 0.0169230769231 --> Loss 0.00130290438732\n",
      "Epoch 37::Minibatch 739::LR 0.0169230769231 --> Loss 0.0023121569554\n",
      "Epoch 37::Minibatch 740::LR 0.0169230769231 --> Loss 0.00372498313586\n",
      "Epoch 37::Minibatch 741::LR 0.0169230769231 --> Loss 0.00248246590296\n",
      "Epoch 37::Minibatch 742::LR 0.0169230769231 --> Loss 0.0020508491993\n",
      "Epoch 37::Minibatch 743::LR 0.0169230769231 --> Loss 0.00151926676432\n",
      "Epoch 37::Minibatch 744::LR 0.0169230769231 --> Loss 0.00189583003521\n",
      "Epoch 37::Minibatch 745::LR 0.0169230769231 --> Loss 0.00275166968505\n",
      "Epoch 37::Minibatch 746::LR 0.0169230769231 --> Loss 0.00279912134012\n",
      "Epoch 37::Minibatch 747::LR 0.0169230769231 --> Loss 0.00174118439356\n",
      "Epoch 37::Minibatch 748::LR 0.0169230769231 --> Loss 0.000623499602079\n",
      "Epoch 37::Minibatch 749::LR 0.0169230769231 --> Loss 0.00168659130732\n",
      "Epoch 37::Minibatch 750::LR 0.0169230769231 --> Loss 0.00240193982919\n",
      "Epoch 37::Minibatch 751::LR 0.0169230769231 --> Loss 0.00299125949542\n",
      "Epoch 37::Minibatch 752::LR 0.0169230769231 --> Loss 0.00153132339319\n",
      "Epoch 37::Minibatch 753::LR 0.0169230769231 --> Loss 0.00219760894775\n",
      "Epoch 37::Minibatch 754::LR 0.0169230769231 --> Loss 0.00243156234423\n",
      "Epoch 37::Minibatch 755::LR 0.0169230769231 --> Loss 0.00265022615592\n",
      "Epoch 37::Minibatch 756::LR 0.0169230769231 --> Loss 0.00128295014302\n",
      "Epoch 37::Minibatch 757::LR 0.0169230769231 --> Loss 0.000557504196962\n",
      "Epoch 37::Minibatch 758::LR 0.0169230769231 --> Loss 0.0015605528156\n",
      "Epoch 37::Minibatch 759::LR 0.0169230769231 --> Loss 0.00327079534531\n",
      "Epoch 37::Minibatch 760::LR 0.0169230769231 --> Loss 0.00273052692413\n",
      "Epoch 37::Minibatch 761::LR 0.0169230769231 --> Loss 0.00528262734413\n",
      "Epoch 37::Minibatch 762::LR 0.0169230769231 --> Loss 0.00345074415207\n",
      "Epoch 37::Minibatch 763::LR 0.0169230769231 --> Loss 0.00336377263069\n",
      "Epoch 37::Minibatch 764::LR 0.0169230769231 --> Loss 0.0029698830843\n",
      "Epoch 37::Minibatch 765::LR 0.0169230769231 --> Loss 0.0012228851517\n",
      "Epoch 37::Minibatch 766::LR 0.0169230769231 --> Loss 0.00229300240676\n",
      "Epoch 37::Minibatch 767::LR 0.0169230769231 --> Loss 0.00467578252157\n",
      "Epoch 37::Minibatch 768::LR 0.0169230769231 --> Loss 0.00359927733739\n",
      "Epoch 37::Minibatch 769::LR 0.0169230769231 --> Loss 0.00181007027626\n",
      "Epoch 37::Minibatch 770::LR 0.0169230769231 --> Loss 0.00151134769122\n",
      "Epoch 37::Minibatch 771::LR 0.0169230769231 --> Loss 0.00329757948716\n",
      "Epoch 37::Minibatch 772::LR 0.0169230769231 --> Loss 0.00365649660428\n",
      "Epoch 37::Minibatch 773::LR 0.0169230769231 --> Loss 0.00319206555684\n",
      "Epoch 37::Minibatch 774::LR 0.0169230769231 --> Loss 0.00190644145012\n",
      "Epoch 37::Minibatch 775::LR 0.0169230769231 --> Loss 0.00314052641392\n",
      "Epoch 37::Minibatch 776::LR 0.0169230769231 --> Loss 0.00390386819839\n",
      "Epoch 37::Minibatch 777::LR 0.0169230769231 --> Loss 0.00573335210482\n",
      "Epoch 37::Minibatch 778::LR 0.0169230769231 --> Loss 0.00663082520167\n",
      "Epoch 37::Minibatch 779::LR 0.0169230769231 --> Loss 0.00248557329178\n",
      "Epoch 37::Minibatch 780::LR 0.0169230769231 --> Loss 0.00147741069396\n",
      "Epoch 37::Minibatch 781::LR 0.0169230769231 --> Loss 0.00349446932475\n",
      "Epoch 37::Minibatch 782::LR 0.0169230769231 --> Loss 0.00384100079536\n",
      "Epoch 37::Minibatch 783::LR 0.0169230769231 --> Loss 0.00225967764854\n",
      "Epoch 37::Minibatch 784::LR 0.0169230769231 --> Loss 0.000712354133526\n",
      "Epoch 37::Minibatch 785::LR 0.0169230769231 --> Loss 0.00351520339648\n",
      "Epoch 37::Minibatch 786::LR 0.0169230769231 --> Loss 0.00368019104004\n",
      "Epoch 37::Minibatch 787::LR 0.0169230769231 --> Loss 0.00257018327713\n",
      "Epoch 37::Minibatch 788::LR 0.0169230769231 --> Loss 0.00246415456136\n",
      "Epoch 37::Minibatch 789::LR 0.0169230769231 --> Loss 0.000722647557656\n",
      "Epoch 37::Minibatch 790::LR 0.0169230769231 --> Loss 0.00317429900169\n",
      "Epoch 37::Minibatch 791::LR 0.0169230769231 --> Loss 0.0032059242328\n",
      "Epoch 37::Minibatch 792::LR 0.0169230769231 --> Loss 0.00299087802569\n",
      "Epoch 37::Minibatch 793::LR 0.0169230769231 --> Loss 0.00162177532911\n",
      "Epoch 37::Minibatch 794::LR 0.0169230769231 --> Loss 0.00098219136397\n",
      "Epoch 37::Minibatch 795::LR 0.0169230769231 --> Loss 0.00258777161439\n",
      "Epoch 37::Minibatch 796::LR 0.0169230769231 --> Loss 0.00464420437813\n",
      "Epoch 37::Minibatch 797::LR 0.0169230769231 --> Loss 0.00548197905223\n",
      "Epoch 37::Minibatch 798::LR 0.0169230769231 --> Loss 0.00293522636096\n",
      "Epoch 37::Minibatch 799::LR 0.0169230769231 --> Loss 0.00223513066769\n",
      "Epoch 37::Minibatch 800::LR 0.0169230769231 --> Loss 0.00199748973052\n",
      "Epoch 37::Minibatch 801::LR 0.0169230769231 --> Loss 0.00374377409617\n",
      "Epoch 37::Minibatch 802::LR 0.0169230769231 --> Loss 0.00117857893308\n",
      "Epoch 37::Minibatch 803::LR 0.0169230769231 --> Loss 0.00296673576037\n",
      "Epoch 37::Minibatch 804::LR 0.0169230769231 --> Loss 0.0020544197162\n",
      "Epoch 37::Minibatch 805::LR 0.0169230769231 --> Loss 0.00217055380344\n",
      "Epoch 37::Minibatch 806::LR 0.0169230769231 --> Loss 0.00326155006886\n",
      "Epoch 37::Minibatch 807::LR 0.0169230769231 --> Loss 0.00305732667446\n",
      "Epoch 37::Minibatch 808::LR 0.0169230769231 --> Loss 0.00287772019704\n",
      "Epoch 37::Minibatch 809::LR 0.0169230769231 --> Loss 0.00294221957525\n",
      "Epoch 37::Minibatch 810::LR 0.0169230769231 --> Loss 0.00399386048317\n",
      "Epoch 37::Minibatch 811::LR 0.0169230769231 --> Loss 0.00384172280629\n",
      "Epoch 37::Minibatch 812::LR 0.0169230769231 --> Loss 0.00355217297872\n",
      "Epoch 37::Minibatch 813::LR 0.0169230769231 --> Loss 0.00291883369287\n",
      "Epoch 37::Minibatch 814::LR 0.0169230769231 --> Loss 0.00149718523026\n",
      "Epoch 37::Minibatch 815::LR 0.0169230769231 --> Loss 0.00342507362366\n",
      "Epoch 37::Minibatch 816::LR 0.0169230769231 --> Loss 0.00388132015864\n",
      "Epoch 37::Minibatch 817::LR 0.0169230769231 --> Loss 0.00455307245255\n",
      "Epoch 37::Minibatch 818::LR 0.0169230769231 --> Loss 0.00123016178608\n",
      "Epoch 37::Minibatch 819::LR 0.0169230769231 --> Loss 0.000731113354365\n",
      "Epoch 37::Minibatch 820::LR 0.0169230769231 --> Loss 0.00497431755066\n",
      "Epoch 37::Minibatch 821::LR 0.0169230769231 --> Loss 0.00306583185991\n",
      "Epoch 37::Minibatch 822::LR 0.0169230769231 --> Loss 0.00367320577304\n",
      "Epoch 37::Minibatch 823::LR 0.0169230769231 --> Loss 0.00124883602063\n",
      "Epoch 37::Minibatch 824::LR 0.0169230769231 --> Loss 0.00137069811424\n",
      "Epoch 37::Minibatch 825::LR 0.0169230769231 --> Loss 0.00378156661987\n",
      "Epoch 37::Minibatch 826::LR 0.0169230769231 --> Loss 0.00448262015978\n",
      "Epoch 37::Minibatch 827::LR 0.0169230769231 --> Loss 0.00205480337143\n",
      "Epoch 37::Minibatch 828::LR 0.0169230769231 --> Loss 0.00048600807786\n",
      "Epoch 37::Minibatch 829::LR 0.0169230769231 --> Loss 0.00225727657477\n",
      "Epoch 37::Minibatch 830::LR 0.0169230769231 --> Loss 0.00388748606046\n",
      "Epoch 37::Minibatch 831::LR 0.0169230769231 --> Loss 0.00233654598395\n",
      "Epoch 37::Minibatch 832::LR 0.0169230769231 --> Loss 0.00206318020821\n",
      "Epoch 37::Minibatch 833::LR 0.0169230769231 --> Loss 0.00179960807165\n",
      "Epoch 37::Minibatch 834::LR 0.0169230769231 --> Loss 0.000792029251655\n",
      "Epoch 37::Minibatch 835::LR 0.0169230769231 --> Loss 0.00383916576703\n",
      "Epoch 37::Minibatch 836::LR 0.0169230769231 --> Loss 0.00356534083684\n",
      "Epoch 37::Minibatch 837::LR 0.0169230769231 --> Loss 0.00227548062801\n",
      "Epoch 37::Minibatch 838::LR 0.0169230769231 --> Loss 0.000650653342406\n",
      "Epoch 37::Minibatch 839::LR 0.0169230769231 --> Loss 0.00233889857928\n",
      "Epoch 37::Minibatch 840::LR 0.0169230769231 --> Loss 0.00284147163232\n",
      "Epoch 37::Minibatch 841::LR 0.0169230769231 --> Loss 0.00274569372336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 842::LR 0.0169230769231 --> Loss 0.00210822145144\n",
      "Epoch 37::Minibatch 843::LR 0.0169230769231 --> Loss 0.000964984794458\n",
      "Epoch 37::Minibatch 844::LR 0.0169230769231 --> Loss 0.00146189630032\n",
      "Epoch 37::Minibatch 845::LR 0.0169230769231 --> Loss 0.00392681280772\n",
      "Epoch 37::Minibatch 846::LR 0.0169230769231 --> Loss 0.00167079548041\n",
      "Epoch 37::Minibatch 847::LR 0.0169230769231 --> Loss 0.00238714456558\n",
      "Epoch 37::Minibatch 848::LR 0.0169230769231 --> Loss 0.00115364919106\n",
      "Epoch 37::Minibatch 849::LR 0.0169230769231 --> Loss 0.00178568303585\n",
      "Epoch 37::Minibatch 850::LR 0.0169230769231 --> Loss 0.00315990388393\n",
      "Epoch 37::Minibatch 851::LR 0.0169230769231 --> Loss 0.00251859347026\n",
      "Epoch 37::Minibatch 852::LR 0.0169230769231 --> Loss 0.00114785601695\n",
      "Epoch 37::Minibatch 853::LR 0.0169230769231 --> Loss 0.00130671670039\n",
      "Epoch 37::Minibatch 854::LR 0.0169230769231 --> Loss 0.00251549899578\n",
      "Epoch 37::Minibatch 855::LR 0.0169230769231 --> Loss 0.0020957159996\n",
      "Epoch 37::Minibatch 856::LR 0.0169230769231 --> Loss 0.00177208721638\n",
      "Epoch 37::Minibatch 857::LR 0.0169230769231 --> Loss 0.00120525191228\n",
      "Epoch 37::Minibatch 858::LR 0.0169230769231 --> Loss 0.000603979974985\n",
      "Epoch 37::Minibatch 859::LR 0.0169230769231 --> Loss 0.00199751873811\n",
      "Epoch 37::Minibatch 860::LR 0.0169230769231 --> Loss 0.00131037900845\n",
      "Epoch 37::Minibatch 861::LR 0.0169230769231 --> Loss 0.000948466161887\n",
      "Epoch 37::Minibatch 862::LR 0.0169230769231 --> Loss 0.00372887253761\n",
      "Epoch 37::Minibatch 863::LR 0.0169230769231 --> Loss 0.00335008144379\n",
      "Epoch 37::Minibatch 864::LR 0.0169230769231 --> Loss 0.00258230805397\n",
      "Epoch 37::Minibatch 865::LR 0.0169230769231 --> Loss 0.000539209594329\n",
      "Epoch 37::Minibatch 866::LR 0.0169230769231 --> Loss 0.00206188003222\n",
      "Epoch 37::Minibatch 867::LR 0.0169230769231 --> Loss 0.00285416265329\n",
      "Epoch 37::Minibatch 868::LR 0.0169230769231 --> Loss 0.00244346121947\n",
      "Epoch 37::Minibatch 869::LR 0.0169230769231 --> Loss 0.00214396973451\n",
      "Epoch 37::Minibatch 870::LR 0.0169230769231 --> Loss 0.00317458073298\n",
      "Epoch 37::Minibatch 871::LR 0.0169230769231 --> Loss 0.00164867182573\n",
      "Epoch 37::Minibatch 872::LR 0.0169230769231 --> Loss 0.00207979400953\n",
      "Epoch 37::Minibatch 873::LR 0.0169230769231 --> Loss 0.00246137340864\n",
      "Epoch 37::Minibatch 874::LR 0.0169230769231 --> Loss 0.00487629334132\n",
      "Epoch 37::Minibatch 875::LR 0.0169230769231 --> Loss 0.000669413705667\n",
      "Epoch 37::Minibatch 876::LR 0.0169230769231 --> Loss 0.00263456583023\n",
      "Epoch 37::Minibatch 877::LR 0.0169230769231 --> Loss 0.00419974446297\n",
      "Epoch 37::Minibatch 878::LR 0.0169230769231 --> Loss 0.00283145288626\n",
      "Epoch 37::Minibatch 879::LR 0.0169230769231 --> Loss 0.00385013500849\n",
      "Epoch 37::Minibatch 880::LR 0.0169230769231 --> Loss 0.00486982186635\n",
      "Epoch 37::Minibatch 881::LR 0.0169230769231 --> Loss 0.00412529150645\n",
      "Epoch 37::Minibatch 882::LR 0.0169230769231 --> Loss 0.00188202341398\n",
      "Epoch 37::Minibatch 883::LR 0.0169230769231 --> Loss 0.00365086754163\n",
      "Epoch 37::Minibatch 884::LR 0.0169230769231 --> Loss 0.00281423807144\n",
      "Epoch 37::Minibatch 885::LR 0.0169230769231 --> Loss 0.00258738497893\n",
      "Epoch 37::Minibatch 886::LR 0.0169230769231 --> Loss 0.000440492083629\n",
      "Epoch 37::Minibatch 887::LR 0.0169230769231 --> Loss 0.00560358166695\n",
      "Epoch 37::Minibatch 888::LR 0.0169230769231 --> Loss 0.00241127888362\n",
      "Epoch 37::Minibatch 889::LR 0.0169230769231 --> Loss 0.00246857444445\n",
      "Epoch 37::Minibatch 890::LR 0.0169230769231 --> Loss 0.0035450275739\n",
      "Epoch 37::Minibatch 891::LR 0.0169230769231 --> Loss 0.00168476859728\n",
      "Epoch 37::Minibatch 892::LR 0.0169230769231 --> Loss 0.000778577774763\n",
      "Epoch 37::Minibatch 893::LR 0.0169230769231 --> Loss 0.00221672574679\n",
      "Epoch 37::Minibatch 894::LR 0.0169230769231 --> Loss 0.00194096088409\n",
      "Epoch 37::Minibatch 895::LR 0.0169230769231 --> Loss 0.00224427322547\n",
      "Epoch 37::Minibatch 896::LR 0.0169230769231 --> Loss 0.00125677118699\n",
      "Epoch 37::Minibatch 897::LR 0.0169230769231 --> Loss 0.000663733333349\n",
      "Epoch 37::Minibatch 898::LR 0.0169230769231 --> Loss 0.00193002700806\n",
      "Epoch 37::Minibatch 899::LR 0.0169230769231 --> Loss 0.00243721425533\n",
      "Epoch 37::Minibatch 900::LR 0.0169230769231 --> Loss 0.00299320379893\n",
      "Epoch 37::Minibatch 901::LR 0.0169230769231 --> Loss 0.000583732227484\n",
      "Epoch 37::Minibatch 902::LR 0.0169230769231 --> Loss 0.00138601581256\n",
      "Epoch 37::Minibatch 903::LR 0.0169230769231 --> Loss 0.00255487561226\n",
      "Epoch 37::Minibatch 904::LR 0.0169230769231 --> Loss 0.00179567376773\n",
      "Epoch 37::Minibatch 905::LR 0.0169230769231 --> Loss 0.00138588140408\n",
      "Epoch 37::Minibatch 906::LR 0.0169230769231 --> Loss 0.00101163228353\n",
      "Epoch 37::Minibatch 907::LR 0.0169230769231 --> Loss 0.00153628190358\n",
      "Epoch 37::Minibatch 908::LR 0.0169230769231 --> Loss 0.00206629991531\n",
      "Epoch 37::Minibatch 909::LR 0.0169230769231 --> Loss 0.00192589064439\n",
      "Epoch 37::Minibatch 910::LR 0.0169230769231 --> Loss 0.000840212702751\n",
      "Epoch 37::Minibatch 911::LR 0.0169230769231 --> Loss 0.00127953052521\n",
      "Epoch 37::Minibatch 912::LR 0.0169230769231 --> Loss 0.00207867642244\n",
      "Epoch 37::Minibatch 913::LR 0.0169230769231 --> Loss 0.00231944362322\n",
      "Epoch 37::Minibatch 914::LR 0.0169230769231 --> Loss 0.00127910166979\n",
      "Epoch 37::Minibatch 915::LR 0.0169230769231 --> Loss 0.000543069491784\n",
      "Epoch 37::Minibatch 916::LR 0.0169230769231 --> Loss 0.00196127951145\n",
      "Epoch 37::Minibatch 917::LR 0.0169230769231 --> Loss 0.00309025088946\n",
      "Epoch 37::Minibatch 918::LR 0.0169230769231 --> Loss 0.00416238109271\n",
      "Epoch 37::Minibatch 919::LR 0.0169230769231 --> Loss 0.00055888881286\n",
      "Epoch 37::Minibatch 920::LR 0.0169230769231 --> Loss 0.0113169829051\n",
      "Epoch 37::Minibatch 921::LR 0.0169230769231 --> Loss 0.00303258220355\n",
      "Epoch 37::Minibatch 922::LR 0.0169230769231 --> Loss 0.00301768799623\n",
      "Epoch 37::Minibatch 923::LR 0.0169230769231 --> Loss 0.00110656172037\n",
      "Epoch 37::Minibatch 924::LR 0.0169230769231 --> Loss 0.00314524451892\n",
      "Epoch 37::Minibatch 925::LR 0.0169230769231 --> Loss 0.00222238222758\n",
      "Epoch 37::Minibatch 926::LR 0.0169230769231 --> Loss 0.00432695110639\n",
      "Epoch 37::Minibatch 927::LR 0.0169230769231 --> Loss 0.00464095989863\n",
      "Epoch 37::Minibatch 928::LR 0.0169230769231 --> Loss 0.00582128683726\n",
      "Epoch 37::Minibatch 929::LR 0.0169230769231 --> Loss 0.00492481072744\n",
      "Epoch 37::Minibatch 930::LR 0.0169230769231 --> Loss 0.00924452066422\n",
      "Epoch 37::Minibatch 931::LR 0.0169230769231 --> Loss 0.00294110854467\n",
      "Epoch 37::Minibatch 932::LR 0.0169230769231 --> Loss 0.00498545328776\n",
      "Epoch 37::Minibatch 933::LR 0.0169230769231 --> Loss 0.00223308304946\n",
      "Epoch 37::Minibatch 934::LR 0.0169230769231 --> Loss 0.00276292602221\n",
      "Epoch 37::Minibatch 935::LR 0.0169230769231 --> Loss 0.00418535788854\n",
      "Epoch 37::Minibatch 936::LR 0.0169230769231 --> Loss 0.000757912049691\n",
      "Epoch 37::Minibatch 937::LR 0.0169230769231 --> Loss 0.00218780060609\n",
      "Epoch 37::Minibatch 938::LR 0.0169230769231 --> Loss 0.0018333063523\n",
      "Epoch 37::Minibatch 939::LR 0.0169230769231 --> Loss 0.00204388380051\n",
      "Epoch 37::Minibatch 940::LR 0.0169230769231 --> Loss 0.000903282364209\n",
      "Epoch 37::Minibatch 941::LR 0.0169230769231 --> Loss 0.00072631880641\n",
      "Epoch 37::Minibatch 942::LR 0.0169230769231 --> Loss 0.0025368587176\n",
      "Epoch 37::Minibatch 943::LR 0.0169230769231 --> Loss 0.0022455283006\n",
      "Epoch 37::Minibatch 944::LR 0.0169230769231 --> Loss 0.00159764488538\n",
      "Epoch 37::Minibatch 945::LR 0.0169230769231 --> Loss 0.00086723357439\n",
      "Epoch 37::Minibatch 946::LR 0.0169230769231 --> Loss 0.00225471417109\n",
      "Epoch 37::Minibatch 947::LR 0.0169230769231 --> Loss 0.00212150216103\n",
      "Epoch 37::Minibatch 948::LR 0.0169230769231 --> Loss 0.00374680280685\n",
      "Epoch 37::Minibatch 949::LR 0.0169230769231 --> Loss 0.00167428652445\n",
      "Epoch 37::Minibatch 950::LR 0.0169230769231 --> Loss 0.000676601181428\n",
      "Epoch 37::Minibatch 951::LR 0.0169230769231 --> Loss 0.00332744459311\n",
      "Epoch 37::Minibatch 952::LR 0.0169230769231 --> Loss 0.00231269220511\n",
      "Epoch 37::Minibatch 953::LR 0.0169230769231 --> Loss 0.0014143371582\n",
      "Epoch 37::Minibatch 954::LR 0.0169230769231 --> Loss 0.000923300186793\n",
      "Epoch 37::Minibatch 955::LR 0.0169230769231 --> Loss 0.00256159623464\n",
      "Epoch 37::Minibatch 956::LR 0.0169230769231 --> Loss 0.00297207673391\n",
      "Epoch 37::Minibatch 957::LR 0.0169230769231 --> Loss 0.00182684878508\n",
      "Epoch 37::Minibatch 958::LR 0.0169230769231 --> Loss 0.00217492719491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37::Minibatch 959::LR 0.0169230769231 --> Loss 0.00245424171289\n",
      "Epoch 37::Minibatch 960::LR 0.0169230769231 --> Loss 0.00518511851629\n",
      "Epoch 37::Minibatch 961::LR 0.0169230769231 --> Loss 0.00285122096539\n",
      "Epoch 37::Minibatch 962::LR 0.0169230769231 --> Loss 0.00218896786372\n",
      "Epoch 37::Minibatch 963::LR 0.0169230769231 --> Loss 0.00102818121513\n",
      "Epoch 37::Minibatch 964::LR 0.0169230769231 --> Loss 0.00229537367821\n",
      "Epoch 37::Minibatch 965::LR 0.0169230769231 --> Loss 0.00616538405418\n",
      "Epoch 37::Minibatch 966::LR 0.0169230769231 --> Loss 0.00484770933787\n",
      "Epoch 37::Minibatch 967::LR 0.0169230769231 --> Loss 0.00120910475651\n",
      "Epoch 37::Minibatch 968::LR 0.0169230769231 --> Loss 0.00094257603089\n",
      "Epoch 37::Minibatch 969::LR 0.0169230769231 --> Loss 0.00412386616071\n",
      "Epoch 37::Minibatch 970::LR 0.0169230769231 --> Loss 0.00394017100334\n",
      "Epoch 37::Minibatch 971::LR 0.0169230769231 --> Loss 0.00315697630246\n",
      "Epoch 37::Minibatch 972::LR 0.0169230769231 --> Loss 0.00683315992355\n",
      "Epoch 37::Minibatch 973::LR 0.0169230769231 --> Loss 0.0092133752505\n",
      "Epoch 37::Minibatch 974::LR 0.0169230769231 --> Loss 0.00774173418681\n",
      "Epoch 37::Minibatch 975::LR 0.0169230769231 --> Loss 0.00519573291143\n",
      "Epoch 37::Minibatch 976::LR 0.0169230769231 --> Loss 0.00351248780886\n",
      "Epoch 37::Minibatch 977::LR 0.0169230769231 --> Loss 0.00312083880107\n",
      "Epoch 37::Minibatch 978::LR 0.0169230769231 --> Loss 0.00300442457199\n",
      "Epoch 37::Minibatch 979::LR 0.0169230769231 --> Loss 0.00275595744451\n",
      "Epoch 37::Minibatch 980::LR 0.0169230769231 --> Loss 0.00319187204043\n",
      "Epoch 37::Minibatch 981::LR 0.0169230769231 --> Loss 0.00379516561826\n",
      "Epoch 37::Minibatch 982::LR 0.0169230769231 --> Loss 0.00347165266673\n",
      "Epoch 37::Minibatch 983::LR 0.0169230769231 --> Loss 0.00222666064898\n",
      "Epoch 37::Minibatch 984::LR 0.0169230769231 --> Loss 0.0014701239268\n",
      "Epoch 37::Minibatch 985::LR 0.0169230769231 --> Loss 0.00282118678093\n",
      "Epoch 37::Minibatch 986::LR 0.0169230769231 --> Loss 0.00252516150475\n",
      "Epoch 37::Minibatch 987::LR 0.0169230769231 --> Loss 0.00293322821458\n",
      "Epoch 37::Minibatch 988::LR 0.0169230769231 --> Loss 0.00225291013718\n",
      "Epoch 37::Minibatch 989::LR 0.0169230769231 --> Loss 0.00261278271675\n",
      "Epoch 37::Minibatch 990::LR 0.0169230769231 --> Loss 0.00252749125163\n",
      "Epoch 37::Minibatch 991::LR 0.0169230769231 --> Loss 0.0012077570955\n",
      "Epoch 37::Minibatch 992::LR 0.0169230769231 --> Loss 0.00150322109461\n",
      "Epoch 37::Minibatch 993::LR 0.0169230769231 --> Loss 0.00274147689342\n",
      "Epoch 37::Minibatch 994::LR 0.0169230769231 --> Loss 0.00184065322081\n",
      "Epoch 37::Minibatch 995::LR 0.0169230769231 --> Loss 0.00074428871274\n",
      "Epoch 37::Minibatch 996::LR 0.0169230769231 --> Loss 0.00248036007086\n",
      "Epoch 37::Minibatch 997::LR 0.0169230769231 --> Loss 0.00211661497752\n",
      "Epoch 37::Minibatch 998::LR 0.0169230769231 --> Loss 0.00240402003129\n",
      "Epoch 37::Minibatch 999::LR 0.0169230769231 --> Loss 0.00207179983457\n",
      "Epoch 37::Minibatch 1000::LR 0.0169230769231 --> Loss 0.00255489091078\n",
      "Epoch 37::Minibatch 1001::LR 0.0169230769231 --> Loss 0.00201491216818\n",
      "Epoch 37::Minibatch 1002::LR 0.0169230769231 --> Loss 0.00138026565313\n",
      "Epoch 37::Minibatch 1003::LR 0.0169230769231 --> Loss 0.00224841634432\n",
      "Epoch 37::Minibatch 1004::LR 0.0169230769231 --> Loss 0.00105423102776\n",
      "Epoch 37::Minibatch 1005::LR 0.0169230769231 --> Loss 0.00249226907889\n",
      "Epoch 37::Minibatch 1006::LR 0.0169230769231 --> Loss 0.00121158063412\n",
      "Epoch 37::Minibatch 1007::LR 0.0169230769231 --> Loss 0.00163529515266\n",
      "Epoch 37::Minibatch 1008::LR 0.0169230769231 --> Loss 0.000905823707581\n",
      "Epoch 37::Minibatch 1009::LR 0.0169230769231 --> Loss 0.00118638753891\n",
      "Epoch 37::Minibatch 1010::LR 0.0169230769231 --> Loss 0.00114973614613\n",
      "Epoch 37::Minibatch 1011::LR 0.0169230769231 --> Loss 0.00149573494991\n",
      "Epoch 37::Minibatch 1012::LR 0.0169230769231 --> Loss 0.00131562054157\n",
      "Epoch 37::Minibatch 1013::LR 0.0169230769231 --> Loss 0.0032637099425\n",
      "Epoch 37::Minibatch 1014::LR 0.0169230769231 --> Loss 0.00302657286326\n",
      "Epoch 37::Minibatch 1015::LR 0.0169230769231 --> Loss 0.0014967940251\n",
      "Epoch 37::Minibatch 1016::LR 0.0169230769231 --> Loss 0.00430346647898\n",
      "Epoch 37::Minibatch 1017::LR 0.0169230769231 --> Loss 0.00312348683675\n",
      "Epoch 37::Minibatch 1018::LR 0.0169230769231 --> Loss 0.00237793385983\n",
      "Epoch 37::Minibatch 1019::LR 0.0169230769231 --> Loss 0.00146108259757\n",
      "Epoch 37::Minibatch 1020::LR 0.0169230769231 --> Loss 0.00161902407805\n",
      "Epoch 37::Minibatch 1021::LR 0.0169230769231 --> Loss 0.00175859510899\n",
      "Epoch 37::Minibatch 1022::LR 0.0169230769231 --> Loss 0.00127178410689\n",
      "Epoch 37::Minibatch 1023::LR 0.0169230769231 --> Loss 0.000952465633551\n",
      "Epoch 37::Minibatch 1024::LR 0.0169230769231 --> Loss 0.000962066451708\n",
      "Epoch 37::Minibatch 1025::LR 0.0169230769231 --> Loss 0.00134304801623\n",
      "Epoch 37::Minibatch 1026::LR 0.0169230769231 --> Loss 0.000671218087276\n",
      "Epoch 37::Minibatch 1027::LR 0.0169230769231 --> Loss 0.000957376658916\n",
      "Epoch 37::Minibatch 1028::LR 0.0169230769231 --> Loss 0.00069991081953\n",
      "Epoch 37::Minibatch 1029::LR 0.0169230769231 --> Loss 0.000735133737326\n",
      "Epoch 37::Minibatch 1030::LR 0.0169230769231 --> Loss 0.00088246524334\n",
      "Epoch 37::Minibatch 1031::LR 0.0169230769231 --> Loss 0.000662983059883\n",
      "Epoch 37::Minibatch 1032::LR 0.0169230769231 --> Loss 0.00076440786322\n",
      "Epoch 37::Minibatch 1033::LR 0.0169230769231 --> Loss 0.000651330550512\n",
      "Epoch 37::Minibatch 1034::LR 0.0169230769231 --> Loss 0.000618936568499\n",
      "Epoch 37::Minibatch 1035::LR 0.0169230769231 --> Loss 0.00040178929766\n",
      "Epoch 37::Minibatch 1036::LR 0.0169230769231 --> Loss 0.000320345982909\n",
      "Epoch 37::Minibatch 1037::LR 0.0169230769231 --> Loss 0.000617502778769\n",
      "Epoch 37::Minibatch 1038::LR 0.0169230769231 --> Loss 0.000969543059667\n",
      "Epoch 37::Minibatch 1039::LR 0.0169230769231 --> Loss 0.000849934717019\n",
      "Epoch 37::Minibatch 1040::LR 0.0169230769231 --> Loss 0.000331013302008\n",
      "Epoch 37::Minibatch 1041::LR 0.0169230769231 --> Loss 0.000473435123761\n",
      "Epoch 38::Minibatch 1::LR 0.0146153846154 --> Loss 0.00710874239604\n",
      "Epoch 38::Minibatch 2::LR 0.0146153846154 --> Loss 0.00439560612043\n",
      "Epoch 38::Minibatch 3::LR 0.0146153846154 --> Loss 0.00267697811127\n",
      "Epoch 38::Minibatch 4::LR 0.0146153846154 --> Loss 0.00360314329465\n",
      "Epoch 38::Minibatch 5::LR 0.0146153846154 --> Loss 0.00421958764394\n",
      "Epoch 38::Minibatch 6::LR 0.0146153846154 --> Loss 0.0019438368082\n",
      "Epoch 38::Minibatch 7::LR 0.0146153846154 --> Loss 0.00681212822596\n",
      "Epoch 38::Minibatch 8::LR 0.0146153846154 --> Loss 0.00632234255473\n",
      "Epoch 38::Minibatch 9::LR 0.0146153846154 --> Loss 0.00497474273046\n",
      "Epoch 38::Minibatch 10::LR 0.0146153846154 --> Loss 0.0021824290355\n",
      "Epoch 38::Minibatch 11::LR 0.0146153846154 --> Loss 0.00207800805569\n",
      "Epoch 38::Minibatch 12::LR 0.0146153846154 --> Loss 0.00326997896036\n",
      "Epoch 38::Minibatch 13::LR 0.0146153846154 --> Loss 0.00527054230372\n",
      "Epoch 38::Minibatch 14::LR 0.0146153846154 --> Loss 0.00525025486946\n",
      "Epoch 38::Minibatch 15::LR 0.0146153846154 --> Loss 0.00454001784325\n",
      "Epoch 38::Minibatch 16::LR 0.0146153846154 --> Loss 0.000677665919065\n",
      "Epoch 38::Minibatch 17::LR 0.0146153846154 --> Loss 0.00322667022546\n",
      "Epoch 38::Minibatch 18::LR 0.0146153846154 --> Loss 0.00273293217023\n",
      "Epoch 38::Minibatch 19::LR 0.0146153846154 --> Loss 0.0017156046629\n",
      "Epoch 38::Minibatch 20::LR 0.0146153846154 --> Loss 0.00227343996366\n",
      "Epoch 38::Minibatch 21::LR 0.0146153846154 --> Loss 0.00349008758863\n",
      "Epoch 38::Minibatch 22::LR 0.0146153846154 --> Loss 0.00223907649517\n",
      "Epoch 38::Minibatch 23::LR 0.0146153846154 --> Loss 0.000994840164979\n",
      "Epoch 38::Minibatch 24::LR 0.0146153846154 --> Loss 0.000578404217958\n",
      "Epoch 38::Minibatch 25::LR 0.0146153846154 --> Loss 0.00149632980426\n",
      "Epoch 38::Minibatch 26::LR 0.0146153846154 --> Loss 0.00168720761935\n",
      "Epoch 38::Minibatch 27::LR 0.0146153846154 --> Loss 0.0013421112299\n",
      "Epoch 38::Minibatch 28::LR 0.0146153846154 --> Loss 0.000587750871976\n",
      "Epoch 38::Minibatch 29::LR 0.0146153846154 --> Loss 0.00077088351051\n",
      "Epoch 38::Minibatch 30::LR 0.0146153846154 --> Loss 0.00131818602482\n",
      "Epoch 38::Minibatch 31::LR 0.0146153846154 --> Loss 0.00177148679892\n",
      "Epoch 38::Minibatch 32::LR 0.0146153846154 --> Loss 0.001542070508\n",
      "Epoch 38::Minibatch 33::LR 0.0146153846154 --> Loss 0.000863846043746\n",
      "Epoch 38::Minibatch 34::LR 0.0146153846154 --> Loss 0.00203343749046\n",
      "Epoch 38::Minibatch 35::LR 0.0146153846154 --> Loss 0.00253925422827\n",
      "Epoch 38::Minibatch 36::LR 0.0146153846154 --> Loss 0.00225131611029\n",
      "Epoch 38::Minibatch 37::LR 0.0146153846154 --> Loss 0.000792135397593\n",
      "Epoch 38::Minibatch 38::LR 0.0146153846154 --> Loss 0.000813938428958\n",
      "Epoch 38::Minibatch 39::LR 0.0146153846154 --> Loss 0.00207136233648\n",
      "Epoch 38::Minibatch 40::LR 0.0146153846154 --> Loss 0.00305138011773\n",
      "Epoch 38::Minibatch 41::LR 0.0146153846154 --> Loss 0.0023838130633\n",
      "Epoch 38::Minibatch 42::LR 0.0146153846154 --> Loss 0.00367991288503\n",
      "Epoch 38::Minibatch 43::LR 0.0146153846154 --> Loss 0.00206225593885\n",
      "Epoch 38::Minibatch 44::LR 0.0146153846154 --> Loss 0.00351370135943\n",
      "Epoch 38::Minibatch 45::LR 0.0146153846154 --> Loss 0.00246731360753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 46::LR 0.0146153846154 --> Loss 0.00289857248465\n",
      "Epoch 38::Minibatch 47::LR 0.0146153846154 --> Loss 0.0028880606095\n",
      "Epoch 38::Minibatch 48::LR 0.0146153846154 --> Loss 0.00424548387527\n",
      "Epoch 38::Minibatch 49::LR 0.0146153846154 --> Loss 0.00490766127904\n",
      "Epoch 38::Minibatch 50::LR 0.0146153846154 --> Loss 0.00574934681257\n",
      "Epoch 38::Minibatch 51::LR 0.0146153846154 --> Loss 0.00356398781141\n",
      "Epoch 38::Minibatch 52::LR 0.0146153846154 --> Loss 0.00329783598582\n",
      "Epoch 38::Minibatch 53::LR 0.0146153846154 --> Loss 0.00333945473035\n",
      "Epoch 38::Minibatch 54::LR 0.0146153846154 --> Loss 0.00391590476036\n",
      "Epoch 38::Minibatch 55::LR 0.0146153846154 --> Loss 0.00100495437781\n",
      "Epoch 38::Minibatch 56::LR 0.0146153846154 --> Loss 0.00275992552439\n",
      "Epoch 38::Minibatch 57::LR 0.0146153846154 --> Loss 0.00426377733548\n",
      "Epoch 38::Minibatch 58::LR 0.0146153846154 --> Loss 0.00314028223356\n",
      "Epoch 38::Minibatch 59::LR 0.0146153846154 --> Loss 0.00240744153659\n",
      "Epoch 38::Minibatch 60::LR 0.0146153846154 --> Loss 0.00251783112685\n",
      "Epoch 38::Minibatch 61::LR 0.0146153846154 --> Loss 0.000688064346711\n",
      "Epoch 38::Minibatch 62::LR 0.0146153846154 --> Loss 0.00234136780103\n",
      "Epoch 38::Minibatch 63::LR 0.0146153846154 --> Loss 0.00209987123807\n",
      "Epoch 38::Minibatch 64::LR 0.0146153846154 --> Loss 0.000810599625111\n",
      "Epoch 38::Minibatch 65::LR 0.0146153846154 --> Loss 0.00207818428675\n",
      "Epoch 38::Minibatch 66::LR 0.0146153846154 --> Loss 0.00288402716319\n",
      "Epoch 38::Minibatch 67::LR 0.0146153846154 --> Loss 0.00239008367062\n",
      "Epoch 38::Minibatch 68::LR 0.0146153846154 --> Loss 0.00179334878922\n",
      "Epoch 38::Minibatch 69::LR 0.0146153846154 --> Loss 0.00346525549889\n",
      "Epoch 38::Minibatch 70::LR 0.0146153846154 --> Loss 0.00313342650731\n",
      "Epoch 38::Minibatch 71::LR 0.0146153846154 --> Loss 0.00219913125038\n",
      "Epoch 38::Minibatch 72::LR 0.0146153846154 --> Loss 0.000557625641425\n",
      "Epoch 38::Minibatch 73::LR 0.0146153846154 --> Loss 0.00355773846308\n",
      "Epoch 38::Minibatch 74::LR 0.0146153846154 --> Loss 0.00388837973277\n",
      "Epoch 38::Minibatch 75::LR 0.0146153846154 --> Loss 0.00189537624518\n",
      "Epoch 38::Minibatch 76::LR 0.0146153846154 --> Loss 0.000517809887727\n",
      "Epoch 38::Minibatch 77::LR 0.0146153846154 --> Loss 0.00317963997523\n",
      "Epoch 38::Minibatch 78::LR 0.0146153846154 --> Loss 0.00409343997637\n",
      "Epoch 38::Minibatch 79::LR 0.0146153846154 --> Loss 0.00159429947535\n",
      "Epoch 38::Minibatch 80::LR 0.0146153846154 --> Loss 0.00263680140177\n",
      "Epoch 38::Minibatch 81::LR 0.0146153846154 --> Loss 0.00240457952023\n",
      "Epoch 38::Minibatch 82::LR 0.0146153846154 --> Loss 0.00172774394353\n",
      "Epoch 38::Minibatch 83::LR 0.0146153846154 --> Loss 0.00353951176008\n",
      "Epoch 38::Minibatch 84::LR 0.0146153846154 --> Loss 0.00177748223146\n",
      "Epoch 38::Minibatch 85::LR 0.0146153846154 --> Loss 0.00237732390563\n",
      "Epoch 38::Minibatch 86::LR 0.0146153846154 --> Loss 0.00202748497327\n",
      "Epoch 38::Minibatch 87::LR 0.0146153846154 --> Loss 0.00209596693516\n",
      "Epoch 38::Minibatch 88::LR 0.0146153846154 --> Loss 0.00160776158174\n",
      "Epoch 38::Minibatch 89::LR 0.0146153846154 --> Loss 0.0021271632115\n",
      "Epoch 38::Minibatch 90::LR 0.0146153846154 --> Loss 0.00104263216257\n",
      "Epoch 38::Minibatch 91::LR 0.0146153846154 --> Loss 0.000886331796646\n",
      "Epoch 38::Minibatch 92::LR 0.0146153846154 --> Loss 0.00247242589792\n",
      "Epoch 38::Minibatch 93::LR 0.0146153846154 --> Loss 0.00165895601114\n",
      "Epoch 38::Minibatch 94::LR 0.0146153846154 --> Loss 0.00172979911168\n",
      "Epoch 38::Minibatch 95::LR 0.0146153846154 --> Loss 0.00194057842096\n",
      "Epoch 38::Minibatch 96::LR 0.0146153846154 --> Loss 0.00418916583061\n",
      "Epoch 38::Minibatch 97::LR 0.0146153846154 --> Loss 0.00296974082788\n",
      "Epoch 38::Minibatch 98::LR 0.0146153846154 --> Loss 0.00113668541114\n",
      "Epoch 38::Minibatch 99::LR 0.0146153846154 --> Loss 0.00147576342026\n",
      "Epoch 38::Minibatch 100::LR 0.0146153846154 --> Loss 0.0037688712279\n",
      "Epoch 38::Minibatch 101::LR 0.0146153846154 --> Loss 0.000902775526047\n",
      "Epoch 38::Minibatch 102::LR 0.0146153846154 --> Loss 0.00375037670135\n",
      "Epoch 38::Minibatch 103::LR 0.0146153846154 --> Loss 0.0037381319205\n",
      "Epoch 38::Minibatch 104::LR 0.0146153846154 --> Loss 0.00260067164898\n",
      "Epoch 38::Minibatch 105::LR 0.0146153846154 --> Loss 0.00186439494292\n",
      "Epoch 38::Minibatch 106::LR 0.0146153846154 --> Loss 0.011210471789\n",
      "Epoch 38::Minibatch 107::LR 0.0146153846154 --> Loss 0.00464491963387\n",
      "Epoch 38::Minibatch 108::LR 0.0146153846154 --> Loss 0.000883891483148\n",
      "Epoch 38::Minibatch 109::LR 0.0146153846154 --> Loss 0.00428396264712\n",
      "Epoch 38::Minibatch 110::LR 0.0146153846154 --> Loss 0.00216901918252\n",
      "Epoch 38::Minibatch 111::LR 0.0146153846154 --> Loss 0.000772616863251\n",
      "Epoch 38::Minibatch 112::LR 0.0146153846154 --> Loss 0.00320725023746\n",
      "Epoch 38::Minibatch 113::LR 0.0146153846154 --> Loss 0.00228822827339\n",
      "Epoch 38::Minibatch 114::LR 0.0146153846154 --> Loss 0.00130358080069\n",
      "Epoch 38::Minibatch 115::LR 0.0146153846154 --> Loss 0.00105256607135\n",
      "Epoch 38::Minibatch 116::LR 0.0146153846154 --> Loss 0.00262705087662\n",
      "Epoch 38::Minibatch 117::LR 0.0146153846154 --> Loss 0.0041420241197\n",
      "Epoch 38::Minibatch 118::LR 0.0146153846154 --> Loss 0.00628809650739\n",
      "Epoch 38::Minibatch 119::LR 0.0146153846154 --> Loss 0.000444202323755\n",
      "Epoch 38::Minibatch 120::LR 0.0146153846154 --> Loss 0.00166349709034\n",
      "Epoch 38::Minibatch 121::LR 0.0146153846154 --> Loss 0.002247133255\n",
      "Epoch 38::Minibatch 122::LR 0.0146153846154 --> Loss 0.00392715613047\n",
      "Epoch 38::Minibatch 123::LR 0.0146153846154 --> Loss 0.000564252038797\n",
      "Epoch 38::Minibatch 124::LR 0.0146153846154 --> Loss 0.00265978415807\n",
      "Epoch 38::Minibatch 125::LR 0.0146153846154 --> Loss 0.00432538310687\n",
      "Epoch 38::Minibatch 126::LR 0.0146153846154 --> Loss 0.00229239940643\n",
      "Epoch 38::Minibatch 127::LR 0.0146153846154 --> Loss 0.00518209139506\n",
      "Epoch 38::Minibatch 128::LR 0.0146153846154 --> Loss 0.00343935290972\n",
      "Epoch 38::Minibatch 129::LR 0.0146153846154 --> Loss 0.00223070661227\n",
      "Epoch 38::Minibatch 130::LR 0.0146153846154 --> Loss 0.00427424311638\n",
      "Epoch 38::Minibatch 131::LR 0.0146153846154 --> Loss 0.00165286242962\n",
      "Epoch 38::Minibatch 132::LR 0.0146153846154 --> Loss 0.00266941209634\n",
      "Epoch 38::Minibatch 133::LR 0.0146153846154 --> Loss 0.00263757328192\n",
      "Epoch 38::Minibatch 134::LR 0.0146153846154 --> Loss 0.00202999631564\n",
      "Epoch 38::Minibatch 135::LR 0.0146153846154 --> Loss 0.00115479071935\n",
      "Epoch 38::Minibatch 136::LR 0.0146153846154 --> Loss 0.00226772785187\n",
      "Epoch 38::Minibatch 137::LR 0.0146153846154 --> Loss 0.0031942598025\n",
      "Epoch 38::Minibatch 138::LR 0.0146153846154 --> Loss 0.00117019454638\n",
      "Epoch 38::Minibatch 139::LR 0.0146153846154 --> Loss 0.00182690004508\n",
      "Epoch 38::Minibatch 140::LR 0.0146153846154 --> Loss 0.00230922222137\n",
      "Epoch 38::Minibatch 141::LR 0.0146153846154 --> Loss 0.00280956566334\n",
      "Epoch 38::Minibatch 142::LR 0.0146153846154 --> Loss 0.00266683280468\n",
      "Epoch 38::Minibatch 143::LR 0.0146153846154 --> Loss 0.000516283313433\n",
      "Epoch 38::Minibatch 144::LR 0.0146153846154 --> Loss 0.00344242413839\n",
      "Epoch 38::Minibatch 145::LR 0.0146153846154 --> Loss 0.0040616607666\n",
      "Epoch 38::Minibatch 146::LR 0.0146153846154 --> Loss 0.00246216595173\n",
      "Epoch 38::Minibatch 147::LR 0.0146153846154 --> Loss 0.00178382198016\n",
      "Epoch 38::Minibatch 148::LR 0.0146153846154 --> Loss 0.000937661131223\n",
      "Epoch 38::Minibatch 149::LR 0.0146153846154 --> Loss 0.00288259208202\n",
      "Epoch 38::Minibatch 150::LR 0.0146153846154 --> Loss 0.0026360531648\n",
      "Epoch 38::Minibatch 151::LR 0.0146153846154 --> Loss 0.00431654771169\n",
      "Epoch 38::Minibatch 152::LR 0.0146153846154 --> Loss 0.000893934071064\n",
      "Epoch 38::Minibatch 153::LR 0.0146153846154 --> Loss 0.00156093825897\n",
      "Epoch 38::Minibatch 154::LR 0.0146153846154 --> Loss 0.00198471049468\n",
      "Epoch 38::Minibatch 155::LR 0.0146153846154 --> Loss 0.00392266829809\n",
      "Epoch 38::Minibatch 156::LR 0.0146153846154 --> Loss 0.00233853558699\n",
      "Epoch 38::Minibatch 157::LR 0.0146153846154 --> Loss 0.000680547157923\n",
      "Epoch 38::Minibatch 158::LR 0.0146153846154 --> Loss 0.00323391834895\n",
      "Epoch 38::Minibatch 159::LR 0.0146153846154 --> Loss 0.00271173536777\n",
      "Epoch 38::Minibatch 160::LR 0.0146153846154 --> Loss 0.00268150627613\n",
      "Epoch 38::Minibatch 161::LR 0.0146153846154 --> Loss 0.000986961225669\n",
      "Epoch 38::Minibatch 162::LR 0.0146153846154 --> Loss 0.00405394275983\n",
      "Epoch 38::Minibatch 163::LR 0.0146153846154 --> Loss 0.00242277264595\n",
      "Epoch 38::Minibatch 164::LR 0.0146153846154 --> Loss 0.00257365445296\n",
      "Epoch 38::Minibatch 165::LR 0.0146153846154 --> Loss 0.000479463239511\n",
      "Epoch 38::Minibatch 166::LR 0.0146153846154 --> Loss 0.00168030560017\n",
      "Epoch 38::Minibatch 167::LR 0.0146153846154 --> Loss 0.00249764323235\n",
      "Epoch 38::Minibatch 168::LR 0.0146153846154 --> Loss 0.00212829232216\n",
      "Epoch 38::Minibatch 169::LR 0.0146153846154 --> Loss 0.000969353516897\n",
      "Epoch 38::Minibatch 170::LR 0.0146153846154 --> Loss 0.000933756927649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 171::LR 0.0146153846154 --> Loss 0.00252770026525\n",
      "Epoch 38::Minibatch 172::LR 0.0146153846154 --> Loss 0.00430390715599\n",
      "Epoch 38::Minibatch 173::LR 0.0146153846154 --> Loss 0.00206981341044\n",
      "Epoch 38::Minibatch 174::LR 0.0146153846154 --> Loss 0.000935376286507\n",
      "Epoch 38::Minibatch 175::LR 0.0146153846154 --> Loss 0.00242103656133\n",
      "Epoch 38::Minibatch 176::LR 0.0146153846154 --> Loss 0.00304237325986\n",
      "Epoch 38::Minibatch 177::LR 0.0146153846154 --> Loss 0.00417060176531\n",
      "Epoch 38::Minibatch 178::LR 0.0146153846154 --> Loss 0.00143969575564\n",
      "Epoch 38::Minibatch 179::LR 0.0146153846154 --> Loss 0.00111498604218\n",
      "Epoch 38::Minibatch 180::LR 0.0146153846154 --> Loss 0.00325929403305\n",
      "Epoch 38::Minibatch 181::LR 0.0146153846154 --> Loss 0.0029706543684\n",
      "Epoch 38::Minibatch 182::LR 0.0146153846154 --> Loss 0.000675296982129\n",
      "Epoch 38::Minibatch 183::LR 0.0146153846154 --> Loss 0.00149972617626\n",
      "Epoch 38::Minibatch 184::LR 0.0146153846154 --> Loss 0.00336316943169\n",
      "Epoch 38::Minibatch 185::LR 0.0146153846154 --> Loss 0.00252978046735\n",
      "Epoch 38::Minibatch 186::LR 0.0146153846154 --> Loss 0.000895285308361\n",
      "Epoch 38::Minibatch 187::LR 0.0146153846154 --> Loss 0.00125192373991\n",
      "Epoch 38::Minibatch 188::LR 0.0146153846154 --> Loss 0.00390645464261\n",
      "Epoch 38::Minibatch 189::LR 0.0146153846154 --> Loss 0.00397969285647\n",
      "Epoch 38::Minibatch 190::LR 0.0146153846154 --> Loss 0.00226044634978\n",
      "Epoch 38::Minibatch 191::LR 0.0146153846154 --> Loss 0.000433310021957\n",
      "Epoch 38::Minibatch 192::LR 0.0146153846154 --> Loss 0.00276934305827\n",
      "Epoch 38::Minibatch 193::LR 0.0146153846154 --> Loss 0.00270462036133\n",
      "Epoch 38::Minibatch 194::LR 0.0146153846154 --> Loss 0.00170397619406\n",
      "Epoch 38::Minibatch 195::LR 0.0146153846154 --> Loss 0.000367414106925\n",
      "Epoch 38::Minibatch 196::LR 0.0146153846154 --> Loss 0.00137587885062\n",
      "Epoch 38::Minibatch 197::LR 0.0146153846154 --> Loss 0.00295622646809\n",
      "Epoch 38::Minibatch 198::LR 0.0146153846154 --> Loss 0.00233135302862\n",
      "Epoch 38::Minibatch 199::LR 0.0146153846154 --> Loss 0.000287517954906\n",
      "Epoch 38::Minibatch 200::LR 0.0146153846154 --> Loss 0.00203342219194\n",
      "Epoch 38::Minibatch 201::LR 0.0146153846154 --> Loss 0.00192221879959\n",
      "Epoch 38::Minibatch 202::LR 0.0146153846154 --> Loss 0.00180112679799\n",
      "Epoch 38::Minibatch 203::LR 0.0146153846154 --> Loss 0.00176318963369\n",
      "Epoch 38::Minibatch 204::LR 0.0146153846154 --> Loss 0.00141433467468\n",
      "Epoch 38::Minibatch 205::LR 0.0146153846154 --> Loss 0.00223029275735\n",
      "Epoch 38::Minibatch 206::LR 0.0146153846154 --> Loss 0.00506125291189\n",
      "Epoch 38::Minibatch 207::LR 0.0146153846154 --> Loss 0.00139587700367\n",
      "Epoch 38::Minibatch 208::LR 0.0146153846154 --> Loss 0.0011020731926\n",
      "Epoch 38::Minibatch 209::LR 0.0146153846154 --> Loss 0.00257393360138\n",
      "Epoch 38::Minibatch 210::LR 0.0146153846154 --> Loss 0.00241572022438\n",
      "Epoch 38::Minibatch 211::LR 0.0146153846154 --> Loss 0.00277152518431\n",
      "Epoch 38::Minibatch 212::LR 0.0146153846154 --> Loss 0.00369271794955\n",
      "Epoch 38::Minibatch 213::LR 0.0146153846154 --> Loss 0.0052840479215\n",
      "Epoch 38::Minibatch 214::LR 0.0146153846154 --> Loss 0.00652032732964\n",
      "Epoch 38::Minibatch 215::LR 0.0146153846154 --> Loss 0.00135511865218\n",
      "Epoch 38::Minibatch 216::LR 0.0146153846154 --> Loss 0.00520711859067\n",
      "Epoch 38::Minibatch 217::LR 0.0146153846154 --> Loss 0.0056989411513\n",
      "Epoch 38::Minibatch 218::LR 0.0146153846154 --> Loss 0.00388490200043\n",
      "Epoch 38::Minibatch 219::LR 0.0146153846154 --> Loss 0.00447402199109\n",
      "Epoch 38::Minibatch 220::LR 0.0146153846154 --> Loss 0.00431136965752\n",
      "Epoch 38::Minibatch 221::LR 0.0146153846154 --> Loss 0.00429070075353\n",
      "Epoch 38::Minibatch 222::LR 0.0146153846154 --> Loss 0.00314564168453\n",
      "Epoch 38::Minibatch 223::LR 0.0146153846154 --> Loss 0.00137178520362\n",
      "Epoch 38::Minibatch 224::LR 0.0146153846154 --> Loss 0.00155690332254\n",
      "Epoch 38::Minibatch 225::LR 0.0146153846154 --> Loss 0.00798017501831\n",
      "Epoch 38::Minibatch 226::LR 0.0146153846154 --> Loss 0.00358085433642\n",
      "Epoch 38::Minibatch 227::LR 0.0146153846154 --> Loss 0.00167635321617\n",
      "Epoch 38::Minibatch 228::LR 0.0146153846154 --> Loss 0.0006308349967\n",
      "Epoch 38::Minibatch 229::LR 0.0146153846154 --> Loss 0.00476885557175\n",
      "Epoch 38::Minibatch 230::LR 0.0146153846154 --> Loss 0.00356150309245\n",
      "Epoch 38::Minibatch 231::LR 0.0146153846154 --> Loss 0.00266802171866\n",
      "Epoch 38::Minibatch 232::LR 0.0146153846154 --> Loss 0.00114809493224\n",
      "Epoch 38::Minibatch 233::LR 0.0146153846154 --> Loss 0.00247313141823\n",
      "Epoch 38::Minibatch 234::LR 0.0146153846154 --> Loss 0.00754901091258\n",
      "Epoch 38::Minibatch 235::LR 0.0146153846154 --> Loss 0.0045563797156\n",
      "Epoch 38::Minibatch 236::LR 0.0146153846154 --> Loss 0.00164629956086\n",
      "Epoch 38::Minibatch 237::LR 0.0146153846154 --> Loss 0.000557580838601\n",
      "Epoch 38::Minibatch 238::LR 0.0146153846154 --> Loss 0.003497295777\n",
      "Epoch 38::Minibatch 239::LR 0.0146153846154 --> Loss 0.00295731047789\n",
      "Epoch 38::Minibatch 240::LR 0.0146153846154 --> Loss 0.0032918570439\n",
      "Epoch 38::Minibatch 241::LR 0.0146153846154 --> Loss 0.000744854807854\n",
      "Epoch 38::Minibatch 242::LR 0.0146153846154 --> Loss 0.00665632009506\n",
      "Epoch 38::Minibatch 243::LR 0.0146153846154 --> Loss 0.00318510691325\n",
      "Epoch 38::Minibatch 244::LR 0.0146153846154 --> Loss 0.00266846259435\n",
      "Epoch 38::Minibatch 245::LR 0.0146153846154 --> Loss 0.000411754399538\n",
      "Epoch 38::Minibatch 246::LR 0.0146153846154 --> Loss 0.00184203445911\n",
      "Epoch 38::Minibatch 247::LR 0.0146153846154 --> Loss 0.00965474843979\n",
      "Epoch 38::Minibatch 248::LR 0.0146153846154 --> Loss 0.00431014537811\n",
      "Epoch 38::Minibatch 249::LR 0.0146153846154 --> Loss 0.00233820021152\n",
      "Epoch 38::Minibatch 250::LR 0.0146153846154 --> Loss 0.00230400383472\n",
      "Epoch 38::Minibatch 251::LR 0.0146153846154 --> Loss 0.00230013807615\n",
      "Epoch 38::Minibatch 252::LR 0.0146153846154 --> Loss 0.0015639808774\n",
      "Epoch 38::Minibatch 253::LR 0.0146153846154 --> Loss 0.00268618643284\n",
      "Epoch 38::Minibatch 254::LR 0.0146153846154 --> Loss 0.00474776625633\n",
      "Epoch 38::Minibatch 255::LR 0.0146153846154 --> Loss 0.00385693748792\n",
      "Epoch 38::Minibatch 256::LR 0.0146153846154 --> Loss 0.00132196197907\n",
      "Epoch 38::Minibatch 257::LR 0.0146153846154 --> Loss 0.00112302233775\n",
      "Epoch 38::Minibatch 258::LR 0.0146153846154 --> Loss 0.00367313702901\n",
      "Epoch 38::Minibatch 259::LR 0.0146153846154 --> Loss 0.00151719659567\n",
      "Epoch 38::Minibatch 260::LR 0.0146153846154 --> Loss 0.00182983458042\n",
      "Epoch 38::Minibatch 261::LR 0.0146153846154 --> Loss 0.00260576109091\n",
      "Epoch 38::Minibatch 262::LR 0.0146153846154 --> Loss 0.00177959084511\n",
      "Epoch 38::Minibatch 263::LR 0.0146153846154 --> Loss 0.00225057244301\n",
      "Epoch 38::Minibatch 264::LR 0.0146153846154 --> Loss 0.00353482286135\n",
      "Epoch 38::Minibatch 265::LR 0.0146153846154 --> Loss 0.00999143600464\n",
      "Epoch 38::Minibatch 266::LR 0.0146153846154 --> Loss 0.000823323577642\n",
      "Epoch 38::Minibatch 267::LR 0.0146153846154 --> Loss 0.00881141265233\n",
      "Epoch 38::Minibatch 268::LR 0.0146153846154 --> Loss 0.000974038739999\n",
      "Epoch 38::Minibatch 269::LR 0.0146153846154 --> Loss 0.0034512424469\n",
      "Epoch 38::Minibatch 270::LR 0.0146153846154 --> Loss 0.00769903580348\n",
      "Epoch 38::Minibatch 271::LR 0.0146153846154 --> Loss 0.00229535917441\n",
      "Epoch 38::Minibatch 272::LR 0.0146153846154 --> Loss 0.00452409903208\n",
      "Epoch 38::Minibatch 273::LR 0.0146153846154 --> Loss 0.00125418583552\n",
      "Epoch 38::Minibatch 274::LR 0.0146153846154 --> Loss 0.00174855629603\n",
      "Epoch 38::Minibatch 275::LR 0.0146153846154 --> Loss 0.00237854659557\n",
      "Epoch 38::Minibatch 276::LR 0.0146153846154 --> Loss 0.00326215048631\n",
      "Epoch 38::Minibatch 277::LR 0.0146153846154 --> Loss 0.000806675950686\n",
      "Epoch 38::Minibatch 278::LR 0.0146153846154 --> Loss 0.00246562321981\n",
      "Epoch 38::Minibatch 279::LR 0.0146153846154 --> Loss 0.00182871977488\n",
      "Epoch 38::Minibatch 280::LR 0.0146153846154 --> Loss 0.00162748992443\n",
      "Epoch 38::Minibatch 281::LR 0.0146153846154 --> Loss 0.0010281247894\n",
      "Epoch 38::Minibatch 282::LR 0.0146153846154 --> Loss 0.0018817092975\n",
      "Epoch 38::Minibatch 283::LR 0.0146153846154 --> Loss 0.0017745278279\n",
      "Epoch 38::Minibatch 284::LR 0.0146153846154 --> Loss 0.00145829916\n",
      "Epoch 38::Minibatch 285::LR 0.0146153846154 --> Loss 0.00106059451898\n",
      "Epoch 38::Minibatch 286::LR 0.0146153846154 --> Loss 0.00184168318907\n",
      "Epoch 38::Minibatch 287::LR 0.0146153846154 --> Loss 0.00183366576831\n",
      "Epoch 38::Minibatch 288::LR 0.0146153846154 --> Loss 0.00099754969279\n",
      "Epoch 38::Minibatch 289::LR 0.0146153846154 --> Loss 0.00148050636053\n",
      "Epoch 38::Minibatch 290::LR 0.0146153846154 --> Loss 0.00175993204117\n",
      "Epoch 38::Minibatch 291::LR 0.0146153846154 --> Loss 0.00158954590559\n",
      "Epoch 38::Minibatch 292::LR 0.0146153846154 --> Loss 0.000559757451216\n",
      "Epoch 38::Minibatch 293::LR 0.0146153846154 --> Loss 0.00143654674292\n",
      "Epoch 38::Minibatch 294::LR 0.0146153846154 --> Loss 0.00161204755306\n",
      "Epoch 38::Minibatch 295::LR 0.0146153846154 --> Loss 0.00183667620023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 296::LR 0.0146153846154 --> Loss 0.0015718682607\n",
      "Epoch 38::Minibatch 297::LR 0.0146153846154 --> Loss 0.00138527760903\n",
      "Epoch 38::Minibatch 298::LR 0.0146153846154 --> Loss 0.00139494131009\n",
      "Epoch 38::Minibatch 299::LR 0.0146153846154 --> Loss 0.000804488956928\n",
      "Epoch 38::Minibatch 300::LR 0.0146153846154 --> Loss 0.0026201971372\n",
      "Epoch 38::Minibatch 301::LR 0.0146153846154 --> Loss 0.00253867050012\n",
      "Epoch 38::Minibatch 302::LR 0.0146153846154 --> Loss 0.0023566343387\n",
      "Epoch 38::Minibatch 303::LR 0.0146153846154 --> Loss 0.000806355377038\n",
      "Epoch 38::Minibatch 304::LR 0.0146153846154 --> Loss 0.00286339342594\n",
      "Epoch 38::Minibatch 305::LR 0.0146153846154 --> Loss 0.00170509537061\n",
      "Epoch 38::Minibatch 306::LR 0.0146153846154 --> Loss 0.000924285848935\n",
      "Epoch 38::Minibatch 307::LR 0.0146153846154 --> Loss 0.00239083548387\n",
      "Epoch 38::Minibatch 308::LR 0.0146153846154 --> Loss 0.00199590404828\n",
      "Epoch 38::Minibatch 309::LR 0.0146153846154 --> Loss 0.00103901386261\n",
      "Epoch 38::Minibatch 310::LR 0.0146153846154 --> Loss 0.00119336197774\n",
      "Epoch 38::Minibatch 311::LR 0.0146153846154 --> Loss 0.00179137686888\n",
      "Epoch 38::Minibatch 312::LR 0.0146153846154 --> Loss 0.00283738831679\n",
      "Epoch 38::Minibatch 313::LR 0.0146153846154 --> Loss 0.00230734805266\n",
      "Epoch 38::Minibatch 314::LR 0.0146153846154 --> Loss 0.00191654940446\n",
      "Epoch 38::Minibatch 315::LR 0.0146153846154 --> Loss 0.0010528665781\n",
      "Epoch 38::Minibatch 316::LR 0.0146153846154 --> Loss 0.0023394626379\n",
      "Epoch 38::Minibatch 317::LR 0.0146153846154 --> Loss 0.00156219015519\n",
      "Epoch 38::Minibatch 318::LR 0.0146153846154 --> Loss 0.0013199108839\n",
      "Epoch 38::Minibatch 319::LR 0.0146153846154 --> Loss 0.00229736208916\n",
      "Epoch 38::Minibatch 320::LR 0.0146153846154 --> Loss 0.00296733101209\n",
      "Epoch 38::Minibatch 321::LR 0.0146153846154 --> Loss 0.000838036735853\n",
      "Epoch 38::Minibatch 322::LR 0.0146153846154 --> Loss 0.00333057622115\n",
      "Epoch 38::Minibatch 323::LR 0.0146153846154 --> Loss 0.00338807384173\n",
      "Epoch 38::Minibatch 324::LR 0.0146153846154 --> Loss 0.00265449543794\n",
      "Epoch 38::Minibatch 325::LR 0.0146153846154 --> Loss 0.00236089328925\n",
      "Epoch 38::Minibatch 326::LR 0.0146153846154 --> Loss 0.00510652462641\n",
      "Epoch 38::Minibatch 327::LR 0.0146153846154 --> Loss 0.00220168252786\n",
      "Epoch 38::Minibatch 328::LR 0.0146153846154 --> Loss 0.0028376464049\n",
      "Epoch 38::Minibatch 329::LR 0.0146153846154 --> Loss 0.00117341071367\n",
      "Epoch 38::Minibatch 330::LR 0.0146153846154 --> Loss 0.00158369153738\n",
      "Epoch 38::Minibatch 331::LR 0.0146153846154 --> Loss 0.00253033498923\n",
      "Epoch 38::Minibatch 332::LR 0.0146153846154 --> Loss 0.00242779354254\n",
      "Epoch 38::Minibatch 333::LR 0.0146153846154 --> Loss 0.00147244920333\n",
      "Epoch 38::Minibatch 334::LR 0.0146153846154 --> Loss 0.0043662516276\n",
      "Epoch 38::Minibatch 335::LR 0.0146153846154 --> Loss 0.00190576871236\n",
      "Epoch 38::Minibatch 336::LR 0.0146153846154 --> Loss 0.00227062086264\n",
      "Epoch 38::Minibatch 337::LR 0.0146153846154 --> Loss 0.00381967345874\n",
      "Epoch 38::Minibatch 338::LR 0.0146153846154 --> Loss 0.000560197134813\n",
      "Epoch 38::Minibatch 339::LR 0.0146153846154 --> Loss 0.00319571713607\n",
      "Epoch 38::Minibatch 340::LR 0.0146153846154 --> Loss 0.00357644200325\n",
      "Epoch 38::Minibatch 341::LR 0.0146153846154 --> Loss 0.0041479742527\n",
      "Epoch 38::Minibatch 342::LR 0.0146153846154 --> Loss 0.00304010252158\n",
      "Epoch 38::Minibatch 343::LR 0.0146153846154 --> Loss 0.0016354572773\n",
      "Epoch 38::Minibatch 344::LR 0.0146153846154 --> Loss 0.0031495932738\n",
      "Epoch 38::Minibatch 345::LR 0.0146153846154 --> Loss 0.0040037838618\n",
      "Epoch 38::Minibatch 346::LR 0.0146153846154 --> Loss 0.00522589484851\n",
      "Epoch 38::Minibatch 347::LR 0.0146153846154 --> Loss 0.000819511214892\n",
      "Epoch 38::Minibatch 348::LR 0.0146153846154 --> Loss 0.00287537813187\n",
      "Epoch 38::Minibatch 349::LR 0.0146153846154 --> Loss 0.00328451196353\n",
      "Epoch 38::Minibatch 350::LR 0.0146153846154 --> Loss 0.00163826117913\n",
      "Epoch 38::Minibatch 351::LR 0.0146153846154 --> Loss 0.00340822935104\n",
      "Epoch 38::Minibatch 352::LR 0.0146153846154 --> Loss 0.00481937368711\n",
      "Epoch 38::Minibatch 353::LR 0.0146153846154 --> Loss 0.00346983869871\n",
      "Epoch 38::Minibatch 354::LR 0.0146153846154 --> Loss 0.00293688952923\n",
      "Epoch 38::Minibatch 355::LR 0.0146153846154 --> Loss 0.00632874170939\n",
      "Epoch 38::Minibatch 356::LR 0.0146153846154 --> Loss 0.00317597985268\n",
      "Epoch 38::Minibatch 357::LR 0.0146153846154 --> Loss 0.00121923128764\n",
      "Epoch 38::Minibatch 358::LR 0.0146153846154 --> Loss 0.00189796308676\n",
      "Epoch 38::Minibatch 359::LR 0.0146153846154 --> Loss 0.0026561764876\n",
      "Epoch 38::Minibatch 360::LR 0.0146153846154 --> Loss 0.00224620600541\n",
      "Epoch 38::Minibatch 361::LR 0.0146153846154 --> Loss 0.00220119059086\n",
      "Epoch 38::Minibatch 362::LR 0.0146153846154 --> Loss 0.00219969570637\n",
      "Epoch 38::Minibatch 363::LR 0.0146153846154 --> Loss 0.000627597570419\n",
      "Epoch 38::Minibatch 364::LR 0.0146153846154 --> Loss 0.00195676406225\n",
      "Epoch 38::Minibatch 365::LR 0.0146153846154 --> Loss 0.0019688141346\n",
      "Epoch 38::Minibatch 366::LR 0.0146153846154 --> Loss 0.00207599719365\n",
      "Epoch 38::Minibatch 367::LR 0.0146153846154 --> Loss 0.000962662994862\n",
      "Epoch 38::Minibatch 368::LR 0.0146153846154 --> Loss 0.000971114039421\n",
      "Epoch 38::Minibatch 369::LR 0.0146153846154 --> Loss 0.00268391529719\n",
      "Epoch 38::Minibatch 370::LR 0.0146153846154 --> Loss 0.00216834525267\n",
      "Epoch 38::Minibatch 371::LR 0.0146153846154 --> Loss 0.00181768139203\n",
      "Epoch 38::Minibatch 372::LR 0.0146153846154 --> Loss 0.000426077942053\n",
      "Epoch 38::Minibatch 373::LR 0.0146153846154 --> Loss 0.00181208292643\n",
      "Epoch 38::Minibatch 374::LR 0.0146153846154 --> Loss 0.00224973201752\n",
      "Epoch 38::Minibatch 375::LR 0.0146153846154 --> Loss 0.00190266867479\n",
      "Epoch 38::Minibatch 376::LR 0.0146153846154 --> Loss 0.00117950071891\n",
      "Epoch 38::Minibatch 377::LR 0.0146153846154 --> Loss 0.00189547101657\n",
      "Epoch 38::Minibatch 378::LR 0.0146153846154 --> Loss 0.00207577109337\n",
      "Epoch 38::Minibatch 379::LR 0.0146153846154 --> Loss 0.00229716420174\n",
      "Epoch 38::Minibatch 380::LR 0.0146153846154 --> Loss 0.00154911230008\n",
      "Epoch 38::Minibatch 381::LR 0.0146153846154 --> Loss 0.0010001762708\n",
      "Epoch 38::Minibatch 382::LR 0.0146153846154 --> Loss 0.0020489893357\n",
      "Epoch 38::Minibatch 383::LR 0.0146153846154 --> Loss 0.0019946394364\n",
      "Epoch 38::Minibatch 384::LR 0.0146153846154 --> Loss 0.00114842434724\n",
      "Epoch 38::Minibatch 385::LR 0.0146153846154 --> Loss 0.00106832732757\n",
      "Epoch 38::Minibatch 386::LR 0.0146153846154 --> Loss 0.00228223303954\n",
      "Epoch 38::Minibatch 387::LR 0.0146153846154 --> Loss 0.00236643115679\n",
      "Epoch 38::Minibatch 388::LR 0.0146153846154 --> Loss 0.00123834729195\n",
      "Epoch 38::Minibatch 389::LR 0.0146153846154 --> Loss 0.00178618152936\n",
      "Epoch 38::Minibatch 390::LR 0.0146153846154 --> Loss 0.00316781520844\n",
      "Epoch 38::Minibatch 391::LR 0.0146153846154 --> Loss 0.00252164502939\n",
      "Epoch 38::Minibatch 392::LR 0.0146153846154 --> Loss 0.00253928303719\n",
      "Epoch 38::Minibatch 393::LR 0.0146153846154 --> Loss 0.0027242120107\n",
      "Epoch 38::Minibatch 394::LR 0.0146153846154 --> Loss 0.00200242420038\n",
      "Epoch 38::Minibatch 395::LR 0.0146153846154 --> Loss 0.00208519895871\n",
      "Epoch 38::Minibatch 396::LR 0.0146153846154 --> Loss 0.00195058584213\n",
      "Epoch 38::Minibatch 397::LR 0.0146153846154 --> Loss 0.00209270358086\n",
      "Epoch 38::Minibatch 398::LR 0.0146153846154 --> Loss 0.00208227058252\n",
      "Epoch 38::Minibatch 399::LR 0.0146153846154 --> Loss 0.0023820934693\n",
      "Epoch 38::Minibatch 400::LR 0.0146153846154 --> Loss 0.0020220553875\n",
      "Epoch 38::Minibatch 401::LR 0.0146153846154 --> Loss 0.00339282075564\n",
      "Epoch 38::Minibatch 402::LR 0.0146153846154 --> Loss 0.00171167433262\n",
      "Epoch 38::Minibatch 403::LR 0.0146153846154 --> Loss 0.00143424004316\n",
      "Epoch 38::Minibatch 404::LR 0.0146153846154 --> Loss 0.00130923231443\n",
      "Epoch 38::Minibatch 405::LR 0.0146153846154 --> Loss 0.00330704788367\n",
      "Epoch 38::Minibatch 406::LR 0.0146153846154 --> Loss 0.00231697281202\n",
      "Epoch 38::Minibatch 407::LR 0.0146153846154 --> Loss 0.00170929054419\n",
      "Epoch 38::Minibatch 408::LR 0.0146153846154 --> Loss 0.000436334908009\n",
      "Epoch 38::Minibatch 409::LR 0.0146153846154 --> Loss 0.00220151484013\n",
      "Epoch 38::Minibatch 410::LR 0.0146153846154 --> Loss 0.00313047726949\n",
      "Epoch 38::Minibatch 411::LR 0.0146153846154 --> Loss 0.00167944808801\n",
      "Epoch 38::Minibatch 412::LR 0.0146153846154 --> Loss 0.000942503611247\n",
      "Epoch 38::Minibatch 413::LR 0.0146153846154 --> Loss 0.00198699335257\n",
      "Epoch 38::Minibatch 414::LR 0.0146153846154 --> Loss 0.00189082384109\n",
      "Epoch 38::Minibatch 415::LR 0.0146153846154 --> Loss 0.00118710368872\n",
      "Epoch 38::Minibatch 416::LR 0.0146153846154 --> Loss 0.000788955539465\n",
      "Epoch 38::Minibatch 417::LR 0.0146153846154 --> Loss 0.00167881568273\n",
      "Epoch 38::Minibatch 418::LR 0.0146153846154 --> Loss 0.00255766789118\n",
      "Epoch 38::Minibatch 419::LR 0.0146153846154 --> Loss 0.000494290987651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 420::LR 0.0146153846154 --> Loss 0.000700849940379\n",
      "Epoch 38::Minibatch 421::LR 0.0146153846154 --> Loss 0.00186640342077\n",
      "Epoch 38::Minibatch 422::LR 0.0146153846154 --> Loss 0.00204843779405\n",
      "Epoch 38::Minibatch 423::LR 0.0146153846154 --> Loss 0.00100219547749\n",
      "Epoch 38::Minibatch 424::LR 0.0146153846154 --> Loss 0.00152684092522\n",
      "Epoch 38::Minibatch 425::LR 0.0146153846154 --> Loss 0.00285415112972\n",
      "Epoch 38::Minibatch 426::LR 0.0146153846154 --> Loss 0.00200067778428\n",
      "Epoch 38::Minibatch 427::LR 0.0146153846154 --> Loss 0.000754698018233\n",
      "Epoch 38::Minibatch 428::LR 0.0146153846154 --> Loss 0.000896183550358\n",
      "Epoch 38::Minibatch 429::LR 0.0146153846154 --> Loss 0.00221480091413\n",
      "Epoch 38::Minibatch 430::LR 0.0146153846154 --> Loss 0.00719056208928\n",
      "Epoch 38::Minibatch 431::LR 0.0146153846154 --> Loss 0.00344864885012\n",
      "Epoch 38::Minibatch 432::LR 0.0146153846154 --> Loss 0.00381830255191\n",
      "Epoch 38::Minibatch 433::LR 0.0146153846154 --> Loss 0.00253971715768\n",
      "Epoch 38::Minibatch 434::LR 0.0146153846154 --> Loss 0.00240410963694\n",
      "Epoch 38::Minibatch 435::LR 0.0146153846154 --> Loss 0.00224503676097\n",
      "Epoch 38::Minibatch 436::LR 0.0146153846154 --> Loss 0.0015708993872\n",
      "Epoch 38::Minibatch 437::LR 0.0146153846154 --> Loss 0.00272262533506\n",
      "Epoch 38::Minibatch 438::LR 0.0146153846154 --> Loss 0.00218625863393\n",
      "Epoch 38::Minibatch 439::LR 0.0146153846154 --> Loss 0.0018785427014\n",
      "Epoch 38::Minibatch 440::LR 0.0146153846154 --> Loss 0.00290169914563\n",
      "Epoch 38::Minibatch 441::LR 0.0146153846154 --> Loss 0.00271696209908\n",
      "Epoch 38::Minibatch 442::LR 0.0146153846154 --> Loss 0.00241168538729\n",
      "Epoch 38::Minibatch 443::LR 0.0146153846154 --> Loss 0.00341029206912\n",
      "Epoch 38::Minibatch 444::LR 0.0146153846154 --> Loss 0.00262126366297\n",
      "Epoch 38::Minibatch 445::LR 0.0146153846154 --> Loss 0.000837047596773\n",
      "Epoch 38::Minibatch 446::LR 0.0146153846154 --> Loss 0.0013410482804\n",
      "Epoch 38::Minibatch 447::LR 0.0146153846154 --> Loss 0.00224533756574\n",
      "Epoch 38::Minibatch 448::LR 0.0146153846154 --> Loss 0.00229479034742\n",
      "Epoch 38::Minibatch 449::LR 0.0146153846154 --> Loss 0.00352718869845\n",
      "Epoch 38::Minibatch 450::LR 0.0146153846154 --> Loss 0.0020953087012\n",
      "Epoch 38::Minibatch 451::LR 0.0146153846154 --> Loss 0.00376271923383\n",
      "Epoch 38::Minibatch 452::LR 0.0146153846154 --> Loss 0.00226507842541\n",
      "Epoch 38::Minibatch 453::LR 0.0146153846154 --> Loss 0.00034320525825\n",
      "Epoch 38::Minibatch 454::LR 0.0146153846154 --> Loss 0.00333572904269\n",
      "Epoch 38::Minibatch 455::LR 0.0146153846154 --> Loss 0.0025426864624\n",
      "Epoch 38::Minibatch 456::LR 0.0146153846154 --> Loss 0.00304191768169\n",
      "Epoch 38::Minibatch 457::LR 0.0146153846154 --> Loss 0.00186424752076\n",
      "Epoch 38::Minibatch 458::LR 0.0146153846154 --> Loss 0.000711250106494\n",
      "Epoch 38::Minibatch 459::LR 0.0146153846154 --> Loss 0.00371855815252\n",
      "Epoch 38::Minibatch 460::LR 0.0146153846154 --> Loss 0.00239509721597\n",
      "Epoch 38::Minibatch 461::LR 0.0146153846154 --> Loss 0.00360462268194\n",
      "Epoch 38::Minibatch 462::LR 0.0146153846154 --> Loss 0.000364217584332\n",
      "Epoch 38::Minibatch 463::LR 0.0146153846154 --> Loss 0.00391790270805\n",
      "Epoch 38::Minibatch 464::LR 0.0146153846154 --> Loss 0.00192438602448\n",
      "Epoch 38::Minibatch 465::LR 0.0146153846154 --> Loss 0.00428651809692\n",
      "Epoch 38::Minibatch 466::LR 0.0146153846154 --> Loss 0.0048767666022\n",
      "Epoch 38::Minibatch 467::LR 0.0146153846154 --> Loss 0.00491944630941\n",
      "Epoch 38::Minibatch 468::LR 0.0146153846154 --> Loss 0.00548619031906\n",
      "Epoch 38::Minibatch 469::LR 0.0146153846154 --> Loss 0.00579237023989\n",
      "Epoch 38::Minibatch 470::LR 0.0146153846154 --> Loss 0.00352107365926\n",
      "Epoch 38::Minibatch 471::LR 0.0146153846154 --> Loss 0.00163916846116\n",
      "Epoch 38::Minibatch 472::LR 0.0146153846154 --> Loss 0.00356577595075\n",
      "Epoch 38::Minibatch 473::LR 0.0146153846154 --> Loss 0.00231610774994\n",
      "Epoch 38::Minibatch 474::LR 0.0146153846154 --> Loss 0.000683045734962\n",
      "Epoch 38::Minibatch 475::LR 0.0146153846154 --> Loss 0.00462956865629\n",
      "Epoch 38::Minibatch 476::LR 0.0146153846154 --> Loss 0.00750471671422\n",
      "Epoch 38::Minibatch 477::LR 0.0146153846154 --> Loss 0.000911544064681\n",
      "Epoch 38::Minibatch 478::LR 0.0146153846154 --> Loss 0.00238989293575\n",
      "Epoch 38::Minibatch 479::LR 0.0146153846154 --> Loss 0.00194830238819\n",
      "Epoch 38::Minibatch 480::LR 0.0146153846154 --> Loss 0.00150030891101\n",
      "Epoch 38::Minibatch 481::LR 0.0146153846154 --> Loss 0.000958342552185\n",
      "Epoch 38::Minibatch 482::LR 0.0146153846154 --> Loss 0.00205690761407\n",
      "Epoch 38::Minibatch 483::LR 0.0146153846154 --> Loss 0.00297233899434\n",
      "Epoch 38::Minibatch 484::LR 0.0146153846154 --> Loss 0.00333031932513\n",
      "Epoch 38::Minibatch 485::LR 0.0146153846154 --> Loss 0.000758130798737\n",
      "Epoch 38::Minibatch 486::LR 0.0146153846154 --> Loss 0.00282070457935\n",
      "Epoch 38::Minibatch 487::LR 0.0146153846154 --> Loss 0.00327297687531\n",
      "Epoch 38::Minibatch 488::LR 0.0146153846154 --> Loss 0.00200481275717\n",
      "Epoch 38::Minibatch 489::LR 0.0146153846154 --> Loss 0.00306256393592\n",
      "Epoch 38::Minibatch 490::LR 0.0146153846154 --> Loss 0.000412325958411\n",
      "Epoch 38::Minibatch 491::LR 0.0146153846154 --> Loss 0.00304208815098\n",
      "Epoch 38::Minibatch 492::LR 0.0146153846154 --> Loss 0.00306179106236\n",
      "Epoch 38::Minibatch 493::LR 0.0146153846154 --> Loss 0.00300448000431\n",
      "Epoch 38::Minibatch 494::LR 0.0146153846154 --> Loss 0.000728882104158\n",
      "Epoch 38::Minibatch 495::LR 0.0146153846154 --> Loss 0.0018146977822\n",
      "Epoch 38::Minibatch 496::LR 0.0146153846154 --> Loss 0.00277119378249\n",
      "Epoch 38::Minibatch 497::LR 0.0146153846154 --> Loss 0.0009088687102\n",
      "Epoch 38::Minibatch 498::LR 0.0146153846154 --> Loss 0.000545234034459\n",
      "Epoch 38::Minibatch 499::LR 0.0146153846154 --> Loss 0.00336002985636\n",
      "Epoch 38::Minibatch 500::LR 0.0146153846154 --> Loss 0.00141917695602\n",
      "Epoch 38::Minibatch 501::LR 0.0146153846154 --> Loss 0.00195715129375\n",
      "Epoch 38::Minibatch 502::LR 0.0146153846154 --> Loss 0.0037004506588\n",
      "Epoch 38::Minibatch 503::LR 0.0146153846154 --> Loss 0.00651996254921\n",
      "Epoch 38::Minibatch 504::LR 0.0146153846154 --> Loss 0.00642081141472\n",
      "Epoch 38::Minibatch 505::LR 0.0146153846154 --> Loss 0.00381990830104\n",
      "Epoch 38::Minibatch 506::LR 0.0146153846154 --> Loss 0.00324667990208\n",
      "Epoch 38::Minibatch 507::LR 0.0146153846154 --> Loss 0.00562222202619\n",
      "Epoch 38::Minibatch 508::LR 0.0146153846154 --> Loss 0.00337383747101\n",
      "Epoch 38::Minibatch 509::LR 0.0146153846154 --> Loss 0.00415986061096\n",
      "Epoch 38::Minibatch 510::LR 0.0146153846154 --> Loss 0.00434137622515\n",
      "Epoch 38::Minibatch 511::LR 0.0146153846154 --> Loss 0.00404289682706\n",
      "Epoch 38::Minibatch 512::LR 0.0146153846154 --> Loss 0.00269015828768\n",
      "Epoch 38::Minibatch 513::LR 0.0146153846154 --> Loss 0.000586592257023\n",
      "Epoch 38::Minibatch 514::LR 0.0146153846154 --> Loss 0.00255678196748\n",
      "Epoch 38::Minibatch 515::LR 0.0146153846154 --> Loss 0.00298459450404\n",
      "Epoch 38::Minibatch 516::LR 0.0146153846154 --> Loss 0.00389239192009\n",
      "Epoch 38::Minibatch 517::LR 0.0146153846154 --> Loss 0.00365082462629\n",
      "Epoch 38::Minibatch 518::LR 0.0146153846154 --> Loss 0.0025633507967\n",
      "Epoch 38::Minibatch 519::LR 0.0146153846154 --> Loss 0.0036147514979\n",
      "Epoch 38::Minibatch 520::LR 0.0146153846154 --> Loss 0.00571055730184\n",
      "Epoch 38::Minibatch 521::LR 0.0146153846154 --> Loss 0.00579538067182\n",
      "Epoch 38::Minibatch 522::LR 0.0146153846154 --> Loss 0.00679041385651\n",
      "Epoch 38::Minibatch 523::LR 0.0146153846154 --> Loss 0.00061841994524\n",
      "Epoch 38::Minibatch 524::LR 0.0146153846154 --> Loss 0.00137567341328\n",
      "Epoch 38::Minibatch 525::LR 0.0146153846154 --> Loss 0.00298278152943\n",
      "Epoch 38::Minibatch 526::LR 0.0146153846154 --> Loss 0.0036083304882\n",
      "Epoch 38::Minibatch 527::LR 0.0146153846154 --> Loss 0.00210227529208\n",
      "Epoch 38::Minibatch 528::LR 0.0146153846154 --> Loss 0.000901244282722\n",
      "Epoch 38::Minibatch 529::LR 0.0146153846154 --> Loss 0.0037202056249\n",
      "Epoch 38::Minibatch 530::LR 0.0146153846154 --> Loss 0.00367164373398\n",
      "Epoch 38::Minibatch 531::LR 0.0146153846154 --> Loss 0.00325667043527\n",
      "Epoch 38::Minibatch 532::LR 0.0146153846154 --> Loss 0.00255122323831\n",
      "Epoch 38::Minibatch 533::LR 0.0146153846154 --> Loss 0.00483645995458\n",
      "Epoch 38::Minibatch 534::LR 0.0146153846154 --> Loss 0.003654961586\n",
      "Epoch 38::Minibatch 535::LR 0.0146153846154 --> Loss 0.00335268378258\n",
      "Epoch 38::Minibatch 536::LR 0.0146153846154 --> Loss 0.0021104858319\n",
      "Epoch 38::Minibatch 537::LR 0.0146153846154 --> Loss 0.000577232390642\n",
      "Epoch 38::Minibatch 538::LR 0.0146153846154 --> Loss 0.00161242187023\n",
      "Epoch 38::Minibatch 539::LR 0.0146153846154 --> Loss 0.00327495157719\n",
      "Epoch 38::Minibatch 540::LR 0.0146153846154 --> Loss 0.00336233019829\n",
      "Epoch 38::Minibatch 541::LR 0.0146153846154 --> Loss 0.00281673749288\n",
      "Epoch 38::Minibatch 542::LR 0.0146153846154 --> Loss 0.0024136531353\n",
      "Epoch 38::Minibatch 543::LR 0.0146153846154 --> Loss 0.00251530567805\n",
      "Epoch 38::Minibatch 544::LR 0.0146153846154 --> Loss 0.0041143989563\n",
      "Epoch 38::Minibatch 545::LR 0.0146153846154 --> Loss 0.00193109313647\n",
      "Epoch 38::Minibatch 546::LR 0.0146153846154 --> Loss 0.000662783433994\n",
      "Epoch 38::Minibatch 547::LR 0.0146153846154 --> Loss 0.0025618493557\n",
      "Epoch 38::Minibatch 548::LR 0.0146153846154 --> Loss 0.00332068105539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 549::LR 0.0146153846154 --> Loss 0.00902672767639\n",
      "Epoch 38::Minibatch 550::LR 0.0146153846154 --> Loss 0.00118976304928\n",
      "Epoch 38::Minibatch 551::LR 0.0146153846154 --> Loss 0.00246549427509\n",
      "Epoch 38::Minibatch 552::LR 0.0146153846154 --> Loss 0.00341009060542\n",
      "Epoch 38::Minibatch 553::LR 0.0146153846154 --> Loss 0.00287686983744\n",
      "Epoch 38::Minibatch 554::LR 0.0146153846154 --> Loss 0.00354116439819\n",
      "Epoch 38::Minibatch 555::LR 0.0146153846154 --> Loss 0.000925746758779\n",
      "Epoch 38::Minibatch 556::LR 0.0146153846154 --> Loss 0.00189145624638\n",
      "Epoch 38::Minibatch 557::LR 0.0146153846154 --> Loss 0.00241446276506\n",
      "Epoch 38::Minibatch 558::LR 0.0146153846154 --> Loss 0.00355802377065\n",
      "Epoch 38::Minibatch 559::LR 0.0146153846154 --> Loss 0.00364047686259\n",
      "Epoch 38::Minibatch 560::LR 0.0146153846154 --> Loss 0.00305418054263\n",
      "Epoch 38::Minibatch 561::LR 0.0146153846154 --> Loss 0.00260637680689\n",
      "Epoch 38::Minibatch 562::LR 0.0146153846154 --> Loss 0.00232739726702\n",
      "Epoch 38::Minibatch 563::LR 0.0146153846154 --> Loss 0.00393754720688\n",
      "Epoch 38::Minibatch 564::LR 0.0146153846154 --> Loss 0.00301582058271\n",
      "Epoch 38::Minibatch 565::LR 0.0146153846154 --> Loss 0.00355662624041\n",
      "Epoch 38::Minibatch 566::LR 0.0146153846154 --> Loss 0.00214102824529\n",
      "Epoch 38::Minibatch 567::LR 0.0146153846154 --> Loss 0.00254687786102\n",
      "Epoch 38::Minibatch 568::LR 0.0146153846154 --> Loss 0.00170272767544\n",
      "Epoch 38::Minibatch 569::LR 0.0146153846154 --> Loss 0.000556332270304\n",
      "Epoch 38::Minibatch 570::LR 0.0146153846154 --> Loss 0.00158585002025\n",
      "Epoch 38::Minibatch 571::LR 0.0146153846154 --> Loss 0.00198139925798\n",
      "Epoch 38::Minibatch 572::LR 0.0146153846154 --> Loss 0.0021408867836\n",
      "Epoch 38::Minibatch 573::LR 0.0146153846154 --> Loss 0.00140209496021\n",
      "Epoch 38::Minibatch 574::LR 0.0146153846154 --> Loss 0.0010390624404\n",
      "Epoch 38::Minibatch 575::LR 0.0146153846154 --> Loss 0.00168105006218\n",
      "Epoch 38::Minibatch 576::LR 0.0146153846154 --> Loss 0.0019963936011\n",
      "Epoch 38::Minibatch 577::LR 0.0146153846154 --> Loss 0.00157742351294\n",
      "Epoch 38::Minibatch 578::LR 0.0146153846154 --> Loss 0.00124522924423\n",
      "Epoch 38::Minibatch 579::LR 0.0146153846154 --> Loss 0.00116982032855\n",
      "Epoch 38::Minibatch 580::LR 0.0146153846154 --> Loss 0.00190678437551\n",
      "Epoch 38::Minibatch 581::LR 0.0146153846154 --> Loss 0.00169466058413\n",
      "Epoch 38::Minibatch 582::LR 0.0146153846154 --> Loss 0.00421489953995\n",
      "Epoch 38::Minibatch 583::LR 0.0146153846154 --> Loss 0.000954140921434\n",
      "Epoch 38::Minibatch 584::LR 0.0146153846154 --> Loss 0.00131024857362\n",
      "Epoch 38::Minibatch 585::LR 0.0146153846154 --> Loss 0.00379703442256\n",
      "Epoch 38::Minibatch 586::LR 0.0146153846154 --> Loss 0.00364110191663\n",
      "Epoch 38::Minibatch 587::LR 0.0146153846154 --> Loss 0.00110238661369\n",
      "Epoch 38::Minibatch 588::LR 0.0146153846154 --> Loss 0.00135075181723\n",
      "Epoch 38::Minibatch 589::LR 0.0146153846154 --> Loss 0.0026868702968\n",
      "Epoch 38::Minibatch 590::LR 0.0146153846154 --> Loss 0.0017413888375\n",
      "Epoch 38::Minibatch 591::LR 0.0146153846154 --> Loss 0.0025775017341\n",
      "Epoch 38::Minibatch 592::LR 0.0146153846154 --> Loss 0.00113516877095\n",
      "Epoch 38::Minibatch 593::LR 0.0146153846154 --> Loss 0.00241385380427\n",
      "Epoch 38::Minibatch 594::LR 0.0146153846154 --> Loss 0.00246630092462\n",
      "Epoch 38::Minibatch 595::LR 0.0146153846154 --> Loss 0.00302846471469\n",
      "Epoch 38::Minibatch 596::LR 0.0146153846154 --> Loss 0.00179074347019\n",
      "Epoch 38::Minibatch 597::LR 0.0146153846154 --> Loss 0.00114680826664\n",
      "Epoch 38::Minibatch 598::LR 0.0146153846154 --> Loss 0.00272463182608\n",
      "Epoch 38::Minibatch 599::LR 0.0146153846154 --> Loss 0.00176050186157\n",
      "Epoch 38::Minibatch 600::LR 0.0146153846154 --> Loss 0.00207766989867\n",
      "Epoch 38::Minibatch 601::LR 0.0146153846154 --> Loss 0.00366122166316\n",
      "Epoch 38::Minibatch 602::LR 0.0146153846154 --> Loss 0.00206368823846\n",
      "Epoch 38::Minibatch 603::LR 0.0146153846154 --> Loss 0.0026051312685\n",
      "Epoch 38::Minibatch 604::LR 0.0146153846154 --> Loss 0.00161076356967\n",
      "Epoch 38::Minibatch 605::LR 0.0146153846154 --> Loss 0.0022323568662\n",
      "Epoch 38::Minibatch 606::LR 0.0146153846154 --> Loss 0.00181217928727\n",
      "Epoch 38::Minibatch 607::LR 0.0146153846154 --> Loss 0.000813933312893\n",
      "Epoch 38::Minibatch 608::LR 0.0146153846154 --> Loss 0.0015292284886\n",
      "Epoch 38::Minibatch 609::LR 0.0146153846154 --> Loss 0.00242123921712\n",
      "Epoch 38::Minibatch 610::LR 0.0146153846154 --> Loss 0.00406102856\n",
      "Epoch 38::Minibatch 611::LR 0.0146153846154 --> Loss 0.00272294660409\n",
      "Epoch 38::Minibatch 612::LR 0.0146153846154 --> Loss 0.000466916710138\n",
      "Epoch 38::Minibatch 613::LR 0.0146153846154 --> Loss 0.00131225417058\n",
      "Epoch 38::Minibatch 614::LR 0.0146153846154 --> Loss 0.0023771293958\n",
      "Epoch 38::Minibatch 615::LR 0.0146153846154 --> Loss 0.00163190792004\n",
      "Epoch 38::Minibatch 616::LR 0.0146153846154 --> Loss 0.000909058451653\n",
      "Epoch 38::Minibatch 617::LR 0.0146153846154 --> Loss 0.000489306350549\n",
      "Epoch 38::Minibatch 618::LR 0.0146153846154 --> Loss 0.0030023008585\n",
      "Epoch 38::Minibatch 619::LR 0.0146153846154 --> Loss 0.00192538738251\n",
      "Epoch 38::Minibatch 620::LR 0.0146153846154 --> Loss 0.00166742324829\n",
      "Epoch 38::Minibatch 621::LR 0.0146153846154 --> Loss 0.000838495095571\n",
      "Epoch 38::Minibatch 622::LR 0.0146153846154 --> Loss 0.000772789865732\n",
      "Epoch 38::Minibatch 623::LR 0.0146153846154 --> Loss 0.00221091071765\n",
      "Epoch 38::Minibatch 624::LR 0.0146153846154 --> Loss 0.00174878120422\n",
      "Epoch 38::Minibatch 625::LR 0.0146153846154 --> Loss 0.00257352073987\n",
      "Epoch 38::Minibatch 626::LR 0.0146153846154 --> Loss 0.00332506855329\n",
      "Epoch 38::Minibatch 627::LR 0.0146153846154 --> Loss 0.00125405073166\n",
      "Epoch 38::Minibatch 628::LR 0.0146153846154 --> Loss 0.00087100515763\n",
      "Epoch 38::Minibatch 629::LR 0.0146153846154 --> Loss 0.00292518397172\n",
      "Epoch 38::Minibatch 630::LR 0.0146153846154 --> Loss 0.00287394384543\n",
      "Epoch 38::Minibatch 631::LR 0.0146153846154 --> Loss 0.00475045959155\n",
      "Epoch 38::Minibatch 632::LR 0.0146153846154 --> Loss 0.000798454234997\n",
      "Epoch 38::Minibatch 633::LR 0.0146153846154 --> Loss 0.00159283041954\n",
      "Epoch 38::Minibatch 634::LR 0.0146153846154 --> Loss 0.00313304066658\n",
      "Epoch 38::Minibatch 635::LR 0.0146153846154 --> Loss 0.0052321434021\n",
      "Epoch 38::Minibatch 636::LR 0.0146153846154 --> Loss 0.00440352161725\n",
      "Epoch 38::Minibatch 637::LR 0.0146153846154 --> Loss 0.000695958385865\n",
      "Epoch 38::Minibatch 638::LR 0.0146153846154 --> Loss 0.00149151871602\n",
      "Epoch 38::Minibatch 639::LR 0.0146153846154 --> Loss 0.00313895682494\n",
      "Epoch 38::Minibatch 640::LR 0.0146153846154 --> Loss 0.00435267647107\n",
      "Epoch 38::Minibatch 641::LR 0.0146153846154 --> Loss 0.00298093398412\n",
      "Epoch 38::Minibatch 642::LR 0.0146153846154 --> Loss 0.00053337196509\n",
      "Epoch 38::Minibatch 643::LR 0.0146153846154 --> Loss 0.00229346513748\n",
      "Epoch 38::Minibatch 644::LR 0.0146153846154 --> Loss 0.00380982597669\n",
      "Epoch 38::Minibatch 645::LR 0.0146153846154 --> Loss 0.00457819064458\n",
      "Epoch 38::Minibatch 646::LR 0.0146153846154 --> Loss 0.00152159521977\n",
      "Epoch 38::Minibatch 647::LR 0.0146153846154 --> Loss 0.000457461178303\n",
      "Epoch 38::Minibatch 648::LR 0.0146153846154 --> Loss 0.0026552549998\n",
      "Epoch 38::Minibatch 649::LR 0.0146153846154 --> Loss 0.00301790177822\n",
      "Epoch 38::Minibatch 650::LR 0.0146153846154 --> Loss 0.00303173482418\n",
      "Epoch 38::Minibatch 651::LR 0.0146153846154 --> Loss 0.00130161782106\n",
      "Epoch 38::Minibatch 652::LR 0.0146153846154 --> Loss 0.000780028005441\n",
      "Epoch 38::Minibatch 653::LR 0.0146153846154 --> Loss 0.00276221791903\n",
      "Epoch 38::Minibatch 654::LR 0.0146153846154 --> Loss 0.00307702839375\n",
      "Epoch 38::Minibatch 655::LR 0.0146153846154 --> Loss 0.00369269609451\n",
      "Epoch 38::Minibatch 656::LR 0.0146153846154 --> Loss 0.00075878004233\n",
      "Epoch 38::Minibatch 657::LR 0.0146153846154 --> Loss 0.00225429733594\n",
      "Epoch 38::Minibatch 658::LR 0.0146153846154 --> Loss 0.00430054664612\n",
      "Epoch 38::Minibatch 659::LR 0.0146153846154 --> Loss 0.00216474552949\n",
      "Epoch 38::Minibatch 660::LR 0.0146153846154 --> Loss 0.00264130135377\n",
      "Epoch 38::Minibatch 661::LR 0.0146153846154 --> Loss 0.002179317077\n",
      "Epoch 38::Minibatch 662::LR 0.0146153846154 --> Loss 0.00178382297357\n",
      "Epoch 38::Minibatch 663::LR 0.0146153846154 --> Loss 0.00355707844098\n",
      "Epoch 38::Minibatch 664::LR 0.0146153846154 --> Loss 0.0030018577973\n",
      "Epoch 38::Minibatch 665::LR 0.0146153846154 --> Loss 0.000689338892698\n",
      "Epoch 38::Minibatch 666::LR 0.0146153846154 --> Loss 0.00389451225599\n",
      "Epoch 38::Minibatch 667::LR 0.0146153846154 --> Loss 0.00254737317562\n",
      "Epoch 38::Minibatch 668::LR 0.0146153846154 --> Loss 0.00604717890422\n",
      "Epoch 38::Minibatch 669::LR 0.0146153846154 --> Loss 0.00107220421235\n",
      "Epoch 38::Minibatch 670::LR 0.0146153846154 --> Loss 0.00131759474675\n",
      "Epoch 38::Minibatch 671::LR 0.0146153846154 --> Loss 0.00498895287514\n",
      "Epoch 38::Minibatch 672::LR 0.0146153846154 --> Loss 0.0032497860988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 673::LR 0.0146153846154 --> Loss 0.00158560007811\n",
      "Epoch 38::Minibatch 674::LR 0.0146153846154 --> Loss 0.000510719219844\n",
      "Epoch 38::Minibatch 675::LR 0.0146153846154 --> Loss 0.00219815075397\n",
      "Epoch 38::Minibatch 676::LR 0.0146153846154 --> Loss 0.00218464275201\n",
      "Epoch 38::Minibatch 677::LR 0.0146153846154 --> Loss 0.00265948275725\n",
      "Epoch 38::Minibatch 678::LR 0.0146153846154 --> Loss 0.00184195717176\n",
      "Epoch 38::Minibatch 679::LR 0.0146153846154 --> Loss 0.00324944218\n",
      "Epoch 38::Minibatch 680::LR 0.0146153846154 --> Loss 0.00210988998413\n",
      "Epoch 38::Minibatch 681::LR 0.0146153846154 --> Loss 0.00234239220619\n",
      "Epoch 38::Minibatch 682::LR 0.0146153846154 --> Loss 0.000762031773726\n",
      "Epoch 38::Minibatch 683::LR 0.0146153846154 --> Loss 0.00224997798602\n",
      "Epoch 38::Minibatch 684::LR 0.0146153846154 --> Loss 0.00234390576681\n",
      "Epoch 38::Minibatch 685::LR 0.0146153846154 --> Loss 0.00278556863467\n",
      "Epoch 38::Minibatch 686::LR 0.0146153846154 --> Loss 0.00157761543989\n",
      "Epoch 38::Minibatch 687::LR 0.0146153846154 --> Loss 0.00087876200676\n",
      "Epoch 38::Minibatch 688::LR 0.0146153846154 --> Loss 0.00281253178914\n",
      "Epoch 38::Minibatch 689::LR 0.0146153846154 --> Loss 0.00244411389033\n",
      "Epoch 38::Minibatch 690::LR 0.0146153846154 --> Loss 0.00185103038947\n",
      "Epoch 38::Minibatch 691::LR 0.0146153846154 --> Loss 0.000657445689042\n",
      "Epoch 38::Minibatch 692::LR 0.0146153846154 --> Loss 0.00243167837461\n",
      "Epoch 38::Minibatch 693::LR 0.0146153846154 --> Loss 0.00263953089714\n",
      "Epoch 38::Minibatch 694::LR 0.0146153846154 --> Loss 0.00296791136265\n",
      "Epoch 38::Minibatch 695::LR 0.0146153846154 --> Loss 0.00182435750961\n",
      "Epoch 38::Minibatch 696::LR 0.0146153846154 --> Loss 0.00201708614826\n",
      "Epoch 38::Minibatch 697::LR 0.0146153846154 --> Loss 0.00139560341835\n",
      "Epoch 38::Minibatch 698::LR 0.0146153846154 --> Loss 0.00166882137458\n",
      "Epoch 38::Minibatch 699::LR 0.0146153846154 --> Loss 0.00363596836726\n",
      "Epoch 38::Minibatch 700::LR 0.0146153846154 --> Loss 0.00251810789108\n",
      "Epoch 38::Minibatch 701::LR 0.0146153846154 --> Loss 0.00184757669767\n",
      "Epoch 38::Minibatch 702::LR 0.0146153846154 --> Loss 0.00167236228784\n",
      "Epoch 38::Minibatch 703::LR 0.0146153846154 --> Loss 0.0042192987601\n",
      "Epoch 38::Minibatch 704::LR 0.0146153846154 --> Loss 0.00180674374104\n",
      "Epoch 38::Minibatch 705::LR 0.0146153846154 --> Loss 0.00279953678449\n",
      "Epoch 38::Minibatch 706::LR 0.0146153846154 --> Loss 0.00217341780663\n",
      "Epoch 38::Minibatch 707::LR 0.0146153846154 --> Loss 0.0011855901281\n",
      "Epoch 38::Minibatch 708::LR 0.0146153846154 --> Loss 0.00173013011614\n",
      "Epoch 38::Minibatch 709::LR 0.0146153846154 --> Loss 0.00166469325622\n",
      "Epoch 38::Minibatch 710::LR 0.0146153846154 --> Loss 0.00259027838707\n",
      "Epoch 38::Minibatch 711::LR 0.0146153846154 --> Loss 0.00199886798859\n",
      "Epoch 38::Minibatch 712::LR 0.0146153846154 --> Loss 0.00138683448235\n",
      "Epoch 38::Minibatch 713::LR 0.0146153846154 --> Loss 0.001817334493\n",
      "Epoch 38::Minibatch 714::LR 0.0146153846154 --> Loss 0.00290019989014\n",
      "Epoch 38::Minibatch 715::LR 0.0146153846154 --> Loss 0.0029008736213\n",
      "Epoch 38::Minibatch 716::LR 0.0146153846154 --> Loss 0.0016822830836\n",
      "Epoch 38::Minibatch 717::LR 0.0146153846154 --> Loss 0.00169008175532\n",
      "Epoch 38::Minibatch 718::LR 0.0146153846154 --> Loss 0.0012952965498\n",
      "Epoch 38::Minibatch 719::LR 0.0146153846154 --> Loss 0.00175134440263\n",
      "Epoch 38::Minibatch 720::LR 0.0146153846154 --> Loss 0.00284387211005\n",
      "Epoch 38::Minibatch 721::LR 0.0146153846154 --> Loss 0.00060640056928\n",
      "Epoch 38::Minibatch 722::LR 0.0146153846154 --> Loss 0.00449694474538\n",
      "Epoch 38::Minibatch 723::LR 0.0146153846154 --> Loss 0.00474676728249\n",
      "Epoch 38::Minibatch 724::LR 0.0146153846154 --> Loss 0.000965389112631\n",
      "Epoch 38::Minibatch 725::LR 0.0146153846154 --> Loss 0.00200527509054\n",
      "Epoch 38::Minibatch 726::LR 0.0146153846154 --> Loss 0.00330582757791\n",
      "Epoch 38::Minibatch 727::LR 0.0146153846154 --> Loss 0.00290433704853\n",
      "Epoch 38::Minibatch 728::LR 0.0146153846154 --> Loss 0.000642202397188\n",
      "Epoch 38::Minibatch 729::LR 0.0146153846154 --> Loss 0.000711846252282\n",
      "Epoch 38::Minibatch 730::LR 0.0146153846154 --> Loss 0.00287269373735\n",
      "Epoch 38::Minibatch 731::LR 0.0146153846154 --> Loss 0.00263139267763\n",
      "Epoch 38::Minibatch 732::LR 0.0146153846154 --> Loss 0.00197359502316\n",
      "Epoch 38::Minibatch 733::LR 0.0146153846154 --> Loss 0.000570012827714\n",
      "Epoch 38::Minibatch 734::LR 0.0146153846154 --> Loss 0.00161118934552\n",
      "Epoch 38::Minibatch 735::LR 0.0146153846154 --> Loss 0.00253345072269\n",
      "Epoch 38::Minibatch 736::LR 0.0146153846154 --> Loss 0.00347067117691\n",
      "Epoch 38::Minibatch 737::LR 0.0146153846154 --> Loss 0.0028320668141\n",
      "Epoch 38::Minibatch 738::LR 0.0146153846154 --> Loss 0.00128264288108\n",
      "Epoch 38::Minibatch 739::LR 0.0146153846154 --> Loss 0.00229551017284\n",
      "Epoch 38::Minibatch 740::LR 0.0146153846154 --> Loss 0.00371873537699\n",
      "Epoch 38::Minibatch 741::LR 0.0146153846154 --> Loss 0.00247510115306\n",
      "Epoch 38::Minibatch 742::LR 0.0146153846154 --> Loss 0.00204491376877\n",
      "Epoch 38::Minibatch 743::LR 0.0146153846154 --> Loss 0.00151696165403\n",
      "Epoch 38::Minibatch 744::LR 0.0146153846154 --> Loss 0.00189798474312\n",
      "Epoch 38::Minibatch 745::LR 0.0146153846154 --> Loss 0.00274923106035\n",
      "Epoch 38::Minibatch 746::LR 0.0146153846154 --> Loss 0.00279071112474\n",
      "Epoch 38::Minibatch 747::LR 0.0146153846154 --> Loss 0.00173819283644\n",
      "Epoch 38::Minibatch 748::LR 0.0146153846154 --> Loss 0.000624168862899\n",
      "Epoch 38::Minibatch 749::LR 0.0146153846154 --> Loss 0.00168865740299\n",
      "Epoch 38::Minibatch 750::LR 0.0146153846154 --> Loss 0.00239935676257\n",
      "Epoch 38::Minibatch 751::LR 0.0146153846154 --> Loss 0.00300266742706\n",
      "Epoch 38::Minibatch 752::LR 0.0146153846154 --> Loss 0.00154712597529\n",
      "Epoch 38::Minibatch 753::LR 0.0146153846154 --> Loss 0.00219960371653\n",
      "Epoch 38::Minibatch 754::LR 0.0146153846154 --> Loss 0.00243530770143\n",
      "Epoch 38::Minibatch 755::LR 0.0146153846154 --> Loss 0.0026476709048\n",
      "Epoch 38::Minibatch 756::LR 0.0146153846154 --> Loss 0.00127983768781\n",
      "Epoch 38::Minibatch 757::LR 0.0146153846154 --> Loss 0.00055168201526\n",
      "Epoch 38::Minibatch 758::LR 0.0146153846154 --> Loss 0.00156218846639\n",
      "Epoch 38::Minibatch 759::LR 0.0146153846154 --> Loss 0.0032425904274\n",
      "Epoch 38::Minibatch 760::LR 0.0146153846154 --> Loss 0.00271860698859\n",
      "Epoch 38::Minibatch 761::LR 0.0146153846154 --> Loss 0.00521176298459\n",
      "Epoch 38::Minibatch 762::LR 0.0146153846154 --> Loss 0.00342820088069\n",
      "Epoch 38::Minibatch 763::LR 0.0146153846154 --> Loss 0.00334617813428\n",
      "Epoch 38::Minibatch 764::LR 0.0146153846154 --> Loss 0.00295984347661\n",
      "Epoch 38::Minibatch 765::LR 0.0146153846154 --> Loss 0.00121780018012\n",
      "Epoch 38::Minibatch 766::LR 0.0146153846154 --> Loss 0.00228892664115\n",
      "Epoch 38::Minibatch 767::LR 0.0146153846154 --> Loss 0.00464865724246\n",
      "Epoch 38::Minibatch 768::LR 0.0146153846154 --> Loss 0.00358699719111\n",
      "Epoch 38::Minibatch 769::LR 0.0146153846154 --> Loss 0.00180482149124\n",
      "Epoch 38::Minibatch 770::LR 0.0146153846154 --> Loss 0.00150941520929\n",
      "Epoch 38::Minibatch 771::LR 0.0146153846154 --> Loss 0.00327456116676\n",
      "Epoch 38::Minibatch 772::LR 0.0146153846154 --> Loss 0.00365389347076\n",
      "Epoch 38::Minibatch 773::LR 0.0146153846154 --> Loss 0.0031873947382\n",
      "Epoch 38::Minibatch 774::LR 0.0146153846154 --> Loss 0.00190568546454\n",
      "Epoch 38::Minibatch 775::LR 0.0146153846154 --> Loss 0.00311107099056\n",
      "Epoch 38::Minibatch 776::LR 0.0146153846154 --> Loss 0.00392239054044\n",
      "Epoch 38::Minibatch 777::LR 0.0146153846154 --> Loss 0.00566858649254\n",
      "Epoch 38::Minibatch 778::LR 0.0146153846154 --> Loss 0.00651714166005\n",
      "Epoch 38::Minibatch 779::LR 0.0146153846154 --> Loss 0.00247855603695\n",
      "Epoch 38::Minibatch 780::LR 0.0146153846154 --> Loss 0.00147213468949\n",
      "Epoch 38::Minibatch 781::LR 0.0146153846154 --> Loss 0.00348974704742\n",
      "Epoch 38::Minibatch 782::LR 0.0146153846154 --> Loss 0.00385248621305\n",
      "Epoch 38::Minibatch 783::LR 0.0146153846154 --> Loss 0.00225906213125\n",
      "Epoch 38::Minibatch 784::LR 0.0146153846154 --> Loss 0.000712560911973\n",
      "Epoch 38::Minibatch 785::LR 0.0146153846154 --> Loss 0.00355204661687\n",
      "Epoch 38::Minibatch 786::LR 0.0146153846154 --> Loss 0.00371081153552\n",
      "Epoch 38::Minibatch 787::LR 0.0146153846154 --> Loss 0.00257206201553\n",
      "Epoch 38::Minibatch 788::LR 0.0146153846154 --> Loss 0.00248109062513\n",
      "Epoch 38::Minibatch 789::LR 0.0146153846154 --> Loss 0.000722309301297\n",
      "Epoch 38::Minibatch 790::LR 0.0146153846154 --> Loss 0.00318416337172\n",
      "Epoch 38::Minibatch 791::LR 0.0146153846154 --> Loss 0.0031937088569\n",
      "Epoch 38::Minibatch 792::LR 0.0146153846154 --> Loss 0.00299296140671\n",
      "Epoch 38::Minibatch 793::LR 0.0146153846154 --> Loss 0.00161825189988\n",
      "Epoch 38::Minibatch 794::LR 0.0146153846154 --> Loss 0.00098260362943\n",
      "Epoch 38::Minibatch 795::LR 0.0146153846154 --> Loss 0.0025787371397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 796::LR 0.0146153846154 --> Loss 0.00460859497388\n",
      "Epoch 38::Minibatch 797::LR 0.0146153846154 --> Loss 0.00543807784716\n",
      "Epoch 38::Minibatch 798::LR 0.0146153846154 --> Loss 0.00292602837086\n",
      "Epoch 38::Minibatch 799::LR 0.0146153846154 --> Loss 0.00223402202129\n",
      "Epoch 38::Minibatch 800::LR 0.0146153846154 --> Loss 0.00199625750383\n",
      "Epoch 38::Minibatch 801::LR 0.0146153846154 --> Loss 0.00372004548709\n",
      "Epoch 38::Minibatch 802::LR 0.0146153846154 --> Loss 0.00117357780536\n",
      "Epoch 38::Minibatch 803::LR 0.0146153846154 --> Loss 0.00297051588694\n",
      "Epoch 38::Minibatch 804::LR 0.0146153846154 --> Loss 0.00205096423626\n",
      "Epoch 38::Minibatch 805::LR 0.0146153846154 --> Loss 0.0021681557099\n",
      "Epoch 38::Minibatch 806::LR 0.0146153846154 --> Loss 0.00323138654232\n",
      "Epoch 38::Minibatch 807::LR 0.0146153846154 --> Loss 0.0030504177014\n",
      "Epoch 38::Minibatch 808::LR 0.0146153846154 --> Loss 0.00287626047929\n",
      "Epoch 38::Minibatch 809::LR 0.0146153846154 --> Loss 0.00291599810123\n",
      "Epoch 38::Minibatch 810::LR 0.0146153846154 --> Loss 0.00395202795664\n",
      "Epoch 38::Minibatch 811::LR 0.0146153846154 --> Loss 0.00380073626836\n",
      "Epoch 38::Minibatch 812::LR 0.0146153846154 --> Loss 0.00352043032646\n",
      "Epoch 38::Minibatch 813::LR 0.0146153846154 --> Loss 0.00289069275061\n",
      "Epoch 38::Minibatch 814::LR 0.0146153846154 --> Loss 0.0014910124739\n",
      "Epoch 38::Minibatch 815::LR 0.0146153846154 --> Loss 0.00340751409531\n",
      "Epoch 38::Minibatch 816::LR 0.0146153846154 --> Loss 0.00386695742607\n",
      "Epoch 38::Minibatch 817::LR 0.0146153846154 --> Loss 0.00450215101242\n",
      "Epoch 38::Minibatch 818::LR 0.0146153846154 --> Loss 0.00122829804818\n",
      "Epoch 38::Minibatch 819::LR 0.0146153846154 --> Loss 0.000732972621918\n",
      "Epoch 38::Minibatch 820::LR 0.0146153846154 --> Loss 0.00495372891426\n",
      "Epoch 38::Minibatch 821::LR 0.0146153846154 --> Loss 0.00306904911995\n",
      "Epoch 38::Minibatch 822::LR 0.0146153846154 --> Loss 0.00367607871691\n",
      "Epoch 38::Minibatch 823::LR 0.0146153846154 --> Loss 0.00124674161275\n",
      "Epoch 38::Minibatch 824::LR 0.0146153846154 --> Loss 0.00137307008108\n",
      "Epoch 38::Minibatch 825::LR 0.0146153846154 --> Loss 0.00379692236582\n",
      "Epoch 38::Minibatch 826::LR 0.0146153846154 --> Loss 0.00449852903684\n",
      "Epoch 38::Minibatch 827::LR 0.0146153846154 --> Loss 0.00205365896225\n",
      "Epoch 38::Minibatch 828::LR 0.0146153846154 --> Loss 0.000485855291287\n",
      "Epoch 38::Minibatch 829::LR 0.0146153846154 --> Loss 0.00225800991058\n",
      "Epoch 38::Minibatch 830::LR 0.0146153846154 --> Loss 0.00386436581612\n",
      "Epoch 38::Minibatch 831::LR 0.0146153846154 --> Loss 0.00232635935148\n",
      "Epoch 38::Minibatch 832::LR 0.0146153846154 --> Loss 0.0020550908645\n",
      "Epoch 38::Minibatch 833::LR 0.0146153846154 --> Loss 0.00179657379786\n",
      "Epoch 38::Minibatch 834::LR 0.0146153846154 --> Loss 0.000792980541786\n",
      "Epoch 38::Minibatch 835::LR 0.0146153846154 --> Loss 0.00385922114054\n",
      "Epoch 38::Minibatch 836::LR 0.0146153846154 --> Loss 0.00356767614683\n",
      "Epoch 38::Minibatch 837::LR 0.0146153846154 --> Loss 0.00228332539399\n",
      "Epoch 38::Minibatch 838::LR 0.0146153846154 --> Loss 0.00065199320515\n",
      "Epoch 38::Minibatch 839::LR 0.0146153846154 --> Loss 0.00232970217864\n",
      "Epoch 38::Minibatch 840::LR 0.0146153846154 --> Loss 0.00284412960211\n",
      "Epoch 38::Minibatch 841::LR 0.0146153846154 --> Loss 0.00274582008521\n",
      "Epoch 38::Minibatch 842::LR 0.0146153846154 --> Loss 0.00211089114348\n",
      "Epoch 38::Minibatch 843::LR 0.0146153846154 --> Loss 0.000963004132112\n",
      "Epoch 38::Minibatch 844::LR 0.0146153846154 --> Loss 0.00146145433187\n",
      "Epoch 38::Minibatch 845::LR 0.0146153846154 --> Loss 0.0039088110129\n",
      "Epoch 38::Minibatch 846::LR 0.0146153846154 --> Loss 0.00167189578215\n",
      "Epoch 38::Minibatch 847::LR 0.0146153846154 --> Loss 0.00239548544089\n",
      "Epoch 38::Minibatch 848::LR 0.0146153846154 --> Loss 0.00116358151038\n",
      "Epoch 38::Minibatch 849::LR 0.0146153846154 --> Loss 0.0017872329553\n",
      "Epoch 38::Minibatch 850::LR 0.0146153846154 --> Loss 0.00316490352154\n",
      "Epoch 38::Minibatch 851::LR 0.0146153846154 --> Loss 0.00251385748386\n",
      "Epoch 38::Minibatch 852::LR 0.0146153846154 --> Loss 0.00115279416243\n",
      "Epoch 38::Minibatch 853::LR 0.0146153846154 --> Loss 0.00130763024092\n",
      "Epoch 38::Minibatch 854::LR 0.0146153846154 --> Loss 0.00251455903053\n",
      "Epoch 38::Minibatch 855::LR 0.0146153846154 --> Loss 0.00209412276745\n",
      "Epoch 38::Minibatch 856::LR 0.0146153846154 --> Loss 0.00177108705044\n",
      "Epoch 38::Minibatch 857::LR 0.0146153846154 --> Loss 0.00120494772991\n",
      "Epoch 38::Minibatch 858::LR 0.0146153846154 --> Loss 0.000605298330386\n",
      "Epoch 38::Minibatch 859::LR 0.0146153846154 --> Loss 0.00200393994649\n",
      "Epoch 38::Minibatch 860::LR 0.0146153846154 --> Loss 0.00131382097801\n",
      "Epoch 38::Minibatch 861::LR 0.0146153846154 --> Loss 0.000949460963408\n",
      "Epoch 38::Minibatch 862::LR 0.0146153846154 --> Loss 0.00373407721519\n",
      "Epoch 38::Minibatch 863::LR 0.0146153846154 --> Loss 0.00334900061289\n",
      "Epoch 38::Minibatch 864::LR 0.0146153846154 --> Loss 0.00258275866508\n",
      "Epoch 38::Minibatch 865::LR 0.0146153846154 --> Loss 0.00054738347729\n",
      "Epoch 38::Minibatch 866::LR 0.0146153846154 --> Loss 0.00205923398336\n",
      "Epoch 38::Minibatch 867::LR 0.0146153846154 --> Loss 0.00285192410151\n",
      "Epoch 38::Minibatch 868::LR 0.0146153846154 --> Loss 0.00245104511579\n",
      "Epoch 38::Minibatch 869::LR 0.0146153846154 --> Loss 0.00214741567771\n",
      "Epoch 38::Minibatch 870::LR 0.0146153846154 --> Loss 0.00315781931082\n",
      "Epoch 38::Minibatch 871::LR 0.0146153846154 --> Loss 0.00165711760521\n",
      "Epoch 38::Minibatch 872::LR 0.0146153846154 --> Loss 0.00207182566325\n",
      "Epoch 38::Minibatch 873::LR 0.0146153846154 --> Loss 0.00246533870697\n",
      "Epoch 38::Minibatch 874::LR 0.0146153846154 --> Loss 0.00481342275937\n",
      "Epoch 38::Minibatch 875::LR 0.0146153846154 --> Loss 0.000681882848342\n",
      "Epoch 38::Minibatch 876::LR 0.0146153846154 --> Loss 0.00261106193066\n",
      "Epoch 38::Minibatch 877::LR 0.0146153846154 --> Loss 0.00411528507868\n",
      "Epoch 38::Minibatch 878::LR 0.0146153846154 --> Loss 0.00280367294947\n",
      "Epoch 38::Minibatch 879::LR 0.0146153846154 --> Loss 0.00383663972219\n",
      "Epoch 38::Minibatch 880::LR 0.0146153846154 --> Loss 0.00487469553947\n",
      "Epoch 38::Minibatch 881::LR 0.0146153846154 --> Loss 0.00410251140594\n",
      "Epoch 38::Minibatch 882::LR 0.0146153846154 --> Loss 0.00187523285548\n",
      "Epoch 38::Minibatch 883::LR 0.0146153846154 --> Loss 0.00365771015485\n",
      "Epoch 38::Minibatch 884::LR 0.0146153846154 --> Loss 0.00282048245271\n",
      "Epoch 38::Minibatch 885::LR 0.0146153846154 --> Loss 0.00258777717749\n",
      "Epoch 38::Minibatch 886::LR 0.0146153846154 --> Loss 0.000442675054073\n",
      "Epoch 38::Minibatch 887::LR 0.0146153846154 --> Loss 0.00563004652659\n",
      "Epoch 38::Minibatch 888::LR 0.0146153846154 --> Loss 0.00240594307582\n",
      "Epoch 38::Minibatch 889::LR 0.0146153846154 --> Loss 0.00246364295483\n",
      "Epoch 38::Minibatch 890::LR 0.0146153846154 --> Loss 0.00353566249212\n",
      "Epoch 38::Minibatch 891::LR 0.0146153846154 --> Loss 0.00167875051498\n",
      "Epoch 38::Minibatch 892::LR 0.0146153846154 --> Loss 0.000776332567135\n",
      "Epoch 38::Minibatch 893::LR 0.0146153846154 --> Loss 0.00220871508121\n",
      "Epoch 38::Minibatch 894::LR 0.0146153846154 --> Loss 0.00193257192771\n",
      "Epoch 38::Minibatch 895::LR 0.0146153846154 --> Loss 0.00224059740702\n",
      "Epoch 38::Minibatch 896::LR 0.0146153846154 --> Loss 0.00126088619232\n",
      "Epoch 38::Minibatch 897::LR 0.0146153846154 --> Loss 0.000663121094306\n",
      "Epoch 38::Minibatch 898::LR 0.0146153846154 --> Loss 0.00192006647587\n",
      "Epoch 38::Minibatch 899::LR 0.0146153846154 --> Loss 0.00243515590827\n",
      "Epoch 38::Minibatch 900::LR 0.0146153846154 --> Loss 0.00297828018665\n",
      "Epoch 38::Minibatch 901::LR 0.0146153846154 --> Loss 0.000584232558807\n",
      "Epoch 38::Minibatch 902::LR 0.0146153846154 --> Loss 0.00138508508603\n",
      "Epoch 38::Minibatch 903::LR 0.0146153846154 --> Loss 0.00256247619788\n",
      "Epoch 38::Minibatch 904::LR 0.0146153846154 --> Loss 0.00179785827796\n",
      "Epoch 38::Minibatch 905::LR 0.0146153846154 --> Loss 0.00138495435317\n",
      "Epoch 38::Minibatch 906::LR 0.0146153846154 --> Loss 0.00100995033979\n",
      "Epoch 38::Minibatch 907::LR 0.0146153846154 --> Loss 0.00153562923272\n",
      "Epoch 38::Minibatch 908::LR 0.0146153846154 --> Loss 0.00206997295221\n",
      "Epoch 38::Minibatch 909::LR 0.0146153846154 --> Loss 0.00192785441875\n",
      "Epoch 38::Minibatch 910::LR 0.0146153846154 --> Loss 0.000840438206991\n",
      "Epoch 38::Minibatch 911::LR 0.0146153846154 --> Loss 0.00128249794245\n",
      "Epoch 38::Minibatch 912::LR 0.0146153846154 --> Loss 0.00208676993847\n",
      "Epoch 38::Minibatch 913::LR 0.0146153846154 --> Loss 0.00233520110448\n",
      "Epoch 38::Minibatch 914::LR 0.0146153846154 --> Loss 0.00129136711359\n",
      "Epoch 38::Minibatch 915::LR 0.0146153846154 --> Loss 0.000547054459651\n",
      "Epoch 38::Minibatch 916::LR 0.0146153846154 --> Loss 0.00194514254729\n",
      "Epoch 38::Minibatch 917::LR 0.0146153846154 --> Loss 0.0030530244112\n",
      "Epoch 38::Minibatch 918::LR 0.0146153846154 --> Loss 0.0039843471845\n",
      "Epoch 38::Minibatch 919::LR 0.0146153846154 --> Loss 0.000566303233306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 920::LR 0.0146153846154 --> Loss 0.0109798089663\n",
      "Epoch 38::Minibatch 921::LR 0.0146153846154 --> Loss 0.00303891619047\n",
      "Epoch 38::Minibatch 922::LR 0.0146153846154 --> Loss 0.00302710493406\n",
      "Epoch 38::Minibatch 923::LR 0.0146153846154 --> Loss 0.00109867890676\n",
      "Epoch 38::Minibatch 924::LR 0.0146153846154 --> Loss 0.00316028058529\n",
      "Epoch 38::Minibatch 925::LR 0.0146153846154 --> Loss 0.00222945531209\n",
      "Epoch 38::Minibatch 926::LR 0.0146153846154 --> Loss 0.00426375548045\n",
      "Epoch 38::Minibatch 927::LR 0.0146153846154 --> Loss 0.00453786333402\n",
      "Epoch 38::Minibatch 928::LR 0.0146153846154 --> Loss 0.00579992214839\n",
      "Epoch 38::Minibatch 929::LR 0.0146153846154 --> Loss 0.00484803279241\n",
      "Epoch 38::Minibatch 930::LR 0.0146153846154 --> Loss 0.00917719443639\n",
      "Epoch 38::Minibatch 931::LR 0.0146153846154 --> Loss 0.00292900264263\n",
      "Epoch 38::Minibatch 932::LR 0.0146153846154 --> Loss 0.00493978222211\n",
      "Epoch 38::Minibatch 933::LR 0.0146153846154 --> Loss 0.00220941940943\n",
      "Epoch 38::Minibatch 934::LR 0.0146153846154 --> Loss 0.0027094467481\n",
      "Epoch 38::Minibatch 935::LR 0.0146153846154 --> Loss 0.00411181926727\n",
      "Epoch 38::Minibatch 936::LR 0.0146153846154 --> Loss 0.000730568667253\n",
      "Epoch 38::Minibatch 937::LR 0.0146153846154 --> Loss 0.00214975853761\n",
      "Epoch 38::Minibatch 938::LR 0.0146153846154 --> Loss 0.00179502348105\n",
      "Epoch 38::Minibatch 939::LR 0.0146153846154 --> Loss 0.00201150000095\n",
      "Epoch 38::Minibatch 940::LR 0.0146153846154 --> Loss 0.000900303423405\n",
      "Epoch 38::Minibatch 941::LR 0.0146153846154 --> Loss 0.000721847762664\n",
      "Epoch 38::Minibatch 942::LR 0.0146153846154 --> Loss 0.00254149794579\n",
      "Epoch 38::Minibatch 943::LR 0.0146153846154 --> Loss 0.00222920695941\n",
      "Epoch 38::Minibatch 944::LR 0.0146153846154 --> Loss 0.00158083786567\n",
      "Epoch 38::Minibatch 945::LR 0.0146153846154 --> Loss 0.000852386852105\n",
      "Epoch 38::Minibatch 946::LR 0.0146153846154 --> Loss 0.00222429772218\n",
      "Epoch 38::Minibatch 947::LR 0.0146153846154 --> Loss 0.0020995670557\n",
      "Epoch 38::Minibatch 948::LR 0.0146153846154 --> Loss 0.00368694583575\n",
      "Epoch 38::Minibatch 949::LR 0.0146153846154 --> Loss 0.00166804114978\n",
      "Epoch 38::Minibatch 950::LR 0.0146153846154 --> Loss 0.000673509339492\n",
      "Epoch 38::Minibatch 951::LR 0.0146153846154 --> Loss 0.00332091410955\n",
      "Epoch 38::Minibatch 952::LR 0.0146153846154 --> Loss 0.00230812807878\n",
      "Epoch 38::Minibatch 953::LR 0.0146153846154 --> Loss 0.00141512493292\n",
      "Epoch 38::Minibatch 954::LR 0.0146153846154 --> Loss 0.000921293397744\n",
      "Epoch 38::Minibatch 955::LR 0.0146153846154 --> Loss 0.00256498734156\n",
      "Epoch 38::Minibatch 956::LR 0.0146153846154 --> Loss 0.00295075158278\n",
      "Epoch 38::Minibatch 957::LR 0.0146153846154 --> Loss 0.00182992080847\n",
      "Epoch 38::Minibatch 958::LR 0.0146153846154 --> Loss 0.00217533906301\n",
      "Epoch 38::Minibatch 959::LR 0.0146153846154 --> Loss 0.00244071900845\n",
      "Epoch 38::Minibatch 960::LR 0.0146153846154 --> Loss 0.00515496412913\n",
      "Epoch 38::Minibatch 961::LR 0.0146153846154 --> Loss 0.00282489697138\n",
      "Epoch 38::Minibatch 962::LR 0.0146153846154 --> Loss 0.00215478678544\n",
      "Epoch 38::Minibatch 963::LR 0.0146153846154 --> Loss 0.00102540463209\n",
      "Epoch 38::Minibatch 964::LR 0.0146153846154 --> Loss 0.00228816727797\n",
      "Epoch 38::Minibatch 965::LR 0.0146153846154 --> Loss 0.0061581381162\n",
      "Epoch 38::Minibatch 966::LR 0.0146153846154 --> Loss 0.00486249566078\n",
      "Epoch 38::Minibatch 967::LR 0.0146153846154 --> Loss 0.00120157122612\n",
      "Epoch 38::Minibatch 968::LR 0.0146153846154 --> Loss 0.000924373666445\n",
      "Epoch 38::Minibatch 969::LR 0.0146153846154 --> Loss 0.00402647296588\n",
      "Epoch 38::Minibatch 970::LR 0.0146153846154 --> Loss 0.00383211215337\n",
      "Epoch 38::Minibatch 971::LR 0.0146153846154 --> Loss 0.00311443328857\n",
      "Epoch 38::Minibatch 972::LR 0.0146153846154 --> Loss 0.00655466159185\n",
      "Epoch 38::Minibatch 973::LR 0.0146153846154 --> Loss 0.00908600091934\n",
      "Epoch 38::Minibatch 974::LR 0.0146153846154 --> Loss 0.00760953028997\n",
      "Epoch 38::Minibatch 975::LR 0.0146153846154 --> Loss 0.0053633860747\n",
      "Epoch 38::Minibatch 976::LR 0.0146153846154 --> Loss 0.00349503119787\n",
      "Epoch 38::Minibatch 977::LR 0.0146153846154 --> Loss 0.00308534820875\n",
      "Epoch 38::Minibatch 978::LR 0.0146153846154 --> Loss 0.00295996665955\n",
      "Epoch 38::Minibatch 979::LR 0.0146153846154 --> Loss 0.00273099680742\n",
      "Epoch 38::Minibatch 980::LR 0.0146153846154 --> Loss 0.00315345863501\n",
      "Epoch 38::Minibatch 981::LR 0.0146153846154 --> Loss 0.00371018012365\n",
      "Epoch 38::Minibatch 982::LR 0.0146153846154 --> Loss 0.00331771771113\n",
      "Epoch 38::Minibatch 983::LR 0.0146153846154 --> Loss 0.00216827630997\n",
      "Epoch 38::Minibatch 984::LR 0.0146153846154 --> Loss 0.00141944328944\n",
      "Epoch 38::Minibatch 985::LR 0.0146153846154 --> Loss 0.00272709548473\n",
      "Epoch 38::Minibatch 986::LR 0.0146153846154 --> Loss 0.00243162512779\n",
      "Epoch 38::Minibatch 987::LR 0.0146153846154 --> Loss 0.00286340018113\n",
      "Epoch 38::Minibatch 988::LR 0.0146153846154 --> Loss 0.00217637459437\n",
      "Epoch 38::Minibatch 989::LR 0.0146153846154 --> Loss 0.00254931926727\n",
      "Epoch 38::Minibatch 990::LR 0.0146153846154 --> Loss 0.0024835362037\n",
      "Epoch 38::Minibatch 991::LR 0.0146153846154 --> Loss 0.00117460181316\n",
      "Epoch 38::Minibatch 992::LR 0.0146153846154 --> Loss 0.00148091256618\n",
      "Epoch 38::Minibatch 993::LR 0.0146153846154 --> Loss 0.00269099315008\n",
      "Epoch 38::Minibatch 994::LR 0.0146153846154 --> Loss 0.0018107910951\n",
      "Epoch 38::Minibatch 995::LR 0.0146153846154 --> Loss 0.000734032789866\n",
      "Epoch 38::Minibatch 996::LR 0.0146153846154 --> Loss 0.00243972440561\n",
      "Epoch 38::Minibatch 997::LR 0.0146153846154 --> Loss 0.0020934043328\n",
      "Epoch 38::Minibatch 998::LR 0.0146153846154 --> Loss 0.00237695376078\n",
      "Epoch 38::Minibatch 999::LR 0.0146153846154 --> Loss 0.00205383320649\n",
      "Epoch 38::Minibatch 1000::LR 0.0146153846154 --> Loss 0.00254245221615\n",
      "Epoch 38::Minibatch 1001::LR 0.0146153846154 --> Loss 0.00200389246146\n",
      "Epoch 38::Minibatch 1002::LR 0.0146153846154 --> Loss 0.00136245687803\n",
      "Epoch 38::Minibatch 1003::LR 0.0146153846154 --> Loss 0.00220796247323\n",
      "Epoch 38::Minibatch 1004::LR 0.0146153846154 --> Loss 0.00105023523172\n",
      "Epoch 38::Minibatch 1005::LR 0.0146153846154 --> Loss 0.00246031463146\n",
      "Epoch 38::Minibatch 1006::LR 0.0146153846154 --> Loss 0.00118719160557\n",
      "Epoch 38::Minibatch 1007::LR 0.0146153846154 --> Loss 0.00160594463348\n",
      "Epoch 38::Minibatch 1008::LR 0.0146153846154 --> Loss 0.000901652276516\n",
      "Epoch 38::Minibatch 1009::LR 0.0146153846154 --> Loss 0.00117126395305\n",
      "Epoch 38::Minibatch 1010::LR 0.0146153846154 --> Loss 0.00114294449488\n",
      "Epoch 38::Minibatch 1011::LR 0.0146153846154 --> Loss 0.00147721519073\n",
      "Epoch 38::Minibatch 1012::LR 0.0146153846154 --> Loss 0.00130574335655\n",
      "Epoch 38::Minibatch 1013::LR 0.0146153846154 --> Loss 0.00322156031926\n",
      "Epoch 38::Minibatch 1014::LR 0.0146153846154 --> Loss 0.00298710405827\n",
      "Epoch 38::Minibatch 1015::LR 0.0146153846154 --> Loss 0.00149092823267\n",
      "Epoch 38::Minibatch 1016::LR 0.0146153846154 --> Loss 0.00427059849103\n",
      "Epoch 38::Minibatch 1017::LR 0.0146153846154 --> Loss 0.00311971108119\n",
      "Epoch 38::Minibatch 1018::LR 0.0146153846154 --> Loss 0.00235501448313\n",
      "Epoch 38::Minibatch 1019::LR 0.0146153846154 --> Loss 0.00144172261159\n",
      "Epoch 38::Minibatch 1020::LR 0.0146153846154 --> Loss 0.00160606125991\n",
      "Epoch 38::Minibatch 1021::LR 0.0146153846154 --> Loss 0.00174650510152\n",
      "Epoch 38::Minibatch 1022::LR 0.0146153846154 --> Loss 0.00125923166672\n",
      "Epoch 38::Minibatch 1023::LR 0.0146153846154 --> Loss 0.000943247377872\n",
      "Epoch 38::Minibatch 1024::LR 0.0146153846154 --> Loss 0.000955206155777\n",
      "Epoch 38::Minibatch 1025::LR 0.0146153846154 --> Loss 0.00133909364541\n",
      "Epoch 38::Minibatch 1026::LR 0.0146153846154 --> Loss 0.000667027582725\n",
      "Epoch 38::Minibatch 1027::LR 0.0146153846154 --> Loss 0.000954579114914\n",
      "Epoch 38::Minibatch 1028::LR 0.0146153846154 --> Loss 0.000695245613654\n",
      "Epoch 38::Minibatch 1029::LR 0.0146153846154 --> Loss 0.000733801573515\n",
      "Epoch 38::Minibatch 1030::LR 0.0146153846154 --> Loss 0.000878172020117\n",
      "Epoch 38::Minibatch 1031::LR 0.0146153846154 --> Loss 0.000657159586747\n",
      "Epoch 38::Minibatch 1032::LR 0.0146153846154 --> Loss 0.000761598447959\n",
      "Epoch 38::Minibatch 1033::LR 0.0146153846154 --> Loss 0.000648864756028\n",
      "Epoch 38::Minibatch 1034::LR 0.0146153846154 --> Loss 0.000616874049107\n",
      "Epoch 38::Minibatch 1035::LR 0.0146153846154 --> Loss 0.000400216629108\n",
      "Epoch 38::Minibatch 1036::LR 0.0146153846154 --> Loss 0.000319258670012\n",
      "Epoch 38::Minibatch 1037::LR 0.0146153846154 --> Loss 0.000618999302387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38::Minibatch 1038::LR 0.0146153846154 --> Loss 0.000951693455378\n",
      "Epoch 38::Minibatch 1039::LR 0.0146153846154 --> Loss 0.000846179127693\n",
      "Epoch 38::Minibatch 1040::LR 0.0146153846154 --> Loss 0.000329258541266\n",
      "Epoch 38::Minibatch 1041::LR 0.0146153846154 --> Loss 0.000470536549886\n",
      "Epoch 39::Minibatch 1::LR 0.0123076923077 --> Loss 0.00704128821691\n",
      "Epoch 39::Minibatch 2::LR 0.0123076923077 --> Loss 0.00433845361074\n",
      "Epoch 39::Minibatch 3::LR 0.0123076923077 --> Loss 0.00261751314004\n",
      "Epoch 39::Minibatch 4::LR 0.0123076923077 --> Loss 0.00357058048248\n",
      "Epoch 39::Minibatch 5::LR 0.0123076923077 --> Loss 0.00419114391009\n",
      "Epoch 39::Minibatch 6::LR 0.0123076923077 --> Loss 0.00192216932774\n",
      "Epoch 39::Minibatch 7::LR 0.0123076923077 --> Loss 0.00676133314768\n",
      "Epoch 39::Minibatch 8::LR 0.0123076923077 --> Loss 0.0062738720576\n",
      "Epoch 39::Minibatch 9::LR 0.0123076923077 --> Loss 0.00494252045949\n",
      "Epoch 39::Minibatch 10::LR 0.0123076923077 --> Loss 0.00215267717838\n",
      "Epoch 39::Minibatch 11::LR 0.0123076923077 --> Loss 0.00205472151438\n",
      "Epoch 39::Minibatch 12::LR 0.0123076923077 --> Loss 0.00325843711694\n",
      "Epoch 39::Minibatch 13::LR 0.0123076923077 --> Loss 0.0052655005455\n",
      "Epoch 39::Minibatch 14::LR 0.0123076923077 --> Loss 0.00524629553159\n",
      "Epoch 39::Minibatch 15::LR 0.0123076923077 --> Loss 0.00453200896581\n",
      "Epoch 39::Minibatch 16::LR 0.0123076923077 --> Loss 0.000672439038754\n",
      "Epoch 39::Minibatch 17::LR 0.0123076923077 --> Loss 0.00323057572047\n",
      "Epoch 39::Minibatch 18::LR 0.0123076923077 --> Loss 0.00274828096231\n",
      "Epoch 39::Minibatch 19::LR 0.0123076923077 --> Loss 0.00173485140006\n",
      "Epoch 39::Minibatch 20::LR 0.0123076923077 --> Loss 0.00229808211327\n",
      "Epoch 39::Minibatch 21::LR 0.0123076923077 --> Loss 0.00350966771444\n",
      "Epoch 39::Minibatch 22::LR 0.0123076923077 --> Loss 0.00224199473858\n",
      "Epoch 39::Minibatch 23::LR 0.0123076923077 --> Loss 0.00100638151169\n",
      "Epoch 39::Minibatch 24::LR 0.0123076923077 --> Loss 0.000589888542891\n",
      "Epoch 39::Minibatch 25::LR 0.0123076923077 --> Loss 0.00152109950781\n",
      "Epoch 39::Minibatch 26::LR 0.0123076923077 --> Loss 0.00171145379543\n",
      "Epoch 39::Minibatch 27::LR 0.0123076923077 --> Loss 0.00137604872386\n",
      "Epoch 39::Minibatch 28::LR 0.0123076923077 --> Loss 0.000601581682762\n",
      "Epoch 39::Minibatch 29::LR 0.0123076923077 --> Loss 0.000801174590985\n",
      "Epoch 39::Minibatch 30::LR 0.0123076923077 --> Loss 0.00135785222054\n",
      "Epoch 39::Minibatch 31::LR 0.0123076923077 --> Loss 0.00180439591408\n",
      "Epoch 39::Minibatch 32::LR 0.0123076923077 --> Loss 0.0015683166186\n",
      "Epoch 39::Minibatch 33::LR 0.0123076923077 --> Loss 0.000873724321524\n",
      "Epoch 39::Minibatch 34::LR 0.0123076923077 --> Loss 0.00204174101353\n",
      "Epoch 39::Minibatch 35::LR 0.0123076923077 --> Loss 0.00249813973904\n",
      "Epoch 39::Minibatch 36::LR 0.0123076923077 --> Loss 0.00225484172503\n",
      "Epoch 39::Minibatch 37::LR 0.0123076923077 --> Loss 0.000805660188198\n",
      "Epoch 39::Minibatch 38::LR 0.0123076923077 --> Loss 0.000833361446857\n",
      "Epoch 39::Minibatch 39::LR 0.0123076923077 --> Loss 0.00207120279471\n",
      "Epoch 39::Minibatch 40::LR 0.0123076923077 --> Loss 0.00304994702339\n",
      "Epoch 39::Minibatch 41::LR 0.0123076923077 --> Loss 0.00237377007802\n",
      "Epoch 39::Minibatch 42::LR 0.0123076923077 --> Loss 0.0035524225235\n",
      "Epoch 39::Minibatch 43::LR 0.0123076923077 --> Loss 0.00206338365873\n",
      "Epoch 39::Minibatch 44::LR 0.0123076923077 --> Loss 0.00352200190226\n",
      "Epoch 39::Minibatch 45::LR 0.0123076923077 --> Loss 0.00246964712938\n",
      "Epoch 39::Minibatch 46::LR 0.0123076923077 --> Loss 0.00287256002426\n",
      "Epoch 39::Minibatch 47::LR 0.0123076923077 --> Loss 0.00283207535744\n",
      "Epoch 39::Minibatch 48::LR 0.0123076923077 --> Loss 0.00415751457214\n",
      "Epoch 39::Minibatch 49::LR 0.0123076923077 --> Loss 0.0048153201739\n",
      "Epoch 39::Minibatch 50::LR 0.0123076923077 --> Loss 0.00570362130801\n",
      "Epoch 39::Minibatch 51::LR 0.0123076923077 --> Loss 0.00344215234121\n",
      "Epoch 39::Minibatch 52::LR 0.0123076923077 --> Loss 0.00326709032059\n",
      "Epoch 39::Minibatch 53::LR 0.0123076923077 --> Loss 0.00332890073458\n",
      "Epoch 39::Minibatch 54::LR 0.0123076923077 --> Loss 0.00389912048976\n",
      "Epoch 39::Minibatch 55::LR 0.0123076923077 --> Loss 0.00100817402204\n",
      "Epoch 39::Minibatch 56::LR 0.0123076923077 --> Loss 0.00275610129038\n",
      "Epoch 39::Minibatch 57::LR 0.0123076923077 --> Loss 0.00421847661336\n",
      "Epoch 39::Minibatch 58::LR 0.0123076923077 --> Loss 0.00313003460566\n",
      "Epoch 39::Minibatch 59::LR 0.0123076923077 --> Loss 0.00239029208819\n",
      "Epoch 39::Minibatch 60::LR 0.0123076923077 --> Loss 0.0025120562315\n",
      "Epoch 39::Minibatch 61::LR 0.0123076923077 --> Loss 0.00068660457929\n",
      "Epoch 39::Minibatch 62::LR 0.0123076923077 --> Loss 0.00231707493464\n",
      "Epoch 39::Minibatch 63::LR 0.0123076923077 --> Loss 0.00211235721906\n",
      "Epoch 39::Minibatch 64::LR 0.0123076923077 --> Loss 0.000813458412886\n",
      "Epoch 39::Minibatch 65::LR 0.0123076923077 --> Loss 0.00207403500875\n",
      "Epoch 39::Minibatch 66::LR 0.0123076923077 --> Loss 0.00290148417155\n",
      "Epoch 39::Minibatch 67::LR 0.0123076923077 --> Loss 0.00237825413545\n",
      "Epoch 39::Minibatch 68::LR 0.0123076923077 --> Loss 0.00179266134898\n",
      "Epoch 39::Minibatch 69::LR 0.0123076923077 --> Loss 0.003446666797\n",
      "Epoch 39::Minibatch 70::LR 0.0123076923077 --> Loss 0.00312714914481\n",
      "Epoch 39::Minibatch 71::LR 0.0123076923077 --> Loss 0.00219469626745\n",
      "Epoch 39::Minibatch 72::LR 0.0123076923077 --> Loss 0.000560975819826\n",
      "Epoch 39::Minibatch 73::LR 0.0123076923077 --> Loss 0.00353871464729\n",
      "Epoch 39::Minibatch 74::LR 0.0123076923077 --> Loss 0.00387592077255\n",
      "Epoch 39::Minibatch 75::LR 0.0123076923077 --> Loss 0.0018668482701\n",
      "Epoch 39::Minibatch 76::LR 0.0123076923077 --> Loss 0.000519420653582\n",
      "Epoch 39::Minibatch 77::LR 0.0123076923077 --> Loss 0.00316812018553\n",
      "Epoch 39::Minibatch 78::LR 0.0123076923077 --> Loss 0.00412344972293\n",
      "Epoch 39::Minibatch 79::LR 0.0123076923077 --> Loss 0.00158272425334\n",
      "Epoch 39::Minibatch 80::LR 0.0123076923077 --> Loss 0.00261238118013\n",
      "Epoch 39::Minibatch 81::LR 0.0123076923077 --> Loss 0.00239365339279\n",
      "Epoch 39::Minibatch 82::LR 0.0123076923077 --> Loss 0.00171621223291\n",
      "Epoch 39::Minibatch 83::LR 0.0123076923077 --> Loss 0.00349299867948\n",
      "Epoch 39::Minibatch 84::LR 0.0123076923077 --> Loss 0.00177098214626\n",
      "Epoch 39::Minibatch 85::LR 0.0123076923077 --> Loss 0.00235924283663\n",
      "Epoch 39::Minibatch 86::LR 0.0123076923077 --> Loss 0.00202269117037\n",
      "Epoch 39::Minibatch 87::LR 0.0123076923077 --> Loss 0.00208552618821\n",
      "Epoch 39::Minibatch 88::LR 0.0123076923077 --> Loss 0.00160324841738\n",
      "Epoch 39::Minibatch 89::LR 0.0123076923077 --> Loss 0.00212252656619\n",
      "Epoch 39::Minibatch 90::LR 0.0123076923077 --> Loss 0.0010440381368\n",
      "Epoch 39::Minibatch 91::LR 0.0123076923077 --> Loss 0.000890094836553\n",
      "Epoch 39::Minibatch 92::LR 0.0123076923077 --> Loss 0.00246389110883\n",
      "Epoch 39::Minibatch 93::LR 0.0123076923077 --> Loss 0.00165759136279\n",
      "Epoch 39::Minibatch 94::LR 0.0123076923077 --> Loss 0.00173080205917\n",
      "Epoch 39::Minibatch 95::LR 0.0123076923077 --> Loss 0.00194866855939\n",
      "Epoch 39::Minibatch 96::LR 0.0123076923077 --> Loss 0.00410837252935\n",
      "Epoch 39::Minibatch 97::LR 0.0123076923077 --> Loss 0.00296503881613\n",
      "Epoch 39::Minibatch 98::LR 0.0123076923077 --> Loss 0.00114653338989\n",
      "Epoch 39::Minibatch 99::LR 0.0123076923077 --> Loss 0.00149019469817\n",
      "Epoch 39::Minibatch 100::LR 0.0123076923077 --> Loss 0.00370640238126\n",
      "Epoch 39::Minibatch 101::LR 0.0123076923077 --> Loss 0.000906085868677\n",
      "Epoch 39::Minibatch 102::LR 0.0123076923077 --> Loss 0.00372086882591\n",
      "Epoch 39::Minibatch 103::LR 0.0123076923077 --> Loss 0.00371350566546\n",
      "Epoch 39::Minibatch 104::LR 0.0123076923077 --> Loss 0.00259373605251\n",
      "Epoch 39::Minibatch 105::LR 0.0123076923077 --> Loss 0.00183480918407\n",
      "Epoch 39::Minibatch 106::LR 0.0123076923077 --> Loss 0.0108121124903\n",
      "Epoch 39::Minibatch 107::LR 0.0123076923077 --> Loss 0.00462219039599\n",
      "Epoch 39::Minibatch 108::LR 0.0123076923077 --> Loss 0.000877878367901\n",
      "Epoch 39::Minibatch 109::LR 0.0123076923077 --> Loss 0.00427056352297\n",
      "Epoch 39::Minibatch 110::LR 0.0123076923077 --> Loss 0.0021654454867\n",
      "Epoch 39::Minibatch 111::LR 0.0123076923077 --> Loss 0.000767080585162\n",
      "Epoch 39::Minibatch 112::LR 0.0123076923077 --> Loss 0.00320196648439\n",
      "Epoch 39::Minibatch 113::LR 0.0123076923077 --> Loss 0.00227762381236\n",
      "Epoch 39::Minibatch 114::LR 0.0123076923077 --> Loss 0.00130134989818\n",
      "Epoch 39::Minibatch 115::LR 0.0123076923077 --> Loss 0.00104480296373\n",
      "Epoch 39::Minibatch 116::LR 0.0123076923077 --> Loss 0.00263064563274\n",
      "Epoch 39::Minibatch 117::LR 0.0123076923077 --> Loss 0.00413037459056\n",
      "Epoch 39::Minibatch 118::LR 0.0123076923077 --> Loss 0.00624229669571\n",
      "Epoch 39::Minibatch 119::LR 0.0123076923077 --> Loss 0.000438777705034\n",
      "Epoch 39::Minibatch 120::LR 0.0123076923077 --> Loss 0.00167064170043\n",
      "Epoch 39::Minibatch 121::LR 0.0123076923077 --> Loss 0.0022364594539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 122::LR 0.0123076923077 --> Loss 0.00392590403557\n",
      "Epoch 39::Minibatch 123::LR 0.0123076923077 --> Loss 0.00055276547869\n",
      "Epoch 39::Minibatch 124::LR 0.0123076923077 --> Loss 0.00267771204313\n",
      "Epoch 39::Minibatch 125::LR 0.0123076923077 --> Loss 0.00431650837262\n",
      "Epoch 39::Minibatch 126::LR 0.0123076923077 --> Loss 0.00227174599965\n",
      "Epoch 39::Minibatch 127::LR 0.0123076923077 --> Loss 0.00521900455157\n",
      "Epoch 39::Minibatch 128::LR 0.0123076923077 --> Loss 0.00342971960704\n",
      "Epoch 39::Minibatch 129::LR 0.0123076923077 --> Loss 0.00220872203509\n",
      "Epoch 39::Minibatch 130::LR 0.0123076923077 --> Loss 0.00426683425903\n",
      "Epoch 39::Minibatch 131::LR 0.0123076923077 --> Loss 0.00164302577575\n",
      "Epoch 39::Minibatch 132::LR 0.0123076923077 --> Loss 0.00264608164628\n",
      "Epoch 39::Minibatch 133::LR 0.0123076923077 --> Loss 0.00262562096119\n",
      "Epoch 39::Minibatch 134::LR 0.0123076923077 --> Loss 0.00202174305916\n",
      "Epoch 39::Minibatch 135::LR 0.0123076923077 --> Loss 0.00113922427098\n",
      "Epoch 39::Minibatch 136::LR 0.0123076923077 --> Loss 0.00224503556887\n",
      "Epoch 39::Minibatch 137::LR 0.0123076923077 --> Loss 0.00316633045673\n",
      "Epoch 39::Minibatch 138::LR 0.0123076923077 --> Loss 0.0011651045084\n",
      "Epoch 39::Minibatch 139::LR 0.0123076923077 --> Loss 0.00182086288929\n",
      "Epoch 39::Minibatch 140::LR 0.0123076923077 --> Loss 0.00229893147945\n",
      "Epoch 39::Minibatch 141::LR 0.0123076923077 --> Loss 0.00279754420122\n",
      "Epoch 39::Minibatch 142::LR 0.0123076923077 --> Loss 0.00266246140003\n",
      "Epoch 39::Minibatch 143::LR 0.0123076923077 --> Loss 0.000514742434025\n",
      "Epoch 39::Minibatch 144::LR 0.0123076923077 --> Loss 0.00345525781314\n",
      "Epoch 39::Minibatch 145::LR 0.0123076923077 --> Loss 0.00405664523443\n",
      "Epoch 39::Minibatch 146::LR 0.0123076923077 --> Loss 0.00245863993963\n",
      "Epoch 39::Minibatch 147::LR 0.0123076923077 --> Loss 0.00178530931473\n",
      "Epoch 39::Minibatch 148::LR 0.0123076923077 --> Loss 0.0009330072999\n",
      "Epoch 39::Minibatch 149::LR 0.0123076923077 --> Loss 0.0028864222765\n",
      "Epoch 39::Minibatch 150::LR 0.0123076923077 --> Loss 0.00263327856859\n",
      "Epoch 39::Minibatch 151::LR 0.0123076923077 --> Loss 0.00432325601578\n",
      "Epoch 39::Minibatch 152::LR 0.0123076923077 --> Loss 0.000893203914165\n",
      "Epoch 39::Minibatch 153::LR 0.0123076923077 --> Loss 0.00155265669028\n",
      "Epoch 39::Minibatch 154::LR 0.0123076923077 --> Loss 0.0019816472133\n",
      "Epoch 39::Minibatch 155::LR 0.0123076923077 --> Loss 0.00389787038167\n",
      "Epoch 39::Minibatch 156::LR 0.0123076923077 --> Loss 0.00233723421892\n",
      "Epoch 39::Minibatch 157::LR 0.0123076923077 --> Loss 0.000680999060472\n",
      "Epoch 39::Minibatch 158::LR 0.0123076923077 --> Loss 0.00324414432049\n",
      "Epoch 39::Minibatch 159::LR 0.0123076923077 --> Loss 0.00271061857541\n",
      "Epoch 39::Minibatch 160::LR 0.0123076923077 --> Loss 0.00268852770329\n",
      "Epoch 39::Minibatch 161::LR 0.0123076923077 --> Loss 0.000985732078552\n",
      "Epoch 39::Minibatch 162::LR 0.0123076923077 --> Loss 0.00407437602679\n",
      "Epoch 39::Minibatch 163::LR 0.0123076923077 --> Loss 0.00242883741856\n",
      "Epoch 39::Minibatch 164::LR 0.0123076923077 --> Loss 0.00258395512899\n",
      "Epoch 39::Minibatch 165::LR 0.0123076923077 --> Loss 0.000476646721363\n",
      "Epoch 39::Minibatch 166::LR 0.0123076923077 --> Loss 0.00167731881142\n",
      "Epoch 39::Minibatch 167::LR 0.0123076923077 --> Loss 0.00250284532706\n",
      "Epoch 39::Minibatch 168::LR 0.0123076923077 --> Loss 0.00212783118089\n",
      "Epoch 39::Minibatch 169::LR 0.0123076923077 --> Loss 0.000966218511264\n",
      "Epoch 39::Minibatch 170::LR 0.0123076923077 --> Loss 0.00093125919501\n",
      "Epoch 39::Minibatch 171::LR 0.0123076923077 --> Loss 0.00253217299779\n",
      "Epoch 39::Minibatch 172::LR 0.0123076923077 --> Loss 0.00432042519252\n",
      "Epoch 39::Minibatch 173::LR 0.0123076923077 --> Loss 0.00208542863528\n",
      "Epoch 39::Minibatch 174::LR 0.0123076923077 --> Loss 0.00093292037646\n",
      "Epoch 39::Minibatch 175::LR 0.0123076923077 --> Loss 0.00243693590164\n",
      "Epoch 39::Minibatch 176::LR 0.0123076923077 --> Loss 0.00302970230579\n",
      "Epoch 39::Minibatch 177::LR 0.0123076923077 --> Loss 0.00415344079336\n",
      "Epoch 39::Minibatch 178::LR 0.0123076923077 --> Loss 0.00142892698447\n",
      "Epoch 39::Minibatch 179::LR 0.0123076923077 --> Loss 0.00109946062167\n",
      "Epoch 39::Minibatch 180::LR 0.0123076923077 --> Loss 0.00323380132516\n",
      "Epoch 39::Minibatch 181::LR 0.0123076923077 --> Loss 0.00295584360758\n",
      "Epoch 39::Minibatch 182::LR 0.0123076923077 --> Loss 0.000670269032319\n",
      "Epoch 39::Minibatch 183::LR 0.0123076923077 --> Loss 0.00148814191421\n",
      "Epoch 39::Minibatch 184::LR 0.0123076923077 --> Loss 0.00335499087969\n",
      "Epoch 39::Minibatch 185::LR 0.0123076923077 --> Loss 0.00249996741613\n",
      "Epoch 39::Minibatch 186::LR 0.0123076923077 --> Loss 0.000888660848141\n",
      "Epoch 39::Minibatch 187::LR 0.0123076923077 --> Loss 0.00124681760867\n",
      "Epoch 39::Minibatch 188::LR 0.0123076923077 --> Loss 0.00387728095055\n",
      "Epoch 39::Minibatch 189::LR 0.0123076923077 --> Loss 0.00395081281662\n",
      "Epoch 39::Minibatch 190::LR 0.0123076923077 --> Loss 0.0022475673755\n",
      "Epoch 39::Minibatch 191::LR 0.0123076923077 --> Loss 0.00043004065752\n",
      "Epoch 39::Minibatch 192::LR 0.0123076923077 --> Loss 0.00276530484358\n",
      "Epoch 39::Minibatch 193::LR 0.0123076923077 --> Loss 0.0027052774032\n",
      "Epoch 39::Minibatch 194::LR 0.0123076923077 --> Loss 0.00169742544492\n",
      "Epoch 39::Minibatch 195::LR 0.0123076923077 --> Loss 0.000365850975116\n",
      "Epoch 39::Minibatch 196::LR 0.0123076923077 --> Loss 0.00137575894594\n",
      "Epoch 39::Minibatch 197::LR 0.0123076923077 --> Loss 0.00295230786006\n",
      "Epoch 39::Minibatch 198::LR 0.0123076923077 --> Loss 0.0023327066501\n",
      "Epoch 39::Minibatch 199::LR 0.0123076923077 --> Loss 0.00028676400582\n",
      "Epoch 39::Minibatch 200::LR 0.0123076923077 --> Loss 0.00203326145808\n",
      "Epoch 39::Minibatch 201::LR 0.0123076923077 --> Loss 0.00192082822323\n",
      "Epoch 39::Minibatch 202::LR 0.0123076923077 --> Loss 0.00179925640424\n",
      "Epoch 39::Minibatch 203::LR 0.0123076923077 --> Loss 0.00176742474238\n",
      "Epoch 39::Minibatch 204::LR 0.0123076923077 --> Loss 0.00141516198715\n",
      "Epoch 39::Minibatch 205::LR 0.0123076923077 --> Loss 0.00223526120186\n",
      "Epoch 39::Minibatch 206::LR 0.0123076923077 --> Loss 0.00498044729233\n",
      "Epoch 39::Minibatch 207::LR 0.0123076923077 --> Loss 0.00139595200618\n",
      "Epoch 39::Minibatch 208::LR 0.0123076923077 --> Loss 0.00110281646252\n",
      "Epoch 39::Minibatch 209::LR 0.0123076923077 --> Loss 0.0025868944327\n",
      "Epoch 39::Minibatch 210::LR 0.0123076923077 --> Loss 0.00242949008942\n",
      "Epoch 39::Minibatch 211::LR 0.0123076923077 --> Loss 0.00278834462166\n",
      "Epoch 39::Minibatch 212::LR 0.0123076923077 --> Loss 0.00368037501971\n",
      "Epoch 39::Minibatch 213::LR 0.0123076923077 --> Loss 0.00526593923569\n",
      "Epoch 39::Minibatch 214::LR 0.0123076923077 --> Loss 0.00640948255857\n",
      "Epoch 39::Minibatch 215::LR 0.0123076923077 --> Loss 0.00135330557823\n",
      "Epoch 39::Minibatch 216::LR 0.0123076923077 --> Loss 0.00519156177839\n",
      "Epoch 39::Minibatch 217::LR 0.0123076923077 --> Loss 0.00567652146022\n",
      "Epoch 39::Minibatch 218::LR 0.0123076923077 --> Loss 0.00388160506884\n",
      "Epoch 39::Minibatch 219::LR 0.0123076923077 --> Loss 0.00448496977488\n",
      "Epoch 39::Minibatch 220::LR 0.0123076923077 --> Loss 0.0043054262797\n",
      "Epoch 39::Minibatch 221::LR 0.0123076923077 --> Loss 0.00430204590162\n",
      "Epoch 39::Minibatch 222::LR 0.0123076923077 --> Loss 0.00314509948095\n",
      "Epoch 39::Minibatch 223::LR 0.0123076923077 --> Loss 0.00136973162492\n",
      "Epoch 39::Minibatch 224::LR 0.0123076923077 --> Loss 0.00155094007651\n",
      "Epoch 39::Minibatch 225::LR 0.0123076923077 --> Loss 0.00800862789154\n",
      "Epoch 39::Minibatch 226::LR 0.0123076923077 --> Loss 0.00356861750285\n",
      "Epoch 39::Minibatch 227::LR 0.0123076923077 --> Loss 0.00167633612951\n",
      "Epoch 39::Minibatch 228::LR 0.0123076923077 --> Loss 0.000627130419016\n",
      "Epoch 39::Minibatch 229::LR 0.0123076923077 --> Loss 0.00478426853816\n",
      "Epoch 39::Minibatch 230::LR 0.0123076923077 --> Loss 0.00354148546855\n",
      "Epoch 39::Minibatch 231::LR 0.0123076923077 --> Loss 0.00266912897428\n",
      "Epoch 39::Minibatch 232::LR 0.0123076923077 --> Loss 0.00114533901215\n",
      "Epoch 39::Minibatch 233::LR 0.0123076923077 --> Loss 0.00247491180897\n",
      "Epoch 39::Minibatch 234::LR 0.0123076923077 --> Loss 0.00758806705475\n",
      "Epoch 39::Minibatch 235::LR 0.0123076923077 --> Loss 0.00455112616221\n",
      "Epoch 39::Minibatch 236::LR 0.0123076923077 --> Loss 0.00164204120636\n",
      "Epoch 39::Minibatch 237::LR 0.0123076923077 --> Loss 0.000551993697882\n",
      "Epoch 39::Minibatch 238::LR 0.0123076923077 --> Loss 0.00351249376933\n",
      "Epoch 39::Minibatch 239::LR 0.0123076923077 --> Loss 0.00295845290025\n",
      "Epoch 39::Minibatch 240::LR 0.0123076923077 --> Loss 0.00330549418926\n",
      "Epoch 39::Minibatch 241::LR 0.0123076923077 --> Loss 0.000745445440213\n",
      "Epoch 39::Minibatch 242::LR 0.0123076923077 --> Loss 0.00665035645167\n",
      "Epoch 39::Minibatch 243::LR 0.0123076923077 --> Loss 0.00317093133926\n",
      "Epoch 39::Minibatch 244::LR 0.0123076923077 --> Loss 0.00265638728937\n",
      "Epoch 39::Minibatch 245::LR 0.0123076923077 --> Loss 0.000408481930693\n",
      "Epoch 39::Minibatch 246::LR 0.0123076923077 --> Loss 0.00182895203431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 247::LR 0.0123076923077 --> Loss 0.00949068625768\n",
      "Epoch 39::Minibatch 248::LR 0.0123076923077 --> Loss 0.00430648088455\n",
      "Epoch 39::Minibatch 249::LR 0.0123076923077 --> Loss 0.00232711493969\n",
      "Epoch 39::Minibatch 250::LR 0.0123076923077 --> Loss 0.0022991023461\n",
      "Epoch 39::Minibatch 251::LR 0.0123076923077 --> Loss 0.00229490220547\n",
      "Epoch 39::Minibatch 252::LR 0.0123076923077 --> Loss 0.00155585507552\n",
      "Epoch 39::Minibatch 253::LR 0.0123076923077 --> Loss 0.00266691346963\n",
      "Epoch 39::Minibatch 254::LR 0.0123076923077 --> Loss 0.00473395784696\n",
      "Epoch 39::Minibatch 255::LR 0.0123076923077 --> Loss 0.00385739445686\n",
      "Epoch 39::Minibatch 256::LR 0.0123076923077 --> Loss 0.00130880494912\n",
      "Epoch 39::Minibatch 257::LR 0.0123076923077 --> Loss 0.00112204362949\n",
      "Epoch 39::Minibatch 258::LR 0.0123076923077 --> Loss 0.00367636561394\n",
      "Epoch 39::Minibatch 259::LR 0.0123076923077 --> Loss 0.0015030486385\n",
      "Epoch 39::Minibatch 260::LR 0.0123076923077 --> Loss 0.00182641347249\n",
      "Epoch 39::Minibatch 261::LR 0.0123076923077 --> Loss 0.00259726901849\n",
      "Epoch 39::Minibatch 262::LR 0.0123076923077 --> Loss 0.00177392800649\n",
      "Epoch 39::Minibatch 263::LR 0.0123076923077 --> Loss 0.00224527756373\n",
      "Epoch 39::Minibatch 264::LR 0.0123076923077 --> Loss 0.00353474577268\n",
      "Epoch 39::Minibatch 265::LR 0.0123076923077 --> Loss 0.0100174442927\n",
      "Epoch 39::Minibatch 266::LR 0.0123076923077 --> Loss 0.000812415033579\n",
      "Epoch 39::Minibatch 267::LR 0.0123076923077 --> Loss 0.00876894235611\n",
      "Epoch 39::Minibatch 268::LR 0.0123076923077 --> Loss 0.000962479909261\n",
      "Epoch 39::Minibatch 269::LR 0.0123076923077 --> Loss 0.00344891031583\n",
      "Epoch 39::Minibatch 270::LR 0.0123076923077 --> Loss 0.0077910621961\n",
      "Epoch 39::Minibatch 271::LR 0.0123076923077 --> Loss 0.00227020879587\n",
      "Epoch 39::Minibatch 272::LR 0.0123076923077 --> Loss 0.00454369107882\n",
      "Epoch 39::Minibatch 273::LR 0.0123076923077 --> Loss 0.00123009075721\n",
      "Epoch 39::Minibatch 274::LR 0.0123076923077 --> Loss 0.00174376269182\n",
      "Epoch 39::Minibatch 275::LR 0.0123076923077 --> Loss 0.00236193776131\n",
      "Epoch 39::Minibatch 276::LR 0.0123076923077 --> Loss 0.00324263314406\n",
      "Epoch 39::Minibatch 277::LR 0.0123076923077 --> Loss 0.000794723182917\n",
      "Epoch 39::Minibatch 278::LR 0.0123076923077 --> Loss 0.00245039244493\n",
      "Epoch 39::Minibatch 279::LR 0.0123076923077 --> Loss 0.00179558932781\n",
      "Epoch 39::Minibatch 280::LR 0.0123076923077 --> Loss 0.00159973263741\n",
      "Epoch 39::Minibatch 281::LR 0.0123076923077 --> Loss 0.00100951155027\n",
      "Epoch 39::Minibatch 282::LR 0.0123076923077 --> Loss 0.0018545059363\n",
      "Epoch 39::Minibatch 283::LR 0.0123076923077 --> Loss 0.00174655417601\n",
      "Epoch 39::Minibatch 284::LR 0.0123076923077 --> Loss 0.00143654088179\n",
      "Epoch 39::Minibatch 285::LR 0.0123076923077 --> Loss 0.00104729910692\n",
      "Epoch 39::Minibatch 286::LR 0.0123076923077 --> Loss 0.00181738058726\n",
      "Epoch 39::Minibatch 287::LR 0.0123076923077 --> Loss 0.0018115657568\n",
      "Epoch 39::Minibatch 288::LR 0.0123076923077 --> Loss 0.000985108415286\n",
      "Epoch 39::Minibatch 289::LR 0.0123076923077 --> Loss 0.00146349728107\n",
      "Epoch 39::Minibatch 290::LR 0.0123076923077 --> Loss 0.00174147526423\n",
      "Epoch 39::Minibatch 291::LR 0.0123076923077 --> Loss 0.0015742306908\n",
      "Epoch 39::Minibatch 292::LR 0.0123076923077 --> Loss 0.000553497473399\n",
      "Epoch 39::Minibatch 293::LR 0.0123076923077 --> Loss 0.00142405539751\n",
      "Epoch 39::Minibatch 294::LR 0.0123076923077 --> Loss 0.00160985181729\n",
      "Epoch 39::Minibatch 295::LR 0.0123076923077 --> Loss 0.00182535449664\n",
      "Epoch 39::Minibatch 296::LR 0.0123076923077 --> Loss 0.00155939489603\n",
      "Epoch 39::Minibatch 297::LR 0.0123076923077 --> Loss 0.00137592732906\n",
      "Epoch 39::Minibatch 298::LR 0.0123076923077 --> Loss 0.00138660808404\n",
      "Epoch 39::Minibatch 299::LR 0.0123076923077 --> Loss 0.000801087568204\n",
      "Epoch 39::Minibatch 300::LR 0.0123076923077 --> Loss 0.00260755360126\n",
      "Epoch 39::Minibatch 301::LR 0.0123076923077 --> Loss 0.0025279468298\n",
      "Epoch 39::Minibatch 302::LR 0.0123076923077 --> Loss 0.00235338528951\n",
      "Epoch 39::Minibatch 303::LR 0.0123076923077 --> Loss 0.000800500015418\n",
      "Epoch 39::Minibatch 304::LR 0.0123076923077 --> Loss 0.00285085558891\n",
      "Epoch 39::Minibatch 305::LR 0.0123076923077 --> Loss 0.00170134584109\n",
      "Epoch 39::Minibatch 306::LR 0.0123076923077 --> Loss 0.000919807354609\n",
      "Epoch 39::Minibatch 307::LR 0.0123076923077 --> Loss 0.00239228884379\n",
      "Epoch 39::Minibatch 308::LR 0.0123076923077 --> Loss 0.00198785265287\n",
      "Epoch 39::Minibatch 309::LR 0.0123076923077 --> Loss 0.00103558669488\n",
      "Epoch 39::Minibatch 310::LR 0.0123076923077 --> Loss 0.00118991633256\n",
      "Epoch 39::Minibatch 311::LR 0.0123076923077 --> Loss 0.00178657432397\n",
      "Epoch 39::Minibatch 312::LR 0.0123076923077 --> Loss 0.00283626794815\n",
      "Epoch 39::Minibatch 313::LR 0.0123076923077 --> Loss 0.002301547726\n",
      "Epoch 39::Minibatch 314::LR 0.0123076923077 --> Loss 0.00191396911939\n",
      "Epoch 39::Minibatch 315::LR 0.0123076923077 --> Loss 0.00105159759521\n",
      "Epoch 39::Minibatch 316::LR 0.0123076923077 --> Loss 0.00233602444331\n",
      "Epoch 39::Minibatch 317::LR 0.0123076923077 --> Loss 0.0015600263079\n",
      "Epoch 39::Minibatch 318::LR 0.0123076923077 --> Loss 0.00131936401129\n",
      "Epoch 39::Minibatch 319::LR 0.0123076923077 --> Loss 0.00229240218798\n",
      "Epoch 39::Minibatch 320::LR 0.0123076923077 --> Loss 0.00295518875122\n",
      "Epoch 39::Minibatch 321::LR 0.0123076923077 --> Loss 0.000835952460766\n",
      "Epoch 39::Minibatch 322::LR 0.0123076923077 --> Loss 0.00330938021342\n",
      "Epoch 39::Minibatch 323::LR 0.0123076923077 --> Loss 0.00338330308596\n",
      "Epoch 39::Minibatch 324::LR 0.0123076923077 --> Loss 0.00265455325445\n",
      "Epoch 39::Minibatch 325::LR 0.0123076923077 --> Loss 0.00235845367114\n",
      "Epoch 39::Minibatch 326::LR 0.0123076923077 --> Loss 0.00507021824519\n",
      "Epoch 39::Minibatch 327::LR 0.0123076923077 --> Loss 0.00219485064348\n",
      "Epoch 39::Minibatch 328::LR 0.0123076923077 --> Loss 0.00282114207745\n",
      "Epoch 39::Minibatch 329::LR 0.0123076923077 --> Loss 0.00116869817177\n",
      "Epoch 39::Minibatch 330::LR 0.0123076923077 --> Loss 0.0015815971295\n",
      "Epoch 39::Minibatch 331::LR 0.0123076923077 --> Loss 0.00252911408742\n",
      "Epoch 39::Minibatch 332::LR 0.0123076923077 --> Loss 0.00242366154989\n",
      "Epoch 39::Minibatch 333::LR 0.0123076923077 --> Loss 0.00147072970867\n",
      "Epoch 39::Minibatch 334::LR 0.0123076923077 --> Loss 0.00435465137164\n",
      "Epoch 39::Minibatch 335::LR 0.0123076923077 --> Loss 0.00190578997135\n",
      "Epoch 39::Minibatch 336::LR 0.0123076923077 --> Loss 0.00227023502191\n",
      "Epoch 39::Minibatch 337::LR 0.0123076923077 --> Loss 0.00382689317067\n",
      "Epoch 39::Minibatch 338::LR 0.0123076923077 --> Loss 0.000559735099475\n",
      "Epoch 39::Minibatch 339::LR 0.0123076923077 --> Loss 0.00318661351999\n",
      "Epoch 39::Minibatch 340::LR 0.0123076923077 --> Loss 0.00355996568998\n",
      "Epoch 39::Minibatch 341::LR 0.0123076923077 --> Loss 0.00412358601888\n",
      "Epoch 39::Minibatch 342::LR 0.0123076923077 --> Loss 0.00303454319636\n",
      "Epoch 39::Minibatch 343::LR 0.0123076923077 --> Loss 0.00163454244534\n",
      "Epoch 39::Minibatch 344::LR 0.0123076923077 --> Loss 0.00314487814903\n",
      "Epoch 39::Minibatch 345::LR 0.0123076923077 --> Loss 0.00398995598157\n",
      "Epoch 39::Minibatch 346::LR 0.0123076923077 --> Loss 0.00520305275917\n",
      "Epoch 39::Minibatch 347::LR 0.0123076923077 --> Loss 0.000819549560547\n",
      "Epoch 39::Minibatch 348::LR 0.0123076923077 --> Loss 0.00286270399888\n",
      "Epoch 39::Minibatch 349::LR 0.0123076923077 --> Loss 0.00326985061169\n",
      "Epoch 39::Minibatch 350::LR 0.0123076923077 --> Loss 0.00163725177447\n",
      "Epoch 39::Minibatch 351::LR 0.0123076923077 --> Loss 0.00340471307437\n",
      "Epoch 39::Minibatch 352::LR 0.0123076923077 --> Loss 0.00480082909266\n",
      "Epoch 39::Minibatch 353::LR 0.0123076923077 --> Loss 0.0034633342425\n",
      "Epoch 39::Minibatch 354::LR 0.0123076923077 --> Loss 0.00293489138285\n",
      "Epoch 39::Minibatch 355::LR 0.0123076923077 --> Loss 0.00633691032728\n",
      "Epoch 39::Minibatch 356::LR 0.0123076923077 --> Loss 0.00317890028159\n",
      "Epoch 39::Minibatch 357::LR 0.0123076923077 --> Loss 0.00122932563225\n",
      "Epoch 39::Minibatch 358::LR 0.0123076923077 --> Loss 0.00188941001892\n",
      "Epoch 39::Minibatch 359::LR 0.0123076923077 --> Loss 0.00265305141608\n",
      "Epoch 39::Minibatch 360::LR 0.0123076923077 --> Loss 0.00223744610945\n",
      "Epoch 39::Minibatch 361::LR 0.0123076923077 --> Loss 0.00218993067741\n",
      "Epoch 39::Minibatch 362::LR 0.0123076923077 --> Loss 0.00218988557657\n",
      "Epoch 39::Minibatch 363::LR 0.0123076923077 --> Loss 0.0006254418691\n",
      "Epoch 39::Minibatch 364::LR 0.0123076923077 --> Loss 0.0019529513518\n",
      "Epoch 39::Minibatch 365::LR 0.0123076923077 --> Loss 0.00196178277334\n",
      "Epoch 39::Minibatch 366::LR 0.0123076923077 --> Loss 0.00206676582495\n",
      "Epoch 39::Minibatch 367::LR 0.0123076923077 --> Loss 0.000956671436628\n",
      "Epoch 39::Minibatch 368::LR 0.0123076923077 --> Loss 0.000969749291738\n",
      "Epoch 39::Minibatch 369::LR 0.0123076923077 --> Loss 0.00266755561034\n",
      "Epoch 39::Minibatch 370::LR 0.0123076923077 --> Loss 0.00215892950694\n",
      "Epoch 39::Minibatch 371::LR 0.0123076923077 --> Loss 0.00181095163027\n",
      "Epoch 39::Minibatch 372::LR 0.0123076923077 --> Loss 0.000424969544013\n",
      "Epoch 39::Minibatch 373::LR 0.0123076923077 --> Loss 0.00181067744891\n",
      "Epoch 39::Minibatch 374::LR 0.0123076923077 --> Loss 0.00224504888058\n",
      "Epoch 39::Minibatch 375::LR 0.0123076923077 --> Loss 0.00190262158712\n",
      "Epoch 39::Minibatch 376::LR 0.0123076923077 --> Loss 0.00117372214794\n",
      "Epoch 39::Minibatch 377::LR 0.0123076923077 --> Loss 0.00189190248648\n",
      "Epoch 39::Minibatch 378::LR 0.0123076923077 --> Loss 0.00207186063131\n",
      "Epoch 39::Minibatch 379::LR 0.0123076923077 --> Loss 0.00229255537192\n",
      "Epoch 39::Minibatch 380::LR 0.0123076923077 --> Loss 0.00154594441255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 381::LR 0.0123076923077 --> Loss 0.00100073476632\n",
      "Epoch 39::Minibatch 382::LR 0.0123076923077 --> Loss 0.00204966902733\n",
      "Epoch 39::Minibatch 383::LR 0.0123076923077 --> Loss 0.00199355920156\n",
      "Epoch 39::Minibatch 384::LR 0.0123076923077 --> Loss 0.00115170886119\n",
      "Epoch 39::Minibatch 385::LR 0.0123076923077 --> Loss 0.00106988588969\n",
      "Epoch 39::Minibatch 386::LR 0.0123076923077 --> Loss 0.00228677749634\n",
      "Epoch 39::Minibatch 387::LR 0.0123076923077 --> Loss 0.00236605385939\n",
      "Epoch 39::Minibatch 388::LR 0.0123076923077 --> Loss 0.00124170780182\n",
      "Epoch 39::Minibatch 389::LR 0.0123076923077 --> Loss 0.00178660909335\n",
      "Epoch 39::Minibatch 390::LR 0.0123076923077 --> Loss 0.0031494363149\n",
      "Epoch 39::Minibatch 391::LR 0.0123076923077 --> Loss 0.00251602709293\n",
      "Epoch 39::Minibatch 392::LR 0.0123076923077 --> Loss 0.0025345202287\n",
      "Epoch 39::Minibatch 393::LR 0.0123076923077 --> Loss 0.00272286117077\n",
      "Epoch 39::Minibatch 394::LR 0.0123076923077 --> Loss 0.00199966768424\n",
      "Epoch 39::Minibatch 395::LR 0.0123076923077 --> Loss 0.00208678344886\n",
      "Epoch 39::Minibatch 396::LR 0.0123076923077 --> Loss 0.00195203443368\n",
      "Epoch 39::Minibatch 397::LR 0.0123076923077 --> Loss 0.00209575533867\n",
      "Epoch 39::Minibatch 398::LR 0.0123076923077 --> Loss 0.0020853014787\n",
      "Epoch 39::Minibatch 399::LR 0.0123076923077 --> Loss 0.00238398929437\n",
      "Epoch 39::Minibatch 400::LR 0.0123076923077 --> Loss 0.00202504952749\n",
      "Epoch 39::Minibatch 401::LR 0.0123076923077 --> Loss 0.0033893541495\n",
      "Epoch 39::Minibatch 402::LR 0.0123076923077 --> Loss 0.00171196540197\n",
      "Epoch 39::Minibatch 403::LR 0.0123076923077 --> Loss 0.00143699248632\n",
      "Epoch 39::Minibatch 404::LR 0.0123076923077 --> Loss 0.00130551775297\n",
      "Epoch 39::Minibatch 405::LR 0.0123076923077 --> Loss 0.00330414195855\n",
      "Epoch 39::Minibatch 406::LR 0.0123076923077 --> Loss 0.00231607556343\n",
      "Epoch 39::Minibatch 407::LR 0.0123076923077 --> Loss 0.00171141982079\n",
      "Epoch 39::Minibatch 408::LR 0.0123076923077 --> Loss 0.000436746080716\n",
      "Epoch 39::Minibatch 409::LR 0.0123076923077 --> Loss 0.00220149874687\n",
      "Epoch 39::Minibatch 410::LR 0.0123076923077 --> Loss 0.00313059250514\n",
      "Epoch 39::Minibatch 411::LR 0.0123076923077 --> Loss 0.00168285489082\n",
      "Epoch 39::Minibatch 412::LR 0.0123076923077 --> Loss 0.000942350625992\n",
      "Epoch 39::Minibatch 413::LR 0.0123076923077 --> Loss 0.00198941787084\n",
      "Epoch 39::Minibatch 414::LR 0.0123076923077 --> Loss 0.00189350644747\n",
      "Epoch 39::Minibatch 415::LR 0.0123076923077 --> Loss 0.00118941873312\n",
      "Epoch 39::Minibatch 416::LR 0.0123076923077 --> Loss 0.000788433154424\n",
      "Epoch 39::Minibatch 417::LR 0.0123076923077 --> Loss 0.00167899767558\n",
      "Epoch 39::Minibatch 418::LR 0.0123076923077 --> Loss 0.00255264818668\n",
      "Epoch 39::Minibatch 419::LR 0.0123076923077 --> Loss 0.000495019306739\n",
      "Epoch 39::Minibatch 420::LR 0.0123076923077 --> Loss 0.000703111390273\n",
      "Epoch 39::Minibatch 421::LR 0.0123076923077 --> Loss 0.0018672311306\n",
      "Epoch 39::Minibatch 422::LR 0.0123076923077 --> Loss 0.00204849580924\n",
      "Epoch 39::Minibatch 423::LR 0.0123076923077 --> Loss 0.001006158789\n",
      "Epoch 39::Minibatch 424::LR 0.0123076923077 --> Loss 0.00152929127216\n",
      "Epoch 39::Minibatch 425::LR 0.0123076923077 --> Loss 0.00285431563854\n",
      "Epoch 39::Minibatch 426::LR 0.0123076923077 --> Loss 0.00200402677059\n",
      "Epoch 39::Minibatch 427::LR 0.0123076923077 --> Loss 0.000758321086566\n",
      "Epoch 39::Minibatch 428::LR 0.0123076923077 --> Loss 0.000891138712565\n",
      "Epoch 39::Minibatch 429::LR 0.0123076923077 --> Loss 0.00221277972062\n",
      "Epoch 39::Minibatch 430::LR 0.0123076923077 --> Loss 0.00707348267237\n",
      "Epoch 39::Minibatch 431::LR 0.0123076923077 --> Loss 0.0034280693531\n",
      "Epoch 39::Minibatch 432::LR 0.0123076923077 --> Loss 0.00378618359566\n",
      "Epoch 39::Minibatch 433::LR 0.0123076923077 --> Loss 0.0025425461928\n",
      "Epoch 39::Minibatch 434::LR 0.0123076923077 --> Loss 0.00239833315214\n",
      "Epoch 39::Minibatch 435::LR 0.0123076923077 --> Loss 0.00224559326967\n",
      "Epoch 39::Minibatch 436::LR 0.0123076923077 --> Loss 0.00156747102737\n",
      "Epoch 39::Minibatch 437::LR 0.0123076923077 --> Loss 0.00271051883698\n",
      "Epoch 39::Minibatch 438::LR 0.0123076923077 --> Loss 0.00217652956645\n",
      "Epoch 39::Minibatch 439::LR 0.0123076923077 --> Loss 0.00187323451042\n",
      "Epoch 39::Minibatch 440::LR 0.0123076923077 --> Loss 0.00289499958356\n",
      "Epoch 39::Minibatch 441::LR 0.0123076923077 --> Loss 0.00271120786667\n",
      "Epoch 39::Minibatch 442::LR 0.0123076923077 --> Loss 0.00240399499734\n",
      "Epoch 39::Minibatch 443::LR 0.0123076923077 --> Loss 0.00340609192848\n",
      "Epoch 39::Minibatch 444::LR 0.0123076923077 --> Loss 0.00261730313301\n",
      "Epoch 39::Minibatch 445::LR 0.0123076923077 --> Loss 0.000836419165134\n",
      "Epoch 39::Minibatch 446::LR 0.0123076923077 --> Loss 0.00133923669656\n",
      "Epoch 39::Minibatch 447::LR 0.0123076923077 --> Loss 0.00224106649558\n",
      "Epoch 39::Minibatch 448::LR 0.0123076923077 --> Loss 0.0022949608167\n",
      "Epoch 39::Minibatch 449::LR 0.0123076923077 --> Loss 0.00352367758751\n",
      "Epoch 39::Minibatch 450::LR 0.0123076923077 --> Loss 0.00209321836631\n",
      "Epoch 39::Minibatch 451::LR 0.0123076923077 --> Loss 0.00375488241514\n",
      "Epoch 39::Minibatch 452::LR 0.0123076923077 --> Loss 0.00226223409176\n",
      "Epoch 39::Minibatch 453::LR 0.0123076923077 --> Loss 0.000342422425747\n",
      "Epoch 39::Minibatch 454::LR 0.0123076923077 --> Loss 0.00332123498122\n",
      "Epoch 39::Minibatch 455::LR 0.0123076923077 --> Loss 0.00253811935584\n",
      "Epoch 39::Minibatch 456::LR 0.0123076923077 --> Loss 0.00304421703021\n",
      "Epoch 39::Minibatch 457::LR 0.0123076923077 --> Loss 0.00186527748903\n",
      "Epoch 39::Minibatch 458::LR 0.0123076923077 --> Loss 0.000711684823036\n",
      "Epoch 39::Minibatch 459::LR 0.0123076923077 --> Loss 0.00369492332141\n",
      "Epoch 39::Minibatch 460::LR 0.0123076923077 --> Loss 0.00239217281342\n",
      "Epoch 39::Minibatch 461::LR 0.0123076923077 --> Loss 0.00359375317891\n",
      "Epoch 39::Minibatch 462::LR 0.0123076923077 --> Loss 0.000363624518116\n",
      "Epoch 39::Minibatch 463::LR 0.0123076923077 --> Loss 0.00388219594955\n",
      "Epoch 39::Minibatch 464::LR 0.0123076923077 --> Loss 0.00192301213741\n",
      "Epoch 39::Minibatch 465::LR 0.0123076923077 --> Loss 0.00425563573837\n",
      "Epoch 39::Minibatch 466::LR 0.0123076923077 --> Loss 0.00486630797386\n",
      "Epoch 39::Minibatch 467::LR 0.0123076923077 --> Loss 0.00490008791288\n",
      "Epoch 39::Minibatch 468::LR 0.0123076923077 --> Loss 0.00546050786972\n",
      "Epoch 39::Minibatch 469::LR 0.0123076923077 --> Loss 0.00576787432035\n",
      "Epoch 39::Minibatch 470::LR 0.0123076923077 --> Loss 0.00351368824641\n",
      "Epoch 39::Minibatch 471::LR 0.0123076923077 --> Loss 0.0016352156798\n",
      "Epoch 39::Minibatch 472::LR 0.0123076923077 --> Loss 0.0035674893856\n",
      "Epoch 39::Minibatch 473::LR 0.0123076923077 --> Loss 0.00231698493163\n",
      "Epoch 39::Minibatch 474::LR 0.0123076923077 --> Loss 0.00068150177598\n",
      "Epoch 39::Minibatch 475::LR 0.0123076923077 --> Loss 0.00460847775141\n",
      "Epoch 39::Minibatch 476::LR 0.0123076923077 --> Loss 0.00748308738073\n",
      "Epoch 39::Minibatch 477::LR 0.0123076923077 --> Loss 0.000910512407621\n",
      "Epoch 39::Minibatch 478::LR 0.0123076923077 --> Loss 0.00238831738631\n",
      "Epoch 39::Minibatch 479::LR 0.0123076923077 --> Loss 0.00194578329722\n",
      "Epoch 39::Minibatch 480::LR 0.0123076923077 --> Loss 0.00149786879619\n",
      "Epoch 39::Minibatch 481::LR 0.0123076923077 --> Loss 0.000958370963732\n",
      "Epoch 39::Minibatch 482::LR 0.0123076923077 --> Loss 0.00205526371797\n",
      "Epoch 39::Minibatch 483::LR 0.0123076923077 --> Loss 0.00296513338884\n",
      "Epoch 39::Minibatch 484::LR 0.0123076923077 --> Loss 0.00332173069318\n",
      "Epoch 39::Minibatch 485::LR 0.0123076923077 --> Loss 0.000757064471642\n",
      "Epoch 39::Minibatch 486::LR 0.0123076923077 --> Loss 0.00282447576523\n",
      "Epoch 39::Minibatch 487::LR 0.0123076923077 --> Loss 0.00326956570148\n",
      "Epoch 39::Minibatch 488::LR 0.0123076923077 --> Loss 0.00200239320596\n",
      "Epoch 39::Minibatch 489::LR 0.0123076923077 --> Loss 0.00306582927704\n",
      "Epoch 39::Minibatch 490::LR 0.0123076923077 --> Loss 0.000412123973171\n",
      "Epoch 39::Minibatch 491::LR 0.0123076923077 --> Loss 0.00301655928294\n",
      "Epoch 39::Minibatch 492::LR 0.0123076923077 --> Loss 0.00306158582369\n",
      "Epoch 39::Minibatch 493::LR 0.0123076923077 --> Loss 0.00300310452779\n",
      "Epoch 39::Minibatch 494::LR 0.0123076923077 --> Loss 0.000728108684222\n",
      "Epoch 39::Minibatch 495::LR 0.0123076923077 --> Loss 0.00181385596593\n",
      "Epoch 39::Minibatch 496::LR 0.0123076923077 --> Loss 0.00277044534683\n",
      "Epoch 39::Minibatch 497::LR 0.0123076923077 --> Loss 0.000907563269138\n",
      "Epoch 39::Minibatch 498::LR 0.0123076923077 --> Loss 0.000544194380442\n",
      "Epoch 39::Minibatch 499::LR 0.0123076923077 --> Loss 0.00335491657257\n",
      "Epoch 39::Minibatch 500::LR 0.0123076923077 --> Loss 0.00141840656598\n",
      "Epoch 39::Minibatch 501::LR 0.0123076923077 --> Loss 0.00194495896498\n",
      "Epoch 39::Minibatch 502::LR 0.0123076923077 --> Loss 0.00369239489237\n",
      "Epoch 39::Minibatch 503::LR 0.0123076923077 --> Loss 0.00648339867592\n",
      "Epoch 39::Minibatch 504::LR 0.0123076923077 --> Loss 0.00638147513072\n",
      "Epoch 39::Minibatch 505::LR 0.0123076923077 --> Loss 0.00380063096682\n",
      "Epoch 39::Minibatch 506::LR 0.0123076923077 --> Loss 0.00323643346628\n",
      "Epoch 39::Minibatch 507::LR 0.0123076923077 --> Loss 0.00560340921084\n",
      "Epoch 39::Minibatch 508::LR 0.0123076923077 --> Loss 0.00337260007858\n",
      "Epoch 39::Minibatch 509::LR 0.0123076923077 --> Loss 0.00414859056473\n",
      "Epoch 39::Minibatch 510::LR 0.0123076923077 --> Loss 0.0043374812603\n",
      "Epoch 39::Minibatch 511::LR 0.0123076923077 --> Loss 0.00405143936475\n",
      "Epoch 39::Minibatch 512::LR 0.0123076923077 --> Loss 0.0026936451594\n",
      "Epoch 39::Minibatch 513::LR 0.0123076923077 --> Loss 0.000585466126601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 514::LR 0.0123076923077 --> Loss 0.00254255950451\n",
      "Epoch 39::Minibatch 515::LR 0.0123076923077 --> Loss 0.00298392693202\n",
      "Epoch 39::Minibatch 516::LR 0.0123076923077 --> Loss 0.00389111916224\n",
      "Epoch 39::Minibatch 517::LR 0.0123076923077 --> Loss 0.00365205168724\n",
      "Epoch 39::Minibatch 518::LR 0.0123076923077 --> Loss 0.00256044348081\n",
      "Epoch 39::Minibatch 519::LR 0.0123076923077 --> Loss 0.00362587134043\n",
      "Epoch 39::Minibatch 520::LR 0.0123076923077 --> Loss 0.00573408842087\n",
      "Epoch 39::Minibatch 521::LR 0.0123076923077 --> Loss 0.00583308855693\n",
      "Epoch 39::Minibatch 522::LR 0.0123076923077 --> Loss 0.00673481941223\n",
      "Epoch 39::Minibatch 523::LR 0.0123076923077 --> Loss 0.000617605199416\n",
      "Epoch 39::Minibatch 524::LR 0.0123076923077 --> Loss 0.00137319594622\n",
      "Epoch 39::Minibatch 525::LR 0.0123076923077 --> Loss 0.00297180791696\n",
      "Epoch 39::Minibatch 526::LR 0.0123076923077 --> Loss 0.0035943198204\n",
      "Epoch 39::Minibatch 527::LR 0.0123076923077 --> Loss 0.00209970255693\n",
      "Epoch 39::Minibatch 528::LR 0.0123076923077 --> Loss 0.000898673137029\n",
      "Epoch 39::Minibatch 529::LR 0.0123076923077 --> Loss 0.00370769063632\n",
      "Epoch 39::Minibatch 530::LR 0.0123076923077 --> Loss 0.00365475416183\n",
      "Epoch 39::Minibatch 531::LR 0.0123076923077 --> Loss 0.00323903361956\n",
      "Epoch 39::Minibatch 532::LR 0.0123076923077 --> Loss 0.00254470070203\n",
      "Epoch 39::Minibatch 533::LR 0.0123076923077 --> Loss 0.00482907613118\n",
      "Epoch 39::Minibatch 534::LR 0.0123076923077 --> Loss 0.00365271846453\n",
      "Epoch 39::Minibatch 535::LR 0.0123076923077 --> Loss 0.00335841139158\n",
      "Epoch 39::Minibatch 536::LR 0.0123076923077 --> Loss 0.00211157898108\n",
      "Epoch 39::Minibatch 537::LR 0.0123076923077 --> Loss 0.000576479931672\n",
      "Epoch 39::Minibatch 538::LR 0.0123076923077 --> Loss 0.0016092145443\n",
      "Epoch 39::Minibatch 539::LR 0.0123076923077 --> Loss 0.00326957682769\n",
      "Epoch 39::Minibatch 540::LR 0.0123076923077 --> Loss 0.0033588262399\n",
      "Epoch 39::Minibatch 541::LR 0.0123076923077 --> Loss 0.00281378428141\n",
      "Epoch 39::Minibatch 542::LR 0.0123076923077 --> Loss 0.0024115439256\n",
      "Epoch 39::Minibatch 543::LR 0.0123076923077 --> Loss 0.00250744183858\n",
      "Epoch 39::Minibatch 544::LR 0.0123076923077 --> Loss 0.00412685275078\n",
      "Epoch 39::Minibatch 545::LR 0.0123076923077 --> Loss 0.00192366778851\n",
      "Epoch 39::Minibatch 546::LR 0.0123076923077 --> Loss 0.000662834246953\n",
      "Epoch 39::Minibatch 547::LR 0.0123076923077 --> Loss 0.00255911191305\n",
      "Epoch 39::Minibatch 548::LR 0.0123076923077 --> Loss 0.00330974360307\n",
      "Epoch 39::Minibatch 549::LR 0.0123076923077 --> Loss 0.00904973824819\n",
      "Epoch 39::Minibatch 550::LR 0.0123076923077 --> Loss 0.00119013230006\n",
      "Epoch 39::Minibatch 551::LR 0.0123076923077 --> Loss 0.00246612926324\n",
      "Epoch 39::Minibatch 552::LR 0.0123076923077 --> Loss 0.0034074695905\n",
      "Epoch 39::Minibatch 553::LR 0.0123076923077 --> Loss 0.00286571661631\n",
      "Epoch 39::Minibatch 554::LR 0.0123076923077 --> Loss 0.00352498571078\n",
      "Epoch 39::Minibatch 555::LR 0.0123076923077 --> Loss 0.00092320750157\n",
      "Epoch 39::Minibatch 556::LR 0.0123076923077 --> Loss 0.00188717385133\n",
      "Epoch 39::Minibatch 557::LR 0.0123076923077 --> Loss 0.00241657376289\n",
      "Epoch 39::Minibatch 558::LR 0.0123076923077 --> Loss 0.0035572763284\n",
      "Epoch 39::Minibatch 559::LR 0.0123076923077 --> Loss 0.00364019393921\n",
      "Epoch 39::Minibatch 560::LR 0.0123076923077 --> Loss 0.00305606285731\n",
      "Epoch 39::Minibatch 561::LR 0.0123076923077 --> Loss 0.00260508775711\n",
      "Epoch 39::Minibatch 562::LR 0.0123076923077 --> Loss 0.00232589821021\n",
      "Epoch 39::Minibatch 563::LR 0.0123076923077 --> Loss 0.00393083731333\n",
      "Epoch 39::Minibatch 564::LR 0.0123076923077 --> Loss 0.00301235655944\n",
      "Epoch 39::Minibatch 565::LR 0.0123076923077 --> Loss 0.00355528593063\n",
      "Epoch 39::Minibatch 566::LR 0.0123076923077 --> Loss 0.00213607231776\n",
      "Epoch 39::Minibatch 567::LR 0.0123076923077 --> Loss 0.00254907031854\n",
      "Epoch 39::Minibatch 568::LR 0.0123076923077 --> Loss 0.00169758160909\n",
      "Epoch 39::Minibatch 569::LR 0.0123076923077 --> Loss 0.000555382271608\n",
      "Epoch 39::Minibatch 570::LR 0.0123076923077 --> Loss 0.00158074567715\n",
      "Epoch 39::Minibatch 571::LR 0.0123076923077 --> Loss 0.00197058320045\n",
      "Epoch 39::Minibatch 572::LR 0.0123076923077 --> Loss 0.00213039477666\n",
      "Epoch 39::Minibatch 573::LR 0.0123076923077 --> Loss 0.00139657855034\n",
      "Epoch 39::Minibatch 574::LR 0.0123076923077 --> Loss 0.00103819549084\n",
      "Epoch 39::Minibatch 575::LR 0.0123076923077 --> Loss 0.00167569001516\n",
      "Epoch 39::Minibatch 576::LR 0.0123076923077 --> Loss 0.00199205001195\n",
      "Epoch 39::Minibatch 577::LR 0.0123076923077 --> Loss 0.00157276640336\n",
      "Epoch 39::Minibatch 578::LR 0.0123076923077 --> Loss 0.00124206612508\n",
      "Epoch 39::Minibatch 579::LR 0.0123076923077 --> Loss 0.00116779436668\n",
      "Epoch 39::Minibatch 580::LR 0.0123076923077 --> Loss 0.00190476000309\n",
      "Epoch 39::Minibatch 581::LR 0.0123076923077 --> Loss 0.00169305642446\n",
      "Epoch 39::Minibatch 582::LR 0.0123076923077 --> Loss 0.00421737790108\n",
      "Epoch 39::Minibatch 583::LR 0.0123076923077 --> Loss 0.000953913728396\n",
      "Epoch 39::Minibatch 584::LR 0.0123076923077 --> Loss 0.00131048729022\n",
      "Epoch 39::Minibatch 585::LR 0.0123076923077 --> Loss 0.00377703110377\n",
      "Epoch 39::Minibatch 586::LR 0.0123076923077 --> Loss 0.00362647294998\n",
      "Epoch 39::Minibatch 587::LR 0.0123076923077 --> Loss 0.00110050529242\n",
      "Epoch 39::Minibatch 588::LR 0.0123076923077 --> Loss 0.00134784479936\n",
      "Epoch 39::Minibatch 589::LR 0.0123076923077 --> Loss 0.00267778416475\n",
      "Epoch 39::Minibatch 590::LR 0.0123076923077 --> Loss 0.00173374632994\n",
      "Epoch 39::Minibatch 591::LR 0.0123076923077 --> Loss 0.00256199856599\n",
      "Epoch 39::Minibatch 592::LR 0.0123076923077 --> Loss 0.00113323539495\n",
      "Epoch 39::Minibatch 593::LR 0.0123076923077 --> Loss 0.00240925232569\n",
      "Epoch 39::Minibatch 594::LR 0.0123076923077 --> Loss 0.00245331466198\n",
      "Epoch 39::Minibatch 595::LR 0.0123076923077 --> Loss 0.00302632331848\n",
      "Epoch 39::Minibatch 596::LR 0.0123076923077 --> Loss 0.00178362150987\n",
      "Epoch 39::Minibatch 597::LR 0.0123076923077 --> Loss 0.00114392479261\n",
      "Epoch 39::Minibatch 598::LR 0.0123076923077 --> Loss 0.00271505554517\n",
      "Epoch 39::Minibatch 599::LR 0.0123076923077 --> Loss 0.00175693372885\n",
      "Epoch 39::Minibatch 600::LR 0.0123076923077 --> Loss 0.00207166274389\n",
      "Epoch 39::Minibatch 601::LR 0.0123076923077 --> Loss 0.00365197579066\n",
      "Epoch 39::Minibatch 602::LR 0.0123076923077 --> Loss 0.00206092536449\n",
      "Epoch 39::Minibatch 603::LR 0.0123076923077 --> Loss 0.00260447820028\n",
      "Epoch 39::Minibatch 604::LR 0.0123076923077 --> Loss 0.00160925467809\n",
      "Epoch 39::Minibatch 605::LR 0.0123076923077 --> Loss 0.0022264178594\n",
      "Epoch 39::Minibatch 606::LR 0.0123076923077 --> Loss 0.00180667459965\n",
      "Epoch 39::Minibatch 607::LR 0.0123076923077 --> Loss 0.000812455713749\n",
      "Epoch 39::Minibatch 608::LR 0.0123076923077 --> Loss 0.00152646869421\n",
      "Epoch 39::Minibatch 609::LR 0.0123076923077 --> Loss 0.00242107709249\n",
      "Epoch 39::Minibatch 610::LR 0.0123076923077 --> Loss 0.00406581521034\n",
      "Epoch 39::Minibatch 611::LR 0.0123076923077 --> Loss 0.00273373981317\n",
      "Epoch 39::Minibatch 612::LR 0.0123076923077 --> Loss 0.000466581781705\n",
      "Epoch 39::Minibatch 613::LR 0.0123076923077 --> Loss 0.00131286402543\n",
      "Epoch 39::Minibatch 614::LR 0.0123076923077 --> Loss 0.00237361212571\n",
      "Epoch 39::Minibatch 615::LR 0.0123076923077 --> Loss 0.00162920504808\n",
      "Epoch 39::Minibatch 616::LR 0.0123076923077 --> Loss 0.000908380746841\n",
      "Epoch 39::Minibatch 617::LR 0.0123076923077 --> Loss 0.000489183863004\n",
      "Epoch 39::Minibatch 618::LR 0.0123076923077 --> Loss 0.00302789866924\n",
      "Epoch 39::Minibatch 619::LR 0.0123076923077 --> Loss 0.0019249600172\n",
      "Epoch 39::Minibatch 620::LR 0.0123076923077 --> Loss 0.00166395117839\n",
      "Epoch 39::Minibatch 621::LR 0.0123076923077 --> Loss 0.000837197601795\n",
      "Epoch 39::Minibatch 622::LR 0.0123076923077 --> Loss 0.000771815776825\n",
      "Epoch 39::Minibatch 623::LR 0.0123076923077 --> Loss 0.00221066991488\n",
      "Epoch 39::Minibatch 624::LR 0.0123076923077 --> Loss 0.00174673060576\n",
      "Epoch 39::Minibatch 625::LR 0.0123076923077 --> Loss 0.00256220678488\n",
      "Epoch 39::Minibatch 626::LR 0.0123076923077 --> Loss 0.00328753829002\n",
      "Epoch 39::Minibatch 627::LR 0.0123076923077 --> Loss 0.00125218023856\n",
      "Epoch 39::Minibatch 628::LR 0.0123076923077 --> Loss 0.000870373745759\n",
      "Epoch 39::Minibatch 629::LR 0.0123076923077 --> Loss 0.00290392855803\n",
      "Epoch 39::Minibatch 630::LR 0.0123076923077 --> Loss 0.00285467286905\n",
      "Epoch 39::Minibatch 631::LR 0.0123076923077 --> Loss 0.00469388365746\n",
      "Epoch 39::Minibatch 632::LR 0.0123076923077 --> Loss 0.000799415707588\n",
      "Epoch 39::Minibatch 633::LR 0.0123076923077 --> Loss 0.00158937772115\n",
      "Epoch 39::Minibatch 634::LR 0.0123076923077 --> Loss 0.00312520762285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 635::LR 0.0123076923077 --> Loss 0.00519583145777\n",
      "Epoch 39::Minibatch 636::LR 0.0123076923077 --> Loss 0.00437790075938\n",
      "Epoch 39::Minibatch 637::LR 0.0123076923077 --> Loss 0.000694208095471\n",
      "Epoch 39::Minibatch 638::LR 0.0123076923077 --> Loss 0.0014935896794\n",
      "Epoch 39::Minibatch 639::LR 0.0123076923077 --> Loss 0.00313385784626\n",
      "Epoch 39::Minibatch 640::LR 0.0123076923077 --> Loss 0.0043229675293\n",
      "Epoch 39::Minibatch 641::LR 0.0123076923077 --> Loss 0.0029729539156\n",
      "Epoch 39::Minibatch 642::LR 0.0123076923077 --> Loss 0.000533747971058\n",
      "Epoch 39::Minibatch 643::LR 0.0123076923077 --> Loss 0.00229144473871\n",
      "Epoch 39::Minibatch 644::LR 0.0123076923077 --> Loss 0.00380197167397\n",
      "Epoch 39::Minibatch 645::LR 0.0123076923077 --> Loss 0.00459579745928\n",
      "Epoch 39::Minibatch 646::LR 0.0123076923077 --> Loss 0.00152526438236\n",
      "Epoch 39::Minibatch 647::LR 0.0123076923077 --> Loss 0.000457420945168\n",
      "Epoch 39::Minibatch 648::LR 0.0123076923077 --> Loss 0.00264031648636\n",
      "Epoch 39::Minibatch 649::LR 0.0123076923077 --> Loss 0.00298798064391\n",
      "Epoch 39::Minibatch 650::LR 0.0123076923077 --> Loss 0.00300982058048\n",
      "Epoch 39::Minibatch 651::LR 0.0123076923077 --> Loss 0.00129792024692\n",
      "Epoch 39::Minibatch 652::LR 0.0123076923077 --> Loss 0.000781498054663\n",
      "Epoch 39::Minibatch 653::LR 0.0123076923077 --> Loss 0.00275552531083\n",
      "Epoch 39::Minibatch 654::LR 0.0123076923077 --> Loss 0.0030663104852\n",
      "Epoch 39::Minibatch 655::LR 0.0123076923077 --> Loss 0.0037014846007\n",
      "Epoch 39::Minibatch 656::LR 0.0123076923077 --> Loss 0.00075942153732\n",
      "Epoch 39::Minibatch 657::LR 0.0123076923077 --> Loss 0.0022512169679\n",
      "Epoch 39::Minibatch 658::LR 0.0123076923077 --> Loss 0.00426807920138\n",
      "Epoch 39::Minibatch 659::LR 0.0123076923077 --> Loss 0.0021576265494\n",
      "Epoch 39::Minibatch 660::LR 0.0123076923077 --> Loss 0.0026396069924\n",
      "Epoch 39::Minibatch 661::LR 0.0123076923077 --> Loss 0.00216658333937\n",
      "Epoch 39::Minibatch 662::LR 0.0123076923077 --> Loss 0.00178231616815\n",
      "Epoch 39::Minibatch 663::LR 0.0123076923077 --> Loss 0.00353354096413\n",
      "Epoch 39::Minibatch 664::LR 0.0123076923077 --> Loss 0.00297593772411\n",
      "Epoch 39::Minibatch 665::LR 0.0123076923077 --> Loss 0.000689130723476\n",
      "Epoch 39::Minibatch 666::LR 0.0123076923077 --> Loss 0.00389048139254\n",
      "Epoch 39::Minibatch 667::LR 0.0123076923077 --> Loss 0.00254960119724\n",
      "Epoch 39::Minibatch 668::LR 0.0123076923077 --> Loss 0.00600805679957\n",
      "Epoch 39::Minibatch 669::LR 0.0123076923077 --> Loss 0.0010702547431\n",
      "Epoch 39::Minibatch 670::LR 0.0123076923077 --> Loss 0.00131597578526\n",
      "Epoch 39::Minibatch 671::LR 0.0123076923077 --> Loss 0.00497850418091\n",
      "Epoch 39::Minibatch 672::LR 0.0123076923077 --> Loss 0.00323051850001\n",
      "Epoch 39::Minibatch 673::LR 0.0123076923077 --> Loss 0.00158249994119\n",
      "Epoch 39::Minibatch 674::LR 0.0123076923077 --> Loss 0.000511010934909\n",
      "Epoch 39::Minibatch 675::LR 0.0123076923077 --> Loss 0.0021962972482\n",
      "Epoch 39::Minibatch 676::LR 0.0123076923077 --> Loss 0.00219054202239\n",
      "Epoch 39::Minibatch 677::LR 0.0123076923077 --> Loss 0.00265253384908\n",
      "Epoch 39::Minibatch 678::LR 0.0123076923077 --> Loss 0.00183906078339\n",
      "Epoch 39::Minibatch 679::LR 0.0123076923077 --> Loss 0.00324121971925\n",
      "Epoch 39::Minibatch 680::LR 0.0123076923077 --> Loss 0.00210806032022\n",
      "Epoch 39::Minibatch 681::LR 0.0123076923077 --> Loss 0.00233607610067\n",
      "Epoch 39::Minibatch 682::LR 0.0123076923077 --> Loss 0.000762130469084\n",
      "Epoch 39::Minibatch 683::LR 0.0123076923077 --> Loss 0.00224000255267\n",
      "Epoch 39::Minibatch 684::LR 0.0123076923077 --> Loss 0.00234520991643\n",
      "Epoch 39::Minibatch 685::LR 0.0123076923077 --> Loss 0.00278056581815\n",
      "Epoch 39::Minibatch 686::LR 0.0123076923077 --> Loss 0.00157474001249\n",
      "Epoch 39::Minibatch 687::LR 0.0123076923077 --> Loss 0.000877459645271\n",
      "Epoch 39::Minibatch 688::LR 0.0123076923077 --> Loss 0.00281228065491\n",
      "Epoch 39::Minibatch 689::LR 0.0123076923077 --> Loss 0.00244132260482\n",
      "Epoch 39::Minibatch 690::LR 0.0123076923077 --> Loss 0.00184683640798\n",
      "Epoch 39::Minibatch 691::LR 0.0123076923077 --> Loss 0.000657601108154\n",
      "Epoch 39::Minibatch 692::LR 0.0123076923077 --> Loss 0.00242949863275\n",
      "Epoch 39::Minibatch 693::LR 0.0123076923077 --> Loss 0.00264414827029\n",
      "Epoch 39::Minibatch 694::LR 0.0123076923077 --> Loss 0.00296359320482\n",
      "Epoch 39::Minibatch 695::LR 0.0123076923077 --> Loss 0.00182980736097\n",
      "Epoch 39::Minibatch 696::LR 0.0123076923077 --> Loss 0.0020150377353\n",
      "Epoch 39::Minibatch 697::LR 0.0123076923077 --> Loss 0.00139515221119\n",
      "Epoch 39::Minibatch 698::LR 0.0123076923077 --> Loss 0.00166976531347\n",
      "Epoch 39::Minibatch 699::LR 0.0123076923077 --> Loss 0.00362585306168\n",
      "Epoch 39::Minibatch 700::LR 0.0123076923077 --> Loss 0.00250852505366\n",
      "Epoch 39::Minibatch 701::LR 0.0123076923077 --> Loss 0.00184110939503\n",
      "Epoch 39::Minibatch 702::LR 0.0123076923077 --> Loss 0.00167345881462\n",
      "Epoch 39::Minibatch 703::LR 0.0123076923077 --> Loss 0.00419729868571\n",
      "Epoch 39::Minibatch 704::LR 0.0123076923077 --> Loss 0.00180772205194\n",
      "Epoch 39::Minibatch 705::LR 0.0123076923077 --> Loss 0.00279117623965\n",
      "Epoch 39::Minibatch 706::LR 0.0123076923077 --> Loss 0.00216762383779\n",
      "Epoch 39::Minibatch 707::LR 0.0123076923077 --> Loss 0.00118746290604\n",
      "Epoch 39::Minibatch 708::LR 0.0123076923077 --> Loss 0.00173028906186\n",
      "Epoch 39::Minibatch 709::LR 0.0123076923077 --> Loss 0.00166413227717\n",
      "Epoch 39::Minibatch 710::LR 0.0123076923077 --> Loss 0.00258809109529\n",
      "Epoch 39::Minibatch 711::LR 0.0123076923077 --> Loss 0.00200177192688\n",
      "Epoch 39::Minibatch 712::LR 0.0123076923077 --> Loss 0.00139193326235\n",
      "Epoch 39::Minibatch 713::LR 0.0123076923077 --> Loss 0.00182167212168\n",
      "Epoch 39::Minibatch 714::LR 0.0123076923077 --> Loss 0.00290379941463\n",
      "Epoch 39::Minibatch 715::LR 0.0123076923077 --> Loss 0.00289306660493\n",
      "Epoch 39::Minibatch 716::LR 0.0123076923077 --> Loss 0.0016847550869\n",
      "Epoch 39::Minibatch 717::LR 0.0123076923077 --> Loss 0.00169362306595\n",
      "Epoch 39::Minibatch 718::LR 0.0123076923077 --> Loss 0.00129789034526\n",
      "Epoch 39::Minibatch 719::LR 0.0123076923077 --> Loss 0.00175480127335\n",
      "Epoch 39::Minibatch 720::LR 0.0123076923077 --> Loss 0.00285317361355\n",
      "Epoch 39::Minibatch 721::LR 0.0123076923077 --> Loss 0.000607408384482\n",
      "Epoch 39::Minibatch 722::LR 0.0123076923077 --> Loss 0.004477947553\n",
      "Epoch 39::Minibatch 723::LR 0.0123076923077 --> Loss 0.0047303712368\n",
      "Epoch 39::Minibatch 724::LR 0.0123076923077 --> Loss 0.00096587618192\n",
      "Epoch 39::Minibatch 725::LR 0.0123076923077 --> Loss 0.00199690441291\n",
      "Epoch 39::Minibatch 726::LR 0.0123076923077 --> Loss 0.00325416107972\n",
      "Epoch 39::Minibatch 727::LR 0.0123076923077 --> Loss 0.00287993570169\n",
      "Epoch 39::Minibatch 728::LR 0.0123076923077 --> Loss 0.00064259365201\n",
      "Epoch 39::Minibatch 729::LR 0.0123076923077 --> Loss 0.000711731115977\n",
      "Epoch 39::Minibatch 730::LR 0.0123076923077 --> Loss 0.00286306838195\n",
      "Epoch 39::Minibatch 731::LR 0.0123076923077 --> Loss 0.00262999494871\n",
      "Epoch 39::Minibatch 732::LR 0.0123076923077 --> Loss 0.00196567813555\n",
      "Epoch 39::Minibatch 733::LR 0.0123076923077 --> Loss 0.000566891829173\n",
      "Epoch 39::Minibatch 734::LR 0.0123076923077 --> Loss 0.00160623013973\n",
      "Epoch 39::Minibatch 735::LR 0.0123076923077 --> Loss 0.00254127204418\n",
      "Epoch 39::Minibatch 736::LR 0.0123076923077 --> Loss 0.00346916516622\n",
      "Epoch 39::Minibatch 737::LR 0.0123076923077 --> Loss 0.00281544804573\n",
      "Epoch 39::Minibatch 738::LR 0.0123076923077 --> Loss 0.00126085559527\n",
      "Epoch 39::Minibatch 739::LR 0.0123076923077 --> Loss 0.00227702001731\n",
      "Epoch 39::Minibatch 740::LR 0.0123076923077 --> Loss 0.00371254285177\n",
      "Epoch 39::Minibatch 741::LR 0.0123076923077 --> Loss 0.0024679116408\n",
      "Epoch 39::Minibatch 742::LR 0.0123076923077 --> Loss 0.00203835129738\n",
      "Epoch 39::Minibatch 743::LR 0.0123076923077 --> Loss 0.00151254514853\n",
      "Epoch 39::Minibatch 744::LR 0.0123076923077 --> Loss 0.00189899543921\n",
      "Epoch 39::Minibatch 745::LR 0.0123076923077 --> Loss 0.00274710694949\n",
      "Epoch 39::Minibatch 746::LR 0.0123076923077 --> Loss 0.00278235157331\n",
      "Epoch 39::Minibatch 747::LR 0.0123076923077 --> Loss 0.0017352382342\n",
      "Epoch 39::Minibatch 748::LR 0.0123076923077 --> Loss 0.000624933193127\n",
      "Epoch 39::Minibatch 749::LR 0.0123076923077 --> Loss 0.00169064819813\n",
      "Epoch 39::Minibatch 750::LR 0.0123076923077 --> Loss 0.00239680806796\n",
      "Epoch 39::Minibatch 751::LR 0.0123076923077 --> Loss 0.00301297406356\n",
      "Epoch 39::Minibatch 752::LR 0.0123076923077 --> Loss 0.0015618506074\n",
      "Epoch 39::Minibatch 753::LR 0.0123076923077 --> Loss 0.00220180690289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 754::LR 0.0123076923077 --> Loss 0.00243948698044\n",
      "Epoch 39::Minibatch 755::LR 0.0123076923077 --> Loss 0.00264483630657\n",
      "Epoch 39::Minibatch 756::LR 0.0123076923077 --> Loss 0.00127719789743\n",
      "Epoch 39::Minibatch 757::LR 0.0123076923077 --> Loss 0.000546617855628\n",
      "Epoch 39::Minibatch 758::LR 0.0123076923077 --> Loss 0.00156468629837\n",
      "Epoch 39::Minibatch 759::LR 0.0123076923077 --> Loss 0.00321374773979\n",
      "Epoch 39::Minibatch 760::LR 0.0123076923077 --> Loss 0.00270596027374\n",
      "Epoch 39::Minibatch 761::LR 0.0123076923077 --> Loss 0.00513800859451\n",
      "Epoch 39::Minibatch 762::LR 0.0123076923077 --> Loss 0.00340512553851\n",
      "Epoch 39::Minibatch 763::LR 0.0123076923077 --> Loss 0.00332699577014\n",
      "Epoch 39::Minibatch 764::LR 0.0123076923077 --> Loss 0.00294987360636\n",
      "Epoch 39::Minibatch 765::LR 0.0123076923077 --> Loss 0.00121256728967\n",
      "Epoch 39::Minibatch 766::LR 0.0123076923077 --> Loss 0.00228382647038\n",
      "Epoch 39::Minibatch 767::LR 0.0123076923077 --> Loss 0.00461863438288\n",
      "Epoch 39::Minibatch 768::LR 0.0123076923077 --> Loss 0.00357322096825\n",
      "Epoch 39::Minibatch 769::LR 0.0123076923077 --> Loss 0.00179914196332\n",
      "Epoch 39::Minibatch 770::LR 0.0123076923077 --> Loss 0.00150633017222\n",
      "Epoch 39::Minibatch 771::LR 0.0123076923077 --> Loss 0.00325076421102\n",
      "Epoch 39::Minibatch 772::LR 0.0123076923077 --> Loss 0.00364748358727\n",
      "Epoch 39::Minibatch 773::LR 0.0123076923077 --> Loss 0.00318031569322\n",
      "Epoch 39::Minibatch 774::LR 0.0123076923077 --> Loss 0.00190298994382\n",
      "Epoch 39::Minibatch 775::LR 0.0123076923077 --> Loss 0.00308066248894\n",
      "Epoch 39::Minibatch 776::LR 0.0123076923077 --> Loss 0.00393845637639\n",
      "Epoch 39::Minibatch 777::LR 0.0123076923077 --> Loss 0.00560336271922\n",
      "Epoch 39::Minibatch 778::LR 0.0123076923077 --> Loss 0.00640511314074\n",
      "Epoch 39::Minibatch 779::LR 0.0123076923077 --> Loss 0.00246955533822\n",
      "Epoch 39::Minibatch 780::LR 0.0123076923077 --> Loss 0.00146686265866\n",
      "Epoch 39::Minibatch 781::LR 0.0123076923077 --> Loss 0.00348268270493\n",
      "Epoch 39::Minibatch 782::LR 0.0123076923077 --> Loss 0.00386445204417\n",
      "Epoch 39::Minibatch 783::LR 0.0123076923077 --> Loss 0.00225840985775\n",
      "Epoch 39::Minibatch 784::LR 0.0123076923077 --> Loss 0.000712526887655\n",
      "Epoch 39::Minibatch 785::LR 0.0123076923077 --> Loss 0.0035872399807\n",
      "Epoch 39::Minibatch 786::LR 0.0123076923077 --> Loss 0.00373851299286\n",
      "Epoch 39::Minibatch 787::LR 0.0123076923077 --> Loss 0.00257410526276\n",
      "Epoch 39::Minibatch 788::LR 0.0123076923077 --> Loss 0.00249785125256\n",
      "Epoch 39::Minibatch 789::LR 0.0123076923077 --> Loss 0.000722070733706\n",
      "Epoch 39::Minibatch 790::LR 0.0123076923077 --> Loss 0.00319459954898\n",
      "Epoch 39::Minibatch 791::LR 0.0123076923077 --> Loss 0.00318177163601\n",
      "Epoch 39::Minibatch 792::LR 0.0123076923077 --> Loss 0.00299371898174\n",
      "Epoch 39::Minibatch 793::LR 0.0123076923077 --> Loss 0.00161486417055\n",
      "Epoch 39::Minibatch 794::LR 0.0123076923077 --> Loss 0.000983128150304\n",
      "Epoch 39::Minibatch 795::LR 0.0123076923077 --> Loss 0.00257107774417\n",
      "Epoch 39::Minibatch 796::LR 0.0123076923077 --> Loss 0.00457577149073\n",
      "Epoch 39::Minibatch 797::LR 0.0123076923077 --> Loss 0.00539689222972\n",
      "Epoch 39::Minibatch 798::LR 0.0123076923077 --> Loss 0.00291784862677\n",
      "Epoch 39::Minibatch 799::LR 0.0123076923077 --> Loss 0.00223339855671\n",
      "Epoch 39::Minibatch 800::LR 0.0123076923077 --> Loss 0.00199484864871\n",
      "Epoch 39::Minibatch 801::LR 0.0123076923077 --> Loss 0.00369706948598\n",
      "Epoch 39::Minibatch 802::LR 0.0123076923077 --> Loss 0.00116867919763\n",
      "Epoch 39::Minibatch 803::LR 0.0123076923077 --> Loss 0.00297411302725\n",
      "Epoch 39::Minibatch 804::LR 0.0123076923077 --> Loss 0.00204767386119\n",
      "Epoch 39::Minibatch 805::LR 0.0123076923077 --> Loss 0.00216573357582\n",
      "Epoch 39::Minibatch 806::LR 0.0123076923077 --> Loss 0.00319799939791\n",
      "Epoch 39::Minibatch 807::LR 0.0123076923077 --> Loss 0.00304200589657\n",
      "Epoch 39::Minibatch 808::LR 0.0123076923077 --> Loss 0.00287181695302\n",
      "Epoch 39::Minibatch 809::LR 0.0123076923077 --> Loss 0.00288987418016\n",
      "Epoch 39::Minibatch 810::LR 0.0123076923077 --> Loss 0.00391136089961\n",
      "Epoch 39::Minibatch 811::LR 0.0123076923077 --> Loss 0.00375941236814\n",
      "Epoch 39::Minibatch 812::LR 0.0123076923077 --> Loss 0.00348877191544\n",
      "Epoch 39::Minibatch 813::LR 0.0123076923077 --> Loss 0.00286574244499\n",
      "Epoch 39::Minibatch 814::LR 0.0123076923077 --> Loss 0.00148465792338\n",
      "Epoch 39::Minibatch 815::LR 0.0123076923077 --> Loss 0.00338856101036\n",
      "Epoch 39::Minibatch 816::LR 0.0123076923077 --> Loss 0.00385116298993\n",
      "Epoch 39::Minibatch 817::LR 0.0123076923077 --> Loss 0.00445308804512\n",
      "Epoch 39::Minibatch 818::LR 0.0123076923077 --> Loss 0.00122627228498\n",
      "Epoch 39::Minibatch 819::LR 0.0123076923077 --> Loss 0.000734728723764\n",
      "Epoch 39::Minibatch 820::LR 0.0123076923077 --> Loss 0.00493175029755\n",
      "Epoch 39::Minibatch 821::LR 0.0123076923077 --> Loss 0.00307216902574\n",
      "Epoch 39::Minibatch 822::LR 0.0123076923077 --> Loss 0.00367834647497\n",
      "Epoch 39::Minibatch 823::LR 0.0123076923077 --> Loss 0.00124469518661\n",
      "Epoch 39::Minibatch 824::LR 0.0123076923077 --> Loss 0.00137565433979\n",
      "Epoch 39::Minibatch 825::LR 0.0123076923077 --> Loss 0.00381247798602\n",
      "Epoch 39::Minibatch 826::LR 0.0123076923077 --> Loss 0.00451064586639\n",
      "Epoch 39::Minibatch 827::LR 0.0123076923077 --> Loss 0.0020519644022\n",
      "Epoch 39::Minibatch 828::LR 0.0123076923077 --> Loss 0.000485822806756\n",
      "Epoch 39::Minibatch 829::LR 0.0123076923077 --> Loss 0.00225910524527\n",
      "Epoch 39::Minibatch 830::LR 0.0123076923077 --> Loss 0.00384109298388\n",
      "Epoch 39::Minibatch 831::LR 0.0123076923077 --> Loss 0.00231626987457\n",
      "Epoch 39::Minibatch 832::LR 0.0123076923077 --> Loss 0.00204695145289\n",
      "Epoch 39::Minibatch 833::LR 0.0123076923077 --> Loss 0.00179360349973\n",
      "Epoch 39::Minibatch 834::LR 0.0123076923077 --> Loss 0.000794024268786\n",
      "Epoch 39::Minibatch 835::LR 0.0123076923077 --> Loss 0.00388191541036\n",
      "Epoch 39::Minibatch 836::LR 0.0123076923077 --> Loss 0.00357084989548\n",
      "Epoch 39::Minibatch 837::LR 0.0123076923077 --> Loss 0.00229077180227\n",
      "Epoch 39::Minibatch 838::LR 0.0123076923077 --> Loss 0.000653167764346\n",
      "Epoch 39::Minibatch 839::LR 0.0123076923077 --> Loss 0.00232018192609\n",
      "Epoch 39::Minibatch 840::LR 0.0123076923077 --> Loss 0.0028471527497\n",
      "Epoch 39::Minibatch 841::LR 0.0123076923077 --> Loss 0.0027458379666\n",
      "Epoch 39::Minibatch 842::LR 0.0123076923077 --> Loss 0.00211314578851\n",
      "Epoch 39::Minibatch 843::LR 0.0123076923077 --> Loss 0.000961076815923\n",
      "Epoch 39::Minibatch 844::LR 0.0123076923077 --> Loss 0.00146108984947\n",
      "Epoch 39::Minibatch 845::LR 0.0123076923077 --> Loss 0.00389089941978\n",
      "Epoch 39::Minibatch 846::LR 0.0123076923077 --> Loss 0.00167294323444\n",
      "Epoch 39::Minibatch 847::LR 0.0123076923077 --> Loss 0.00240352729956\n",
      "Epoch 39::Minibatch 848::LR 0.0123076923077 --> Loss 0.00117344150941\n",
      "Epoch 39::Minibatch 849::LR 0.0123076923077 --> Loss 0.00178897957007\n",
      "Epoch 39::Minibatch 850::LR 0.0123076923077 --> Loss 0.00317025840282\n",
      "Epoch 39::Minibatch 851::LR 0.0123076923077 --> Loss 0.00250832358996\n",
      "Epoch 39::Minibatch 852::LR 0.0123076923077 --> Loss 0.00115756392479\n",
      "Epoch 39::Minibatch 853::LR 0.0123076923077 --> Loss 0.00130845397711\n",
      "Epoch 39::Minibatch 854::LR 0.0123076923077 --> Loss 0.0025139550368\n",
      "Epoch 39::Minibatch 855::LR 0.0123076923077 --> Loss 0.00209275623163\n",
      "Epoch 39::Minibatch 856::LR 0.0123076923077 --> Loss 0.00177008529504\n",
      "Epoch 39::Minibatch 857::LR 0.0123076923077 --> Loss 0.00120463430882\n",
      "Epoch 39::Minibatch 858::LR 0.0123076923077 --> Loss 0.000606751143932\n",
      "Epoch 39::Minibatch 859::LR 0.0123076923077 --> Loss 0.00201053361098\n",
      "Epoch 39::Minibatch 860::LR 0.0123076923077 --> Loss 0.00131738672654\n",
      "Epoch 39::Minibatch 861::LR 0.0123076923077 --> Loss 0.000950530171394\n",
      "Epoch 39::Minibatch 862::LR 0.0123076923077 --> Loss 0.00373932361603\n",
      "Epoch 39::Minibatch 863::LR 0.0123076923077 --> Loss 0.00334819157918\n",
      "Epoch 39::Minibatch 864::LR 0.0123076923077 --> Loss 0.00258470416069\n",
      "Epoch 39::Minibatch 865::LR 0.0123076923077 --> Loss 0.000555554777384\n",
      "Epoch 39::Minibatch 866::LR 0.0123076923077 --> Loss 0.00205666323503\n",
      "Epoch 39::Minibatch 867::LR 0.0123076923077 --> Loss 0.00284986793995\n",
      "Epoch 39::Minibatch 868::LR 0.0123076923077 --> Loss 0.00245878517628\n",
      "Epoch 39::Minibatch 869::LR 0.0123076923077 --> Loss 0.00215056498845\n",
      "Epoch 39::Minibatch 870::LR 0.0123076923077 --> Loss 0.00314105967681\n",
      "Epoch 39::Minibatch 871::LR 0.0123076923077 --> Loss 0.00166564981143\n",
      "Epoch 39::Minibatch 872::LR 0.0123076923077 --> Loss 0.00206413090229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 873::LR 0.0123076923077 --> Loss 0.0024696346124\n",
      "Epoch 39::Minibatch 874::LR 0.0123076923077 --> Loss 0.00475215355555\n",
      "Epoch 39::Minibatch 875::LR 0.0123076923077 --> Loss 0.000694764306148\n",
      "Epoch 39::Minibatch 876::LR 0.0123076923077 --> Loss 0.00258719285329\n",
      "Epoch 39::Minibatch 877::LR 0.0123076923077 --> Loss 0.00403543233871\n",
      "Epoch 39::Minibatch 878::LR 0.0123076923077 --> Loss 0.00277610480785\n",
      "Epoch 39::Minibatch 879::LR 0.0123076923077 --> Loss 0.00382250150045\n",
      "Epoch 39::Minibatch 880::LR 0.0123076923077 --> Loss 0.00488033215205\n",
      "Epoch 39::Minibatch 881::LR 0.0123076923077 --> Loss 0.00407775918643\n",
      "Epoch 39::Minibatch 882::LR 0.0123076923077 --> Loss 0.00186803479989\n",
      "Epoch 39::Minibatch 883::LR 0.0123076923077 --> Loss 0.00366301814715\n",
      "Epoch 39::Minibatch 884::LR 0.0123076923077 --> Loss 0.00282681405544\n",
      "Epoch 39::Minibatch 885::LR 0.0123076923077 --> Loss 0.00258790791035\n",
      "Epoch 39::Minibatch 886::LR 0.0123076923077 --> Loss 0.000445242275794\n",
      "Epoch 39::Minibatch 887::LR 0.0123076923077 --> Loss 0.00565395991007\n",
      "Epoch 39::Minibatch 888::LR 0.0123076923077 --> Loss 0.0024014099439\n",
      "Epoch 39::Minibatch 889::LR 0.0123076923077 --> Loss 0.00245960056782\n",
      "Epoch 39::Minibatch 890::LR 0.0123076923077 --> Loss 0.00352808872859\n",
      "Epoch 39::Minibatch 891::LR 0.0123076923077 --> Loss 0.00167290687561\n",
      "Epoch 39::Minibatch 892::LR 0.0123076923077 --> Loss 0.000774357418219\n",
      "Epoch 39::Minibatch 893::LR 0.0123076923077 --> Loss 0.00220093349616\n",
      "Epoch 39::Minibatch 894::LR 0.0123076923077 --> Loss 0.00192451417446\n",
      "Epoch 39::Minibatch 895::LR 0.0123076923077 --> Loss 0.00223737378915\n",
      "Epoch 39::Minibatch 896::LR 0.0123076923077 --> Loss 0.00126551876465\n",
      "Epoch 39::Minibatch 897::LR 0.0123076923077 --> Loss 0.000662847061952\n",
      "Epoch 39::Minibatch 898::LR 0.0123076923077 --> Loss 0.00191036661466\n",
      "Epoch 39::Minibatch 899::LR 0.0123076923077 --> Loss 0.00243301371733\n",
      "Epoch 39::Minibatch 900::LR 0.0123076923077 --> Loss 0.00296274165312\n",
      "Epoch 39::Minibatch 901::LR 0.0123076923077 --> Loss 0.000584920297066\n",
      "Epoch 39::Minibatch 902::LR 0.0123076923077 --> Loss 0.00138428429763\n",
      "Epoch 39::Minibatch 903::LR 0.0123076923077 --> Loss 0.00257096350193\n",
      "Epoch 39::Minibatch 904::LR 0.0123076923077 --> Loss 0.0018010054032\n",
      "Epoch 39::Minibatch 905::LR 0.0123076923077 --> Loss 0.00138428777456\n",
      "Epoch 39::Minibatch 906::LR 0.0123076923077 --> Loss 0.00100854853789\n",
      "Epoch 39::Minibatch 907::LR 0.0123076923077 --> Loss 0.00153544177612\n",
      "Epoch 39::Minibatch 908::LR 0.0123076923077 --> Loss 0.00207480947177\n",
      "Epoch 39::Minibatch 909::LR 0.0123076923077 --> Loss 0.00193033854167\n",
      "Epoch 39::Minibatch 910::LR 0.0123076923077 --> Loss 0.000840784609318\n",
      "Epoch 39::Minibatch 911::LR 0.0123076923077 --> Loss 0.00128564884265\n",
      "Epoch 39::Minibatch 912::LR 0.0123076923077 --> Loss 0.00209493319194\n",
      "Epoch 39::Minibatch 913::LR 0.0123076923077 --> Loss 0.0023521878322\n",
      "Epoch 39::Minibatch 914::LR 0.0123076923077 --> Loss 0.00130474835634\n",
      "Epoch 39::Minibatch 915::LR 0.0123076923077 --> Loss 0.000551286588113\n",
      "Epoch 39::Minibatch 916::LR 0.0123076923077 --> Loss 0.00192934910456\n",
      "Epoch 39::Minibatch 917::LR 0.0123076923077 --> Loss 0.00301576177279\n",
      "Epoch 39::Minibatch 918::LR 0.0123076923077 --> Loss 0.00380525151889\n",
      "Epoch 39::Minibatch 919::LR 0.0123076923077 --> Loss 0.000574771960576\n",
      "Epoch 39::Minibatch 920::LR 0.0123076923077 --> Loss 0.0106022779147\n",
      "Epoch 39::Minibatch 921::LR 0.0123076923077 --> Loss 0.00303949495157\n",
      "Epoch 39::Minibatch 922::LR 0.0123076923077 --> Loss 0.00303465048472\n",
      "Epoch 39::Minibatch 923::LR 0.0123076923077 --> Loss 0.00109316706657\n",
      "Epoch 39::Minibatch 924::LR 0.0123076923077 --> Loss 0.00318260808786\n",
      "Epoch 39::Minibatch 925::LR 0.0123076923077 --> Loss 0.00223480184873\n",
      "Epoch 39::Minibatch 926::LR 0.0123076923077 --> Loss 0.00420018672943\n",
      "Epoch 39::Minibatch 927::LR 0.0123076923077 --> Loss 0.00444178859393\n",
      "Epoch 39::Minibatch 928::LR 0.0123076923077 --> Loss 0.00577709317207\n",
      "Epoch 39::Minibatch 929::LR 0.0123076923077 --> Loss 0.0047726949056\n",
      "Epoch 39::Minibatch 930::LR 0.0123076923077 --> Loss 0.00906272093455\n",
      "Epoch 39::Minibatch 931::LR 0.0123076923077 --> Loss 0.00291731675466\n",
      "Epoch 39::Minibatch 932::LR 0.0123076923077 --> Loss 0.00489755352338\n",
      "Epoch 39::Minibatch 933::LR 0.0123076923077 --> Loss 0.00218971610069\n",
      "Epoch 39::Minibatch 934::LR 0.0123076923077 --> Loss 0.00266053199768\n",
      "Epoch 39::Minibatch 935::LR 0.0123076923077 --> Loss 0.00404195944468\n",
      "Epoch 39::Minibatch 936::LR 0.0123076923077 --> Loss 0.000705108245214\n",
      "Epoch 39::Minibatch 937::LR 0.0123076923077 --> Loss 0.0021146941185\n",
      "Epoch 39::Minibatch 938::LR 0.0123076923077 --> Loss 0.00176010171572\n",
      "Epoch 39::Minibatch 939::LR 0.0123076923077 --> Loss 0.00198200285435\n",
      "Epoch 39::Minibatch 940::LR 0.0123076923077 --> Loss 0.000897786815961\n",
      "Epoch 39::Minibatch 941::LR 0.0123076923077 --> Loss 0.000717591593663\n",
      "Epoch 39::Minibatch 942::LR 0.0123076923077 --> Loss 0.00254496316115\n",
      "Epoch 39::Minibatch 943::LR 0.0123076923077 --> Loss 0.00221472124259\n",
      "Epoch 39::Minibatch 944::LR 0.0123076923077 --> Loss 0.00156532625357\n",
      "Epoch 39::Minibatch 945::LR 0.0123076923077 --> Loss 0.000838589370251\n",
      "Epoch 39::Minibatch 946::LR 0.0123076923077 --> Loss 0.00219623506069\n",
      "Epoch 39::Minibatch 947::LR 0.0123076923077 --> Loss 0.00207989712556\n",
      "Epoch 39::Minibatch 948::LR 0.0123076923077 --> Loss 0.00363096237183\n",
      "Epoch 39::Minibatch 949::LR 0.0123076923077 --> Loss 0.00166292339563\n",
      "Epoch 39::Minibatch 950::LR 0.0123076923077 --> Loss 0.000670876254638\n",
      "Epoch 39::Minibatch 951::LR 0.0123076923077 --> Loss 0.00331262886524\n",
      "Epoch 39::Minibatch 952::LR 0.0123076923077 --> Loss 0.00230398694674\n",
      "Epoch 39::Minibatch 953::LR 0.0123076923077 --> Loss 0.00141613562902\n",
      "Epoch 39::Minibatch 954::LR 0.0123076923077 --> Loss 0.000919646819433\n",
      "Epoch 39::Minibatch 955::LR 0.0123076923077 --> Loss 0.00256833136082\n",
      "Epoch 39::Minibatch 956::LR 0.0123076923077 --> Loss 0.0029327271382\n",
      "Epoch 39::Minibatch 957::LR 0.0123076923077 --> Loss 0.00183424413204\n",
      "Epoch 39::Minibatch 958::LR 0.0123076923077 --> Loss 0.00217682739099\n",
      "Epoch 39::Minibatch 959::LR 0.0123076923077 --> Loss 0.00242932756742\n",
      "Epoch 39::Minibatch 960::LR 0.0123076923077 --> Loss 0.00512750506401\n",
      "Epoch 39::Minibatch 961::LR 0.0123076923077 --> Loss 0.00279985586802\n",
      "Epoch 39::Minibatch 962::LR 0.0123076923077 --> Loss 0.00212317605813\n",
      "Epoch 39::Minibatch 963::LR 0.0123076923077 --> Loss 0.00102302620808\n",
      "Epoch 39::Minibatch 964::LR 0.0123076923077 --> Loss 0.0022817059358\n",
      "Epoch 39::Minibatch 965::LR 0.0123076923077 --> Loss 0.00614788889885\n",
      "Epoch 39::Minibatch 966::LR 0.0123076923077 --> Loss 0.0048811340332\n",
      "Epoch 39::Minibatch 967::LR 0.0123076923077 --> Loss 0.00119576096535\n",
      "Epoch 39::Minibatch 968::LR 0.0123076923077 --> Loss 0.000907258689404\n",
      "Epoch 39::Minibatch 969::LR 0.0123076923077 --> Loss 0.00393196940422\n",
      "Epoch 39::Minibatch 970::LR 0.0123076923077 --> Loss 0.00372527281443\n",
      "Epoch 39::Minibatch 971::LR 0.0123076923077 --> Loss 0.00306793153286\n",
      "Epoch 39::Minibatch 972::LR 0.0123076923077 --> Loss 0.00628219167391\n",
      "Epoch 39::Minibatch 973::LR 0.0123076923077 --> Loss 0.00891868114471\n",
      "Epoch 39::Minibatch 974::LR 0.0123076923077 --> Loss 0.00745933612188\n",
      "Epoch 39::Minibatch 975::LR 0.0123076923077 --> Loss 0.00550693949064\n",
      "Epoch 39::Minibatch 976::LR 0.0123076923077 --> Loss 0.00347776611646\n",
      "Epoch 39::Minibatch 977::LR 0.0123076923077 --> Loss 0.00305286963781\n",
      "Epoch 39::Minibatch 978::LR 0.0123076923077 --> Loss 0.00291806320349\n",
      "Epoch 39::Minibatch 979::LR 0.0123076923077 --> Loss 0.002719510595\n",
      "Epoch 39::Minibatch 980::LR 0.0123076923077 --> Loss 0.0031180057923\n",
      "Epoch 39::Minibatch 981::LR 0.0123076923077 --> Loss 0.00362813989321\n",
      "Epoch 39::Minibatch 982::LR 0.0123076923077 --> Loss 0.00316670219103\n",
      "Epoch 39::Minibatch 983::LR 0.0123076923077 --> Loss 0.0021092526118\n",
      "Epoch 39::Minibatch 984::LR 0.0123076923077 --> Loss 0.00137020617723\n",
      "Epoch 39::Minibatch 985::LR 0.0123076923077 --> Loss 0.00263317167759\n",
      "Epoch 39::Minibatch 986::LR 0.0123076923077 --> Loss 0.0023374948899\n",
      "Epoch 39::Minibatch 987::LR 0.0123076923077 --> Loss 0.00279406328996\n",
      "Epoch 39::Minibatch 988::LR 0.0123076923077 --> Loss 0.00209869523843\n",
      "Epoch 39::Minibatch 989::LR 0.0123076923077 --> Loss 0.00248452941577\n",
      "Epoch 39::Minibatch 990::LR 0.0123076923077 --> Loss 0.00243825455507\n",
      "Epoch 39::Minibatch 991::LR 0.0123076923077 --> Loss 0.00114025642474\n",
      "Epoch 39::Minibatch 992::LR 0.0123076923077 --> Loss 0.00145732988914\n",
      "Epoch 39::Minibatch 993::LR 0.0123076923077 --> Loss 0.00263899107774\n",
      "Epoch 39::Minibatch 994::LR 0.0123076923077 --> Loss 0.00177846352259\n",
      "Epoch 39::Minibatch 995::LR 0.0123076923077 --> Loss 0.000723508695761\n",
      "Epoch 39::Minibatch 996::LR 0.0123076923077 --> Loss 0.00239614903927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39::Minibatch 997::LR 0.0123076923077 --> Loss 0.0020655186971\n",
      "Epoch 39::Minibatch 998::LR 0.0123076923077 --> Loss 0.00234495977561\n",
      "Epoch 39::Minibatch 999::LR 0.0123076923077 --> Loss 0.00203266660372\n",
      "Epoch 39::Minibatch 1000::LR 0.0123076923077 --> Loss 0.00252498706182\n",
      "Epoch 39::Minibatch 1001::LR 0.0123076923077 --> Loss 0.00198908706506\n",
      "Epoch 39::Minibatch 1002::LR 0.0123076923077 --> Loss 0.00134564379851\n",
      "Epoch 39::Minibatch 1003::LR 0.0123076923077 --> Loss 0.00216966072718\n",
      "Epoch 39::Minibatch 1004::LR 0.0123076923077 --> Loss 0.00104561944803\n",
      "Epoch 39::Minibatch 1005::LR 0.0123076923077 --> Loss 0.00242999871572\n",
      "Epoch 39::Minibatch 1006::LR 0.0123076923077 --> Loss 0.00116487811009\n",
      "Epoch 39::Minibatch 1007::LR 0.0123076923077 --> Loss 0.00157869021098\n",
      "Epoch 39::Minibatch 1008::LR 0.0123076923077 --> Loss 0.000897076427937\n",
      "Epoch 39::Minibatch 1009::LR 0.0123076923077 --> Loss 0.00115759630998\n",
      "Epoch 39::Minibatch 1010::LR 0.0123076923077 --> Loss 0.00113719671965\n",
      "Epoch 39::Minibatch 1011::LR 0.0123076923077 --> Loss 0.00145890702804\n",
      "Epoch 39::Minibatch 1012::LR 0.0123076923077 --> Loss 0.00129416892926\n",
      "Epoch 39::Minibatch 1013::LR 0.0123076923077 --> Loss 0.00317970434825\n",
      "Epoch 39::Minibatch 1014::LR 0.0123076923077 --> Loss 0.00294833779335\n",
      "Epoch 39::Minibatch 1015::LR 0.0123076923077 --> Loss 0.00148499796788\n",
      "Epoch 39::Minibatch 1016::LR 0.0123076923077 --> Loss 0.00423750162125\n",
      "Epoch 39::Minibatch 1017::LR 0.0123076923077 --> Loss 0.00311512887478\n",
      "Epoch 39::Minibatch 1018::LR 0.0123076923077 --> Loss 0.00233192880948\n",
      "Epoch 39::Minibatch 1019::LR 0.0123076923077 --> Loss 0.00142269700766\n",
      "Epoch 39::Minibatch 1020::LR 0.0123076923077 --> Loss 0.00159330685933\n",
      "Epoch 39::Minibatch 1021::LR 0.0123076923077 --> Loss 0.00173409461975\n",
      "Epoch 39::Minibatch 1022::LR 0.0123076923077 --> Loss 0.00124632140001\n",
      "Epoch 39::Minibatch 1023::LR 0.0123076923077 --> Loss 0.000934045712153\n",
      "Epoch 39::Minibatch 1024::LR 0.0123076923077 --> Loss 0.000948456923167\n",
      "Epoch 39::Minibatch 1025::LR 0.0123076923077 --> Loss 0.00133497953415\n",
      "Epoch 39::Minibatch 1026::LR 0.0123076923077 --> Loss 0.00066319912672\n",
      "Epoch 39::Minibatch 1027::LR 0.0123076923077 --> Loss 0.000951774319013\n",
      "Epoch 39::Minibatch 1028::LR 0.0123076923077 --> Loss 0.000690719137589\n",
      "Epoch 39::Minibatch 1029::LR 0.0123076923077 --> Loss 0.000732502738635\n",
      "Epoch 39::Minibatch 1030::LR 0.0123076923077 --> Loss 0.000873829424381\n",
      "Epoch 39::Minibatch 1031::LR 0.0123076923077 --> Loss 0.000651246209939\n",
      "Epoch 39::Minibatch 1032::LR 0.0123076923077 --> Loss 0.000758547286193\n",
      "Epoch 39::Minibatch 1033::LR 0.0123076923077 --> Loss 0.000646072626114\n",
      "Epoch 39::Minibatch 1034::LR 0.0123076923077 --> Loss 0.000614411483208\n",
      "Epoch 39::Minibatch 1035::LR 0.0123076923077 --> Loss 0.000398592054844\n",
      "Epoch 39::Minibatch 1036::LR 0.0123076923077 --> Loss 0.000318255970875\n",
      "Epoch 39::Minibatch 1037::LR 0.0123076923077 --> Loss 0.000620120664438\n",
      "Epoch 39::Minibatch 1038::LR 0.0123076923077 --> Loss 0.000934306979179\n",
      "Epoch 39::Minibatch 1039::LR 0.0123076923077 --> Loss 0.000842602749666\n",
      "Epoch 39::Minibatch 1040::LR 0.0123076923077 --> Loss 0.00032761529088\n",
      "Epoch 39::Minibatch 1041::LR 0.0123076923077 --> Loss 0.000467868944009\n",
      "Epoch 40::Minibatch 1::LR 0.01 --> Loss 0.00698048750559\n",
      "Epoch 40::Minibatch 2::LR 0.01 --> Loss 0.00428396701813\n",
      "Epoch 40::Minibatch 3::LR 0.01 --> Loss 0.00255934715271\n",
      "Epoch 40::Minibatch 4::LR 0.01 --> Loss 0.00353905876478\n",
      "Epoch 40::Minibatch 5::LR 0.01 --> Loss 0.00416292667389\n",
      "Epoch 40::Minibatch 6::LR 0.01 --> Loss 0.00190121610959\n",
      "Epoch 40::Minibatch 7::LR 0.01 --> Loss 0.00671219348907\n",
      "Epoch 40::Minibatch 8::LR 0.01 --> Loss 0.00622721513112\n",
      "Epoch 40::Minibatch 9::LR 0.01 --> Loss 0.00491048534711\n",
      "Epoch 40::Minibatch 10::LR 0.01 --> Loss 0.00212338169416\n",
      "Epoch 40::Minibatch 11::LR 0.01 --> Loss 0.00203153034051\n",
      "Epoch 40::Minibatch 12::LR 0.01 --> Loss 0.00324804286162\n",
      "Epoch 40::Minibatch 13::LR 0.01 --> Loss 0.00526136318843\n",
      "Epoch 40::Minibatch 14::LR 0.01 --> Loss 0.00524340311686\n",
      "Epoch 40::Minibatch 15::LR 0.01 --> Loss 0.00452394803365\n",
      "Epoch 40::Minibatch 16::LR 0.01 --> Loss 0.000667912413677\n",
      "Epoch 40::Minibatch 17::LR 0.01 --> Loss 0.00323436180751\n",
      "Epoch 40::Minibatch 18::LR 0.01 --> Loss 0.00276460846265\n",
      "Epoch 40::Minibatch 19::LR 0.01 --> Loss 0.0017540093263\n",
      "Epoch 40::Minibatch 20::LR 0.01 --> Loss 0.00232235232989\n",
      "Epoch 40::Minibatch 21::LR 0.01 --> Loss 0.00353072047234\n",
      "Epoch 40::Minibatch 22::LR 0.01 --> Loss 0.00224530915419\n",
      "Epoch 40::Minibatch 23::LR 0.01 --> Loss 0.00101756483316\n",
      "Epoch 40::Minibatch 24::LR 0.01 --> Loss 0.000600984642903\n",
      "Epoch 40::Minibatch 25::LR 0.01 --> Loss 0.00154574443897\n",
      "Epoch 40::Minibatch 26::LR 0.01 --> Loss 0.00173621535301\n",
      "Epoch 40::Minibatch 27::LR 0.01 --> Loss 0.0014110014836\n",
      "Epoch 40::Minibatch 28::LR 0.01 --> Loss 0.000615525394678\n",
      "Epoch 40::Minibatch 29::LR 0.01 --> Loss 0.000832457542419\n",
      "Epoch 40::Minibatch 30::LR 0.01 --> Loss 0.00139896253745\n",
      "Epoch 40::Minibatch 31::LR 0.01 --> Loss 0.00183868348598\n",
      "Epoch 40::Minibatch 32::LR 0.01 --> Loss 0.00159615536531\n",
      "Epoch 40::Minibatch 33::LR 0.01 --> Loss 0.000884068906307\n",
      "Epoch 40::Minibatch 34::LR 0.01 --> Loss 0.00205245713393\n",
      "Epoch 40::Minibatch 35::LR 0.01 --> Loss 0.00246335903804\n",
      "Epoch 40::Minibatch 36::LR 0.01 --> Loss 0.00226009150346\n",
      "Epoch 40::Minibatch 37::LR 0.01 --> Loss 0.000819528301557\n",
      "Epoch 40::Minibatch 38::LR 0.01 --> Loss 0.000854844053586\n",
      "Epoch 40::Minibatch 39::LR 0.01 --> Loss 0.00207466046015\n",
      "Epoch 40::Minibatch 40::LR 0.01 --> Loss 0.00304844180743\n",
      "Epoch 40::Minibatch 41::LR 0.01 --> Loss 0.00236367225647\n",
      "Epoch 40::Minibatch 42::LR 0.01 --> Loss 0.00342939734459\n",
      "Epoch 40::Minibatch 43::LR 0.01 --> Loss 0.00206535081069\n",
      "Epoch 40::Minibatch 44::LR 0.01 --> Loss 0.00352372924487\n",
      "Epoch 40::Minibatch 45::LR 0.01 --> Loss 0.00246958573659\n",
      "Epoch 40::Minibatch 46::LR 0.01 --> Loss 0.00284659544627\n",
      "Epoch 40::Minibatch 47::LR 0.01 --> Loss 0.00277913331985\n",
      "Epoch 40::Minibatch 48::LR 0.01 --> Loss 0.00406949599584\n",
      "Epoch 40::Minibatch 49::LR 0.01 --> Loss 0.00472148458163\n",
      "Epoch 40::Minibatch 50::LR 0.01 --> Loss 0.00565507054329\n",
      "Epoch 40::Minibatch 51::LR 0.01 --> Loss 0.00331575373809\n",
      "Epoch 40::Minibatch 52::LR 0.01 --> Loss 0.00323108474414\n",
      "Epoch 40::Minibatch 53::LR 0.01 --> Loss 0.00331671833992\n",
      "Epoch 40::Minibatch 54::LR 0.01 --> Loss 0.00388031919797\n",
      "Epoch 40::Minibatch 55::LR 0.01 --> Loss 0.00101204494635\n",
      "Epoch 40::Minibatch 56::LR 0.01 --> Loss 0.00275009095669\n",
      "Epoch 40::Minibatch 57::LR 0.01 --> Loss 0.0041740779082\n",
      "Epoch 40::Minibatch 58::LR 0.01 --> Loss 0.00311924358209\n",
      "Epoch 40::Minibatch 59::LR 0.01 --> Loss 0.00236883997917\n",
      "Epoch 40::Minibatch 60::LR 0.01 --> Loss 0.00250217636426\n",
      "Epoch 40::Minibatch 61::LR 0.01 --> Loss 0.000686316688855\n",
      "Epoch 40::Minibatch 62::LR 0.01 --> Loss 0.00229245920976\n",
      "Epoch 40::Minibatch 63::LR 0.01 --> Loss 0.0021237663428\n",
      "Epoch 40::Minibatch 64::LR 0.01 --> Loss 0.000817722926537\n",
      "Epoch 40::Minibatch 65::LR 0.01 --> Loss 0.00207121908665\n",
      "Epoch 40::Minibatch 66::LR 0.01 --> Loss 0.00291507820288\n",
      "Epoch 40::Minibatch 67::LR 0.01 --> Loss 0.0023685803016\n",
      "Epoch 40::Minibatch 68::LR 0.01 --> Loss 0.00179358025392\n",
      "Epoch 40::Minibatch 69::LR 0.01 --> Loss 0.00342857480049\n",
      "Epoch 40::Minibatch 70::LR 0.01 --> Loss 0.00312157313029\n",
      "Epoch 40::Minibatch 71::LR 0.01 --> Loss 0.00219072739283\n",
      "Epoch 40::Minibatch 72::LR 0.01 --> Loss 0.000564932376146\n",
      "Epoch 40::Minibatch 73::LR 0.01 --> Loss 0.00351817091306\n",
      "Epoch 40::Minibatch 74::LR 0.01 --> Loss 0.00386371890704\n",
      "Epoch 40::Minibatch 75::LR 0.01 --> Loss 0.00183795213699\n",
      "Epoch 40::Minibatch 76::LR 0.01 --> Loss 0.000521697600683\n",
      "Epoch 40::Minibatch 77::LR 0.01 --> Loss 0.00315628906091\n",
      "Epoch 40::Minibatch 78::LR 0.01 --> Loss 0.0041541437308\n",
      "Epoch 40::Minibatch 79::LR 0.01 --> Loss 0.00157359709342\n",
      "Epoch 40::Minibatch 80::LR 0.01 --> Loss 0.00258964379628\n",
      "Epoch 40::Minibatch 81::LR 0.01 --> Loss 0.00238443156083\n",
      "Epoch 40::Minibatch 82::LR 0.01 --> Loss 0.00170656522115\n",
      "Epoch 40::Minibatch 83::LR 0.01 --> Loss 0.00344693700473\n",
      "Epoch 40::Minibatch 84::LR 0.01 --> Loss 0.00176696618398\n",
      "Epoch 40::Minibatch 85::LR 0.01 --> Loss 0.00234269479911\n",
      "Epoch 40::Minibatch 86::LR 0.01 --> Loss 0.00201964179675\n",
      "Epoch 40::Minibatch 87::LR 0.01 --> Loss 0.00207771321138\n",
      "Epoch 40::Minibatch 88::LR 0.01 --> Loss 0.00160055190325\n",
      "Epoch 40::Minibatch 89::LR 0.01 --> Loss 0.00212008694808\n",
      "Epoch 40::Minibatch 90::LR 0.01 --> Loss 0.00104615181684\n",
      "Epoch 40::Minibatch 91::LR 0.01 --> Loss 0.000894481738408\n",
      "Epoch 40::Minibatch 92::LR 0.01 --> Loss 0.00245654761791\n",
      "Epoch 40::Minibatch 93::LR 0.01 --> Loss 0.0016585167249\n",
      "Epoch 40::Minibatch 94::LR 0.01 --> Loss 0.00173324644566\n",
      "Epoch 40::Minibatch 95::LR 0.01 --> Loss 0.00195809662342\n",
      "Epoch 40::Minibatch 96::LR 0.01 --> Loss 0.00402823487918\n",
      "Epoch 40::Minibatch 97::LR 0.01 --> Loss 0.0029610534509\n",
      "Epoch 40::Minibatch 98::LR 0.01 --> Loss 0.00115694632133\n",
      "Epoch 40::Minibatch 99::LR 0.01 --> Loss 0.00150623371204\n",
      "Epoch 40::Minibatch 100::LR 0.01 --> Loss 0.00364369829496\n",
      "Epoch 40::Minibatch 101::LR 0.01 --> Loss 0.000910439590613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 102::LR 0.01 --> Loss 0.00368674476941\n",
      "Epoch 40::Minibatch 103::LR 0.01 --> Loss 0.00368784189224\n",
      "Epoch 40::Minibatch 104::LR 0.01 --> Loss 0.00258687456449\n",
      "Epoch 40::Minibatch 105::LR 0.01 --> Loss 0.00180585861206\n",
      "Epoch 40::Minibatch 106::LR 0.01 --> Loss 0.0104072157542\n",
      "Epoch 40::Minibatch 107::LR 0.01 --> Loss 0.00459703763326\n",
      "Epoch 40::Minibatch 108::LR 0.01 --> Loss 0.000871580441793\n",
      "Epoch 40::Minibatch 109::LR 0.01 --> Loss 0.00425229509672\n",
      "Epoch 40::Minibatch 110::LR 0.01 --> Loss 0.00216258347034\n",
      "Epoch 40::Minibatch 111::LR 0.01 --> Loss 0.000761587967475\n",
      "Epoch 40::Minibatch 112::LR 0.01 --> Loss 0.00319611589114\n",
      "Epoch 40::Minibatch 113::LR 0.01 --> Loss 0.00226668616136\n",
      "Epoch 40::Minibatch 114::LR 0.01 --> Loss 0.00129848827918\n",
      "Epoch 40::Minibatch 115::LR 0.01 --> Loss 0.00103829870621\n",
      "Epoch 40::Minibatch 116::LR 0.01 --> Loss 0.00263309597969\n",
      "Epoch 40::Minibatch 117::LR 0.01 --> Loss 0.00410984992981\n",
      "Epoch 40::Minibatch 118::LR 0.01 --> Loss 0.00619129180908\n",
      "Epoch 40::Minibatch 119::LR 0.01 --> Loss 0.000434117168188\n",
      "Epoch 40::Minibatch 120::LR 0.01 --> Loss 0.00167590498924\n",
      "Epoch 40::Minibatch 121::LR 0.01 --> Loss 0.00222709377607\n",
      "Epoch 40::Minibatch 122::LR 0.01 --> Loss 0.003917324543\n",
      "Epoch 40::Minibatch 123::LR 0.01 --> Loss 0.000543020963669\n",
      "Epoch 40::Minibatch 124::LR 0.01 --> Loss 0.0026950921615\n",
      "Epoch 40::Minibatch 125::LR 0.01 --> Loss 0.00430803815524\n",
      "Epoch 40::Minibatch 126::LR 0.01 --> Loss 0.00225180486838\n",
      "Epoch 40::Minibatch 127::LR 0.01 --> Loss 0.00524423281352\n",
      "Epoch 40::Minibatch 128::LR 0.01 --> Loss 0.00342036922773\n",
      "Epoch 40::Minibatch 129::LR 0.01 --> Loss 0.00218781669935\n",
      "Epoch 40::Minibatch 130::LR 0.01 --> Loss 0.00425903876623\n",
      "Epoch 40::Minibatch 131::LR 0.01 --> Loss 0.00163254350424\n",
      "Epoch 40::Minibatch 132::LR 0.01 --> Loss 0.00262285192808\n",
      "Epoch 40::Minibatch 133::LR 0.01 --> Loss 0.00261372625828\n",
      "Epoch 40::Minibatch 134::LR 0.01 --> Loss 0.00201462010543\n",
      "Epoch 40::Minibatch 135::LR 0.01 --> Loss 0.0011252078414\n",
      "Epoch 40::Minibatch 136::LR 0.01 --> Loss 0.00222328921159\n",
      "Epoch 40::Minibatch 137::LR 0.01 --> Loss 0.00313892046611\n",
      "Epoch 40::Minibatch 138::LR 0.01 --> Loss 0.00116061657667\n",
      "Epoch 40::Minibatch 139::LR 0.01 --> Loss 0.00181539654732\n",
      "Epoch 40::Minibatch 140::LR 0.01 --> Loss 0.00228938400745\n",
      "Epoch 40::Minibatch 141::LR 0.01 --> Loss 0.00278614540895\n",
      "Epoch 40::Minibatch 142::LR 0.01 --> Loss 0.00265672167142\n",
      "Epoch 40::Minibatch 143::LR 0.01 --> Loss 0.000514013270537\n",
      "Epoch 40::Minibatch 144::LR 0.01 --> Loss 0.00346642692884\n",
      "Epoch 40::Minibatch 145::LR 0.01 --> Loss 0.00405255595843\n",
      "Epoch 40::Minibatch 146::LR 0.01 --> Loss 0.00245592792829\n",
      "Epoch 40::Minibatch 147::LR 0.01 --> Loss 0.00178765436014\n",
      "Epoch 40::Minibatch 148::LR 0.01 --> Loss 0.000928968985875\n",
      "Epoch 40::Minibatch 149::LR 0.01 --> Loss 0.00288967927297\n",
      "Epoch 40::Minibatch 150::LR 0.01 --> Loss 0.00263103048007\n",
      "Epoch 40::Minibatch 151::LR 0.01 --> Loss 0.0043300028642\n",
      "Epoch 40::Minibatch 152::LR 0.01 --> Loss 0.000892885327339\n",
      "Epoch 40::Minibatch 153::LR 0.01 --> Loss 0.0015459583203\n",
      "Epoch 40::Minibatch 154::LR 0.01 --> Loss 0.00197939236959\n",
      "Epoch 40::Minibatch 155::LR 0.01 --> Loss 0.00387215415637\n",
      "Epoch 40::Minibatch 156::LR 0.01 --> Loss 0.00233604411284\n",
      "Epoch 40::Minibatch 157::LR 0.01 --> Loss 0.00068212479353\n",
      "Epoch 40::Minibatch 158::LR 0.01 --> Loss 0.00325169344743\n",
      "Epoch 40::Minibatch 159::LR 0.01 --> Loss 0.00271002570788\n",
      "Epoch 40::Minibatch 160::LR 0.01 --> Loss 0.00269631902377\n",
      "Epoch 40::Minibatch 161::LR 0.01 --> Loss 0.00098532607158\n",
      "Epoch 40::Minibatch 162::LR 0.01 --> Loss 0.0040945271651\n",
      "Epoch 40::Minibatch 163::LR 0.01 --> Loss 0.00243586917718\n",
      "Epoch 40::Minibatch 164::LR 0.01 --> Loss 0.0025956505537\n",
      "Epoch 40::Minibatch 165::LR 0.01 --> Loss 0.000474153757095\n",
      "Epoch 40::Minibatch 166::LR 0.01 --> Loss 0.0016752743721\n",
      "Epoch 40::Minibatch 167::LR 0.01 --> Loss 0.00250858426094\n",
      "Epoch 40::Minibatch 168::LR 0.01 --> Loss 0.00212836146355\n",
      "Epoch 40::Minibatch 169::LR 0.01 --> Loss 0.00096365104119\n",
      "Epoch 40::Minibatch 170::LR 0.01 --> Loss 0.000929495294889\n",
      "Epoch 40::Minibatch 171::LR 0.01 --> Loss 0.00253737767537\n",
      "Epoch 40::Minibatch 172::LR 0.01 --> Loss 0.00433791319529\n",
      "Epoch 40::Minibatch 173::LR 0.01 --> Loss 0.0021021737655\n",
      "Epoch 40::Minibatch 174::LR 0.01 --> Loss 0.000931352277597\n",
      "Epoch 40::Minibatch 175::LR 0.01 --> Loss 0.00245518803596\n",
      "Epoch 40::Minibatch 176::LR 0.01 --> Loss 0.00301712493102\n",
      "Epoch 40::Minibatch 177::LR 0.01 --> Loss 0.00413640181224\n",
      "Epoch 40::Minibatch 178::LR 0.01 --> Loss 0.00141848315795\n",
      "Epoch 40::Minibatch 179::LR 0.01 --> Loss 0.00108430633942\n",
      "Epoch 40::Minibatch 180::LR 0.01 --> Loss 0.00320743024349\n",
      "Epoch 40::Minibatch 181::LR 0.01 --> Loss 0.00294039507707\n",
      "Epoch 40::Minibatch 182::LR 0.01 --> Loss 0.000665648529927\n",
      "Epoch 40::Minibatch 183::LR 0.01 --> Loss 0.00147667894761\n",
      "Epoch 40::Minibatch 184::LR 0.01 --> Loss 0.00334590673447\n",
      "Epoch 40::Minibatch 185::LR 0.01 --> Loss 0.00246882538001\n",
      "Epoch 40::Minibatch 186::LR 0.01 --> Loss 0.000881981054942\n",
      "Epoch 40::Minibatch 187::LR 0.01 --> Loss 0.00124126315117\n",
      "Epoch 40::Minibatch 188::LR 0.01 --> Loss 0.00384680191676\n",
      "Epoch 40::Minibatch 189::LR 0.01 --> Loss 0.00392088651657\n",
      "Epoch 40::Minibatch 190::LR 0.01 --> Loss 0.00223358134429\n",
      "Epoch 40::Minibatch 191::LR 0.01 --> Loss 0.000426766624053\n",
      "Epoch 40::Minibatch 192::LR 0.01 --> Loss 0.0027601993084\n",
      "Epoch 40::Minibatch 193::LR 0.01 --> Loss 0.00270506739616\n",
      "Epoch 40::Minibatch 194::LR 0.01 --> Loss 0.00169072906176\n",
      "Epoch 40::Minibatch 195::LR 0.01 --> Loss 0.000364394734303\n",
      "Epoch 40::Minibatch 196::LR 0.01 --> Loss 0.00137398173412\n",
      "Epoch 40::Minibatch 197::LR 0.01 --> Loss 0.00294701476892\n",
      "Epoch 40::Minibatch 198::LR 0.01 --> Loss 0.00233278314273\n",
      "Epoch 40::Minibatch 199::LR 0.01 --> Loss 0.000286008020242\n",
      "Epoch 40::Minibatch 200::LR 0.01 --> Loss 0.00203351656596\n",
      "Epoch 40::Minibatch 201::LR 0.01 --> Loss 0.00191974679629\n",
      "Epoch 40::Minibatch 202::LR 0.01 --> Loss 0.00179810742537\n",
      "Epoch 40::Minibatch 203::LR 0.01 --> Loss 0.00177275756995\n",
      "Epoch 40::Minibatch 204::LR 0.01 --> Loss 0.00141667137543\n",
      "Epoch 40::Minibatch 205::LR 0.01 --> Loss 0.00224107702573\n",
      "Epoch 40::Minibatch 206::LR 0.01 --> Loss 0.00489870508512\n",
      "Epoch 40::Minibatch 207::LR 0.01 --> Loss 0.00139657924573\n",
      "Epoch 40::Minibatch 208::LR 0.01 --> Loss 0.00110442350308\n",
      "Epoch 40::Minibatch 209::LR 0.01 --> Loss 0.00259843508403\n",
      "Epoch 40::Minibatch 210::LR 0.01 --> Loss 0.00244313736757\n",
      "Epoch 40::Minibatch 211::LR 0.01 --> Loss 0.00280412574609\n",
      "Epoch 40::Minibatch 212::LR 0.01 --> Loss 0.0036683456103\n",
      "Epoch 40::Minibatch 213::LR 0.01 --> Loss 0.00524852752686\n",
      "Epoch 40::Minibatch 214::LR 0.01 --> Loss 0.00629701296488\n",
      "Epoch 40::Minibatch 215::LR 0.01 --> Loss 0.00135090132554\n",
      "Epoch 40::Minibatch 216::LR 0.01 --> Loss 0.00517549753189\n",
      "Epoch 40::Minibatch 217::LR 0.01 --> Loss 0.0056555279096\n",
      "Epoch 40::Minibatch 218::LR 0.01 --> Loss 0.0038771768411\n",
      "Epoch 40::Minibatch 219::LR 0.01 --> Loss 0.00449395457904\n",
      "Epoch 40::Minibatch 220::LR 0.01 --> Loss 0.00429983615875\n",
      "Epoch 40::Minibatch 221::LR 0.01 --> Loss 0.00431468248367\n",
      "Epoch 40::Minibatch 222::LR 0.01 --> Loss 0.00314556936423\n",
      "Epoch 40::Minibatch 223::LR 0.01 --> Loss 0.00136753062407\n",
      "Epoch 40::Minibatch 224::LR 0.01 --> Loss 0.00154531766971\n",
      "Epoch 40::Minibatch 225::LR 0.01 --> Loss 0.00803382873535\n",
      "Epoch 40::Minibatch 226::LR 0.01 --> Loss 0.00355701128642\n",
      "Epoch 40::Minibatch 227::LR 0.01 --> Loss 0.00167645653089\n",
      "Epoch 40::Minibatch 228::LR 0.01 --> Loss 0.000623707075914\n",
      "Epoch 40::Minibatch 229::LR 0.01 --> Loss 0.00480061213175\n",
      "Epoch 40::Minibatch 230::LR 0.01 --> Loss 0.00352232297262\n",
      "Epoch 40::Minibatch 231::LR 0.01 --> Loss 0.00267020046711\n",
      "Epoch 40::Minibatch 232::LR 0.01 --> Loss 0.00114271422227\n",
      "Epoch 40::Minibatch 233::LR 0.01 --> Loss 0.00247671206792\n",
      "Epoch 40::Minibatch 234::LR 0.01 --> Loss 0.00762477397919\n",
      "Epoch 40::Minibatch 235::LR 0.01 --> Loss 0.00454365650813\n",
      "Epoch 40::Minibatch 236::LR 0.01 --> Loss 0.00163819352786\n",
      "Epoch 40::Minibatch 237::LR 0.01 --> Loss 0.000546646565199\n",
      "Epoch 40::Minibatch 238::LR 0.01 --> Loss 0.00352909763654\n",
      "Epoch 40::Minibatch 239::LR 0.01 --> Loss 0.00296023130417\n",
      "Epoch 40::Minibatch 240::LR 0.01 --> Loss 0.0033215379715\n",
      "Epoch 40::Minibatch 241::LR 0.01 --> Loss 0.000746186226606\n",
      "Epoch 40::Minibatch 242::LR 0.01 --> Loss 0.00664590040843\n",
      "Epoch 40::Minibatch 243::LR 0.01 --> Loss 0.00315694212914\n",
      "Epoch 40::Minibatch 244::LR 0.01 --> Loss 0.00264469345411\n",
      "Epoch 40::Minibatch 245::LR 0.01 --> Loss 0.00040524204572\n",
      "Epoch 40::Minibatch 246::LR 0.01 --> Loss 0.0018157351017\n",
      "Epoch 40::Minibatch 247::LR 0.01 --> Loss 0.00932486057281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 248::LR 0.01 --> Loss 0.00430368463198\n",
      "Epoch 40::Minibatch 249::LR 0.01 --> Loss 0.00231648862362\n",
      "Epoch 40::Minibatch 250::LR 0.01 --> Loss 0.00229493419329\n",
      "Epoch 40::Minibatch 251::LR 0.01 --> Loss 0.00228957672914\n",
      "Epoch 40::Minibatch 252::LR 0.01 --> Loss 0.00154819250107\n",
      "Epoch 40::Minibatch 253::LR 0.01 --> Loss 0.00264832595984\n",
      "Epoch 40::Minibatch 254::LR 0.01 --> Loss 0.00472073157628\n",
      "Epoch 40::Minibatch 255::LR 0.01 --> Loss 0.00385620673498\n",
      "Epoch 40::Minibatch 256::LR 0.01 --> Loss 0.00129620432854\n",
      "Epoch 40::Minibatch 257::LR 0.01 --> Loss 0.00112190852563\n",
      "Epoch 40::Minibatch 258::LR 0.01 --> Loss 0.00367955406507\n",
      "Epoch 40::Minibatch 259::LR 0.01 --> Loss 0.00148898661137\n",
      "Epoch 40::Minibatch 260::LR 0.01 --> Loss 0.0018225667874\n",
      "Epoch 40::Minibatch 261::LR 0.01 --> Loss 0.00258884092172\n",
      "Epoch 40::Minibatch 262::LR 0.01 --> Loss 0.00176845173041\n",
      "Epoch 40::Minibatch 263::LR 0.01 --> Loss 0.00224049488703\n",
      "Epoch 40::Minibatch 264::LR 0.01 --> Loss 0.00353631059329\n",
      "Epoch 40::Minibatch 265::LR 0.01 --> Loss 0.0100460012754\n",
      "Epoch 40::Minibatch 266::LR 0.01 --> Loss 0.000801639060179\n",
      "Epoch 40::Minibatch 267::LR 0.01 --> Loss 0.00873020728429\n",
      "Epoch 40::Minibatch 268::LR 0.01 --> Loss 0.000951057374477\n",
      "Epoch 40::Minibatch 269::LR 0.01 --> Loss 0.00344647407532\n",
      "Epoch 40::Minibatch 270::LR 0.01 --> Loss 0.00788992007573\n",
      "Epoch 40::Minibatch 271::LR 0.01 --> Loss 0.00224474151929\n",
      "Epoch 40::Minibatch 272::LR 0.01 --> Loss 0.0045631202062\n",
      "Epoch 40::Minibatch 273::LR 0.01 --> Loss 0.00120584011078\n",
      "Epoch 40::Minibatch 274::LR 0.01 --> Loss 0.00173890332381\n",
      "Epoch 40::Minibatch 275::LR 0.01 --> Loss 0.00234541932742\n",
      "Epoch 40::Minibatch 276::LR 0.01 --> Loss 0.00322180112203\n",
      "Epoch 40::Minibatch 277::LR 0.01 --> Loss 0.00078269029657\n",
      "Epoch 40::Minibatch 278::LR 0.01 --> Loss 0.00243443886439\n",
      "Epoch 40::Minibatch 279::LR 0.01 --> Loss 0.00176207820574\n",
      "Epoch 40::Minibatch 280::LR 0.01 --> Loss 0.00157155116399\n",
      "Epoch 40::Minibatch 281::LR 0.01 --> Loss 0.000990627805392\n",
      "Epoch 40::Minibatch 282::LR 0.01 --> Loss 0.00182628194491\n",
      "Epoch 40::Minibatch 283::LR 0.01 --> Loss 0.00171805143356\n",
      "Epoch 40::Minibatch 284::LR 0.01 --> Loss 0.00141417741776\n",
      "Epoch 40::Minibatch 285::LR 0.01 --> Loss 0.00103360543648\n",
      "Epoch 40::Minibatch 286::LR 0.01 --> Loss 0.0017921380202\n",
      "Epoch 40::Minibatch 287::LR 0.01 --> Loss 0.00178853948911\n",
      "Epoch 40::Minibatch 288::LR 0.01 --> Loss 0.000972251693408\n",
      "Epoch 40::Minibatch 289::LR 0.01 --> Loss 0.00144542336464\n",
      "Epoch 40::Minibatch 290::LR 0.01 --> Loss 0.00172212521235\n",
      "Epoch 40::Minibatch 291::LR 0.01 --> Loss 0.00155805895726\n",
      "Epoch 40::Minibatch 292::LR 0.01 --> Loss 0.000546860744556\n",
      "Epoch 40::Minibatch 293::LR 0.01 --> Loss 0.00141064623992\n",
      "Epoch 40::Minibatch 294::LR 0.01 --> Loss 0.00160731563965\n",
      "Epoch 40::Minibatch 295::LR 0.01 --> Loss 0.00181291341782\n",
      "Epoch 40::Minibatch 296::LR 0.01 --> Loss 0.00154594461123\n",
      "Epoch 40::Minibatch 297::LR 0.01 --> Loss 0.00136559307575\n",
      "Epoch 40::Minibatch 298::LR 0.01 --> Loss 0.00137725104888\n",
      "Epoch 40::Minibatch 299::LR 0.01 --> Loss 0.000797244260708\n",
      "Epoch 40::Minibatch 300::LR 0.01 --> Loss 0.00259450674057\n",
      "Epoch 40::Minibatch 301::LR 0.01 --> Loss 0.00251688659191\n",
      "Epoch 40::Minibatch 302::LR 0.01 --> Loss 0.00235051631927\n",
      "Epoch 40::Minibatch 303::LR 0.01 --> Loss 0.000794104486704\n",
      "Epoch 40::Minibatch 304::LR 0.01 --> Loss 0.00283819854259\n",
      "Epoch 40::Minibatch 305::LR 0.01 --> Loss 0.00169677694639\n",
      "Epoch 40::Minibatch 306::LR 0.01 --> Loss 0.000914596517881\n",
      "Epoch 40::Minibatch 307::LR 0.01 --> Loss 0.00239503939946\n",
      "Epoch 40::Minibatch 308::LR 0.01 --> Loss 0.0019784283638\n",
      "Epoch 40::Minibatch 309::LR 0.01 --> Loss 0.00103140453498\n",
      "Epoch 40::Minibatch 310::LR 0.01 --> Loss 0.00118545591831\n",
      "Epoch 40::Minibatch 311::LR 0.01 --> Loss 0.00178033431371\n",
      "Epoch 40::Minibatch 312::LR 0.01 --> Loss 0.00283563554287\n",
      "Epoch 40::Minibatch 313::LR 0.01 --> Loss 0.00229556838671\n",
      "Epoch 40::Minibatch 314::LR 0.01 --> Loss 0.00191090881824\n",
      "Epoch 40::Minibatch 315::LR 0.01 --> Loss 0.00104968895515\n",
      "Epoch 40::Minibatch 316::LR 0.01 --> Loss 0.00233162939548\n",
      "Epoch 40::Minibatch 317::LR 0.01 --> Loss 0.00155721803506\n",
      "Epoch 40::Minibatch 318::LR 0.01 --> Loss 0.00131802946329\n",
      "Epoch 40::Minibatch 319::LR 0.01 --> Loss 0.0022863650322\n",
      "Epoch 40::Minibatch 320::LR 0.01 --> Loss 0.00294276614984\n",
      "Epoch 40::Minibatch 321::LR 0.01 --> Loss 0.000833385884762\n",
      "Epoch 40::Minibatch 322::LR 0.01 --> Loss 0.00328872124354\n",
      "Epoch 40::Minibatch 323::LR 0.01 --> Loss 0.00337836583455\n",
      "Epoch 40::Minibatch 324::LR 0.01 --> Loss 0.00265437304974\n",
      "Epoch 40::Minibatch 325::LR 0.01 --> Loss 0.00235576113065\n",
      "Epoch 40::Minibatch 326::LR 0.01 --> Loss 0.00503099123637\n",
      "Epoch 40::Minibatch 327::LR 0.01 --> Loss 0.00218722601732\n",
      "Epoch 40::Minibatch 328::LR 0.01 --> Loss 0.00280528604984\n",
      "Epoch 40::Minibatch 329::LR 0.01 --> Loss 0.0011633909742\n",
      "Epoch 40::Minibatch 330::LR 0.01 --> Loss 0.00157899250587\n",
      "Epoch 40::Minibatch 331::LR 0.01 --> Loss 0.00252782285213\n",
      "Epoch 40::Minibatch 332::LR 0.01 --> Loss 0.00241960346699\n",
      "Epoch 40::Minibatch 333::LR 0.01 --> Loss 0.00146812270085\n",
      "Epoch 40::Minibatch 334::LR 0.01 --> Loss 0.0043415816625\n",
      "Epoch 40::Minibatch 335::LR 0.01 --> Loss 0.00190554579099\n",
      "Epoch 40::Minibatch 336::LR 0.01 --> Loss 0.00226933101813\n",
      "Epoch 40::Minibatch 337::LR 0.01 --> Loss 0.00383167624474\n",
      "Epoch 40::Minibatch 338::LR 0.01 --> Loss 0.000558737615744\n",
      "Epoch 40::Minibatch 339::LR 0.01 --> Loss 0.00317756036917\n",
      "Epoch 40::Minibatch 340::LR 0.01 --> Loss 0.00354337612788\n",
      "Epoch 40::Minibatch 341::LR 0.01 --> Loss 0.00409942428271\n",
      "Epoch 40::Minibatch 342::LR 0.01 --> Loss 0.00302728950977\n",
      "Epoch 40::Minibatch 343::LR 0.01 --> Loss 0.00163330763578\n",
      "Epoch 40::Minibatch 344::LR 0.01 --> Loss 0.00313891450564\n",
      "Epoch 40::Minibatch 345::LR 0.01 --> Loss 0.00397599418958\n",
      "Epoch 40::Minibatch 346::LR 0.01 --> Loss 0.00518108208974\n",
      "Epoch 40::Minibatch 347::LR 0.01 --> Loss 0.000819245278835\n",
      "Epoch 40::Minibatch 348::LR 0.01 --> Loss 0.00285298864047\n",
      "Epoch 40::Minibatch 349::LR 0.01 --> Loss 0.00325497408708\n",
      "Epoch 40::Minibatch 350::LR 0.01 --> Loss 0.00163594166438\n",
      "Epoch 40::Minibatch 351::LR 0.01 --> Loss 0.00340087175369\n",
      "Epoch 40::Minibatch 352::LR 0.01 --> Loss 0.00478091041247\n",
      "Epoch 40::Minibatch 353::LR 0.01 --> Loss 0.00345664143562\n",
      "Epoch 40::Minibatch 354::LR 0.01 --> Loss 0.0029323832194\n",
      "Epoch 40::Minibatch 355::LR 0.01 --> Loss 0.00634255329768\n",
      "Epoch 40::Minibatch 356::LR 0.01 --> Loss 0.00318105777105\n",
      "Epoch 40::Minibatch 357::LR 0.01 --> Loss 0.00123972733816\n",
      "Epoch 40::Minibatch 358::LR 0.01 --> Loss 0.00188079694907\n",
      "Epoch 40::Minibatch 359::LR 0.01 --> Loss 0.00264987389247\n",
      "Epoch 40::Minibatch 360::LR 0.01 --> Loss 0.00222819030285\n",
      "Epoch 40::Minibatch 361::LR 0.01 --> Loss 0.00217835585276\n",
      "Epoch 40::Minibatch 362::LR 0.01 --> Loss 0.00217956622442\n",
      "Epoch 40::Minibatch 363::LR 0.01 --> Loss 0.000622996389866\n",
      "Epoch 40::Minibatch 364::LR 0.01 --> Loss 0.0019483590126\n",
      "Epoch 40::Minibatch 365::LR 0.01 --> Loss 0.00195418079694\n",
      "Epoch 40::Minibatch 366::LR 0.01 --> Loss 0.00205683370431\n",
      "Epoch 40::Minibatch 367::LR 0.01 --> Loss 0.000950478216012\n",
      "Epoch 40::Minibatch 368::LR 0.01 --> Loss 0.000967874228954\n",
      "Epoch 40::Minibatch 369::LR 0.01 --> Loss 0.00264991521835\n",
      "Epoch 40::Minibatch 370::LR 0.01 --> Loss 0.00214844246705\n",
      "Epoch 40::Minibatch 371::LR 0.01 --> Loss 0.001803556482\n",
      "Epoch 40::Minibatch 372::LR 0.01 --> Loss 0.000423583189646\n",
      "Epoch 40::Minibatch 373::LR 0.01 --> Loss 0.00180811484655\n",
      "Epoch 40::Minibatch 374::LR 0.01 --> Loss 0.00223869899909\n",
      "Epoch 40::Minibatch 375::LR 0.01 --> Loss 0.00190154492855\n",
      "Epoch 40::Minibatch 376::LR 0.01 --> Loss 0.00116767913103\n",
      "Epoch 40::Minibatch 377::LR 0.01 --> Loss 0.00188781917095\n",
      "Epoch 40::Minibatch 378::LR 0.01 --> Loss 0.00206741968791\n",
      "Epoch 40::Minibatch 379::LR 0.01 --> Loss 0.00228766739368\n",
      "Epoch 40::Minibatch 380::LR 0.01 --> Loss 0.00154256780942\n",
      "Epoch 40::Minibatch 381::LR 0.01 --> Loss 0.00100100626548\n",
      "Epoch 40::Minibatch 382::LR 0.01 --> Loss 0.00204941749573\n",
      "Epoch 40::Minibatch 383::LR 0.01 --> Loss 0.00199170192083\n",
      "Epoch 40::Minibatch 384::LR 0.01 --> Loss 0.00115420689185\n",
      "Epoch 40::Minibatch 385::LR 0.01 --> Loss 0.00107120176156\n",
      "Epoch 40::Minibatch 386::LR 0.01 --> Loss 0.00229032119115\n",
      "Epoch 40::Minibatch 387::LR 0.01 --> Loss 0.00236543178558\n",
      "Epoch 40::Minibatch 388::LR 0.01 --> Loss 0.00124471028646\n",
      "Epoch 40::Minibatch 389::LR 0.01 --> Loss 0.00178694248199\n",
      "Epoch 40::Minibatch 390::LR 0.01 --> Loss 0.00313010851542\n",
      "Epoch 40::Minibatch 391::LR 0.01 --> Loss 0.00251015444597\n",
      "Epoch 40::Minibatch 392::LR 0.01 --> Loss 0.00252898732821\n",
      "Epoch 40::Minibatch 393::LR 0.01 --> Loss 0.00272103051345\n",
      "Epoch 40::Minibatch 394::LR 0.01 --> Loss 0.00199534217517\n",
      "Epoch 40::Minibatch 395::LR 0.01 --> Loss 0.00208787719409\n",
      "Epoch 40::Minibatch 396::LR 0.01 --> Loss 0.00195302824179\n",
      "Epoch 40::Minibatch 397::LR 0.01 --> Loss 0.0020984518528\n",
      "Epoch 40::Minibatch 398::LR 0.01 --> Loss 0.00208799183369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 399::LR 0.01 --> Loss 0.00238557378451\n",
      "Epoch 40::Minibatch 400::LR 0.01 --> Loss 0.00202800432841\n",
      "Epoch 40::Minibatch 401::LR 0.01 --> Loss 0.00338521202405\n",
      "Epoch 40::Minibatch 402::LR 0.01 --> Loss 0.00171269138654\n",
      "Epoch 40::Minibatch 403::LR 0.01 --> Loss 0.00144016961257\n",
      "Epoch 40::Minibatch 404::LR 0.01 --> Loss 0.00130191644033\n",
      "Epoch 40::Minibatch 405::LR 0.01 --> Loss 0.00330143868923\n",
      "Epoch 40::Minibatch 406::LR 0.01 --> Loss 0.00231619298458\n",
      "Epoch 40::Minibatch 407::LR 0.01 --> Loss 0.00171383182208\n",
      "Epoch 40::Minibatch 408::LR 0.01 --> Loss 0.000436946948369\n",
      "Epoch 40::Minibatch 409::LR 0.01 --> Loss 0.00220184028149\n",
      "Epoch 40::Minibatch 410::LR 0.01 --> Loss 0.0031305450201\n",
      "Epoch 40::Minibatch 411::LR 0.01 --> Loss 0.00168623367945\n",
      "Epoch 40::Minibatch 412::LR 0.01 --> Loss 0.000941917002201\n",
      "Epoch 40::Minibatch 413::LR 0.01 --> Loss 0.00199157992999\n",
      "Epoch 40::Minibatch 414::LR 0.01 --> Loss 0.00189582804839\n",
      "Epoch 40::Minibatch 415::LR 0.01 --> Loss 0.0011913900574\n",
      "Epoch 40::Minibatch 416::LR 0.01 --> Loss 0.000787632813056\n",
      "Epoch 40::Minibatch 417::LR 0.01 --> Loss 0.00167877078056\n",
      "Epoch 40::Minibatch 418::LR 0.01 --> Loss 0.00254712680976\n",
      "Epoch 40::Minibatch 419::LR 0.01 --> Loss 0.000495594044526\n",
      "Epoch 40::Minibatch 420::LR 0.01 --> Loss 0.00070521324873\n",
      "Epoch 40::Minibatch 421::LR 0.01 --> Loss 0.00186828712622\n",
      "Epoch 40::Minibatch 422::LR 0.01 --> Loss 0.00204913894335\n",
      "Epoch 40::Minibatch 423::LR 0.01 --> Loss 0.00101013461749\n",
      "Epoch 40::Minibatch 424::LR 0.01 --> Loss 0.00153169920047\n",
      "Epoch 40::Minibatch 425::LR 0.01 --> Loss 0.00285497128963\n",
      "Epoch 40::Minibatch 426::LR 0.01 --> Loss 0.00200769583384\n",
      "Epoch 40::Minibatch 427::LR 0.01 --> Loss 0.000761751880248\n",
      "Epoch 40::Minibatch 428::LR 0.01 --> Loss 0.000886508127054\n",
      "Epoch 40::Minibatch 429::LR 0.01 --> Loss 0.00221123059591\n",
      "Epoch 40::Minibatch 430::LR 0.01 --> Loss 0.00695889790853\n",
      "Epoch 40::Minibatch 431::LR 0.01 --> Loss 0.0034076265494\n",
      "Epoch 40::Minibatch 432::LR 0.01 --> Loss 0.00375509897868\n",
      "Epoch 40::Minibatch 433::LR 0.01 --> Loss 0.00254533966382\n",
      "Epoch 40::Minibatch 434::LR 0.01 --> Loss 0.00239242196083\n",
      "Epoch 40::Minibatch 435::LR 0.01 --> Loss 0.00224626362324\n",
      "Epoch 40::Minibatch 436::LR 0.01 --> Loss 0.00156449576219\n",
      "Epoch 40::Minibatch 437::LR 0.01 --> Loss 0.00269945144653\n",
      "Epoch 40::Minibatch 438::LR 0.01 --> Loss 0.00216788013776\n",
      "Epoch 40::Minibatch 439::LR 0.01 --> Loss 0.00186848282814\n",
      "Epoch 40::Minibatch 440::LR 0.01 --> Loss 0.00288928409417\n",
      "Epoch 40::Minibatch 441::LR 0.01 --> Loss 0.00270637075106\n",
      "Epoch 40::Minibatch 442::LR 0.01 --> Loss 0.0023973351717\n",
      "Epoch 40::Minibatch 443::LR 0.01 --> Loss 0.00340268572172\n",
      "Epoch 40::Minibatch 444::LR 0.01 --> Loss 0.00261448343595\n",
      "Epoch 40::Minibatch 445::LR 0.01 --> Loss 0.000836149851481\n",
      "Epoch 40::Minibatch 446::LR 0.01 --> Loss 0.00133796920379\n",
      "Epoch 40::Minibatch 447::LR 0.01 --> Loss 0.00223748644193\n",
      "Epoch 40::Minibatch 448::LR 0.01 --> Loss 0.00229579905669\n",
      "Epoch 40::Minibatch 449::LR 0.01 --> Loss 0.00352031985919\n",
      "Epoch 40::Minibatch 450::LR 0.01 --> Loss 0.00209195792675\n",
      "Epoch 40::Minibatch 451::LR 0.01 --> Loss 0.0037475558122\n",
      "Epoch 40::Minibatch 452::LR 0.01 --> Loss 0.00225965559483\n",
      "Epoch 40::Minibatch 453::LR 0.01 --> Loss 0.00034166003267\n",
      "Epoch 40::Minibatch 454::LR 0.01 --> Loss 0.0033065400521\n",
      "Epoch 40::Minibatch 455::LR 0.01 --> Loss 0.00253397146861\n",
      "Epoch 40::Minibatch 456::LR 0.01 --> Loss 0.00304710408052\n",
      "Epoch 40::Minibatch 457::LR 0.01 --> Loss 0.00186696330706\n",
      "Epoch 40::Minibatch 458::LR 0.01 --> Loss 0.00071248292923\n",
      "Epoch 40::Minibatch 459::LR 0.01 --> Loss 0.0036688888073\n",
      "Epoch 40::Minibatch 460::LR 0.01 --> Loss 0.0023897643884\n",
      "Epoch 40::Minibatch 461::LR 0.01 --> Loss 0.00358312249184\n",
      "Epoch 40::Minibatch 462::LR 0.01 --> Loss 0.000363104815284\n",
      "Epoch 40::Minibatch 463::LR 0.01 --> Loss 0.00384352842967\n",
      "Epoch 40::Minibatch 464::LR 0.01 --> Loss 0.00192211290201\n",
      "Epoch 40::Minibatch 465::LR 0.01 --> Loss 0.00422658244769\n",
      "Epoch 40::Minibatch 466::LR 0.01 --> Loss 0.00485625982285\n",
      "Epoch 40::Minibatch 467::LR 0.01 --> Loss 0.00488135059675\n",
      "Epoch 40::Minibatch 468::LR 0.01 --> Loss 0.00543427626292\n",
      "Epoch 40::Minibatch 469::LR 0.01 --> Loss 0.00574422677358\n",
      "Epoch 40::Minibatch 470::LR 0.01 --> Loss 0.00350625077883\n",
      "Epoch 40::Minibatch 471::LR 0.01 --> Loss 0.00163114726543\n",
      "Epoch 40::Minibatch 472::LR 0.01 --> Loss 0.00356956720352\n",
      "Epoch 40::Minibatch 473::LR 0.01 --> Loss 0.00231775979201\n",
      "Epoch 40::Minibatch 474::LR 0.01 --> Loss 0.000679843177398\n",
      "Epoch 40::Minibatch 475::LR 0.01 --> Loss 0.0045880095164\n",
      "Epoch 40::Minibatch 476::LR 0.01 --> Loss 0.00746055444082\n",
      "Epoch 40::Minibatch 477::LR 0.01 --> Loss 0.000909443398317\n",
      "Epoch 40::Minibatch 478::LR 0.01 --> Loss 0.00238691031933\n",
      "Epoch 40::Minibatch 479::LR 0.01 --> Loss 0.00194319705168\n",
      "Epoch 40::Minibatch 480::LR 0.01 --> Loss 0.00149536172549\n",
      "Epoch 40::Minibatch 481::LR 0.01 --> Loss 0.000958434442679\n",
      "Epoch 40::Minibatch 482::LR 0.01 --> Loss 0.00205361624559\n",
      "Epoch 40::Minibatch 483::LR 0.01 --> Loss 0.00295785109202\n",
      "Epoch 40::Minibatch 484::LR 0.01 --> Loss 0.00331331034501\n",
      "Epoch 40::Minibatch 485::LR 0.01 --> Loss 0.000755915393432\n",
      "Epoch 40::Minibatch 486::LR 0.01 --> Loss 0.0028280299902\n",
      "Epoch 40::Minibatch 487::LR 0.01 --> Loss 0.00326597650846\n",
      "Epoch 40::Minibatch 488::LR 0.01 --> Loss 0.00200000941753\n",
      "Epoch 40::Minibatch 489::LR 0.01 --> Loss 0.00306994398435\n",
      "Epoch 40::Minibatch 490::LR 0.01 --> Loss 0.000411847109596\n",
      "Epoch 40::Minibatch 491::LR 0.01 --> Loss 0.00299041986465\n",
      "Epoch 40::Minibatch 492::LR 0.01 --> Loss 0.00306157608827\n",
      "Epoch 40::Minibatch 493::LR 0.01 --> Loss 0.00300226231416\n",
      "Epoch 40::Minibatch 494::LR 0.01 --> Loss 0.000727333625158\n",
      "Epoch 40::Minibatch 495::LR 0.01 --> Loss 0.00181325058142\n",
      "Epoch 40::Minibatch 496::LR 0.01 --> Loss 0.0027696810166\n",
      "Epoch 40::Minibatch 497::LR 0.01 --> Loss 0.000906195143859\n",
      "Epoch 40::Minibatch 498::LR 0.01 --> Loss 0.000543086429437\n",
      "Epoch 40::Minibatch 499::LR 0.01 --> Loss 0.00335007588069\n",
      "Epoch 40::Minibatch 500::LR 0.01 --> Loss 0.00141779134671\n",
      "Epoch 40::Minibatch 501::LR 0.01 --> Loss 0.00193287789822\n",
      "Epoch 40::Minibatch 502::LR 0.01 --> Loss 0.00368330081304\n",
      "Epoch 40::Minibatch 503::LR 0.01 --> Loss 0.0064447192351\n",
      "Epoch 40::Minibatch 504::LR 0.01 --> Loss 0.00634323676427\n",
      "Epoch 40::Minibatch 505::LR 0.01 --> Loss 0.00378135641416\n",
      "Epoch 40::Minibatch 506::LR 0.01 --> Loss 0.00322596867879\n",
      "Epoch 40::Minibatch 507::LR 0.01 --> Loss 0.00558468461037\n",
      "Epoch 40::Minibatch 508::LR 0.01 --> Loss 0.00337166706721\n",
      "Epoch 40::Minibatch 509::LR 0.01 --> Loss 0.0041371401151\n",
      "Epoch 40::Minibatch 510::LR 0.01 --> Loss 0.00433405439059\n",
      "Epoch 40::Minibatch 511::LR 0.01 --> Loss 0.00406031092008\n",
      "Epoch 40::Minibatch 512::LR 0.01 --> Loss 0.00269786298275\n",
      "Epoch 40::Minibatch 513::LR 0.01 --> Loss 0.000584555665652\n",
      "Epoch 40::Minibatch 514::LR 0.01 --> Loss 0.00252673168977\n",
      "Epoch 40::Minibatch 515::LR 0.01 --> Loss 0.00298343300819\n",
      "Epoch 40::Minibatch 516::LR 0.01 --> Loss 0.00388936797778\n",
      "Epoch 40::Minibatch 517::LR 0.01 --> Loss 0.00365194996198\n",
      "Epoch 40::Minibatch 518::LR 0.01 --> Loss 0.00255724906921\n",
      "Epoch 40::Minibatch 519::LR 0.01 --> Loss 0.00363605817159\n",
      "Epoch 40::Minibatch 520::LR 0.01 --> Loss 0.00575674851735\n",
      "Epoch 40::Minibatch 521::LR 0.01 --> Loss 0.00587127129237\n",
      "Epoch 40::Minibatch 522::LR 0.01 --> Loss 0.0066791176796\n",
      "Epoch 40::Minibatch 523::LR 0.01 --> Loss 0.00061673566699\n",
      "Epoch 40::Minibatch 524::LR 0.01 --> Loss 0.00137078980605\n",
      "Epoch 40::Minibatch 525::LR 0.01 --> Loss 0.00296081741651\n",
      "Epoch 40::Minibatch 526::LR 0.01 --> Loss 0.00358063220978\n",
      "Epoch 40::Minibatch 527::LR 0.01 --> Loss 0.00209739486376\n",
      "Epoch 40::Minibatch 528::LR 0.01 --> Loss 0.00089658031861\n",
      "Epoch 40::Minibatch 529::LR 0.01 --> Loss 0.00369563539823\n",
      "Epoch 40::Minibatch 530::LR 0.01 --> Loss 0.00363790035248\n",
      "Epoch 40::Minibatch 531::LR 0.01 --> Loss 0.00322122593721\n",
      "Epoch 40::Minibatch 532::LR 0.01 --> Loss 0.00253832360109\n",
      "Epoch 40::Minibatch 533::LR 0.01 --> Loss 0.0048216120402\n",
      "Epoch 40::Minibatch 534::LR 0.01 --> Loss 0.00365080595016\n",
      "Epoch 40::Minibatch 535::LR 0.01 --> Loss 0.00336388746897\n",
      "Epoch 40::Minibatch 536::LR 0.01 --> Loss 0.00211267113686\n",
      "Epoch 40::Minibatch 537::LR 0.01 --> Loss 0.000575807392597\n",
      "Epoch 40::Minibatch 538::LR 0.01 --> Loss 0.00160604417324\n",
      "Epoch 40::Minibatch 539::LR 0.01 --> Loss 0.00326436837514\n",
      "Epoch 40::Minibatch 540::LR 0.01 --> Loss 0.0033556942145\n",
      "Epoch 40::Minibatch 541::LR 0.01 --> Loss 0.00281115392844\n",
      "Epoch 40::Minibatch 542::LR 0.01 --> Loss 0.00240969598293\n",
      "Epoch 40::Minibatch 543::LR 0.01 --> Loss 0.00249982595444\n",
      "Epoch 40::Minibatch 544::LR 0.01 --> Loss 0.00413820902507\n",
      "Epoch 40::Minibatch 545::LR 0.01 --> Loss 0.00191619773706\n",
      "Epoch 40::Minibatch 546::LR 0.01 --> Loss 0.00066278681159\n",
      "Epoch 40::Minibatch 547::LR 0.01 --> Loss 0.00255629400412\n",
      "Epoch 40::Minibatch 548::LR 0.01 --> Loss 0.00329911092917\n",
      "Epoch 40::Minibatch 549::LR 0.01 --> Loss 0.00906850735346\n",
      "Epoch 40::Minibatch 550::LR 0.01 --> Loss 0.00119042495886\n",
      "Epoch 40::Minibatch 551::LR 0.01 --> Loss 0.00246660888195\n",
      "Epoch 40::Minibatch 552::LR 0.01 --> Loss 0.00340474883715\n",
      "Epoch 40::Minibatch 553::LR 0.01 --> Loss 0.00285528659821\n",
      "Epoch 40::Minibatch 554::LR 0.01 --> Loss 0.00350821654002\n",
      "Epoch 40::Minibatch 555::LR 0.01 --> Loss 0.000920626024405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 556::LR 0.01 --> Loss 0.00188286523024\n",
      "Epoch 40::Minibatch 557::LR 0.01 --> Loss 0.00241885185242\n",
      "Epoch 40::Minibatch 558::LR 0.01 --> Loss 0.00355708082517\n",
      "Epoch 40::Minibatch 559::LR 0.01 --> Loss 0.00364036361376\n",
      "Epoch 40::Minibatch 560::LR 0.01 --> Loss 0.00305796901385\n",
      "Epoch 40::Minibatch 561::LR 0.01 --> Loss 0.00260408520699\n",
      "Epoch 40::Minibatch 562::LR 0.01 --> Loss 0.00232447346052\n",
      "Epoch 40::Minibatch 563::LR 0.01 --> Loss 0.0039230020841\n",
      "Epoch 40::Minibatch 564::LR 0.01 --> Loss 0.00300894677639\n",
      "Epoch 40::Minibatch 565::LR 0.01 --> Loss 0.00355440378189\n",
      "Epoch 40::Minibatch 566::LR 0.01 --> Loss 0.0021311233441\n",
      "Epoch 40::Minibatch 567::LR 0.01 --> Loss 0.00255139112473\n",
      "Epoch 40::Minibatch 568::LR 0.01 --> Loss 0.00169238229593\n",
      "Epoch 40::Minibatch 569::LR 0.01 --> Loss 0.000554333974918\n",
      "Epoch 40::Minibatch 570::LR 0.01 --> Loss 0.00157568275928\n",
      "Epoch 40::Minibatch 571::LR 0.01 --> Loss 0.00195974091689\n",
      "Epoch 40::Minibatch 572::LR 0.01 --> Loss 0.00211989045143\n",
      "Epoch 40::Minibatch 573::LR 0.01 --> Loss 0.00139098137617\n",
      "Epoch 40::Minibatch 574::LR 0.01 --> Loss 0.00103729794423\n",
      "Epoch 40::Minibatch 575::LR 0.01 --> Loss 0.00167021512985\n",
      "Epoch 40::Minibatch 576::LR 0.01 --> Loss 0.00198776563009\n",
      "Epoch 40::Minibatch 577::LR 0.01 --> Loss 0.00156795481841\n",
      "Epoch 40::Minibatch 578::LR 0.01 --> Loss 0.00123870283365\n",
      "Epoch 40::Minibatch 579::LR 0.01 --> Loss 0.00116567194462\n",
      "Epoch 40::Minibatch 580::LR 0.01 --> Loss 0.00190261185169\n",
      "Epoch 40::Minibatch 581::LR 0.01 --> Loss 0.00169141252836\n",
      "Epoch 40::Minibatch 582::LR 0.01 --> Loss 0.00421842177709\n",
      "Epoch 40::Minibatch 583::LR 0.01 --> Loss 0.000953556696574\n",
      "Epoch 40::Minibatch 584::LR 0.01 --> Loss 0.00131078173717\n",
      "Epoch 40::Minibatch 585::LR 0.01 --> Loss 0.00375678777695\n",
      "Epoch 40::Minibatch 586::LR 0.01 --> Loss 0.00361149072647\n",
      "Epoch 40::Minibatch 587::LR 0.01 --> Loss 0.00109849184752\n",
      "Epoch 40::Minibatch 588::LR 0.01 --> Loss 0.00134494642417\n",
      "Epoch 40::Minibatch 589::LR 0.01 --> Loss 0.00266834040483\n",
      "Epoch 40::Minibatch 590::LR 0.01 --> Loss 0.00172631820043\n",
      "Epoch 40::Minibatch 591::LR 0.01 --> Loss 0.00254714330037\n",
      "Epoch 40::Minibatch 592::LR 0.01 --> Loss 0.00113135178884\n",
      "Epoch 40::Minibatch 593::LR 0.01 --> Loss 0.00240546703339\n",
      "Epoch 40::Minibatch 594::LR 0.01 --> Loss 0.002440559268\n",
      "Epoch 40::Minibatch 595::LR 0.01 --> Loss 0.00302408357461\n",
      "Epoch 40::Minibatch 596::LR 0.01 --> Loss 0.00177662014961\n",
      "Epoch 40::Minibatch 597::LR 0.01 --> Loss 0.00114105304082\n",
      "Epoch 40::Minibatch 598::LR 0.01 --> Loss 0.00270600835482\n",
      "Epoch 40::Minibatch 599::LR 0.01 --> Loss 0.00175357480844\n",
      "Epoch 40::Minibatch 600::LR 0.01 --> Loss 0.0020658582449\n",
      "Epoch 40::Minibatch 601::LR 0.01 --> Loss 0.00364276369413\n",
      "Epoch 40::Minibatch 602::LR 0.01 --> Loss 0.00205815593402\n",
      "Epoch 40::Minibatch 603::LR 0.01 --> Loss 0.00260402778784\n",
      "Epoch 40::Minibatch 604::LR 0.01 --> Loss 0.00160803854465\n",
      "Epoch 40::Minibatch 605::LR 0.01 --> Loss 0.00222069283326\n",
      "Epoch 40::Minibatch 606::LR 0.01 --> Loss 0.00180133779844\n",
      "Epoch 40::Minibatch 607::LR 0.01 --> Loss 0.000811033695936\n",
      "Epoch 40::Minibatch 608::LR 0.01 --> Loss 0.00152383357286\n",
      "Epoch 40::Minibatch 609::LR 0.01 --> Loss 0.00242069780827\n",
      "Epoch 40::Minibatch 610::LR 0.01 --> Loss 0.00407115697861\n",
      "Epoch 40::Minibatch 611::LR 0.01 --> Loss 0.00274522840977\n",
      "Epoch 40::Minibatch 612::LR 0.01 --> Loss 0.000466299752394\n",
      "Epoch 40::Minibatch 613::LR 0.01 --> Loss 0.00131367862225\n",
      "Epoch 40::Minibatch 614::LR 0.01 --> Loss 0.00237022598584\n",
      "Epoch 40::Minibatch 615::LR 0.01 --> Loss 0.00162663588921\n",
      "Epoch 40::Minibatch 616::LR 0.01 --> Loss 0.000907815496127\n",
      "Epoch 40::Minibatch 617::LR 0.01 --> Loss 0.00048912341396\n",
      "Epoch 40::Minibatch 618::LR 0.01 --> Loss 0.00305598775546\n",
      "Epoch 40::Minibatch 619::LR 0.01 --> Loss 0.0019245972236\n",
      "Epoch 40::Minibatch 620::LR 0.01 --> Loss 0.00166040430466\n",
      "Epoch 40::Minibatch 621::LR 0.01 --> Loss 0.00083582808574\n",
      "Epoch 40::Minibatch 622::LR 0.01 --> Loss 0.000770885000626\n",
      "Epoch 40::Minibatch 623::LR 0.01 --> Loss 0.00221070806185\n",
      "Epoch 40::Minibatch 624::LR 0.01 --> Loss 0.00174524525801\n",
      "Epoch 40::Minibatch 625::LR 0.01 --> Loss 0.00255123178164\n",
      "Epoch 40::Minibatch 626::LR 0.01 --> Loss 0.00325083176295\n",
      "Epoch 40::Minibatch 627::LR 0.01 --> Loss 0.00125030140082\n",
      "Epoch 40::Minibatch 628::LR 0.01 --> Loss 0.000869800547759\n",
      "Epoch 40::Minibatch 629::LR 0.01 --> Loss 0.00288300951322\n",
      "Epoch 40::Minibatch 630::LR 0.01 --> Loss 0.00283552467823\n",
      "Epoch 40::Minibatch 631::LR 0.01 --> Loss 0.00463864723841\n",
      "Epoch 40::Minibatch 632::LR 0.01 --> Loss 0.00080040127039\n",
      "Epoch 40::Minibatch 633::LR 0.01 --> Loss 0.00158599416415\n",
      "Epoch 40::Minibatch 634::LR 0.01 --> Loss 0.00311717728774\n",
      "Epoch 40::Minibatch 635::LR 0.01 --> Loss 0.00515790422757\n",
      "Epoch 40::Minibatch 636::LR 0.01 --> Loss 0.00435169816017\n",
      "Epoch 40::Minibatch 637::LR 0.01 --> Loss 0.000692712714275\n",
      "Epoch 40::Minibatch 638::LR 0.01 --> Loss 0.00149583697319\n",
      "Epoch 40::Minibatch 639::LR 0.01 --> Loss 0.00312892456849\n",
      "Epoch 40::Minibatch 640::LR 0.01 --> Loss 0.00429324706395\n",
      "Epoch 40::Minibatch 641::LR 0.01 --> Loss 0.00296501119932\n",
      "Epoch 40::Minibatch 642::LR 0.01 --> Loss 0.000534144093593\n",
      "Epoch 40::Minibatch 643::LR 0.01 --> Loss 0.00228948513667\n",
      "Epoch 40::Minibatch 644::LR 0.01 --> Loss 0.00379390319188\n",
      "Epoch 40::Minibatch 645::LR 0.01 --> Loss 0.00461290200551\n",
      "Epoch 40::Minibatch 646::LR 0.01 --> Loss 0.00152913282315\n",
      "Epoch 40::Minibatch 647::LR 0.01 --> Loss 0.000457769085964\n",
      "Epoch 40::Minibatch 648::LR 0.01 --> Loss 0.00262566506863\n",
      "Epoch 40::Minibatch 649::LR 0.01 --> Loss 0.00295778612296\n",
      "Epoch 40::Minibatch 650::LR 0.01 --> Loss 0.00298710286617\n",
      "Epoch 40::Minibatch 651::LR 0.01 --> Loss 0.00129434853792\n",
      "Epoch 40::Minibatch 652::LR 0.01 --> Loss 0.000783308148384\n",
      "Epoch 40::Minibatch 653::LR 0.01 --> Loss 0.00274847368399\n",
      "Epoch 40::Minibatch 654::LR 0.01 --> Loss 0.00305428862572\n",
      "Epoch 40::Minibatch 655::LR 0.01 --> Loss 0.00370972077052\n",
      "Epoch 40::Minibatch 656::LR 0.01 --> Loss 0.000760080963373\n",
      "Epoch 40::Minibatch 657::LR 0.01 --> Loss 0.00224780857563\n",
      "Epoch 40::Minibatch 658::LR 0.01 --> Loss 0.00423475980759\n",
      "Epoch 40::Minibatch 659::LR 0.01 --> Loss 0.00215046048164\n",
      "Epoch 40::Minibatch 660::LR 0.01 --> Loss 0.00263728360335\n",
      "Epoch 40::Minibatch 661::LR 0.01 --> Loss 0.00215418080489\n",
      "Epoch 40::Minibatch 662::LR 0.01 --> Loss 0.00178074240685\n",
      "Epoch 40::Minibatch 663::LR 0.01 --> Loss 0.00350840846697\n",
      "Epoch 40::Minibatch 664::LR 0.01 --> Loss 0.00294945478439\n",
      "Epoch 40::Minibatch 665::LR 0.01 --> Loss 0.00068924754858\n",
      "Epoch 40::Minibatch 666::LR 0.01 --> Loss 0.00388546506564\n",
      "Epoch 40::Minibatch 667::LR 0.01 --> Loss 0.00255224982897\n",
      "Epoch 40::Minibatch 668::LR 0.01 --> Loss 0.00597012241681\n",
      "Epoch 40::Minibatch 669::LR 0.01 --> Loss 0.0010682724913\n",
      "Epoch 40::Minibatch 670::LR 0.01 --> Loss 0.00131451805433\n",
      "Epoch 40::Minibatch 671::LR 0.01 --> Loss 0.00496905287107\n",
      "Epoch 40::Minibatch 672::LR 0.01 --> Loss 0.00321186741193\n",
      "Epoch 40::Minibatch 673::LR 0.01 --> Loss 0.00157928278049\n",
      "Epoch 40::Minibatch 674::LR 0.01 --> Loss 0.000511366079251\n",
      "Epoch 40::Minibatch 675::LR 0.01 --> Loss 0.00219350814819\n",
      "Epoch 40::Minibatch 676::LR 0.01 --> Loss 0.00219697117805\n",
      "Epoch 40::Minibatch 677::LR 0.01 --> Loss 0.00264565149943\n",
      "Epoch 40::Minibatch 678::LR 0.01 --> Loss 0.00183638036251\n",
      "Epoch 40::Minibatch 679::LR 0.01 --> Loss 0.00323340614637\n",
      "Epoch 40::Minibatch 680::LR 0.01 --> Loss 0.00210632065932\n",
      "Epoch 40::Minibatch 681::LR 0.01 --> Loss 0.0023299062252\n",
      "Epoch 40::Minibatch 682::LR 0.01 --> Loss 0.000762280672789\n",
      "Epoch 40::Minibatch 683::LR 0.01 --> Loss 0.00223001102606\n",
      "Epoch 40::Minibatch 684::LR 0.01 --> Loss 0.00234669804573\n",
      "Epoch 40::Minibatch 685::LR 0.01 --> Loss 0.00277553300063\n",
      "Epoch 40::Minibatch 686::LR 0.01 --> Loss 0.00157124151786\n",
      "Epoch 40::Minibatch 687::LR 0.01 --> Loss 0.000875797172387\n",
      "Epoch 40::Minibatch 688::LR 0.01 --> Loss 0.00281138797601\n",
      "Epoch 40::Minibatch 689::LR 0.01 --> Loss 0.00243896663189\n",
      "Epoch 40::Minibatch 690::LR 0.01 --> Loss 0.00184269368649\n",
      "Epoch 40::Minibatch 691::LR 0.01 --> Loss 0.000657864908377\n",
      "Epoch 40::Minibatch 692::LR 0.01 --> Loss 0.00242732644081\n",
      "Epoch 40::Minibatch 693::LR 0.01 --> Loss 0.00264888882637\n",
      "Epoch 40::Minibatch 694::LR 0.01 --> Loss 0.00295931537946\n",
      "Epoch 40::Minibatch 695::LR 0.01 --> Loss 0.00183551808198\n",
      "Epoch 40::Minibatch 696::LR 0.01 --> Loss 0.00201302289963\n",
      "Epoch 40::Minibatch 697::LR 0.01 --> Loss 0.00139478276173\n",
      "Epoch 40::Minibatch 698::LR 0.01 --> Loss 0.00167083601157\n",
      "Epoch 40::Minibatch 699::LR 0.01 --> Loss 0.00361581325531\n",
      "Epoch 40::Minibatch 700::LR 0.01 --> Loss 0.00249876916409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 701::LR 0.01 --> Loss 0.00183423578739\n",
      "Epoch 40::Minibatch 702::LR 0.01 --> Loss 0.00167455355326\n",
      "Epoch 40::Minibatch 703::LR 0.01 --> Loss 0.00417248010635\n",
      "Epoch 40::Minibatch 704::LR 0.01 --> Loss 0.00180882255236\n",
      "Epoch 40::Minibatch 705::LR 0.01 --> Loss 0.00278186460336\n",
      "Epoch 40::Minibatch 706::LR 0.01 --> Loss 0.00216132581234\n",
      "Epoch 40::Minibatch 707::LR 0.01 --> Loss 0.00118963460128\n",
      "Epoch 40::Minibatch 708::LR 0.01 --> Loss 0.00173057417075\n",
      "Epoch 40::Minibatch 709::LR 0.01 --> Loss 0.00166381210089\n",
      "Epoch 40::Minibatch 710::LR 0.01 --> Loss 0.00258461376031\n",
      "Epoch 40::Minibatch 711::LR 0.01 --> Loss 0.00200413306554\n",
      "Epoch 40::Minibatch 712::LR 0.01 --> Loss 0.00139734447002\n",
      "Epoch 40::Minibatch 713::LR 0.01 --> Loss 0.00182640691598\n",
      "Epoch 40::Minibatch 714::LR 0.01 --> Loss 0.0029062940677\n",
      "Epoch 40::Minibatch 715::LR 0.01 --> Loss 0.00288362622261\n",
      "Epoch 40::Minibatch 716::LR 0.01 --> Loss 0.00168695191542\n",
      "Epoch 40::Minibatch 717::LR 0.01 --> Loss 0.00169722775618\n",
      "Epoch 40::Minibatch 718::LR 0.01 --> Loss 0.00130050470432\n",
      "Epoch 40::Minibatch 719::LR 0.01 --> Loss 0.00175795018673\n",
      "Epoch 40::Minibatch 720::LR 0.01 --> Loss 0.00286100586255\n",
      "Epoch 40::Minibatch 721::LR 0.01 --> Loss 0.000608665744464\n",
      "Epoch 40::Minibatch 722::LR 0.01 --> Loss 0.00445746302605\n",
      "Epoch 40::Minibatch 723::LR 0.01 --> Loss 0.0047122557958\n",
      "Epoch 40::Minibatch 724::LR 0.01 --> Loss 0.000966514746348\n",
      "Epoch 40::Minibatch 725::LR 0.01 --> Loss 0.0019884198904\n",
      "Epoch 40::Minibatch 726::LR 0.01 --> Loss 0.00320326586564\n",
      "Epoch 40::Minibatch 727::LR 0.01 --> Loss 0.0028560256958\n",
      "Epoch 40::Minibatch 728::LR 0.01 --> Loss 0.000643043021361\n",
      "Epoch 40::Minibatch 729::LR 0.01 --> Loss 0.000711898853381\n",
      "Epoch 40::Minibatch 730::LR 0.01 --> Loss 0.00285284936428\n",
      "Epoch 40::Minibatch 731::LR 0.01 --> Loss 0.00262759387493\n",
      "Epoch 40::Minibatch 732::LR 0.01 --> Loss 0.00195875306924\n",
      "Epoch 40::Minibatch 733::LR 0.01 --> Loss 0.000564184337854\n",
      "Epoch 40::Minibatch 734::LR 0.01 --> Loss 0.00160109291474\n",
      "Epoch 40::Minibatch 735::LR 0.01 --> Loss 0.0025486544768\n",
      "Epoch 40::Minibatch 736::LR 0.01 --> Loss 0.00346758882205\n",
      "Epoch 40::Minibatch 737::LR 0.01 --> Loss 0.00279806812604\n",
      "Epoch 40::Minibatch 738::LR 0.01 --> Loss 0.0012373628219\n",
      "Epoch 40::Minibatch 739::LR 0.01 --> Loss 0.00225667933623\n",
      "Epoch 40::Minibatch 740::LR 0.01 --> Loss 0.00370634754499\n",
      "Epoch 40::Minibatch 741::LR 0.01 --> Loss 0.00246087789536\n",
      "Epoch 40::Minibatch 742::LR 0.01 --> Loss 0.00203103303909\n",
      "Epoch 40::Minibatch 743::LR 0.01 --> Loss 0.00150566409032\n",
      "Epoch 40::Minibatch 744::LR 0.01 --> Loss 0.00189860363801\n",
      "Epoch 40::Minibatch 745::LR 0.01 --> Loss 0.00274530450503\n",
      "Epoch 40::Minibatch 746::LR 0.01 --> Loss 0.00277404705683\n",
      "Epoch 40::Minibatch 747::LR 0.01 --> Loss 0.00173233091831\n",
      "Epoch 40::Minibatch 748::LR 0.01 --> Loss 0.000625789066156\n",
      "Epoch 40::Minibatch 749::LR 0.01 --> Loss 0.0016925261418\n",
      "Epoch 40::Minibatch 750::LR 0.01 --> Loss 0.00239427924156\n",
      "Epoch 40::Minibatch 751::LR 0.01 --> Loss 0.0030218309164\n",
      "Epoch 40::Minibatch 752::LR 0.01 --> Loss 0.00157513459524\n",
      "Epoch 40::Minibatch 753::LR 0.01 --> Loss 0.00220412095388\n",
      "Epoch 40::Minibatch 754::LR 0.01 --> Loss 0.00244415422281\n",
      "Epoch 40::Minibatch 755::LR 0.01 --> Loss 0.00264168043931\n",
      "Epoch 40::Minibatch 756::LR 0.01 --> Loss 0.0012751236558\n",
      "Epoch 40::Minibatch 757::LR 0.01 --> Loss 0.000542381703854\n",
      "Epoch 40::Minibatch 758::LR 0.01 --> Loss 0.0015681613485\n",
      "Epoch 40::Minibatch 759::LR 0.01 --> Loss 0.00318435192108\n",
      "Epoch 40::Minibatch 760::LR 0.01 --> Loss 0.0026926668485\n",
      "Epoch 40::Minibatch 761::LR 0.01 --> Loss 0.00506126125654\n",
      "Epoch 40::Minibatch 762::LR 0.01 --> Loss 0.0033817255497\n",
      "Epoch 40::Minibatch 763::LR 0.01 --> Loss 0.00330624639988\n",
      "Epoch 40::Minibatch 764::LR 0.01 --> Loss 0.0029400018851\n",
      "Epoch 40::Minibatch 765::LR 0.01 --> Loss 0.00120719651381\n",
      "Epoch 40::Minibatch 766::LR 0.01 --> Loss 0.00227763513724\n",
      "Epoch 40::Minibatch 767::LR 0.01 --> Loss 0.0045854818821\n",
      "Epoch 40::Minibatch 768::LR 0.01 --> Loss 0.00355794390043\n",
      "Epoch 40::Minibatch 769::LR 0.01 --> Loss 0.00179296692212\n",
      "Epoch 40::Minibatch 770::LR 0.01 --> Loss 0.00150213291248\n",
      "Epoch 40::Minibatch 771::LR 0.01 --> Loss 0.00322634339333\n",
      "Epoch 40::Minibatch 772::LR 0.01 --> Loss 0.00363697091738\n",
      "Epoch 40::Minibatch 773::LR 0.01 --> Loss 0.00317063967387\n",
      "Epoch 40::Minibatch 774::LR 0.01 --> Loss 0.00189827760061\n",
      "Epoch 40::Minibatch 775::LR 0.01 --> Loss 0.0030492289861\n",
      "Epoch 40::Minibatch 776::LR 0.01 --> Loss 0.00395145376523\n",
      "Epoch 40::Minibatch 777::LR 0.01 --> Loss 0.0055369913578\n",
      "Epoch 40::Minibatch 778::LR 0.01 --> Loss 0.00629480441411\n",
      "Epoch 40::Minibatch 779::LR 0.01 --> Loss 0.00245856126149\n",
      "Epoch 40::Minibatch 780::LR 0.01 --> Loss 0.00146159658829\n",
      "Epoch 40::Minibatch 781::LR 0.01 --> Loss 0.00347341299057\n",
      "Epoch 40::Minibatch 782::LR 0.01 --> Loss 0.00387630263964\n",
      "Epoch 40::Minibatch 783::LR 0.01 --> Loss 0.00225767175357\n",
      "Epoch 40::Minibatch 784::LR 0.01 --> Loss 0.000712230453889\n",
      "Epoch 40::Minibatch 785::LR 0.01 --> Loss 0.00361901521683\n",
      "Epoch 40::Minibatch 786::LR 0.01 --> Loss 0.00376140713692\n",
      "Epoch 40::Minibatch 787::LR 0.01 --> Loss 0.0025760747989\n",
      "Epoch 40::Minibatch 788::LR 0.01 --> Loss 0.00251370131969\n",
      "Epoch 40::Minibatch 789::LR 0.01 --> Loss 0.000721944570541\n",
      "Epoch 40::Minibatch 790::LR 0.01 --> Loss 0.00320532123248\n",
      "Epoch 40::Minibatch 791::LR 0.01 --> Loss 0.00317020654678\n",
      "Epoch 40::Minibatch 792::LR 0.01 --> Loss 0.00299253106117\n",
      "Epoch 40::Minibatch 793::LR 0.01 --> Loss 0.00161154667536\n",
      "Epoch 40::Minibatch 794::LR 0.01 --> Loss 0.000983744263649\n",
      "Epoch 40::Minibatch 795::LR 0.01 --> Loss 0.00256498197714\n",
      "Epoch 40::Minibatch 796::LR 0.01 --> Loss 0.00454636573792\n",
      "Epoch 40::Minibatch 797::LR 0.01 --> Loss 0.00535845796267\n",
      "Epoch 40::Minibatch 798::LR 0.01 --> Loss 0.00291065613429\n",
      "Epoch 40::Minibatch 799::LR 0.01 --> Loss 0.00223326226075\n",
      "Epoch 40::Minibatch 800::LR 0.01 --> Loss 0.00199320892493\n",
      "Epoch 40::Minibatch 801::LR 0.01 --> Loss 0.00367482821147\n",
      "Epoch 40::Minibatch 802::LR 0.01 --> Loss 0.00116390277942\n",
      "Epoch 40::Minibatch 803::LR 0.01 --> Loss 0.00297750234604\n",
      "Epoch 40::Minibatch 804::LR 0.01 --> Loss 0.00204454044501\n",
      "Epoch 40::Minibatch 805::LR 0.01 --> Loss 0.0021631560723\n",
      "Epoch 40::Minibatch 806::LR 0.01 --> Loss 0.00316146413485\n",
      "Epoch 40::Minibatch 807::LR 0.01 --> Loss 0.00303202966849\n",
      "Epoch 40::Minibatch 808::LR 0.01 --> Loss 0.0028647762537\n",
      "Epoch 40::Minibatch 809::LR 0.01 --> Loss 0.00286401331425\n",
      "Epoch 40::Minibatch 810::LR 0.01 --> Loss 0.00387209097544\n",
      "Epoch 40::Minibatch 811::LR 0.01 --> Loss 0.00371785283089\n",
      "Epoch 40::Minibatch 812::LR 0.01 --> Loss 0.00345720410347\n",
      "Epoch 40::Minibatch 813::LR 0.01 --> Loss 0.00284426848094\n",
      "Epoch 40::Minibatch 814::LR 0.01 --> Loss 0.00147821764151\n",
      "Epoch 40::Minibatch 815::LR 0.01 --> Loss 0.0033681833744\n",
      "Epoch 40::Minibatch 816::LR 0.01 --> Loss 0.0038335386912\n",
      "Epoch 40::Minibatch 817::LR 0.01 --> Loss 0.00440557837486\n",
      "Epoch 40::Minibatch 818::LR 0.01 --> Loss 0.00122403959433\n",
      "Epoch 40::Minibatch 819::LR 0.01 --> Loss 0.000736379871766\n",
      "Epoch 40::Minibatch 820::LR 0.01 --> Loss 0.00490779519081\n",
      "Epoch 40::Minibatch 821::LR 0.01 --> Loss 0.00307485302289\n",
      "Epoch 40::Minibatch 822::LR 0.01 --> Loss 0.00367976307869\n",
      "Epoch 40::Minibatch 823::LR 0.01 --> Loss 0.00124270478884\n",
      "Epoch 40::Minibatch 824::LR 0.01 --> Loss 0.00137841790915\n",
      "Epoch 40::Minibatch 825::LR 0.01 --> Loss 0.00382794936498\n",
      "Epoch 40::Minibatch 826::LR 0.01 --> Loss 0.00451879620552\n",
      "Epoch 40::Minibatch 827::LR 0.01 --> Loss 0.00204973479112\n",
      "Epoch 40::Minibatch 828::LR 0.01 --> Loss 0.000485977480809\n",
      "Epoch 40::Minibatch 829::LR 0.01 --> Loss 0.00226012686888\n",
      "Epoch 40::Minibatch 830::LR 0.01 --> Loss 0.00381773114204\n",
      "Epoch 40::Minibatch 831::LR 0.01 --> Loss 0.00230629344781\n",
      "Epoch 40::Minibatch 832::LR 0.01 --> Loss 0.00203871826331\n",
      "Epoch 40::Minibatch 833::LR 0.01 --> Loss 0.00179076194763\n",
      "Epoch 40::Minibatch 834::LR 0.01 --> Loss 0.000795194407304\n",
      "Epoch 40::Minibatch 835::LR 0.01 --> Loss 0.00390726526578\n",
      "Epoch 40::Minibatch 836::LR 0.01 --> Loss 0.00357475399971\n",
      "Epoch 40::Minibatch 837::LR 0.01 --> Loss 0.00229761282603\n",
      "Epoch 40::Minibatch 838::LR 0.01 --> Loss 0.000654113590717\n",
      "Epoch 40::Minibatch 839::LR 0.01 --> Loss 0.00231032550335\n",
      "Epoch 40::Minibatch 840::LR 0.01 --> Loss 0.0028503938516\n",
      "Epoch 40::Minibatch 841::LR 0.01 --> Loss 0.00274556179841\n",
      "Epoch 40::Minibatch 842::LR 0.01 --> Loss 0.00211484690507\n",
      "Epoch 40::Minibatch 843::LR 0.01 --> Loss 0.000959209303061\n",
      "Epoch 40::Minibatch 844::LR 0.01 --> Loss 0.00146079043547\n",
      "Epoch 40::Minibatch 845::LR 0.01 --> Loss 0.00387314399083\n",
      "Epoch 40::Minibatch 846::LR 0.01 --> Loss 0.00167385756969\n",
      "Epoch 40::Minibatch 847::LR 0.01 --> Loss 0.00241102735202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 848::LR 0.01 --> Loss 0.00118306626876\n",
      "Epoch 40::Minibatch 849::LR 0.01 --> Loss 0.00179084459941\n",
      "Epoch 40::Minibatch 850::LR 0.01 --> Loss 0.00317579428355\n",
      "Epoch 40::Minibatch 851::LR 0.01 --> Loss 0.00250181118647\n",
      "Epoch 40::Minibatch 852::LR 0.01 --> Loss 0.001162040929\n",
      "Epoch 40::Minibatch 853::LR 0.01 --> Loss 0.00130916466316\n",
      "Epoch 40::Minibatch 854::LR 0.01 --> Loss 0.00251363913218\n",
      "Epoch 40::Minibatch 855::LR 0.01 --> Loss 0.00209155440331\n",
      "Epoch 40::Minibatch 856::LR 0.01 --> Loss 0.00176907082399\n",
      "Epoch 40::Minibatch 857::LR 0.01 --> Loss 0.00120431512594\n",
      "Epoch 40::Minibatch 858::LR 0.01 --> Loss 0.000608342885971\n",
      "Epoch 40::Minibatch 859::LR 0.01 --> Loss 0.00201727390289\n",
      "Epoch 40::Minibatch 860::LR 0.01 --> Loss 0.00132107079029\n",
      "Epoch 40::Minibatch 861::LR 0.01 --> Loss 0.00095167517662\n",
      "Epoch 40::Minibatch 862::LR 0.01 --> Loss 0.0037446085612\n",
      "Epoch 40::Minibatch 863::LR 0.01 --> Loss 0.00334764957428\n",
      "Epoch 40::Minibatch 864::LR 0.01 --> Loss 0.00258779029051\n",
      "Epoch 40::Minibatch 865::LR 0.01 --> Loss 0.000563634335995\n",
      "Epoch 40::Minibatch 866::LR 0.01 --> Loss 0.00205417672793\n",
      "Epoch 40::Minibatch 867::LR 0.01 --> Loss 0.00284800887108\n",
      "Epoch 40::Minibatch 868::LR 0.01 --> Loss 0.00246652364731\n",
      "Epoch 40::Minibatch 869::LR 0.01 --> Loss 0.00215319514275\n",
      "Epoch 40::Minibatch 870::LR 0.01 --> Loss 0.00312418182691\n",
      "Epoch 40::Minibatch 871::LR 0.01 --> Loss 0.00167410870393\n",
      "Epoch 40::Minibatch 872::LR 0.01 --> Loss 0.00205662628015\n",
      "Epoch 40::Minibatch 873::LR 0.01 --> Loss 0.00247409919898\n",
      "Epoch 40::Minibatch 874::LR 0.01 --> Loss 0.00469269792239\n",
      "Epoch 40::Minibatch 875::LR 0.01 --> Loss 0.000707949846983\n",
      "Epoch 40::Minibatch 876::LR 0.01 --> Loss 0.00256290376186\n",
      "Epoch 40::Minibatch 877::LR 0.01 --> Loss 0.0039612531662\n",
      "Epoch 40::Minibatch 878::LR 0.01 --> Loss 0.00274904131889\n",
      "Epoch 40::Minibatch 879::LR 0.01 --> Loss 0.00380753318469\n",
      "Epoch 40::Minibatch 880::LR 0.01 --> Loss 0.00488643288612\n",
      "Epoch 40::Minibatch 881::LR 0.01 --> Loss 0.00405115246773\n",
      "Epoch 40::Minibatch 882::LR 0.01 --> Loss 0.00186040262381\n",
      "Epoch 40::Minibatch 883::LR 0.01 --> Loss 0.00366660356522\n",
      "Epoch 40::Minibatch 884::LR 0.01 --> Loss 0.00283322135607\n",
      "Epoch 40::Minibatch 885::LR 0.01 --> Loss 0.00258778115114\n",
      "Epoch 40::Minibatch 886::LR 0.01 --> Loss 0.000448122123877\n",
      "Epoch 40::Minibatch 887::LR 0.01 --> Loss 0.00567492604256\n",
      "Epoch 40::Minibatch 888::LR 0.01 --> Loss 0.00239766875903\n",
      "Epoch 40::Minibatch 889::LR 0.01 --> Loss 0.00245620409648\n",
      "Epoch 40::Minibatch 890::LR 0.01 --> Loss 0.00352190534274\n",
      "Epoch 40::Minibatch 891::LR 0.01 --> Loss 0.00166719396909\n",
      "Epoch 40::Minibatch 892::LR 0.01 --> Loss 0.000772681931655\n",
      "Epoch 40::Minibatch 893::LR 0.01 --> Loss 0.00219331423442\n",
      "Epoch 40::Minibatch 894::LR 0.01 --> Loss 0.00191680788994\n",
      "Epoch 40::Minibatch 895::LR 0.01 --> Loss 0.00223453044891\n",
      "Epoch 40::Minibatch 896::LR 0.01 --> Loss 0.00127064704895\n",
      "Epoch 40::Minibatch 897::LR 0.01 --> Loss 0.000662943323453\n",
      "Epoch 40::Minibatch 898::LR 0.01 --> Loss 0.00190106173356\n",
      "Epoch 40::Minibatch 899::LR 0.01 --> Loss 0.00243071635564\n",
      "Epoch 40::Minibatch 900::LR 0.01 --> Loss 0.00294651865959\n",
      "Epoch 40::Minibatch 901::LR 0.01 --> Loss 0.000585821370284\n",
      "Epoch 40::Minibatch 902::LR 0.01 --> Loss 0.00138363023599\n",
      "Epoch 40::Minibatch 903::LR 0.01 --> Loss 0.00258030136426\n",
      "Epoch 40::Minibatch 904::LR 0.01 --> Loss 0.00180503050486\n",
      "Epoch 40::Minibatch 905::LR 0.01 --> Loss 0.00138387352228\n",
      "Epoch 40::Minibatch 906::LR 0.01 --> Loss 0.00100744297107\n",
      "Epoch 40::Minibatch 907::LR 0.01 --> Loss 0.00153575132291\n",
      "Epoch 40::Minibatch 908::LR 0.01 --> Loss 0.00208072821299\n",
      "Epoch 40::Minibatch 909::LR 0.01 --> Loss 0.00193324585756\n",
      "Epoch 40::Minibatch 910::LR 0.01 --> Loss 0.000841299494108\n",
      "Epoch 40::Minibatch 911::LR 0.01 --> Loss 0.00128901789586\n",
      "Epoch 40::Minibatch 912::LR 0.01 --> Loss 0.00210302809874\n",
      "Epoch 40::Minibatch 913::LR 0.01 --> Loss 0.00237036168575\n",
      "Epoch 40::Minibatch 914::LR 0.01 --> Loss 0.0013192559282\n",
      "Epoch 40::Minibatch 915::LR 0.01 --> Loss 0.000555794934432\n",
      "Epoch 40::Minibatch 916::LR 0.01 --> Loss 0.00191419064999\n",
      "Epoch 40::Minibatch 917::LR 0.01 --> Loss 0.00297869900862\n",
      "Epoch 40::Minibatch 918::LR 0.01 --> Loss 0.00362967014313\n",
      "Epoch 40::Minibatch 919::LR 0.01 --> Loss 0.000584264546633\n",
      "Epoch 40::Minibatch 920::LR 0.01 --> Loss 0.0101879580816\n",
      "Epoch 40::Minibatch 921::LR 0.01 --> Loss 0.00303272823493\n",
      "Epoch 40::Minibatch 922::LR 0.01 --> Loss 0.00303896884123\n",
      "Epoch 40::Minibatch 923::LR 0.01 --> Loss 0.00109004745881\n",
      "Epoch 40::Minibatch 924::LR 0.01 --> Loss 0.00321033418179\n",
      "Epoch 40::Minibatch 925::LR 0.01 --> Loss 0.00223737855752\n",
      "Epoch 40::Minibatch 926::LR 0.01 --> Loss 0.00413652340571\n",
      "Epoch 40::Minibatch 927::LR 0.01 --> Loss 0.0043524547418\n",
      "Epoch 40::Minibatch 928::LR 0.01 --> Loss 0.00575116872787\n",
      "Epoch 40::Minibatch 929::LR 0.01 --> Loss 0.00469804962476\n",
      "Epoch 40::Minibatch 930::LR 0.01 --> Loss 0.00890336354574\n",
      "Epoch 40::Minibatch 931::LR 0.01 --> Loss 0.00290527164936\n",
      "Epoch 40::Minibatch 932::LR 0.01 --> Loss 0.00485773404439\n",
      "Epoch 40::Minibatch 933::LR 0.01 --> Loss 0.00217346449693\n",
      "Epoch 40::Minibatch 934::LR 0.01 --> Loss 0.00261618594329\n",
      "Epoch 40::Minibatch 935::LR 0.01 --> Loss 0.0039757168293\n",
      "Epoch 40::Minibatch 936::LR 0.01 --> Loss 0.000681717793147\n",
      "Epoch 40::Minibatch 937::LR 0.01 --> Loss 0.00208283742269\n",
      "Epoch 40::Minibatch 938::LR 0.01 --> Loss 0.00172887504101\n",
      "Epoch 40::Minibatch 939::LR 0.01 --> Loss 0.00195560634136\n",
      "Epoch 40::Minibatch 940::LR 0.01 --> Loss 0.000895769000053\n",
      "Epoch 40::Minibatch 941::LR 0.01 --> Loss 0.00071356271704\n",
      "Epoch 40::Minibatch 942::LR 0.01 --> Loss 0.0025469938914\n",
      "Epoch 40::Minibatch 943::LR 0.01 --> Loss 0.00220208028952\n",
      "Epoch 40::Minibatch 944::LR 0.01 --> Loss 0.00155121475458\n",
      "Epoch 40::Minibatch 945::LR 0.01 --> Loss 0.000825973252455\n",
      "Epoch 40::Minibatch 946::LR 0.01 --> Loss 0.00217091917992\n",
      "Epoch 40::Minibatch 947::LR 0.01 --> Loss 0.00206300258636\n",
      "Epoch 40::Minibatch 948::LR 0.01 --> Loss 0.00357987880707\n",
      "Epoch 40::Minibatch 949::LR 0.01 --> Loss 0.0016591099898\n",
      "Epoch 40::Minibatch 950::LR 0.01 --> Loss 0.000668758004904\n",
      "Epoch 40::Minibatch 951::LR 0.01 --> Loss 0.00330185612043\n",
      "Epoch 40::Minibatch 952::LR 0.01 --> Loss 0.00230046550433\n",
      "Epoch 40::Minibatch 953::LR 0.01 --> Loss 0.00141746431589\n",
      "Epoch 40::Minibatch 954::LR 0.01 --> Loss 0.000918409427007\n",
      "Epoch 40::Minibatch 955::LR 0.01 --> Loss 0.00257156511148\n",
      "Epoch 40::Minibatch 956::LR 0.01 --> Loss 0.00291848659515\n",
      "Epoch 40::Minibatch 957::LR 0.01 --> Loss 0.0018400490284\n",
      "Epoch 40::Minibatch 958::LR 0.01 --> Loss 0.00217960894108\n",
      "Epoch 40::Minibatch 959::LR 0.01 --> Loss 0.00242070257664\n",
      "Epoch 40::Minibatch 960::LR 0.01 --> Loss 0.00510206619898\n",
      "Epoch 40::Minibatch 961::LR 0.01 --> Loss 0.00277664899826\n",
      "Epoch 40::Minibatch 962::LR 0.01 --> Loss 0.00209507147471\n",
      "Epoch 40::Minibatch 963::LR 0.01 --> Loss 0.00102123161157\n",
      "Epoch 40::Minibatch 964::LR 0.01 --> Loss 0.00227644483248\n",
      "Epoch 40::Minibatch 965::LR 0.01 --> Loss 0.00612789154053\n",
      "Epoch 40::Minibatch 966::LR 0.01 --> Loss 0.00490101099014\n",
      "Epoch 40::Minibatch 967::LR 0.01 --> Loss 0.0011920585235\n",
      "Epoch 40::Minibatch 968::LR 0.01 --> Loss 0.000891784727573\n",
      "Epoch 40::Minibatch 969::LR 0.01 --> Loss 0.003841329813\n",
      "Epoch 40::Minibatch 970::LR 0.01 --> Loss 0.00362104574839\n",
      "Epoch 40::Minibatch 971::LR 0.01 --> Loss 0.00301792502403\n",
      "Epoch 40::Minibatch 972::LR 0.01 --> Loss 0.00602039456367\n",
      "Epoch 40::Minibatch 973::LR 0.01 --> Loss 0.00871963342031\n",
      "Epoch 40::Minibatch 974::LR 0.01 --> Loss 0.00729109684626\n",
      "Epoch 40::Minibatch 975::LR 0.01 --> Loss 0.00560802022616\n",
      "Epoch 40::Minibatch 976::LR 0.01 --> Loss 0.00346021056175\n",
      "Epoch 40::Minibatch 977::LR 0.01 --> Loss 0.0030235149463\n",
      "Epoch 40::Minibatch 978::LR 0.01 --> Loss 0.00287929097811\n",
      "Epoch 40::Minibatch 979::LR 0.01 --> Loss 0.00272319972515\n",
      "Epoch 40::Minibatch 980::LR 0.01 --> Loss 0.0030863759915\n",
      "Epoch 40::Minibatch 981::LR 0.01 --> Loss 0.00355073094368\n",
      "Epoch 40::Minibatch 982::LR 0.01 --> Loss 0.00302010655403\n",
      "Epoch 40::Minibatch 983::LR 0.01 --> Loss 0.00205038925012\n",
      "Epoch 40::Minibatch 984::LR 0.01 --> Loss 0.00132305830717\n",
      "Epoch 40::Minibatch 985::LR 0.01 --> Loss 0.00254078626633\n",
      "Epoch 40::Minibatch 986::LR 0.01 --> Loss 0.00224425633748\n",
      "Epoch 40::Minibatch 987::LR 0.01 --> Loss 0.00272583882014\n",
      "Epoch 40::Minibatch 988::LR 0.01 --> Loss 0.00202099899451\n",
      "Epoch 40::Minibatch 989::LR 0.01 --> Loss 0.00241945882638\n",
      "Epoch 40::Minibatch 990::LR 0.01 --> Loss 0.0023921585083\n",
      "Epoch 40::Minibatch 991::LR 0.01 --> Loss 0.00110489507516\n",
      "Epoch 40::Minibatch 992::LR 0.01 --> Loss 0.00143270711104\n",
      "Epoch 40::Minibatch 993::LR 0.01 --> Loss 0.00258613824844\n",
      "Epoch 40::Minibatch 994::LR 0.01 --> Loss 0.00174400726954\n",
      "Epoch 40::Minibatch 995::LR 0.01 --> Loss 0.000712875773509\n",
      "Epoch 40::Minibatch 996::LR 0.01 --> Loss 0.00235002775987\n",
      "Epoch 40::Minibatch 997::LR 0.01 --> Loss 0.00203332960606\n",
      "Epoch 40::Minibatch 998::LR 0.01 --> Loss 0.00230852067471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40::Minibatch 999::LR 0.01 --> Loss 0.00200870613257\n",
      "Epoch 40::Minibatch 1000::LR 0.01 --> Loss 0.0025026534001\n",
      "Epoch 40::Minibatch 1001::LR 0.01 --> Loss 0.00197074989478\n",
      "Epoch 40::Minibatch 1002::LR 0.01 --> Loss 0.00132946829001\n",
      "Epoch 40::Minibatch 1003::LR 0.01 --> Loss 0.00213352541129\n",
      "Epoch 40::Minibatch 1004::LR 0.01 --> Loss 0.00104056914647\n",
      "Epoch 40::Minibatch 1005::LR 0.01 --> Loss 0.00240249872208\n",
      "Epoch 40::Minibatch 1006::LR 0.01 --> Loss 0.00114428540071\n",
      "Epoch 40::Minibatch 1007::LR 0.01 --> Loss 0.00155329316854\n",
      "Epoch 40::Minibatch 1008::LR 0.01 --> Loss 0.000892216960589\n",
      "Epoch 40::Minibatch 1009::LR 0.01 --> Loss 0.00114525993665\n",
      "Epoch 40::Minibatch 1010::LR 0.01 --> Loss 0.00113215237856\n",
      "Epoch 40::Minibatch 1011::LR 0.01 --> Loss 0.00144082238277\n",
      "Epoch 40::Minibatch 1012::LR 0.01 --> Loss 0.00128086974223\n",
      "Epoch 40::Minibatch 1013::LR 0.01 --> Loss 0.00313828349113\n",
      "Epoch 40::Minibatch 1014::LR 0.01 --> Loss 0.00291014154752\n",
      "Epoch 40::Minibatch 1015::LR 0.01 --> Loss 0.00147909065088\n",
      "Epoch 40::Minibatch 1016::LR 0.01 --> Loss 0.00420437177022\n",
      "Epoch 40::Minibatch 1017::LR 0.01 --> Loss 0.00310982326667\n",
      "Epoch 40::Minibatch 1018::LR 0.01 --> Loss 0.00230879803499\n",
      "Epoch 40::Minibatch 1019::LR 0.01 --> Loss 0.00140399624904\n",
      "Epoch 40::Minibatch 1020::LR 0.01 --> Loss 0.0015807445844\n",
      "Epoch 40::Minibatch 1021::LR 0.01 --> Loss 0.00172141512235\n",
      "Epoch 40::Minibatch 1022::LR 0.01 --> Loss 0.00123306065798\n",
      "Epoch 40::Minibatch 1023::LR 0.01 --> Loss 0.000924836993217\n",
      "Epoch 40::Minibatch 1024::LR 0.01 --> Loss 0.000941766103109\n",
      "Epoch 40::Minibatch 1025::LR 0.01 --> Loss 0.00133071372906\n",
      "Epoch 40::Minibatch 1026::LR 0.01 --> Loss 0.000659745335579\n",
      "Epoch 40::Minibatch 1027::LR 0.01 --> Loss 0.000948975682259\n",
      "Epoch 40::Minibatch 1028::LR 0.01 --> Loss 0.000686336755753\n",
      "Epoch 40::Minibatch 1029::LR 0.01 --> Loss 0.000731302847465\n",
      "Epoch 40::Minibatch 1030::LR 0.01 --> Loss 0.000869444708029\n",
      "Epoch 40::Minibatch 1031::LR 0.01 --> Loss 0.000645284205675\n",
      "Epoch 40::Minibatch 1032::LR 0.01 --> Loss 0.000755305737257\n",
      "Epoch 40::Minibatch 1033::LR 0.01 --> Loss 0.000642956445614\n",
      "Epoch 40::Minibatch 1034::LR 0.01 --> Loss 0.000611492196719\n",
      "Epoch 40::Minibatch 1035::LR 0.01 --> Loss 0.000396894663572\n",
      "Epoch 40::Minibatch 1036::LR 0.01 --> Loss 0.000317331850529\n",
      "Epoch 40::Minibatch 1037::LR 0.01 --> Loss 0.000620819677909\n",
      "Epoch 40::Minibatch 1038::LR 0.01 --> Loss 0.000917422274748\n",
      "Epoch 40::Minibatch 1039::LR 0.01 --> Loss 0.000839210351308\n",
      "Epoch 40::Minibatch 1040::LR 0.01 --> Loss 0.000326050420602\n",
      "Epoch 40::Minibatch 1041::LR 0.01 --> Loss 0.000465439707041\n",
      "Training finished, starting predicting\n",
      "********************\n",
      "For fold 0\n",
      "\t Label LYING_DOWN:::-> Balanced Accuracy 0.8469436\n",
      "\t Label SITTING:::-> Balanced Accuracy 0.7395759\n",
      "\t Label FIX_walking:::-> Balanced Accuracy 0.793695\n",
      "\t Label FIX_running:::-> Balanced Accuracy 0.9179074\n",
      "\t Label BICYCLING:::-> Balanced Accuracy 0.8874898\n",
      "\t Label SLEEPING:::-> Balanced Accuracy 0.8642421\n",
      "\t Label LAB_WORK:::-> Balanced Accuracy 0.9109001\n",
      "\t Label IN_CLASS:::-> Balanced Accuracy 0.8818119\n",
      "\t Label IN_A_MEETING:::-> Balanced Accuracy 0.8717169\n",
      "\t Label LOC_main_workplace:::-> Balanced Accuracy 0.8364515\n",
      "\t Label OR_indoors:::-> Balanced Accuracy 0.6969502\n",
      "\t Label OR_outside:::-> Balanced Accuracy 0.8218405\n",
      "\t Label IN_A_CAR:::-> Balanced Accuracy 0.8650538\n",
      "\t Label ON_A_BUS:::-> Balanced Accuracy 0.8726865\n",
      "\t Label DRIVE_-_I_M_THE_DRIVER:::-> Balanced Accuracy 0.8689922\n",
      "\t Label DRIVE_-_I_M_A_PASSENGER:::-> Balanced Accuracy 0.9094766\n",
      "\t Label LOC_home:::-> Balanced Accuracy 0.7517142\n",
      "\t Label FIX_restaurant:::-> Balanced Accuracy 0.893276\n",
      "\t Label PHONE_IN_POCKET:::-> Balanced Accuracy 0.7987878\n",
      "\t Label OR_exercise:::-> Balanced Accuracy 0.8355256\n",
      "\t Label COOKING:::-> Balanced Accuracy 0.8068537\n",
      "\t Label SHOPPING:::-> Balanced Accuracy 0.8741651\n",
      "\t Label STROLLING:::-> Balanced Accuracy 0.9163774\n",
      "\t Label DRINKING__ALCOHOL_:::-> Balanced Accuracy 0.9172179\n",
      "\t Label BATHING_-_SHOWER:::-> Balanced Accuracy 0.7879911\n",
      "\t Label CLEANING:::-> Balanced Accuracy 0.7727289\n",
      "\t Label DOING_LAUNDRY:::-> Balanced Accuracy 0.9017307\n",
      "\t Label WASHING_DISHES:::-> Balanced Accuracy 0.8150544\n",
      "\t Label WATCHING_TV:::-> Balanced Accuracy 0.7734697\n",
      "\t Label SURFING_THE_INTERNET:::-> Balanced Accuracy 0.7321027\n",
      "\t Label AT_A_PARTY:::-> Balanced Accuracy 0.947705\n",
      "\t Label AT_A_BAR:::-> Balanced Accuracy 0.9631967\n",
      "\t Label LOC_beach:::-> Balanced Accuracy 0.9579872\n",
      "\t Label SINGING:::-> Balanced Accuracy 0.9485426\n",
      "\t Label TALKING:::-> Balanced Accuracy 0.7110574\n",
      "\t Label COMPUTER_WORK:::-> Balanced Accuracy 0.7618859\n",
      "\t Label EATING:::-> Balanced Accuracy 0.6920099\n",
      "\t Label TOILET:::-> Balanced Accuracy 0.7556759\n",
      "\t Label GROOMING:::-> Balanced Accuracy 0.7436105\n",
      "\t Label DRESSING:::-> Balanced Accuracy 0.801751\n",
      "\t Label AT_THE_GYM:::-> Balanced Accuracy 0.9081364\n",
      "\t Label STAIRS_-_GOING_UP:::-> Balanced Accuracy 0.9255062\n",
      "\t Label STAIRS_-_GOING_DOWN:::-> Balanced Accuracy 0.9321021\n",
      "\t Label ELEVATOR:::-> Balanced Accuracy 0.9186117\n",
      "\t Label OR_standing:::-> Balanced Accuracy 0.6855062\n",
      "\t Label AT_SCHOOL:::-> Balanced Accuracy 0.7764993\n",
      "\t Label PHONE_IN_HAND:::-> Balanced Accuracy 0.7392335\n",
      "\t Label PHONE_IN_BAG:::-> Balanced Accuracy 0.8071417\n",
      "\t Label PHONE_ON_TABLE:::-> Balanced Accuracy 0.6880415\n",
      "\t Label WITH_CO-WORKERS:::-> Balanced Accuracy 0.8583442\n",
      "\t Label WITH_FRIENDS:::-> Balanced Accuracy 0.7409505\n",
      "********************\n",
      "For fold 0\n",
      "\t Label LYING_DOWN:::-> Balanced Accuracy 0.6338062\n",
      "\t Label SITTING:::-> Balanced Accuracy 0.5514668\n",
      "\t Label FIX_walking:::-> Balanced Accuracy 0.5733553\n",
      "\t Label FIX_running:::-> Balanced Accuracy 0.3869733\n",
      "\t Label BICYCLING:::-> Balanced Accuracy 0.4442666\n",
      "\t Label SLEEPING:::-> Balanced Accuracy 0.5042473\n",
      "\t Label LAB_WORK:::-> Balanced Accuracy 0.5047773\n",
      "\t Label IN_CLASS:::-> Balanced Accuracy 0.512423\n",
      "\t Label IN_A_MEETING:::-> Balanced Accuracy 0.4205182\n",
      "\t Label LOC_main_workplace:::-> Balanced Accuracy 0.4754209\n",
      "\t Label OR_indoors:::-> Balanced Accuracy 0.5391155\n",
      "\t Label OR_outside:::-> Balanced Accuracy 0.5149707\n",
      "\t Label IN_A_CAR:::-> Balanced Accuracy 0.5099386\n",
      "\t Label ON_A_BUS:::-> Balanced Accuracy 0.4860613\n",
      "\t Label DRIVE_-_I_M_THE_DRIVER:::-> Balanced Accuracy 0.3890629\n",
      "\t Label DRIVE_-_I_M_A_PASSENGER:::-> Balanced Accuracy 0.3837046\n",
      "\t Label LOC_home:::-> Balanced Accuracy 0.5123157\n",
      "\t Label FIX_restaurant:::-> Balanced Accuracy 0.47215\n",
      "\t Label PHONE_IN_POCKET:::-> Balanced Accuracy 0.4575653\n",
      "\t Label OR_exercise:::-> Balanced Accuracy 0.4836456\n",
      "\t Label COOKING:::-> Balanced Accuracy 0.4895641\n",
      "\t Label SHOPPING:::-> Balanced Accuracy 0.4907571\n",
      "\t Label STROLLING:::-> Balanced Accuracy 0.2670301\n",
      "\t Label DRINKING__ALCOHOL_:::-> Balanced Accuracy 0.6100558\n",
      "\t Label BATHING_-_SHOWER:::-> Balanced Accuracy 0.4778971\n",
      "\t Label CLEANING:::-> Balanced Accuracy 0.6051714\n",
      "\t Label DOING_LAUNDRY:::-> Balanced Accuracy 0.3204271\n",
      "\t Label WASHING_DISHES:::-> Balanced Accuracy 0.5464215\n",
      "\t Label WATCHING_TV:::-> Balanced Accuracy 0.5229872\n",
      "\t Label SURFING_THE_INTERNET:::-> Balanced Accuracy 0.503302\n",
      "\t Label AT_A_PARTY:::-> Balanced Accuracy 0.6305551\n",
      "\t Label AT_A_BAR:::-> Balanced Accuracy 0.9701041\n",
      "\t Label LOC_beach:::-> Balanced Accuracy 0.6513288\n",
      "\t Label SINGING:::-> Balanced Accuracy 0.4843543\n",
      "\t Label TALKING:::-> Balanced Accuracy 0.532142\n",
      "\t Label COMPUTER_WORK:::-> Balanced Accuracy 0.5518248\n",
      "\t Label EATING:::-> Balanced Accuracy 0.4997826\n",
      "\t Label TOILET:::-> Balanced Accuracy 0.5226784\n",
      "\t Label GROOMING:::-> Balanced Accuracy 0.6020868\n",
      "\t Label DRESSING:::-> Balanced Accuracy 0.520393\n",
      "\t Label AT_THE_GYM:::-> Balanced Accuracy 0.3820641\n",
      "\t Label STAIRS_-_GOING_UP:::-> Balanced Accuracy 0.6041471\n",
      "\t Label STAIRS_-_GOING_DOWN:::-> Balanced Accuracy 0.6155727\n",
      "\t Label ELEVATOR:::-> Balanced Accuracy 0.9817397\n",
      "\t Label OR_standing:::-> Balanced Accuracy 0.4898709\n",
      "\t Label AT_SCHOOL:::-> Balanced Accuracy 0.5791023\n",
      "\t Label PHONE_IN_HAND:::-> Balanced Accuracy 0.5291437\n",
      "\t Label PHONE_IN_BAG:::-> Balanced Accuracy 0.4856938\n",
      "\t Label PHONE_ON_TABLE:::-> Balanced Accuracy 0.4742845\n",
      "\t Label WITH_CO-WORKERS:::-> Balanced Accuracy 0.5824852\n",
      "\t Label WITH_FRIENDS:::-> Balanced Accuracy 0.5424763\n",
      "********************\n",
      "For fold 0\n",
      "\t Label LYING_DOWN:::-> Balanced Accuracy 0.8469436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Label SITTING:::-> Balanced Accuracy 0.7395759\n",
      "\t Label FIX_walking:::-> Balanced Accuracy 0.793695\n",
      "\t Label FIX_running:::-> Balanced Accuracy 0.9179074\n",
      "\t Label BICYCLING:::-> Balanced Accuracy 0.8874898\n",
      "\t Label SLEEPING:::-> Balanced Accuracy 0.8642421\n",
      "\t Label LAB_WORK:::-> Balanced Accuracy 0.9109001\n",
      "\t Label IN_CLASS:::-> Balanced Accuracy 0.8818119\n",
      "\t Label IN_A_MEETING:::-> Balanced Accuracy 0.8717169\n",
      "\t Label LOC_main_workplace:::-> Balanced Accuracy 0.8364515\n",
      "\t Label OR_indoors:::-> Balanced Accuracy 0.6969502\n",
      "\t Label OR_outside:::-> Balanced Accuracy 0.8218405\n",
      "\t Label IN_A_CAR:::-> Balanced Accuracy 0.8650538\n",
      "\t Label ON_A_BUS:::-> Balanced Accuracy 0.8726865\n",
      "\t Label DRIVE_-_I_M_THE_DRIVER:::-> Balanced Accuracy 0.8689922\n",
      "\t Label DRIVE_-_I_M_A_PASSENGER:::-> Balanced Accuracy 0.9094766\n",
      "\t Label LOC_home:::-> Balanced Accuracy 0.7517142\n",
      "\t Label FIX_restaurant:::-> Balanced Accuracy 0.893276\n",
      "\t Label PHONE_IN_POCKET:::-> Balanced Accuracy 0.7987878\n",
      "\t Label OR_exercise:::-> Balanced Accuracy 0.8355256\n",
      "\t Label COOKING:::-> Balanced Accuracy 0.8068537\n",
      "\t Label SHOPPING:::-> Balanced Accuracy 0.8741651\n",
      "\t Label STROLLING:::-> Balanced Accuracy 0.9163774\n",
      "\t Label DRINKING__ALCOHOL_:::-> Balanced Accuracy 0.9172179\n",
      "\t Label BATHING_-_SHOWER:::-> Balanced Accuracy 0.7879911\n",
      "\t Label CLEANING:::-> Balanced Accuracy 0.7727289\n",
      "\t Label DOING_LAUNDRY:::-> Balanced Accuracy 0.9017307\n",
      "\t Label WASHING_DISHES:::-> Balanced Accuracy 0.8150544\n",
      "\t Label WATCHING_TV:::-> Balanced Accuracy 0.7734697\n",
      "\t Label SURFING_THE_INTERNET:::-> Balanced Accuracy 0.7321027\n",
      "\t Label AT_A_PARTY:::-> Balanced Accuracy 0.947705\n",
      "\t Label AT_A_BAR:::-> Balanced Accuracy 0.9631967\n",
      "\t Label LOC_beach:::-> Balanced Accuracy 0.9579872\n",
      "\t Label SINGING:::-> Balanced Accuracy 0.9485426\n",
      "\t Label TALKING:::-> Balanced Accuracy 0.7110574\n",
      "\t Label COMPUTER_WORK:::-> Balanced Accuracy 0.7618859\n",
      "\t Label EATING:::-> Balanced Accuracy 0.6920099\n",
      "\t Label TOILET:::-> Balanced Accuracy 0.7556759\n",
      "\t Label GROOMING:::-> Balanced Accuracy 0.7436105\n",
      "\t Label DRESSING:::-> Balanced Accuracy 0.801751\n",
      "\t Label AT_THE_GYM:::-> Balanced Accuracy 0.9081364\n",
      "\t Label STAIRS_-_GOING_UP:::-> Balanced Accuracy 0.9255062\n",
      "\t Label STAIRS_-_GOING_DOWN:::-> Balanced Accuracy 0.9321021\n",
      "\t Label ELEVATOR:::-> Balanced Accuracy 0.9186117\n",
      "\t Label OR_standing:::-> Balanced Accuracy 0.6855062\n",
      "\t Label AT_SCHOOL:::-> Balanced Accuracy 0.7764993\n",
      "\t Label PHONE_IN_HAND:::-> Balanced Accuracy 0.7392335\n",
      "\t Label PHONE_IN_BAG:::-> Balanced Accuracy 0.8071417\n",
      "\t Label PHONE_ON_TABLE:::-> Balanced Accuracy 0.6880415\n",
      "\t Label WITH_CO-WORKERS:::-> Balanced Accuracy 0.8583442\n",
      "\t Label WITH_FRIENDS:::-> Balanced Accuracy 0.7409505\n",
      "********************\n",
      "For fold 0\n",
      "\t Label LYING_DOWN:::-> Balanced Accuracy 0.6338062\n",
      "\t Label SITTING:::-> Balanced Accuracy 0.5514668\n",
      "\t Label FIX_walking:::-> Balanced Accuracy 0.5733553\n",
      "\t Label FIX_running:::-> Balanced Accuracy 0.3869733\n",
      "\t Label BICYCLING:::-> Balanced Accuracy 0.4442666\n",
      "\t Label SLEEPING:::-> Balanced Accuracy 0.5042473\n",
      "\t Label LAB_WORK:::-> Balanced Accuracy 0.5047773\n",
      "\t Label IN_CLASS:::-> Balanced Accuracy 0.512423\n",
      "\t Label IN_A_MEETING:::-> Balanced Accuracy 0.4205182\n",
      "\t Label LOC_main_workplace:::-> Balanced Accuracy 0.4754209\n",
      "\t Label OR_indoors:::-> Balanced Accuracy 0.5391155\n",
      "\t Label OR_outside:::-> Balanced Accuracy 0.5149707\n",
      "\t Label IN_A_CAR:::-> Balanced Accuracy 0.5099386\n",
      "\t Label ON_A_BUS:::-> Balanced Accuracy 0.4860613\n",
      "\t Label DRIVE_-_I_M_THE_DRIVER:::-> Balanced Accuracy 0.3890629\n",
      "\t Label DRIVE_-_I_M_A_PASSENGER:::-> Balanced Accuracy 0.3837046\n",
      "\t Label LOC_home:::-> Balanced Accuracy 0.5123157\n",
      "\t Label FIX_restaurant:::-> Balanced Accuracy 0.47215\n",
      "\t Label PHONE_IN_POCKET:::-> Balanced Accuracy 0.4575653\n",
      "\t Label OR_exercise:::-> Balanced Accuracy 0.4836456\n",
      "\t Label COOKING:::-> Balanced Accuracy 0.4895641\n",
      "\t Label SHOPPING:::-> Balanced Accuracy 0.4907571\n",
      "\t Label STROLLING:::-> Balanced Accuracy 0.2670301\n",
      "\t Label DRINKING__ALCOHOL_:::-> Balanced Accuracy 0.6100558\n",
      "\t Label BATHING_-_SHOWER:::-> Balanced Accuracy 0.4778971\n",
      "\t Label CLEANING:::-> Balanced Accuracy 0.6051714\n",
      "\t Label DOING_LAUNDRY:::-> Balanced Accuracy 0.3204271\n",
      "\t Label WASHING_DISHES:::-> Balanced Accuracy 0.5464215\n",
      "\t Label WATCHING_TV:::-> Balanced Accuracy 0.5229872\n",
      "\t Label SURFING_THE_INTERNET:::-> Balanced Accuracy 0.503302\n",
      "\t Label AT_A_PARTY:::-> Balanced Accuracy 0.6305551\n",
      "\t Label AT_A_BAR:::-> Balanced Accuracy 0.9701041\n",
      "\t Label LOC_beach:::-> Balanced Accuracy 0.6513288\n",
      "\t Label SINGING:::-> Balanced Accuracy 0.4843543\n",
      "\t Label TALKING:::-> Balanced Accuracy 0.532142\n",
      "\t Label COMPUTER_WORK:::-> Balanced Accuracy 0.5518248\n",
      "\t Label EATING:::-> Balanced Accuracy 0.4997826\n",
      "\t Label TOILET:::-> Balanced Accuracy 0.5226784\n",
      "\t Label GROOMING:::-> Balanced Accuracy 0.6020868\n",
      "\t Label DRESSING:::-> Balanced Accuracy 0.520393\n",
      "\t Label AT_THE_GYM:::-> Balanced Accuracy 0.3820641\n",
      "\t Label STAIRS_-_GOING_UP:::-> Balanced Accuracy 0.6041471\n",
      "\t Label STAIRS_-_GOING_DOWN:::-> Balanced Accuracy 0.6155727\n",
      "\t Label ELEVATOR:::-> Balanced Accuracy 0.9817397\n",
      "\t Label OR_standing:::-> Balanced Accuracy 0.4898709\n",
      "\t Label AT_SCHOOL:::-> Balanced Accuracy 0.5791023\n",
      "\t Label PHONE_IN_HAND:::-> Balanced Accuracy 0.5291437\n",
      "\t Label PHONE_IN_BAG:::-> Balanced Accuracy 0.4856938\n",
      "\t Label PHONE_ON_TABLE:::-> Balanced Accuracy 0.4742845\n",
      "\t Label WITH_CO-WORKERS:::-> Balanced Accuracy 0.5824852\n",
      "\t Label WITH_FRIENDS:::-> Balanced Accuracy 0.5424763\n",
      "Epoch 1::Minibatch 1::LR 0.1 --> Loss 0.00692722082138\n",
      "Epoch 1::Minibatch 2::LR 0.1 --> Loss 0.00418116013209\n",
      "Epoch 1::Minibatch 3::LR 0.1 --> Loss 0.00267140289148\n",
      "Epoch 1::Minibatch 4::LR 0.1 --> Loss 0.00346467852592\n",
      "Epoch 1::Minibatch 5::LR 0.1 --> Loss 0.00369850357374\n",
      "Epoch 1::Minibatch 6::LR 0.1 --> Loss 0.00183799664179\n",
      "Epoch 1::Minibatch 7::LR 0.1 --> Loss 0.00646309574445\n",
      "Epoch 1::Minibatch 8::LR 0.1 --> Loss 0.00584260423978\n",
      "Epoch 1::Minibatch 9::LR 0.1 --> Loss 0.00430189212163\n",
      "Epoch 1::Minibatch 10::LR 0.1 --> Loss 0.00218664566676\n",
      "Epoch 1::Minibatch 11::LR 0.1 --> Loss 0.00199725190798\n",
      "Epoch 1::Minibatch 12::LR 0.1 --> Loss 0.00320730090141\n",
      "Epoch 1::Minibatch 13::LR 0.1 --> Loss 0.00432309587797\n",
      "Epoch 1::Minibatch 14::LR 0.1 --> Loss 0.00451593319575\n",
      "Epoch 1::Minibatch 15::LR 0.1 --> Loss 0.00327344755332\n",
      "Epoch 1::Minibatch 16::LR 0.1 --> Loss 0.000527021884918\n",
      "Epoch 1::Minibatch 17::LR 0.1 --> Loss 0.00308825135231\n",
      "Epoch 1::Minibatch 18::LR 0.1 --> Loss 0.00219038923581\n",
      "Epoch 1::Minibatch 19::LR 0.1 --> Loss 0.0010078766942\n",
      "Epoch 1::Minibatch 20::LR 0.1 --> Loss 0.00168976326783\n",
      "Epoch 1::Minibatch 21::LR 0.1 --> Loss 0.00306125680606\n",
      "Epoch 1::Minibatch 22::LR 0.1 --> Loss 0.00229002296925\n",
      "Epoch 1::Minibatch 23::LR 0.1 --> Loss 0.000680590718985\n",
      "Epoch 1::Minibatch 24::LR 0.1 --> Loss 0.000370355919003\n",
      "Epoch 1::Minibatch 25::LR 0.1 --> Loss 0.00106331090132\n",
      "Epoch 1::Minibatch 26::LR 0.1 --> Loss 0.00119043767452\n",
      "Epoch 1::Minibatch 27::LR 0.1 --> Loss 0.000833829939365\n",
      "Epoch 1::Minibatch 28::LR 0.1 --> Loss 0.000345144247015\n",
      "Epoch 1::Minibatch 29::LR 0.1 --> Loss 0.000319410661856\n",
      "Epoch 1::Minibatch 30::LR 0.1 --> Loss 0.00072717110316\n",
      "Epoch 1::Minibatch 31::LR 0.1 --> Loss 0.00112766434749\n",
      "Epoch 1::Minibatch 32::LR 0.1 --> Loss 0.00110242555539\n",
      "Epoch 1::Minibatch 33::LR 0.1 --> Loss 0.000721954703331\n",
      "Epoch 1::Minibatch 34::LR 0.1 --> Loss 0.0022775298357\n",
      "Epoch 1::Minibatch 35::LR 0.1 --> Loss 0.00362366557121\n",
      "Epoch 1::Minibatch 36::LR 0.1 --> Loss 0.00209478815397\n",
      "Epoch 1::Minibatch 37::LR 0.1 --> Loss 0.000785388549169\n",
      "Epoch 1::Minibatch 38::LR 0.1 --> Loss 0.000843347410361\n",
      "Epoch 1::Minibatch 39::LR 0.1 --> Loss 0.0029345001777\n",
      "Epoch 1::Minibatch 40::LR 0.1 --> Loss 0.00580030441284\n",
      "Epoch 1::Minibatch 41::LR 0.1 --> Loss 0.00350151340167\n",
      "Epoch 1::Minibatch 42::LR 0.1 --> Loss 0.00611610412598\n",
      "Epoch 1::Minibatch 43::LR 0.1 --> Loss 0.00221806506316\n",
      "Epoch 1::Minibatch 44::LR 0.1 --> Loss 0.00340902884801\n",
      "Epoch 1::Minibatch 45::LR 0.1 --> Loss 0.0030133364598\n",
      "Epoch 1::Minibatch 46::LR 0.1 --> Loss 0.003667456309\n",
      "Epoch 1::Minibatch 47::LR 0.1 --> Loss 0.0054819782575\n",
      "Epoch 1::Minibatch 48::LR 0.1 --> Loss 0.00519614140193\n",
      "Epoch 1::Minibatch 49::LR 0.1 --> Loss 0.00552242358526\n",
      "Epoch 1::Minibatch 50::LR 0.1 --> Loss 0.00575272917747\n",
      "Epoch 1::Minibatch 51::LR 0.1 --> Loss 0.00897140185038\n",
      "Epoch 1::Minibatch 52::LR 0.1 --> Loss 0.00277002751827\n",
      "Epoch 1::Minibatch 53::LR 0.1 --> Loss 0.00461288730303\n",
      "Epoch 1::Minibatch 54::LR 0.1 --> Loss 0.00401101549466\n",
      "Epoch 1::Minibatch 55::LR 0.1 --> Loss 0.00105031738679\n",
      "Epoch 1::Minibatch 56::LR 0.1 --> Loss 0.00253448486328\n",
      "Epoch 1::Minibatch 57::LR 0.1 --> Loss 0.00539436737696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 58::LR 0.1 --> Loss 0.00291779438655\n",
      "Epoch 1::Minibatch 59::LR 0.1 --> Loss 0.00253943244616\n",
      "Epoch 1::Minibatch 60::LR 0.1 --> Loss 0.00228055973848\n",
      "Epoch 1::Minibatch 61::LR 0.1 --> Loss 0.00111147930225\n",
      "Epoch 1::Minibatch 62::LR 0.1 --> Loss 0.00395963788033\n",
      "Epoch 1::Minibatch 63::LR 0.1 --> Loss 0.00237552583218\n",
      "Epoch 1::Minibatch 64::LR 0.1 --> Loss 0.00109395394723\n",
      "Epoch 1::Minibatch 65::LR 0.1 --> Loss 0.00254916012287\n",
      "Epoch 1::Minibatch 66::LR 0.1 --> Loss 0.00305319488049\n",
      "Epoch 1::Minibatch 67::LR 0.1 --> Loss 0.00290908833345\n",
      "Epoch 1::Minibatch 68::LR 0.1 --> Loss 0.00219712734222\n",
      "Epoch 1::Minibatch 69::LR 0.1 --> Loss 0.00434122165044\n",
      "Epoch 1::Minibatch 70::LR 0.1 --> Loss 0.00337579846382\n",
      "Epoch 1::Minibatch 71::LR 0.1 --> Loss 0.00206661542257\n",
      "Epoch 1::Minibatch 72::LR 0.1 --> Loss 0.000569719225168\n",
      "Epoch 1::Minibatch 73::LR 0.1 --> Loss 0.003634121418\n",
      "Epoch 1::Minibatch 74::LR 0.1 --> Loss 0.00431727250417\n",
      "Epoch 1::Minibatch 75::LR 0.1 --> Loss 0.00450598239899\n",
      "Epoch 1::Minibatch 76::LR 0.1 --> Loss 0.000637241055568\n",
      "Epoch 1::Minibatch 77::LR 0.1 --> Loss 0.00258406956991\n",
      "Epoch 1::Minibatch 78::LR 0.1 --> Loss 0.00390561898549\n",
      "Epoch 1::Minibatch 79::LR 0.1 --> Loss 0.00221658905347\n",
      "Epoch 1::Minibatch 80::LR 0.1 --> Loss 0.00353000481923\n",
      "Epoch 1::Minibatch 81::LR 0.1 --> Loss 0.00316483557224\n",
      "Epoch 1::Minibatch 82::LR 0.1 --> Loss 0.00202750504017\n",
      "Epoch 1::Minibatch 83::LR 0.1 --> Loss 0.00568451404572\n",
      "Epoch 1::Minibatch 84::LR 0.1 --> Loss 0.00200361470381\n",
      "Epoch 1::Minibatch 85::LR 0.1 --> Loss 0.00279179930687\n",
      "Epoch 1::Minibatch 86::LR 0.1 --> Loss 0.00240339616934\n",
      "Epoch 1::Minibatch 87::LR 0.1 --> Loss 0.00254104952017\n",
      "Epoch 1::Minibatch 88::LR 0.1 --> Loss 0.00177998105685\n",
      "Epoch 1::Minibatch 89::LR 0.1 --> Loss 0.00228382786115\n",
      "Epoch 1::Minibatch 90::LR 0.1 --> Loss 0.00107341706753\n",
      "Epoch 1::Minibatch 91::LR 0.1 --> Loss 0.000845156212648\n",
      "Epoch 1::Minibatch 92::LR 0.1 --> Loss 0.00256233493487\n",
      "Epoch 1::Minibatch 93::LR 0.1 --> Loss 0.00170580645402\n",
      "Epoch 1::Minibatch 94::LR 0.1 --> Loss 0.00169041295846\n",
      "Epoch 1::Minibatch 95::LR 0.1 --> Loss 0.00166811148326\n",
      "Epoch 1::Minibatch 96::LR 0.1 --> Loss 0.00604734142621\n",
      "Epoch 1::Minibatch 97::LR 0.1 --> Loss 0.00234851956367\n",
      "Epoch 1::Minibatch 98::LR 0.1 --> Loss 0.0008838575085\n",
      "Epoch 1::Minibatch 99::LR 0.1 --> Loss 0.00127444843451\n",
      "Epoch 1::Minibatch 100::LR 0.1 --> Loss 0.00562246600787\n",
      "Epoch 1::Minibatch 101::LR 0.1 --> Loss 0.00113443732262\n",
      "Epoch 1::Minibatch 102::LR 0.1 --> Loss 0.00371478358905\n",
      "Epoch 1::Minibatch 103::LR 0.1 --> Loss 0.0038145049413\n",
      "Epoch 1::Minibatch 104::LR 0.1 --> Loss 0.0030680835247\n",
      "Epoch 1::Minibatch 105::LR 0.1 --> Loss 0.00278669297695\n",
      "Epoch 1::Minibatch 106::LR 0.1 --> Loss 0.0162579584122\n",
      "Epoch 1::Minibatch 107::LR 0.1 --> Loss 0.00459327061971\n",
      "Epoch 1::Minibatch 108::LR 0.1 --> Loss 0.00157503992319\n",
      "Epoch 1::Minibatch 109::LR 0.1 --> Loss 0.00468027671178\n",
      "Epoch 1::Minibatch 110::LR 0.1 --> Loss 0.00287676990032\n",
      "Epoch 1::Minibatch 111::LR 0.1 --> Loss 0.00136439462503\n",
      "Epoch 1::Minibatch 112::LR 0.1 --> Loss 0.00409506320953\n",
      "Epoch 1::Minibatch 113::LR 0.1 --> Loss 0.00300066014131\n",
      "Epoch 1::Minibatch 114::LR 0.1 --> Loss 0.00173697928588\n",
      "Epoch 1::Minibatch 115::LR 0.1 --> Loss 0.00169656674067\n",
      "Epoch 1::Minibatch 116::LR 0.1 --> Loss 0.00317673524221\n",
      "Epoch 1::Minibatch 117::LR 0.1 --> Loss 0.00337461352348\n",
      "Epoch 1::Minibatch 118::LR 0.1 --> Loss 0.00624942104022\n",
      "Epoch 1::Minibatch 119::LR 0.1 --> Loss 0.000871002276738\n",
      "Epoch 1::Minibatch 120::LR 0.1 --> Loss 0.00204564074675\n",
      "Epoch 1::Minibatch 121::LR 0.1 --> Loss 0.00291235188643\n",
      "Epoch 1::Minibatch 122::LR 0.1 --> Loss 0.00379353761673\n",
      "Epoch 1::Minibatch 123::LR 0.1 --> Loss 0.00146737992764\n",
      "Epoch 1::Minibatch 124::LR 0.1 --> Loss 0.00303738673528\n",
      "Epoch 1::Minibatch 125::LR 0.1 --> Loss 0.00478697299957\n",
      "Epoch 1::Minibatch 126::LR 0.1 --> Loss 0.00299601574739\n",
      "Epoch 1::Minibatch 127::LR 0.1 --> Loss 0.00394474903742\n",
      "Epoch 1::Minibatch 128::LR 0.1 --> Loss 0.00376751303673\n",
      "Epoch 1::Minibatch 129::LR 0.1 --> Loss 0.00302025953929\n",
      "Epoch 1::Minibatch 130::LR 0.1 --> Loss 0.00449550668399\n",
      "Epoch 1::Minibatch 131::LR 0.1 --> Loss 0.00184929688772\n",
      "Epoch 1::Minibatch 132::LR 0.1 --> Loss 0.00322896560033\n",
      "Epoch 1::Minibatch 133::LR 0.1 --> Loss 0.0030379952987\n",
      "Epoch 1::Minibatch 134::LR 0.1 --> Loss 0.00252668976784\n",
      "Epoch 1::Minibatch 135::LR 0.1 --> Loss 0.00176201820374\n",
      "Epoch 1::Minibatch 136::LR 0.1 --> Loss 0.00288367132346\n",
      "Epoch 1::Minibatch 137::LR 0.1 --> Loss 0.0036960264047\n",
      "Epoch 1::Minibatch 138::LR 0.1 --> Loss 0.00132073223591\n",
      "Epoch 1::Minibatch 139::LR 0.1 --> Loss 0.00193784534931\n",
      "Epoch 1::Minibatch 140::LR 0.1 --> Loss 0.00248353997866\n",
      "Epoch 1::Minibatch 141::LR 0.1 --> Loss 0.00264887372653\n",
      "Epoch 1::Minibatch 142::LR 0.1 --> Loss 0.00286130388578\n",
      "Epoch 1::Minibatch 143::LR 0.1 --> Loss 0.000584293256203\n",
      "Epoch 1::Minibatch 144::LR 0.1 --> Loss 0.0032684447368\n",
      "Epoch 1::Minibatch 145::LR 0.1 --> Loss 0.00449165940285\n",
      "Epoch 1::Minibatch 146::LR 0.1 --> Loss 0.00257576008638\n",
      "Epoch 1::Minibatch 147::LR 0.1 --> Loss 0.00185307959716\n",
      "Epoch 1::Minibatch 148::LR 0.1 --> Loss 0.000975433488687\n",
      "Epoch 1::Minibatch 149::LR 0.1 --> Loss 0.00283489386241\n",
      "Epoch 1::Minibatch 150::LR 0.1 --> Loss 0.00264285326004\n",
      "Epoch 1::Minibatch 151::LR 0.1 --> Loss 0.00396340370178\n",
      "Epoch 1::Minibatch 152::LR 0.1 --> Loss 0.000854660073916\n",
      "Epoch 1::Minibatch 153::LR 0.1 --> Loss 0.00193521201611\n",
      "Epoch 1::Minibatch 154::LR 0.1 --> Loss 0.00203414539496\n",
      "Epoch 1::Minibatch 155::LR 0.1 --> Loss 0.00568165421486\n",
      "Epoch 1::Minibatch 156::LR 0.1 --> Loss 0.00218217770259\n",
      "Epoch 1::Minibatch 157::LR 0.1 --> Loss 0.000622200121482\n",
      "Epoch 1::Minibatch 158::LR 0.1 --> Loss 0.00294229865074\n",
      "Epoch 1::Minibatch 159::LR 0.1 --> Loss 0.00273248255253\n",
      "Epoch 1::Minibatch 160::LR 0.1 --> Loss 0.00261225541433\n",
      "Epoch 1::Minibatch 161::LR 0.1 --> Loss 0.000998551646868\n",
      "Epoch 1::Minibatch 162::LR 0.1 --> Loss 0.00340109308561\n",
      "Epoch 1::Minibatch 163::LR 0.1 --> Loss 0.00233623643716\n",
      "Epoch 1::Minibatch 164::LR 0.1 --> Loss 0.00242916067441\n",
      "Epoch 1::Minibatch 165::LR 0.1 --> Loss 0.000511900583903\n",
      "Epoch 1::Minibatch 166::LR 0.1 --> Loss 0.00176188369592\n",
      "Epoch 1::Minibatch 167::LR 0.1 --> Loss 0.00239290157954\n",
      "Epoch 1::Minibatch 168::LR 0.1 --> Loss 0.00209891001383\n",
      "Epoch 1::Minibatch 169::LR 0.1 --> Loss 0.000964608192444\n",
      "Epoch 1::Minibatch 170::LR 0.1 --> Loss 0.000947188238303\n",
      "Epoch 1::Minibatch 171::LR 0.1 --> Loss 0.00241529107094\n",
      "Epoch 1::Minibatch 172::LR 0.1 --> Loss 0.00403192917506\n",
      "Epoch 1::Minibatch 173::LR 0.1 --> Loss 0.00189529796441\n",
      "Epoch 1::Minibatch 174::LR 0.1 --> Loss 0.00100151171287\n",
      "Epoch 1::Minibatch 175::LR 0.1 --> Loss 0.0021480913957\n",
      "Epoch 1::Minibatch 176::LR 0.1 --> Loss 0.00342621922493\n",
      "Epoch 1::Minibatch 177::LR 0.1 --> Loss 0.00514592369397\n",
      "Epoch 1::Minibatch 178::LR 0.1 --> Loss 0.00163115739822\n",
      "Epoch 1::Minibatch 179::LR 0.1 --> Loss 0.00136881649494\n",
      "Epoch 1::Minibatch 180::LR 0.1 --> Loss 0.00405711134275\n",
      "Epoch 1::Minibatch 181::LR 0.1 --> Loss 0.00344017823537\n",
      "Epoch 1::Minibatch 182::LR 0.1 --> Loss 0.000771342813969\n",
      "Epoch 1::Minibatch 183::LR 0.1 --> Loss 0.00179277439912\n",
      "Epoch 1::Minibatch 184::LR 0.1 --> Loss 0.0035097638766\n",
      "Epoch 1::Minibatch 185::LR 0.1 --> Loss 0.00236139535904\n",
      "Epoch 1::Minibatch 186::LR 0.1 --> Loss 0.00100052167972\n",
      "Epoch 1::Minibatch 187::LR 0.1 --> Loss 0.00122503300508\n",
      "Epoch 1::Minibatch 188::LR 0.1 --> Loss 0.00373090823491\n",
      "Epoch 1::Minibatch 189::LR 0.1 --> Loss 0.00434916655223\n",
      "Epoch 1::Minibatch 190::LR 0.1 --> Loss 0.00218893229961\n",
      "Epoch 1::Minibatch 191::LR 0.1 --> Loss 0.000429403930902\n",
      "Epoch 1::Minibatch 192::LR 0.1 --> Loss 0.00260574539502\n",
      "Epoch 1::Minibatch 193::LR 0.1 --> Loss 0.00243618130684\n",
      "Epoch 1::Minibatch 194::LR 0.1 --> Loss 0.00183416148027\n",
      "Epoch 1::Minibatch 195::LR 0.1 --> Loss 0.000390773167213\n",
      "Epoch 1::Minibatch 196::LR 0.1 --> Loss 0.00107950806618\n",
      "Epoch 1::Minibatch 197::LR 0.1 --> Loss 0.00271635234356\n",
      "Epoch 1::Minibatch 198::LR 0.1 --> Loss 0.001969191432\n",
      "Epoch 1::Minibatch 199::LR 0.1 --> Loss 0.000292137960593\n",
      "Epoch 1::Minibatch 200::LR 0.1 --> Loss 0.00194727083047\n",
      "Epoch 1::Minibatch 201::LR 0.1 --> Loss 0.00191576838493\n",
      "Epoch 1::Minibatch 202::LR 0.1 --> Loss 0.00182728767395\n",
      "Epoch 1::Minibatch 203::LR 0.1 --> Loss 0.00177125791709\n",
      "Epoch 1::Minibatch 204::LR 0.1 --> Loss 0.00139985481898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 205::LR 0.1 --> Loss 0.00211009283861\n",
      "Epoch 1::Minibatch 206::LR 0.1 --> Loss 0.0056070236365\n",
      "Epoch 1::Minibatch 207::LR 0.1 --> Loss 0.0013556137681\n",
      "Epoch 1::Minibatch 208::LR 0.1 --> Loss 0.00108776887258\n",
      "Epoch 1::Minibatch 209::LR 0.1 --> Loss 0.0018528475364\n",
      "Epoch 1::Minibatch 210::LR 0.1 --> Loss 0.0017203472058\n",
      "Epoch 1::Minibatch 211::LR 0.1 --> Loss 0.00190030833085\n",
      "Epoch 1::Minibatch 212::LR 0.1 --> Loss 0.00457987984022\n",
      "Epoch 1::Minibatch 213::LR 0.1 --> Loss 0.00695876439412\n",
      "Epoch 1::Minibatch 214::LR 0.1 --> Loss 0.00991988341014\n",
      "Epoch 1::Minibatch 215::LR 0.1 --> Loss 0.0012663675348\n",
      "Epoch 1::Minibatch 216::LR 0.1 --> Loss 0.00516617496808\n",
      "Epoch 1::Minibatch 217::LR 0.1 --> Loss 0.0058422601223\n",
      "Epoch 1::Minibatch 218::LR 0.1 --> Loss 0.00391224662463\n",
      "Epoch 1::Minibatch 219::LR 0.1 --> Loss 0.00329759418964\n",
      "Epoch 1::Minibatch 220::LR 0.1 --> Loss 0.00469345092773\n",
      "Epoch 1::Minibatch 221::LR 0.1 --> Loss 0.00410779635111\n",
      "Epoch 1::Minibatch 222::LR 0.1 --> Loss 0.00325431982676\n",
      "Epoch 1::Minibatch 223::LR 0.1 --> Loss 0.00123781283696\n",
      "Epoch 1::Minibatch 224::LR 0.1 --> Loss 0.00168317397436\n",
      "Epoch 1::Minibatch 225::LR 0.1 --> Loss 0.00675882180532\n",
      "Epoch 1::Minibatch 226::LR 0.1 --> Loss 0.00371051907539\n",
      "Epoch 1::Minibatch 227::LR 0.1 --> Loss 0.00168562054634\n",
      "Epoch 1::Minibatch 228::LR 0.1 --> Loss 0.000741874029239\n",
      "Epoch 1::Minibatch 229::LR 0.1 --> Loss 0.00480824271838\n",
      "Epoch 1::Minibatch 230::LR 0.1 --> Loss 0.00410647908847\n",
      "Epoch 1::Minibatch 231::LR 0.1 --> Loss 0.00252149323622\n",
      "Epoch 1::Minibatch 232::LR 0.1 --> Loss 0.00116436233123\n",
      "Epoch 1::Minibatch 233::LR 0.1 --> Loss 0.00227657993635\n",
      "Epoch 1::Minibatch 234::LR 0.1 --> Loss 0.00640267173449\n",
      "Epoch 1::Minibatch 235::LR 0.1 --> Loss 0.0045243593057\n",
      "Epoch 1::Minibatch 236::LR 0.1 --> Loss 0.00175602912903\n",
      "Epoch 1::Minibatch 237::LR 0.1 --> Loss 0.000688471396764\n",
      "Epoch 1::Minibatch 238::LR 0.1 --> Loss 0.00324276804924\n",
      "Epoch 1::Minibatch 239::LR 0.1 --> Loss 0.00286833584309\n",
      "Epoch 1::Minibatch 240::LR 0.1 --> Loss 0.00313902278741\n",
      "Epoch 1::Minibatch 241::LR 0.1 --> Loss 0.000739512940248\n",
      "Epoch 1::Minibatch 242::LR 0.1 --> Loss 0.0076824148496\n",
      "Epoch 1::Minibatch 243::LR 0.1 --> Loss 0.00361030260722\n",
      "Epoch 1::Minibatch 244::LR 0.1 --> Loss 0.00304170668125\n",
      "Epoch 1::Minibatch 245::LR 0.1 --> Loss 0.000502935796976\n",
      "Epoch 1::Minibatch 246::LR 0.1 --> Loss 0.00206917365392\n",
      "Epoch 1::Minibatch 247::LR 0.1 --> Loss 0.0191105397542\n",
      "Epoch 1::Minibatch 248::LR 0.1 --> Loss 0.00507625341415\n",
      "Epoch 1::Minibatch 249::LR 0.1 --> Loss 0.00333744366964\n",
      "Epoch 1::Minibatch 250::LR 0.1 --> Loss 0.00287392218908\n",
      "Epoch 1::Minibatch 251::LR 0.1 --> Loss 0.00254290958246\n",
      "Epoch 1::Minibatch 252::LR 0.1 --> Loss 0.00211363554001\n",
      "Epoch 1::Minibatch 253::LR 0.1 --> Loss 0.00344115932782\n",
      "Epoch 1::Minibatch 254::LR 0.1 --> Loss 0.00559284130732\n",
      "Epoch 1::Minibatch 255::LR 0.1 --> Loss 0.00411328117053\n",
      "Epoch 1::Minibatch 256::LR 0.1 --> Loss 0.00207060257594\n",
      "Epoch 1::Minibatch 257::LR 0.1 --> Loss 0.00145985633135\n",
      "Epoch 1::Minibatch 258::LR 0.1 --> Loss 0.00375658988953\n",
      "Epoch 1::Minibatch 259::LR 0.1 --> Loss 0.0019354514281\n",
      "Epoch 1::Minibatch 260::LR 0.1 --> Loss 0.00199848532677\n",
      "Epoch 1::Minibatch 261::LR 0.1 --> Loss 0.00321245809396\n",
      "Epoch 1::Minibatch 262::LR 0.1 --> Loss 0.00215376198292\n",
      "Epoch 1::Minibatch 263::LR 0.1 --> Loss 0.00238285720348\n",
      "Epoch 1::Minibatch 264::LR 0.1 --> Loss 0.00387460033099\n",
      "Epoch 1::Minibatch 265::LR 0.1 --> Loss 0.0113535269101\n",
      "Epoch 1::Minibatch 266::LR 0.1 --> Loss 0.00116784294446\n",
      "Epoch 1::Minibatch 267::LR 0.1 --> Loss 0.00978877305984\n",
      "Epoch 1::Minibatch 268::LR 0.1 --> Loss 0.00140769739946\n",
      "Epoch 1::Minibatch 269::LR 0.1 --> Loss 0.00398898442586\n",
      "Epoch 1::Minibatch 270::LR 0.1 --> Loss 0.00575230201085\n",
      "Epoch 1::Minibatch 271::LR 0.1 --> Loss 0.00322586715221\n",
      "Epoch 1::Minibatch 272::LR 0.1 --> Loss 0.00403897643089\n",
      "Epoch 1::Minibatch 273::LR 0.1 --> Loss 0.00194389243921\n",
      "Epoch 1::Minibatch 274::LR 0.1 --> Loss 0.00186430573463\n",
      "Epoch 1::Minibatch 275::LR 0.1 --> Loss 0.00301586429278\n",
      "Epoch 1::Minibatch 276::LR 0.1 --> Loss 0.00352036476135\n",
      "Epoch 1::Minibatch 277::LR 0.1 --> Loss 0.00107037752867\n",
      "Epoch 1::Minibatch 278::LR 0.1 --> Loss 0.00280863483747\n",
      "Epoch 1::Minibatch 279::LR 0.1 --> Loss 0.00275074919065\n",
      "Epoch 1::Minibatch 280::LR 0.1 --> Loss 0.00224494198958\n",
      "Epoch 1::Minibatch 281::LR 0.1 --> Loss 0.00134575694799\n",
      "Epoch 1::Minibatch 282::LR 0.1 --> Loss 0.00243813653787\n",
      "Epoch 1::Minibatch 283::LR 0.1 --> Loss 0.00242772181829\n",
      "Epoch 1::Minibatch 284::LR 0.1 --> Loss 0.00177011986574\n",
      "Epoch 1::Minibatch 285::LR 0.1 --> Loss 0.00117554257313\n",
      "Epoch 1::Minibatch 286::LR 0.1 --> Loss 0.00228867411613\n",
      "Epoch 1::Minibatch 287::LR 0.1 --> Loss 0.0021213744084\n",
      "Epoch 1::Minibatch 288::LR 0.1 --> Loss 0.00102539320787\n",
      "Epoch 1::Minibatch 289::LR 0.1 --> Loss 0.0015364976724\n",
      "Epoch 1::Minibatch 290::LR 0.1 --> Loss 0.00201277434826\n",
      "Epoch 1::Minibatch 291::LR 0.1 --> Loss 0.00169995089372\n",
      "Epoch 1::Minibatch 292::LR 0.1 --> Loss 0.000579742342234\n",
      "Epoch 1::Minibatch 293::LR 0.1 --> Loss 0.00142564058304\n",
      "Epoch 1::Minibatch 294::LR 0.1 --> Loss 0.00156741946936\n",
      "Epoch 1::Minibatch 295::LR 0.1 --> Loss 0.00190227031708\n",
      "Epoch 1::Minibatch 296::LR 0.1 --> Loss 0.00149411102136\n",
      "Epoch 1::Minibatch 297::LR 0.1 --> Loss 0.00138759563367\n",
      "Epoch 1::Minibatch 298::LR 0.1 --> Loss 0.00127050876617\n",
      "Epoch 1::Minibatch 299::LR 0.1 --> Loss 0.000762141545614\n",
      "Epoch 1::Minibatch 300::LR 0.1 --> Loss 0.00319414893786\n",
      "Epoch 1::Minibatch 301::LR 0.1 --> Loss 0.0028280578057\n",
      "Epoch 1::Minibatch 302::LR 0.1 --> Loss 0.00250835518042\n",
      "Epoch 1::Minibatch 303::LR 0.1 --> Loss 0.000813811669747\n",
      "Epoch 1::Minibatch 304::LR 0.1 --> Loss 0.00315464456876\n",
      "Epoch 1::Minibatch 305::LR 0.1 --> Loss 0.00165791461865\n",
      "Epoch 1::Minibatch 306::LR 0.1 --> Loss 0.000892843703429\n",
      "Epoch 1::Minibatch 307::LR 0.1 --> Loss 0.00254831790924\n",
      "Epoch 1::Minibatch 308::LR 0.1 --> Loss 0.00188399354617\n",
      "Epoch 1::Minibatch 309::LR 0.1 --> Loss 0.000918004115423\n",
      "Epoch 1::Minibatch 310::LR 0.1 --> Loss 0.000975132882595\n",
      "Epoch 1::Minibatch 311::LR 0.1 --> Loss 0.0016216892004\n",
      "Epoch 1::Minibatch 312::LR 0.1 --> Loss 0.0031828246514\n",
      "Epoch 1::Minibatch 313::LR 0.1 --> Loss 0.00246701618036\n",
      "Epoch 1::Minibatch 314::LR 0.1 --> Loss 0.00191894173622\n",
      "Epoch 1::Minibatch 315::LR 0.1 --> Loss 0.000902038812637\n",
      "Epoch 1::Minibatch 316::LR 0.1 --> Loss 0.00239146749179\n",
      "Epoch 1::Minibatch 317::LR 0.1 --> Loss 0.00151602238417\n",
      "Epoch 1::Minibatch 318::LR 0.1 --> Loss 0.00110552618901\n",
      "Epoch 1::Minibatch 319::LR 0.1 --> Loss 0.00227396349112\n",
      "Epoch 1::Minibatch 320::LR 0.1 --> Loss 0.00326008697351\n",
      "Epoch 1::Minibatch 321::LR 0.1 --> Loss 0.000862718820572\n",
      "Epoch 1::Minibatch 322::LR 0.1 --> Loss 0.0036321969827\n",
      "Epoch 1::Minibatch 323::LR 0.1 --> Loss 0.00374487757683\n",
      "Epoch 1::Minibatch 324::LR 0.1 --> Loss 0.00270790080229\n",
      "Epoch 1::Minibatch 325::LR 0.1 --> Loss 0.00255721509457\n",
      "Epoch 1::Minibatch 326::LR 0.1 --> Loss 0.00793009122213\n",
      "Epoch 1::Minibatch 327::LR 0.1 --> Loss 0.00227044284344\n",
      "Epoch 1::Minibatch 328::LR 0.1 --> Loss 0.00347451686859\n",
      "Epoch 1::Minibatch 329::LR 0.1 --> Loss 0.00128643482924\n",
      "Epoch 1::Minibatch 330::LR 0.1 --> Loss 0.0016066835324\n",
      "Epoch 1::Minibatch 331::LR 0.1 --> Loss 0.00263381103675\n",
      "Epoch 1::Minibatch 332::LR 0.1 --> Loss 0.00256220718225\n",
      "Epoch 1::Minibatch 333::LR 0.1 --> Loss 0.00142606119315\n",
      "Epoch 1::Minibatch 334::LR 0.1 --> Loss 0.00415607094765\n",
      "Epoch 1::Minibatch 335::LR 0.1 --> Loss 0.00189029792945\n",
      "Epoch 1::Minibatch 336::LR 0.1 --> Loss 0.00209580600262\n",
      "Epoch 1::Minibatch 337::LR 0.1 --> Loss 0.00311818401019\n",
      "Epoch 1::Minibatch 338::LR 0.1 --> Loss 0.000480353236198\n",
      "Epoch 1::Minibatch 339::LR 0.1 --> Loss 0.00339291890462\n",
      "Epoch 1::Minibatch 340::LR 0.1 --> Loss 0.00435992042224\n",
      "Epoch 1::Minibatch 341::LR 0.1 --> Loss 0.00514023820559\n",
      "Epoch 1::Minibatch 342::LR 0.1 --> Loss 0.004163813591\n",
      "Epoch 1::Minibatch 343::LR 0.1 --> Loss 0.00171575248241\n",
      "Epoch 1::Minibatch 344::LR 0.1 --> Loss 0.00301548878352\n",
      "Epoch 1::Minibatch 345::LR 0.1 --> Loss 0.00401463190715\n",
      "Epoch 1::Minibatch 346::LR 0.1 --> Loss 0.00546534578005\n",
      "Epoch 1::Minibatch 347::LR 0.1 --> Loss 0.000900068879128\n",
      "Epoch 1::Minibatch 348::LR 0.1 --> Loss 0.00426715612411\n",
      "Epoch 1::Minibatch 349::LR 0.1 --> Loss 0.00358814557393\n",
      "Epoch 1::Minibatch 350::LR 0.1 --> Loss 0.00179596583049\n",
      "Epoch 1::Minibatch 351::LR 0.1 --> Loss 0.0038051323096\n",
      "Epoch 1::Minibatch 352::LR 0.1 --> Loss 0.00453023433685\n",
      "Epoch 1::Minibatch 353::LR 0.1 --> Loss 0.00363703012466\n",
      "Epoch 1::Minibatch 354::LR 0.1 --> Loss 0.00309557795525\n",
      "Epoch 1::Minibatch 355::LR 0.1 --> Loss 0.00580147425334\n",
      "Epoch 1::Minibatch 356::LR 0.1 --> Loss 0.00312078098456\n",
      "Epoch 1::Minibatch 357::LR 0.1 --> Loss 0.00103630026182\n",
      "Epoch 1::Minibatch 358::LR 0.1 --> Loss 0.00221451918284\n",
      "Epoch 1::Minibatch 359::LR 0.1 --> Loss 0.00289682328701\n",
      "Epoch 1::Minibatch 360::LR 0.1 --> Loss 0.00252339263757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 361::LR 0.1 --> Loss 0.00249744911989\n",
      "Epoch 1::Minibatch 362::LR 0.1 --> Loss 0.00258810142676\n",
      "Epoch 1::Minibatch 363::LR 0.1 --> Loss 0.000658049931129\n",
      "Epoch 1::Minibatch 364::LR 0.1 --> Loss 0.00200369656086\n",
      "Epoch 1::Minibatch 365::LR 0.1 --> Loss 0.00213416238626\n",
      "Epoch 1::Minibatch 366::LR 0.1 --> Loss 0.00233895202478\n",
      "Epoch 1::Minibatch 367::LR 0.1 --> Loss 0.00113066673279\n",
      "Epoch 1::Minibatch 368::LR 0.1 --> Loss 0.000951306521893\n",
      "Epoch 1::Minibatch 369::LR 0.1 --> Loss 0.00300753156344\n",
      "Epoch 1::Minibatch 370::LR 0.1 --> Loss 0.00226220349471\n",
      "Epoch 1::Minibatch 371::LR 0.1 --> Loss 0.00184882601102\n",
      "Epoch 1::Minibatch 372::LR 0.1 --> Loss 0.0004175978899\n",
      "Epoch 1::Minibatch 373::LR 0.1 --> Loss 0.00173628429572\n",
      "Epoch 1::Minibatch 374::LR 0.1 --> Loss 0.00208811382453\n",
      "Epoch 1::Minibatch 375::LR 0.1 --> Loss 0.00177366515001\n",
      "Epoch 1::Minibatch 376::LR 0.1 --> Loss 0.00122444570065\n",
      "Epoch 1::Minibatch 377::LR 0.1 --> Loss 0.00195088406404\n",
      "Epoch 1::Minibatch 378::LR 0.1 --> Loss 0.00209851185481\n",
      "Epoch 1::Minibatch 379::LR 0.1 --> Loss 0.00242593606313\n",
      "Epoch 1::Minibatch 380::LR 0.1 --> Loss 0.0016051564614\n",
      "Epoch 1::Minibatch 381::LR 0.1 --> Loss 0.000949453016122\n",
      "Epoch 1::Minibatch 382::LR 0.1 --> Loss 0.00198377112548\n",
      "Epoch 1::Minibatch 383::LR 0.1 --> Loss 0.00185429831346\n",
      "Epoch 1::Minibatch 384::LR 0.1 --> Loss 0.000999517937501\n",
      "Epoch 1::Minibatch 385::LR 0.1 --> Loss 0.000996444324652\n",
      "Epoch 1::Minibatch 386::LR 0.1 --> Loss 0.00214021543662\n",
      "Epoch 1::Minibatch 387::LR 0.1 --> Loss 0.00226887186368\n",
      "Epoch 1::Minibatch 388::LR 0.1 --> Loss 0.00110740790764\n",
      "Epoch 1::Minibatch 389::LR 0.1 --> Loss 0.00183724939823\n",
      "Epoch 1::Minibatch 390::LR 0.1 --> Loss 0.00361052791278\n",
      "Epoch 1::Minibatch 391::LR 0.1 --> Loss 0.00264856715997\n",
      "Epoch 1::Minibatch 392::LR 0.1 --> Loss 0.00261589030425\n",
      "Epoch 1::Minibatch 393::LR 0.1 --> Loss 0.00278369625409\n",
      "Epoch 1::Minibatch 394::LR 0.1 --> Loss 0.00217987895012\n",
      "Epoch 1::Minibatch 395::LR 0.1 --> Loss 0.00200836479664\n",
      "Epoch 1::Minibatch 396::LR 0.1 --> Loss 0.00192842562993\n",
      "Epoch 1::Minibatch 397::LR 0.1 --> Loss 0.0020762437582\n",
      "Epoch 1::Minibatch 398::LR 0.1 --> Loss 0.00199827333291\n",
      "Epoch 1::Minibatch 399::LR 0.1 --> Loss 0.00230909705162\n",
      "Epoch 1::Minibatch 400::LR 0.1 --> Loss 0.00196062982082\n",
      "Epoch 1::Minibatch 401::LR 0.1 --> Loss 0.00343798796336\n",
      "Epoch 1::Minibatch 402::LR 0.1 --> Loss 0.00174037893613\n",
      "Epoch 1::Minibatch 403::LR 0.1 --> Loss 0.00142606357733\n",
      "Epoch 1::Minibatch 404::LR 0.1 --> Loss 0.00134434541066\n",
      "Epoch 1::Minibatch 405::LR 0.1 --> Loss 0.00316660841306\n",
      "Epoch 1::Minibatch 406::LR 0.1 --> Loss 0.00232269227505\n",
      "Epoch 1::Minibatch 407::LR 0.1 --> Loss 0.00164649744829\n",
      "Epoch 1::Minibatch 408::LR 0.1 --> Loss 0.000422424773375\n",
      "Epoch 1::Minibatch 409::LR 0.1 --> Loss 0.00235887467861\n",
      "Epoch 1::Minibatch 410::LR 0.1 --> Loss 0.00338738997777\n",
      "Epoch 1::Minibatch 411::LR 0.1 --> Loss 0.00150816440582\n",
      "Epoch 1::Minibatch 412::LR 0.1 --> Loss 0.000891625980536\n",
      "Epoch 1::Minibatch 413::LR 0.1 --> Loss 0.00180887818336\n",
      "Epoch 1::Minibatch 414::LR 0.1 --> Loss 0.00177505711714\n",
      "Epoch 1::Minibatch 415::LR 0.1 --> Loss 0.00106303284566\n",
      "Epoch 1::Minibatch 416::LR 0.1 --> Loss 0.000775454690059\n",
      "Epoch 1::Minibatch 417::LR 0.1 --> Loss 0.00161789635817\n",
      "Epoch 1::Minibatch 418::LR 0.1 --> Loss 0.00285229404767\n",
      "Epoch 1::Minibatch 419::LR 0.1 --> Loss 0.000463938613733\n",
      "Epoch 1::Minibatch 420::LR 0.1 --> Loss 0.000609337141116\n",
      "Epoch 1::Minibatch 421::LR 0.1 --> Loss 0.0018336113294\n",
      "Epoch 1::Minibatch 422::LR 0.1 --> Loss 0.00203663349152\n",
      "Epoch 1::Minibatch 423::LR 0.1 --> Loss 0.000851878424486\n",
      "Epoch 1::Minibatch 424::LR 0.1 --> Loss 0.00145904143651\n",
      "Epoch 1::Minibatch 425::LR 0.1 --> Loss 0.00274618804455\n",
      "Epoch 1::Minibatch 426::LR 0.1 --> Loss 0.00182520171007\n",
      "Epoch 1::Minibatch 427::LR 0.1 --> Loss 0.000657992810011\n",
      "Epoch 1::Minibatch 428::LR 0.1 --> Loss 0.00112435837587\n",
      "Epoch 1::Minibatch 429::LR 0.1 --> Loss 0.00257311383883\n",
      "Epoch 1::Minibatch 430::LR 0.1 --> Loss 0.0112229196231\n",
      "Epoch 1::Minibatch 431::LR 0.1 --> Loss 0.0041492040952\n",
      "Epoch 1::Minibatch 432::LR 0.1 --> Loss 0.00476100802422\n",
      "Epoch 1::Minibatch 433::LR 0.1 --> Loss 0.00254141489665\n",
      "Epoch 1::Minibatch 434::LR 0.1 --> Loss 0.00272125005722\n",
      "Epoch 1::Minibatch 435::LR 0.1 --> Loss 0.00240067561467\n",
      "Epoch 1::Minibatch 436::LR 0.1 --> Loss 0.00156463623047\n",
      "Epoch 1::Minibatch 437::LR 0.1 --> Loss 0.00278972327709\n",
      "Epoch 1::Minibatch 438::LR 0.1 --> Loss 0.00223151604335\n",
      "Epoch 1::Minibatch 439::LR 0.1 --> Loss 0.00182396431764\n",
      "Epoch 1::Minibatch 440::LR 0.1 --> Loss 0.00294444044431\n",
      "Epoch 1::Minibatch 441::LR 0.1 --> Loss 0.0027238591512\n",
      "Epoch 1::Minibatch 442::LR 0.1 --> Loss 0.00236762384574\n",
      "Epoch 1::Minibatch 443::LR 0.1 --> Loss 0.00330455958843\n",
      "Epoch 1::Minibatch 444::LR 0.1 --> Loss 0.00247657914956\n",
      "Epoch 1::Minibatch 445::LR 0.1 --> Loss 0.000731004327536\n",
      "Epoch 1::Minibatch 446::LR 0.1 --> Loss 0.0012408798933\n",
      "Epoch 1::Minibatch 447::LR 0.1 --> Loss 0.00217046360175\n",
      "Epoch 1::Minibatch 448::LR 0.1 --> Loss 0.0021661178271\n",
      "Epoch 1::Minibatch 449::LR 0.1 --> Loss 0.00393834471703\n",
      "Epoch 1::Minibatch 450::LR 0.1 --> Loss 0.00205251375834\n",
      "Epoch 1::Minibatch 451::LR 0.1 --> Loss 0.00412357409795\n",
      "Epoch 1::Minibatch 452::LR 0.1 --> Loss 0.00228844364484\n",
      "Epoch 1::Minibatch 453::LR 0.1 --> Loss 0.000361706788341\n",
      "Epoch 1::Minibatch 454::LR 0.1 --> Loss 0.0039147345225\n",
      "Epoch 1::Minibatch 455::LR 0.1 --> Loss 0.00257487793763\n",
      "Epoch 1::Minibatch 456::LR 0.1 --> Loss 0.00309471766154\n",
      "Epoch 1::Minibatch 457::LR 0.1 --> Loss 0.00192939261595\n",
      "Epoch 1::Minibatch 458::LR 0.1 --> Loss 0.000645221223434\n",
      "Epoch 1::Minibatch 459::LR 0.1 --> Loss 0.00554110805194\n",
      "Epoch 1::Minibatch 460::LR 0.1 --> Loss 0.00253889838854\n",
      "Epoch 1::Minibatch 461::LR 0.1 --> Loss 0.0040390086174\n",
      "Epoch 1::Minibatch 462::LR 0.1 --> Loss 0.000346910034617\n",
      "Epoch 1::Minibatch 463::LR 0.1 --> Loss 0.00453602671623\n",
      "Epoch 1::Minibatch 464::LR 0.1 --> Loss 0.00204331080119\n",
      "Epoch 1::Minibatch 465::LR 0.1 --> Loss 0.0046818335851\n",
      "Epoch 1::Minibatch 466::LR 0.1 --> Loss 0.00510403911273\n",
      "Epoch 1::Minibatch 467::LR 0.1 --> Loss 0.00554186145465\n",
      "Epoch 1::Minibatch 468::LR 0.1 --> Loss 0.00592169523239\n",
      "Epoch 1::Minibatch 469::LR 0.1 --> Loss 0.00571386257807\n",
      "Epoch 1::Minibatch 470::LR 0.1 --> Loss 0.00350873668989\n",
      "Epoch 1::Minibatch 471::LR 0.1 --> Loss 0.00173636774222\n",
      "Epoch 1::Minibatch 472::LR 0.1 --> Loss 0.00346945961316\n",
      "Epoch 1::Minibatch 473::LR 0.1 --> Loss 0.00226835827033\n",
      "Epoch 1::Minibatch 474::LR 0.1 --> Loss 0.000665468176206\n",
      "Epoch 1::Minibatch 475::LR 0.1 --> Loss 0.00453253388405\n",
      "Epoch 1::Minibatch 476::LR 0.1 --> Loss 0.00658086498578\n",
      "Epoch 1::Minibatch 477::LR 0.1 --> Loss 0.000935047864914\n",
      "Epoch 1::Minibatch 478::LR 0.1 --> Loss 0.00251675784588\n",
      "Epoch 1::Minibatch 479::LR 0.1 --> Loss 0.00199743787448\n",
      "Epoch 1::Minibatch 480::LR 0.1 --> Loss 0.0016159654657\n",
      "Epoch 1::Minibatch 481::LR 0.1 --> Loss 0.000978240172068\n",
      "Epoch 1::Minibatch 482::LR 0.1 --> Loss 0.00216896831989\n",
      "Epoch 1::Minibatch 483::LR 0.1 --> Loss 0.00342671791712\n",
      "Epoch 1::Minibatch 484::LR 0.1 --> Loss 0.00364134351412\n",
      "Epoch 1::Minibatch 485::LR 0.1 --> Loss 0.000753369480371\n",
      "Epoch 1::Minibatch 486::LR 0.1 --> Loss 0.00307532807191\n",
      "Epoch 1::Minibatch 487::LR 0.1 --> Loss 0.00346950650215\n",
      "Epoch 1::Minibatch 488::LR 0.1 --> Loss 0.00209238211314\n",
      "Epoch 1::Minibatch 489::LR 0.1 --> Loss 0.00330277760824\n",
      "Epoch 1::Minibatch 490::LR 0.1 --> Loss 0.000399331053098\n",
      "Epoch 1::Minibatch 491::LR 0.1 --> Loss 0.00511899113655\n",
      "Epoch 1::Minibatch 492::LR 0.1 --> Loss 0.00300941268603\n",
      "Epoch 1::Minibatch 493::LR 0.1 --> Loss 0.0030062542359\n",
      "Epoch 1::Minibatch 494::LR 0.1 --> Loss 0.000744238644838\n",
      "Epoch 1::Minibatch 495::LR 0.1 --> Loss 0.00195042073727\n",
      "Epoch 1::Minibatch 496::LR 0.1 --> Loss 0.00307699938615\n",
      "Epoch 1::Minibatch 497::LR 0.1 --> Loss 0.000920933584372\n",
      "Epoch 1::Minibatch 498::LR 0.1 --> Loss 0.000555425186952\n",
      "Epoch 1::Minibatch 499::LR 0.1 --> Loss 0.0039492281278\n",
      "Epoch 1::Minibatch 500::LR 0.1 --> Loss 0.0014413634936\n",
      "Epoch 1::Minibatch 501::LR 0.1 --> Loss 0.00212301015854\n",
      "Epoch 1::Minibatch 502::LR 0.1 --> Loss 0.00374851902326\n",
      "Epoch 1::Minibatch 503::LR 0.1 --> Loss 0.00798607826233\n",
      "Epoch 1::Minibatch 504::LR 0.1 --> Loss 0.00741984526316\n",
      "Epoch 1::Minibatch 505::LR 0.1 --> Loss 0.00433454076449\n",
      "Epoch 1::Minibatch 506::LR 0.1 --> Loss 0.00333979606628\n",
      "Epoch 1::Minibatch 507::LR 0.1 --> Loss 0.00593403776487\n",
      "Epoch 1::Minibatch 508::LR 0.1 --> Loss 0.00331637382507\n",
      "Epoch 1::Minibatch 509::LR 0.1 --> Loss 0.00464335242907\n",
      "Epoch 1::Minibatch 510::LR 0.1 --> Loss 0.0050856033961\n",
      "Epoch 1::Minibatch 511::LR 0.1 --> Loss 0.00372430960337\n",
      "Epoch 1::Minibatch 512::LR 0.1 --> Loss 0.0026463886102\n",
      "Epoch 1::Minibatch 513::LR 0.1 --> Loss 0.000674301981926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 514::LR 0.1 --> Loss 0.00240026533604\n",
      "Epoch 1::Minibatch 515::LR 0.1 --> Loss 0.00299198190371\n",
      "Epoch 1::Minibatch 516::LR 0.1 --> Loss 0.00369850754738\n",
      "Epoch 1::Minibatch 517::LR 0.1 --> Loss 0.00318702677886\n",
      "Epoch 1::Minibatch 518::LR 0.1 --> Loss 0.00250018199285\n",
      "Epoch 1::Minibatch 519::LR 0.1 --> Loss 0.00334555546443\n",
      "Epoch 1::Minibatch 520::LR 0.1 --> Loss 0.0054517741998\n",
      "Epoch 1::Minibatch 521::LR 0.1 --> Loss 0.00583045760791\n",
      "Epoch 1::Minibatch 522::LR 0.1 --> Loss 0.00761000712713\n",
      "Epoch 1::Minibatch 523::LR 0.1 --> Loss 0.000637349933386\n",
      "Epoch 1::Minibatch 524::LR 0.1 --> Loss 0.00147107452154\n",
      "Epoch 1::Minibatch 525::LR 0.1 --> Loss 0.00328711807728\n",
      "Epoch 1::Minibatch 526::LR 0.1 --> Loss 0.0036009478569\n",
      "Epoch 1::Minibatch 527::LR 0.1 --> Loss 0.00232887049516\n",
      "Epoch 1::Minibatch 528::LR 0.1 --> Loss 0.00111064751943\n",
      "Epoch 1::Minibatch 529::LR 0.1 --> Loss 0.00428273359934\n",
      "Epoch 1::Minibatch 530::LR 0.1 --> Loss 0.00443734606107\n",
      "Epoch 1::Minibatch 531::LR 0.1 --> Loss 0.00374204754829\n",
      "Epoch 1::Minibatch 532::LR 0.1 --> Loss 0.00274288256963\n",
      "Epoch 1::Minibatch 533::LR 0.1 --> Loss 0.00489752729734\n",
      "Epoch 1::Minibatch 534::LR 0.1 --> Loss 0.00328408360481\n",
      "Epoch 1::Minibatch 535::LR 0.1 --> Loss 0.00311293880145\n",
      "Epoch 1::Minibatch 536::LR 0.1 --> Loss 0.00218730390072\n",
      "Epoch 1::Minibatch 537::LR 0.1 --> Loss 0.000642313857873\n",
      "Epoch 1::Minibatch 538::LR 0.1 --> Loss 0.00168285032113\n",
      "Epoch 1::Minibatch 539::LR 0.1 --> Loss 0.00344887574514\n",
      "Epoch 1::Minibatch 540::LR 0.1 --> Loss 0.00329936921597\n",
      "Epoch 1::Minibatch 541::LR 0.1 --> Loss 0.0029222424825\n",
      "Epoch 1::Minibatch 542::LR 0.1 --> Loss 0.00255432625612\n",
      "Epoch 1::Minibatch 543::LR 0.1 --> Loss 0.00285857141018\n",
      "Epoch 1::Minibatch 544::LR 0.1 --> Loss 0.00397120634715\n",
      "Epoch 1::Minibatch 545::LR 0.1 --> Loss 0.00203526039918\n",
      "Epoch 1::Minibatch 546::LR 0.1 --> Loss 0.000638513962428\n",
      "Epoch 1::Minibatch 547::LR 0.1 --> Loss 0.00263844589392\n",
      "Epoch 1::Minibatch 548::LR 0.1 --> Loss 0.00363908926646\n",
      "Epoch 1::Minibatch 549::LR 0.1 --> Loss 0.00858370780945\n",
      "Epoch 1::Minibatch 550::LR 0.1 --> Loss 0.00114715248346\n",
      "Epoch 1::Minibatch 551::LR 0.1 --> Loss 0.00236265281836\n",
      "Epoch 1::Minibatch 552::LR 0.1 --> Loss 0.00348563154538\n",
      "Epoch 1::Minibatch 553::LR 0.1 --> Loss 0.00315761725108\n",
      "Epoch 1::Minibatch 554::LR 0.1 --> Loss 0.00382938186328\n",
      "Epoch 1::Minibatch 555::LR 0.1 --> Loss 0.0010167602698\n",
      "Epoch 1::Minibatch 556::LR 0.1 --> Loss 0.00206238726775\n",
      "Epoch 1::Minibatch 557::LR 0.1 --> Loss 0.002494409283\n",
      "Epoch 1::Minibatch 558::LR 0.1 --> Loss 0.00370555996895\n",
      "Epoch 1::Minibatch 559::LR 0.1 --> Loss 0.00370935440063\n",
      "Epoch 1::Minibatch 560::LR 0.1 --> Loss 0.00303058067958\n",
      "Epoch 1::Minibatch 561::LR 0.1 --> Loss 0.00273236453533\n",
      "Epoch 1::Minibatch 562::LR 0.1 --> Loss 0.00244937419891\n",
      "Epoch 1::Minibatch 563::LR 0.1 --> Loss 0.00430890758832\n",
      "Epoch 1::Minibatch 564::LR 0.1 --> Loss 0.00315716505051\n",
      "Epoch 1::Minibatch 565::LR 0.1 --> Loss 0.00371994217237\n",
      "Epoch 1::Minibatch 566::LR 0.1 --> Loss 0.00232807020346\n",
      "Epoch 1::Minibatch 567::LR 0.1 --> Loss 0.00253722031911\n",
      "Epoch 1::Minibatch 568::LR 0.1 --> Loss 0.00188862939676\n",
      "Epoch 1::Minibatch 569::LR 0.1 --> Loss 0.000585847347975\n",
      "Epoch 1::Minibatch 570::LR 0.1 --> Loss 0.0017490931352\n",
      "Epoch 1::Minibatch 571::LR 0.1 --> Loss 0.00233193775018\n",
      "Epoch 1::Minibatch 572::LR 0.1 --> Loss 0.0024322672685\n",
      "Epoch 1::Minibatch 573::LR 0.1 --> Loss 0.00156150639057\n",
      "Epoch 1::Minibatch 574::LR 0.1 --> Loss 0.00106330712636\n",
      "Epoch 1::Minibatch 575::LR 0.1 --> Loss 0.0018558315436\n",
      "Epoch 1::Minibatch 576::LR 0.1 --> Loss 0.00210362315178\n",
      "Epoch 1::Minibatch 577::LR 0.1 --> Loss 0.00169649243355\n",
      "Epoch 1::Minibatch 578::LR 0.1 --> Loss 0.00136046687762\n",
      "Epoch 1::Minibatch 579::LR 0.1 --> Loss 0.00124646325906\n",
      "Epoch 1::Minibatch 580::LR 0.1 --> Loss 0.00197397549947\n",
      "Epoch 1::Minibatch 581::LR 0.1 --> Loss 0.00171846787135\n",
      "Epoch 1::Minibatch 582::LR 0.1 --> Loss 0.00438537597656\n",
      "Epoch 1::Minibatch 583::LR 0.1 --> Loss 0.000964639683565\n",
      "Epoch 1::Minibatch 584::LR 0.1 --> Loss 0.00130689501762\n",
      "Epoch 1::Minibatch 585::LR 0.1 --> Loss 0.00535782337189\n",
      "Epoch 1::Minibatch 586::LR 0.1 --> Loss 0.00409037152926\n",
      "Epoch 1::Minibatch 587::LR 0.1 --> Loss 0.00116712838411\n",
      "Epoch 1::Minibatch 588::LR 0.1 --> Loss 0.00140202999115\n",
      "Epoch 1::Minibatch 589::LR 0.1 --> Loss 0.00277011950811\n",
      "Epoch 1::Minibatch 590::LR 0.1 --> Loss 0.00198301315308\n",
      "Epoch 1::Minibatch 591::LR 0.1 --> Loss 0.00311055481434\n",
      "Epoch 1::Minibatch 592::LR 0.1 --> Loss 0.00122525374095\n",
      "Epoch 1::Minibatch 593::LR 0.1 --> Loss 0.00261930147807\n",
      "Epoch 1::Minibatch 594::LR 0.1 --> Loss 0.00290063758691\n",
      "Epoch 1::Minibatch 595::LR 0.1 --> Loss 0.00300128320853\n",
      "Epoch 1::Minibatch 596::LR 0.1 --> Loss 0.00202522397041\n",
      "Epoch 1::Minibatch 597::LR 0.1 --> Loss 0.0012134685119\n",
      "Epoch 1::Minibatch 598::LR 0.1 --> Loss 0.00290656606356\n",
      "Epoch 1::Minibatch 599::LR 0.1 --> Loss 0.00190677980582\n",
      "Epoch 1::Minibatch 600::LR 0.1 --> Loss 0.00227389335632\n",
      "Epoch 1::Minibatch 601::LR 0.1 --> Loss 0.0036286743482\n",
      "Epoch 1::Minibatch 602::LR 0.1 --> Loss 0.00212425728639\n",
      "Epoch 1::Minibatch 603::LR 0.1 --> Loss 0.00266562004884\n",
      "Epoch 1::Minibatch 604::LR 0.1 --> Loss 0.00169227500757\n",
      "Epoch 1::Minibatch 605::LR 0.1 --> Loss 0.0024270315965\n",
      "Epoch 1::Minibatch 606::LR 0.1 --> Loss 0.00199169933796\n",
      "Epoch 1::Minibatch 607::LR 0.1 --> Loss 0.000861917336782\n",
      "Epoch 1::Minibatch 608::LR 0.1 --> Loss 0.00156643211842\n",
      "Epoch 1::Minibatch 609::LR 0.1 --> Loss 0.00241382737954\n",
      "Epoch 1::Minibatch 610::LR 0.1 --> Loss 0.00330556372801\n",
      "Epoch 1::Minibatch 611::LR 0.1 --> Loss 0.00223788380623\n",
      "Epoch 1::Minibatch 612::LR 0.1 --> Loss 0.000474170744419\n",
      "Epoch 1::Minibatch 613::LR 0.1 --> Loss 0.00132717996836\n",
      "Epoch 1::Minibatch 614::LR 0.1 --> Loss 0.00233318249385\n",
      "Epoch 1::Minibatch 615::LR 0.1 --> Loss 0.00169866184394\n",
      "Epoch 1::Minibatch 616::LR 0.1 --> Loss 0.000929111242294\n",
      "Epoch 1::Minibatch 617::LR 0.1 --> Loss 0.000485049684842\n",
      "Epoch 1::Minibatch 618::LR 0.1 --> Loss 0.00242072284222\n",
      "Epoch 1::Minibatch 619::LR 0.1 --> Loss 0.00191334168116\n",
      "Epoch 1::Minibatch 620::LR 0.1 --> Loss 0.00172894457976\n",
      "Epoch 1::Minibatch 621::LR 0.1 --> Loss 0.000856039325396\n",
      "Epoch 1::Minibatch 622::LR 0.1 --> Loss 0.0007769412299\n",
      "Epoch 1::Minibatch 623::LR 0.1 --> Loss 0.00219829817613\n",
      "Epoch 1::Minibatch 624::LR 0.1 --> Loss 0.00172462443511\n",
      "Epoch 1::Minibatch 625::LR 0.1 --> Loss 0.0029857313633\n",
      "Epoch 1::Minibatch 626::LR 0.1 --> Loss 0.0048436041673\n",
      "Epoch 1::Minibatch 627::LR 0.1 --> Loss 0.00133657902479\n",
      "Epoch 1::Minibatch 628::LR 0.1 --> Loss 0.00088782787323\n",
      "Epoch 1::Minibatch 629::LR 0.1 --> Loss 0.00339364051819\n",
      "Epoch 1::Minibatch 630::LR 0.1 --> Loss 0.00322985569636\n",
      "Epoch 1::Minibatch 631::LR 0.1 --> Loss 0.00584224780401\n",
      "Epoch 1::Minibatch 632::LR 0.1 --> Loss 0.000799371798833\n",
      "Epoch 1::Minibatch 633::LR 0.1 --> Loss 0.00160913536946\n",
      "Epoch 1::Minibatch 634::LR 0.1 --> Loss 0.00304044465224\n",
      "Epoch 1::Minibatch 635::LR 0.1 --> Loss 0.00421162843704\n",
      "Epoch 1::Minibatch 636::LR 0.1 --> Loss 0.00851111888885\n",
      "Epoch 1::Minibatch 637::LR 0.1 --> Loss 0.000800552467505\n",
      "Epoch 1::Minibatch 638::LR 0.1 --> Loss 0.00156835029523\n",
      "Epoch 1::Minibatch 639::LR 0.1 --> Loss 0.00338969707489\n",
      "Epoch 1::Minibatch 640::LR 0.1 --> Loss 0.0066099802653\n",
      "Epoch 1::Minibatch 641::LR 0.1 --> Loss 0.00302307367325\n",
      "Epoch 1::Minibatch 642::LR 0.1 --> Loss 0.000510829339425\n",
      "Epoch 1::Minibatch 643::LR 0.1 --> Loss 0.00226594070594\n",
      "Epoch 1::Minibatch 644::LR 0.1 --> Loss 0.00382789333661\n",
      "Epoch 1::Minibatch 645::LR 0.1 --> Loss 0.00429727713267\n",
      "Epoch 1::Minibatch 646::LR 0.1 --> Loss 0.00150660802921\n",
      "Epoch 1::Minibatch 647::LR 0.1 --> Loss 0.00055870860815\n",
      "Epoch 1::Minibatch 648::LR 0.1 --> Loss 0.00303316076597\n",
      "Epoch 1::Minibatch 649::LR 0.1 --> Loss 0.00353086312612\n",
      "Epoch 1::Minibatch 650::LR 0.1 --> Loss 0.00331774950027\n",
      "Epoch 1::Minibatch 651::LR 0.1 --> Loss 0.001390645504\n",
      "Epoch 1::Minibatch 652::LR 0.1 --> Loss 0.000813245922327\n",
      "Epoch 1::Minibatch 653::LR 0.1 --> Loss 0.00292940715949\n",
      "Epoch 1::Minibatch 654::LR 0.1 --> Loss 0.0030063555638\n",
      "Epoch 1::Minibatch 655::LR 0.1 --> Loss 0.00351607203484\n",
      "Epoch 1::Minibatch 656::LR 0.1 --> Loss 0.000735390683015\n",
      "Epoch 1::Minibatch 657::LR 0.1 --> Loss 0.00211384455363\n",
      "Epoch 1::Minibatch 658::LR 0.1 --> Loss 0.0049623799324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 659::LR 0.1 --> Loss 0.00234105587006\n",
      "Epoch 1::Minibatch 660::LR 0.1 --> Loss 0.0024259475867\n",
      "Epoch 1::Minibatch 661::LR 0.1 --> Loss 0.00254023472468\n",
      "Epoch 1::Minibatch 662::LR 0.1 --> Loss 0.00179788490136\n",
      "Epoch 1::Minibatch 663::LR 0.1 --> Loss 0.00370500326157\n",
      "Epoch 1::Minibatch 664::LR 0.1 --> Loss 0.00340346415838\n",
      "Epoch 1::Minibatch 665::LR 0.1 --> Loss 0.000776801158985\n",
      "Epoch 1::Minibatch 666::LR 0.1 --> Loss 0.00394117712975\n",
      "Epoch 1::Minibatch 667::LR 0.1 --> Loss 0.00252971013387\n",
      "Epoch 1::Minibatch 668::LR 0.1 --> Loss 0.0074955924352\n",
      "Epoch 1::Minibatch 669::LR 0.1 --> Loss 0.00114374319712\n",
      "Epoch 1::Minibatch 670::LR 0.1 --> Loss 0.00133637736241\n",
      "Epoch 1::Minibatch 671::LR 0.1 --> Loss 0.00545159339905\n",
      "Epoch 1::Minibatch 672::LR 0.1 --> Loss 0.00393174648285\n",
      "Epoch 1::Minibatch 673::LR 0.1 --> Loss 0.00165895968676\n",
      "Epoch 1::Minibatch 674::LR 0.1 --> Loss 0.000532189905643\n",
      "Epoch 1::Minibatch 675::LR 0.1 --> Loss 0.00226963996887\n",
      "Epoch 1::Minibatch 676::LR 0.1 --> Loss 0.00226243555546\n",
      "Epoch 1::Minibatch 677::LR 0.1 --> Loss 0.00290877044201\n",
      "Epoch 1::Minibatch 678::LR 0.1 --> Loss 0.00195249239604\n",
      "Epoch 1::Minibatch 679::LR 0.1 --> Loss 0.00372574607531\n",
      "Epoch 1::Minibatch 680::LR 0.1 --> Loss 0.00216377357642\n",
      "Epoch 1::Minibatch 681::LR 0.1 --> Loss 0.00250350733598\n",
      "Epoch 1::Minibatch 682::LR 0.1 --> Loss 0.000783448070288\n",
      "Epoch 1::Minibatch 683::LR 0.1 --> Loss 0.00239027281602\n",
      "Epoch 1::Minibatch 684::LR 0.1 --> Loss 0.00232884923617\n",
      "Epoch 1::Minibatch 685::LR 0.1 --> Loss 0.00297024488449\n",
      "Epoch 1::Minibatch 686::LR 0.1 --> Loss 0.00151694595814\n",
      "Epoch 1::Minibatch 687::LR 0.1 --> Loss 0.000837942759196\n",
      "Epoch 1::Minibatch 688::LR 0.1 --> Loss 0.00269291440646\n",
      "Epoch 1::Minibatch 689::LR 0.1 --> Loss 0.00255333721638\n",
      "Epoch 1::Minibatch 690::LR 0.1 --> Loss 0.00192146837711\n",
      "Epoch 1::Minibatch 691::LR 0.1 --> Loss 0.000662979880969\n",
      "Epoch 1::Minibatch 692::LR 0.1 --> Loss 0.0024347025156\n",
      "Epoch 1::Minibatch 693::LR 0.1 --> Loss 0.00251149237156\n",
      "Epoch 1::Minibatch 694::LR 0.1 --> Loss 0.0030551836888\n",
      "Epoch 1::Minibatch 695::LR 0.1 --> Loss 0.00178906738758\n",
      "Epoch 1::Minibatch 696::LR 0.1 --> Loss 0.00215670307477\n",
      "Epoch 1::Minibatch 697::LR 0.1 --> Loss 0.0013971978426\n",
      "Epoch 1::Minibatch 698::LR 0.1 --> Loss 0.00163189411163\n",
      "Epoch 1::Minibatch 699::LR 0.1 --> Loss 0.00404307126999\n",
      "Epoch 1::Minibatch 700::LR 0.1 --> Loss 0.00263198633989\n",
      "Epoch 1::Minibatch 701::LR 0.1 --> Loss 0.00195800801118\n",
      "Epoch 1::Minibatch 702::LR 0.1 --> Loss 0.00168524185816\n",
      "Epoch 1::Minibatch 703::LR 0.1 --> Loss 0.00431336204211\n",
      "Epoch 1::Minibatch 704::LR 0.1 --> Loss 0.00183296879133\n",
      "Epoch 1::Minibatch 705::LR 0.1 --> Loss 0.00280215044816\n",
      "Epoch 1::Minibatch 706::LR 0.1 --> Loss 0.00218173384666\n",
      "Epoch 1::Minibatch 707::LR 0.1 --> Loss 0.00121171911558\n",
      "Epoch 1::Minibatch 708::LR 0.1 --> Loss 0.00174172580242\n",
      "Epoch 1::Minibatch 709::LR 0.1 --> Loss 0.00171798209349\n",
      "Epoch 1::Minibatch 710::LR 0.1 --> Loss 0.00241373956203\n",
      "Epoch 1::Minibatch 711::LR 0.1 --> Loss 0.0018122023344\n",
      "Epoch 1::Minibatch 712::LR 0.1 --> Loss 0.00137314081192\n",
      "Epoch 1::Minibatch 713::LR 0.1 --> Loss 0.00176369130611\n",
      "Epoch 1::Minibatch 714::LR 0.1 --> Loss 0.00258860448996\n",
      "Epoch 1::Minibatch 715::LR 0.1 --> Loss 0.00281084577243\n",
      "Epoch 1::Minibatch 716::LR 0.1 --> Loss 0.00155679980914\n",
      "Epoch 1::Minibatch 717::LR 0.1 --> Loss 0.00157242486874\n",
      "Epoch 1::Minibatch 718::LR 0.1 --> Loss 0.00120681633552\n",
      "Epoch 1::Minibatch 719::LR 0.1 --> Loss 0.00158722996712\n",
      "Epoch 1::Minibatch 720::LR 0.1 --> Loss 0.00229481200377\n",
      "Epoch 1::Minibatch 721::LR 0.1 --> Loss 0.000624701331059\n",
      "Epoch 1::Minibatch 722::LR 0.1 --> Loss 0.00544261574745\n",
      "Epoch 1::Minibatch 723::LR 0.1 --> Loss 0.00480760574341\n",
      "Epoch 1::Minibatch 724::LR 0.1 --> Loss 0.00100905656815\n",
      "Epoch 1::Minibatch 725::LR 0.1 --> Loss 0.00220151801904\n",
      "Epoch 1::Minibatch 726::LR 0.1 --> Loss 0.00513159950574\n",
      "Epoch 1::Minibatch 727::LR 0.1 --> Loss 0.0029177693526\n",
      "Epoch 1::Minibatch 728::LR 0.1 --> Loss 0.000679470449686\n",
      "Epoch 1::Minibatch 729::LR 0.1 --> Loss 0.00076865101854\n",
      "Epoch 1::Minibatch 730::LR 0.1 --> Loss 0.00251964966456\n",
      "Epoch 1::Minibatch 731::LR 0.1 --> Loss 0.00240520099799\n",
      "Epoch 1::Minibatch 732::LR 0.1 --> Loss 0.00238898078601\n",
      "Epoch 1::Minibatch 733::LR 0.1 --> Loss 0.000687888562679\n",
      "Epoch 1::Minibatch 734::LR 0.1 --> Loss 0.00172473371029\n",
      "Epoch 1::Minibatch 735::LR 0.1 --> Loss 0.00228004018466\n",
      "Epoch 1::Minibatch 736::LR 0.1 --> Loss 0.00341941277186\n",
      "Epoch 1::Minibatch 737::LR 0.1 --> Loss 0.00308295587699\n",
      "Epoch 1::Minibatch 738::LR 0.1 --> Loss 0.00151993900537\n",
      "Epoch 1::Minibatch 739::LR 0.1 --> Loss 0.00238093972206\n",
      "Epoch 1::Minibatch 740::LR 0.1 --> Loss 0.00397027333577\n",
      "Epoch 1::Minibatch 741::LR 0.1 --> Loss 0.00266934394836\n",
      "Epoch 1::Minibatch 742::LR 0.1 --> Loss 0.00201169033845\n",
      "Epoch 1::Minibatch 743::LR 0.1 --> Loss 0.0011156163613\n",
      "Epoch 1::Minibatch 744::LR 0.1 --> Loss 0.00166543751955\n",
      "Epoch 1::Minibatch 745::LR 0.1 --> Loss 0.00286314070225\n",
      "Epoch 1::Minibatch 746::LR 0.1 --> Loss 0.00297590156396\n",
      "Epoch 1::Minibatch 747::LR 0.1 --> Loss 0.00178582946459\n",
      "Epoch 1::Minibatch 748::LR 0.1 --> Loss 0.000600030471881\n",
      "Epoch 1::Minibatch 749::LR 0.1 --> Loss 0.00161617825429\n",
      "Epoch 1::Minibatch 750::LR 0.1 --> Loss 0.00246232748032\n",
      "Epoch 1::Minibatch 751::LR 0.1 --> Loss 0.00260019898415\n",
      "Epoch 1::Minibatch 752::LR 0.1 --> Loss 0.000990902682145\n",
      "Epoch 1::Minibatch 753::LR 0.1 --> Loss 0.00214339693387\n",
      "Epoch 1::Minibatch 754::LR 0.1 --> Loss 0.00238427400589\n",
      "Epoch 1::Minibatch 755::LR 0.1 --> Loss 0.0024941243728\n",
      "Epoch 1::Minibatch 756::LR 0.1 --> Loss 0.00140571107467\n",
      "Epoch 1::Minibatch 757::LR 0.1 --> Loss 0.000842162867387\n",
      "Epoch 1::Minibatch 758::LR 0.1 --> Loss 0.00166319906712\n",
      "Epoch 1::Minibatch 759::LR 0.1 --> Loss 0.00394843220711\n",
      "Epoch 1::Minibatch 760::LR 0.1 --> Loss 0.00296450734138\n",
      "Epoch 1::Minibatch 761::LR 0.1 --> Loss 0.00689553976059\n",
      "Epoch 1::Minibatch 762::LR 0.1 --> Loss 0.00376663684845\n",
      "Epoch 1::Minibatch 763::LR 0.1 --> Loss 0.00361773649851\n",
      "Epoch 1::Minibatch 764::LR 0.1 --> Loss 0.00313601454099\n",
      "Epoch 1::Minibatch 765::LR 0.1 --> Loss 0.0012616315484\n",
      "Epoch 1::Minibatch 766::LR 0.1 --> Loss 0.00225223024686\n",
      "Epoch 1::Minibatch 767::LR 0.1 --> Loss 0.00488645195961\n",
      "Epoch 1::Minibatch 768::LR 0.1 --> Loss 0.00347748239835\n",
      "Epoch 1::Minibatch 769::LR 0.1 --> Loss 0.00189867456754\n",
      "Epoch 1::Minibatch 770::LR 0.1 --> Loss 0.00131716986497\n",
      "Epoch 1::Minibatch 771::LR 0.1 --> Loss 0.00378456473351\n",
      "Epoch 1::Minibatch 772::LR 0.1 --> Loss 0.00314732690652\n",
      "Epoch 1::Minibatch 773::LR 0.1 --> Loss 0.00305923422178\n",
      "Epoch 1::Minibatch 774::LR 0.1 --> Loss 0.00171305616697\n",
      "Epoch 1::Minibatch 775::LR 0.1 --> Loss 0.00423353672028\n",
      "Epoch 1::Minibatch 776::LR 0.1 --> Loss 0.00349635481834\n",
      "Epoch 1::Minibatch 777::LR 0.1 --> Loss 0.00760148207347\n",
      "Epoch 1::Minibatch 778::LR 0.1 --> Loss 0.0125868868828\n",
      "Epoch 1::Minibatch 779::LR 0.1 --> Loss 0.00127510766188\n",
      "Epoch 1::Minibatch 780::LR 0.1 --> Loss 0.00170926272869\n",
      "Epoch 1::Minibatch 781::LR 0.1 --> Loss 0.00370542923609\n",
      "Epoch 1::Minibatch 782::LR 0.1 --> Loss 0.00448661605517\n",
      "Epoch 1::Minibatch 783::LR 0.1 --> Loss 0.00252100547155\n",
      "Epoch 1::Minibatch 784::LR 0.1 --> Loss 0.00081795334816\n",
      "Epoch 1::Minibatch 785::LR 0.1 --> Loss 0.00418230772018\n",
      "Epoch 1::Minibatch 786::LR 0.1 --> Loss 0.00395258148511\n",
      "Epoch 1::Minibatch 787::LR 0.1 --> Loss 0.00317335049311\n",
      "Epoch 1::Minibatch 788::LR 0.1 --> Loss 0.0028010503451\n",
      "Epoch 1::Minibatch 789::LR 0.1 --> Loss 0.000742534250021\n",
      "Epoch 1::Minibatch 790::LR 0.1 --> Loss 0.00344440142314\n",
      "Epoch 1::Minibatch 791::LR 0.1 --> Loss 0.0040858344237\n",
      "Epoch 1::Minibatch 792::LR 0.1 --> Loss 0.00377065698306\n",
      "Epoch 1::Minibatch 793::LR 0.1 --> Loss 0.00224135716756\n",
      "Epoch 1::Minibatch 794::LR 0.1 --> Loss 0.00126875261466\n",
      "Epoch 1::Minibatch 795::LR 0.1 --> Loss 0.00385192871094\n",
      "Epoch 1::Minibatch 796::LR 0.1 --> Loss 0.00585546374321\n",
      "Epoch 1::Minibatch 797::LR 0.1 --> Loss 0.0101784682274\n",
      "Epoch 1::Minibatch 798::LR 0.1 --> Loss 0.00346009492874\n",
      "Epoch 1::Minibatch 799::LR 0.1 --> Loss 0.00292150596778\n",
      "Epoch 1::Minibatch 800::LR 0.1 --> Loss 0.00226006507874\n",
      "Epoch 1::Minibatch 801::LR 0.1 --> Loss 0.00422236879667\n",
      "Epoch 1::Minibatch 802::LR 0.1 --> Loss 0.0013682632645\n",
      "Epoch 1::Minibatch 803::LR 0.1 --> Loss 0.00304829120636\n",
      "Epoch 1::Minibatch 804::LR 0.1 --> Loss 0.00226737419764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 805::LR 0.1 --> Loss 0.00234784444173\n",
      "Epoch 1::Minibatch 806::LR 0.1 --> Loss 0.00330776830514\n",
      "Epoch 1::Minibatch 807::LR 0.1 --> Loss 0.00301379481951\n",
      "Epoch 1::Minibatch 808::LR 0.1 --> Loss 0.00284731109937\n",
      "Epoch 1::Minibatch 809::LR 0.1 --> Loss 0.00508147398631\n",
      "Epoch 1::Minibatch 810::LR 0.1 --> Loss 0.00635094404221\n",
      "Epoch 1::Minibatch 811::LR 0.1 --> Loss 0.00593613862991\n",
      "Epoch 1::Minibatch 812::LR 0.1 --> Loss 0.00530030608177\n",
      "Epoch 1::Minibatch 813::LR 0.1 --> Loss 0.00453098058701\n",
      "Epoch 1::Minibatch 814::LR 0.1 --> Loss 0.00235754013062\n",
      "Epoch 1::Minibatch 815::LR 0.1 --> Loss 0.00449730038643\n",
      "Epoch 1::Minibatch 816::LR 0.1 --> Loss 0.00458300391833\n",
      "Epoch 1::Minibatch 817::LR 0.1 --> Loss 0.00448760946592\n",
      "Epoch 1::Minibatch 818::LR 0.1 --> Loss 0.00145701388518\n",
      "Epoch 1::Minibatch 819::LR 0.1 --> Loss 0.000749548127254\n",
      "Epoch 1::Minibatch 820::LR 0.1 --> Loss 0.00555016001066\n",
      "Epoch 1::Minibatch 821::LR 0.1 --> Loss 0.00341617226601\n",
      "Epoch 1::Minibatch 822::LR 0.1 --> Loss 0.00399749000867\n",
      "Epoch 1::Minibatch 823::LR 0.1 --> Loss 0.00131824374199\n",
      "Epoch 1::Minibatch 824::LR 0.1 --> Loss 0.00145231664181\n",
      "Epoch 1::Minibatch 825::LR 0.1 --> Loss 0.00377361615499\n",
      "Epoch 1::Minibatch 826::LR 0.1 --> Loss 0.00364242712657\n",
      "Epoch 1::Minibatch 827::LR 0.1 --> Loss 0.00222445964813\n",
      "Epoch 1::Minibatch 828::LR 0.1 --> Loss 0.00057586958011\n",
      "Epoch 1::Minibatch 829::LR 0.1 --> Loss 0.00240320007006\n",
      "Epoch 1::Minibatch 830::LR 0.1 --> Loss 0.00456618666649\n",
      "Epoch 1::Minibatch 831::LR 0.1 --> Loss 0.0025419296821\n",
      "Epoch 1::Minibatch 832::LR 0.1 --> Loss 0.00219595273336\n",
      "Epoch 1::Minibatch 833::LR 0.1 --> Loss 0.00176160295804\n",
      "Epoch 1::Minibatch 834::LR 0.1 --> Loss 0.00077519223094\n",
      "Epoch 1::Minibatch 835::LR 0.1 --> Loss 0.0038130291303\n",
      "Epoch 1::Minibatch 836::LR 0.1 --> Loss 0.00392975449562\n",
      "Epoch 1::Minibatch 837::LR 0.1 --> Loss 0.0024388285478\n",
      "Epoch 1::Minibatch 838::LR 0.1 --> Loss 0.000695262650649\n",
      "Epoch 1::Minibatch 839::LR 0.1 --> Loss 0.00254216829936\n",
      "Epoch 1::Minibatch 840::LR 0.1 --> Loss 0.00310799340407\n",
      "Epoch 1::Minibatch 841::LR 0.1 --> Loss 0.00300199667613\n",
      "Epoch 1::Minibatch 842::LR 0.1 --> Loss 0.00220493912697\n",
      "Epoch 1::Minibatch 843::LR 0.1 --> Loss 0.00101089944442\n",
      "Epoch 1::Minibatch 844::LR 0.1 --> Loss 0.00147937228282\n",
      "Epoch 1::Minibatch 845::LR 0.1 --> Loss 0.00411176164945\n",
      "Epoch 1::Minibatch 846::LR 0.1 --> Loss 0.00163879454136\n",
      "Epoch 1::Minibatch 847::LR 0.1 --> Loss 0.00233966787656\n",
      "Epoch 1::Minibatch 848::LR 0.1 --> Loss 0.000977476636569\n",
      "Epoch 1::Minibatch 849::LR 0.1 --> Loss 0.0019062791268\n",
      "Epoch 1::Minibatch 850::LR 0.1 --> Loss 0.00330827772617\n",
      "Epoch 1::Minibatch 851::LR 0.1 --> Loss 0.00321633835634\n",
      "Epoch 1::Minibatch 852::LR 0.1 --> Loss 0.00113165795803\n",
      "Epoch 1::Minibatch 853::LR 0.1 --> Loss 0.00134851634502\n",
      "Epoch 1::Minibatch 854::LR 0.1 --> Loss 0.00257338722547\n",
      "Epoch 1::Minibatch 855::LR 0.1 --> Loss 0.00209093014399\n",
      "Epoch 1::Minibatch 856::LR 0.1 --> Loss 0.00176964998245\n",
      "Epoch 1::Minibatch 857::LR 0.1 --> Loss 0.00123642245928\n",
      "Epoch 1::Minibatch 858::LR 0.1 --> Loss 0.000581661512454\n",
      "Epoch 1::Minibatch 859::LR 0.1 --> Loss 0.00187373101711\n",
      "Epoch 1::Minibatch 860::LR 0.1 --> Loss 0.00120913058519\n",
      "Epoch 1::Minibatch 861::LR 0.1 --> Loss 0.000906345645587\n",
      "Epoch 1::Minibatch 862::LR 0.1 --> Loss 0.00329440295696\n",
      "Epoch 1::Minibatch 863::LR 0.1 --> Loss 0.00384532054265\n",
      "Epoch 1::Minibatch 864::LR 0.1 --> Loss 0.00312000989914\n",
      "Epoch 1::Minibatch 865::LR 0.1 --> Loss 0.000433804094791\n",
      "Epoch 1::Minibatch 866::LR 0.1 --> Loss 0.00215025524298\n",
      "Epoch 1::Minibatch 867::LR 0.1 --> Loss 0.00294027388096\n",
      "Epoch 1::Minibatch 868::LR 0.1 --> Loss 0.00240789135297\n",
      "Epoch 1::Minibatch 869::LR 0.1 --> Loss 0.0020902077357\n",
      "Epoch 1::Minibatch 870::LR 0.1 --> Loss 0.00359238942464\n",
      "Epoch 1::Minibatch 871::LR 0.1 --> Loss 0.00152464667956\n",
      "Epoch 1::Minibatch 872::LR 0.1 --> Loss 0.00237010300159\n",
      "Epoch 1::Minibatch 873::LR 0.1 --> Loss 0.00250126481056\n",
      "Epoch 1::Minibatch 874::LR 0.1 --> Loss 0.00647207140923\n",
      "Epoch 1::Minibatch 875::LR 0.1 --> Loss 0.00052104845643\n",
      "Epoch 1::Minibatch 876::LR 0.1 --> Loss 0.00477049311002\n",
      "Epoch 1::Minibatch 877::LR 0.1 --> Loss 0.0109537657102\n",
      "Epoch 1::Minibatch 878::LR 0.1 --> Loss 0.00341051499049\n",
      "Epoch 1::Minibatch 879::LR 0.1 --> Loss 0.00438731312752\n",
      "Epoch 1::Minibatch 880::LR 0.1 --> Loss 0.00528086622556\n",
      "Epoch 1::Minibatch 881::LR 0.1 --> Loss 0.00417782584826\n",
      "Epoch 1::Minibatch 882::LR 0.1 --> Loss 0.00185648302237\n",
      "Epoch 1::Minibatch 883::LR 0.1 --> Loss 0.00350303371747\n",
      "Epoch 1::Minibatch 884::LR 0.1 --> Loss 0.00274046262105\n",
      "Epoch 1::Minibatch 885::LR 0.1 --> Loss 0.0028613203764\n",
      "Epoch 1::Minibatch 886::LR 0.1 --> Loss 0.00117124984662\n",
      "Epoch 1::Minibatch 887::LR 0.1 --> Loss 0.00617533445358\n",
      "Epoch 1::Minibatch 888::LR 0.1 --> Loss 0.0027109704415\n",
      "Epoch 1::Minibatch 889::LR 0.1 --> Loss 0.00410894076029\n",
      "Epoch 1::Minibatch 890::LR 0.1 --> Loss 0.00564011534055\n",
      "Epoch 1::Minibatch 891::LR 0.1 --> Loss 0.00241790791353\n",
      "Epoch 1::Minibatch 892::LR 0.1 --> Loss 0.000935423274835\n",
      "Epoch 1::Minibatch 893::LR 0.1 --> Loss 0.00279500007629\n",
      "Epoch 1::Minibatch 894::LR 0.1 --> Loss 0.00245489915212\n",
      "Epoch 1::Minibatch 895::LR 0.1 --> Loss 0.00281937897205\n",
      "Epoch 1::Minibatch 896::LR 0.1 --> Loss 0.00167387386163\n",
      "Epoch 1::Minibatch 897::LR 0.1 --> Loss 0.000785846710205\n",
      "Epoch 1::Minibatch 898::LR 0.1 --> Loss 0.002418085138\n",
      "Epoch 1::Minibatch 899::LR 0.1 --> Loss 0.00260829011599\n",
      "Epoch 1::Minibatch 900::LR 0.1 --> Loss 0.00401966055234\n",
      "Epoch 1::Minibatch 901::LR 0.1 --> Loss 0.000580954899391\n",
      "Epoch 1::Minibatch 902::LR 0.1 --> Loss 0.00143314232429\n",
      "Epoch 1::Minibatch 903::LR 0.1 --> Loss 0.00309188445409\n",
      "Epoch 1::Minibatch 904::LR 0.1 --> Loss 0.00252111117045\n",
      "Epoch 1::Minibatch 905::LR 0.1 --> Loss 0.00144599497318\n",
      "Epoch 1::Minibatch 906::LR 0.1 --> Loss 0.00104847898086\n",
      "Epoch 1::Minibatch 907::LR 0.1 --> Loss 0.00158141066631\n",
      "Epoch 1::Minibatch 908::LR 0.1 --> Loss 0.00296545227369\n",
      "Epoch 1::Minibatch 909::LR 0.1 --> Loss 0.00276052494844\n",
      "Epoch 1::Minibatch 910::LR 0.1 --> Loss 0.000827393829823\n",
      "Epoch 1::Minibatch 911::LR 0.1 --> Loss 0.00122843265533\n",
      "Epoch 1::Minibatch 912::LR 0.1 --> Loss 0.00266114036242\n",
      "Epoch 1::Minibatch 913::LR 0.1 --> Loss 0.00246768097083\n",
      "Epoch 1::Minibatch 914::LR 0.1 --> Loss 0.00146069208781\n",
      "Epoch 1::Minibatch 915::LR 0.1 --> Loss 0.000448057601849\n",
      "Epoch 1::Minibatch 916::LR 0.1 --> Loss 0.00321995357672\n",
      "Epoch 1::Minibatch 917::LR 0.1 --> Loss 0.00407943487167\n",
      "Epoch 1::Minibatch 918::LR 0.1 --> Loss 0.00704147895177\n",
      "Epoch 1::Minibatch 919::LR 0.1 --> Loss 0.00126223027706\n",
      "Epoch 1::Minibatch 920::LR 0.1 --> Loss 0.00926060358683\n",
      "Epoch 1::Minibatch 921::LR 0.1 --> Loss 0.00353220423063\n",
      "Epoch 1::Minibatch 922::LR 0.1 --> Loss 0.00382255633672\n",
      "Epoch 1::Minibatch 923::LR 0.1 --> Loss 0.00214106857777\n",
      "Epoch 1::Minibatch 924::LR 0.1 --> Loss 0.00380330681801\n",
      "Epoch 1::Minibatch 925::LR 0.1 --> Loss 0.00294129550457\n",
      "Epoch 1::Minibatch 926::LR 0.1 --> Loss 0.00612678050995\n",
      "Epoch 1::Minibatch 927::LR 0.1 --> Loss 0.0108877205849\n",
      "Epoch 1::Minibatch 928::LR 0.1 --> Loss 0.00800565163294\n",
      "Epoch 1::Minibatch 929::LR 0.1 --> Loss 0.0100937390327\n",
      "Epoch 1::Minibatch 930::LR 0.1 --> Loss 0.00684137662252\n",
      "Epoch 1::Minibatch 931::LR 0.1 --> Loss 0.00440153161685\n",
      "Epoch 1::Minibatch 932::LR 0.1 --> Loss 0.00826227585475\n",
      "Epoch 1::Minibatch 933::LR 0.1 --> Loss 0.00476970156034\n",
      "Epoch 1::Minibatch 934::LR 0.1 --> Loss 0.00640477220217\n",
      "Epoch 1::Minibatch 935::LR 0.1 --> Loss 0.00783386945724\n",
      "Epoch 1::Minibatch 936::LR 0.1 --> Loss 0.00210820118586\n",
      "Epoch 1::Minibatch 937::LR 0.1 --> Loss 0.00454666733742\n",
      "Epoch 1::Minibatch 938::LR 0.1 --> Loss 0.00430948495865\n",
      "Epoch 1::Minibatch 939::LR 0.1 --> Loss 0.00408252795537\n",
      "Epoch 1::Minibatch 940::LR 0.1 --> Loss 0.000949999292692\n",
      "Epoch 1::Minibatch 941::LR 0.1 --> Loss 0.000803387761116\n",
      "Epoch 1::Minibatch 942::LR 0.1 --> Loss 0.00249214867751\n",
      "Epoch 1::Minibatch 943::LR 0.1 --> Loss 0.00352360367775\n",
      "Epoch 1::Minibatch 944::LR 0.1 --> Loss 0.00259170015653\n",
      "Epoch 1::Minibatch 945::LR 0.1 --> Loss 0.00157518943151\n",
      "Epoch 1::Minibatch 946::LR 0.1 --> Loss 0.00406237165133\n",
      "Epoch 1::Minibatch 947::LR 0.1 --> Loss 0.00355671644211\n",
      "Epoch 1::Minibatch 948::LR 0.1 --> Loss 0.00613276720047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1::Minibatch 949::LR 0.1 --> Loss 0.00198127706846\n",
      "Epoch 1::Minibatch 950::LR 0.1 --> Loss 0.000654574334621\n",
      "Epoch 1::Minibatch 951::LR 0.1 --> Loss 0.00360563913981\n",
      "Epoch 1::Minibatch 952::LR 0.1 --> Loss 0.00254339595636\n",
      "Epoch 1::Minibatch 953::LR 0.1 --> Loss 0.00127430687348\n",
      "Epoch 1::Minibatch 954::LR 0.1 --> Loss 0.000921206672986\n",
      "Epoch 1::Minibatch 955::LR 0.1 --> Loss 0.00264823436737\n",
      "Epoch 1::Minibatch 956::LR 0.1 --> Loss 0.00481000820796\n",
      "Epoch 1::Minibatch 957::LR 0.1 --> Loss 0.00197811245918\n",
      "Epoch 1::Minibatch 958::LR 0.1 --> Loss 0.00280907928944\n",
      "Epoch 1::Minibatch 959::LR 0.1 --> Loss 0.00347834030787\n",
      "Epoch 1::Minibatch 960::LR 0.1 --> Loss 0.0062759009997\n",
      "Epoch 1::Minibatch 961::LR 0.1 --> Loss 0.00321093539397\n",
      "Epoch 1::Minibatch 962::LR 0.1 --> Loss 0.00313263277213\n",
      "Epoch 1::Minibatch 963::LR 0.1 --> Loss 0.00124833812316\n",
      "Epoch 1::Minibatch 964::LR 0.1 --> Loss 0.00278086086114\n",
      "Epoch 1::Minibatch 965::LR 0.1 --> Loss 0.0109078296026\n",
      "Epoch 1::Minibatch 966::LR 0.1 --> Loss 0.00506191492081\n",
      "Epoch 1::Minibatch 967::LR 0.1 --> Loss 0.00239250997702\n",
      "Epoch 1::Minibatch 968::LR 0.1 --> Loss 0.00232773443063\n",
      "Epoch 1::Minibatch 969::LR 0.1 --> Loss 0.00881758610408\n",
      "Epoch 1::Minibatch 970::LR 0.1 --> Loss 0.00569541970889\n",
      "Epoch 1::Minibatch 971::LR 0.1 --> Loss 0.00352975606918\n",
      "Epoch 1::Minibatch 972::LR 0.1 --> Loss 0.00914220492045\n",
      "Epoch 1::Minibatch 973::LR 0.1 --> Loss 0.0100276295344\n",
      "Epoch 1::Minibatch 974::LR 0.1 --> Loss 0.0051803958416\n",
      "Epoch 1::Minibatch 975::LR 0.1 --> Loss 0.00492262999217\n",
      "Epoch 1::Minibatch 976::LR 0.1 --> Loss 0.00434244394302\n",
      "Epoch 1::Minibatch 977::LR 0.1 --> Loss 0.0043394211928\n",
      "Epoch 1::Minibatch 978::LR 0.1 --> Loss 0.00402917861938\n",
      "Epoch 1::Minibatch 979::LR 0.1 --> Loss 0.00397964199384\n",
      "Epoch 1::Minibatch 980::LR 0.1 --> Loss 0.00434920907021\n",
      "Epoch 1::Minibatch 981::LR 0.1 --> Loss 0.00521536151568\n",
      "Epoch 1::Minibatch 982::LR 0.1 --> Loss 0.0120059084892\n",
      "Epoch 1::Minibatch 983::LR 0.1 --> Loss 0.00345754384995\n",
      "Epoch 1::Minibatch 984::LR 0.1 --> Loss 0.00452609380086\n",
      "Epoch 1::Minibatch 985::LR 0.1 --> Loss 0.00626775383949\n",
      "Epoch 1::Minibatch 986::LR 0.1 --> Loss 0.0062577021122\n",
      "Epoch 1::Minibatch 987::LR 0.1 --> Loss 0.00729365110397\n",
      "Epoch 1::Minibatch 988::LR 0.1 --> Loss 0.00573510050774\n",
      "Epoch 1::Minibatch 989::LR 0.1 --> Loss 0.00573336799939\n",
      "Epoch 1::Minibatch 990::LR 0.1 --> Loss 0.00531755208969\n",
      "Epoch 1::Minibatch 991::LR 0.1 --> Loss 0.00425208330154\n",
      "Epoch 1::Minibatch 992::LR 0.1 --> Loss 0.00453093330065\n",
      "Epoch 1::Minibatch 993::LR 0.1 --> Loss 0.00597461263339\n",
      "Epoch 1::Minibatch 994::LR 0.1 --> Loss 0.00403051018715\n",
      "Epoch 1::Minibatch 995::LR 0.1 --> Loss 0.00171837290128\n",
      "Epoch 1::Minibatch 996::LR 0.1 --> Loss 0.00672671079636\n",
      "Epoch 1::Minibatch 997::LR 0.1 --> Loss 0.00513577779134\n",
      "Epoch 1::Minibatch 998::LR 0.1 --> Loss 0.00501028895378\n",
      "Epoch 1::Minibatch 999::LR 0.1 --> Loss 0.00377975622813\n",
      "Epoch 1::Minibatch 1000::LR 0.1 --> Loss 0.00494407773018\n",
      "Epoch 1::Minibatch 1001::LR 0.1 --> Loss 0.00443667769432\n",
      "Epoch 1::Minibatch 1002::LR 0.1 --> Loss 0.00448752244314\n",
      "Epoch 1::Minibatch 1003::LR 0.1 --> Loss 0.00633193016052\n",
      "Epoch 1::Minibatch 1004::LR 0.1 --> Loss 0.00199576179187\n",
      "Epoch 1::Minibatch 1005::LR 0.1 --> Loss 0.00953946113586\n",
      "Epoch 1::Minibatch 1006::LR 0.1 --> Loss 0.00852936506271\n",
      "Epoch 1::Minibatch 1007::LR 0.1 --> Loss 0.00866672277451\n",
      "Epoch 1::Minibatch 1008::LR 0.1 --> Loss 0.0019537293911\n",
      "Epoch 1::Minibatch 1009::LR 0.1 --> Loss 0.0082266887029\n",
      "Epoch 1::Minibatch 1010::LR 0.1 --> Loss 0.0071396501859\n",
      "Epoch 1::Minibatch 1011::LR 0.1 --> Loss 0.00969449917475\n",
      "Epoch 1::Minibatch 1012::LR 0.1 --> Loss 0.00584182302157\n",
      "Epoch 1::Minibatch 1013::LR 0.1 --> Loss 0.00552989204725\n",
      "Epoch 1::Minibatch 1014::LR 0.1 --> Loss 0.00469351927439\n",
      "Epoch 1::Minibatch 1015::LR 0.1 --> Loss 0.00271129886309\n",
      "Epoch 1::Minibatch 1016::LR 0.1 --> Loss 0.00757734537125\n",
      "Epoch 1::Minibatch 1017::LR 0.1 --> Loss 0.00451715985934\n",
      "Epoch 1::Minibatch 1018::LR 0.1 --> Loss 0.0049068526427\n",
      "Epoch 1::Minibatch 1019::LR 0.1 --> Loss 0.00380205233892\n",
      "Epoch 1::Minibatch 1020::LR 0.1 --> Loss 0.00344683845838\n",
      "Epoch 1::Minibatch 1021::LR 0.1 --> Loss 0.00305295050144\n",
      "Epoch 1::Minibatch 1022::LR 0.1 --> Loss 0.00253987193108\n",
      "Epoch 1::Minibatch 1023::LR 0.1 --> Loss 0.00228155314922\n",
      "Epoch 1::Minibatch 1024::LR 0.1 --> Loss 0.00211799005667\n",
      "Epoch 1::Minibatch 1025::LR 0.1 --> Loss 0.00217210054398\n",
      "Epoch 1::Minibatch 1026::LR 0.1 --> Loss 0.00127509097258\n",
      "Epoch 1::Minibatch 1027::LR 0.1 --> Loss 0.00160406639179\n",
      "Epoch 1::Minibatch 1028::LR 0.1 --> Loss 0.00115690072378\n",
      "Epoch 1::Minibatch 1029::LR 0.1 --> Loss 0.00100300411383\n",
      "Epoch 1::Minibatch 1030::LR 0.1 --> Loss 0.00134457925955\n",
      "Epoch 1::Minibatch 1031::LR 0.1 --> Loss 0.000896171927452\n",
      "Epoch 1::Minibatch 1032::LR 0.1 --> Loss 0.000828942308823\n",
      "Epoch 1::Minibatch 1033::LR 0.1 --> Loss 0.000676129857699\n",
      "Epoch 1::Minibatch 1034::LR 0.1 --> Loss 0.000970828433832\n",
      "Epoch 1::Minibatch 1035::LR 0.1 --> Loss 0.000988645950953\n",
      "Epoch 1::Minibatch 1036::LR 0.1 --> Loss 0.000786982278029\n",
      "Epoch 1::Minibatch 1037::LR 0.1 --> Loss 0.000651082346837\n",
      "Epoch 1::Minibatch 1038::LR 0.1 --> Loss 0.00160875032345\n",
      "Epoch 1::Minibatch 1039::LR 0.1 --> Loss 0.00148907015721\n",
      "Epoch 1::Minibatch 1040::LR 0.1 --> Loss 0.000654834657907\n",
      "Epoch 1::Minibatch 1041::LR 0.1 --> Loss 0.000774069130421\n",
      "Epoch 2::Minibatch 1::LR 0.0976923076923 --> Loss 0.008774386247\n",
      "Epoch 2::Minibatch 2::LR 0.0976923076923 --> Loss 0.00547914385796\n",
      "Epoch 2::Minibatch 3::LR 0.0976923076923 --> Loss 0.00396142363548\n",
      "Epoch 2::Minibatch 4::LR 0.0976923076923 --> Loss 0.00438697417577\n",
      "Epoch 2::Minibatch 5::LR 0.0976923076923 --> Loss 0.00450824578603\n",
      "Epoch 2::Minibatch 6::LR 0.0976923076923 --> Loss 0.00225688536962\n",
      "Epoch 2::Minibatch 7::LR 0.0976923076923 --> Loss 0.00744842847188\n",
      "Epoch 2::Minibatch 8::LR 0.0976923076923 --> Loss 0.00733953158061\n",
      "Epoch 2::Minibatch 9::LR 0.0976923076923 --> Loss 0.00540601015091\n",
      "Epoch 2::Minibatch 10::LR 0.0976923076923 --> Loss 0.00248676796754\n",
      "Epoch 2::Minibatch 11::LR 0.0976923076923 --> Loss 0.00214681486289\n",
      "Epoch 2::Minibatch 12::LR 0.0976923076923 --> Loss 0.00368337194125\n",
      "Epoch 2::Minibatch 13::LR 0.0976923076923 --> Loss 0.00499223709106\n",
      "Epoch 2::Minibatch 14::LR 0.0976923076923 --> Loss 0.00470461010933\n",
      "Epoch 2::Minibatch 15::LR 0.0976923076923 --> Loss 0.00352499922117\n",
      "Epoch 2::Minibatch 16::LR 0.0976923076923 --> Loss 0.000545341074467\n",
      "Epoch 2::Minibatch 17::LR 0.0976923076923 --> Loss 0.00258942405383\n",
      "Epoch 2::Minibatch 18::LR 0.0976923076923 --> Loss 0.00225737452507\n",
      "Epoch 2::Minibatch 19::LR 0.0976923076923 --> Loss 0.00120702415705\n",
      "Epoch 2::Minibatch 20::LR 0.0976923076923 --> Loss 0.00165173977613\n",
      "Epoch 2::Minibatch 21::LR 0.0976923076923 --> Loss 0.00341329574585\n",
      "Epoch 2::Minibatch 22::LR 0.0976923076923 --> Loss 0.00225999375184\n",
      "Epoch 2::Minibatch 23::LR 0.0976923076923 --> Loss 0.000807838737965\n",
      "Epoch 2::Minibatch 24::LR 0.0976923076923 --> Loss 0.000351956635714\n",
      "Epoch 2::Minibatch 25::LR 0.0976923076923 --> Loss 0.00103810052077\n",
      "Epoch 2::Minibatch 26::LR 0.0976923076923 --> Loss 0.00125123858452\n",
      "Epoch 2::Minibatch 27::LR 0.0976923076923 --> Loss 0.000875236590703\n",
      "Epoch 2::Minibatch 28::LR 0.0976923076923 --> Loss 0.000334994221727\n",
      "Epoch 2::Minibatch 29::LR 0.0976923076923 --> Loss 0.000314226647218\n",
      "Epoch 2::Minibatch 30::LR 0.0976923076923 --> Loss 0.000749794989824\n",
      "Epoch 2::Minibatch 31::LR 0.0976923076923 --> Loss 0.00117605874936\n",
      "Epoch 2::Minibatch 32::LR 0.0976923076923 --> Loss 0.00112166166306\n",
      "Epoch 2::Minibatch 33::LR 0.0976923076923 --> Loss 0.000756810555855\n",
      "Epoch 2::Minibatch 34::LR 0.0976923076923 --> Loss 0.0023287798961\n",
      "Epoch 2::Minibatch 35::LR 0.0976923076923 --> Loss 0.00357854485512\n",
      "Epoch 2::Minibatch 36::LR 0.0976923076923 --> Loss 0.00218053619067\n",
      "Epoch 2::Minibatch 37::LR 0.0976923076923 --> Loss 0.000726508746545\n",
      "Epoch 2::Minibatch 38::LR 0.0976923076923 --> Loss 0.000847064753373\n",
      "Epoch 2::Minibatch 39::LR 0.0976923076923 --> Loss 0.00259706497192\n",
      "Epoch 2::Minibatch 40::LR 0.0976923076923 --> Loss 0.00366694728533\n",
      "Epoch 2::Minibatch 41::LR 0.0976923076923 --> Loss 0.00342905243238\n",
      "Epoch 2::Minibatch 42::LR 0.0976923076923 --> Loss 0.00661084612211\n",
      "Epoch 2::Minibatch 43::LR 0.0976923076923 --> Loss 0.00194150467714\n",
      "Epoch 2::Minibatch 44::LR 0.0976923076923 --> Loss 0.00320673684279\n",
      "Epoch 2::Minibatch 45::LR 0.0976923076923 --> Loss 0.00276207327843\n",
      "Epoch 2::Minibatch 46::LR 0.0976923076923 --> Loss 0.00371951301893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 47::LR 0.0976923076923 --> Loss 0.00553057273229\n",
      "Epoch 2::Minibatch 48::LR 0.0976923076923 --> Loss 0.006296535333\n",
      "Epoch 2::Minibatch 49::LR 0.0976923076923 --> Loss 0.00539074619611\n",
      "Epoch 2::Minibatch 50::LR 0.0976923076923 --> Loss 0.00547458807627\n",
      "Epoch 2::Minibatch 51::LR 0.0976923076923 --> Loss 0.00610686500867\n",
      "Epoch 2::Minibatch 52::LR 0.0976923076923 --> Loss 0.00302660266558\n",
      "Epoch 2::Minibatch 53::LR 0.0976923076923 --> Loss 0.00388345400492\n",
      "Epoch 2::Minibatch 54::LR 0.0976923076923 --> Loss 0.00382300019264\n",
      "Epoch 2::Minibatch 55::LR 0.0976923076923 --> Loss 0.00102427562078\n",
      "Epoch 2::Minibatch 56::LR 0.0976923076923 --> Loss 0.00262623548508\n",
      "Epoch 2::Minibatch 57::LR 0.0976923076923 --> Loss 0.00569779276848\n",
      "Epoch 2::Minibatch 58::LR 0.0976923076923 --> Loss 0.00357289036115\n",
      "Epoch 2::Minibatch 59::LR 0.0976923076923 --> Loss 0.00251410822074\n",
      "Epoch 2::Minibatch 60::LR 0.0976923076923 --> Loss 0.00224786539872\n",
      "Epoch 2::Minibatch 61::LR 0.0976923076923 --> Loss 0.00104953120152\n",
      "Epoch 2::Minibatch 62::LR 0.0976923076923 --> Loss 0.00383562684059\n",
      "Epoch 2::Minibatch 63::LR 0.0976923076923 --> Loss 0.00226358811061\n",
      "Epoch 2::Minibatch 64::LR 0.0976923076923 --> Loss 0.00105777025223\n",
      "Epoch 2::Minibatch 65::LR 0.0976923076923 --> Loss 0.00254466712475\n",
      "Epoch 2::Minibatch 66::LR 0.0976923076923 --> Loss 0.00298093159993\n",
      "Epoch 2::Minibatch 67::LR 0.0976923076923 --> Loss 0.00291268308957\n",
      "Epoch 2::Minibatch 68::LR 0.0976923076923 --> Loss 0.00211764653524\n",
      "Epoch 2::Minibatch 69::LR 0.0976923076923 --> Loss 0.00426379084587\n",
      "Epoch 2::Minibatch 70::LR 0.0976923076923 --> Loss 0.00347981850306\n",
      "Epoch 2::Minibatch 71::LR 0.0976923076923 --> Loss 0.00217771689097\n",
      "Epoch 2::Minibatch 72::LR 0.0976923076923 --> Loss 0.000594902833303\n",
      "Epoch 2::Minibatch 73::LR 0.0976923076923 --> Loss 0.00364772240321\n",
      "Epoch 2::Minibatch 74::LR 0.0976923076923 --> Loss 0.00442428787549\n",
      "Epoch 2::Minibatch 75::LR 0.0976923076923 --> Loss 0.00255026022593\n",
      "Epoch 2::Minibatch 76::LR 0.0976923076923 --> Loss 0.000650954544544\n",
      "Epoch 2::Minibatch 77::LR 0.0976923076923 --> Loss 0.00457384785016\n",
      "Epoch 2::Minibatch 78::LR 0.0976923076923 --> Loss 0.00383184432983\n",
      "Epoch 2::Minibatch 79::LR 0.0976923076923 --> Loss 0.00230366786321\n",
      "Epoch 2::Minibatch 80::LR 0.0976923076923 --> Loss 0.00370350003242\n",
      "Epoch 2::Minibatch 81::LR 0.0976923076923 --> Loss 0.00313175817331\n",
      "Epoch 2::Minibatch 82::LR 0.0976923076923 --> Loss 0.00216709474723\n",
      "Epoch 2::Minibatch 83::LR 0.0976923076923 --> Loss 0.00661699493726\n",
      "Epoch 2::Minibatch 84::LR 0.0976923076923 --> Loss 0.00213575045268\n",
      "Epoch 2::Minibatch 85::LR 0.0976923076923 --> Loss 0.00294807771842\n",
      "Epoch 2::Minibatch 86::LR 0.0976923076923 --> Loss 0.0025222247839\n",
      "Epoch 2::Minibatch 87::LR 0.0976923076923 --> Loss 0.0026960670948\n",
      "Epoch 2::Minibatch 88::LR 0.0976923076923 --> Loss 0.00193558057149\n",
      "Epoch 2::Minibatch 89::LR 0.0976923076923 --> Loss 0.00240497509638\n",
      "Epoch 2::Minibatch 90::LR 0.0976923076923 --> Loss 0.00132492204507\n",
      "Epoch 2::Minibatch 91::LR 0.0976923076923 --> Loss 0.00106023679177\n",
      "Epoch 2::Minibatch 92::LR 0.0976923076923 --> Loss 0.00282150785128\n",
      "Epoch 2::Minibatch 93::LR 0.0976923076923 --> Loss 0.00185767849286\n",
      "Epoch 2::Minibatch 94::LR 0.0976923076923 --> Loss 0.00185658256213\n",
      "Epoch 2::Minibatch 95::LR 0.0976923076923 --> Loss 0.00174912353357\n",
      "Epoch 2::Minibatch 96::LR 0.0976923076923 --> Loss 0.00575419386228\n",
      "Epoch 2::Minibatch 97::LR 0.0976923076923 --> Loss 0.00266385177771\n",
      "Epoch 2::Minibatch 98::LR 0.0976923076923 --> Loss 0.000945865909259\n",
      "Epoch 2::Minibatch 99::LR 0.0976923076923 --> Loss 0.00130515406529\n",
      "Epoch 2::Minibatch 100::LR 0.0976923076923 --> Loss 0.00574510931969\n",
      "Epoch 2::Minibatch 101::LR 0.0976923076923 --> Loss 0.00107949395974\n",
      "Epoch 2::Minibatch 102::LR 0.0976923076923 --> Loss 0.00368363380432\n",
      "Epoch 2::Minibatch 103::LR 0.0976923076923 --> Loss 0.00388242483139\n",
      "Epoch 2::Minibatch 104::LR 0.0976923076923 --> Loss 0.00297191858292\n",
      "Epoch 2::Minibatch 105::LR 0.0976923076923 --> Loss 0.00326726595561\n",
      "Epoch 2::Minibatch 106::LR 0.0976923076923 --> Loss 0.0190280675888\n",
      "Epoch 2::Minibatch 107::LR 0.0976923076923 --> Loss 0.00485267043114\n",
      "Epoch 2::Minibatch 108::LR 0.0976923076923 --> Loss 0.00150470525026\n",
      "Epoch 2::Minibatch 109::LR 0.0976923076923 --> Loss 0.00473115921021\n",
      "Epoch 2::Minibatch 110::LR 0.0976923076923 --> Loss 0.00291183590889\n",
      "Epoch 2::Minibatch 111::LR 0.0976923076923 --> Loss 0.00137320041656\n",
      "Epoch 2::Minibatch 112::LR 0.0976923076923 --> Loss 0.00418362180392\n",
      "Epoch 2::Minibatch 113::LR 0.0976923076923 --> Loss 0.00312966227531\n",
      "Epoch 2::Minibatch 114::LR 0.0976923076923 --> Loss 0.00183568716049\n",
      "Epoch 2::Minibatch 115::LR 0.0976923076923 --> Loss 0.00176474114259\n",
      "Epoch 2::Minibatch 116::LR 0.0976923076923 --> Loss 0.00324545542399\n",
      "Epoch 2::Minibatch 117::LR 0.0976923076923 --> Loss 0.00377074877421\n",
      "Epoch 2::Minibatch 118::LR 0.0976923076923 --> Loss 0.00677257935206\n",
      "Epoch 2::Minibatch 119::LR 0.0976923076923 --> Loss 0.000957020819187\n",
      "Epoch 2::Minibatch 120::LR 0.0976923076923 --> Loss 0.00218674639861\n",
      "Epoch 2::Minibatch 121::LR 0.0976923076923 --> Loss 0.00321028312047\n",
      "Epoch 2::Minibatch 122::LR 0.0976923076923 --> Loss 0.00414235472679\n",
      "Epoch 2::Minibatch 123::LR 0.0976923076923 --> Loss 0.00166976213455\n",
      "Epoch 2::Minibatch 124::LR 0.0976923076923 --> Loss 0.00321375350157\n",
      "Epoch 2::Minibatch 125::LR 0.0976923076923 --> Loss 0.00492584109306\n",
      "Epoch 2::Minibatch 126::LR 0.0976923076923 --> Loss 0.00315260688464\n",
      "Epoch 2::Minibatch 127::LR 0.0976923076923 --> Loss 0.00454962770144\n",
      "Epoch 2::Minibatch 128::LR 0.0976923076923 --> Loss 0.00382574478785\n",
      "Epoch 2::Minibatch 129::LR 0.0976923076923 --> Loss 0.00314297874769\n",
      "Epoch 2::Minibatch 130::LR 0.0976923076923 --> Loss 0.0043349468708\n",
      "Epoch 2::Minibatch 131::LR 0.0976923076923 --> Loss 0.00195664306482\n",
      "Epoch 2::Minibatch 132::LR 0.0976923076923 --> Loss 0.00341614047686\n",
      "Epoch 2::Minibatch 133::LR 0.0976923076923 --> Loss 0.00329109311104\n",
      "Epoch 2::Minibatch 134::LR 0.0976923076923 --> Loss 0.00275201876958\n",
      "Epoch 2::Minibatch 135::LR 0.0976923076923 --> Loss 0.00195308188597\n",
      "Epoch 2::Minibatch 136::LR 0.0976923076923 --> Loss 0.00304026126862\n",
      "Epoch 2::Minibatch 137::LR 0.0976923076923 --> Loss 0.00387061436971\n",
      "Epoch 2::Minibatch 138::LR 0.0976923076923 --> Loss 0.00141760597626\n",
      "Epoch 2::Minibatch 139::LR 0.0976923076923 --> Loss 0.00199761390686\n",
      "Epoch 2::Minibatch 140::LR 0.0976923076923 --> Loss 0.00258038679759\n",
      "Epoch 2::Minibatch 141::LR 0.0976923076923 --> Loss 0.00292705376943\n",
      "Epoch 2::Minibatch 142::LR 0.0976923076923 --> Loss 0.00317356805007\n",
      "Epoch 2::Minibatch 143::LR 0.0976923076923 --> Loss 0.000627120534579\n",
      "Epoch 2::Minibatch 144::LR 0.0976923076923 --> Loss 0.00324953556061\n",
      "Epoch 2::Minibatch 145::LR 0.0976923076923 --> Loss 0.0044665602843\n",
      "Epoch 2::Minibatch 146::LR 0.0976923076923 --> Loss 0.00268730203311\n",
      "Epoch 2::Minibatch 147::LR 0.0976923076923 --> Loss 0.00186212937037\n",
      "Epoch 2::Minibatch 148::LR 0.0976923076923 --> Loss 0.00103561878204\n",
      "Epoch 2::Minibatch 149::LR 0.0976923076923 --> Loss 0.00281514525414\n",
      "Epoch 2::Minibatch 150::LR 0.0976923076923 --> Loss 0.00275289773941\n",
      "Epoch 2::Minibatch 151::LR 0.0976923076923 --> Loss 0.00405898332596\n",
      "Epoch 2::Minibatch 152::LR 0.0976923076923 --> Loss 0.000918743014336\n",
      "Epoch 2::Minibatch 153::LR 0.0976923076923 --> Loss 0.00196285784245\n",
      "Epoch 2::Minibatch 154::LR 0.0976923076923 --> Loss 0.00209026495616\n",
      "Epoch 2::Minibatch 155::LR 0.0976923076923 --> Loss 0.004769769907\n",
      "Epoch 2::Minibatch 156::LR 0.0976923076923 --> Loss 0.00224268178145\n",
      "Epoch 2::Minibatch 157::LR 0.0976923076923 --> Loss 0.000698617945115\n",
      "Epoch 2::Minibatch 158::LR 0.0976923076923 --> Loss 0.00295919676622\n",
      "Epoch 2::Minibatch 159::LR 0.0976923076923 --> Loss 0.00277876615524\n",
      "Epoch 2::Minibatch 160::LR 0.0976923076923 --> Loss 0.0026693713665\n",
      "Epoch 2::Minibatch 161::LR 0.0976923076923 --> Loss 0.00102139770985\n",
      "Epoch 2::Minibatch 162::LR 0.0976923076923 --> Loss 0.00366348981857\n",
      "Epoch 2::Minibatch 163::LR 0.0976923076923 --> Loss 0.00237849811713\n",
      "Epoch 2::Minibatch 164::LR 0.0976923076923 --> Loss 0.00249870081743\n",
      "Epoch 2::Minibatch 165::LR 0.0976923076923 --> Loss 0.000530833949645\n",
      "Epoch 2::Minibatch 166::LR 0.0976923076923 --> Loss 0.0018217809995\n",
      "Epoch 2::Minibatch 167::LR 0.0976923076923 --> Loss 0.00250183602174\n",
      "Epoch 2::Minibatch 168::LR 0.0976923076923 --> Loss 0.00220086952051\n",
      "Epoch 2::Minibatch 169::LR 0.0976923076923 --> Loss 0.00100263565779\n",
      "Epoch 2::Minibatch 170::LR 0.0976923076923 --> Loss 0.00101065357526\n",
      "Epoch 2::Minibatch 171::LR 0.0976923076923 --> Loss 0.00248337348302\n",
      "Epoch 2::Minibatch 172::LR 0.0976923076923 --> Loss 0.00540131251017\n",
      "Epoch 2::Minibatch 173::LR 0.0976923076923 --> Loss 0.00198906560739\n",
      "Epoch 2::Minibatch 174::LR 0.0976923076923 --> Loss 0.00106264650822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 175::LR 0.0976923076923 --> Loss 0.00223420500755\n",
      "Epoch 2::Minibatch 176::LR 0.0976923076923 --> Loss 0.00346679369609\n",
      "Epoch 2::Minibatch 177::LR 0.0976923076923 --> Loss 0.00490798513095\n",
      "Epoch 2::Minibatch 178::LR 0.0976923076923 --> Loss 0.0017093616724\n",
      "Epoch 2::Minibatch 179::LR 0.0976923076923 --> Loss 0.00136100331942\n",
      "Epoch 2::Minibatch 180::LR 0.0976923076923 --> Loss 0.00375952323278\n",
      "Epoch 2::Minibatch 181::LR 0.0976923076923 --> Loss 0.00360678831736\n",
      "Epoch 2::Minibatch 182::LR 0.0976923076923 --> Loss 0.00083397825559\n",
      "Epoch 2::Minibatch 183::LR 0.0976923076923 --> Loss 0.00166917820772\n",
      "Epoch 2::Minibatch 184::LR 0.0976923076923 --> Loss 0.00358830650647\n",
      "Epoch 2::Minibatch 185::LR 0.0976923076923 --> Loss 0.00260517736276\n",
      "Epoch 2::Minibatch 186::LR 0.0976923076923 --> Loss 0.00104182779789\n",
      "Epoch 2::Minibatch 187::LR 0.0976923076923 --> Loss 0.00125756343206\n",
      "Epoch 2::Minibatch 188::LR 0.0976923076923 --> Loss 0.00394167820613\n",
      "Epoch 2::Minibatch 189::LR 0.0976923076923 --> Loss 0.00472237507502\n",
      "Epoch 2::Minibatch 190::LR 0.0976923076923 --> Loss 0.00227897047997\n",
      "Epoch 2::Minibatch 191::LR 0.0976923076923 --> Loss 0.000461706519127\n",
      "Epoch 2::Minibatch 192::LR 0.0976923076923 --> Loss 0.00257522861163\n",
      "Epoch 2::Minibatch 193::LR 0.0976923076923 --> Loss 0.00252876996994\n",
      "Epoch 2::Minibatch 194::LR 0.0976923076923 --> Loss 0.00179611285528\n",
      "Epoch 2::Minibatch 195::LR 0.0976923076923 --> Loss 0.000405311013261\n",
      "Epoch 2::Minibatch 196::LR 0.0976923076923 --> Loss 0.00110554903746\n",
      "Epoch 2::Minibatch 197::LR 0.0976923076923 --> Loss 0.00271687249343\n",
      "Epoch 2::Minibatch 198::LR 0.0976923076923 --> Loss 0.00206981221835\n",
      "Epoch 2::Minibatch 199::LR 0.0976923076923 --> Loss 0.000297311246395\n",
      "Epoch 2::Minibatch 200::LR 0.0976923076923 --> Loss 0.00203063090642\n",
      "Epoch 2::Minibatch 201::LR 0.0976923076923 --> Loss 0.00192268550396\n",
      "Epoch 2::Minibatch 202::LR 0.0976923076923 --> Loss 0.00186284621557\n",
      "Epoch 2::Minibatch 203::LR 0.0976923076923 --> Loss 0.00178578615189\n",
      "Epoch 2::Minibatch 204::LR 0.0976923076923 --> Loss 0.00144110878309\n",
      "Epoch 2::Minibatch 205::LR 0.0976923076923 --> Loss 0.00217962682247\n",
      "Epoch 2::Minibatch 206::LR 0.0976923076923 --> Loss 0.00645290017128\n",
      "Epoch 2::Minibatch 207::LR 0.0976923076923 --> Loss 0.00138131429752\n",
      "Epoch 2::Minibatch 208::LR 0.0976923076923 --> Loss 0.00112829556068\n",
      "Epoch 2::Minibatch 209::LR 0.0976923076923 --> Loss 0.00193891326586\n",
      "Epoch 2::Minibatch 210::LR 0.0976923076923 --> Loss 0.00176713506381\n",
      "Epoch 2::Minibatch 211::LR 0.0976923076923 --> Loss 0.00193671902021\n",
      "Epoch 2::Minibatch 212::LR 0.0976923076923 --> Loss 0.00439974427223\n",
      "Epoch 2::Minibatch 213::LR 0.0976923076923 --> Loss 0.00651360710462\n",
      "Epoch 2::Minibatch 214::LR 0.0976923076923 --> Loss 0.0102058275541\n",
      "Epoch 2::Minibatch 215::LR 0.0976923076923 --> Loss 0.0012865404288\n",
      "Epoch 2::Minibatch 216::LR 0.0976923076923 --> Loss 0.0052136695385\n",
      "Epoch 2::Minibatch 217::LR 0.0976923076923 --> Loss 0.00565449595451\n",
      "Epoch 2::Minibatch 218::LR 0.0976923076923 --> Loss 0.00400088628133\n",
      "Epoch 2::Minibatch 219::LR 0.0976923076923 --> Loss 0.00344764351845\n",
      "Epoch 2::Minibatch 220::LR 0.0976923076923 --> Loss 0.00465696851412\n",
      "Epoch 2::Minibatch 221::LR 0.0976923076923 --> Loss 0.00420926968257\n",
      "Epoch 2::Minibatch 222::LR 0.0976923076923 --> Loss 0.00325459639231\n",
      "Epoch 2::Minibatch 223::LR 0.0976923076923 --> Loss 0.00127939989169\n",
      "Epoch 2::Minibatch 224::LR 0.0976923076923 --> Loss 0.00173010210196\n",
      "Epoch 2::Minibatch 225::LR 0.0976923076923 --> Loss 0.00696845531464\n",
      "Epoch 2::Minibatch 226::LR 0.0976923076923 --> Loss 0.00371765573819\n",
      "Epoch 2::Minibatch 227::LR 0.0976923076923 --> Loss 0.00165615955989\n",
      "Epoch 2::Minibatch 228::LR 0.0976923076923 --> Loss 0.000746884445349\n",
      "Epoch 2::Minibatch 229::LR 0.0976923076923 --> Loss 0.00466287056605\n",
      "Epoch 2::Minibatch 230::LR 0.0976923076923 --> Loss 0.00412255088488\n",
      "Epoch 2::Minibatch 231::LR 0.0976923076923 --> Loss 0.00249534606934\n",
      "Epoch 2::Minibatch 232::LR 0.0976923076923 --> Loss 0.00115870098273\n",
      "Epoch 2::Minibatch 233::LR 0.0976923076923 --> Loss 0.00230135003726\n",
      "Epoch 2::Minibatch 234::LR 0.0976923076923 --> Loss 0.00622651775678\n",
      "Epoch 2::Minibatch 235::LR 0.0976923076923 --> Loss 0.0039925690492\n",
      "Epoch 2::Minibatch 236::LR 0.0976923076923 --> Loss 0.00173025369644\n",
      "Epoch 2::Minibatch 237::LR 0.0976923076923 --> Loss 0.000702847540379\n",
      "Epoch 2::Minibatch 238::LR 0.0976923076923 --> Loss 0.00336103876432\n",
      "Epoch 2::Minibatch 239::LR 0.0976923076923 --> Loss 0.00288256029288\n",
      "Epoch 2::Minibatch 240::LR 0.0976923076923 --> Loss 0.00312572717667\n",
      "Epoch 2::Minibatch 241::LR 0.0976923076923 --> Loss 0.00074767212073\n",
      "Epoch 2::Minibatch 242::LR 0.0976923076923 --> Loss 0.00746456623077\n",
      "Epoch 2::Minibatch 243::LR 0.0976923076923 --> Loss 0.00368452946345\n",
      "Epoch 2::Minibatch 244::LR 0.0976923076923 --> Loss 0.0030987483263\n",
      "Epoch 2::Minibatch 245::LR 0.0976923076923 --> Loss 0.000528937727213\n",
      "Epoch 2::Minibatch 246::LR 0.0976923076923 --> Loss 0.00215395847956\n",
      "Epoch 2::Minibatch 247::LR 0.0976923076923 --> Loss 0.0144780794779\n",
      "Epoch 2::Minibatch 248::LR 0.0976923076923 --> Loss 0.00752578496933\n",
      "Epoch 2::Minibatch 249::LR 0.0976923076923 --> Loss 0.00276299496492\n",
      "Epoch 2::Minibatch 250::LR 0.0976923076923 --> Loss 0.00262054045995\n",
      "Epoch 2::Minibatch 251::LR 0.0976923076923 --> Loss 0.00231390357018\n",
      "Epoch 2::Minibatch 252::LR 0.0976923076923 --> Loss 0.00190316259861\n",
      "Epoch 2::Minibatch 253::LR 0.0976923076923 --> Loss 0.00323703547319\n",
      "Epoch 2::Minibatch 254::LR 0.0976923076923 --> Loss 0.00533763289452\n",
      "Epoch 2::Minibatch 255::LR 0.0976923076923 --> Loss 0.00400038878123\n",
      "Epoch 2::Minibatch 256::LR 0.0976923076923 --> Loss 0.00184581398964\n",
      "Epoch 2::Minibatch 257::LR 0.0976923076923 --> Loss 0.00125295102596\n",
      "Epoch 2::Minibatch 258::LR 0.0976923076923 --> Loss 0.00357896606127\n",
      "Epoch 2::Minibatch 259::LR 0.0976923076923 --> Loss 0.00180230061213\n",
      "Epoch 2::Minibatch 260::LR 0.0976923076923 --> Loss 0.00182695925236\n",
      "Epoch 2::Minibatch 261::LR 0.0976923076923 --> Loss 0.00302311340968\n",
      "Epoch 2::Minibatch 262::LR 0.0976923076923 --> Loss 0.00200806856155\n",
      "Epoch 2::Minibatch 263::LR 0.0976923076923 --> Loss 0.002311531504\n",
      "Epoch 2::Minibatch 264::LR 0.0976923076923 --> Loss 0.00365529616674\n",
      "Epoch 2::Minibatch 265::LR 0.0976923076923 --> Loss 0.0219887844721\n",
      "Epoch 2::Minibatch 266::LR 0.0976923076923 --> Loss 0.00109455863635\n",
      "Epoch 2::Minibatch 267::LR 0.0976923076923 --> Loss 0.010062828064\n",
      "Epoch 2::Minibatch 268::LR 0.0976923076923 --> Loss 0.00130405505498\n",
      "Epoch 2::Minibatch 269::LR 0.0976923076923 --> Loss 0.00370915770531\n",
      "Epoch 2::Minibatch 270::LR 0.0976923076923 --> Loss 0.00571745435397\n",
      "Epoch 2::Minibatch 271::LR 0.0976923076923 --> Loss 0.00298498292764\n",
      "Epoch 2::Minibatch 272::LR 0.0976923076923 --> Loss 0.00394067168236\n",
      "Epoch 2::Minibatch 273::LR 0.0976923076923 --> Loss 0.00187822639942\n",
      "Epoch 2::Minibatch 274::LR 0.0976923076923 --> Loss 0.00179174562295\n",
      "Epoch 2::Minibatch 275::LR 0.0976923076923 --> Loss 0.00281873643398\n",
      "Epoch 2::Minibatch 276::LR 0.0976923076923 --> Loss 0.00344164609909\n",
      "Epoch 2::Minibatch 277::LR 0.0976923076923 --> Loss 0.00105727483829\n",
      "Epoch 2::Minibatch 278::LR 0.0976923076923 --> Loss 0.00266678591569\n",
      "Epoch 2::Minibatch 279::LR 0.0976923076923 --> Loss 0.00257053633531\n",
      "Epoch 2::Minibatch 280::LR 0.0976923076923 --> Loss 0.00216865976652\n",
      "Epoch 2::Minibatch 281::LR 0.0976923076923 --> Loss 0.00131405711174\n",
      "Epoch 2::Minibatch 282::LR 0.0976923076923 --> Loss 0.00229811767737\n",
      "Epoch 2::Minibatch 283::LR 0.0976923076923 --> Loss 0.00225719710191\n",
      "Epoch 2::Minibatch 284::LR 0.0976923076923 --> Loss 0.00171623309453\n",
      "Epoch 2::Minibatch 285::LR 0.0976923076923 --> Loss 0.00117341309786\n",
      "Epoch 2::Minibatch 286::LR 0.0976923076923 --> Loss 0.00213625510534\n",
      "Epoch 2::Minibatch 287::LR 0.0976923076923 --> Loss 0.00202433665593\n",
      "Epoch 2::Minibatch 288::LR 0.0976923076923 --> Loss 0.00102677971125\n",
      "Epoch 2::Minibatch 289::LR 0.0976923076923 --> Loss 0.00150269508362\n",
      "Epoch 2::Minibatch 290::LR 0.0976923076923 --> Loss 0.00188786904017\n",
      "Epoch 2::Minibatch 291::LR 0.0976923076923 --> Loss 0.00162140756845\n",
      "Epoch 2::Minibatch 292::LR 0.0976923076923 --> Loss 0.000577036688725\n",
      "Epoch 2::Minibatch 293::LR 0.0976923076923 --> Loss 0.00137916256984\n",
      "Epoch 2::Minibatch 294::LR 0.0976923076923 --> Loss 0.00151481628418\n",
      "Epoch 2::Minibatch 295::LR 0.0976923076923 --> Loss 0.00177116413911\n",
      "Epoch 2::Minibatch 296::LR 0.0976923076923 --> Loss 0.00143880953391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 297::LR 0.0976923076923 --> Loss 0.00130844225486\n",
      "Epoch 2::Minibatch 298::LR 0.0976923076923 --> Loss 0.00122208118439\n",
      "Epoch 2::Minibatch 299::LR 0.0976923076923 --> Loss 0.000697258313497\n",
      "Epoch 2::Minibatch 300::LR 0.0976923076923 --> Loss 0.00296160161495\n",
      "Epoch 2::Minibatch 301::LR 0.0976923076923 --> Loss 0.00281055967013\n",
      "Epoch 2::Minibatch 302::LR 0.0976923076923 --> Loss 0.00253561556339\n",
      "Epoch 2::Minibatch 303::LR 0.0976923076923 --> Loss 0.000830012907585\n",
      "Epoch 2::Minibatch 304::LR 0.0976923076923 --> Loss 0.00313446303209\n",
      "Epoch 2::Minibatch 305::LR 0.0976923076923 --> Loss 0.00164690554142\n",
      "Epoch 2::Minibatch 306::LR 0.0976923076923 --> Loss 0.000884269972642\n",
      "Epoch 2::Minibatch 307::LR 0.0976923076923 --> Loss 0.00258748094241\n",
      "Epoch 2::Minibatch 308::LR 0.0976923076923 --> Loss 0.00191920856635\n",
      "Epoch 2::Minibatch 309::LR 0.0976923076923 --> Loss 0.000931875507037\n",
      "Epoch 2::Minibatch 310::LR 0.0976923076923 --> Loss 0.000996078153451\n",
      "Epoch 2::Minibatch 311::LR 0.0976923076923 --> Loss 0.00157924741507\n",
      "Epoch 2::Minibatch 312::LR 0.0976923076923 --> Loss 0.00306595981121\n",
      "Epoch 2::Minibatch 313::LR 0.0976923076923 --> Loss 0.00239172796408\n",
      "Epoch 2::Minibatch 314::LR 0.0976923076923 --> Loss 0.00190063675245\n",
      "Epoch 2::Minibatch 315::LR 0.0976923076923 --> Loss 0.000947712957859\n",
      "Epoch 2::Minibatch 316::LR 0.0976923076923 --> Loss 0.00230312327544\n",
      "Epoch 2::Minibatch 317::LR 0.0976923076923 --> Loss 0.00149541258812\n",
      "Epoch 2::Minibatch 318::LR 0.0976923076923 --> Loss 0.00113490561644\n",
      "Epoch 2::Minibatch 319::LR 0.0976923076923 --> Loss 0.00224414726098\n",
      "Epoch 2::Minibatch 320::LR 0.0976923076923 --> Loss 0.00329935948054\n",
      "Epoch 2::Minibatch 321::LR 0.0976923076923 --> Loss 0.000821626981099\n",
      "Epoch 2::Minibatch 322::LR 0.0976923076923 --> Loss 0.00357835332553\n",
      "Epoch 2::Minibatch 323::LR 0.0976923076923 --> Loss 0.00345854401588\n",
      "Epoch 2::Minibatch 324::LR 0.0976923076923 --> Loss 0.00265240569909\n",
      "Epoch 2::Minibatch 325::LR 0.0976923076923 --> Loss 0.00249299327532\n",
      "Epoch 2::Minibatch 326::LR 0.0976923076923 --> Loss 0.00592153032621\n",
      "Epoch 2::Minibatch 327::LR 0.0976923076923 --> Loss 0.00220213909944\n",
      "Epoch 2::Minibatch 328::LR 0.0976923076923 --> Loss 0.00343760093053\n",
      "Epoch 2::Minibatch 329::LR 0.0976923076923 --> Loss 0.0012178576986\n",
      "Epoch 2::Minibatch 330::LR 0.0976923076923 --> Loss 0.00158089021842\n",
      "Epoch 2::Minibatch 331::LR 0.0976923076923 --> Loss 0.00253354708354\n",
      "Epoch 2::Minibatch 332::LR 0.0976923076923 --> Loss 0.00253720959028\n",
      "Epoch 2::Minibatch 333::LR 0.0976923076923 --> Loss 0.00138368626436\n",
      "Epoch 2::Minibatch 334::LR 0.0976923076923 --> Loss 0.00410440882047\n",
      "Epoch 2::Minibatch 335::LR 0.0976923076923 --> Loss 0.00188481688499\n",
      "Epoch 2::Minibatch 336::LR 0.0976923076923 --> Loss 0.00206278483073\n",
      "Epoch 2::Minibatch 337::LR 0.0976923076923 --> Loss 0.003110790054\n",
      "Epoch 2::Minibatch 338::LR 0.0976923076923 --> Loss 0.000480074038108\n",
      "Epoch 2::Minibatch 339::LR 0.0976923076923 --> Loss 0.00338582118352\n",
      "Epoch 2::Minibatch 340::LR 0.0976923076923 --> Loss 0.00495901346207\n",
      "Epoch 2::Minibatch 341::LR 0.0976923076923 --> Loss 0.00489176511765\n",
      "Epoch 2::Minibatch 342::LR 0.0976923076923 --> Loss 0.00329877416293\n",
      "Epoch 2::Minibatch 343::LR 0.0976923076923 --> Loss 0.00170760671298\n",
      "Epoch 2::Minibatch 344::LR 0.0976923076923 --> Loss 0.00291491727034\n",
      "Epoch 2::Minibatch 345::LR 0.0976923076923 --> Loss 0.00427468260129\n",
      "Epoch 2::Minibatch 346::LR 0.0976923076923 --> Loss 0.00577372113864\n",
      "Epoch 2::Minibatch 347::LR 0.0976923076923 --> Loss 0.000894140899181\n",
      "Epoch 2::Minibatch 348::LR 0.0976923076923 --> Loss 0.00393836855888\n",
      "Epoch 2::Minibatch 349::LR 0.0976923076923 --> Loss 0.00349105993907\n",
      "Epoch 2::Minibatch 350::LR 0.0976923076923 --> Loss 0.00175649702549\n",
      "Epoch 2::Minibatch 351::LR 0.0976923076923 --> Loss 0.0036829662323\n",
      "Epoch 2::Minibatch 352::LR 0.0976923076923 --> Loss 0.00475953141848\n",
      "Epoch 2::Minibatch 353::LR 0.0976923076923 --> Loss 0.00355934063594\n",
      "Epoch 2::Minibatch 354::LR 0.0976923076923 --> Loss 0.00299024264018\n",
      "Epoch 2::Minibatch 355::LR 0.0976923076923 --> Loss 0.00587089737256\n",
      "Epoch 2::Minibatch 356::LR 0.0976923076923 --> Loss 0.00304649134477\n",
      "Epoch 2::Minibatch 357::LR 0.0976923076923 --> Loss 0.00102234890064\n",
      "Epoch 2::Minibatch 358::LR 0.0976923076923 --> Loss 0.00218128363291\n",
      "Epoch 2::Minibatch 359::LR 0.0976923076923 --> Loss 0.00285226901372\n",
      "Epoch 2::Minibatch 360::LR 0.0976923076923 --> Loss 0.0025021280845\n",
      "Epoch 2::Minibatch 361::LR 0.0976923076923 --> Loss 0.0024511851867\n",
      "Epoch 2::Minibatch 362::LR 0.0976923076923 --> Loss 0.00260593314966\n",
      "Epoch 2::Minibatch 363::LR 0.0976923076923 --> Loss 0.000659999549389\n",
      "Epoch 2::Minibatch 364::LR 0.0976923076923 --> Loss 0.00202569484711\n",
      "Epoch 2::Minibatch 365::LR 0.0976923076923 --> Loss 0.00208117922147\n",
      "Epoch 2::Minibatch 366::LR 0.0976923076923 --> Loss 0.00230771223704\n",
      "Epoch 2::Minibatch 367::LR 0.0976923076923 --> Loss 0.00114491413037\n",
      "Epoch 2::Minibatch 368::LR 0.0976923076923 --> Loss 0.000972111523151\n",
      "Epoch 2::Minibatch 369::LR 0.0976923076923 --> Loss 0.00291915973028\n",
      "Epoch 2::Minibatch 370::LR 0.0976923076923 --> Loss 0.00223900834719\n",
      "Epoch 2::Minibatch 371::LR 0.0976923076923 --> Loss 0.0018754384915\n",
      "Epoch 2::Minibatch 372::LR 0.0976923076923 --> Loss 0.000416157419483\n",
      "Epoch 2::Minibatch 373::LR 0.0976923076923 --> Loss 0.00172779877981\n",
      "Epoch 2::Minibatch 374::LR 0.0976923076923 --> Loss 0.00206312159697\n",
      "Epoch 2::Minibatch 375::LR 0.0976923076923 --> Loss 0.0017803833882\n",
      "Epoch 2::Minibatch 376::LR 0.0976923076923 --> Loss 0.00120468089978\n",
      "Epoch 2::Minibatch 377::LR 0.0976923076923 --> Loss 0.00192484358946\n",
      "Epoch 2::Minibatch 378::LR 0.0976923076923 --> Loss 0.00207460522652\n",
      "Epoch 2::Minibatch 379::LR 0.0976923076923 --> Loss 0.00237155457338\n",
      "Epoch 2::Minibatch 380::LR 0.0976923076923 --> Loss 0.00157684793075\n",
      "Epoch 2::Minibatch 381::LR 0.0976923076923 --> Loss 0.000944825212161\n",
      "Epoch 2::Minibatch 382::LR 0.0976923076923 --> Loss 0.00196603397528\n",
      "Epoch 2::Minibatch 383::LR 0.0976923076923 --> Loss 0.00184250632922\n",
      "Epoch 2::Minibatch 384::LR 0.0976923076923 --> Loss 0.00100015431643\n",
      "Epoch 2::Minibatch 385::LR 0.0976923076923 --> Loss 0.000988368491332\n",
      "Epoch 2::Minibatch 386::LR 0.0976923076923 --> Loss 0.00209515810013\n",
      "Epoch 2::Minibatch 387::LR 0.0976923076923 --> Loss 0.00224221368631\n",
      "Epoch 2::Minibatch 388::LR 0.0976923076923 --> Loss 0.00109557569027\n",
      "Epoch 2::Minibatch 389::LR 0.0976923076923 --> Loss 0.00181702593962\n",
      "Epoch 2::Minibatch 390::LR 0.0976923076923 --> Loss 0.00368398984273\n",
      "Epoch 2::Minibatch 391::LR 0.0976923076923 --> Loss 0.00265626768271\n",
      "Epoch 2::Minibatch 392::LR 0.0976923076923 --> Loss 0.00260671794415\n",
      "Epoch 2::Minibatch 393::LR 0.0976923076923 --> Loss 0.00273249049981\n",
      "Epoch 2::Minibatch 394::LR 0.0976923076923 --> Loss 0.00218058506648\n",
      "Epoch 2::Minibatch 395::LR 0.0976923076923 --> Loss 0.0019828214248\n",
      "Epoch 2::Minibatch 396::LR 0.0976923076923 --> Loss 0.00189731478691\n",
      "Epoch 2::Minibatch 397::LR 0.0976923076923 --> Loss 0.00203158795834\n",
      "Epoch 2::Minibatch 398::LR 0.0976923076923 --> Loss 0.00197021722794\n",
      "Epoch 2::Minibatch 399::LR 0.0976923076923 --> Loss 0.00228222290675\n",
      "Epoch 2::Minibatch 400::LR 0.0976923076923 --> Loss 0.00196562945843\n",
      "Epoch 2::Minibatch 401::LR 0.0976923076923 --> Loss 0.00344794273376\n",
      "Epoch 2::Minibatch 402::LR 0.0976923076923 --> Loss 0.00195491413275\n",
      "Epoch 2::Minibatch 403::LR 0.0976923076923 --> Loss 0.00146063745022\n",
      "Epoch 2::Minibatch 404::LR 0.0976923076923 --> Loss 0.00141214330991\n",
      "Epoch 2::Minibatch 405::LR 0.0976923076923 --> Loss 0.00324492275715\n",
      "Epoch 2::Minibatch 406::LR 0.0976923076923 --> Loss 0.00236325204372\n",
      "Epoch 2::Minibatch 407::LR 0.0976923076923 --> Loss 0.00167843103409\n",
      "Epoch 2::Minibatch 408::LR 0.0976923076923 --> Loss 0.000429425736268\n",
      "Epoch 2::Minibatch 409::LR 0.0976923076923 --> Loss 0.00226289550463\n",
      "Epoch 2::Minibatch 410::LR 0.0976923076923 --> Loss 0.00315957109133\n",
      "Epoch 2::Minibatch 411::LR 0.0976923076923 --> Loss 0.00147005508343\n",
      "Epoch 2::Minibatch 412::LR 0.0976923076923 --> Loss 0.000884141425292\n",
      "Epoch 2::Minibatch 413::LR 0.0976923076923 --> Loss 0.00180660049121\n",
      "Epoch 2::Minibatch 414::LR 0.0976923076923 --> Loss 0.00175034443537\n",
      "Epoch 2::Minibatch 415::LR 0.0976923076923 --> Loss 0.00105329334736\n",
      "Epoch 2::Minibatch 416::LR 0.0976923076923 --> Loss 0.000757408291101\n",
      "Epoch 2::Minibatch 417::LR 0.0976923076923 --> Loss 0.00161468068759\n",
      "Epoch 2::Minibatch 418::LR 0.0976923076923 --> Loss 0.00271011988322\n",
      "Epoch 2::Minibatch 419::LR 0.0976923076923 --> Loss 0.000516558239857\n",
      "Epoch 2::Minibatch 420::LR 0.0976923076923 --> Loss 0.000656906465689\n",
      "Epoch 2::Minibatch 421::LR 0.0976923076923 --> Loss 0.00195261061192\n",
      "Epoch 2::Minibatch 422::LR 0.0976923076923 --> Loss 0.00218121111393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 423::LR 0.0976923076923 --> Loss 0.000966869294643\n",
      "Epoch 2::Minibatch 424::LR 0.0976923076923 --> Loss 0.0014863294363\n",
      "Epoch 2::Minibatch 425::LR 0.0976923076923 --> Loss 0.00279877901077\n",
      "Epoch 2::Minibatch 426::LR 0.0976923076923 --> Loss 0.0018839130799\n",
      "Epoch 2::Minibatch 427::LR 0.0976923076923 --> Loss 0.000728454440832\n",
      "Epoch 2::Minibatch 428::LR 0.0976923076923 --> Loss 0.00116833299398\n",
      "Epoch 2::Minibatch 429::LR 0.0976923076923 --> Loss 0.00255344311396\n",
      "Epoch 2::Minibatch 430::LR 0.0976923076923 --> Loss 0.0104400960604\n",
      "Epoch 2::Minibatch 431::LR 0.0976923076923 --> Loss 0.00449169397354\n",
      "Epoch 2::Minibatch 432::LR 0.0976923076923 --> Loss 0.00481169342995\n",
      "Epoch 2::Minibatch 433::LR 0.0976923076923 --> Loss 0.00255321760972\n",
      "Epoch 2::Minibatch 434::LR 0.0976923076923 --> Loss 0.00266114811103\n",
      "Epoch 2::Minibatch 435::LR 0.0976923076923 --> Loss 0.00236492156982\n",
      "Epoch 2::Minibatch 436::LR 0.0976923076923 --> Loss 0.00158317973216\n",
      "Epoch 2::Minibatch 437::LR 0.0976923076923 --> Loss 0.00307689944903\n",
      "Epoch 2::Minibatch 438::LR 0.0976923076923 --> Loss 0.00257171134154\n",
      "Epoch 2::Minibatch 439::LR 0.0976923076923 --> Loss 0.00204003453255\n",
      "Epoch 2::Minibatch 440::LR 0.0976923076923 --> Loss 0.00316540181637\n",
      "Epoch 2::Minibatch 441::LR 0.0976923076923 --> Loss 0.00301736255487\n",
      "Epoch 2::Minibatch 442::LR 0.0976923076923 --> Loss 0.00264698465665\n",
      "Epoch 2::Minibatch 443::LR 0.0976923076923 --> Loss 0.00352057655652\n",
      "Epoch 2::Minibatch 444::LR 0.0976923076923 --> Loss 0.00270030319691\n",
      "Epoch 2::Minibatch 445::LR 0.0976923076923 --> Loss 0.00084854632616\n",
      "Epoch 2::Minibatch 446::LR 0.0976923076923 --> Loss 0.00148275007804\n",
      "Epoch 2::Minibatch 447::LR 0.0976923076923 --> Loss 0.00234285394351\n",
      "Epoch 2::Minibatch 448::LR 0.0976923076923 --> Loss 0.00232331156731\n",
      "Epoch 2::Minibatch 449::LR 0.0976923076923 --> Loss 0.00367875893911\n",
      "Epoch 2::Minibatch 450::LR 0.0976923076923 --> Loss 0.00211322406928\n",
      "Epoch 2::Minibatch 451::LR 0.0976923076923 --> Loss 0.00424540638924\n",
      "Epoch 2::Minibatch 452::LR 0.0976923076923 --> Loss 0.00239617129167\n",
      "Epoch 2::Minibatch 453::LR 0.0976923076923 --> Loss 0.000343059475223\n",
      "Epoch 2::Minibatch 454::LR 0.0976923076923 --> Loss 0.00337092200915\n",
      "Epoch 2::Minibatch 455::LR 0.0976923076923 --> Loss 0.00259894152482\n",
      "Epoch 2::Minibatch 456::LR 0.0976923076923 --> Loss 0.00310547828674\n",
      "Epoch 2::Minibatch 457::LR 0.0976923076923 --> Loss 0.0019142862161\n",
      "Epoch 2::Minibatch 458::LR 0.0976923076923 --> Loss 0.000693274239699\n",
      "Epoch 2::Minibatch 459::LR 0.0976923076923 --> Loss 0.00405350406965\n",
      "Epoch 2::Minibatch 460::LR 0.0976923076923 --> Loss 0.00253750622272\n",
      "Epoch 2::Minibatch 461::LR 0.0976923076923 --> Loss 0.00397918224335\n",
      "Epoch 2::Minibatch 462::LR 0.0976923076923 --> Loss 0.000349143172304\n",
      "Epoch 2::Minibatch 463::LR 0.0976923076923 --> Loss 0.00455545107524\n",
      "Epoch 2::Minibatch 464::LR 0.0976923076923 --> Loss 0.00198647876581\n",
      "Epoch 2::Minibatch 465::LR 0.0976923076923 --> Loss 0.00469638943672\n",
      "Epoch 2::Minibatch 466::LR 0.0976923076923 --> Loss 0.00500071048737\n",
      "Epoch 2::Minibatch 467::LR 0.0976923076923 --> Loss 0.00565298279126\n",
      "Epoch 2::Minibatch 468::LR 0.0976923076923 --> Loss 0.00588042616844\n",
      "Epoch 2::Minibatch 469::LR 0.0976923076923 --> Loss 0.00589802622795\n",
      "Epoch 2::Minibatch 470::LR 0.0976923076923 --> Loss 0.00355991959572\n",
      "Epoch 2::Minibatch 471::LR 0.0976923076923 --> Loss 0.0017165072759\n",
      "Epoch 2::Minibatch 472::LR 0.0976923076923 --> Loss 0.00350438992182\n",
      "Epoch 2::Minibatch 473::LR 0.0976923076923 --> Loss 0.00224980115891\n",
      "Epoch 2::Minibatch 474::LR 0.0976923076923 --> Loss 0.000639440764983\n",
      "Epoch 2::Minibatch 475::LR 0.0976923076923 --> Loss 0.00399952173233\n",
      "Epoch 2::Minibatch 476::LR 0.0976923076923 --> Loss 0.006165056626\n",
      "Epoch 2::Minibatch 477::LR 0.0976923076923 --> Loss 0.000937408804893\n",
      "Epoch 2::Minibatch 478::LR 0.0976923076923 --> Loss 0.00254715899626\n",
      "Epoch 2::Minibatch 479::LR 0.0976923076923 --> Loss 0.00199403047562\n",
      "Epoch 2::Minibatch 480::LR 0.0976923076923 --> Loss 0.00159673511982\n",
      "Epoch 2::Minibatch 481::LR 0.0976923076923 --> Loss 0.000980882445971\n",
      "Epoch 2::Minibatch 482::LR 0.0976923076923 --> Loss 0.00213883320491\n",
      "Epoch 2::Minibatch 483::LR 0.0976923076923 --> Loss 0.00339826901754\n",
      "Epoch 2::Minibatch 484::LR 0.0976923076923 --> Loss 0.00365368485451\n",
      "Epoch 2::Minibatch 485::LR 0.0976923076923 --> Loss 0.000745907823245\n",
      "Epoch 2::Minibatch 486::LR 0.0976923076923 --> Loss 0.00326414783796\n",
      "Epoch 2::Minibatch 487::LR 0.0976923076923 --> Loss 0.00343657573064\n",
      "Epoch 2::Minibatch 488::LR 0.0976923076923 --> Loss 0.00207570572694\n",
      "Epoch 2::Minibatch 489::LR 0.0976923076923 --> Loss 0.00337527990341\n",
      "Epoch 2::Minibatch 490::LR 0.0976923076923 --> Loss 0.000379343231519\n",
      "Epoch 2::Minibatch 491::LR 0.0976923076923 --> Loss 0.00462556242943\n",
      "Epoch 2::Minibatch 492::LR 0.0976923076923 --> Loss 0.00298699021339\n",
      "Epoch 2::Minibatch 493::LR 0.0976923076923 --> Loss 0.00314596553644\n",
      "Epoch 2::Minibatch 494::LR 0.0976923076923 --> Loss 0.000714784463247\n",
      "Epoch 2::Minibatch 495::LR 0.0976923076923 --> Loss 0.00191608111064\n",
      "Epoch 2::Minibatch 496::LR 0.0976923076923 --> Loss 0.00297197163105\n",
      "Epoch 2::Minibatch 497::LR 0.0976923076923 --> Loss 0.000904369155566\n",
      "Epoch 2::Minibatch 498::LR 0.0976923076923 --> Loss 0.000530742208163\n",
      "Epoch 2::Minibatch 499::LR 0.0976923076923 --> Loss 0.00401267369588\n",
      "Epoch 2::Minibatch 500::LR 0.0976923076923 --> Loss 0.00149075716734\n",
      "Epoch 2::Minibatch 501::LR 0.0976923076923 --> Loss 0.00240432659785\n",
      "Epoch 2::Minibatch 502::LR 0.0976923076923 --> Loss 0.00391073783239\n",
      "Epoch 2::Minibatch 503::LR 0.0976923076923 --> Loss 0.00934890270233\n",
      "Epoch 2::Minibatch 504::LR 0.0976923076923 --> Loss 0.0090255522728\n",
      "Epoch 2::Minibatch 505::LR 0.0976923076923 --> Loss 0.0042722539107\n",
      "Epoch 2::Minibatch 506::LR 0.0976923076923 --> Loss 0.00332229395707\n",
      "Epoch 2::Minibatch 507::LR 0.0976923076923 --> Loss 0.00604299545288\n",
      "Epoch 2::Minibatch 508::LR 0.0976923076923 --> Loss 0.00334176778793\n",
      "Epoch 2::Minibatch 509::LR 0.0976923076923 --> Loss 0.00511401136716\n",
      "Epoch 2::Minibatch 510::LR 0.0976923076923 --> Loss 0.00504703124364\n",
      "Epoch 2::Minibatch 511::LR 0.0976923076923 --> Loss 0.00378712018331\n",
      "Epoch 2::Minibatch 512::LR 0.0976923076923 --> Loss 0.00282225728035\n",
      "Epoch 2::Minibatch 513::LR 0.0976923076923 --> Loss 0.000806379069885\n",
      "Epoch 2::Minibatch 514::LR 0.0976923076923 --> Loss 0.0026490787665\n",
      "Epoch 2::Minibatch 515::LR 0.0976923076923 --> Loss 0.00299237529437\n",
      "Epoch 2::Minibatch 516::LR 0.0976923076923 --> Loss 0.00371878862381\n",
      "Epoch 2::Minibatch 517::LR 0.0976923076923 --> Loss 0.00310990154743\n",
      "Epoch 2::Minibatch 518::LR 0.0976923076923 --> Loss 0.00253042697906\n",
      "Epoch 2::Minibatch 519::LR 0.0976923076923 --> Loss 0.00331259985765\n",
      "Epoch 2::Minibatch 520::LR 0.0976923076923 --> Loss 0.00481986999512\n",
      "Epoch 2::Minibatch 521::LR 0.0976923076923 --> Loss 0.00498936613401\n",
      "Epoch 2::Minibatch 522::LR 0.0976923076923 --> Loss 0.00682389656703\n",
      "Epoch 2::Minibatch 523::LR 0.0976923076923 --> Loss 0.000604554563761\n",
      "Epoch 2::Minibatch 524::LR 0.0976923076923 --> Loss 0.00142142365376\n",
      "Epoch 2::Minibatch 525::LR 0.0976923076923 --> Loss 0.00336883664131\n",
      "Epoch 2::Minibatch 526::LR 0.0976923076923 --> Loss 0.00423564235369\n",
      "Epoch 2::Minibatch 527::LR 0.0976923076923 --> Loss 0.00260546088219\n",
      "Epoch 2::Minibatch 528::LR 0.0976923076923 --> Loss 0.00126600762208\n",
      "Epoch 2::Minibatch 529::LR 0.0976923076923 --> Loss 0.00430590311686\n",
      "Epoch 2::Minibatch 530::LR 0.0976923076923 --> Loss 0.00434763630231\n",
      "Epoch 2::Minibatch 531::LR 0.0976923076923 --> Loss 0.00367208639781\n",
      "Epoch 2::Minibatch 532::LR 0.0976923076923 --> Loss 0.00272483785947\n",
      "Epoch 2::Minibatch 533::LR 0.0976923076923 --> Loss 0.00488149881363\n",
      "Epoch 2::Minibatch 534::LR 0.0976923076923 --> Loss 0.0033547993501\n",
      "Epoch 2::Minibatch 535::LR 0.0976923076923 --> Loss 0.00314519862334\n",
      "Epoch 2::Minibatch 536::LR 0.0976923076923 --> Loss 0.00216436684132\n",
      "Epoch 2::Minibatch 537::LR 0.0976923076923 --> Loss 0.000659697602193\n",
      "Epoch 2::Minibatch 538::LR 0.0976923076923 --> Loss 0.00170989314715\n",
      "Epoch 2::Minibatch 539::LR 0.0976923076923 --> Loss 0.00345910867055\n",
      "Epoch 2::Minibatch 540::LR 0.0976923076923 --> Loss 0.00333222111066\n",
      "Epoch 2::Minibatch 541::LR 0.0976923076923 --> Loss 0.0029153807958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 542::LR 0.0976923076923 --> Loss 0.00254897912343\n",
      "Epoch 2::Minibatch 543::LR 0.0976923076923 --> Loss 0.00284484068553\n",
      "Epoch 2::Minibatch 544::LR 0.0976923076923 --> Loss 0.00400080005328\n",
      "Epoch 2::Minibatch 545::LR 0.0976923076923 --> Loss 0.00203608016173\n",
      "Epoch 2::Minibatch 546::LR 0.0976923076923 --> Loss 0.000611423750718\n",
      "Epoch 2::Minibatch 547::LR 0.0976923076923 --> Loss 0.00261287907759\n",
      "Epoch 2::Minibatch 548::LR 0.0976923076923 --> Loss 0.00400991360346\n",
      "Epoch 2::Minibatch 549::LR 0.0976923076923 --> Loss 0.00854446490606\n",
      "Epoch 2::Minibatch 550::LR 0.0976923076923 --> Loss 0.00113282630841\n",
      "Epoch 2::Minibatch 551::LR 0.0976923076923 --> Loss 0.00237916151683\n",
      "Epoch 2::Minibatch 552::LR 0.0976923076923 --> Loss 0.0035082979997\n",
      "Epoch 2::Minibatch 553::LR 0.0976923076923 --> Loss 0.00316725850105\n",
      "Epoch 2::Minibatch 554::LR 0.0976923076923 --> Loss 0.00414972821871\n",
      "Epoch 2::Minibatch 555::LR 0.0976923076923 --> Loss 0.00100971659025\n",
      "Epoch 2::Minibatch 556::LR 0.0976923076923 --> Loss 0.00204982936382\n",
      "Epoch 2::Minibatch 557::LR 0.0976923076923 --> Loss 0.00246913353602\n",
      "Epoch 2::Minibatch 558::LR 0.0976923076923 --> Loss 0.00386757532756\n",
      "Epoch 2::Minibatch 559::LR 0.0976923076923 --> Loss 0.00373932719231\n",
      "Epoch 2::Minibatch 560::LR 0.0976923076923 --> Loss 0.00311367213726\n",
      "Epoch 2::Minibatch 561::LR 0.0976923076923 --> Loss 0.00273550967375\n",
      "Epoch 2::Minibatch 562::LR 0.0976923076923 --> Loss 0.00243530631065\n",
      "Epoch 2::Minibatch 563::LR 0.0976923076923 --> Loss 0.00433647712072\n",
      "Epoch 2::Minibatch 564::LR 0.0976923076923 --> Loss 0.00316758334637\n",
      "Epoch 2::Minibatch 565::LR 0.0976923076923 --> Loss 0.00370669682821\n",
      "Epoch 2::Minibatch 566::LR 0.0976923076923 --> Loss 0.00229447384675\n",
      "Epoch 2::Minibatch 567::LR 0.0976923076923 --> Loss 0.00253865381082\n",
      "Epoch 2::Minibatch 568::LR 0.0976923076923 --> Loss 0.00187794446945\n",
      "Epoch 2::Minibatch 569::LR 0.0976923076923 --> Loss 0.000564459611972\n",
      "Epoch 2::Minibatch 570::LR 0.0976923076923 --> Loss 0.00174056609472\n",
      "Epoch 2::Minibatch 571::LR 0.0976923076923 --> Loss 0.00230992933114\n",
      "Epoch 2::Minibatch 572::LR 0.0976923076923 --> Loss 0.0024382130305\n",
      "Epoch 2::Minibatch 573::LR 0.0976923076923 --> Loss 0.00155276278655\n",
      "Epoch 2::Minibatch 574::LR 0.0976923076923 --> Loss 0.00104019413392\n",
      "Epoch 2::Minibatch 575::LR 0.0976923076923 --> Loss 0.00183801114559\n",
      "Epoch 2::Minibatch 576::LR 0.0976923076923 --> Loss 0.0020973632733\n",
      "Epoch 2::Minibatch 577::LR 0.0976923076923 --> Loss 0.00169068892797\n",
      "Epoch 2::Minibatch 578::LR 0.0976923076923 --> Loss 0.0013406487306\n",
      "Epoch 2::Minibatch 579::LR 0.0976923076923 --> Loss 0.00122948080301\n",
      "Epoch 2::Minibatch 580::LR 0.0976923076923 --> Loss 0.00196978251139\n",
      "Epoch 2::Minibatch 581::LR 0.0976923076923 --> Loss 0.00170956710974\n",
      "Epoch 2::Minibatch 582::LR 0.0976923076923 --> Loss 0.00417806506157\n",
      "Epoch 2::Minibatch 583::LR 0.0976923076923 --> Loss 0.000948781470458\n",
      "Epoch 2::Minibatch 584::LR 0.0976923076923 --> Loss 0.0013062402606\n",
      "Epoch 2::Minibatch 585::LR 0.0976923076923 --> Loss 0.00540253082911\n",
      "Epoch 2::Minibatch 586::LR 0.0976923076923 --> Loss 0.00427611986796\n",
      "Epoch 2::Minibatch 587::LR 0.0976923076923 --> Loss 0.00115825563669\n",
      "Epoch 2::Minibatch 588::LR 0.0976923076923 --> Loss 0.0014100342989\n",
      "Epoch 2::Minibatch 589::LR 0.0976923076923 --> Loss 0.00280475298564\n",
      "Epoch 2::Minibatch 590::LR 0.0976923076923 --> Loss 0.00196822742621\n",
      "Epoch 2::Minibatch 591::LR 0.0976923076923 --> Loss 0.00277744730314\n",
      "Epoch 2::Minibatch 592::LR 0.0976923076923 --> Loss 0.00120839804411\n",
      "Epoch 2::Minibatch 593::LR 0.0976923076923 --> Loss 0.00253422300021\n",
      "Epoch 2::Minibatch 594::LR 0.0976923076923 --> Loss 0.00291972160339\n",
      "Epoch 2::Minibatch 595::LR 0.0976923076923 --> Loss 0.00304719686508\n",
      "Epoch 2::Minibatch 596::LR 0.0976923076923 --> Loss 0.00198687573274\n",
      "Epoch 2::Minibatch 597::LR 0.0976923076923 --> Loss 0.00120498408874\n",
      "Epoch 2::Minibatch 598::LR 0.0976923076923 --> Loss 0.00296476582686\n",
      "Epoch 2::Minibatch 599::LR 0.0976923076923 --> Loss 0.0018837527434\n",
      "Epoch 2::Minibatch 600::LR 0.0976923076923 --> Loss 0.00229753533999\n",
      "Epoch 2::Minibatch 601::LR 0.0976923076923 --> Loss 0.00363780975342\n",
      "Epoch 2::Minibatch 602::LR 0.0976923076923 --> Loss 0.00211287339528\n",
      "Epoch 2::Minibatch 603::LR 0.0976923076923 --> Loss 0.00270087937514\n",
      "Epoch 2::Minibatch 604::LR 0.0976923076923 --> Loss 0.00169516106447\n",
      "Epoch 2::Minibatch 605::LR 0.0976923076923 --> Loss 0.00241423328718\n",
      "Epoch 2::Minibatch 606::LR 0.0976923076923 --> Loss 0.00198039968808\n",
      "Epoch 2::Minibatch 607::LR 0.0976923076923 --> Loss 0.000844720204671\n",
      "Epoch 2::Minibatch 608::LR 0.0976923076923 --> Loss 0.00157538612684\n",
      "Epoch 2::Minibatch 609::LR 0.0976923076923 --> Loss 0.00238524158796\n",
      "Epoch 2::Minibatch 610::LR 0.0976923076923 --> Loss 0.00349568804105\n",
      "Epoch 2::Minibatch 611::LR 0.0976923076923 --> Loss 0.0023188072443\n",
      "Epoch 2::Minibatch 612::LR 0.0976923076923 --> Loss 0.000463186701139\n",
      "Epoch 2::Minibatch 613::LR 0.0976923076923 --> Loss 0.00131405452887\n",
      "Epoch 2::Minibatch 614::LR 0.0976923076923 --> Loss 0.00236957748731\n",
      "Epoch 2::Minibatch 615::LR 0.0976923076923 --> Loss 0.00171450853348\n",
      "Epoch 2::Minibatch 616::LR 0.0976923076923 --> Loss 0.000929401516914\n",
      "Epoch 2::Minibatch 617::LR 0.0976923076923 --> Loss 0.00047581076622\n",
      "Epoch 2::Minibatch 618::LR 0.0976923076923 --> Loss 0.00245690584183\n",
      "Epoch 2::Minibatch 619::LR 0.0976923076923 --> Loss 0.00191855748494\n",
      "Epoch 2::Minibatch 620::LR 0.0976923076923 --> Loss 0.00172874768575\n",
      "Epoch 2::Minibatch 621::LR 0.0976923076923 --> Loss 0.000843005776405\n",
      "Epoch 2::Minibatch 622::LR 0.0976923076923 --> Loss 0.000766221930583\n",
      "Epoch 2::Minibatch 623::LR 0.0976923076923 --> Loss 0.00221554319064\n",
      "Epoch 2::Minibatch 624::LR 0.0976923076923 --> Loss 0.00180025994778\n",
      "Epoch 2::Minibatch 625::LR 0.0976923076923 --> Loss 0.00307467122873\n",
      "Epoch 2::Minibatch 626::LR 0.0976923076923 --> Loss 0.00482607046763\n",
      "Epoch 2::Minibatch 627::LR 0.0976923076923 --> Loss 0.00132996410131\n",
      "Epoch 2::Minibatch 628::LR 0.0976923076923 --> Loss 0.000881592233976\n",
      "Epoch 2::Minibatch 629::LR 0.0976923076923 --> Loss 0.00346035480499\n",
      "Epoch 2::Minibatch 630::LR 0.0976923076923 --> Loss 0.00328973690669\n",
      "Epoch 2::Minibatch 631::LR 0.0976923076923 --> Loss 0.00511273622513\n",
      "Epoch 2::Minibatch 632::LR 0.0976923076923 --> Loss 0.000787847538789\n",
      "Epoch 2::Minibatch 633::LR 0.0976923076923 --> Loss 0.00160870273908\n",
      "Epoch 2::Minibatch 634::LR 0.0976923076923 --> Loss 0.00309137403965\n",
      "Epoch 2::Minibatch 635::LR 0.0976923076923 --> Loss 0.00498035828273\n",
      "Epoch 2::Minibatch 636::LR 0.0976923076923 --> Loss 0.00492746710777\n",
      "Epoch 2::Minibatch 637::LR 0.0976923076923 --> Loss 0.000805245886246\n",
      "Epoch 2::Minibatch 638::LR 0.0976923076923 --> Loss 0.00159468024969\n",
      "Epoch 2::Minibatch 639::LR 0.0976923076923 --> Loss 0.00336837569873\n",
      "Epoch 2::Minibatch 640::LR 0.0976923076923 --> Loss 0.00483121275902\n",
      "Epoch 2::Minibatch 641::LR 0.0976923076923 --> Loss 0.00308925032616\n",
      "Epoch 2::Minibatch 642::LR 0.0976923076923 --> Loss 0.000504981378714\n",
      "Epoch 2::Minibatch 643::LR 0.0976923076923 --> Loss 0.00227108220259\n",
      "Epoch 2::Minibatch 644::LR 0.0976923076923 --> Loss 0.0038007970651\n",
      "Epoch 2::Minibatch 645::LR 0.0976923076923 --> Loss 0.00385905941327\n",
      "Epoch 2::Minibatch 646::LR 0.0976923076923 --> Loss 0.00151290138563\n",
      "Epoch 2::Minibatch 647::LR 0.0976923076923 --> Loss 0.000583898872137\n",
      "Epoch 2::Minibatch 648::LR 0.0976923076923 --> Loss 0.00288124700387\n",
      "Epoch 2::Minibatch 649::LR 0.0976923076923 --> Loss 0.00335843920708\n",
      "Epoch 2::Minibatch 650::LR 0.0976923076923 --> Loss 0.00320073922475\n",
      "Epoch 2::Minibatch 651::LR 0.0976923076923 --> Loss 0.001354722778\n",
      "Epoch 2::Minibatch 652::LR 0.0976923076923 --> Loss 0.000790180812279\n",
      "Epoch 2::Minibatch 653::LR 0.0976923076923 --> Loss 0.00274905502796\n",
      "Epoch 2::Minibatch 654::LR 0.0976923076923 --> Loss 0.00290195385615\n",
      "Epoch 2::Minibatch 655::LR 0.0976923076923 --> Loss 0.00343199014664\n",
      "Epoch 2::Minibatch 656::LR 0.0976923076923 --> Loss 0.000722344170014\n",
      "Epoch 2::Minibatch 657::LR 0.0976923076923 --> Loss 0.00209601223469\n",
      "Epoch 2::Minibatch 658::LR 0.0976923076923 --> Loss 0.0052301299572\n",
      "Epoch 2::Minibatch 659::LR 0.0976923076923 --> Loss 0.00233136852582\n",
      "Epoch 2::Minibatch 660::LR 0.0976923076923 --> Loss 0.0024946363767\n",
      "Epoch 2::Minibatch 661::LR 0.0976923076923 --> Loss 0.00246352990468\n",
      "Epoch 2::Minibatch 662::LR 0.0976923076923 --> Loss 0.00177837649981\n",
      "Epoch 2::Minibatch 663::LR 0.0976923076923 --> Loss 0.00349371393522\n",
      "Epoch 2::Minibatch 664::LR 0.0976923076923 --> Loss 0.00345376412074\n",
      "Epoch 2::Minibatch 665::LR 0.0976923076923 --> Loss 0.000739617198706\n",
      "Epoch 2::Minibatch 666::LR 0.0976923076923 --> Loss 0.00383049170176\n",
      "Epoch 2::Minibatch 667::LR 0.0976923076923 --> Loss 0.00252900203069\n",
      "Epoch 2::Minibatch 668::LR 0.0976923076923 --> Loss 0.0073975666364\n",
      "Epoch 2::Minibatch 669::LR 0.0976923076923 --> Loss 0.00112031817436\n",
      "Epoch 2::Minibatch 670::LR 0.0976923076923 --> Loss 0.00131176759799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 671::LR 0.0976923076923 --> Loss 0.00539439876874\n",
      "Epoch 2::Minibatch 672::LR 0.0976923076923 --> Loss 0.00386722405752\n",
      "Epoch 2::Minibatch 673::LR 0.0976923076923 --> Loss 0.00163038174311\n",
      "Epoch 2::Minibatch 674::LR 0.0976923076923 --> Loss 0.000514232416948\n",
      "Epoch 2::Minibatch 675::LR 0.0976923076923 --> Loss 0.00217435598373\n",
      "Epoch 2::Minibatch 676::LR 0.0976923076923 --> Loss 0.00209599971771\n",
      "Epoch 2::Minibatch 677::LR 0.0976923076923 --> Loss 0.00277470608552\n",
      "Epoch 2::Minibatch 678::LR 0.0976923076923 --> Loss 0.00192230840524\n",
      "Epoch 2::Minibatch 679::LR 0.0976923076923 --> Loss 0.0035882238547\n",
      "Epoch 2::Minibatch 680::LR 0.0976923076923 --> Loss 0.00212632119656\n",
      "Epoch 2::Minibatch 681::LR 0.0976923076923 --> Loss 0.00247651795546\n",
      "Epoch 2::Minibatch 682::LR 0.0976923076923 --> Loss 0.000771530667941\n",
      "Epoch 2::Minibatch 683::LR 0.0976923076923 --> Loss 0.00230336467425\n",
      "Epoch 2::Minibatch 684::LR 0.0976923076923 --> Loss 0.00228714684645\n",
      "Epoch 2::Minibatch 685::LR 0.0976923076923 --> Loss 0.00293143868446\n",
      "Epoch 2::Minibatch 686::LR 0.0976923076923 --> Loss 0.0015101369222\n",
      "Epoch 2::Minibatch 687::LR 0.0976923076923 --> Loss 0.000812354485194\n",
      "Epoch 2::Minibatch 688::LR 0.0976923076923 --> Loss 0.00269942740599\n",
      "Epoch 2::Minibatch 689::LR 0.0976923076923 --> Loss 0.0024628218015\n",
      "Epoch 2::Minibatch 690::LR 0.0976923076923 --> Loss 0.00191279967626\n",
      "Epoch 2::Minibatch 691::LR 0.0976923076923 --> Loss 0.000663556108872\n",
      "Epoch 2::Minibatch 692::LR 0.0976923076923 --> Loss 0.00238243480523\n",
      "Epoch 2::Minibatch 693::LR 0.0976923076923 --> Loss 0.00246892988682\n",
      "Epoch 2::Minibatch 694::LR 0.0976923076923 --> Loss 0.00305520494779\n",
      "Epoch 2::Minibatch 695::LR 0.0976923076923 --> Loss 0.00178315560023\n",
      "Epoch 2::Minibatch 696::LR 0.0976923076923 --> Loss 0.00214865307013\n",
      "Epoch 2::Minibatch 697::LR 0.0976923076923 --> Loss 0.00138186166684\n",
      "Epoch 2::Minibatch 698::LR 0.0976923076923 --> Loss 0.00162699818611\n",
      "Epoch 2::Minibatch 699::LR 0.0976923076923 --> Loss 0.00396361788114\n",
      "Epoch 2::Minibatch 700::LR 0.0976923076923 --> Loss 0.0026384506623\n",
      "Epoch 2::Minibatch 701::LR 0.0976923076923 --> Loss 0.00194593230883\n",
      "Epoch 2::Minibatch 702::LR 0.0976923076923 --> Loss 0.00162163813909\n",
      "Epoch 2::Minibatch 703::LR 0.0976923076923 --> Loss 0.00432855208715\n",
      "Epoch 2::Minibatch 704::LR 0.0976923076923 --> Loss 0.00183047453562\n",
      "Epoch 2::Minibatch 705::LR 0.0976923076923 --> Loss 0.00283508439859\n",
      "Epoch 2::Minibatch 706::LR 0.0976923076923 --> Loss 0.00215783119202\n",
      "Epoch 2::Minibatch 707::LR 0.0976923076923 --> Loss 0.00118637889624\n",
      "Epoch 2::Minibatch 708::LR 0.0976923076923 --> Loss 0.00172540704409\n",
      "Epoch 2::Minibatch 709::LR 0.0976923076923 --> Loss 0.00166632086039\n",
      "Epoch 2::Minibatch 710::LR 0.0976923076923 --> Loss 0.00240370512009\n",
      "Epoch 2::Minibatch 711::LR 0.0976923076923 --> Loss 0.00179450293382\n",
      "Epoch 2::Minibatch 712::LR 0.0976923076923 --> Loss 0.00135504047076\n",
      "Epoch 2::Minibatch 713::LR 0.0976923076923 --> Loss 0.00177404205004\n",
      "Epoch 2::Minibatch 714::LR 0.0976923076923 --> Loss 0.00258865733941\n",
      "Epoch 2::Minibatch 715::LR 0.0976923076923 --> Loss 0.00277645011743\n",
      "Epoch 2::Minibatch 716::LR 0.0976923076923 --> Loss 0.00153877089421\n",
      "Epoch 2::Minibatch 717::LR 0.0976923076923 --> Loss 0.00156521042188\n",
      "Epoch 2::Minibatch 718::LR 0.0976923076923 --> Loss 0.00120780070623\n",
      "Epoch 2::Minibatch 719::LR 0.0976923076923 --> Loss 0.00159576932589\n",
      "Epoch 2::Minibatch 720::LR 0.0976923076923 --> Loss 0.00229960302512\n",
      "Epoch 2::Minibatch 721::LR 0.0976923076923 --> Loss 0.000625762740771\n",
      "Epoch 2::Minibatch 722::LR 0.0976923076923 --> Loss 0.00498739004135\n",
      "Epoch 2::Minibatch 723::LR 0.0976923076923 --> Loss 0.00475764234861\n",
      "Epoch 2::Minibatch 724::LR 0.0976923076923 --> Loss 0.000999431908131\n",
      "Epoch 2::Minibatch 725::LR 0.0976923076923 --> Loss 0.00223043322563\n",
      "Epoch 2::Minibatch 726::LR 0.0976923076923 --> Loss 0.00492669820786\n",
      "Epoch 2::Minibatch 727::LR 0.0976923076923 --> Loss 0.00300497055054\n",
      "Epoch 2::Minibatch 728::LR 0.0976923076923 --> Loss 0.000669379929701\n",
      "Epoch 2::Minibatch 729::LR 0.0976923076923 --> Loss 0.000775184333324\n",
      "Epoch 2::Minibatch 730::LR 0.0976923076923 --> Loss 0.00244608362516\n",
      "Epoch 2::Minibatch 731::LR 0.0976923076923 --> Loss 0.00236172993978\n",
      "Epoch 2::Minibatch 732::LR 0.0976923076923 --> Loss 0.00247413953145\n",
      "Epoch 2::Minibatch 733::LR 0.0976923076923 --> Loss 0.000693564812342\n",
      "Epoch 2::Minibatch 734::LR 0.0976923076923 --> Loss 0.0017364414533\n",
      "Epoch 2::Minibatch 735::LR 0.0976923076923 --> Loss 0.00224564353625\n",
      "Epoch 2::Minibatch 736::LR 0.0976923076923 --> Loss 0.00338294108709\n",
      "Epoch 2::Minibatch 737::LR 0.0976923076923 --> Loss 0.00308197339376\n",
      "Epoch 2::Minibatch 738::LR 0.0976923076923 --> Loss 0.00152837644021\n",
      "Epoch 2::Minibatch 739::LR 0.0976923076923 --> Loss 0.00238818208377\n",
      "Epoch 2::Minibatch 740::LR 0.0976923076923 --> Loss 0.00395714918772\n",
      "Epoch 2::Minibatch 741::LR 0.0976923076923 --> Loss 0.00268384853999\n",
      "Epoch 2::Minibatch 742::LR 0.0976923076923 --> Loss 0.00203922907511\n",
      "Epoch 2::Minibatch 743::LR 0.0976923076923 --> Loss 0.00118076165517\n",
      "Epoch 2::Minibatch 744::LR 0.0976923076923 --> Loss 0.00166424910227\n",
      "Epoch 2::Minibatch 745::LR 0.0976923076923 --> Loss 0.00284158825874\n",
      "Epoch 2::Minibatch 746::LR 0.0976923076923 --> Loss 0.0029075841109\n",
      "Epoch 2::Minibatch 747::LR 0.0976923076923 --> Loss 0.00178926487764\n",
      "Epoch 2::Minibatch 748::LR 0.0976923076923 --> Loss 0.000592400978009\n",
      "Epoch 2::Minibatch 749::LR 0.0976923076923 --> Loss 0.00160310298204\n",
      "Epoch 2::Minibatch 750::LR 0.0976923076923 --> Loss 0.00240841706594\n",
      "Epoch 2::Minibatch 751::LR 0.0976923076923 --> Loss 0.00262669444084\n",
      "Epoch 2::Minibatch 752::LR 0.0976923076923 --> Loss 0.00101457814376\n",
      "Epoch 2::Minibatch 753::LR 0.0976923076923 --> Loss 0.00210567037265\n",
      "Epoch 2::Minibatch 754::LR 0.0976923076923 --> Loss 0.00234759469827\n",
      "Epoch 2::Minibatch 755::LR 0.0976923076923 --> Loss 0.00249169230461\n",
      "Epoch 2::Minibatch 756::LR 0.0976923076923 --> Loss 0.00154636740685\n",
      "Epoch 2::Minibatch 757::LR 0.0976923076923 --> Loss 0.000884045561155\n",
      "Epoch 2::Minibatch 758::LR 0.0976923076923 --> Loss 0.00166939695676\n",
      "Epoch 2::Minibatch 759::LR 0.0976923076923 --> Loss 0.00393279274305\n",
      "Epoch 2::Minibatch 760::LR 0.0976923076923 --> Loss 0.00308462003867\n",
      "Epoch 2::Minibatch 761::LR 0.0976923076923 --> Loss 0.00678804000219\n",
      "Epoch 2::Minibatch 762::LR 0.0976923076923 --> Loss 0.00373930295308\n",
      "Epoch 2::Minibatch 763::LR 0.0976923076923 --> Loss 0.00351747115453\n",
      "Epoch 2::Minibatch 764::LR 0.0976923076923 --> Loss 0.00320179065069\n",
      "Epoch 2::Minibatch 765::LR 0.0976923076923 --> Loss 0.00126645475626\n",
      "Epoch 2::Minibatch 766::LR 0.0976923076923 --> Loss 0.00221740245819\n",
      "Epoch 2::Minibatch 767::LR 0.0976923076923 --> Loss 0.00493074337641\n",
      "Epoch 2::Minibatch 768::LR 0.0976923076923 --> Loss 0.00346601287524\n",
      "Epoch 2::Minibatch 769::LR 0.0976923076923 --> Loss 0.00192554513613\n",
      "Epoch 2::Minibatch 770::LR 0.0976923076923 --> Loss 0.00138982594013\n",
      "Epoch 2::Minibatch 771::LR 0.0976923076923 --> Loss 0.00376172463099\n",
      "Epoch 2::Minibatch 772::LR 0.0976923076923 --> Loss 0.00314314703147\n",
      "Epoch 2::Minibatch 773::LR 0.0976923076923 --> Loss 0.00311685204506\n",
      "Epoch 2::Minibatch 774::LR 0.0976923076923 --> Loss 0.00173475722472\n",
      "Epoch 2::Minibatch 775::LR 0.0976923076923 --> Loss 0.00411754488945\n",
      "Epoch 2::Minibatch 776::LR 0.0976923076923 --> Loss 0.00345283548037\n",
      "Epoch 2::Minibatch 777::LR 0.0976923076923 --> Loss 0.00776744604111\n",
      "Epoch 2::Minibatch 778::LR 0.0976923076923 --> Loss 0.011219347318\n",
      "Epoch 2::Minibatch 779::LR 0.0976923076923 --> Loss 0.00152598361174\n",
      "Epoch 2::Minibatch 780::LR 0.0976923076923 --> Loss 0.00166318128506\n",
      "Epoch 2::Minibatch 781::LR 0.0976923076923 --> Loss 0.00353980541229\n",
      "Epoch 2::Minibatch 782::LR 0.0976923076923 --> Loss 0.00427866339684\n",
      "Epoch 2::Minibatch 783::LR 0.0976923076923 --> Loss 0.00242877523104\n",
      "Epoch 2::Minibatch 784::LR 0.0976923076923 --> Loss 0.000759656031926\n",
      "Epoch 2::Minibatch 785::LR 0.0976923076923 --> Loss 0.00380994796753\n",
      "Epoch 2::Minibatch 786::LR 0.0976923076923 --> Loss 0.00374865372976\n",
      "Epoch 2::Minibatch 787::LR 0.0976923076923 --> Loss 0.00302122712135\n",
      "Epoch 2::Minibatch 788::LR 0.0976923076923 --> Loss 0.00264488001664\n",
      "Epoch 2::Minibatch 789::LR 0.0976923076923 --> Loss 0.000733268459638\n",
      "Epoch 2::Minibatch 790::LR 0.0976923076923 --> Loss 0.0032834837834\n",
      "Epoch 2::Minibatch 791::LR 0.0976923076923 --> Loss 0.00388364712397\n",
      "Epoch 2::Minibatch 792::LR 0.0976923076923 --> Loss 0.00364949862162\n",
      "Epoch 2::Minibatch 793::LR 0.0976923076923 --> Loss 0.00206313987573\n",
      "Epoch 2::Minibatch 794::LR 0.0976923076923 --> Loss 0.00115540117025\n",
      "Epoch 2::Minibatch 795::LR 0.0976923076923 --> Loss 0.0035736489296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 796::LR 0.0976923076923 --> Loss 0.0060967373848\n",
      "Epoch 2::Minibatch 797::LR 0.0976923076923 --> Loss 0.00863973697027\n",
      "Epoch 2::Minibatch 798::LR 0.0976923076923 --> Loss 0.00344933986664\n",
      "Epoch 2::Minibatch 799::LR 0.0976923076923 --> Loss 0.00276944895585\n",
      "Epoch 2::Minibatch 800::LR 0.0976923076923 --> Loss 0.00216824491819\n",
      "Epoch 2::Minibatch 801::LR 0.0976923076923 --> Loss 0.00399993737539\n",
      "Epoch 2::Minibatch 802::LR 0.0976923076923 --> Loss 0.00135065992673\n",
      "Epoch 2::Minibatch 803::LR 0.0976923076923 --> Loss 0.00280536174774\n",
      "Epoch 2::Minibatch 804::LR 0.0976923076923 --> Loss 0.00220468302568\n",
      "Epoch 2::Minibatch 805::LR 0.0976923076923 --> Loss 0.0022940826416\n",
      "Epoch 2::Minibatch 806::LR 0.0976923076923 --> Loss 0.00302462935448\n",
      "Epoch 2::Minibatch 807::LR 0.0976923076923 --> Loss 0.0028440117836\n",
      "Epoch 2::Minibatch 808::LR 0.0976923076923 --> Loss 0.00266665061315\n",
      "Epoch 2::Minibatch 809::LR 0.0976923076923 --> Loss 0.00453939159711\n",
      "Epoch 2::Minibatch 810::LR 0.0976923076923 --> Loss 0.00589264988899\n",
      "Epoch 2::Minibatch 811::LR 0.0976923076923 --> Loss 0.00548181215922\n",
      "Epoch 2::Minibatch 812::LR 0.0976923076923 --> Loss 0.00543872435888\n",
      "Epoch 2::Minibatch 813::LR 0.0976923076923 --> Loss 0.00466354489326\n",
      "Epoch 2::Minibatch 814::LR 0.0976923076923 --> Loss 0.00201529979706\n",
      "Epoch 2::Minibatch 815::LR 0.0976923076923 --> Loss 0.0041998342673\n",
      "Epoch 2::Minibatch 816::LR 0.0976923076923 --> Loss 0.00441015879313\n",
      "Epoch 2::Minibatch 817::LR 0.0976923076923 --> Loss 0.00522586067518\n",
      "Epoch 2::Minibatch 818::LR 0.0976923076923 --> Loss 0.00150566359361\n",
      "Epoch 2::Minibatch 819::LR 0.0976923076923 --> Loss 0.000875002245108\n",
      "Epoch 2::Minibatch 820::LR 0.0976923076923 --> Loss 0.00562118291855\n",
      "Epoch 2::Minibatch 821::LR 0.0976923076923 --> Loss 0.00339896718661\n",
      "Epoch 2::Minibatch 822::LR 0.0976923076923 --> Loss 0.00402074933052\n",
      "Epoch 2::Minibatch 823::LR 0.0976923076923 --> Loss 0.00129868666331\n",
      "Epoch 2::Minibatch 824::LR 0.0976923076923 --> Loss 0.00142676840226\n",
      "Epoch 2::Minibatch 825::LR 0.0976923076923 --> Loss 0.0037334438165\n",
      "Epoch 2::Minibatch 826::LR 0.0976923076923 --> Loss 0.0038411184152\n",
      "Epoch 2::Minibatch 827::LR 0.0976923076923 --> Loss 0.00248999357224\n",
      "Epoch 2::Minibatch 828::LR 0.0976923076923 --> Loss 0.000780112743378\n",
      "Epoch 2::Minibatch 829::LR 0.0976923076923 --> Loss 0.00249711294969\n",
      "Epoch 2::Minibatch 830::LR 0.0976923076923 --> Loss 0.00452363411585\n",
      "Epoch 2::Minibatch 831::LR 0.0976923076923 --> Loss 0.0025011920929\n",
      "Epoch 2::Minibatch 832::LR 0.0976923076923 --> Loss 0.00212687234084\n",
      "Epoch 2::Minibatch 833::LR 0.0976923076923 --> Loss 0.0017850480477\n",
      "Epoch 2::Minibatch 834::LR 0.0976923076923 --> Loss 0.000773241172234\n",
      "Epoch 2::Minibatch 835::LR 0.0976923076923 --> Loss 0.00374761501948\n",
      "Epoch 2::Minibatch 836::LR 0.0976923076923 --> Loss 0.0039534620444\n",
      "Epoch 2::Minibatch 837::LR 0.0976923076923 --> Loss 0.00248415152232\n",
      "Epoch 2::Minibatch 838::LR 0.0976923076923 --> Loss 0.000697980721792\n",
      "Epoch 2::Minibatch 839::LR 0.0976923076923 --> Loss 0.00253606299559\n",
      "Epoch 2::Minibatch 840::LR 0.0976923076923 --> Loss 0.00302136659622\n",
      "Epoch 2::Minibatch 841::LR 0.0976923076923 --> Loss 0.00296633819739\n",
      "Epoch 2::Minibatch 842::LR 0.0976923076923 --> Loss 0.0021953668197\n",
      "Epoch 2::Minibatch 843::LR 0.0976923076923 --> Loss 0.0010136693716\n",
      "Epoch 2::Minibatch 844::LR 0.0976923076923 --> Loss 0.00147938360771\n",
      "Epoch 2::Minibatch 845::LR 0.0976923076923 --> Loss 0.00422984957695\n",
      "Epoch 2::Minibatch 846::LR 0.0976923076923 --> Loss 0.00162300000588\n",
      "Epoch 2::Minibatch 847::LR 0.0976923076923 --> Loss 0.00236199140549\n",
      "Epoch 2::Minibatch 848::LR 0.0976923076923 --> Loss 0.00108463486036\n",
      "Epoch 2::Minibatch 849::LR 0.0976923076923 --> Loss 0.0018854568402\n",
      "Epoch 2::Minibatch 850::LR 0.0976923076923 --> Loss 0.00325319548448\n",
      "Epoch 2::Minibatch 851::LR 0.0976923076923 --> Loss 0.00297378778458\n",
      "Epoch 2::Minibatch 852::LR 0.0976923076923 --> Loss 0.00113343348106\n",
      "Epoch 2::Minibatch 853::LR 0.0976923076923 --> Loss 0.00132698655128\n",
      "Epoch 2::Minibatch 854::LR 0.0976923076923 --> Loss 0.00255926887194\n",
      "Epoch 2::Minibatch 855::LR 0.0976923076923 --> Loss 0.00210870067279\n",
      "Epoch 2::Minibatch 856::LR 0.0976923076923 --> Loss 0.00175051530202\n",
      "Epoch 2::Minibatch 857::LR 0.0976923076923 --> Loss 0.00120136847099\n",
      "Epoch 2::Minibatch 858::LR 0.0976923076923 --> Loss 0.00057537689805\n",
      "Epoch 2::Minibatch 859::LR 0.0976923076923 --> Loss 0.00184175451597\n",
      "Epoch 2::Minibatch 860::LR 0.0976923076923 --> Loss 0.00123191932837\n",
      "Epoch 2::Minibatch 861::LR 0.0976923076923 --> Loss 0.000913787086805\n",
      "Epoch 2::Minibatch 862::LR 0.0976923076923 --> Loss 0.00334147016207\n",
      "Epoch 2::Minibatch 863::LR 0.0976923076923 --> Loss 0.00388642946879\n",
      "Epoch 2::Minibatch 864::LR 0.0976923076923 --> Loss 0.00326268414656\n",
      "Epoch 2::Minibatch 865::LR 0.0976923076923 --> Loss 0.000596218754848\n",
      "Epoch 2::Minibatch 866::LR 0.0976923076923 --> Loss 0.00220718661944\n",
      "Epoch 2::Minibatch 867::LR 0.0976923076923 --> Loss 0.00308768351873\n",
      "Epoch 2::Minibatch 868::LR 0.0976923076923 --> Loss 0.00257933080196\n",
      "Epoch 2::Minibatch 869::LR 0.0976923076923 --> Loss 0.00216261784236\n",
      "Epoch 2::Minibatch 870::LR 0.0976923076923 --> Loss 0.00354543805122\n",
      "Epoch 2::Minibatch 871::LR 0.0976923076923 --> Loss 0.00157717376947\n",
      "Epoch 2::Minibatch 872::LR 0.0976923076923 --> Loss 0.00233748535315\n",
      "Epoch 2::Minibatch 873::LR 0.0976923076923 --> Loss 0.00250719408194\n",
      "Epoch 2::Minibatch 874::LR 0.0976923076923 --> Loss 0.00637603084246\n",
      "Epoch 2::Minibatch 875::LR 0.0976923076923 --> Loss 0.000616589685281\n",
      "Epoch 2::Minibatch 876::LR 0.0976923076923 --> Loss 0.00361401995023\n",
      "Epoch 2::Minibatch 877::LR 0.0976923076923 --> Loss 0.00378427187602\n",
      "Epoch 2::Minibatch 878::LR 0.0976923076923 --> Loss 0.00336844325066\n",
      "Epoch 2::Minibatch 879::LR 0.0976923076923 --> Loss 0.00395274837812\n",
      "Epoch 2::Minibatch 880::LR 0.0976923076923 --> Loss 0.0044283135732\n",
      "Epoch 2::Minibatch 881::LR 0.0976923076923 --> Loss 0.0043045047919\n",
      "Epoch 2::Minibatch 882::LR 0.0976923076923 --> Loss 0.0020141496261\n",
      "Epoch 2::Minibatch 883::LR 0.0976923076923 --> Loss 0.00339707334836\n",
      "Epoch 2::Minibatch 884::LR 0.0976923076923 --> Loss 0.00267205496629\n",
      "Epoch 2::Minibatch 885::LR 0.0976923076923 --> Loss 0.00253533701102\n",
      "Epoch 2::Minibatch 886::LR 0.0976923076923 --> Loss 0.000582028031349\n",
      "Epoch 2::Minibatch 887::LR 0.0976923076923 --> Loss 0.00531919717789\n",
      "Epoch 2::Minibatch 888::LR 0.0976923076923 --> Loss 0.00265983939171\n",
      "Epoch 2::Minibatch 889::LR 0.0976923076923 --> Loss 0.00312841435273\n",
      "Epoch 2::Minibatch 890::LR 0.0976923076923 --> Loss 0.00454859574636\n",
      "Epoch 2::Minibatch 891::LR 0.0976923076923 --> Loss 0.00200618028641\n",
      "Epoch 2::Minibatch 892::LR 0.0976923076923 --> Loss 0.000874549150467\n",
      "Epoch 2::Minibatch 893::LR 0.0976923076923 --> Loss 0.00256719430288\n",
      "Epoch 2::Minibatch 894::LR 0.0976923076923 --> Loss 0.00220652222633\n",
      "Epoch 2::Minibatch 895::LR 0.0976923076923 --> Loss 0.00251246949037\n",
      "Epoch 2::Minibatch 896::LR 0.0976923076923 --> Loss 0.00125304013491\n",
      "Epoch 2::Minibatch 897::LR 0.0976923076923 --> Loss 0.000715194195509\n",
      "Epoch 2::Minibatch 898::LR 0.0976923076923 --> Loss 0.00212094406287\n",
      "Epoch 2::Minibatch 899::LR 0.0976923076923 --> Loss 0.00245344340801\n",
      "Epoch 2::Minibatch 900::LR 0.0976923076923 --> Loss 0.00339474399885\n",
      "Epoch 2::Minibatch 901::LR 0.0976923076923 --> Loss 0.000568614304066\n",
      "Epoch 2::Minibatch 902::LR 0.0976923076923 --> Loss 0.00140053699414\n",
      "Epoch 2::Minibatch 903::LR 0.0976923076923 --> Loss 0.00257269938787\n",
      "Epoch 2::Minibatch 904::LR 0.0976923076923 --> Loss 0.00200864593188\n",
      "Epoch 2::Minibatch 905::LR 0.0976923076923 --> Loss 0.00140582323074\n",
      "Epoch 2::Minibatch 906::LR 0.0976923076923 --> Loss 0.0010530034701\n",
      "Epoch 2::Minibatch 907::LR 0.0976923076923 --> Loss 0.00156616081794\n",
      "Epoch 2::Minibatch 908::LR 0.0976923076923 --> Loss 0.00227601548036\n",
      "Epoch 2::Minibatch 909::LR 0.0976923076923 --> Loss 0.00215595304966\n",
      "Epoch 2::Minibatch 910::LR 0.0976923076923 --> Loss 0.000803332527479\n",
      "Epoch 2::Minibatch 911::LR 0.0976923076923 --> Loss 0.00119251509507\n",
      "Epoch 2::Minibatch 912::LR 0.0976923076923 --> Loss 0.00198449194431\n",
      "Epoch 2::Minibatch 913::LR 0.0976923076923 --> Loss 0.00215628047784\n",
      "Epoch 2::Minibatch 914::LR 0.0976923076923 --> Loss 0.00112720042467\n",
      "Epoch 2::Minibatch 915::LR 0.0976923076923 --> Loss 0.000448115368684\n",
      "Epoch 2::Minibatch 916::LR 0.0976923076923 --> Loss 0.00240517179171\n",
      "Epoch 2::Minibatch 917::LR 0.0976923076923 --> Loss 0.00372434457143\n",
      "Epoch 2::Minibatch 918::LR 0.0976923076923 --> Loss 0.00885437409083\n",
      "Epoch 2::Minibatch 919::LR 0.0976923076923 --> Loss 0.000768260508776\n",
      "Epoch 2::Minibatch 920::LR 0.0976923076923 --> Loss 0.0091300201416\n",
      "Epoch 2::Minibatch 921::LR 0.0976923076923 --> Loss 0.0031513206164\n",
      "Epoch 2::Minibatch 922::LR 0.0976923076923 --> Loss 0.0035991815726\n",
      "Epoch 2::Minibatch 923::LR 0.0976923076923 --> Loss 0.00183330873648\n",
      "Epoch 2::Minibatch 924::LR 0.0976923076923 --> Loss 0.00356436451276\n",
      "Epoch 2::Minibatch 925::LR 0.0976923076923 --> Loss 0.0027196953694\n",
      "Epoch 2::Minibatch 926::LR 0.0976923076923 --> Loss 0.00591534852982\n",
      "Epoch 2::Minibatch 927::LR 0.0976923076923 --> Loss 0.00972751537959\n",
      "Epoch 2::Minibatch 928::LR 0.0976923076923 --> Loss 0.00735131820043\n",
      "Epoch 2::Minibatch 929::LR 0.0976923076923 --> Loss 0.00926066875458\n",
      "Epoch 2::Minibatch 930::LR 0.0976923076923 --> Loss 0.00680997133255\n",
      "Epoch 2::Minibatch 931::LR 0.0976923076923 --> Loss 0.00414016127586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2::Minibatch 932::LR 0.0976923076923 --> Loss 0.00767652432124\n",
      "Epoch 2::Minibatch 933::LR 0.0976923076923 --> Loss 0.00435743371646\n",
      "Epoch 2::Minibatch 934::LR 0.0976923076923 --> Loss 0.00586673219999\n",
      "Epoch 2::Minibatch 935::LR 0.0976923076923 --> Loss 0.00819623231888\n",
      "Epoch 2::Minibatch 936::LR 0.0976923076923 --> Loss 0.00186545928319\n",
      "Epoch 2::Minibatch 937::LR 0.0976923076923 --> Loss 0.00410219033559\n",
      "Epoch 2::Minibatch 938::LR 0.0976923076923 --> Loss 0.00377442280451\n",
      "Epoch 2::Minibatch 939::LR 0.0976923076923 --> Loss 0.00375673810641\n",
      "Epoch 2::Minibatch 940::LR 0.0976923076923 --> Loss 0.000977124869823\n",
      "Epoch 2::Minibatch 941::LR 0.0976923076923 --> Loss 0.000805247227351\n",
      "Epoch 2::Minibatch 942::LR 0.0976923076923 --> Loss 0.00251688599586\n",
      "Epoch 2::Minibatch 943::LR 0.0976923076923 --> Loss 0.00333939909935\n",
      "Epoch 2::Minibatch 944::LR 0.0976923076923 --> Loss 0.00246478915215\n",
      "Epoch 2::Minibatch 945::LR 0.0976923076923 --> Loss 0.00139499872923\n",
      "Epoch 2::Minibatch 946::LR 0.0976923076923 --> Loss 0.00364665985107\n",
      "Epoch 2::Minibatch 947::LR 0.0976923076923 --> Loss 0.00318117002646\n",
      "Epoch 2::Minibatch 948::LR 0.0976923076923 --> Loss 0.00596137126287\n",
      "Epoch 2::Minibatch 949::LR 0.0976923076923 --> Loss 0.00196247359117\n",
      "Epoch 2::Minibatch 950::LR 0.0976923076923 --> Loss 0.000672915925582\n",
      "Epoch 2::Minibatch 951::LR 0.0976923076923 --> Loss 0.00357998132706\n",
      "Epoch 2::Minibatch 952::LR 0.0976923076923 --> Loss 0.00251303970814\n",
      "Epoch 2::Minibatch 953::LR 0.0976923076923 --> Loss 0.00131002535423\n",
      "Epoch 2::Minibatch 954::LR 0.0976923076923 --> Loss 0.000929706692696\n",
      "Epoch 2::Minibatch 955::LR 0.0976923076923 --> Loss 0.00264135241508\n",
      "Epoch 2::Minibatch 956::LR 0.0976923076923 --> Loss 0.00448704640071\n",
      "Epoch 2::Minibatch 957::LR 0.0976923076923 --> Loss 0.0019870976607\n",
      "Epoch 2::Minibatch 958::LR 0.0976923076923 --> Loss 0.00252774496873\n",
      "Epoch 2::Minibatch 959::LR 0.0976923076923 --> Loss 0.00309199968974\n",
      "Epoch 2::Minibatch 960::LR 0.0976923076923 --> Loss 0.00625749190648\n",
      "Epoch 2::Minibatch 961::LR 0.0976923076923 --> Loss 0.00312751710415\n",
      "Epoch 2::Minibatch 962::LR 0.0976923076923 --> Loss 0.00312755624453\n",
      "Epoch 2::Minibatch 963::LR 0.0976923076923 --> Loss 0.00123445481062\n",
      "Epoch 2::Minibatch 964::LR 0.0976923076923 --> Loss 0.00241650164127\n",
      "Epoch 2::Minibatch 965::LR 0.0976923076923 --> Loss 0.00922318299611\n",
      "Epoch 2::Minibatch 966::LR 0.0976923076923 --> Loss 0.00528945207596\n",
      "Epoch 2::Minibatch 967::LR 0.0976923076923 --> Loss 0.00191584984461\n",
      "Epoch 2::Minibatch 968::LR 0.0976923076923 --> Loss 0.00175126155217\n",
      "Epoch 2::Minibatch 969::LR 0.0976923076923 --> Loss 0.00639645695686\n",
      "Epoch 2::Minibatch 970::LR 0.0976923076923 --> Loss 0.00687979300817\n",
      "Epoch 2::Minibatch 971::LR 0.0976923076923 --> Loss 0.00372087240219\n",
      "Epoch 2::Minibatch 972::LR 0.0976923076923 --> Loss 0.00683930238088\n",
      "Epoch 2::Minibatch 973::LR 0.0976923076923 --> Loss 0.00930599927902\n",
      "Epoch 2::Minibatch 974::LR 0.0976923076923 --> Loss 0.00679437239965\n",
      "Epoch 2::Minibatch 975::LR 0.0976923076923 --> Loss 0.00487276514371\n",
      "Epoch 2::Minibatch 976::LR 0.0976923076923 --> Loss 0.00446656227112\n",
      "Epoch 2::Minibatch 977::LR 0.0976923076923 --> Loss 0.00442922472954\n",
      "Epoch 2::Minibatch 978::LR 0.0976923076923 --> Loss 0.00439729730288\n",
      "Epoch 2::Minibatch 979::LR 0.0976923076923 --> Loss 0.00443006197611\n",
      "Epoch 2::Minibatch 980::LR 0.0976923076923 --> Loss 0.00423275868098\n",
      "Epoch 2::Minibatch 981::LR 0.0976923076923 --> Loss 0.00549296180407\n",
      "Epoch 2::Minibatch 982::LR 0.0976923076923 --> Loss 0.00601600646973\n",
      "Epoch 2::Minibatch 983::LR 0.0976923076923 --> Loss 0.00352820118268\n",
      "Epoch 2::Minibatch 984::LR 0.0976923076923 --> Loss 0.0024729647239\n",
      "Epoch 2::Minibatch 985::LR 0.0976923076923 --> Loss 0.00406843384107\n",
      "Epoch 2::Minibatch 986::LR 0.0976923076923 --> Loss 0.00359876473745\n",
      "Epoch 2::Minibatch 987::LR 0.0976923076923 --> Loss 0.0041920363903\n",
      "Epoch 2::Minibatch 988::LR 0.0976923076923 --> Loss 0.00297295292219\n",
      "Epoch 2::Minibatch 989::LR 0.0976923076923 --> Loss 0.00312606314818\n",
      "Epoch 2::Minibatch 990::LR 0.0976923076923 --> Loss 0.00310136417548\n",
      "Epoch 2::Minibatch 991::LR 0.0976923076923 --> Loss 0.00141127665838\n",
      "Epoch 2::Minibatch 992::LR 0.0976923076923 --> Loss 0.00163402597109\n",
      "Epoch 2::Minibatch 993::LR 0.0976923076923 --> Loss 0.00302208443483\n",
      "Epoch 2::Minibatch 994::LR 0.0976923076923 --> Loss 0.00188882609208\n",
      "Epoch 2::Minibatch 995::LR 0.0976923076923 --> Loss 0.00073563148578\n",
      "Epoch 2::Minibatch 996::LR 0.0976923076923 --> Loss 0.00288746039073\n",
      "Epoch 2::Minibatch 997::LR 0.0976923076923 --> Loss 0.00187824189663\n",
      "Epoch 2::Minibatch 998::LR 0.0976923076923 --> Loss 0.00203692595164\n",
      "Epoch 2::Minibatch 999::LR 0.0976923076923 --> Loss 0.00172767380873\n",
      "Epoch 2::Minibatch 1000::LR 0.0976923076923 --> Loss 0.00191685795784\n",
      "Epoch 2::Minibatch 1001::LR 0.0976923076923 --> Loss 0.00159287502368\n",
      "Epoch 2::Minibatch 1002::LR 0.0976923076923 --> Loss 0.00486765662829\n",
      "Epoch 2::Minibatch 1003::LR 0.0976923076923 --> Loss 0.00549704114596\n",
      "Epoch 2::Minibatch 1004::LR 0.0976923076923 --> Loss 0.000897881090641\n",
      "Epoch 2::Minibatch 1005::LR 0.0976923076923 --> Loss 0.00641424735387\n",
      "Epoch 2::Minibatch 1006::LR 0.0976923076923 --> Loss 0.0048574090004\n",
      "Epoch 2::Minibatch 1007::LR 0.0976923076923 --> Loss 0.00378596862157\n",
      "Epoch 2::Minibatch 1008::LR 0.0976923076923 --> Loss 0.000862875481447\n",
      "Epoch 2::Minibatch 1009::LR 0.0976923076923 --> Loss 0.00215861519178\n",
      "Epoch 2::Minibatch 1010::LR 0.0976923076923 --> Loss 0.0017341953516\n",
      "Epoch 2::Minibatch 1011::LR 0.0976923076923 --> Loss 0.00349997361501\n",
      "Epoch 2::Minibatch 1012::LR 0.0976923076923 --> Loss 0.00191400051117\n",
      "Epoch 2::Minibatch 1013::LR 0.0976923076923 --> Loss 0.00481246352196\n",
      "Epoch 2::Minibatch 1014::LR 0.0976923076923 --> Loss 0.00411130706469\n",
      "Epoch 2::Minibatch 1015::LR 0.0976923076923 --> Loss 0.00181126316388\n",
      "Epoch 2::Minibatch 1016::LR 0.0976923076923 --> Loss 0.00422311147054\n",
      "Epoch 2::Minibatch 1017::LR 0.0976923076923 --> Loss 0.00405950387319\n",
      "Epoch 2::Minibatch 1018::LR 0.0976923076923 --> Loss 0.00343964099884\n",
      "Epoch 2::Minibatch 1019::LR 0.0976923076923 --> Loss 0.00254183133443\n",
      "Epoch 2::Minibatch 1020::LR 0.0976923076923 --> Loss 0.00244123458862\n",
      "Epoch 2::Minibatch 1021::LR 0.0976923076923 --> Loss 0.00250094234943\n",
      "Epoch 2::Minibatch 1022::LR 0.0976923076923 --> Loss 0.00201382001241\n",
      "Epoch 2::Minibatch 1023::LR 0.0976923076923 --> Loss 0.00144307066997\n",
      "Epoch 2::Minibatch 1024::LR 0.0976923076923 --> Loss 0.00129651198785\n",
      "Epoch 2::Minibatch 1025::LR 0.0976923076923 --> Loss 0.00153278261423\n",
      "Epoch 2::Minibatch 1026::LR 0.0976923076923 --> Loss 0.000874745945136\n",
      "Epoch 2::Minibatch 1027::LR 0.0976923076923 --> Loss 0.00103044837713\n",
      "Epoch 2::Minibatch 1028::LR 0.0976923076923 --> Loss 0.000849826832612\n",
      "Epoch 2::Minibatch 1029::LR 0.0976923076923 --> Loss 0.000815548847119\n",
      "Epoch 2::Minibatch 1030::LR 0.0976923076923 --> Loss 0.00102064122756\n",
      "Epoch 2::Minibatch 1031::LR 0.0976923076923 --> Loss 0.000779499908288\n",
      "Epoch 2::Minibatch 1032::LR 0.0976923076923 --> Loss 0.000788358300924\n",
      "Epoch 2::Minibatch 1033::LR 0.0976923076923 --> Loss 0.000650171041489\n",
      "Epoch 2::Minibatch 1034::LR 0.0976923076923 --> Loss 0.000691042393446\n",
      "Epoch 2::Minibatch 1035::LR 0.0976923076923 --> Loss 0.000458339254061\n",
      "Epoch 2::Minibatch 1036::LR 0.0976923076923 --> Loss 0.000291752964258\n",
      "Epoch 2::Minibatch 1037::LR 0.0976923076923 --> Loss 0.000560883382956\n",
      "Epoch 2::Minibatch 1038::LR 0.0976923076923 --> Loss 0.00138206223647\n",
      "Epoch 2::Minibatch 1039::LR 0.0976923076923 --> Loss 0.00105682124694\n",
      "Epoch 2::Minibatch 1040::LR 0.0976923076923 --> Loss 0.000503853410482\n",
      "Epoch 2::Minibatch 1041::LR 0.0976923076923 --> Loss 0.000637792795897\n",
      "Epoch 3::Minibatch 1::LR 0.0953846153846 --> Loss 0.0095268479983\n",
      "Epoch 3::Minibatch 2::LR 0.0953846153846 --> Loss 0.00648297508558\n",
      "Epoch 3::Minibatch 3::LR 0.0953846153846 --> Loss 0.00449356595675\n",
      "Epoch 3::Minibatch 4::LR 0.0953846153846 --> Loss 0.00435249845187\n",
      "Epoch 3::Minibatch 5::LR 0.0953846153846 --> Loss 0.0048073665301\n",
      "Epoch 3::Minibatch 6::LR 0.0953846153846 --> Loss 0.00244127015273\n",
      "Epoch 3::Minibatch 7::LR 0.0953846153846 --> Loss 0.00808192014694\n",
      "Epoch 3::Minibatch 8::LR 0.0953846153846 --> Loss 0.00730571746826\n",
      "Epoch 3::Minibatch 9::LR 0.0953846153846 --> Loss 0.00555580298106\n",
      "Epoch 3::Minibatch 10::LR 0.0953846153846 --> Loss 0.00287034928799\n",
      "Epoch 3::Minibatch 11::LR 0.0953846153846 --> Loss 0.00235486090183\n",
      "Epoch 3::Minibatch 12::LR 0.0953846153846 --> Loss 0.0034394133091\n",
      "Epoch 3::Minibatch 13::LR 0.0953846153846 --> Loss 0.00524983008703\n",
      "Epoch 3::Minibatch 14::LR 0.0953846153846 --> Loss 0.00513335545858\n",
      "Epoch 3::Minibatch 15::LR 0.0953846153846 --> Loss 0.00447387456894\n",
      "Epoch 3::Minibatch 16::LR 0.0953846153846 --> Loss 0.000700777371724\n",
      "Epoch 3::Minibatch 17::LR 0.0953846153846 --> Loss 0.00295831402143\n",
      "Epoch 3::Minibatch 18::LR 0.0953846153846 --> Loss 0.00232246359189\n",
      "Epoch 3::Minibatch 19::LR 0.0953846153846 --> Loss 0.00126872638861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 20::LR 0.0953846153846 --> Loss 0.00182326416175\n",
      "Epoch 3::Minibatch 21::LR 0.0953846153846 --> Loss 0.00303911348184\n",
      "Epoch 3::Minibatch 22::LR 0.0953846153846 --> Loss 0.00238870859146\n",
      "Epoch 3::Minibatch 23::LR 0.0953846153846 --> Loss 0.00083866139253\n",
      "Epoch 3::Minibatch 24::LR 0.0953846153846 --> Loss 0.000372871036331\n",
      "Epoch 3::Minibatch 25::LR 0.0953846153846 --> Loss 0.0010923097531\n",
      "Epoch 3::Minibatch 26::LR 0.0953846153846 --> Loss 0.00127423167229\n",
      "Epoch 3::Minibatch 27::LR 0.0953846153846 --> Loss 0.00101626843214\n",
      "Epoch 3::Minibatch 28::LR 0.0953846153846 --> Loss 0.000369317134221\n",
      "Epoch 3::Minibatch 29::LR 0.0953846153846 --> Loss 0.000320764233669\n",
      "Epoch 3::Minibatch 30::LR 0.0953846153846 --> Loss 0.000778549065193\n",
      "Epoch 3::Minibatch 31::LR 0.0953846153846 --> Loss 0.00125830620527\n",
      "Epoch 3::Minibatch 32::LR 0.0953846153846 --> Loss 0.00132193247477\n",
      "Epoch 3::Minibatch 33::LR 0.0953846153846 --> Loss 0.000771270046631\n",
      "Epoch 3::Minibatch 34::LR 0.0953846153846 --> Loss 0.00240722258886\n",
      "Epoch 3::Minibatch 35::LR 0.0953846153846 --> Loss 0.00358210325241\n",
      "Epoch 3::Minibatch 36::LR 0.0953846153846 --> Loss 0.00228969275951\n",
      "Epoch 3::Minibatch 37::LR 0.0953846153846 --> Loss 0.000732413927714\n",
      "Epoch 3::Minibatch 38::LR 0.0953846153846 --> Loss 0.000840202569962\n",
      "Epoch 3::Minibatch 39::LR 0.0953846153846 --> Loss 0.00261968056361\n",
      "Epoch 3::Minibatch 40::LR 0.0953846153846 --> Loss 0.00351549108823\n",
      "Epoch 3::Minibatch 41::LR 0.0953846153846 --> Loss 0.00306298017502\n",
      "Epoch 3::Minibatch 42::LR 0.0953846153846 --> Loss 0.00522897164027\n",
      "Epoch 3::Minibatch 43::LR 0.0953846153846 --> Loss 0.00195682307084\n",
      "Epoch 3::Minibatch 44::LR 0.0953846153846 --> Loss 0.00312156260014\n",
      "Epoch 3::Minibatch 45::LR 0.0953846153846 --> Loss 0.00270315766335\n",
      "Epoch 3::Minibatch 46::LR 0.0953846153846 --> Loss 0.00370472033819\n",
      "Epoch 3::Minibatch 47::LR 0.0953846153846 --> Loss 0.00540542284648\n",
      "Epoch 3::Minibatch 48::LR 0.0953846153846 --> Loss 0.00553080876668\n",
      "Epoch 3::Minibatch 49::LR 0.0953846153846 --> Loss 0.00595519105593\n",
      "Epoch 3::Minibatch 50::LR 0.0953846153846 --> Loss 0.00578330636024\n",
      "Epoch 3::Minibatch 51::LR 0.0953846153846 --> Loss 0.00674685716629\n",
      "Epoch 3::Minibatch 52::LR 0.0953846153846 --> Loss 0.00293744405111\n",
      "Epoch 3::Minibatch 53::LR 0.0953846153846 --> Loss 0.00398822585742\n",
      "Epoch 3::Minibatch 54::LR 0.0953846153846 --> Loss 0.00386157552401\n",
      "Epoch 3::Minibatch 55::LR 0.0953846153846 --> Loss 0.00103374103705\n",
      "Epoch 3::Minibatch 56::LR 0.0953846153846 --> Loss 0.00261249204477\n",
      "Epoch 3::Minibatch 57::LR 0.0953846153846 --> Loss 0.00567518194516\n",
      "Epoch 3::Minibatch 58::LR 0.0953846153846 --> Loss 0.00352242151896\n",
      "Epoch 3::Minibatch 59::LR 0.0953846153846 --> Loss 0.00255650560061\n",
      "Epoch 3::Minibatch 60::LR 0.0953846153846 --> Loss 0.00231904049714\n",
      "Epoch 3::Minibatch 61::LR 0.0953846153846 --> Loss 0.00103292117516\n",
      "Epoch 3::Minibatch 62::LR 0.0953846153846 --> Loss 0.00359125177066\n",
      "Epoch 3::Minibatch 63::LR 0.0953846153846 --> Loss 0.00227062622706\n",
      "Epoch 3::Minibatch 64::LR 0.0953846153846 --> Loss 0.00104899644852\n",
      "Epoch 3::Minibatch 65::LR 0.0953846153846 --> Loss 0.0025082530578\n",
      "Epoch 3::Minibatch 66::LR 0.0953846153846 --> Loss 0.00297240694364\n",
      "Epoch 3::Minibatch 67::LR 0.0953846153846 --> Loss 0.00292300363382\n",
      "Epoch 3::Minibatch 68::LR 0.0953846153846 --> Loss 0.00209431350231\n",
      "Epoch 3::Minibatch 69::LR 0.0953846153846 --> Loss 0.0042351992925\n",
      "Epoch 3::Minibatch 70::LR 0.0953846153846 --> Loss 0.00342146158218\n",
      "Epoch 3::Minibatch 71::LR 0.0953846153846 --> Loss 0.00218038022518\n",
      "Epoch 3::Minibatch 72::LR 0.0953846153846 --> Loss 0.000609091818333\n",
      "Epoch 3::Minibatch 73::LR 0.0953846153846 --> Loss 0.00359022219976\n",
      "Epoch 3::Minibatch 74::LR 0.0953846153846 --> Loss 0.00444192369779\n",
      "Epoch 3::Minibatch 75::LR 0.0953846153846 --> Loss 0.00278535664082\n",
      "Epoch 3::Minibatch 76::LR 0.0953846153846 --> Loss 0.000651631901662\n",
      "Epoch 3::Minibatch 77::LR 0.0953846153846 --> Loss 0.00361179113388\n",
      "Epoch 3::Minibatch 78::LR 0.0953846153846 --> Loss 0.00382842143377\n",
      "Epoch 3::Minibatch 79::LR 0.0953846153846 --> Loss 0.00220610400041\n",
      "Epoch 3::Minibatch 80::LR 0.0953846153846 --> Loss 0.00366426507632\n",
      "Epoch 3::Minibatch 81::LR 0.0953846153846 --> Loss 0.00331269204617\n",
      "Epoch 3::Minibatch 82::LR 0.0953846153846 --> Loss 0.00209664404392\n",
      "Epoch 3::Minibatch 83::LR 0.0953846153846 --> Loss 0.00459754387538\n",
      "Epoch 3::Minibatch 84::LR 0.0953846153846 --> Loss 0.00213708778222\n",
      "Epoch 3::Minibatch 85::LR 0.0953846153846 --> Loss 0.00298554281394\n",
      "Epoch 3::Minibatch 86::LR 0.0953846153846 --> Loss 0.00245341281096\n",
      "Epoch 3::Minibatch 87::LR 0.0953846153846 --> Loss 0.00257319867611\n",
      "Epoch 3::Minibatch 88::LR 0.0953846153846 --> Loss 0.00184941709042\n",
      "Epoch 3::Minibatch 89::LR 0.0953846153846 --> Loss 0.00248034596443\n",
      "Epoch 3::Minibatch 90::LR 0.0953846153846 --> Loss 0.00114841689666\n",
      "Epoch 3::Minibatch 91::LR 0.0953846153846 --> Loss 0.000902969737848\n",
      "Epoch 3::Minibatch 92::LR 0.0953846153846 --> Loss 0.00270485798518\n",
      "Epoch 3::Minibatch 93::LR 0.0953846153846 --> Loss 0.00174089034398\n",
      "Epoch 3::Minibatch 94::LR 0.0953846153846 --> Loss 0.00175132711728\n",
      "Epoch 3::Minibatch 95::LR 0.0953846153846 --> Loss 0.00170364360015\n",
      "Epoch 3::Minibatch 96::LR 0.0953846153846 --> Loss 0.00576248049736\n",
      "Epoch 3::Minibatch 97::LR 0.0953846153846 --> Loss 0.00314408799013\n",
      "Epoch 3::Minibatch 98::LR 0.0953846153846 --> Loss 0.000956708987554\n",
      "Epoch 3::Minibatch 99::LR 0.0953846153846 --> Loss 0.00130554089944\n",
      "Epoch 3::Minibatch 100::LR 0.0953846153846 --> Loss 0.00556503017743\n",
      "Epoch 3::Minibatch 101::LR 0.0953846153846 --> Loss 0.0010519361496\n",
      "Epoch 3::Minibatch 102::LR 0.0953846153846 --> Loss 0.00368591427803\n",
      "Epoch 3::Minibatch 103::LR 0.0953846153846 --> Loss 0.00382866660754\n",
      "Epoch 3::Minibatch 104::LR 0.0953846153846 --> Loss 0.0029192562898\n",
      "Epoch 3::Minibatch 105::LR 0.0953846153846 --> Loss 0.00280343155066\n",
      "Epoch 3::Minibatch 106::LR 0.0953846153846 --> Loss 0.0179553683599\n",
      "Epoch 3::Minibatch 107::LR 0.0953846153846 --> Loss 0.00492350260417\n",
      "Epoch 3::Minibatch 108::LR 0.0953846153846 --> Loss 0.00138859599829\n",
      "Epoch 3::Minibatch 109::LR 0.0953846153846 --> Loss 0.00462055563927\n",
      "Epoch 3::Minibatch 110::LR 0.0953846153846 --> Loss 0.00285085141659\n",
      "Epoch 3::Minibatch 111::LR 0.0953846153846 --> Loss 0.00129240443309\n",
      "Epoch 3::Minibatch 112::LR 0.0953846153846 --> Loss 0.00407125314077\n",
      "Epoch 3::Minibatch 113::LR 0.0953846153846 --> Loss 0.00304744561513\n",
      "Epoch 3::Minibatch 114::LR 0.0953846153846 --> Loss 0.0017400097847\n",
      "Epoch 3::Minibatch 115::LR 0.0953846153846 --> Loss 0.0016818857193\n",
      "Epoch 3::Minibatch 116::LR 0.0953846153846 --> Loss 0.003111743927\n",
      "Epoch 3::Minibatch 117::LR 0.0953846153846 --> Loss 0.00372062047323\n",
      "Epoch 3::Minibatch 118::LR 0.0953846153846 --> Loss 0.00640389124552\n",
      "Epoch 3::Minibatch 119::LR 0.0953846153846 --> Loss 0.000882973869642\n",
      "Epoch 3::Minibatch 120::LR 0.0953846153846 --> Loss 0.00207425971826\n",
      "Epoch 3::Minibatch 121::LR 0.0953846153846 --> Loss 0.0030300039053\n",
      "Epoch 3::Minibatch 122::LR 0.0953846153846 --> Loss 0.00390270431836\n",
      "Epoch 3::Minibatch 123::LR 0.0953846153846 --> Loss 0.00148836940527\n",
      "Epoch 3::Minibatch 124::LR 0.0953846153846 --> Loss 0.00308695832888\n",
      "Epoch 3::Minibatch 125::LR 0.0953846153846 --> Loss 0.00485618670781\n",
      "Epoch 3::Minibatch 126::LR 0.0953846153846 --> Loss 0.00306975841522\n",
      "Epoch 3::Minibatch 127::LR 0.0953846153846 --> Loss 0.0043389181296\n",
      "Epoch 3::Minibatch 128::LR 0.0953846153846 --> Loss 0.00379108905792\n",
      "Epoch 3::Minibatch 129::LR 0.0953846153846 --> Loss 0.00306445558866\n",
      "Epoch 3::Minibatch 130::LR 0.0953846153846 --> Loss 0.00457930246989\n",
      "Epoch 3::Minibatch 131::LR 0.0953846153846 --> Loss 0.00191102464994\n",
      "Epoch 3::Minibatch 132::LR 0.0953846153846 --> Loss 0.0033272343874\n",
      "Epoch 3::Minibatch 133::LR 0.0953846153846 --> Loss 0.0032185480992\n",
      "Epoch 3::Minibatch 134::LR 0.0953846153846 --> Loss 0.00267072657744\n",
      "Epoch 3::Minibatch 135::LR 0.0953846153846 --> Loss 0.00183239281178\n",
      "Epoch 3::Minibatch 136::LR 0.0953846153846 --> Loss 0.00297989328702\n",
      "Epoch 3::Minibatch 137::LR 0.0953846153846 --> Loss 0.00387284874916\n",
      "Epoch 3::Minibatch 138::LR 0.0953846153846 --> Loss 0.00138717651367\n",
      "Epoch 3::Minibatch 139::LR 0.0953846153846 --> Loss 0.00198253472646\n",
      "Epoch 3::Minibatch 140::LR 0.0953846153846 --> Loss 0.00253458976746\n",
      "Epoch 3::Minibatch 141::LR 0.0953846153846 --> Loss 0.00292026678721\n",
      "Epoch 3::Minibatch 142::LR 0.0953846153846 --> Loss 0.0031285371383\n",
      "Epoch 3::Minibatch 143::LR 0.0953846153846 --> Loss 0.000608037412167\n",
      "Epoch 3::Minibatch 144::LR 0.0953846153846 --> Loss 0.00323600073655\n",
      "Epoch 3::Minibatch 145::LR 0.0953846153846 --> Loss 0.00441566308339\n",
      "Epoch 3::Minibatch 146::LR 0.0953846153846 --> Loss 0.00271520713965\n",
      "Epoch 3::Minibatch 147::LR 0.0953846153846 --> Loss 0.0018931188186\n",
      "Epoch 3::Minibatch 148::LR 0.0953846153846 --> Loss 0.00103753884633\n",
      "Epoch 3::Minibatch 149::LR 0.0953846153846 --> Loss 0.00284357786179\n",
      "Epoch 3::Minibatch 150::LR 0.0953846153846 --> Loss 0.00273604472478\n",
      "Epoch 3::Minibatch 151::LR 0.0953846153846 --> Loss 0.00423287908236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 152::LR 0.0953846153846 --> Loss 0.000912319819132\n",
      "Epoch 3::Minibatch 153::LR 0.0953846153846 --> Loss 0.00192676325639\n",
      "Epoch 3::Minibatch 154::LR 0.0953846153846 --> Loss 0.00208682517211\n",
      "Epoch 3::Minibatch 155::LR 0.0953846153846 --> Loss 0.00474303642909\n",
      "Epoch 3::Minibatch 156::LR 0.0953846153846 --> Loss 0.00228285411994\n",
      "Epoch 3::Minibatch 157::LR 0.0953846153846 --> Loss 0.000693736324708\n",
      "Epoch 3::Minibatch 158::LR 0.0953846153846 --> Loss 0.00297347565492\n",
      "Epoch 3::Minibatch 159::LR 0.0953846153846 --> Loss 0.00276442249616\n",
      "Epoch 3::Minibatch 160::LR 0.0953846153846 --> Loss 0.00273625274499\n",
      "Epoch 3::Minibatch 161::LR 0.0953846153846 --> Loss 0.00103033473094\n",
      "Epoch 3::Minibatch 162::LR 0.0953846153846 --> Loss 0.00369073390961\n",
      "Epoch 3::Minibatch 163::LR 0.0953846153846 --> Loss 0.00238016366959\n",
      "Epoch 3::Minibatch 164::LR 0.0953846153846 --> Loss 0.00253956655661\n",
      "Epoch 3::Minibatch 165::LR 0.0953846153846 --> Loss 0.000529803385337\n",
      "Epoch 3::Minibatch 166::LR 0.0953846153846 --> Loss 0.00181999007861\n",
      "Epoch 3::Minibatch 167::LR 0.0953846153846 --> Loss 0.00247470974922\n",
      "Epoch 3::Minibatch 168::LR 0.0953846153846 --> Loss 0.00223408480485\n",
      "Epoch 3::Minibatch 169::LR 0.0953846153846 --> Loss 0.00102255145709\n",
      "Epoch 3::Minibatch 170::LR 0.0953846153846 --> Loss 0.00100099891424\n",
      "Epoch 3::Minibatch 171::LR 0.0953846153846 --> Loss 0.00247164229552\n",
      "Epoch 3::Minibatch 172::LR 0.0953846153846 --> Loss 0.00494815746943\n",
      "Epoch 3::Minibatch 173::LR 0.0953846153846 --> Loss 0.00200613419215\n",
      "Epoch 3::Minibatch 174::LR 0.0953846153846 --> Loss 0.00106637795766\n",
      "Epoch 3::Minibatch 175::LR 0.0953846153846 --> Loss 0.0022346885999\n",
      "Epoch 3::Minibatch 176::LR 0.0953846153846 --> Loss 0.00335482120514\n",
      "Epoch 3::Minibatch 177::LR 0.0953846153846 --> Loss 0.00466149568558\n",
      "Epoch 3::Minibatch 178::LR 0.0953846153846 --> Loss 0.00170235912005\n",
      "Epoch 3::Minibatch 179::LR 0.0953846153846 --> Loss 0.00136602958043\n",
      "Epoch 3::Minibatch 180::LR 0.0953846153846 --> Loss 0.00367042779922\n",
      "Epoch 3::Minibatch 181::LR 0.0953846153846 --> Loss 0.00349306980769\n",
      "Epoch 3::Minibatch 182::LR 0.0953846153846 --> Loss 0.000829450041056\n",
      "Epoch 3::Minibatch 183::LR 0.0953846153846 --> Loss 0.00168283363183\n",
      "Epoch 3::Minibatch 184::LR 0.0953846153846 --> Loss 0.00349853356679\n",
      "Epoch 3::Minibatch 185::LR 0.0953846153846 --> Loss 0.00266501824061\n",
      "Epoch 3::Minibatch 186::LR 0.0953846153846 --> Loss 0.00102631678184\n",
      "Epoch 3::Minibatch 187::LR 0.0953846153846 --> Loss 0.00124227474133\n",
      "Epoch 3::Minibatch 188::LR 0.0953846153846 --> Loss 0.00394473115603\n",
      "Epoch 3::Minibatch 189::LR 0.0953846153846 --> Loss 0.00474565704664\n",
      "Epoch 3::Minibatch 190::LR 0.0953846153846 --> Loss 0.00230327645938\n",
      "Epoch 3::Minibatch 191::LR 0.0953846153846 --> Loss 0.000453383028507\n",
      "Epoch 3::Minibatch 192::LR 0.0953846153846 --> Loss 0.00256597816944\n",
      "Epoch 3::Minibatch 193::LR 0.0953846153846 --> Loss 0.00247934917609\n",
      "Epoch 3::Minibatch 194::LR 0.0953846153846 --> Loss 0.0017645072937\n",
      "Epoch 3::Minibatch 195::LR 0.0953846153846 --> Loss 0.000405977020661\n",
      "Epoch 3::Minibatch 196::LR 0.0953846153846 --> Loss 0.00111986368895\n",
      "Epoch 3::Minibatch 197::LR 0.0953846153846 --> Loss 0.0027246171236\n",
      "Epoch 3::Minibatch 198::LR 0.0953846153846 --> Loss 0.00207641144594\n",
      "Epoch 3::Minibatch 199::LR 0.0953846153846 --> Loss 0.00029642013212\n",
      "Epoch 3::Minibatch 200::LR 0.0953846153846 --> Loss 0.00205549716949\n",
      "Epoch 3::Minibatch 201::LR 0.0953846153846 --> Loss 0.00200848142306\n",
      "Epoch 3::Minibatch 202::LR 0.0953846153846 --> Loss 0.00187116424243\n",
      "Epoch 3::Minibatch 203::LR 0.0953846153846 --> Loss 0.0018611907959\n",
      "Epoch 3::Minibatch 204::LR 0.0953846153846 --> Loss 0.00146087100108\n",
      "Epoch 3::Minibatch 205::LR 0.0953846153846 --> Loss 0.00219545404116\n",
      "Epoch 3::Minibatch 206::LR 0.0953846153846 --> Loss 0.00668726285299\n",
      "Epoch 3::Minibatch 207::LR 0.0953846153846 --> Loss 0.0014470444123\n",
      "Epoch 3::Minibatch 208::LR 0.0953846153846 --> Loss 0.0011325982213\n",
      "Epoch 3::Minibatch 209::LR 0.0953846153846 --> Loss 0.00194599747658\n",
      "Epoch 3::Minibatch 210::LR 0.0953846153846 --> Loss 0.00186159292857\n",
      "Epoch 3::Minibatch 211::LR 0.0953846153846 --> Loss 0.00197707176208\n",
      "Epoch 3::Minibatch 212::LR 0.0953846153846 --> Loss 0.00429994662603\n",
      "Epoch 3::Minibatch 213::LR 0.0953846153846 --> Loss 0.00617361982663\n",
      "Epoch 3::Minibatch 214::LR 0.0953846153846 --> Loss 0.0104107077916\n",
      "Epoch 3::Minibatch 215::LR 0.0953846153846 --> Loss 0.00133188893398\n",
      "Epoch 3::Minibatch 216::LR 0.0953846153846 --> Loss 0.00538376609484\n",
      "Epoch 3::Minibatch 217::LR 0.0953846153846 --> Loss 0.00561923305194\n",
      "Epoch 3::Minibatch 218::LR 0.0953846153846 --> Loss 0.00400538126628\n",
      "Epoch 3::Minibatch 219::LR 0.0953846153846 --> Loss 0.00352208654086\n",
      "Epoch 3::Minibatch 220::LR 0.0953846153846 --> Loss 0.00462902267774\n",
      "Epoch 3::Minibatch 221::LR 0.0953846153846 --> Loss 0.00421816547712\n",
      "Epoch 3::Minibatch 222::LR 0.0953846153846 --> Loss 0.00343239625295\n",
      "Epoch 3::Minibatch 223::LR 0.0953846153846 --> Loss 0.0012939898173\n",
      "Epoch 3::Minibatch 224::LR 0.0953846153846 --> Loss 0.00176403959592\n",
      "Epoch 3::Minibatch 225::LR 0.0953846153846 --> Loss 0.00695809920629\n",
      "Epoch 3::Minibatch 226::LR 0.0953846153846 --> Loss 0.0038761595885\n",
      "Epoch 3::Minibatch 227::LR 0.0953846153846 --> Loss 0.00177123904228\n",
      "Epoch 3::Minibatch 228::LR 0.0953846153846 --> Loss 0.000764357894659\n",
      "Epoch 3::Minibatch 229::LR 0.0953846153846 --> Loss 0.00460068583488\n",
      "Epoch 3::Minibatch 230::LR 0.0953846153846 --> Loss 0.00412235299746\n",
      "Epoch 3::Minibatch 231::LR 0.0953846153846 --> Loss 0.00267383734385\n",
      "Epoch 3::Minibatch 232::LR 0.0953846153846 --> Loss 0.00120564152797\n",
      "Epoch 3::Minibatch 233::LR 0.0953846153846 --> Loss 0.00233047525088\n",
      "Epoch 3::Minibatch 234::LR 0.0953846153846 --> Loss 0.00670511484146\n",
      "Epoch 3::Minibatch 235::LR 0.0953846153846 --> Loss 0.00466503938039\n",
      "Epoch 3::Minibatch 236::LR 0.0953846153846 --> Loss 0.00182610034943\n",
      "Epoch 3::Minibatch 237::LR 0.0953846153846 --> Loss 0.000709071457386\n",
      "Epoch 3::Minibatch 238::LR 0.0953846153846 --> Loss 0.00341048518817\n",
      "Epoch 3::Minibatch 239::LR 0.0953846153846 --> Loss 0.00293140610059\n",
      "Epoch 3::Minibatch 240::LR 0.0953846153846 --> Loss 0.00330966571967\n",
      "Epoch 3::Minibatch 241::LR 0.0953846153846 --> Loss 0.000760117570559\n",
      "Epoch 3::Minibatch 242::LR 0.0953846153846 --> Loss 0.00737054109573\n",
      "Epoch 3::Minibatch 243::LR 0.0953846153846 --> Loss 0.00368413805962\n",
      "Epoch 3::Minibatch 244::LR 0.0953846153846 --> Loss 0.00308030704657\n",
      "Epoch 3::Minibatch 245::LR 0.0953846153846 --> Loss 0.000509295215209\n",
      "Epoch 3::Minibatch 246::LR 0.0953846153846 --> Loss 0.00211771965027\n",
      "Epoch 3::Minibatch 247::LR 0.0953846153846 --> Loss 0.0141787481308\n",
      "Epoch 3::Minibatch 248::LR 0.0953846153846 --> Loss 0.00433701634407\n",
      "Epoch 3::Minibatch 249::LR 0.0953846153846 --> Loss 0.00291240016619\n",
      "Epoch 3::Minibatch 250::LR 0.0953846153846 --> Loss 0.00270678381125\n",
      "Epoch 3::Minibatch 251::LR 0.0953846153846 --> Loss 0.00256253619989\n",
      "Epoch 3::Minibatch 252::LR 0.0953846153846 --> Loss 0.00187469482422\n",
      "Epoch 3::Minibatch 253::LR 0.0953846153846 --> Loss 0.00323350965977\n",
      "Epoch 3::Minibatch 254::LR 0.0953846153846 --> Loss 0.00541194240252\n",
      "Epoch 3::Minibatch 255::LR 0.0953846153846 --> Loss 0.00398938894272\n",
      "Epoch 3::Minibatch 256::LR 0.0953846153846 --> Loss 0.0018755064408\n",
      "Epoch 3::Minibatch 257::LR 0.0953846153846 --> Loss 0.00125120311975\n",
      "Epoch 3::Minibatch 258::LR 0.0953846153846 --> Loss 0.00361508011818\n",
      "Epoch 3::Minibatch 259::LR 0.0953846153846 --> Loss 0.00184347073237\n",
      "Epoch 3::Minibatch 260::LR 0.0953846153846 --> Loss 0.00183304786682\n",
      "Epoch 3::Minibatch 261::LR 0.0953846153846 --> Loss 0.00303276817004\n",
      "Epoch 3::Minibatch 262::LR 0.0953846153846 --> Loss 0.00202219704787\n",
      "Epoch 3::Minibatch 263::LR 0.0953846153846 --> Loss 0.00230613470078\n",
      "Epoch 3::Minibatch 264::LR 0.0953846153846 --> Loss 0.00365789055824\n",
      "Epoch 3::Minibatch 265::LR 0.0953846153846 --> Loss 0.00914332230886\n",
      "Epoch 3::Minibatch 266::LR 0.0953846153846 --> Loss 0.00109887739023\n",
      "Epoch 3::Minibatch 267::LR 0.0953846153846 --> Loss 0.0101596275965\n",
      "Epoch 3::Minibatch 268::LR 0.0953846153846 --> Loss 0.00129913955927\n",
      "Epoch 3::Minibatch 269::LR 0.0953846153846 --> Loss 0.00363135615985\n",
      "Epoch 3::Minibatch 270::LR 0.0953846153846 --> Loss 0.0058697505792\n",
      "Epoch 3::Minibatch 271::LR 0.0953846153846 --> Loss 0.00294975002607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 272::LR 0.0953846153846 --> Loss 0.0039469341437\n",
      "Epoch 3::Minibatch 273::LR 0.0953846153846 --> Loss 0.00189192056656\n",
      "Epoch 3::Minibatch 274::LR 0.0953846153846 --> Loss 0.00178907672564\n",
      "Epoch 3::Minibatch 275::LR 0.0953846153846 --> Loss 0.00279498656591\n",
      "Epoch 3::Minibatch 276::LR 0.0953846153846 --> Loss 0.00344092289607\n",
      "Epoch 3::Minibatch 277::LR 0.0953846153846 --> Loss 0.00105382899443\n",
      "Epoch 3::Minibatch 278::LR 0.0953846153846 --> Loss 0.00266076783339\n",
      "Epoch 3::Minibatch 279::LR 0.0953846153846 --> Loss 0.00255961815516\n",
      "Epoch 3::Minibatch 280::LR 0.0953846153846 --> Loss 0.00218352019787\n",
      "Epoch 3::Minibatch 281::LR 0.0953846153846 --> Loss 0.00131490975618\n",
      "Epoch 3::Minibatch 282::LR 0.0953846153846 --> Loss 0.00229157924652\n",
      "Epoch 3::Minibatch 283::LR 0.0953846153846 --> Loss 0.00225665986538\n",
      "Epoch 3::Minibatch 284::LR 0.0953846153846 --> Loss 0.00174565335115\n",
      "Epoch 3::Minibatch 285::LR 0.0953846153846 --> Loss 0.0011789838473\n",
      "Epoch 3::Minibatch 286::LR 0.0953846153846 --> Loss 0.00213412125905\n",
      "Epoch 3::Minibatch 287::LR 0.0953846153846 --> Loss 0.00204930086931\n",
      "Epoch 3::Minibatch 288::LR 0.0953846153846 --> Loss 0.00103865981102\n",
      "Epoch 3::Minibatch 289::LR 0.0953846153846 --> Loss 0.00150877386332\n",
      "Epoch 3::Minibatch 290::LR 0.0953846153846 --> Loss 0.00189080953598\n",
      "Epoch 3::Minibatch 291::LR 0.0953846153846 --> Loss 0.00164787818988\n",
      "Epoch 3::Minibatch 292::LR 0.0953846153846 --> Loss 0.000573935508728\n",
      "Epoch 3::Minibatch 293::LR 0.0953846153846 --> Loss 0.0014043183128\n",
      "Epoch 3::Minibatch 294::LR 0.0953846153846 --> Loss 0.00151228706042\n",
      "Epoch 3::Minibatch 295::LR 0.0953846153846 --> Loss 0.00176529129346\n",
      "Epoch 3::Minibatch 296::LR 0.0953846153846 --> Loss 0.00147462874651\n",
      "Epoch 3::Minibatch 297::LR 0.0953846153846 --> Loss 0.00131562838952\n",
      "Epoch 3::Minibatch 298::LR 0.0953846153846 --> Loss 0.00125250637531\n",
      "Epoch 3::Minibatch 299::LR 0.0953846153846 --> Loss 0.000705063243707\n",
      "Epoch 3::Minibatch 300::LR 0.0953846153846 --> Loss 0.00289153754711\n",
      "Epoch 3::Minibatch 301::LR 0.0953846153846 --> Loss 0.00279341578484\n",
      "Epoch 3::Minibatch 302::LR 0.0953846153846 --> Loss 0.00254844009876\n",
      "Epoch 3::Minibatch 303::LR 0.0953846153846 --> Loss 0.000845117171605\n",
      "Epoch 3::Minibatch 304::LR 0.0953846153846 --> Loss 0.00314301649729\n",
      "Epoch 3::Minibatch 305::LR 0.0953846153846 --> Loss 0.00165039211512\n",
      "Epoch 3::Minibatch 306::LR 0.0953846153846 --> Loss 0.000904443164666\n",
      "Epoch 3::Minibatch 307::LR 0.0953846153846 --> Loss 0.00255104223887\n",
      "Epoch 3::Minibatch 308::LR 0.0953846153846 --> Loss 0.00193753103415\n",
      "Epoch 3::Minibatch 309::LR 0.0953846153846 --> Loss 0.000945285260677\n",
      "Epoch 3::Minibatch 310::LR 0.0953846153846 --> Loss 0.00101426114639\n",
      "Epoch 3::Minibatch 311::LR 0.0953846153846 --> Loss 0.00161136110624\n",
      "Epoch 3::Minibatch 312::LR 0.0953846153846 --> Loss 0.00304848849773\n",
      "Epoch 3::Minibatch 313::LR 0.0953846153846 --> Loss 0.00237241764863\n",
      "Epoch 3::Minibatch 314::LR 0.0953846153846 --> Loss 0.0018804470698\n",
      "Epoch 3::Minibatch 315::LR 0.0953846153846 --> Loss 0.000948629279931\n",
      "Epoch 3::Minibatch 316::LR 0.0953846153846 --> Loss 0.00229552209377\n",
      "Epoch 3::Minibatch 317::LR 0.0953846153846 --> Loss 0.00149134427309\n",
      "Epoch 3::Minibatch 318::LR 0.0953846153846 --> Loss 0.00111440072457\n",
      "Epoch 3::Minibatch 319::LR 0.0953846153846 --> Loss 0.00223168273767\n",
      "Epoch 3::Minibatch 320::LR 0.0953846153846 --> Loss 0.00323123077552\n",
      "Epoch 3::Minibatch 321::LR 0.0953846153846 --> Loss 0.000824266076088\n",
      "Epoch 3::Minibatch 322::LR 0.0953846153846 --> Loss 0.00361410140991\n",
      "Epoch 3::Minibatch 323::LR 0.0953846153846 --> Loss 0.00349597613017\n",
      "Epoch 3::Minibatch 324::LR 0.0953846153846 --> Loss 0.00265306154887\n",
      "Epoch 3::Minibatch 325::LR 0.0953846153846 --> Loss 0.00248328387737\n",
      "Epoch 3::Minibatch 326::LR 0.0953846153846 --> Loss 0.00573169986407\n",
      "Epoch 3::Minibatch 327::LR 0.0953846153846 --> Loss 0.00221563398838\n",
      "Epoch 3::Minibatch 328::LR 0.0953846153846 --> Loss 0.00345162034035\n",
      "Epoch 3::Minibatch 329::LR 0.0953846153846 --> Loss 0.00122261246045\n",
      "Epoch 3::Minibatch 330::LR 0.0953846153846 --> Loss 0.00158157120148\n",
      "Epoch 3::Minibatch 331::LR 0.0953846153846 --> Loss 0.00251929799716\n",
      "Epoch 3::Minibatch 332::LR 0.0953846153846 --> Loss 0.00250546634197\n",
      "Epoch 3::Minibatch 333::LR 0.0953846153846 --> Loss 0.00138490865628\n",
      "Epoch 3::Minibatch 334::LR 0.0953846153846 --> Loss 0.00414345105489\n",
      "Epoch 3::Minibatch 335::LR 0.0953846153846 --> Loss 0.00185639063517\n",
      "Epoch 3::Minibatch 336::LR 0.0953846153846 --> Loss 0.00202852984269\n",
      "Epoch 3::Minibatch 337::LR 0.0953846153846 --> Loss 0.00310213108857\n",
      "Epoch 3::Minibatch 338::LR 0.0953846153846 --> Loss 0.00048811674118\n",
      "Epoch 3::Minibatch 339::LR 0.0953846153846 --> Loss 0.00335899273554\n",
      "Epoch 3::Minibatch 340::LR 0.0953846153846 --> Loss 0.0047208460172\n",
      "Epoch 3::Minibatch 341::LR 0.0953846153846 --> Loss 0.00486238121986\n",
      "Epoch 3::Minibatch 342::LR 0.0953846153846 --> Loss 0.00331502636274\n",
      "Epoch 3::Minibatch 343::LR 0.0953846153846 --> Loss 0.00170017540455\n",
      "Epoch 3::Minibatch 344::LR 0.0953846153846 --> Loss 0.0029256772995\n",
      "Epoch 3::Minibatch 345::LR 0.0953846153846 --> Loss 0.00433012882868\n",
      "Epoch 3::Minibatch 346::LR 0.0953846153846 --> Loss 0.00584778229396\n",
      "Epoch 3::Minibatch 347::LR 0.0953846153846 --> Loss 0.000893412828445\n",
      "Epoch 3::Minibatch 348::LR 0.0953846153846 --> Loss 0.00379985690117\n",
      "Epoch 3::Minibatch 349::LR 0.0953846153846 --> Loss 0.00350967486699\n",
      "Epoch 3::Minibatch 350::LR 0.0953846153846 --> Loss 0.0017605950435\n",
      "Epoch 3::Minibatch 351::LR 0.0953846153846 --> Loss 0.0036478471756\n",
      "Epoch 3::Minibatch 352::LR 0.0953846153846 --> Loss 0.00482056975365\n",
      "Epoch 3::Minibatch 353::LR 0.0953846153846 --> Loss 0.00354516943296\n",
      "Epoch 3::Minibatch 354::LR 0.0953846153846 --> Loss 0.00297584255536\n",
      "Epoch 3::Minibatch 355::LR 0.0953846153846 --> Loss 0.00588666359584\n",
      "Epoch 3::Minibatch 356::LR 0.0953846153846 --> Loss 0.00305433471998\n",
      "Epoch 3::Minibatch 357::LR 0.0953846153846 --> Loss 0.0010307431221\n",
      "Epoch 3::Minibatch 358::LR 0.0953846153846 --> Loss 0.00216250856717\n",
      "Epoch 3::Minibatch 359::LR 0.0953846153846 --> Loss 0.00269646247228\n",
      "Epoch 3::Minibatch 360::LR 0.0953846153846 --> Loss 0.00251938422521\n",
      "Epoch 3::Minibatch 361::LR 0.0953846153846 --> Loss 0.00244455416997\n",
      "Epoch 3::Minibatch 362::LR 0.0953846153846 --> Loss 0.00247250517209\n",
      "Epoch 3::Minibatch 363::LR 0.0953846153846 --> Loss 0.000669510215521\n",
      "Epoch 3::Minibatch 364::LR 0.0953846153846 --> Loss 0.0020214976867\n",
      "Epoch 3::Minibatch 365::LR 0.0953846153846 --> Loss 0.00208421210448\n",
      "Epoch 3::Minibatch 366::LR 0.0953846153846 --> Loss 0.00226373553276\n",
      "Epoch 3::Minibatch 367::LR 0.0953846153846 --> Loss 0.00108309537172\n",
      "Epoch 3::Minibatch 368::LR 0.0953846153846 --> Loss 0.000968799988429\n",
      "Epoch 3::Minibatch 369::LR 0.0953846153846 --> Loss 0.00291210770607\n",
      "Epoch 3::Minibatch 370::LR 0.0953846153846 --> Loss 0.00224168221156\n",
      "Epoch 3::Minibatch 371::LR 0.0953846153846 --> Loss 0.00178481777509\n",
      "Epoch 3::Minibatch 372::LR 0.0953846153846 --> Loss 0.000418059279521\n",
      "Epoch 3::Minibatch 373::LR 0.0953846153846 --> Loss 0.00173323512077\n",
      "Epoch 3::Minibatch 374::LR 0.0953846153846 --> Loss 0.00207442104816\n",
      "Epoch 3::Minibatch 375::LR 0.0953846153846 --> Loss 0.00177737752597\n",
      "Epoch 3::Minibatch 376::LR 0.0953846153846 --> Loss 0.0012040946881\n",
      "Epoch 3::Minibatch 377::LR 0.0953846153846 --> Loss 0.00193198104699\n",
      "Epoch 3::Minibatch 378::LR 0.0953846153846 --> Loss 0.00207609812419\n",
      "Epoch 3::Minibatch 379::LR 0.0953846153846 --> Loss 0.00235406061014\n",
      "Epoch 3::Minibatch 380::LR 0.0953846153846 --> Loss 0.00157162328561\n",
      "Epoch 3::Minibatch 381::LR 0.0953846153846 --> Loss 0.000951331853867\n",
      "Epoch 3::Minibatch 382::LR 0.0953846153846 --> Loss 0.00197404603163\n",
      "Epoch 3::Minibatch 383::LR 0.0953846153846 --> Loss 0.00185034116109\n",
      "Epoch 3::Minibatch 384::LR 0.0953846153846 --> Loss 0.00101151247819\n",
      "Epoch 3::Minibatch 385::LR 0.0953846153846 --> Loss 0.000994662940502\n",
      "Epoch 3::Minibatch 386::LR 0.0953846153846 --> Loss 0.00211365858714\n",
      "Epoch 3::Minibatch 387::LR 0.0953846153846 --> Loss 0.00223906636238\n",
      "Epoch 3::Minibatch 388::LR 0.0953846153846 --> Loss 0.0010919452707\n",
      "Epoch 3::Minibatch 389::LR 0.0953846153846 --> Loss 0.00181610723337\n",
      "Epoch 3::Minibatch 390::LR 0.0953846153846 --> Loss 0.00362721125285\n",
      "Epoch 3::Minibatch 391::LR 0.0953846153846 --> Loss 0.00263154188792\n",
      "Epoch 3::Minibatch 392::LR 0.0953846153846 --> Loss 0.00257218539715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 393::LR 0.0953846153846 --> Loss 0.00273912628492\n",
      "Epoch 3::Minibatch 394::LR 0.0953846153846 --> Loss 0.00196114699046\n",
      "Epoch 3::Minibatch 395::LR 0.0953846153846 --> Loss 0.00199054976304\n",
      "Epoch 3::Minibatch 396::LR 0.0953846153846 --> Loss 0.00190496961276\n",
      "Epoch 3::Minibatch 397::LR 0.0953846153846 --> Loss 0.00203122079372\n",
      "Epoch 3::Minibatch 398::LR 0.0953846153846 --> Loss 0.00197453816732\n",
      "Epoch 3::Minibatch 399::LR 0.0953846153846 --> Loss 0.00229306896528\n",
      "Epoch 3::Minibatch 400::LR 0.0953846153846 --> Loss 0.00194721519947\n",
      "Epoch 3::Minibatch 401::LR 0.0953846153846 --> Loss 0.00333393772443\n",
      "Epoch 3::Minibatch 402::LR 0.0953846153846 --> Loss 0.00175426801046\n",
      "Epoch 3::Minibatch 403::LR 0.0953846153846 --> Loss 0.00139826824268\n",
      "Epoch 3::Minibatch 404::LR 0.0953846153846 --> Loss 0.0013917623957\n",
      "Epoch 3::Minibatch 405::LR 0.0953846153846 --> Loss 0.0032530272007\n",
      "Epoch 3::Minibatch 406::LR 0.0953846153846 --> Loss 0.00235168238481\n",
      "Epoch 3::Minibatch 407::LR 0.0953846153846 --> Loss 0.00165984531244\n",
      "Epoch 3::Minibatch 408::LR 0.0953846153846 --> Loss 0.000425016184648\n",
      "Epoch 3::Minibatch 409::LR 0.0953846153846 --> Loss 0.00221306145191\n",
      "Epoch 3::Minibatch 410::LR 0.0953846153846 --> Loss 0.00307022412618\n",
      "Epoch 3::Minibatch 411::LR 0.0953846153846 --> Loss 0.00146867781878\n",
      "Epoch 3::Minibatch 412::LR 0.0953846153846 --> Loss 0.000891820589701\n",
      "Epoch 3::Minibatch 413::LR 0.0953846153846 --> Loss 0.00180428206921\n",
      "Epoch 3::Minibatch 414::LR 0.0953846153846 --> Loss 0.00174660523733\n",
      "Epoch 3::Minibatch 415::LR 0.0953846153846 --> Loss 0.00105587820212\n",
      "Epoch 3::Minibatch 416::LR 0.0953846153846 --> Loss 0.000754642486572\n",
      "Epoch 3::Minibatch 417::LR 0.0953846153846 --> Loss 0.00159707138936\n",
      "Epoch 3::Minibatch 418::LR 0.0953846153846 --> Loss 0.00269998947779\n",
      "Epoch 3::Minibatch 419::LR 0.0953846153846 --> Loss 0.000465732365847\n",
      "Epoch 3::Minibatch 420::LR 0.0953846153846 --> Loss 0.000614657700062\n",
      "Epoch 3::Minibatch 421::LR 0.0953846153846 --> Loss 0.00183984776338\n",
      "Epoch 3::Minibatch 422::LR 0.0953846153846 --> Loss 0.00202129046122\n",
      "Epoch 3::Minibatch 423::LR 0.0953846153846 --> Loss 0.000873787999153\n",
      "Epoch 3::Minibatch 424::LR 0.0953846153846 --> Loss 0.00145887802045\n",
      "Epoch 3::Minibatch 425::LR 0.0953846153846 --> Loss 0.00280830423037\n",
      "Epoch 3::Minibatch 426::LR 0.0953846153846 --> Loss 0.00182751476765\n",
      "Epoch 3::Minibatch 427::LR 0.0953846153846 --> Loss 0.000668576806784\n",
      "Epoch 3::Minibatch 428::LR 0.0953846153846 --> Loss 0.00110687196255\n",
      "Epoch 3::Minibatch 429::LR 0.0953846153846 --> Loss 0.00249975581964\n",
      "Epoch 3::Minibatch 430::LR 0.0953846153846 --> Loss 0.0105824232101\n",
      "Epoch 3::Minibatch 431::LR 0.0953846153846 --> Loss 0.00410850803057\n",
      "Epoch 3::Minibatch 432::LR 0.0953846153846 --> Loss 0.00472371657689\n",
      "Epoch 3::Minibatch 433::LR 0.0953846153846 --> Loss 0.00257148901622\n",
      "Epoch 3::Minibatch 434::LR 0.0953846153846 --> Loss 0.00258566498756\n",
      "Epoch 3::Minibatch 435::LR 0.0953846153846 --> Loss 0.0023618632555\n",
      "Epoch 3::Minibatch 436::LR 0.0953846153846 --> Loss 0.00157966295878\n",
      "Epoch 3::Minibatch 437::LR 0.0953846153846 --> Loss 0.00310839255651\n",
      "Epoch 3::Minibatch 438::LR 0.0953846153846 --> Loss 0.00263866484165\n",
      "Epoch 3::Minibatch 439::LR 0.0953846153846 --> Loss 0.00209585706393\n",
      "Epoch 3::Minibatch 440::LR 0.0953846153846 --> Loss 0.00320800364017\n",
      "Epoch 3::Minibatch 441::LR 0.0953846153846 --> Loss 0.00299903253714\n",
      "Epoch 3::Minibatch 442::LR 0.0953846153846 --> Loss 0.00266265134017\n",
      "Epoch 3::Minibatch 443::LR 0.0953846153846 --> Loss 0.00348160505295\n",
      "Epoch 3::Minibatch 444::LR 0.0953846153846 --> Loss 0.00273789048195\n",
      "Epoch 3::Minibatch 445::LR 0.0953846153846 --> Loss 0.000865075488885\n",
      "Epoch 3::Minibatch 446::LR 0.0953846153846 --> Loss 0.00141720275084\n",
      "Epoch 3::Minibatch 447::LR 0.0953846153846 --> Loss 0.00235729932785\n",
      "Epoch 3::Minibatch 448::LR 0.0953846153846 --> Loss 0.00229738652706\n",
      "Epoch 3::Minibatch 449::LR 0.0953846153846 --> Loss 0.00362481077512\n",
      "Epoch 3::Minibatch 450::LR 0.0953846153846 --> Loss 0.0021272645394\n",
      "Epoch 3::Minibatch 451::LR 0.0953846153846 --> Loss 0.00417564471563\n",
      "Epoch 3::Minibatch 452::LR 0.0953846153846 --> Loss 0.00231813132763\n",
      "Epoch 3::Minibatch 453::LR 0.0953846153846 --> Loss 0.000345384354393\n",
      "Epoch 3::Minibatch 454::LR 0.0953846153846 --> Loss 0.00360601902008\n",
      "Epoch 3::Minibatch 455::LR 0.0953846153846 --> Loss 0.00259975115458\n",
      "Epoch 3::Minibatch 456::LR 0.0953846153846 --> Loss 0.00308312853177\n",
      "Epoch 3::Minibatch 457::LR 0.0953846153846 --> Loss 0.00191762407621\n",
      "Epoch 3::Minibatch 458::LR 0.0953846153846 --> Loss 0.000712127238512\n",
      "Epoch 3::Minibatch 459::LR 0.0953846153846 --> Loss 0.0039573319753\n",
      "Epoch 3::Minibatch 460::LR 0.0953846153846 --> Loss 0.00248559097449\n",
      "Epoch 3::Minibatch 461::LR 0.0953846153846 --> Loss 0.00399730245272\n",
      "Epoch 3::Minibatch 462::LR 0.0953846153846 --> Loss 0.000350764145454\n",
      "Epoch 3::Minibatch 463::LR 0.0953846153846 --> Loss 0.00423837105433\n",
      "Epoch 3::Minibatch 464::LR 0.0953846153846 --> Loss 0.00199843863646\n",
      "Epoch 3::Minibatch 465::LR 0.0953846153846 --> Loss 0.00468260248502\n",
      "Epoch 3::Minibatch 466::LR 0.0953846153846 --> Loss 0.00517964323362\n",
      "Epoch 3::Minibatch 467::LR 0.0953846153846 --> Loss 0.0056120467186\n",
      "Epoch 3::Minibatch 468::LR 0.0953846153846 --> Loss 0.00595571994781\n",
      "Epoch 3::Minibatch 469::LR 0.0953846153846 --> Loss 0.00601839621862\n",
      "Epoch 3::Minibatch 470::LR 0.0953846153846 --> Loss 0.00358373999596\n",
      "Epoch 3::Minibatch 471::LR 0.0953846153846 --> Loss 0.00176990409692\n",
      "Epoch 3::Minibatch 472::LR 0.0953846153846 --> Loss 0.00350659211477\n",
      "Epoch 3::Minibatch 473::LR 0.0953846153846 --> Loss 0.00225464463234\n",
      "Epoch 3::Minibatch 474::LR 0.0953846153846 --> Loss 0.000654847025871\n",
      "Epoch 3::Minibatch 475::LR 0.0953846153846 --> Loss 0.00511862476667\n",
      "Epoch 3::Minibatch 476::LR 0.0953846153846 --> Loss 0.00689002752304\n",
      "Epoch 3::Minibatch 477::LR 0.0953846153846 --> Loss 0.000949646830559\n",
      "Epoch 3::Minibatch 478::LR 0.0953846153846 --> Loss 0.00254885395368\n",
      "Epoch 3::Minibatch 479::LR 0.0953846153846 --> Loss 0.00199680805206\n",
      "Epoch 3::Minibatch 480::LR 0.0953846153846 --> Loss 0.00160713046789\n",
      "Epoch 3::Minibatch 481::LR 0.0953846153846 --> Loss 0.000987427135309\n",
      "Epoch 3::Minibatch 482::LR 0.0953846153846 --> Loss 0.00215309003989\n",
      "Epoch 3::Minibatch 483::LR 0.0953846153846 --> Loss 0.00336403846741\n",
      "Epoch 3::Minibatch 484::LR 0.0953846153846 --> Loss 0.00356724778811\n",
      "Epoch 3::Minibatch 485::LR 0.0953846153846 --> Loss 0.000753190517426\n",
      "Epoch 3::Minibatch 486::LR 0.0953846153846 --> Loss 0.00311754345894\n",
      "Epoch 3::Minibatch 487::LR 0.0953846153846 --> Loss 0.0034644472599\n",
      "Epoch 3::Minibatch 488::LR 0.0953846153846 --> Loss 0.00208910981814\n",
      "Epoch 3::Minibatch 489::LR 0.0953846153846 --> Loss 0.00326229095459\n",
      "Epoch 3::Minibatch 490::LR 0.0953846153846 --> Loss 0.000382621114453\n",
      "Epoch 3::Minibatch 491::LR 0.0953846153846 --> Loss 0.00351544896762\n",
      "Epoch 3::Minibatch 492::LR 0.0953846153846 --> Loss 0.00301171779633\n",
      "Epoch 3::Minibatch 493::LR 0.0953846153846 --> Loss 0.00304088036219\n",
      "Epoch 3::Minibatch 494::LR 0.0953846153846 --> Loss 0.000720956623554\n",
      "Epoch 3::Minibatch 495::LR 0.0953846153846 --> Loss 0.00189708610376\n",
      "Epoch 3::Minibatch 496::LR 0.0953846153846 --> Loss 0.00298078795274\n",
      "Epoch 3::Minibatch 497::LR 0.0953846153846 --> Loss 0.000887715419134\n",
      "Epoch 3::Minibatch 498::LR 0.0953846153846 --> Loss 0.000529688348373\n",
      "Epoch 3::Minibatch 499::LR 0.0953846153846 --> Loss 0.00389840245247\n",
      "Epoch 3::Minibatch 500::LR 0.0953846153846 --> Loss 0.00143589685361\n",
      "Epoch 3::Minibatch 501::LR 0.0953846153846 --> Loss 0.00209760447343\n",
      "Epoch 3::Minibatch 502::LR 0.0953846153846 --> Loss 0.00382819493612\n",
      "Epoch 3::Minibatch 503::LR 0.0953846153846 --> Loss 0.00809764703115\n",
      "Epoch 3::Minibatch 504::LR 0.0953846153846 --> Loss 0.00847770770391\n",
      "Epoch 3::Minibatch 505::LR 0.0953846153846 --> Loss 0.00429493228594\n",
      "Epoch 3::Minibatch 506::LR 0.0953846153846 --> Loss 0.00337316075961\n",
      "Epoch 3::Minibatch 507::LR 0.0953846153846 --> Loss 0.00591517249743\n",
      "Epoch 3::Minibatch 508::LR 0.0953846153846 --> Loss 0.00332228104273\n",
      "Epoch 3::Minibatch 509::LR 0.0953846153846 --> Loss 0.00468819578489\n",
      "Epoch 3::Minibatch 510::LR 0.0953846153846 --> Loss 0.00488673329353\n",
      "Epoch 3::Minibatch 511::LR 0.0953846153846 --> Loss 0.00379964868228\n",
      "Epoch 3::Minibatch 512::LR 0.0953846153846 --> Loss 0.00271311819553\n",
      "Epoch 3::Minibatch 513::LR 0.0953846153846 --> Loss 0.000674622307221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 514::LR 0.0953846153846 --> Loss 0.00248556296031\n",
      "Epoch 3::Minibatch 515::LR 0.0953846153846 --> Loss 0.00299197494984\n",
      "Epoch 3::Minibatch 516::LR 0.0953846153846 --> Loss 0.00368876655897\n",
      "Epoch 3::Minibatch 517::LR 0.0953846153846 --> Loss 0.00310090124607\n",
      "Epoch 3::Minibatch 518::LR 0.0953846153846 --> Loss 0.00252244889736\n",
      "Epoch 3::Minibatch 519::LR 0.0953846153846 --> Loss 0.00335222522418\n",
      "Epoch 3::Minibatch 520::LR 0.0953846153846 --> Loss 0.00497988382975\n",
      "Epoch 3::Minibatch 521::LR 0.0953846153846 --> Loss 0.00505439043045\n",
      "Epoch 3::Minibatch 522::LR 0.0953846153846 --> Loss 0.00736762841543\n",
      "Epoch 3::Minibatch 523::LR 0.0953846153846 --> Loss 0.00060160929958\n",
      "Epoch 3::Minibatch 524::LR 0.0953846153846 --> Loss 0.00142908275127\n",
      "Epoch 3::Minibatch 525::LR 0.0953846153846 --> Loss 0.00331701397896\n",
      "Epoch 3::Minibatch 526::LR 0.0953846153846 --> Loss 0.00416583538055\n",
      "Epoch 3::Minibatch 527::LR 0.0953846153846 --> Loss 0.00239360690117\n",
      "Epoch 3::Minibatch 528::LR 0.0953846153846 --> Loss 0.00112440705299\n",
      "Epoch 3::Minibatch 529::LR 0.0953846153846 --> Loss 0.00417959888776\n",
      "Epoch 3::Minibatch 530::LR 0.0953846153846 --> Loss 0.00434409022331\n",
      "Epoch 3::Minibatch 531::LR 0.0953846153846 --> Loss 0.0036498161157\n",
      "Epoch 3::Minibatch 532::LR 0.0953846153846 --> Loss 0.00272375464439\n",
      "Epoch 3::Minibatch 533::LR 0.0953846153846 --> Loss 0.00486402114232\n",
      "Epoch 3::Minibatch 534::LR 0.0953846153846 --> Loss 0.00346547206243\n",
      "Epoch 3::Minibatch 535::LR 0.0953846153846 --> Loss 0.00311763008436\n",
      "Epoch 3::Minibatch 536::LR 0.0953846153846 --> Loss 0.00215450962385\n",
      "Epoch 3::Minibatch 537::LR 0.0953846153846 --> Loss 0.00061209042867\n",
      "Epoch 3::Minibatch 538::LR 0.0953846153846 --> Loss 0.00170349379381\n",
      "Epoch 3::Minibatch 539::LR 0.0953846153846 --> Loss 0.00348441243172\n",
      "Epoch 3::Minibatch 540::LR 0.0953846153846 --> Loss 0.00336396098137\n",
      "Epoch 3::Minibatch 541::LR 0.0953846153846 --> Loss 0.00293545564016\n",
      "Epoch 3::Minibatch 542::LR 0.0953846153846 --> Loss 0.00256368796031\n",
      "Epoch 3::Minibatch 543::LR 0.0953846153846 --> Loss 0.00284178455671\n",
      "Epoch 3::Minibatch 544::LR 0.0953846153846 --> Loss 0.00387077967326\n",
      "Epoch 3::Minibatch 545::LR 0.0953846153846 --> Loss 0.00204937875271\n",
      "Epoch 3::Minibatch 546::LR 0.0953846153846 --> Loss 0.000626102983952\n",
      "Epoch 3::Minibatch 547::LR 0.0953846153846 --> Loss 0.00261191209157\n",
      "Epoch 3::Minibatch 548::LR 0.0953846153846 --> Loss 0.00378124594688\n",
      "Epoch 3::Minibatch 549::LR 0.0953846153846 --> Loss 0.00797459363937\n",
      "Epoch 3::Minibatch 550::LR 0.0953846153846 --> Loss 0.00114010860523\n",
      "Epoch 3::Minibatch 551::LR 0.0953846153846 --> Loss 0.00232474724452\n",
      "Epoch 3::Minibatch 552::LR 0.0953846153846 --> Loss 0.00350033362707\n",
      "Epoch 3::Minibatch 553::LR 0.0953846153846 --> Loss 0.00319148421288\n",
      "Epoch 3::Minibatch 554::LR 0.0953846153846 --> Loss 0.00349689165751\n",
      "Epoch 3::Minibatch 555::LR 0.0953846153846 --> Loss 0.00102031817039\n",
      "Epoch 3::Minibatch 556::LR 0.0953846153846 --> Loss 0.0020221199592\n",
      "Epoch 3::Minibatch 557::LR 0.0953846153846 --> Loss 0.00247411827246\n",
      "Epoch 3::Minibatch 558::LR 0.0953846153846 --> Loss 0.00374556342761\n",
      "Epoch 3::Minibatch 559::LR 0.0953846153846 --> Loss 0.00369955658913\n",
      "Epoch 3::Minibatch 560::LR 0.0953846153846 --> Loss 0.0030186855793\n",
      "Epoch 3::Minibatch 561::LR 0.0953846153846 --> Loss 0.00271896560987\n",
      "Epoch 3::Minibatch 562::LR 0.0953846153846 --> Loss 0.00243667264779\n",
      "Epoch 3::Minibatch 563::LR 0.0953846153846 --> Loss 0.00412293513616\n",
      "Epoch 3::Minibatch 564::LR 0.0953846153846 --> Loss 0.0031138308843\n",
      "Epoch 3::Minibatch 565::LR 0.0953846153846 --> Loss 0.00365918119748\n",
      "Epoch 3::Minibatch 566::LR 0.0953846153846 --> Loss 0.00231064617634\n",
      "Epoch 3::Minibatch 567::LR 0.0953846153846 --> Loss 0.00253959298134\n",
      "Epoch 3::Minibatch 568::LR 0.0953846153846 --> Loss 0.00188280304273\n",
      "Epoch 3::Minibatch 569::LR 0.0953846153846 --> Loss 0.000573053012292\n",
      "Epoch 3::Minibatch 570::LR 0.0953846153846 --> Loss 0.00173829158147\n",
      "Epoch 3::Minibatch 571::LR 0.0953846153846 --> Loss 0.00232201238473\n",
      "Epoch 3::Minibatch 572::LR 0.0953846153846 --> Loss 0.00242269297441\n",
      "Epoch 3::Minibatch 573::LR 0.0953846153846 --> Loss 0.00155975778898\n",
      "Epoch 3::Minibatch 574::LR 0.0953846153846 --> Loss 0.00105459560951\n",
      "Epoch 3::Minibatch 575::LR 0.0953846153846 --> Loss 0.00184749166171\n",
      "Epoch 3::Minibatch 576::LR 0.0953846153846 --> Loss 0.00209937651952\n",
      "Epoch 3::Minibatch 577::LR 0.0953846153846 --> Loss 0.0017018866539\n",
      "Epoch 3::Minibatch 578::LR 0.0953846153846 --> Loss 0.00135131160418\n",
      "Epoch 3::Minibatch 579::LR 0.0953846153846 --> Loss 0.00123854855696\n",
      "Epoch 3::Minibatch 580::LR 0.0953846153846 --> Loss 0.0019845410188\n",
      "Epoch 3::Minibatch 581::LR 0.0953846153846 --> Loss 0.00172485808531\n",
      "Epoch 3::Minibatch 582::LR 0.0953846153846 --> Loss 0.00413017392159\n",
      "Epoch 3::Minibatch 583::LR 0.0953846153846 --> Loss 0.000954528252284\n",
      "Epoch 3::Minibatch 584::LR 0.0953846153846 --> Loss 0.00131181061268\n",
      "Epoch 3::Minibatch 585::LR 0.0953846153846 --> Loss 0.00498612046242\n",
      "Epoch 3::Minibatch 586::LR 0.0953846153846 --> Loss 0.00418370723724\n",
      "Epoch 3::Minibatch 587::LR 0.0953846153846 --> Loss 0.00116731156905\n",
      "Epoch 3::Minibatch 588::LR 0.0953846153846 --> Loss 0.00142423619827\n",
      "Epoch 3::Minibatch 589::LR 0.0953846153846 --> Loss 0.00283363600572\n",
      "Epoch 3::Minibatch 590::LR 0.0953846153846 --> Loss 0.00195727169514\n",
      "Epoch 3::Minibatch 591::LR 0.0953846153846 --> Loss 0.00339393138885\n",
      "Epoch 3::Minibatch 592::LR 0.0953846153846 --> Loss 0.00120629022519\n",
      "Epoch 3::Minibatch 593::LR 0.0953846153846 --> Loss 0.00247996071974\n",
      "Epoch 3::Minibatch 594::LR 0.0953846153846 --> Loss 0.00286220590274\n",
      "Epoch 3::Minibatch 595::LR 0.0953846153846 --> Loss 0.00304925322533\n",
      "Epoch 3::Minibatch 596::LR 0.0953846153846 --> Loss 0.0019710958004\n",
      "Epoch 3::Minibatch 597::LR 0.0953846153846 --> Loss 0.00119739979506\n",
      "Epoch 3::Minibatch 598::LR 0.0953846153846 --> Loss 0.00291678408782\n",
      "Epoch 3::Minibatch 599::LR 0.0953846153846 --> Loss 0.00187019526958\n",
      "Epoch 3::Minibatch 600::LR 0.0953846153846 --> Loss 0.00226704001427\n",
      "Epoch 3::Minibatch 601::LR 0.0953846153846 --> Loss 0.00368260939916\n",
      "Epoch 3::Minibatch 602::LR 0.0953846153846 --> Loss 0.00212106545766\n",
      "Epoch 3::Minibatch 603::LR 0.0953846153846 --> Loss 0.00265483796597\n",
      "Epoch 3::Minibatch 604::LR 0.0953846153846 --> Loss 0.0016879983743\n",
      "Epoch 3::Minibatch 605::LR 0.0953846153846 --> Loss 0.00241049826145\n",
      "Epoch 3::Minibatch 606::LR 0.0953846153846 --> Loss 0.00196543097496\n",
      "Epoch 3::Minibatch 607::LR 0.0953846153846 --> Loss 0.000839722355207\n",
      "Epoch 3::Minibatch 608::LR 0.0953846153846 --> Loss 0.0015611204505\n",
      "Epoch 3::Minibatch 609::LR 0.0953846153846 --> Loss 0.00237102488677\n",
      "Epoch 3::Minibatch 610::LR 0.0953846153846 --> Loss 0.00369761625926\n",
      "Epoch 3::Minibatch 611::LR 0.0953846153846 --> Loss 0.00239303787549\n",
      "Epoch 3::Minibatch 612::LR 0.0953846153846 --> Loss 0.000462281703949\n",
      "Epoch 3::Minibatch 613::LR 0.0953846153846 --> Loss 0.00131668935219\n",
      "Epoch 3::Minibatch 614::LR 0.0953846153846 --> Loss 0.00238105972608\n",
      "Epoch 3::Minibatch 615::LR 0.0953846153846 --> Loss 0.00168651123842\n",
      "Epoch 3::Minibatch 616::LR 0.0953846153846 --> Loss 0.000917574564616\n",
      "Epoch 3::Minibatch 617::LR 0.0953846153846 --> Loss 0.000476495971282\n",
      "Epoch 3::Minibatch 618::LR 0.0953846153846 --> Loss 0.00248903532823\n",
      "Epoch 3::Minibatch 619::LR 0.0953846153846 --> Loss 0.00190840184689\n",
      "Epoch 3::Minibatch 620::LR 0.0953846153846 --> Loss 0.00174210806688\n",
      "Epoch 3::Minibatch 621::LR 0.0953846153846 --> Loss 0.000852764646212\n",
      "Epoch 3::Minibatch 622::LR 0.0953846153846 --> Loss 0.000773714880149\n",
      "Epoch 3::Minibatch 623::LR 0.0953846153846 --> Loss 0.00220242361228\n",
      "Epoch 3::Minibatch 624::LR 0.0953846153846 --> Loss 0.00180150449276\n",
      "Epoch 3::Minibatch 625::LR 0.0953846153846 --> Loss 0.00302529772123\n",
      "Epoch 3::Minibatch 626::LR 0.0953846153846 --> Loss 0.00474404652913\n",
      "Epoch 3::Minibatch 627::LR 0.0953846153846 --> Loss 0.00132350077232\n",
      "Epoch 3::Minibatch 628::LR 0.0953846153846 --> Loss 0.000883228381475\n",
      "Epoch 3::Minibatch 629::LR 0.0953846153846 --> Loss 0.00339127103488\n",
      "Epoch 3::Minibatch 630::LR 0.0953846153846 --> Loss 0.00321702599525\n",
      "Epoch 3::Minibatch 631::LR 0.0953846153846 --> Loss 0.00650002598763\n",
      "Epoch 3::Minibatch 632::LR 0.0953846153846 --> Loss 0.000785682549079\n",
      "Epoch 3::Minibatch 633::LR 0.0953846153846 --> Loss 0.00160784423351\n",
      "Epoch 3::Minibatch 634::LR 0.0953846153846 --> Loss 0.00309141159058\n",
      "Epoch 3::Minibatch 635::LR 0.0953846153846 --> Loss 0.00422784248988\n",
      "Epoch 3::Minibatch 636::LR 0.0953846153846 --> Loss 0.00512046019236\n",
      "Epoch 3::Minibatch 637::LR 0.0953846153846 --> Loss 0.000782110095024\n",
      "Epoch 3::Minibatch 638::LR 0.0953846153846 --> Loss 0.00153604427973\n",
      "Epoch 3::Minibatch 639::LR 0.0953846153846 --> Loss 0.00335868120193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3::Minibatch 640::LR 0.0953846153846 --> Loss 0.00512576063474\n",
      "Epoch 3::Minibatch 641::LR 0.0953846153846 --> Loss 0.0030997912089\n",
      "Epoch 3::Minibatch 642::LR 0.0953846153846 --> Loss 0.000506722728411\n",
      "Epoch 3::Minibatch 643::LR 0.0953846153846 --> Loss 0.00225469251474\n",
      "Epoch 3::Minibatch 644::LR 0.0953846153846 --> Loss 0.003804119428\n",
      "Epoch 3::Minibatch 645::LR 0.0953846153846 --> Loss 0.00384250203768\n",
      "Epoch 3::Minibatch 646::LR 0.0953846153846 --> Loss 0.00148575832446\n",
      "Epoch 3::Minibatch 647::LR 0.0953846153846 --> Loss 0.000527775039275\n",
      "Epoch 3::Minibatch 648::LR 0.0953846153846 --> Loss 0.00287303566933\n",
      "Epoch 3::Minibatch 649::LR 0.0953846153846 --> Loss 0.00338815053304\n",
      "Epoch 3::Minibatch 650::LR 0.0953846153846 --> Loss 0.00320066730181\n",
      "Epoch 3::Minibatch 651::LR 0.0953846153846 --> Loss 0.00136439283689\n",
      "Epoch 3::Minibatch 652::LR 0.0953846153846 --> Loss 0.000773888925711\n",
      "Epoch 3::Minibatch 653::LR 0.0953846153846 --> Loss 0.00276384294033\n",
      "Epoch 3::Minibatch 654::LR 0.0953846153846 --> Loss 0.0029232164224\n",
      "Epoch 3::Minibatch 655::LR 0.0953846153846 --> Loss 0.00346012393634\n",
      "Epoch 3::Minibatch 656::LR 0.0953846153846 --> Loss 0.000723272462686\n",
      "Epoch 3::Minibatch 657::LR 0.0953846153846 --> Loss 0.00212385475636\n",
      "Epoch 3::Minibatch 658::LR 0.0953846153846 --> Loss 0.00523316780726\n",
      "Epoch 3::Minibatch 659::LR 0.0953846153846 --> Loss 0.00235467533271\n",
      "Epoch 3::Minibatch 660::LR 0.0953846153846 --> Loss 0.00259688436985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-4e17deee0c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                      \u001b[0minstance_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                      lr_init=lr_init,momentum=momentum)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-5c86ddefce5e>\u001b[0m in \u001b[0;36mkfold_validation\u001b[0;34m(model, X, Y, X_test, Y_test, instance_weights, n_folds, n_epochs, lr_init, momentum)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# change instance_weighst to instance_Weights_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         train(model,X_train,y_train,X_valid,y_valid,weights=instance_weights,\n\u001b[0;32m---> 41\u001b[0;31m             n_epoch=n_epochs,batch_size=bs,lr_init=lr_init,momentum=momentum,fold=fold)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0meval_bool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-3296abb89014>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, Y, X_test, Y_test, weights, n_epoch, batch_size, lr_init, momentum, fold)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#loss=mask(criterion=criterion,y_true=labels,y_pred=output,mask_value=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#used for compare\n",
    "class LinearMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMLP,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "mlp0H_train_dict = dict()\n",
    "mlp0H_test_dict = dict()\n",
    "# Train for Linear MLP \n",
    "model=LinearMLP()\n",
    "print(model)\n",
    "\n",
    "# model,X,Y,instance_weights,n_folds,n_epochs,lr_init,momentum\n",
    "mlp0H_train_dict,mlp0H_test_dict=kfold_validation(model,X =X_combined,\n",
    "                    Y=Y_combined,\n",
    "                     instance_weights=weights[0],n_folds = n_fold,n_epochs=n_epoch,\n",
    "                     lr_init=lr_init,momentum=momentum)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearMLP(\n",
      "  (fc1): Linear(in_features=175, out_features=51, bias=True)\n",
      ")\n",
      "0 starting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a44b66e82e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                      \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                      lr_init=lr_init,momentum=momentum,fold = fold_n)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"finished for fold {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-c1b4508cde54>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, Y, X_test, Y_test, weights, n_epoch, batch_size, lr_init, momentum, fold)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_instance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ef27ac39d06e>\u001b[0m in \u001b[0;36mget_instance_matrix\u001b[0;34m(y_train)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_column\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0minstance_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_column\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0minstance_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_neg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcount_0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcount_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_column\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#For 5cv the author used\n",
    "class LinearMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMLP,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "mlp0H_train_dict = dict()\n",
    "mlp0H_test_dict = dict()\n",
    "# Train for Linear MLP\n",
    "model=LinearMLP()\n",
    "print(model)\n",
    "\n",
    "\n",
    "for fold_n in [0,1,2,3,4]:\n",
    "    print \"{} starting\".format(fold_n)\n",
    "#     weights = get_instance_weight(y_train[fold_n])\n",
    "    mlp0H_train_dict[fold_n],mlp0H_test_dict[fold_n]=train(model,X =x_train[fold_n],\n",
    "                    Y=y_train[fold_n],X_test=x_test[fold_n],Y_test = y_test[fold_n],\n",
    "                     weights=weights[fold_n],n_epoch=n_epoch, batch_size = bs,\n",
    "                     lr_init=lr_init,momentum=momentum)\n",
    "    print \"finished for fold {}\".format(fold_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing outputs\n",
    "mlp0H_train_summary=Customdictionary()\n",
    "mlp0H_test_summary=Customdictionary()\n",
    "\n",
    "for k,v in mlp0H_train_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp0H_train_summary[k2]=v2\n",
    "for k,v in mlp0H_test_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp0H_test_summary[k2]=v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOILET --> Bal. accuracy 0.5248\n",
      "SHOPPING --> Bal. accuracy 0.538\n",
      "BICYCLING --> Bal. accuracy 0.5276\n",
      "PHONE_IN_BAG --> Bal. accuracy 0.503\n",
      "FIX_restaurant --> Bal. accuracy 0.5027\n",
      "BATHING_-_SHOWER --> Bal. accuracy 0.535\n",
      "SLEEPING --> Bal. accuracy 0.5078\n",
      "LOC_home --> Bal. accuracy 0.5204\n",
      "WATCHING_TV --> Bal. accuracy 0.5192\n",
      "CLEANING --> Bal. accuracy 0.594\n",
      "LOC_beach --> Bal. accuracy 0.7275\n",
      "EATING --> Bal. accuracy 0.501\n",
      "STAIRS_-_GOING_UP --> Bal. accuracy 0.5134\n",
      "DRIVE_-_I_M_THE_DRIVER --> Bal. accuracy 0.4103\n",
      "OR_indoors --> Bal. accuracy 0.5295\n",
      "SURFING_THE_INTERNET --> Bal. accuracy 0.4992\n",
      "STAIRS_-_GOING_DOWN --> Bal. accuracy 0.6151\n",
      "OR_exercise --> Bal. accuracy 0.4984\n",
      "STROLLING --> Bal. accuracy 0.4069\n",
      "AT_A_PARTY --> Bal. accuracy 0.6081\n",
      "AT_A_BAR --> Bal. accuracy 0.7292\n",
      "TALKING --> Bal. accuracy 0.5172\n",
      "IN_A_MEETING --> Bal. accuracy 0.4783\n",
      "DOING_LAUNDRY --> Bal. accuracy 0.3773\n",
      "DRESSING --> Bal. accuracy 0.5147\n",
      "GROOMING --> Bal. accuracy 0.5547\n",
      "SINGING --> Bal. accuracy 0.484\n",
      "AT_THE_GYM --> Bal. accuracy 0.605\n",
      "FIX_running --> Bal. accuracy 0.4613\n",
      "ON_A_BUS --> Bal. accuracy 0.5051\n",
      "LOC_main_workplace --> Bal. accuracy 0.4902\n",
      "PHONE_ON_TABLE --> Bal. accuracy 0.4863\n",
      "COOKING --> Bal. accuracy 0.5306\n",
      "LYING_DOWN --> Bal. accuracy 0.5875\n",
      "DRIVE_-_I_M_A_PASSENGER --> Bal. accuracy 0.4361\n",
      "IN_CLASS --> Bal. accuracy 0.5028\n",
      "OR_outside --> Bal. accuracy 0.4999\n",
      "FIX_walking --> Bal. accuracy 0.5544\n",
      "PHONE_IN_HAND --> Bal. accuracy 0.5184\n",
      "PHONE_IN_POCKET --> Bal. accuracy 0.4912\n",
      "WASHING_DISHES --> Bal. accuracy 0.5007\n",
      "WITH_FRIENDS --> Bal. accuracy 0.5084\n",
      "SITTING --> Bal. accuracy 0.5411\n",
      "COMPUTER_WORK --> Bal. accuracy 0.4758\n",
      "AT_SCHOOL --> Bal. accuracy 0.5221\n",
      "WITH_CO-WORKERS --> Bal. accuracy 0.532\n",
      "ELEVATOR --> Bal. accuracy 0.6893\n",
      "LAB_WORK --> Bal. accuracy 0.4868\n",
      "IN_A_CAR --> Bal. accuracy 0.525\n",
      "DRINKING__ALCOHOL_ --> Bal. accuracy 0.4825\n",
      "OR_standing --> Bal. accuracy 0.4967\n"
     ]
    }
   ],
   "source": [
    "# Mean dicts\n",
    "for k,v in mlp0H_test_summary.items():\n",
    "    v_mean=np.mean(v)\n",
    "    print('{} --> Bal. accuracy {}'.format(k,np.round(v_mean,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mlp0H_valid_summary.items()[0]\n",
    "# print np.mean(mlp0H_valid_summary.items()[0][1])\n",
    "\n",
    "with open('result/mlp_175_5cv_linear_result.csv','a') as output_file:\n",
    "    output_file.write('label,train_BA,test_BA\\n')\n",
    "    for k in mlp0H_test_summary.keys():\n",
    "        v_mean_test=np.round(np.mean(mlp0H_test_summary[k]),4)\n",
    "        v_mean_train=np.round(np.mean(mlp0H_train_summary[k]),4)\n",
    "        output_file.write(str(k)+','+str(v_mean_train)+','+str(v_mean_test)+'\\n')\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bal. accuracy 0.5229\n"
     ]
    }
   ],
   "source": [
    "average = 0.\n",
    "for k,v in mlp0H_test_summary.items():\n",
    "    average += np.mean(v)\n",
    "print('Bal. accuracy {}'.format(np.round(average/51.,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_0hidden'\n",
    "checkpoint_path=root+'mlp_0hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': n_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (1 Hidden Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_1H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "# Train for MLP-1 Hidden\n",
    "model=MLP_1H()\n",
    "print(model)\n",
    "mlp1H_train_dict,mlp1H_valid_dict=kfold_validation(model,X=X_combined,Y=Y_combined,\n",
    "                 instance_weights=instance_weights,n_folds=n_fold,n_epochs=n_epoch,\n",
    "                 lr_init=lr_init,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing outputs\n",
    "mlp1H_train_summary=Customdictionary()\n",
    "mlp1H_valid_summary=Customdictionary()\n",
    "\n",
    "for k,v in mlp1H_train_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp01H_train_summary[k2]=v2\n",
    "for k,v in mlp1H_valid_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp1H_valid_summary[k2]=v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean dicts\n",
    "for k,v in mlp1H_valid_summary.items():\n",
    "    v_mean=np.mean(v)\n",
    "    print('{} --> Bal. accuracy {}'.format(k,np.round(v_mean,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_1hidden'\n",
    "checkpoint_path=root+'mlp_1hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2H(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2H,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "# Train for MLP-2 Hidden\n",
    "model=MLP_2H()\n",
    "print(model)\n",
    "mlp2H_train_dict,mlp2H_valid_dict=kfold_validation(model,X=X_combined,Y=Y_combined,\n",
    "                 instance_weights=instance_weights,n_folds=n_fold,n_epochs=n_epoch,\n",
    "                 lr_init=lr_init,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing outputs\n",
    "mlp2H_train_summary=Customdictionary()\n",
    "mlp2H_valid_summary=Customdictionary()\n",
    "\n",
    "for k,v in mlp2H_train_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp2H_train_summary[k2]=v2\n",
    "for k,v in mlp2H_valid_dict.items():\n",
    "    for k2,v2 in v.items():\n",
    "        mlp2H_valid_summary[k2]=v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean dicts\n",
    "for k,v in mlp2H_valid_summary.items():\n",
    "    v_mean=np.mean(v)\n",
    "    print('{} --> Bal. accuracy {}'.format(k,np.round(v_mean,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy outputs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hidden'\n",
    "checkpoint_path=root+'mlp_2hidden_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (2 Hidden Layers, with Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_2HDrop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_2HDrop,self).__init__()\n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.20)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model=MLP_2HDrop()\n",
    "C(model) # Train model with CUDA\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=lr_init,momentum=momentum)\n",
    "#criterion=C(nn.BCEWithLogitsLoss()) # Or MultiLabelSoftMarginLoss (same thing in this case)\n",
    "#criterion=C(nn.BCELoss()) # BCEWithLogitsLoss adds a sigmoid layer to the BCELoss layer.\n",
    "# However, we want to binarize the outputs of the sigmoid first before getting the loss.\n",
    "# Though the BCELoss isn't very stable by itself.\n",
    "#criterion=C(nn.MultiLabelMarginLoss) # Needs the sigmoid output first\n",
    "criterion=C(nn.MultiLabelSoftMarginLoss())\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    sum_total=0.\n",
    "    done=1\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=V(C(inputs)).float()\n",
    "        labels=V(C(labels),requires_grad=False).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        if done:\n",
    "            linear_lr_scheduler(optimizer,epoch) # Reduce LR once every epoch\n",
    "            done=0\n",
    "        \n",
    "        output=model(inputs) # Log probabilities\n",
    "        #sigmoid_output=torch.sigmoid(output) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "        #sigmoid_output=(sigmoid_output>=0.50).type(torch.cuda.FloatTensor)# Binarize outputs using a threshold\n",
    "        #sigmoid_output=V(sigmoid_output,requires_grad=True)\n",
    "        \n",
    "        loss=criterion(output.type(torch.cuda.FloatTensor),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_total+=loss.item()\n",
    "        #print(\"Batch Loss: \",loss.item())\n",
    "        for param_group in optimizer.param_groups:\n",
    "            epoch_lr=param_group['lr']\n",
    "        if i%300==0: # Every minibatch\n",
    "            print(\"Epoch {}::Minibatch {}::LR {} --> Loss {}\".format(epoch+1,i+1,epoch_lr,sum_total/bs))\n",
    "            sum_total=0.\n",
    "    done=1\n",
    "print('\\n Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Saving trained models\n",
    "root='saved_models/multilabel_classifier/'\n",
    "model_path=root+'mlp_2hiddendrop'\n",
    "checkpoint_path=root+'mlp_2hiddendrop_checkpoint'\n",
    "\n",
    "torch.save(model,model_path) # Saving the whole model\n",
    "\n",
    "# Saving checkpoint model\n",
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            'sumloss':sum_total/bs},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "# Precision, Recall, F-1, support\n",
    "mlp_0H_clfreport=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Test Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train dataset model performance\n",
    "\n",
    "concat_predictions=torch.zeros(0,output_size)\n",
    "concat_truelabels=torch.zeros(0,output_size)\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs,labels=data\n",
    "    inputs=V(C(inputs)).float()\n",
    "    labels=V(C(labels)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    outputs=model.forward(inputs).cpu() # Perform test time on CPU instead of GPU\n",
    "    \n",
    "    # Concat test set into one tensor\n",
    "    concat_predictions=torch.cat((concat_predictions,outputs),0)\n",
    "    concat_truelabels=torch.cat((concat_truelabels,labels.cpu()),0)\n",
    "\n",
    "concat_predictions=torch.sigmoid(concat_predictions) # Squash log probabilities to between 0 -1 (linear scale)\n",
    "concat_predictions=concat_predictions>=0.50 # Binarize outputs using a threshold\n",
    "\n",
    "# Convert tensor to numpy float array\n",
    "concat_predictions=concat_predictions.numpy().astype(np.float)\n",
    "concat_truelabels=concat_truelabels.numpy().astype(np.float)\n",
    "\n",
    "mlp_0H_clfreport_train=classification_report(y_true=concat_truelabels,y_pred=concat_predictions,\n",
    "                                       target_names=labelname_user,output_dict=True)\n",
    "print('Train Set')\n",
    "for i in range(output_size):\n",
    "    true_perlabel=concat_truelabels[:,i]\n",
    "    prediction_perlabel=concat_predictions[:,i]\n",
    "    bal_acc=balanced_accuracy_score(y_true=true_perlabel,y_pred=prediction_perlabel)\n",
    "    \n",
    "    print('Label {} :::-> Balanced Accuracy {}'.format(labelname_user[i],round(bal_acc,5)))\n",
    "    \n",
    "for key,value in enumerate(mlp_0H_clfreport_train.items()):\n",
    "    print(key,\"\\n\")\n",
    "    print(\"\\t\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12.2333px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.983px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "930.85px",
    "left": "2.28333px",
    "right": "1417.63px",
    "top": "578px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
